<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.5">Jekyll</generator><link href="http://0.0.0.0:8855/feed.xml" rel="self" type="application/atom+xml" /><link href="http://0.0.0.0:8855/" rel="alternate" type="text/html" /><updated>2024-02-25T19:47:00+08:00</updated><id>http://0.0.0.0:8855/feed.xml</id><title type="html">Zhu Philip’s AI Journey</title><subtitle></subtitle><author><name>Zhu Tianda</name></author><entry><title type="html">A Diffusion Model from Scratch in Pytorch</title><link href="http://0.0.0.0:8855/coding/2023/12/11/diffusion-model-demo2.html" rel="alternate" type="text/html" title="A Diffusion Model from Scratch in Pytorch" /><published>2023-12-11T00:00:00+08:00</published><updated>2023-12-11T00:00:00+08:00</updated><id>http://0.0.0.0:8855/coding/2023/12/11/diffusion-model-demo2</id><content type="html" xml:base="http://0.0.0.0:8855/coding/2023/12/11/diffusion-model-demo2.html"><![CDATA[<h1 id="a-diffusion-model-from-scratch-in-pytorch">A Diffusion Model from Scratch in Pytorch</h1>

<p>In this notebook I want to build a very simple (as few code as possible) Diffusion Model for generating car images. I will explain all the theoretical details in the YouTube video.</p>

<p><strong>Sources:</strong></p>
<ul>
  <li>Github implementation <a href="https://github.com/lucidrains/denoising-diffusion-pytorch">Denoising Diffusion Pytorch</a></li>
  <li>Niels Rogge, Kashif Rasul, <a href="https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/annotated_diffusion.ipynb#scrollTo=3a159023">Huggingface notebook</a></li>
  <li>Papers on Diffusion models ([Dhariwal, Nichol, 2021], [Ho et al., 2020] ect.)</li>
</ul>

<h2 id="investigating-the-dataset">Investigating the dataset</h2>

<p>As dataset we use the StandordCars Dataset, which consists of around 8000 images in the train set. Let’s see if this is enough to get good results ;-)</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torchvision</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="k">def</span> <span class="nf">show_images</span><span class="p">(</span><span class="n">datset</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">cols</span><span class="o">=</span><span class="mi">4</span><span class="p">):</span>
    <span class="s">""" Plots some samples from the dataset """</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">15</span><span class="p">))</span> 
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">img</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="n">num_samples</span><span class="p">:</span>
            <span class="k">break</span>
        <span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">num_samples</span><span class="o">/</span><span class="n">cols</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">cols</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span> <span class="o">=</span> <span class="n">torchvision</span><span class="p">.</span><span class="n">datasets</span><span class="p">.</span><span class="n">StanfordCars</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s">"."</span><span class="p">)</span>
<span class="n">show_images</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/assets/2023-12-11-diffusion-model-demo2_files/2023-12-11-diffusion-model-demo2_3_0.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#Try to setup cars image locally by own dataset
#dataset = torchvision.datasets.ImageFolder("./stanford_cars")
#show_images(data)
</span>
<span class="c1">#dataset = V.datasets.ImageFolder(args.dataset_path, transform=transforms)
#dataloader = DataLoader(dataset, batch_size=args.batch_size, shuffle=True)
</span>
</code></pre></div></div>

<p>Later in this notebook we will do some additional modifications to this dataset, for example make the images smaller, convert them to tensors ect.</p>

<h1 id="building-the-diffusion-model">Building the Diffusion Model</h1>

<h2 id="step-1-the-forward-process--noise-scheduler">Step 1: The forward process = Noise scheduler</h2>

<p>We first need to build the inputs for our model, which are more and more noisy images. Instead of doing this sequentially, we can use the closed form provided in the papers to calculate the image for any of the timesteps individually.</p>

<p><strong>Key Takeaways</strong>:</p>
<ul>
  <li>The noise-levels/variances can be pre-computed</li>
  <li>There are different types of variance schedules</li>
  <li>We can sample each timestep image independently (Sums of Gaussians is also Gaussian)</li>
  <li>No model is needed in this forward step</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="n">F</span>

<span class="k">def</span> <span class="nf">linear_beta_schedule</span><span class="p">(</span><span class="n">timesteps</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="mf">0.02</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">timesteps</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">get_index_from_list</span><span class="p">(</span><span class="n">vals</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_shape</span><span class="p">):</span>
    <span class="s">""" 
    Returns a specific index t of a passed list of values vals
    while considering the batch dimension.
    """</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">t</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">vals</span><span class="p">.</span><span class="n">gather</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">t</span><span class="p">.</span><span class="n">cpu</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">out</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">*</span><span class="p">((</span><span class="mi">1</span><span class="p">,)</span> <span class="o">*</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x_shape</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))).</span><span class="n">to</span><span class="p">(</span><span class="n">t</span><span class="p">.</span><span class="n">device</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">forward_diffusion_sample</span><span class="p">(</span><span class="n">x_0</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s">"cpu"</span><span class="p">):</span>
    <span class="s">""" 
    Takes an image and a timestep as input and 
    returns the noisy version of it
    """</span>
    <span class="n">noise</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">x_0</span><span class="p">)</span>
    <span class="n">sqrt_alphas_cumprod_t</span> <span class="o">=</span> <span class="n">get_index_from_list</span><span class="p">(</span><span class="n">sqrt_alphas_cumprod</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_0</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">sqrt_one_minus_alphas_cumprod_t</span> <span class="o">=</span> <span class="n">get_index_from_list</span><span class="p">(</span>
        <span class="n">sqrt_one_minus_alphas_cumprod</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_0</span><span class="p">.</span><span class="n">shape</span>
    <span class="p">)</span>
    <span class="c1"># mean + variance
</span>    <span class="k">return</span> <span class="n">sqrt_alphas_cumprod_t</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="o">*</span> <span class="n">x_0</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> \
    <span class="o">+</span> <span class="n">sqrt_one_minus_alphas_cumprod_t</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="o">*</span> <span class="n">noise</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">noise</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>


<span class="c1"># Define beta schedule
</span><span class="n">T</span> <span class="o">=</span> <span class="mi">300</span>
<span class="n">betas</span> <span class="o">=</span> <span class="n">linear_beta_schedule</span><span class="p">(</span><span class="n">timesteps</span><span class="o">=</span><span class="n">T</span><span class="p">)</span>

<span class="c1"># Pre-calculate different terms for closed form
</span><span class="n">alphas</span> <span class="o">=</span> <span class="mf">1.</span> <span class="o">-</span> <span class="n">betas</span>
<span class="n">alphas_cumprod</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cumprod</span><span class="p">(</span><span class="n">alphas</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">alphas_cumprod_prev</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">pad</span><span class="p">(</span><span class="n">alphas_cumprod</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">value</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<span class="n">sqrt_recip_alphas</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="n">alphas</span><span class="p">)</span>
<span class="n">sqrt_alphas_cumprod</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">alphas_cumprod</span><span class="p">)</span>
<span class="n">sqrt_one_minus_alphas_cumprod</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="n">alphas_cumprod</span><span class="p">)</span>
<span class="n">posterior_variance</span> <span class="o">=</span> <span class="n">betas</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="n">alphas_cumprod_prev</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="n">alphas_cumprod</span><span class="p">)</span>
</code></pre></div></div>

<p>Let’s test it on our dataset …</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">transforms</span> 
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="n">IMG_SIZE</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">128</span>

<span class="k">def</span> <span class="nf">load_transformed_dataset</span><span class="p">():</span>
    <span class="n">data_transforms</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">transforms</span><span class="p">.</span><span class="n">Resize</span><span class="p">((</span><span class="n">IMG_SIZE</span><span class="p">,</span> <span class="n">IMG_SIZE</span><span class="p">)),</span>
        <span class="n">transforms</span><span class="p">.</span><span class="n">RandomHorizontalFlip</span><span class="p">(),</span>
        <span class="n">transforms</span><span class="p">.</span><span class="n">ToTensor</span><span class="p">(),</span> <span class="c1"># Scales data into [0,1] 
</span>        <span class="n">transforms</span><span class="p">.</span><span class="n">Lambda</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="p">(</span><span class="n">t</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># Scale between [-1, 1] 
</span>    <span class="p">]</span>
    <span class="n">data_transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="p">.</span><span class="n">Compose</span><span class="p">(</span><span class="n">data_transforms</span><span class="p">)</span>

    <span class="n">train</span> <span class="o">=</span> <span class="n">torchvision</span><span class="p">.</span><span class="n">datasets</span><span class="p">.</span><span class="n">StanfordCars</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s">"."</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
                                         <span class="n">transform</span><span class="o">=</span><span class="n">data_transform</span><span class="p">)</span>

    <span class="n">test</span> <span class="o">=</span> <span class="n">torchvision</span><span class="p">.</span><span class="n">datasets</span><span class="p">.</span><span class="n">StanfordCars</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s">"."</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
                                         <span class="n">transform</span><span class="o">=</span><span class="n">data_transform</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s">'test'</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">ConcatDataset</span><span class="p">([</span><span class="n">train</span><span class="p">,</span> <span class="n">test</span><span class="p">])</span>
<span class="k">def</span> <span class="nf">show_tensor_image</span><span class="p">(</span><span class="n">image</span><span class="p">):</span>
    <span class="n">reverse_transforms</span> <span class="o">=</span> <span class="n">transforms</span><span class="p">.</span><span class="n">Compose</span><span class="p">([</span>
        <span class="n">transforms</span><span class="p">.</span><span class="n">Lambda</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="p">(</span><span class="n">t</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">),</span>
        <span class="n">transforms</span><span class="p">.</span><span class="n">Lambda</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">t</span><span class="p">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">)),</span> <span class="c1"># CHW to HWC
</span>        <span class="n">transforms</span><span class="p">.</span><span class="n">Lambda</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">t</span> <span class="o">*</span> <span class="mf">255.</span><span class="p">),</span>
        <span class="n">transforms</span><span class="p">.</span><span class="n">Lambda</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">t</span><span class="p">.</span><span class="n">numpy</span><span class="p">().</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">uint8</span><span class="p">)),</span>
        <span class="n">transforms</span><span class="p">.</span><span class="n">ToPILImage</span><span class="p">(),</span>
    <span class="p">])</span>

    <span class="c1"># Take first image of batch
</span>    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">image</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
        <span class="n">image</span> <span class="o">=</span> <span class="n">image</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:]</span> 
    <span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">reverse_transforms</span><span class="p">(</span><span class="n">image</span><span class="p">))</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">load_transformed_dataset</span><span class="p">()</span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">drop_last</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Simulate forward diffusion
</span><span class="n">image</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">dataloader</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>

<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">15</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">axis</span><span class="p">(</span><span class="s">'off'</span><span class="p">)</span>
<span class="n">num_images</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">stepsize</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">T</span><span class="o">/</span><span class="n">num_images</span><span class="p">)</span>

<span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">stepsize</span><span class="p">):</span>
    <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">([</span><span class="n">idx</span><span class="p">]).</span><span class="nb">type</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">int64</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_images</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">idx</span><span class="o">/</span><span class="n">stepsize</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">img</span><span class="p">,</span> <span class="n">noise</span> <span class="o">=</span> <span class="n">forward_diffusion_sample</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
    <span class="n">show_tensor_image</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>/tmp/ipykernel_215535/1509478405.py:11: MatplotlibDeprecationWarning: Auto-removal of overlapping axes is deprecated since 3.6 and will be removed two minor releases later; explicitly call ax.remove() as needed.
  plt.subplot(1, num_images+1, int(idx/stepsize) + 1)
</code></pre></div></div>

<p><img src="/assets/2023-12-11-diffusion-model-demo2_files/2023-12-11-diffusion-model-demo2_12_1.png" alt="png" /></p>

<h2 id="step-2-the-backward-process--u-net">Step 2: The backward process = U-Net</h2>

<p>For a great introduction to UNets, have a look at this post: https://amaarora.github.io/2020/09/13/unet.html.</p>

<p><strong>Key Takeaways</strong>:</p>
<ul>
  <li>We use a simple form of a UNet for to predict the noise in the image</li>
  <li>The input is a noisy image, the ouput the noise in the image</li>
  <li>Because the parameters are shared accross time, we need to tell the network in which timestep we are</li>
  <li>The Timestep is encoded by the transformer Sinusoidal Embedding</li>
  <li>We output one single value (mean), because the variance is fixed</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="nn">math</span>


<span class="k">class</span> <span class="nc">Block</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_ch</span><span class="p">,</span> <span class="n">out_ch</span><span class="p">,</span> <span class="n">time_emb_dim</span><span class="p">,</span> <span class="n">up</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">time_mlp</span> <span class="o">=</span>  <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">time_emb_dim</span><span class="p">,</span> <span class="n">out_ch</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">up</span><span class="p">:</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">in_ch</span><span class="p">,</span> <span class="n">out_ch</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">transform</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span><span class="n">out_ch</span><span class="p">,</span> <span class="n">out_ch</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_ch</span><span class="p">,</span> <span class="n">out_ch</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">transform</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">out_ch</span><span class="p">,</span> <span class="n">out_ch</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">out_ch</span><span class="p">,</span> <span class="n">out_ch</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">bnorm1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">out_ch</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">bnorm2</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">out_ch</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">relu</span>  <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">()</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="p">):</span>
        <span class="c1"># First Conv
</span>        <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">bnorm1</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
        <span class="c1"># Time embedding
</span>        <span class="n">time_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">time_mlp</span><span class="p">(</span><span class="n">t</span><span class="p">))</span>
        <span class="c1"># Extend last 2 dimensions
</span>        <span class="n">time_emb</span> <span class="o">=</span> <span class="n">time_emb</span><span class="p">[(...,</span> <span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="p">)</span> <span class="o">*</span> <span class="mi">2</span><span class="p">]</span>
        <span class="c1"># Add time channel
</span>        <span class="n">h</span> <span class="o">=</span> <span class="n">h</span> <span class="o">+</span> <span class="n">time_emb</span>
        <span class="c1"># Second Conv
</span>        <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">bnorm2</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">h</span><span class="p">)))</span>
        <span class="c1"># Down or Upsample
</span>        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">SinusoidalPositionEmbeddings</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">dim</span> <span class="o">=</span> <span class="n">dim</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">time</span><span class="p">):</span>
        <span class="n">device</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="n">device</span>
        <span class="n">half_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">dim</span> <span class="o">//</span> <span class="mi">2</span>
        <span class="n">embeddings</span> <span class="o">=</span> <span class="n">math</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="mi">10000</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">half_dim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">embeddings</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="n">half_dim</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span> <span class="o">*</span> <span class="o">-</span><span class="n">embeddings</span><span class="p">)</span>
        <span class="n">embeddings</span> <span class="o">=</span> <span class="n">time</span><span class="p">[:,</span> <span class="bp">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">embeddings</span><span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="p">:]</span>
        <span class="n">embeddings</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">((</span><span class="n">embeddings</span><span class="p">.</span><span class="n">sin</span><span class="p">(),</span> <span class="n">embeddings</span><span class="p">.</span><span class="n">cos</span><span class="p">()),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># TODO: Double check the ordering here
</span>        <span class="k">return</span> <span class="n">embeddings</span>


<span class="k">class</span> <span class="nc">SimpleUnet</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="s">"""
    A simplified variant of the Unet architecture.
    """</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="n">image_channels</span> <span class="o">=</span> <span class="mi">3</span>
        <span class="n">down_channels</span> <span class="o">=</span> <span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">1024</span><span class="p">)</span>
        <span class="n">up_channels</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>
        <span class="n">out_dim</span> <span class="o">=</span> <span class="mi">3</span> 
        <span class="n">time_emb_dim</span> <span class="o">=</span> <span class="mi">32</span>

        <span class="c1"># Time embedding
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">time_mlp</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
                <span class="n">SinusoidalPositionEmbeddings</span><span class="p">(</span><span class="n">time_emb_dim</span><span class="p">),</span>
                <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">time_emb_dim</span><span class="p">,</span> <span class="n">time_emb_dim</span><span class="p">),</span>
                <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">()</span>
            <span class="p">)</span>
        
        <span class="c1"># Initial projection
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">conv0</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">image_channels</span><span class="p">,</span> <span class="n">down_channels</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Downsample
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">downs</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">ModuleList</span><span class="p">([</span><span class="n">Block</span><span class="p">(</span><span class="n">down_channels</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">down_channels</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> \
                                    <span class="n">time_emb_dim</span><span class="p">)</span> \
                    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">down_channels</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">)])</span>
        <span class="c1"># Upsample
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">ups</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">ModuleList</span><span class="p">([</span><span class="n">Block</span><span class="p">(</span><span class="n">up_channels</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">up_channels</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> \
                                        <span class="n">time_emb_dim</span><span class="p">,</span> <span class="n">up</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> \
                    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">up_channels</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">)])</span>
        
        <span class="c1"># Edit: Corrected a bug found by Jakub C (see YouTube comment)
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">output</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">up_channels</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">out_dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">timestep</span><span class="p">):</span>
        <span class="c1"># Embedd time
</span>        <span class="n">t</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">time_mlp</span><span class="p">(</span><span class="n">timestep</span><span class="p">)</span>
        <span class="c1"># Initial conv
</span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">conv0</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="c1"># Unet
</span>        <span class="n">residual_inputs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">down</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">downs</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">down</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
            <span class="n">residual_inputs</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">up</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">ups</span><span class="p">:</span>
            <span class="n">residual_x</span> <span class="o">=</span> <span class="n">residual_inputs</span><span class="p">.</span><span class="n">pop</span><span class="p">()</span>
            <span class="c1"># Add residual x as additional channels
</span>            <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">residual_x</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>           
            <span class="n">x</span> <span class="o">=</span> <span class="n">up</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">output</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">SimpleUnet</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Num params: "</span><span class="p">,</span> <span class="nb">sum</span><span class="p">(</span><span class="n">p</span><span class="p">.</span><span class="n">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">()))</span>
<span class="n">model</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Num params:  62438883





SimpleUnet(
  (time_mlp): Sequential(
    (0): SinusoidalPositionEmbeddings()
    (1): Linear(in_features=32, out_features=32, bias=True)
    (2): ReLU()
  )
  (conv0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (downs): ModuleList(
    (0): Block(
      (time_mlp): Linear(in_features=32, out_features=128, bias=True)
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (transform): Conv2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bnorm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bnorm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU()
    )
    (1): Block(
      (time_mlp): Linear(in_features=32, out_features=256, bias=True)
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (transform): Conv2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bnorm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bnorm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU()
    )
    (2): Block(
      (time_mlp): Linear(in_features=32, out_features=512, bias=True)
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (transform): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bnorm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bnorm2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU()
    )
    (3): Block(
      (time_mlp): Linear(in_features=32, out_features=1024, bias=True)
      (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (transform): Conv2d(1024, 1024, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bnorm1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bnorm2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU()
    )
  )
  (ups): ModuleList(
    (0): Block(
      (time_mlp): Linear(in_features=32, out_features=512, bias=True)
      (conv1): Conv2d(2048, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (transform): ConvTranspose2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bnorm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bnorm2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU()
    )
    (1): Block(
      (time_mlp): Linear(in_features=32, out_features=256, bias=True)
      (conv1): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (transform): ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bnorm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bnorm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU()
    )
    (2): Block(
      (time_mlp): Linear(in_features=32, out_features=128, bias=True)
      (conv1): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (transform): ConvTranspose2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bnorm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bnorm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU()
    )
    (3): Block(
      (time_mlp): Linear(in_features=32, out_features=64, bias=True)
      (conv1): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (transform): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bnorm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bnorm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU()
    )
  )
  (output): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))
)
</code></pre></div></div>

<p><strong>Further improvements that can be implemented:</strong></p>
<ul>
  <li>Residual connections</li>
  <li>Different activation functions like SiLU, GWLU, …</li>
  <li>BatchNormalization</li>
  <li>GroupNormalization</li>
  <li>Attention</li>
  <li>…</li>
</ul>

<h2 id="step-3-the-loss">Step 3: The loss</h2>

<p><strong>Key Takeaways:</strong></p>
<ul>
  <li>After some maths we end up with a very simple loss function</li>
  <li>There are other possible choices like L2 loss ect.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">get_loss</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">x_0</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
    <span class="n">x_noisy</span><span class="p">,</span> <span class="n">noise</span> <span class="o">=</span> <span class="n">forward_diffusion_sample</span><span class="p">(</span><span class="n">x_0</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
    <span class="n">noise_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x_noisy</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">F</span><span class="p">.</span><span class="n">l1_loss</span><span class="p">(</span><span class="n">noise</span><span class="p">,</span> <span class="n">noise_pred</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="sampling">Sampling</h2>
<ul>
  <li>Without adding @torch.no_grad() we quickly run out of memory, because pytorch tacks all the previous images for gradient calculation</li>
  <li>Because we pre-calculated the noise variances for the forward pass, we also have to use them when we sequentially perform the backward process</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">@</span><span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">sample_timestep</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
    <span class="s">"""
    Calls the model to predict the noise in the image and returns 
    the denoised image. 
    Applies noise to this image, if we are not in the last step yet.
    """</span>
    <span class="n">betas_t</span> <span class="o">=</span> <span class="n">get_index_from_list</span><span class="p">(</span><span class="n">betas</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">sqrt_one_minus_alphas_cumprod_t</span> <span class="o">=</span> <span class="n">get_index_from_list</span><span class="p">(</span>
        <span class="n">sqrt_one_minus_alphas_cumprod</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span>
    <span class="p">)</span>
    <span class="n">sqrt_recip_alphas_t</span> <span class="o">=</span> <span class="n">get_index_from_list</span><span class="p">(</span><span class="n">sqrt_recip_alphas</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
    
    <span class="c1"># Call model (current image - noise prediction)
</span>    <span class="n">model_mean</span> <span class="o">=</span> <span class="n">sqrt_recip_alphas_t</span> <span class="o">*</span> <span class="p">(</span>
        <span class="n">x</span> <span class="o">-</span> <span class="n">betas_t</span> <span class="o">*</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span> <span class="o">/</span> <span class="n">sqrt_one_minus_alphas_cumprod_t</span>
    <span class="p">)</span>
    <span class="n">posterior_variance_t</span> <span class="o">=</span> <span class="n">get_index_from_list</span><span class="p">(</span><span class="n">posterior_variance</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">t</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># As pointed out by Luis Pereira (see YouTube comment)
</span>        <span class="c1"># The t's are offset from the t's in the paper
</span>        <span class="k">return</span> <span class="n">model_mean</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">noise</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">model_mean</span> <span class="o">+</span> <span class="n">torch</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">posterior_variance_t</span><span class="p">)</span> <span class="o">*</span> <span class="n">noise</span> 

<span class="o">@</span><span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">sample_plot_image</span><span class="p">():</span>
    <span class="c1"># Sample noise
</span>    <span class="n">img_size</span> <span class="o">=</span> <span class="n">IMG_SIZE</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">img_size</span><span class="p">,</span> <span class="n">img_size</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">15</span><span class="p">))</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">axis</span><span class="p">(</span><span class="s">'off'</span><span class="p">)</span>
    <span class="n">num_images</span> <span class="o">=</span> <span class="mi">10</span>
    <span class="n">stepsize</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">T</span><span class="o">/</span><span class="n">num_images</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">T</span><span class="p">)[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">full</span><span class="p">((</span><span class="mi">1</span><span class="p">,),</span> <span class="n">i</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nb">long</span><span class="p">)</span>
        <span class="n">img</span> <span class="o">=</span> <span class="n">sample_timestep</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
        <span class="c1"># Edit: This is to maintain the natural range of the distribution
</span>        <span class="n">img</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="n">stepsize</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_images</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">i</span><span class="o">/</span><span class="n">stepsize</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">show_tensor_image</span><span class="p">(</span><span class="n">img</span><span class="p">.</span><span class="n">detach</span><span class="p">().</span><span class="n">cpu</span><span class="p">())</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>            
</code></pre></div></div>

<h2 id="training">Training</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>

<span class="n">device</span> <span class="o">=</span> <span class="s">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s">"cpu"</span>
<span class="n">model</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">100</span> <span class="c1"># Try more!
</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">step</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">):</span>
      <span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>

      <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="p">(</span><span class="n">BATCH_SIZE</span><span class="p">,),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">).</span><span class="nb">long</span><span class="p">()</span>
      <span class="n">loss</span> <span class="o">=</span> <span class="n">get_loss</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">t</span><span class="p">)</span>
      <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
      <span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>

      <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="mi">5</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">step</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s"> | step </span><span class="si">{</span><span class="n">step</span><span class="si">:</span><span class="mi">03</span><span class="n">d</span><span class="si">}</span><span class="s"> Loss: </span><span class="si">{</span><span class="n">loss</span><span class="p">.</span><span class="n">item</span><span class="p">()</span><span class="si">}</span><span class="s"> "</span><span class="p">)</span>
        <span class="n">sample_plot_image</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 0 | step 000 Loss: 0.8095802068710327 


/tmp/ipykernel_215535/364762590.py:44: MatplotlibDeprecationWarning: Auto-removal of overlapping axes is deprecated since 3.6 and will be removed two minor releases later; explicitly call ax.remove() as needed.
  plt.subplot(1, num_images, int(i/stepsize)+1)
</code></pre></div></div>

<p><img src="/assets/2023-12-11-diffusion-model-demo2_files/2023-12-11-diffusion-model-demo2_23_2.png" alt="png" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 5 | step 000 Loss: 0.16724281013011932 
</code></pre></div></div>

<p><img src="/assets/2023-12-11-diffusion-model-demo2_files/2023-12-11-diffusion-model-demo2_23_4.png" alt="png" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 10 | step 000 Loss: 0.1452174186706543 
</code></pre></div></div>

<p><img src="/assets/2023-12-11-diffusion-model-demo2_files/2023-12-11-diffusion-model-demo2_23_6.png" alt="png" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 15 | step 000 Loss: 0.1479429304599762 
</code></pre></div></div>

<p><img src="/assets/2023-12-11-diffusion-model-demo2_files/2023-12-11-diffusion-model-demo2_23_8.png" alt="png" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 20 | step 000 Loss: 0.1445147842168808 
</code></pre></div></div>

<p><img src="/assets/2023-12-11-diffusion-model-demo2_files/2023-12-11-diffusion-model-demo2_23_10.png" alt="png" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 25 | step 000 Loss: 0.1543230563402176 
</code></pre></div></div>

<p><img src="/assets/2023-12-11-diffusion-model-demo2_files/2023-12-11-diffusion-model-demo2_23_12.png" alt="png" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 30 | step 000 Loss: 0.13048508763313293 
</code></pre></div></div>

<p><img src="/assets/2023-12-11-diffusion-model-demo2_files/2023-12-11-diffusion-model-demo2_23_14.png" alt="png" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 35 | step 000 Loss: 0.14282932877540588 
</code></pre></div></div>

<p><img src="/assets/2023-12-11-diffusion-model-demo2_files/2023-12-11-diffusion-model-demo2_23_16.png" alt="png" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 40 | step 000 Loss: 0.14221858978271484 
</code></pre></div></div>

<p><img src="/assets/2023-12-11-diffusion-model-demo2_files/2023-12-11-diffusion-model-demo2_23_18.png" alt="png" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 45 | step 000 Loss: 0.13406036794185638 
</code></pre></div></div>

<p><img src="/assets/2023-12-11-diffusion-model-demo2_files/2023-12-11-diffusion-model-demo2_23_20.png" alt="png" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 50 | step 000 Loss: 0.14082683622837067 
</code></pre></div></div>

<p><img src="/assets/2023-12-11-diffusion-model-demo2_files/2023-12-11-diffusion-model-demo2_23_22.png" alt="png" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 55 | step 000 Loss: 0.13268257677555084 
</code></pre></div></div>

<p><img src="/assets/2023-12-11-diffusion-model-demo2_files/2023-12-11-diffusion-model-demo2_23_24.png" alt="png" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 60 | step 000 Loss: 0.1329515129327774 
</code></pre></div></div>

<p><img src="/assets/2023-12-11-diffusion-model-demo2_files/2023-12-11-diffusion-model-demo2_23_26.png" alt="png" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 65 | step 000 Loss: 0.12477826327085495 
</code></pre></div></div>

<p><img src="/assets/2023-12-11-diffusion-model-demo2_files/2023-12-11-diffusion-model-demo2_23_28.png" alt="png" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 70 | step 000 Loss: 0.14115868508815765 
</code></pre></div></div>

<p><img src="/assets/2023-12-11-diffusion-model-demo2_files/2023-12-11-diffusion-model-demo2_23_30.png" alt="png" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 75 | step 000 Loss: 0.1246982216835022 
Epoch 80 | step 000 Loss: 0.14474114775657654 
</code></pre></div></div>

<p><img src="/assets/2023-12-11-diffusion-model-demo2_files/2023-12-11-diffusion-model-demo2_23_32.png" alt="png" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 85 | step 000 Loss: 0.12441752851009369 
</code></pre></div></div>

<p><img src="/assets/2023-12-11-diffusion-model-demo2_files/2023-12-11-diffusion-model-demo2_23_34.png" alt="png" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 90 | step 000 Loss: 0.12281842529773712 
</code></pre></div></div>

<p><img src="/assets/2023-12-11-diffusion-model-demo2_files/2023-12-11-diffusion-model-demo2_23_36.png" alt="png" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 95 | step 000 Loss: 0.1393832564353943 
</code></pre></div></div>

<p><img src="/assets/2023-12-11-diffusion-model-demo2_files/2023-12-11-diffusion-model-demo2_23_38.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
</code></pre></div></div>]]></content><author><name>Zhu Tianda</name></author><category term="coding" /><category term="AI" /><summary type="html"><![CDATA[A Diffusion Model from Scratch in Pytorch]]></summary></entry><entry><title type="html">Inspect BERT Vocabulary</title><link href="http://0.0.0.0:8855/coding/2023/12/02/Inspect-BERT-Vocabulary.html" rel="alternate" type="text/html" title="Inspect BERT Vocabulary" /><published>2023-12-02T00:00:00+08:00</published><updated>2023-12-02T00:00:00+08:00</updated><id>http://0.0.0.0:8855/coding/2023/12/02/Inspect-BERT-Vocabulary</id><content type="html" xml:base="http://0.0.0.0:8855/coding/2023/12/02/Inspect-BERT-Vocabulary.html"><![CDATA[<!DOCTYPE html>

<html lang="en">
<head><meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>Inspect_BERT_Vocabulary</title><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<style type="text/css">
    pre { line-height: 125%; }
td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
.highlight .hll { background-color: var(--jp-cell-editor-active-background) }
.highlight { background: var(--jp-cell-editor-background); color: var(--jp-mirror-editor-variable-color) }
.highlight .c { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment */
.highlight .err { color: var(--jp-mirror-editor-error-color) } /* Error */
.highlight .k { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword */
.highlight .o { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator */
.highlight .p { color: var(--jp-mirror-editor-punctuation-color) } /* Punctuation */
.highlight .ch { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Multiline */
.highlight .cp { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Preproc */
.highlight .cpf { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Single */
.highlight .cs { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Special */
.highlight .kc { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Pseudo */
.highlight .kr { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Type */
.highlight .m { color: var(--jp-mirror-editor-number-color) } /* Literal.Number */
.highlight .s { color: var(--jp-mirror-editor-string-color) } /* Literal.String */
.highlight .ow { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator.Word */
.highlight .pm { color: var(--jp-mirror-editor-punctuation-color) } /* Punctuation.Marker */
.highlight .w { color: var(--jp-mirror-editor-variable-color) } /* Text.Whitespace */
.highlight .mb { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Bin */
.highlight .mf { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Float */
.highlight .mh { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Hex */
.highlight .mi { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer */
.highlight .mo { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Oct */
.highlight .sa { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Affix */
.highlight .sb { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Backtick */
.highlight .sc { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Char */
.highlight .dl { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Delimiter */
.highlight .sd { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Doc */
.highlight .s2 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Double */
.highlight .se { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Escape */
.highlight .sh { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Heredoc */
.highlight .si { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Interpol */
.highlight .sx { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Other */
.highlight .sr { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Regex */
.highlight .s1 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Single */
.highlight .ss { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Symbol */
.highlight .il { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer.Long */
  </style>
<style type="text/css">
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*
 * Mozilla scrollbar styling
 */

/* use standard opaque scrollbars for most nodes */
[data-jp-theme-scrollbars='true'] {
  scrollbar-color: rgb(var(--jp-scrollbar-thumb-color))
    var(--jp-scrollbar-background-color);
}

/* for code nodes, use a transparent style of scrollbar. These selectors
 * will match lower in the tree, and so will override the above */
[data-jp-theme-scrollbars='true'] .CodeMirror-hscrollbar,
[data-jp-theme-scrollbars='true'] .CodeMirror-vscrollbar {
  scrollbar-color: rgba(var(--jp-scrollbar-thumb-color), 0.5) transparent;
}

/* tiny scrollbar */

.jp-scrollbar-tiny {
  scrollbar-color: rgba(var(--jp-scrollbar-thumb-color), 0.5) transparent;
  scrollbar-width: thin;
}

/* tiny scrollbar */

.jp-scrollbar-tiny::-webkit-scrollbar,
.jp-scrollbar-tiny::-webkit-scrollbar-corner {
  background-color: transparent;
  height: 4px;
  width: 4px;
}

.jp-scrollbar-tiny::-webkit-scrollbar-thumb {
  background: rgba(var(--jp-scrollbar-thumb-color), 0.5);
}

.jp-scrollbar-tiny::-webkit-scrollbar-track:horizontal {
  border-left: 0 solid transparent;
  border-right: 0 solid transparent;
}

.jp-scrollbar-tiny::-webkit-scrollbar-track:vertical {
  border-top: 0 solid transparent;
  border-bottom: 0 solid transparent;
}

/*
 * Lumino
 */

.lm-ScrollBar[data-orientation='horizontal'] {
  min-height: 16px;
  max-height: 16px;
  min-width: 45px;
  border-top: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='vertical'] {
  min-width: 16px;
  max-width: 16px;
  min-height: 45px;
  border-left: 1px solid #a0a0a0;
}

.lm-ScrollBar-button {
  background-color: #f0f0f0;
  background-position: center center;
  min-height: 15px;
  max-height: 15px;
  min-width: 15px;
  max-width: 15px;
}

.lm-ScrollBar-button:hover {
  background-color: #dadada;
}

.lm-ScrollBar-button.lm-mod-active {
  background-color: #cdcdcd;
}

.lm-ScrollBar-track {
  background: #f0f0f0;
}

.lm-ScrollBar-thumb {
  background: #cdcdcd;
}

.lm-ScrollBar-thumb:hover {
  background: #bababa;
}

.lm-ScrollBar-thumb.lm-mod-active {
  background: #a0a0a0;
}

.lm-ScrollBar[data-orientation='horizontal'] .lm-ScrollBar-thumb {
  height: 100%;
  min-width: 15px;
  border-left: 1px solid #a0a0a0;
  border-right: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='vertical'] .lm-ScrollBar-thumb {
  width: 100%;
  min-height: 15px;
  border-top: 1px solid #a0a0a0;
  border-bottom: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='horizontal']
  .lm-ScrollBar-button[data-action='decrement'] {
  background-image: var(--jp-icon-caret-left);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='horizontal']
  .lm-ScrollBar-button[data-action='increment'] {
  background-image: var(--jp-icon-caret-right);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='vertical']
  .lm-ScrollBar-button[data-action='decrement'] {
  background-image: var(--jp-icon-caret-up);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='vertical']
  .lm-ScrollBar-button[data-action='increment'] {
  background-image: var(--jp-icon-caret-down);
  background-size: 17px;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-Widget {
  box-sizing: border-box;
  position: relative;
  overflow: hidden;
}

.lm-Widget.lm-mod-hidden {
  display: none !important;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.lm-AccordionPanel[data-orientation='horizontal'] > .lm-AccordionPanel-title {
  /* Title is rotated for horizontal accordion panel using CSS */
  display: block;
  transform-origin: top left;
  transform: rotate(-90deg) translate(-100%);
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-CommandPalette {
  display: flex;
  flex-direction: column;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-CommandPalette-search {
  flex: 0 0 auto;
}

.lm-CommandPalette-content {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  min-height: 0;
  overflow: auto;
  list-style-type: none;
}

.lm-CommandPalette-header {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.lm-CommandPalette-item {
  display: flex;
  flex-direction: row;
}

.lm-CommandPalette-itemIcon {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemContent {
  flex: 1 1 auto;
  overflow: hidden;
}

.lm-CommandPalette-itemShortcut {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemLabel {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.lm-close-icon {
  border: 1px solid transparent;
  background-color: transparent;
  position: absolute;
  z-index: 1;
  right: 3%;
  top: 0;
  bottom: 0;
  margin: auto;
  padding: 7px 0;
  display: none;
  vertical-align: middle;
  outline: 0;
  cursor: pointer;
}
.lm-close-icon:after {
  content: 'X';
  display: block;
  width: 15px;
  height: 15px;
  text-align: center;
  color: #000;
  font-weight: normal;
  font-size: 12px;
  cursor: pointer;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-DockPanel {
  z-index: 0;
}

.lm-DockPanel-widget {
  z-index: 0;
}

.lm-DockPanel-tabBar {
  z-index: 1;
}

.lm-DockPanel-handle {
  z-index: 2;
}

.lm-DockPanel-handle.lm-mod-hidden {
  display: none !important;
}

.lm-DockPanel-handle:after {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  content: '';
}

.lm-DockPanel-handle[data-orientation='horizontal'] {
  cursor: ew-resize;
}

.lm-DockPanel-handle[data-orientation='vertical'] {
  cursor: ns-resize;
}

.lm-DockPanel-handle[data-orientation='horizontal']:after {
  left: 50%;
  min-width: 8px;
  transform: translateX(-50%);
}

.lm-DockPanel-handle[data-orientation='vertical']:after {
  top: 50%;
  min-height: 8px;
  transform: translateY(-50%);
}

.lm-DockPanel-overlay {
  z-index: 3;
  box-sizing: border-box;
  pointer-events: none;
}

.lm-DockPanel-overlay.lm-mod-hidden {
  display: none !important;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-Menu {
  z-index: 10000;
  position: absolute;
  white-space: nowrap;
  overflow-x: hidden;
  overflow-y: auto;
  outline: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-Menu-content {
  margin: 0;
  padding: 0;
  display: table;
  list-style-type: none;
}

.lm-Menu-item {
  display: table-row;
}

.lm-Menu-item.lm-mod-hidden,
.lm-Menu-item.lm-mod-collapsed {
  display: none !important;
}

.lm-Menu-itemIcon,
.lm-Menu-itemSubmenuIcon {
  display: table-cell;
  text-align: center;
}

.lm-Menu-itemLabel {
  display: table-cell;
  text-align: left;
}

.lm-Menu-itemShortcut {
  display: table-cell;
  text-align: right;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-MenuBar {
  outline: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-MenuBar-content {
  margin: 0;
  padding: 0;
  display: flex;
  flex-direction: row;
  list-style-type: none;
}

.lm-MenuBar-item {
  box-sizing: border-box;
}

.lm-MenuBar-itemIcon,
.lm-MenuBar-itemLabel {
  display: inline-block;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-ScrollBar {
  display: flex;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-ScrollBar[data-orientation='horizontal'] {
  flex-direction: row;
}

.lm-ScrollBar[data-orientation='vertical'] {
  flex-direction: column;
}

.lm-ScrollBar-button {
  box-sizing: border-box;
  flex: 0 0 auto;
}

.lm-ScrollBar-track {
  box-sizing: border-box;
  position: relative;
  overflow: hidden;
  flex: 1 1 auto;
}

.lm-ScrollBar-thumb {
  box-sizing: border-box;
  position: absolute;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-SplitPanel-child {
  z-index: 0;
}

.lm-SplitPanel-handle {
  z-index: 1;
}

.lm-SplitPanel-handle.lm-mod-hidden {
  display: none !important;
}

.lm-SplitPanel-handle:after {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  content: '';
}

.lm-SplitPanel[data-orientation='horizontal'] > .lm-SplitPanel-handle {
  cursor: ew-resize;
}

.lm-SplitPanel[data-orientation='vertical'] > .lm-SplitPanel-handle {
  cursor: ns-resize;
}

.lm-SplitPanel[data-orientation='horizontal'] > .lm-SplitPanel-handle:after {
  left: 50%;
  min-width: 8px;
  transform: translateX(-50%);
}

.lm-SplitPanel[data-orientation='vertical'] > .lm-SplitPanel-handle:after {
  top: 50%;
  min-height: 8px;
  transform: translateY(-50%);
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-TabBar {
  display: flex;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-TabBar[data-orientation='horizontal'] {
  flex-direction: row;
  align-items: flex-end;
}

.lm-TabBar[data-orientation='vertical'] {
  flex-direction: column;
  align-items: flex-end;
}

.lm-TabBar-content {
  margin: 0;
  padding: 0;
  display: flex;
  flex: 1 1 auto;
  list-style-type: none;
}

.lm-TabBar[data-orientation='horizontal'] > .lm-TabBar-content {
  flex-direction: row;
}

.lm-TabBar[data-orientation='vertical'] > .lm-TabBar-content {
  flex-direction: column;
}

.lm-TabBar-tab {
  display: flex;
  flex-direction: row;
  box-sizing: border-box;
  overflow: hidden;
  touch-action: none; /* Disable native Drag/Drop */
}

.lm-TabBar-tabIcon,
.lm-TabBar-tabCloseIcon {
  flex: 0 0 auto;
}

.lm-TabBar-tabLabel {
  flex: 1 1 auto;
  overflow: hidden;
  white-space: nowrap;
}

.lm-TabBar-tabInput {
  user-select: all;
  width: 100%;
  box-sizing: border-box;
}

.lm-TabBar-tab.lm-mod-hidden {
  display: none !important;
}

.lm-TabBar-addButton.lm-mod-hidden {
  display: none !important;
}

.lm-TabBar.lm-mod-dragging .lm-TabBar-tab {
  position: relative;
}

.lm-TabBar.lm-mod-dragging[data-orientation='horizontal'] .lm-TabBar-tab {
  left: 0;
  transition: left 150ms ease;
}

.lm-TabBar.lm-mod-dragging[data-orientation='vertical'] .lm-TabBar-tab {
  top: 0;
  transition: top 150ms ease;
}

.lm-TabBar.lm-mod-dragging .lm-TabBar-tab.lm-mod-dragging {
  transition: none;
}

.lm-TabBar-tabLabel .lm-TabBar-tabInput {
  user-select: all;
  width: 100%;
  box-sizing: border-box;
  background: inherit;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-TabPanel-tabBar {
  z-index: 1;
}

.lm-TabPanel-stackedPanel {
  z-index: 0;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Collapse {
  display: flex;
  flex-direction: column;
  align-items: stretch;
}

.jp-Collapse-header {
  padding: 1px 12px;
  background-color: var(--jp-layout-color1);
  border-bottom: solid var(--jp-border-width) var(--jp-border-color2);
  color: var(--jp-ui-font-color1);
  cursor: pointer;
  display: flex;
  align-items: center;
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  text-transform: uppercase;
  user-select: none;
}

.jp-Collapser-icon {
  height: 16px;
}

.jp-Collapse-header-collapsed .jp-Collapser-icon {
  transform: rotate(-90deg);
  margin: auto 0;
}

.jp-Collapser-title {
  line-height: 25px;
}

.jp-Collapse-contents {
  padding: 0 12px;
  background-color: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  overflow: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensureUiComponents() in @jupyterlab/buildutils */

/**
 * (DEPRECATED) Support for consuming icons as CSS background images
 */

/* Icons urls */

:root {
  --jp-icon-add-above: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGcgY2xpcC1wYXRoPSJ1cmwoI2NsaXAwXzEzN18xOTQ5MikiPgo8cGF0aCBjbGFzcz0ianAtaWNvbjMiIGQ9Ik00Ljc1IDQuOTMwNjZINi42MjVWNi44MDU2NkM2LjYyNSA3LjAxMTkxIDYuNzkzNzUgNy4xODA2NiA3IDcuMTgwNjZDNy4yMDYyNSA3LjE4MDY2IDcuMzc1IDcuMDExOTEgNy4zNzUgNi44MDU2NlY0LjkzMDY2SDkuMjVDOS40NTYyNSA0LjkzMDY2IDkuNjI1IDQuNzYxOTEgOS42MjUgNC41NTU2NkM5LjYyNSA0LjM0OTQxIDkuNDU2MjUgNC4xODA2NiA5LjI1IDQuMTgwNjZINy4zNzVWMi4zMDU2NkM3LjM3NSAyLjA5OTQxIDcuMjA2MjUgMS45MzA2NiA3IDEuOTMwNjZDNi43OTM3NSAxLjkzMDY2IDYuNjI1IDIuMDk5NDEgNi42MjUgMi4zMDU2NlY0LjE4MDY2SDQuNzVDNC41NDM3NSA0LjE4MDY2IDQuMzc1IDQuMzQ5NDEgNC4zNzUgNC41NTU2NkM0LjM3NSA0Ljc2MTkxIDQuNTQzNzUgNC45MzA2NiA0Ljc1IDQuOTMwNjZaIiBmaWxsPSIjNjE2MTYxIiBzdHJva2U9IiM2MTYxNjEiIHN0cm9rZS13aWR0aD0iMC43Ii8+CjwvZz4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiIGNsaXAtcnVsZT0iZXZlbm9kZCIgZD0iTTExLjUgOS41VjExLjVMMi41IDExLjVWOS41TDExLjUgOS41Wk0xMiA4QzEyLjU1MjMgOCAxMyA4LjQ0NzcyIDEzIDlWMTJDMTMgMTIuNTUyMyAxMi41NTIzIDEzIDEyIDEzTDIgMTNDMS40NDc3MiAxMyAxIDEyLjU1MjMgMSAxMlY5QzEgOC40NDc3MiAxLjQ0NzcxIDggMiA4TDEyIDhaIiBmaWxsPSIjNjE2MTYxIi8+CjxkZWZzPgo8Y2xpcFBhdGggaWQ9ImNsaXAwXzEzN18xOTQ5MiI+CjxyZWN0IGNsYXNzPSJqcC1pY29uMyIgd2lkdGg9IjYiIGhlaWdodD0iNiIgZmlsbD0id2hpdGUiIHRyYW5zZm9ybT0ibWF0cml4KC0xIDAgMCAxIDEwIDEuNTU1NjYpIi8+CjwvY2xpcFBhdGg+CjwvZGVmcz4KPC9zdmc+Cg==);
  --jp-icon-add-below: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGcgY2xpcC1wYXRoPSJ1cmwoI2NsaXAwXzEzN18xOTQ5OCkiPgo8cGF0aCBjbGFzcz0ianAtaWNvbjMiIGQ9Ik05LjI1IDEwLjA2OTNMNy4zNzUgMTAuMDY5M0w3LjM3NSA4LjE5NDM0QzcuMzc1IDcuOTg4MDkgNy4yMDYyNSA3LjgxOTM0IDcgNy44MTkzNEM2Ljc5Mzc1IDcuODE5MzQgNi42MjUgNy45ODgwOSA2LjYyNSA4LjE5NDM0TDYuNjI1IDEwLjA2OTNMNC43NSAxMC4wNjkzQzQuNTQzNzUgMTAuMDY5MyA0LjM3NSAxMC4yMzgxIDQuMzc1IDEwLjQ0NDNDNC4zNzUgMTAuNjUwNiA0LjU0Mzc1IDEwLjgxOTMgNC43NSAxMC44MTkzTDYuNjI1IDEwLjgxOTNMNi42MjUgMTIuNjk0M0M2LjYyNSAxMi45MDA2IDYuNzkzNzUgMTMuMDY5MyA3IDEzLjA2OTNDNy4yMDYyNSAxMy4wNjkzIDcuMzc1IDEyLjkwMDYgNy4zNzUgMTIuNjk0M0w3LjM3NSAxMC44MTkzTDkuMjUgMTAuODE5M0M5LjQ1NjI1IDEwLjgxOTMgOS42MjUgMTAuNjUwNiA5LjYyNSAxMC40NDQzQzkuNjI1IDEwLjIzODEgOS40NTYyNSAxMC4wNjkzIDkuMjUgMTAuMDY5M1oiIGZpbGw9IiM2MTYxNjEiIHN0cm9rZT0iIzYxNjE2MSIgc3Ryb2tlLXdpZHRoPSIwLjciLz4KPC9nPgo8cGF0aCBjbGFzcz0ianAtaWNvbjMiIGZpbGwtcnVsZT0iZXZlbm9kZCIgY2xpcC1ydWxlPSJldmVub2RkIiBkPSJNMi41IDUuNUwyLjUgMy41TDExLjUgMy41TDExLjUgNS41TDIuNSA1LjVaTTIgN0MxLjQ0NzcyIDcgMSA2LjU1MjI4IDEgNkwxIDNDMSAyLjQ0NzcyIDEuNDQ3NzIgMiAyIDJMMTIgMkMxMi41NTIzIDIgMTMgMi40NDc3MiAxMyAzTDEzIDZDMTMgNi41NTIyOSAxMi41NTIzIDcgMTIgN0wyIDdaIiBmaWxsPSIjNjE2MTYxIi8+CjxkZWZzPgo8Y2xpcFBhdGggaWQ9ImNsaXAwXzEzN18xOTQ5OCI+CjxyZWN0IGNsYXNzPSJqcC1pY29uMyIgd2lkdGg9IjYiIGhlaWdodD0iNiIgZmlsbD0id2hpdGUiIHRyYW5zZm9ybT0ibWF0cml4KDEgMS43NDg0NmUtMDcgMS43NDg0NmUtMDcgLTEgNCAxMy40NDQzKSIvPgo8L2NsaXBQYXRoPgo8L2RlZnM+Cjwvc3ZnPgo=);
  --jp-icon-add: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE5IDEzaC02djZoLTJ2LTZINXYtMmg2VjVoMnY2aDZ2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-bell: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE2IDE2IiB2ZXJzaW9uPSIxLjEiPgogICA8cGF0aCBjbGFzcz0ianAtaWNvbjIganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMzMzMzMzIgogICAgICBkPSJtOCAwLjI5Yy0xLjQgMC0yLjcgMC43My0zLjYgMS44LTEuMiAxLjUtMS40IDMuNC0xLjUgNS4yLTAuMTggMi4yLTAuNDQgNC0yLjMgNS4zbDAuMjggMS4zaDVjMC4wMjYgMC42NiAwLjMyIDEuMSAwLjcxIDEuNSAwLjg0IDAuNjEgMiAwLjYxIDIuOCAwIDAuNTItMC40IDAuNi0xIDAuNzEtMS41aDVsMC4yOC0xLjNjLTEuOS0wLjk3LTIuMi0zLjMtMi4zLTUuMy0wLjEzLTEuOC0wLjI2LTMuNy0xLjUtNS4yLTAuODUtMS0yLjItMS44LTMuNi0xLjh6bTAgMS40YzAuODggMCAxLjkgMC41NSAyLjUgMS4zIDAuODggMS4xIDEuMSAyLjcgMS4yIDQuNCAwLjEzIDEuNyAwLjIzIDMuNiAxLjMgNS4yaC0xMGMxLjEtMS42IDEuMi0zLjQgMS4zLTUuMiAwLjEzLTEuNyAwLjMtMy4zIDEuMi00LjQgMC41OS0wLjcyIDEuNi0xLjMgMi41LTEuM3ptLTAuNzQgMTJoMS41Yy0wLjAwMTUgMC4yOCAwLjAxNSAwLjc5LTAuNzQgMC43OS0wLjczIDAuMDAxNi0wLjcyLTAuNTMtMC43NC0wLjc5eiIgLz4KPC9zdmc+Cg==);
  --jp-icon-bug-dot: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjQiIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiPgogICAgICAgIDxwYXRoIGZpbGwtcnVsZT0iZXZlbm9kZCIgY2xpcC1ydWxlPSJldmVub2RkIiBkPSJNMTcuMTkgOEgyMFYxMEgxNy45MUMxNy45NiAxMC4zMyAxOCAxMC42NiAxOCAxMVYxMkgyMFYxNEgxOC41SDE4VjE0LjAyNzVDMTUuNzUgMTQuMjc2MiAxNCAxNi4xODM3IDE0IDE4LjVDMTQgMTkuMjA4IDE0LjE2MzUgMTkuODc3OSAxNC40NTQ5IDIwLjQ3MzlDMTMuNzA2MyAyMC44MTE3IDEyLjg3NTcgMjEgMTIgMjFDOS43OCAyMSA3Ljg1IDE5Ljc5IDYuODEgMThINFYxNkg2LjA5QzYuMDQgMTUuNjcgNiAxNS4zNCA2IDE1VjE0SDRWMTJINlYxMUM2IDEwLjY2IDYuMDQgMTAuMzMgNi4wOSAxMEg0VjhINi44MUM3LjI2IDcuMjIgNy44OCA2LjU1IDguNjIgNi4wNEw3IDQuNDFMOC40MSAzTDEwLjU5IDUuMTdDMTEuMDQgNS4wNiAxMS41MSA1IDEyIDVDMTIuNDkgNSAxMi45NiA1LjA2IDEzLjQyIDUuMTdMMTUuNTkgM0wxNyA0LjQxTDE1LjM3IDYuMDRDMTYuMTIgNi41NSAxNi43NCA3LjIyIDE3LjE5IDhaTTEwIDE2SDE0VjE0SDEwVjE2Wk0xMCAxMkgxNFYxMEgxMFYxMloiIGZpbGw9IiM2MTYxNjEiLz4KICAgICAgICA8cGF0aCBkPSJNMjIgMTguNUMyMiAyMC40MzMgMjAuNDMzIDIyIDE4LjUgMjJDMTYuNTY3IDIyIDE1IDIwLjQzMyAxNSAxOC41QzE1IDE2LjU2NyAxNi41NjcgMTUgMTguNSAxNUMyMC40MzMgMTUgMjIgMTYuNTY3IDIyIDE4LjVaIiBmaWxsPSIjNjE2MTYxIi8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-bug: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0yMCA4aC0yLjgxYy0uNDUtLjc4LTEuMDctMS40NS0xLjgyLTEuOTZMMTcgNC40MSAxNS41OSAzbC0yLjE3IDIuMTdDMTIuOTYgNS4wNiAxMi40OSA1IDEyIDVjLS40OSAwLS45Ni4wNi0xLjQxLjE3TDguNDEgMyA3IDQuNDFsMS42MiAxLjYzQzcuODggNi41NSA3LjI2IDcuMjIgNi44MSA4SDR2MmgyLjA5Yy0uMDUuMzMtLjA5LjY2LS4wOSAxdjFINHYyaDJ2MWMwIC4zNC4wNC42Ny4wOSAxSDR2MmgyLjgxYzEuMDQgMS43OSAyLjk3IDMgNS4xOSAzczQuMTUtMS4yMSA1LjE5LTNIMjB2LTJoLTIuMDljLjA1LS4zMy4wOS0uNjYuMDktMXYtMWgydi0yaC0ydi0xYzAtLjM0LS4wNC0uNjctLjA5LTFIMjBWOHptLTYgOGgtNHYtMmg0djJ6bTAtNGgtNHYtMmg0djJ6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-build: url(data:image/svg+xml;base64,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);
  --jp-icon-caret-down-empty-thin: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwb2x5Z29uIGNsYXNzPSJzdDEiIHBvaW50cz0iOS45LDEzLjYgMy42LDcuNCA0LjQsNi42IDkuOSwxMi4yIDE1LjQsNi43IDE2LjEsNy40ICIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-caret-down-empty: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik01LjIsNS45TDksOS43bDMuOC0zLjhsMS4yLDEuMmwtNC45LDVsLTQuOS01TDUuMiw1Ljl6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-caret-down: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik01LjIsNy41TDksMTEuMmwzLjgtMy44SDUuMnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-caret-left: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwYXRoIGQ9Ik0xMC44LDEyLjhMNy4xLDlsMy44LTMuOGwwLDcuNkgxMC44eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-caret-right: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik03LjIsNS4yTDEwLjksOWwtMy44LDMuOFY1LjJINy4yeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-caret-up-empty-thin: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwb2x5Z29uIGNsYXNzPSJzdDEiIHBvaW50cz0iMTUuNCwxMy4zIDkuOSw3LjcgNC40LDEzLjIgMy42LDEyLjUgOS45LDYuMyAxNi4xLDEyLjYgIi8+Cgk8L2c+Cjwvc3ZnPgo=);
  --jp-icon-caret-up: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwYXRoIGQ9Ik01LjIsMTAuNUw5LDYuOGwzLjgsMy44SDUuMnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-case-sensitive: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KICA8ZyBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiM0MTQxNDEiPgogICAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiAgPC9nPgogIDxnIGNsYXNzPSJqcC1pY29uLWFjY2VudDIiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTcuNiw4aDAuOWwzLjUsOGgtMS4xTDEwLDE0SDZsLTAuOSwySDRMNy42LDh6IE04LDkuMUw2LjQsMTNoMy4yTDgsOS4xeiIvPgogICAgPHBhdGggZD0iTTE2LjYsOS44Yy0wLjIsMC4xLTAuNCwwLjEtMC43LDAuMWMtMC4yLDAtMC40LTAuMS0wLjYtMC4yYy0wLjEtMC4xLTAuMi0wLjQtMC4yLTAuNyBjLTAuMywwLjMtMC42LDAuNS0wLjksMC43Yy0wLjMsMC4xLTAuNywwLjItMS4xLDAuMmMtMC4zLDAtMC41LDAtMC43LTAuMWMtMC4yLTAuMS0wLjQtMC4yLTAuNi0wLjNjLTAuMi0wLjEtMC4zLTAuMy0wLjQtMC41IGMtMC4xLTAuMi0wLjEtMC40LTAuMS0wLjdjMC0wLjMsMC4xLTAuNiwwLjItMC44YzAuMS0wLjIsMC4zLTAuNCwwLjQtMC41QzEyLDcsMTIuMiw2LjksMTIuNSw2LjhjMC4yLTAuMSwwLjUtMC4xLDAuNy0wLjIgYzAuMy0wLjEsMC41LTAuMSwwLjctMC4xYzAuMiwwLDAuNC0wLjEsMC42LTAuMWMwLjIsMCwwLjMtMC4xLDAuNC0wLjJjMC4xLTAuMSwwLjItMC4yLDAuMi0wLjRjMC0xLTEuMS0xLTEuMy0xIGMtMC40LDAtMS40LDAtMS40LDEuMmgtMC45YzAtMC40LDAuMS0wLjcsMC4yLTFjMC4xLTAuMiwwLjMtMC40LDAuNS0wLjZjMC4yLTAuMiwwLjUtMC4zLDAuOC0wLjNDMTMuMyw0LDEzLjYsNCwxMy45LDQgYzAuMywwLDAuNSwwLDAuOCwwLjFjMC4zLDAsMC41LDAuMSwwLjcsMC4yYzAuMiwwLjEsMC40LDAuMywwLjUsMC41QzE2LDUsMTYsNS4yLDE2LDUuNnYyLjljMCwwLjIsMCwwLjQsMCwwLjUgYzAsMC4xLDAuMSwwLjIsMC4zLDAuMmMwLjEsMCwwLjIsMCwwLjMsMFY5Ljh6IE0xNS4yLDYuOWMtMS4yLDAuNi0zLjEsMC4yLTMuMSwxLjRjMCwxLjQsMy4xLDEsMy4xLTAuNVY2Ljl6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-check: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik05IDE2LjE3TDQuODMgMTJsLTEuNDIgMS40MUw5IDE5IDIxIDdsLTEuNDEtMS40MXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-circle-empty: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyIDJDNi40NyAyIDIgNi40NyAyIDEyczQuNDcgMTAgMTAgMTAgMTAtNC40NyAxMC0xMFMxNy41MyAyIDEyIDJ6bTAgMThjLTQuNDEgMC04LTMuNTktOC04czMuNTktOCA4LTggOCAzLjU5IDggOC0zLjU5IDgtOCA4eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-circle: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPGNpcmNsZSBjeD0iOSIgY3k9IjkiIHI9IjgiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-clear: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8bWFzayBpZD0iZG9udXRIb2xlIj4KICAgIDxyZWN0IHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgZmlsbD0id2hpdGUiIC8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSI4IiBmaWxsPSJibGFjayIvPgogIDwvbWFzaz4KCiAgPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxyZWN0IGhlaWdodD0iMTgiIHdpZHRoPSIyIiB4PSIxMSIgeT0iMyIgdHJhbnNmb3JtPSJyb3RhdGUoMzE1LCAxMiwgMTIpIi8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIxMCIgbWFzaz0idXJsKCNkb251dEhvbGUpIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-close: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1ub25lIGpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIGpwLWljb24zLWhvdmVyIiBmaWxsPSJub25lIj4KICAgIDxjaXJjbGUgY3g9IjEyIiBjeT0iMTIiIHI9IjExIi8+CiAgPC9nPgoKICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIGpwLWljb24tYWNjZW50Mi1ob3ZlciIgZmlsbD0iIzYxNjE2MSI+CiAgICA8cGF0aCBkPSJNMTkgNi40MUwxNy41OSA1IDEyIDEwLjU5IDYuNDEgNSA1IDYuNDEgMTAuNTkgMTIgNSAxNy41OSA2LjQxIDE5IDEyIDEzLjQxIDE3LjU5IDE5IDE5IDE3LjU5IDEzLjQxIDEyeiIvPgogIDwvZz4KCiAgPGcgY2xhc3M9ImpwLWljb24tbm9uZSBqcC1pY29uLWJ1c3kiIGZpbGw9Im5vbmUiPgogICAgPGNpcmNsZSBjeD0iMTIiIGN5PSIxMiIgcj0iNyIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-code-check: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBzaGFwZS1yZW5kZXJpbmc9Imdlb21ldHJpY1ByZWNpc2lvbiI+CiAgICA8cGF0aCBkPSJNNi41OSwzLjQxTDIsOEw2LjU5LDEyLjZMOCwxMS4xOEw0LjgyLDhMOCw0LjgyTDYuNTksMy40MU0xMi40MSwzLjQxTDExLDQuODJMMTQuMTgsOEwxMSwxMS4xOEwxMi40MSwxMi42TDE3LDhMMTIuNDEsMy40MU0yMS41OSwxMS41OUwxMy41LDE5LjY4TDkuODMsMTZMOC40MiwxNy40MUwxMy41LDIyLjVMMjMsMTNMMjEuNTksMTEuNTlaIiAvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-code: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjIiIGhlaWdodD0iMjIiIHZpZXdCb3g9IjAgMCAyOCAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTExLjQgMTguNkw2LjggMTRMMTEuNCA5LjRMMTAgOEw0IDE0TDEwIDIwTDExLjQgMTguNlpNMTYuNiAxOC42TDIxLjIgMTRMMTYuNiA5LjRMMTggOEwyNCAxNEwxOCAyMEwxNi42IDE4LjZWMTguNloiLz4KCTwvZz4KPC9zdmc+Cg==);
  --jp-icon-collapse-all: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTggMmMxIDAgMTEgMCAxMiAwczIgMSAyIDJjMCAxIDAgMTEgMCAxMnMwIDItMiAyQzIwIDE0IDIwIDQgMjAgNFMxMCA0IDYgNGMwLTIgMS0yIDItMnoiIC8+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTE4IDhjMC0xLTEtMi0yLTJTNSA2IDQgNnMtMiAxLTIgMmMwIDEgMCAxMSAwIDEyczEgMiAyIDJjMSAwIDExIDAgMTIgMHMyLTEgMi0yYzAtMSAwLTExIDAtMTJ6bS0yIDB2MTJINFY4eiIgLz4KICAgICAgICA8cGF0aCBkPSJNNiAxM3YyaDh2LTJ6IiAvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-console: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwMCAyMDAiPgogIDxnIGNsYXNzPSJqcC1jb25zb2xlLWljb24tYmFja2dyb3VuZC1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiMwMjg4RDEiPgogICAgPHBhdGggZD0iTTIwIDE5LjhoMTYwdjE1OS45SDIweiIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtY29uc29sZS1pY29uLWNvbG9yIGpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIiBmaWxsPSIjZmZmIj4KICAgIDxwYXRoIGQ9Ik0xMDUgMTI3LjNoNDB2MTIuOGgtNDB6TTUxLjEgNzdMNzQgOTkuOWwtMjMuMyAyMy4zIDEwLjUgMTAuNSAyMy4zLTIzLjNMOTUgOTkuOSA4NC41IDg5LjQgNjEuNiA2Ni41eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-copy: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTExLjksMUgzLjJDMi40LDEsMS43LDEuNywxLjcsMi41djEwLjJoMS41VjIuNWg4LjdWMXogTTE0LjEsMy45aC04Yy0wLjgsMC0xLjUsMC43LTEuNSwxLjV2MTAuMmMwLDAuOCwwLjcsMS41LDEuNSwxLjVoOCBjMC44LDAsMS41LTAuNywxLjUtMS41VjUuNEMxNS41LDQuNiwxNC45LDMuOSwxNC4xLDMuOXogTTE0LjEsMTUuNWgtOFY1LjRoOFYxNS41eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-copyright: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGVuYWJsZS1iYWNrZ3JvdW5kPSJuZXcgMCAwIDI0IDI0IiBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCI+CiAgPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0xMS44OCw5LjE0YzEuMjgsMC4wNiwxLjYxLDEuMTUsMS42MywxLjY2aDEuNzljLTAuMDgtMS45OC0xLjQ5LTMuMTktMy40NS0zLjE5QzkuNjQsNy42MSw4LDksOCwxMi4xNCBjMCwxLjk0LDAuOTMsNC4yNCwzLjg0LDQuMjRjMi4yMiwwLDMuNDEtMS42NSwzLjQ0LTIuOTVoLTEuNzljLTAuMDMsMC41OS0wLjQ1LDEuMzgtMS42MywxLjQ0QzEwLjU1LDE0LjgzLDEwLDEzLjgxLDEwLDEyLjE0IEMxMCw5LjI1LDExLjI4LDkuMTYsMTEuODgsOS4xNHogTTEyLDJDNi40OCwyLDIsNi40OCwyLDEyczQuNDgsMTAsMTAsMTBzMTAtNC40OCwxMC0xMFMxNy41MiwyLDEyLDJ6IE0xMiwyMGMtNC40MSwwLTgtMy41OS04LTggczMuNTktOCw4LThzOCwzLjU5LDgsOFMxNi40MSwyMCwxMiwyMHoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-cut: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkuNjQgNy42NGMuMjMtLjUuMzYtMS4wNS4zNi0xLjY0IDAtMi4yMS0xLjc5LTQtNC00UzIgMy43OSAyIDZzMS43OSA0IDQgNGMuNTkgMCAxLjE0LS4xMyAxLjY0LS4zNkwxMCAxMmwtMi4zNiAyLjM2QzcuMTQgMTQuMTMgNi41OSAxNCA2IDE0Yy0yLjIxIDAtNCAxLjc5LTQgNHMxLjc5IDQgNCA0IDQtMS43OSA0LTRjMC0uNTktLjEzLTEuMTQtLjM2LTEuNjRMMTIgMTRsNyA3aDN2LTFMOS42NCA3LjY0ek02IDhjLTEuMSAwLTItLjg5LTItMnMuOS0yIDItMiAyIC44OSAyIDItLjkgMi0yIDJ6bTAgMTJjLTEuMSAwLTItLjg5LTItMnMuOS0yIDItMiAyIC44OSAyIDItLjkgMi0yIDJ6bTYtNy41Yy0uMjggMC0uNS0uMjItLjUtLjVzLjIyLS41LjUtLjUuNS4yMi41LjUtLjIyLjUtLjUuNXpNMTkgM2wtNiA2IDIgMiA3LTdWM3oiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-delete: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2cHgiIGhlaWdodD0iMTZweCI+CiAgICA8cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIiAvPgogICAgPHBhdGggY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjI2MjYyIiBkPSJNNiAxOWMwIDEuMS45IDIgMiAyaDhjMS4xIDAgMi0uOSAyLTJWN0g2djEyek0xOSA0aC0zLjVsLTEtMWgtNWwtMSAxSDV2MmgxNFY0eiIgLz4KPC9zdmc+Cg==);
  --jp-icon-download: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE5IDloLTRWM0g5djZINWw3IDcgNy03ek01IDE4djJoMTR2LTJINXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-duplicate: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiIGNsaXAtcnVsZT0iZXZlbm9kZCIgZD0iTTIuNzk5OTggMC44NzVIOC44OTU4MkM5LjIwMDYxIDAuODc1IDkuNDQ5OTggMS4xMzkxNCA5LjQ0OTk4IDEuNDYxOThDOS40NDk5OCAxLjc4NDgyIDkuMjAwNjEgMi4wNDg5NiA4Ljg5NTgyIDIuMDQ4OTZIMy4zNTQxNUMzLjA0OTM2IDIuMDQ4OTYgMi43OTk5OCAyLjMxMzEgMi43OTk5OCAyLjYzNTk0VjkuNjc5NjlDMi43OTk5OCAxMC4wMDI1IDIuNTUwNjEgMTAuMjY2NyAyLjI0NTgyIDEwLjI2NjdDMS45NDEwMyAxMC4yNjY3IDEuNjkxNjUgMTAuMDAyNSAxLjY5MTY1IDkuNjc5NjlWMi4wNDg5NkMxLjY5MTY1IDEuNDAzMjggMi4xOTA0IDAuODc1IDIuNzk5OTggMC44NzVaTTUuMzY2NjUgMTEuOVY0LjU1SDExLjA4MzNWMTEuOUg1LjM2NjY1Wk00LjE0MTY1IDQuMTQxNjdDNC4xNDE2NSAzLjY5MDYzIDQuNTA3MjggMy4zMjUgNC45NTgzMiAzLjMyNUgxMS40OTE3QzExLjk0MjcgMy4zMjUgMTIuMzA4MyAzLjY5MDYzIDEyLjMwODMgNC4xNDE2N1YxMi4zMDgzQzEyLjMwODMgMTIuNzU5NCAxMS45NDI3IDEzLjEyNSAxMS40OTE3IDEzLjEyNUg0Ljk1ODMyQzQuNTA3MjggMTMuMTI1IDQuMTQxNjUgMTIuNzU5NCA0LjE0MTY1IDEyLjMwODNWNC4xNDE2N1oiIGZpbGw9IiM2MTYxNjEiLz4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBkPSJNOS40MzU3NCA4LjI2NTA3SDguMzY0MzFWOS4zMzY1QzguMzY0MzEgOS40NTQzNSA4LjI2Nzg4IDkuNTUwNzggOC4xNTAwMiA5LjU1MDc4QzguMDMyMTcgOS41NTA3OCA3LjkzNTc0IDkuNDU0MzUgNy45MzU3NCA5LjMzNjVWOC4yNjUwN0g2Ljg2NDMxQzYuNzQ2NDUgOC4yNjUwNyA2LjY1MDAyIDguMTY4NjQgNi42NTAwMiA4LjA1MDc4QzYuNjUwMDIgNy45MzI5MiA2Ljc0NjQ1IDcuODM2NSA2Ljg2NDMxIDcuODM2NUg3LjkzNTc0VjYuNzY1MDdDNy45MzU3NCA2LjY0NzIxIDguMDMyMTcgNi41NTA3OCA4LjE1MDAyIDYuNTUwNzhDOC4yNjc4OCA2LjU1MDc4IDguMzY0MzEgNi42NDcyMSA4LjM2NDMxIDYuNzY1MDdWNy44MzY1SDkuNDM1NzRDOS41NTM2IDcuODM2NSA5LjY1MDAyIDcuOTMyOTIgOS42NTAwMiA4LjA1MDc4QzkuNjUwMDIgOC4xNjg2NCA5LjU1MzYgOC4yNjUwNyA5LjQzNTc0IDguMjY1MDdaIiBmaWxsPSIjNjE2MTYxIiBzdHJva2U9IiM2MTYxNjEiIHN0cm9rZS13aWR0aD0iMC41Ii8+Cjwvc3ZnPgo=);
  --jp-icon-edit: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTMgMTcuMjVWMjFoMy43NUwxNy44MSA5Ljk0bC0zLjc1LTMuNzVMMyAxNy4yNXpNMjAuNzEgNy4wNGMuMzktLjM5LjM5LTEuMDIgMC0xLjQxbC0yLjM0LTIuMzRjLS4zOS0uMzktMS4wMi0uMzktMS40MSAwbC0xLjgzIDEuODMgMy43NSAzLjc1IDEuODMtMS44M3oiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-ellipses: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPGNpcmNsZSBjeD0iNSIgY3k9IjEyIiByPSIyIi8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIyIi8+CiAgICA8Y2lyY2xlIGN4PSIxOSIgY3k9IjEyIiByPSIyIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-error: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj48Y2lyY2xlIGN4PSIxMiIgY3k9IjE5IiByPSIyIi8+PHBhdGggZD0iTTEwIDNoNHYxMmgtNHoiLz48L2c+CjxwYXRoIGZpbGw9Im5vbmUiIGQ9Ik0wIDBoMjR2MjRIMHoiLz4KPC9zdmc+Cg==);
  --jp-icon-expand-all: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTggMmMxIDAgMTEgMCAxMiAwczIgMSAyIDJjMCAxIDAgMTEgMCAxMnMwIDItMiAyQzIwIDE0IDIwIDQgMjAgNFMxMCA0IDYgNGMwLTIgMS0yIDItMnoiIC8+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTE4IDhjMC0xLTEtMi0yLTJTNSA2IDQgNnMtMiAxLTIgMmMwIDEgMCAxMSAwIDEyczEgMiAyIDJjMSAwIDExIDAgMTIgMHMyLTEgMi0yYzAtMSAwLTExIDAtMTJ6bS0yIDB2MTJINFY4eiIgLz4KICAgICAgICA8cGF0aCBkPSJNMTEgMTBIOXYzSDZ2MmgzdjNoMnYtM2gzdi0yaC0zeiIgLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-extension: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwLjUgMTFIMTlWN2MwLTEuMS0uOS0yLTItMmgtNFYzLjVDMTMgMi4xMiAxMS44OCAxIDEwLjUgMVM4IDIuMTIgOCAzLjVWNUg0Yy0xLjEgMC0xLjk5LjktMS45OSAydjMuOEgzLjVjMS40OSAwIDIuNyAxLjIxIDIuNyAyLjdzLTEuMjEgMi43LTIuNyAyLjdIMlYyMGMwIDEuMS45IDIgMiAyaDMuOHYtMS41YzAtMS40OSAxLjIxLTIuNyAyLjctMi43IDEuNDkgMCAyLjcgMS4yMSAyLjcgMi43VjIySDE3YzEuMSAwIDItLjkgMi0ydi00aDEuNWMxLjM4IDAgMi41LTEuMTIgMi41LTIuNVMyMS44OCAxMSAyMC41IDExeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-fast-forward: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTQgMThsOC41LTZMNCA2djEyem05LTEydjEybDguNS02TDEzIDZ6Ii8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-file-upload: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkgMTZoNnYtNmg0bC03LTctNyA3aDR6bS00IDJoMTR2Mkg1eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-file: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkuMyA4LjJsLTUuNS01LjVjLS4zLS4zLS43LS41LTEuMi0uNUgzLjljLS44LjEtMS42LjktMS42IDEuOHYxNC4xYzAgLjkuNyAxLjYgMS42IDEuNmgxNC4yYy45IDAgMS42LS43IDEuNi0xLjZWOS40Yy4xLS41LS4xLS45LS40LTEuMnptLTUuOC0zLjNsMy40IDMuNmgtMy40VjQuOXptMy45IDEyLjdINC43Yy0uMSAwLS4yIDAtLjItLjJWNC43YzAtLjIuMS0uMy4yLS4zaDcuMnY0LjRzMCAuOC4zIDEuMWMuMy4zIDEuMS4zIDEuMS4zaDQuM3Y3LjJzLS4xLjItLjIuMnoiLz4KPC9zdmc+Cg==);
  --jp-icon-filter-dot: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTE0LDEyVjE5Ljg4QzE0LjA0LDIwLjE4IDEzLjk0LDIwLjUgMTMuNzEsMjAuNzFDMTMuMzIsMjEuMSAxMi42OSwyMS4xIDEyLjMsMjAuNzFMMTAuMjksMTguN0MxMC4wNiwxOC40NyA5Ljk2LDE4LjE2IDEwLDE3Ljg3VjEySDkuOTdMNC4yMSw0LjYyQzMuODcsNC4xOSAzLjk1LDMuNTYgNC4zOCwzLjIyQzQuNTcsMy4wOCA0Ljc4LDMgNSwzVjNIMTlWM0MxOS4yMiwzIDE5LjQzLDMuMDggMTkuNjIsMy4yMkMyMC4wNSwzLjU2IDIwLjEzLDQuMTkgMTkuNzksNC42MkwxNC4wMywxMkgxNFoiIC8+CiAgPC9nPgogIDxnIGNsYXNzPSJqcC1pY29uLWRvdCIgZmlsbD0iI0ZGRiI+CiAgICA8Y2lyY2xlIGN4PSIxOCIgY3k9IjE3IiByPSIzIj48L2NpcmNsZT4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-filter-list: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEwIDE4aDR2LTJoLTR2MnpNMyA2djJoMThWNkgzem0zIDdoMTJ2LTJINnYyeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-filter: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTE0LDEyVjE5Ljg4QzE0LjA0LDIwLjE4IDEzLjk0LDIwLjUgMTMuNzEsMjAuNzFDMTMuMzIsMjEuMSAxMi42OSwyMS4xIDEyLjMsMjAuNzFMMTAuMjksMTguN0MxMC4wNiwxOC40NyA5Ljk2LDE4LjE2IDEwLDE3Ljg3VjEySDkuOTdMNC4yMSw0LjYyQzMuODcsNC4xOSAzLjk1LDMuNTYgNC4zOCwzLjIyQzQuNTcsMy4wOCA0Ljc4LDMgNSwzVjNIMTlWM0MxOS4yMiwzIDE5LjQzLDMuMDggMTkuNjIsMy4yMkMyMC4wNSwzLjU2IDIwLjEzLDQuMTkgMTkuNzksNC42MkwxNC4wMywxMkgxNFoiIC8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-folder-favorite: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjRweCIgdmlld0JveD0iMCAwIDI0IDI0IiB3aWR0aD0iMjRweCIgZmlsbD0iIzAwMDAwMCI+CiAgPHBhdGggZD0iTTAgMGgyNHYyNEgwVjB6IiBmaWxsPSJub25lIi8+PHBhdGggY2xhc3M9ImpwLWljb24zIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzYxNjE2MSIgZD0iTTIwIDZoLThsLTItMkg0Yy0xLjEgMC0yIC45LTIgMnYxMmMwIDEuMS45IDIgMiAyaDE2YzEuMSAwIDItLjkgMi0yVjhjMC0xLjEtLjktMi0yLTJ6bS0yLjA2IDExTDE1IDE1LjI4IDEyLjA2IDE3bC43OC0zLjMzLTIuNTktMi4yNCAzLjQxLS4yOUwxNSA4bDEuMzQgMy4xNCAzLjQxLjI5LTIuNTkgMi4yNC43OCAzLjMzeiIvPgo8L3N2Zz4K);
  --jp-icon-folder: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTAgNEg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMThjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY4YzAtMS4xLS45LTItMi0yaC04bC0yLTJ6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-home: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjRweCIgdmlld0JveD0iMCAwIDI0IDI0IiB3aWR0aD0iMjRweCIgZmlsbD0iIzAwMDAwMCI+CiAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPjxwYXRoIGNsYXNzPSJqcC1pY29uMyBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xMCAyMHYtNmg0djZoNXYtOGgzTDEyIDMgMiAxMmgzdjh6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-html5: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDUxMiA1MTIiPgogIDxwYXRoIGNsYXNzPSJqcC1pY29uMCBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiMwMDAiIGQ9Ik0xMDguNCAwaDIzdjIyLjhoMjEuMlYwaDIzdjY5aC0yM1Y0NmgtMjF2MjNoLTIzLjJNMjA2IDIzaC0yMC4zVjBoNjMuN3YyM0gyMjl2NDZoLTIzbTUzLjUtNjloMjQuMWwxNC44IDI0LjNMMzEzLjIgMGgyNC4xdjY5aC0yM1YzNC44bC0xNi4xIDI0LjgtMTYuMS0yNC44VjY5aC0yMi42bTg5LjItNjloMjN2NDYuMmgzMi42VjY5aC01NS42Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI2U0NGQyNiIgZD0iTTEwNy42IDQ3MWwtMzMtMzcwLjRoMzYyLjhsLTMzIDM3MC4yTDI1NS43IDUxMiIvPgogIDxwYXRoIGNsYXNzPSJqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNmMTY1MjkiIGQ9Ik0yNTYgNDgwLjVWMTMxaDE0OC4zTDM3NiA0NDciLz4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNlYmViZWIiIGQ9Ik0xNDIgMTc2LjNoMTE0djQ1LjRoLTY0LjJsNC4yIDQ2LjVoNjB2NDUuM0gxNTQuNG0yIDIyLjhIMjAybDMuMiAzNi4zIDUwLjggMTMuNnY0Ny40bC05My4yLTI2Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIiBmaWxsPSIjZmZmIiBkPSJNMzY5LjYgMTc2LjNIMjU1Ljh2NDUuNGgxMDkuNm0tNC4xIDQ2LjVIMjU1Ljh2NDUuNGg1NmwtNS4zIDU5LTUwLjcgMTMuNnY0Ny4ybDkzLTI1LjgiLz4KPC9zdmc+Cg==);
  --jp-icon-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1icmFuZDQganAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNGRkYiIGQ9Ik0yLjIgMi4yaDE3LjV2MTcuNUgyLjJ6Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzNGNTFCNSIgZD0iTTIuMiAyLjJ2MTcuNWgxNy41bC4xLTE3LjVIMi4yem0xMi4xIDIuMmMxLjIgMCAyLjIgMSAyLjIgMi4ycy0xIDIuMi0yLjIgMi4yLTIuMi0xLTIuMi0yLjIgMS0yLjIgMi4yLTIuMnpNNC40IDE3LjZsMy4zLTguOCAzLjMgNi42IDIuMi0zLjIgNC40IDUuNEg0LjR6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-info: url(data:image/svg+xml;base64,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);
  --jp-icon-inspector: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaW5zcGVjdG9yLWljb24tY29sb3IganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMjAgNEg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMThjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY2YzAtMS4xLS45LTItMi0yem0tNSAxNEg0di00aDExdjR6bTAtNUg0VjloMTF2NHptNSA1aC00VjloNHY5eiIvPgo8L3N2Zz4K);
  --jp-icon-json: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtanNvbi1pY29uLWNvbG9yIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI0Y5QTgyNSI+CiAgICA8cGF0aCBkPSJNMjAuMiAxMS44Yy0xLjYgMC0xLjcuNS0xLjcgMSAwIC40LjEuOS4xIDEuMy4xLjUuMS45LjEgMS4zIDAgMS43LTEuNCAyLjMtMy41IDIuM2gtLjl2LTEuOWguNWMxLjEgMCAxLjQgMCAxLjQtLjggMC0uMyAwLS42LS4xLTEgMC0uNC0uMS0uOC0uMS0xLjIgMC0xLjMgMC0xLjggMS4zLTItMS4zLS4yLTEuMy0uNy0xLjMtMiAwLS40LjEtLjguMS0xLjIuMS0uNC4xLS43LjEtMSAwLS44LS40LS43LTEuNC0uOGgtLjVWNC4xaC45YzIuMiAwIDMuNS43IDMuNSAyLjMgMCAuNC0uMS45LS4xIDEuMy0uMS41LS4xLjktLjEgMS4zIDAgLjUuMiAxIDEuNyAxdjEuOHpNMS44IDEwLjFjMS42IDAgMS43LS41IDEuNy0xIDAtLjQtLjEtLjktLjEtMS4zLS4xLS41LS4xLS45LS4xLTEuMyAwLTEuNiAxLjQtMi4zIDMuNS0yLjNoLjl2MS45aC0uNWMtMSAwLTEuNCAwLTEuNC44IDAgLjMgMCAuNi4xIDEgMCAuMi4xLjYuMSAxIDAgMS4zIDAgMS44LTEuMyAyQzYgMTEuMiA2IDExLjcgNiAxM2MwIC40LS4xLjgtLjEgMS4yLS4xLjMtLjEuNy0uMSAxIDAgLjguMy44IDEuNC44aC41djEuOWgtLjljLTIuMSAwLTMuNS0uNi0zLjUtMi4zIDAtLjQuMS0uOS4xLTEuMy4xLS41LjEtLjkuMS0xLjMgMC0uNS0uMi0xLTEuNy0xdi0xLjl6Ii8+CiAgICA8Y2lyY2xlIGN4PSIxMSIgY3k9IjEzLjgiIHI9IjIuMSIvPgogICAgPGNpcmNsZSBjeD0iMTEiIGN5PSI4LjIiIHI9IjIuMSIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-julia: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDMyNSAzMDAiPgogIDxnIGNsYXNzPSJqcC1icmFuZDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjY2IzYzMzIj4KICAgIDxwYXRoIGQ9Ik0gMTUwLjg5ODQzOCAyMjUgQyAxNTAuODk4NDM4IDI2Ni40MjE4NzUgMTE3LjMyMDMxMiAzMDAgNzUuODk4NDM4IDMwMCBDIDM0LjQ3NjU2MiAzMDAgMC44OTg0MzggMjY2LjQyMTg3NSAwLjg5ODQzOCAyMjUgQyAwLjg5ODQzOCAxODMuNTc4MTI1IDM0LjQ3NjU2MiAxNTAgNzUuODk4NDM4IDE1MCBDIDExNy4zMjAzMTIgMTUwIDE1MC44OTg0MzggMTgzLjU3ODEyNSAxNTAuODk4NDM4IDIyNSIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzM4OTgyNiI+CiAgICA8cGF0aCBkPSJNIDIzNy41IDc1IEMgMjM3LjUgMTE2LjQyMTg3NSAyMDMuOTIxODc1IDE1MCAxNjIuNSAxNTAgQyAxMjEuMDc4MTI1IDE1MCA4Ny41IDExNi40MjE4NzUgODcuNSA3NSBDIDg3LjUgMzMuNTc4MTI1IDEyMS4wNzgxMjUgMCAxNjIuNSAwIEMgMjAzLjkyMTg3NSAwIDIzNy41IDMzLjU3ODEyNSAyMzcuNSA3NSIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzk1NThiMiI+CiAgICA8cGF0aCBkPSJNIDMyNC4xMDE1NjIgMjI1IEMgMzI0LjEwMTU2MiAyNjYuNDIxODc1IDI5MC41MjM0MzggMzAwIDI0OS4xMDE1NjIgMzAwIEMgMjA3LjY3OTY4OCAzMDAgMTc0LjEwMTU2MiAyNjYuNDIxODc1IDE3NC4xMDE1NjIgMjI1IEMgMTc0LjEwMTU2MiAxODMuNTc4MTI1IDIwNy42Nzk2ODggMTUwIDI0OS4xMDE1NjIgMTUwIEMgMjkwLjUyMzQzOCAxNTAgMzI0LjEwMTU2MiAxODMuNTc4MTI1IDMyNC4xMDE1NjIgMjI1Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-jupyter-favicon: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTUyIiBoZWlnaHQ9IjE2NSIgdmlld0JveD0iMCAwIDE1MiAxNjUiIHZlcnNpb249IjEuMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgPGcgY2xhc3M9ImpwLWp1cHl0ZXItaWNvbi1jb2xvciIgZmlsbD0iI0YzNzcyNiI+CiAgICA8cGF0aCB0cmFuc2Zvcm09InRyYW5zbGF0ZSgwLjA3ODk0NywgMTEwLjU4MjkyNykiIGQ9Ik03NS45NDIyODQyLDI5LjU4MDQ1NjEgQzQzLjMwMjM5NDcsMjkuNTgwNDU2MSAxNC43OTY3ODMyLDE3LjY1MzQ2MzQgMCwwIEM1LjUxMDgzMjExLDE1Ljg0MDY4MjkgMTUuNzgxNTM4OSwyOS41NjY3NzMyIDI5LjM5MDQ5NDcsMzkuMjc4NDE3MSBDNDIuOTk5Nyw0OC45ODk4NTM3IDU5LjI3MzcsNTQuMjA2NzgwNSA3NS45NjA1Nzg5LDU0LjIwNjc4MDUgQzkyLjY0NzQ1NzksNTQuMjA2NzgwNSAxMDguOTIxNDU4LDQ4Ljk4OTg1MzcgMTIyLjUzMDY2MywzOS4yNzg0MTcxIEMxMzYuMTM5NDUzLDI5LjU2Njc3MzIgMTQ2LjQxMDI4NCwxNS44NDA2ODI5IDE1MS45MjExNTgsMCBDMTM3LjA4Nzg2OCwxNy42NTM0NjM0IDEwOC41ODI1ODksMjkuNTgwNDU2MSA3NS45NDIyODQyLDI5LjU4MDQ1NjEgTDc1Ljk0MjI4NDIsMjkuNTgwNDU2MSBaIiAvPgogICAgPHBhdGggdHJhbnNmb3JtPSJ0cmFuc2xhdGUoMC4wMzczNjgsIDAuNzA0ODc4KSIgZD0iTTc1Ljk3ODQ1NzksMjQuNjI2NDA3MyBDMTA4LjYxODc2MywyNC42MjY0MDczIDEzNy4xMjQ0NTgsMzYuNTUzNDQxNSAxNTEuOTIxMTU4LDU0LjIwNjc4MDUgQzE0Ni40MTAyODQsMzguMzY2MjIyIDEzNi4xMzk0NTMsMjQuNjQwMTMxNyAxMjIuNTMwNjYzLDE0LjkyODQ4NzggQzEwOC45MjE0NTgsNS4yMTY4NDM5IDkyLjY0NzQ1NzksMCA3NS45NjA1Nzg5LDAgQzU5LjI3MzcsMCA0Mi45OTk3LDUuMjE2ODQzOSAyOS4zOTA0OTQ3LDE0LjkyODQ4NzggQzE1Ljc4MTUzODksMjQuNjQwMTMxNyA1LjUxMDgzMjExLDM4LjM2NjIyMiAwLDU0LjIwNjc4MDUgQzE0LjgzMzA4MTYsMzYuNTg5OTI5MyA0My4zMzg1Njg0LDI0LjYyNjQwNzMgNzUuOTc4NDU3OSwyNC42MjY0MDczIEw3NS45Nzg0NTc5LDI0LjYyNjQwNzMgWiIgLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-jupyter: url(data:image/svg+xml;base64,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);
  --jp-icon-jupyterlab-wordmark: url(data:image/svg+xml;base64,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);
  --jp-icon-kernel: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgZmlsbD0iIzYxNjE2MSIgZD0iTTE1IDlIOXY2aDZWOXptLTIgNGgtMnYtMmgydjJ6bTgtMlY5aC0yVjdjMC0xLjEtLjktMi0yLTJoLTJWM2gtMnYyaC0yVjNIOXYySDdjLTEuMSAwLTIgLjktMiAydjJIM3YyaDJ2MkgzdjJoMnYyYzAgMS4xLjkgMiAyIDJoMnYyaDJ2LTJoMnYyaDJ2LTJoMmMxLjEgMCAyLS45IDItMnYtMmgydi0yaC0ydi0yaDJ6bS00IDZIN1Y3aDEwdjEweiIvPgo8L3N2Zz4K);
  --jp-icon-keyboard: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMjAgNUg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMTdjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY3YzAtMS4xLS45LTItMi0yem0tOSAzaDJ2MmgtMlY4em0wIDNoMnYyaC0ydi0yek04IDhoMnYySDhWOHptMCAzaDJ2Mkg4di0yem0tMSAySDV2LTJoMnYyem0wLTNINVY4aDJ2MnptOSA3SDh2LTJoOHYyem0wLTRoLTJ2LTJoMnYyem0wLTNoLTJWOGgydjJ6bTMgM2gtMnYtMmgydjJ6bTAtM2gtMlY4aDJ2MnoiLz4KPC9zdmc+Cg==);
  --jp-icon-launch: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMzIgMzIiIHdpZHRoPSIzMiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0yNiwyOEg2YTIuMDAyNywyLjAwMjcsMCwwLDEtMi0yVjZBMi4wMDI3LDIuMDAyNywwLDAsMSw2LDRIMTZWNkg2VjI2SDI2VjE2aDJWMjZBMi4wMDI3LDIuMDAyNywwLDAsMSwyNiwyOFoiLz4KICAgIDxwb2x5Z29uIHBvaW50cz0iMjAgMiAyMCA0IDI2LjU4NiA0IDE4IDEyLjU4NiAxOS40MTQgMTQgMjggNS40MTQgMjggMTIgMzAgMTIgMzAgMiAyMCAyIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-launcher: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkgMTlINVY1aDdWM0g1YTIgMiAwIDAwLTIgMnYxNGEyIDIgMCAwMDIgMmgxNGMxLjEgMCAyLS45IDItMnYtN2gtMnY3ek0xNCAzdjJoMy41OWwtOS44MyA5LjgzIDEuNDEgMS40MUwxOSA2LjQxVjEwaDJWM2gtN3oiLz4KPC9zdmc+Cg==);
  --jp-icon-line-form: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGZpbGw9IndoaXRlIiBkPSJNNS44OCA0LjEyTDEzLjc2IDEybC03Ljg4IDcuODhMOCAyMmwxMC0xMEw4IDJ6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-link: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTMuOSAxMmMwLTEuNzEgMS4zOS0zLjEgMy4xLTMuMWg0VjdIN2MtMi43NiAwLTUgMi4yNC01IDVzMi4yNCA1IDUgNWg0di0xLjlIN2MtMS43MSAwLTMuMS0xLjM5LTMuMS0zLjF6TTggMTNoOHYtMkg4djJ6bTktNmgtNHYxLjloNGMxLjcxIDAgMy4xIDEuMzkgMy4xIDMuMXMtMS4zOSAzLjEtMy4xIDMuMWgtNFYxN2g0YzIuNzYgMCA1LTIuMjQgNS01cy0yLjI0LTUtNS01eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-list: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xOSA1djE0SDVWNWgxNG0xLjEtMkgzLjljLS41IDAtLjkuNC0uOS45djE2LjJjMCAuNC40LjkuOS45aDE2LjJjLjQgMCAuOS0uNS45LS45VjMuOWMwLS41LS41LS45LS45LS45ek0xMSA3aDZ2MmgtNlY3em0wIDRoNnYyaC02di0yem0wIDRoNnYyaC02ek03IDdoMnYySDd6bTAgNGgydjJIN3ptMCA0aDJ2Mkg3eiIvPgo8L3N2Zz4K);
  --jp-icon-markdown: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjN0IxRkEyIiBkPSJNNSAxNC45aDEybC02LjEgNnptOS40LTYuOGMwLTEuMy0uMS0yLjktLjEtNC41LS40IDEuNC0uOSAyLjktMS4zIDQuM2wtMS4zIDQuM2gtMkw4LjUgNy45Yy0uNC0xLjMtLjctMi45LTEtNC4zLS4xIDEuNi0uMSAzLjItLjIgNC42TDcgMTIuNEg0LjhsLjctMTFoMy4zTDEwIDVjLjQgMS4yLjcgMi43IDEgMy45LjMtMS4yLjctMi42IDEtMy45bDEuMi0zLjdoMy4zbC42IDExaC0yLjRsLS4zLTQuMnoiLz4KPC9zdmc+Cg==);
  --jp-icon-move-down: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBkPSJNMTIuNDcxIDcuNTI4OTlDMTIuNzYzMiA3LjIzNjg0IDEyLjc2MzIgNi43NjMxNiAxMi40NzEgNi40NzEwMVY2LjQ3MTAxQzEyLjE3OSA2LjE3OTA1IDExLjcwNTcgNi4xNzg4NCAxMS40MTM1IDYuNDcwNTRMNy43NSAxMC4xMjc1VjEuNzVDNy43NSAxLjMzNTc5IDcuNDE0MjEgMSA3IDFWMUM2LjU4NTc5IDEgNi4yNSAxLjMzNTc5IDYuMjUgMS43NVYxMC4xMjc1TDIuNTk3MjYgNi40NjgyMkMyLjMwMzM4IDYuMTczODEgMS44MjY0MSA2LjE3MzU5IDEuNTMyMjYgNi40Njc3NFY2LjQ2Nzc0QzEuMjM4MyA2Ljc2MTcgMS4yMzgzIDcuMjM4MyAxLjUzMjI2IDcuNTMyMjZMNi4yOTI4OSAxMi4yOTI5QzYuNjgzNDIgMTIuNjgzNCA3LjMxNjU4IDEyLjY4MzQgNy43MDcxMSAxMi4yOTI5TDEyLjQ3MSA3LjUyODk5WiIgZmlsbD0iIzYxNjE2MSIvPgo8L3N2Zz4K);
  --jp-icon-move-up: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBkPSJNMS41Mjg5OSA2LjQ3MTAxQzEuMjM2ODQgNi43NjMxNiAxLjIzNjg0IDcuMjM2ODQgMS41Mjg5OSA3LjUyODk5VjcuNTI4OTlDMS44MjA5NSA3LjgyMDk1IDIuMjk0MjYgNy44MjExNiAyLjU4NjQ5IDcuNTI5NDZMNi4yNSAzLjg3MjVWMTIuMjVDNi4yNSAxMi42NjQyIDYuNTg1NzkgMTMgNyAxM1YxM0M3LjQxNDIxIDEzIDcuNzUgMTIuNjY0MiA3Ljc1IDEyLjI1VjMuODcyNUwxMS40MDI3IDcuNTMxNzhDMTEuNjk2NiA3LjgyNjE5IDEyLjE3MzYgNy44MjY0MSAxMi40Njc3IDcuNTMyMjZWNy41MzIyNkMxMi43NjE3IDcuMjM4MyAxMi43NjE3IDYuNzYxNyAxMi40Njc3IDYuNDY3NzRMNy43MDcxMSAxLjcwNzExQzcuMzE2NTggMS4zMTY1OCA2LjY4MzQyIDEuMzE2NTggNi4yOTI4OSAxLjcwNzExTDEuNTI4OTkgNi40NzEwMVoiIGZpbGw9IiM2MTYxNjEiLz4KPC9zdmc+Cg==);
  --jp-icon-new-folder: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwIDZoLThsLTItMkg0Yy0xLjExIDAtMS45OS44OS0xLjk5IDJMMiAxOGMwIDEuMTEuODkgMiAyIDJoMTZjMS4xMSAwIDItLjg5IDItMlY4YzAtMS4xMS0uODktMi0yLTJ6bS0xIDhoLTN2M2gtMnYtM2gtM3YtMmgzVjloMnYzaDN2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-not-trusted: url(data:image/svg+xml;base64,PHN2ZyBmaWxsPSJub25lIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI1IDI1Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDMgMykiIGQ9Ik0xLjg2MDk0IDExLjQ0MDlDMC44MjY0NDggOC43NzAyNyAwLjg2Mzc3OSA2LjA1NzY0IDEuMjQ5MDcgNC4xOTkzMkMyLjQ4MjA2IDMuOTMzNDcgNC4wODA2OCAzLjQwMzQ3IDUuNjAxMDIgMi44NDQ5QzcuMjM1NDkgMi4yNDQ0IDguODU2NjYgMS41ODE1IDkuOTg3NiAxLjA5NTM5QzExLjA1OTcgMS41ODM0MSAxMi42MDk0IDIuMjQ0NCAxNC4yMTggMi44NDMzOUMxNS43NTAzIDMuNDEzOTQgMTcuMzk5NSAzLjk1MjU4IDE4Ljc1MzkgNC4yMTM4NUMxOS4xMzY0IDYuMDcxNzcgMTkuMTcwOSA4Ljc3NzIyIDE4LjEzOSAxMS40NDA5QzE3LjAzMDMgMTQuMzAzMiAxNC42NjY4IDE3LjE4NDQgOS45OTk5OSAxOC45MzU0QzUuMzMzMTkgMTcuMTg0NCAyLjk2OTY4IDE0LjMwMzIgMS44NjA5NCAxMS40NDA5WiIvPgogICAgPHBhdGggY2xhc3M9ImpwLWljb24yIiBzdHJva2U9IiMzMzMzMzMiIHN0cm9rZS13aWR0aD0iMiIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoOS4zMTU5MiA5LjMyMDMxKSIgZD0iTTcuMzY4NDIgMEwwIDcuMzY0NzkiLz4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDkuMzE1OTIgMTYuNjgzNikgc2NhbGUoMSAtMSkiIGQ9Ik03LjM2ODQyIDBMMCA3LjM2NDc5Ii8+Cjwvc3ZnPgo=);
  --jp-icon-notebook: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtbm90ZWJvb2staWNvbi1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNFRjZDMDAiPgogICAgPHBhdGggZD0iTTE4LjcgMy4zdjE1LjRIMy4zVjMuM2gxNS40bTEuNS0xLjVIMS44djE4LjNoMTguM2wuMS0xOC4zeiIvPgogICAgPHBhdGggZD0iTTE2LjUgMTYuNWwtNS40LTQuMy01LjYgNC4zdi0xMWgxMXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-numbering: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjIiIGhlaWdodD0iMjIiIHZpZXdCb3g9IjAgMCAyOCAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTQgMTlINlYxOS41SDVWMjAuNUg2VjIxSDRWMjJIN1YxOEg0VjE5Wk01IDEwSDZWNkg0VjdINVYxMFpNNCAxM0g1LjhMNCAxNS4xVjE2SDdWMTVINS4yTDcgMTIuOVYxMkg0VjEzWk05IDdWOUgyM1Y3SDlaTTkgMjFIMjNWMTlIOVYyMVpNOSAxNUgyM1YxM0g5VjE1WiIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-offline-bolt: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyIDIuMDJjLTUuNTEgMC05Ljk4IDQuNDctOS45OCA5Ljk4czQuNDcgOS45OCA5Ljk4IDkuOTggOS45OC00LjQ3IDkuOTgtOS45OFMxNy41MSAyLjAyIDEyIDIuMDJ6TTExLjQ4IDIwdi02LjI2SDhMMTMgNHY2LjI2aDMuMzVMMTEuNDggMjB6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-palette: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE4IDEzVjIwSDRWNkg5LjAyQzkuMDcgNS4yOSA5LjI0IDQuNjIgOS41IDRINEMyLjkgNCAyIDQuOSAyIDZWMjBDMiAyMS4xIDIuOSAyMiA0IDIySDE4QzE5LjEgMjIgMjAgMjEuMSAyMCAyMFYxNUwxOCAxM1pNMTkuMyA4Ljg5QzE5Ljc0IDguMTkgMjAgNy4zOCAyMCA2LjVDMjAgNC4wMSAxNy45OSAyIDE1LjUgMkMxMy4wMSAyIDExIDQuMDEgMTEgNi41QzExIDguOTkgMTMuMDEgMTEgMTUuNDkgMTFDMTYuMzcgMTEgMTcuMTkgMTAuNzQgMTcuODggMTAuM0wyMSAxMy40MkwyMi40MiAxMkwxOS4zIDguODlaTTE1LjUgOUMxNC4xMiA5IDEzIDcuODggMTMgNi41QzEzIDUuMTIgMTQuMTIgNCAxNS41IDRDMTYuODggNCAxOCA1LjEyIDE4IDYuNUMxOCA3Ljg4IDE2Ljg4IDkgMTUuNSA5WiIvPgogICAgPHBhdGggZmlsbC1ydWxlPSJldmVub2RkIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik00IDZIOS4wMTg5NEM5LjAwNjM5IDYuMTY1MDIgOSA2LjMzMTc2IDkgNi41QzkgOC44MTU3NyAxMC4yMTEgMTAuODQ4NyAxMi4wMzQzIDEySDlWMTRIMTZWMTIuOTgxMUMxNi41NzAzIDEyLjkzNzcgMTcuMTIgMTIuODIwNyAxNy42Mzk2IDEyLjYzOTZMMTggMTNWMjBINFY2Wk04IDhINlYxMEg4VjhaTTYgMTJIOFYxNEg2VjEyWk04IDE2SDZWMThIOFYxNlpNOSAxNkgxNlYxOEg5VjE2WiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-paste: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTE5IDJoLTQuMThDMTQuNC44NCAxMy4zIDAgMTIgMGMtMS4zIDAtMi40Ljg0LTIuODIgMkg1Yy0xLjEgMC0yIC45LTIgMnYxNmMwIDEuMS45IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjRjMC0xLjEtLjktMi0yLTJ6bS03IDBjLjU1IDAgMSAuNDUgMSAxcy0uNDUgMS0xIDEtMS0uNDUtMS0xIC40NS0xIDEtMXptNyAxOEg1VjRoMnYzaDEwVjRoMnYxNnoiLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-pdf: url(data:image/svg+xml;base64,PHN2ZwogICB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyMiAyMiIgd2lkdGg9IjE2Ij4KICAgIDxwYXRoIHRyYW5zZm9ybT0icm90YXRlKDQ1KSIgY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI0ZGMkEyQSIKICAgICAgIGQ9Im0gMjIuMzQ0MzY5LC0zLjAxNjM2NDIgaCA1LjYzODYwNCB2IDEuNTc5MjQzMyBoIC0zLjU0OTIyNyB2IDEuNTA4NjkyOTkgaCAzLjMzNzU3NiBWIDEuNjUwODE1NCBoIC0zLjMzNzU3NiB2IDMuNDM1MjYxMyBoIC0yLjA4OTM3NyB6IG0gLTcuMTM2NDQ0LDEuNTc5MjQzMyB2IDQuOTQzOTU0MyBoIDAuNzQ4OTIgcSAxLjI4MDc2MSwwIDEuOTUzNzAzLC0wLjYzNDk1MzUgMC42NzgzNjksLTAuNjM0OTUzNSAwLjY3ODM2OSwtMS44NDUxNjQxIDAsLTEuMjA0NzgzNTUgLTAuNjcyOTQyLC0xLjgzNDMxMDExIC0wLjY3Mjk0MiwtMC42Mjk1MjY1OSAtMS45NTkxMywtMC42Mjk1MjY1OSB6IG0gLTIuMDg5Mzc3LC0xLjU3OTI0MzMgaCAyLjIwMzM0MyBxIDEuODQ1MTY0LDAgMi43NDYwMzksMC4yNjU5MjA3IDAuOTA2MzAxLDAuMjYwNDkzNyAxLjU1MjEwOCwwLjg5MDAyMDMgMC41Njk4MywwLjU0ODEyMjMgMC44NDY2MDUsMS4yNjQ0ODAwNiAwLjI3Njc3NCwwLjcxNjM1NzgxIDAuMjc2Nzc0LDEuNjIyNjU4OTQgMCwwLjkxNzE1NTEgLTAuMjc2Nzc0LDEuNjM4OTM5OSAtMC4yNzY3NzUsMC43MTYzNTc4IC0wLjg0NjYwNSwxLjI2NDQ4IC0wLjY1MTIzNCwwLjYyOTUyNjYgLTEuNTYyOTYyLDAuODk1NDQ3MyAtMC45MTE3MjgsMC4yNjA0OTM3IC0yLjczNTE4NSwwLjI2MDQ5MzcgaCAtMi4yMDMzNDMgeiBtIC04LjE0NTg1NjUsMCBoIDMuNDY3ODIzIHEgMS41NDY2ODE2LDAgMi4zNzE1Nzg1LDAuNjg5MjIzIDAuODMwMzI0LDAuNjgzNzk2MSAwLjgzMDMyNCwxLjk1MzcwMzE0IDAsMS4yNzUzMzM5NyAtMC44MzAzMjQsMS45NjQ1NTcwNiBRIDkuOTg3MTk2MSwyLjI3NDkxNSA4LjQ0MDUxNDUsMi4yNzQ5MTUgSCA3LjA2MjA2ODQgViA1LjA4NjA3NjcgSCA0Ljk3MjY5MTUgWiBtIDIuMDg5Mzc2OSwxLjUxNDExOTkgdiAyLjI2MzAzOTQzIGggMS4xNTU5NDEgcSAwLjYwNzgxODgsMCAwLjkzODg2MjksLTAuMjkzMDU1NDcgMC4zMzEwNDQxLC0wLjI5ODQ4MjQxIDAuMzMxMDQ0MSwtMC44NDExNzc3MiAwLC0wLjU0MjY5NTMxIC0wLjMzMTA0NDEsLTAuODM1NzUwNzQgLTAuMzMxMDQ0MSwtMC4yOTMwNTU1IC0wLjkzODg2MjksLTAuMjkzMDU1NSB6IgovPgo8L3N2Zz4K);
  --jp-icon-python: url(data:image/svg+xml;base64,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);
  --jp-icon-r-kernel: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMjE5NkYzIiBkPSJNNC40IDIuNWMxLjItLjEgMi45LS4zIDQuOS0uMyAyLjUgMCA0LjEuNCA1LjIgMS4zIDEgLjcgMS41IDEuOSAxLjUgMy41IDAgMi0xLjQgMy41LTIuOSA0LjEgMS4yLjQgMS43IDEuNiAyLjIgMyAuNiAxLjkgMSAzLjkgMS4zIDQuNmgtMy44Yy0uMy0uNC0uOC0xLjctMS4yLTMuN3MtMS4yLTIuNi0yLjYtMi42aC0uOXY2LjRINC40VjIuNXptMy43IDYuOWgxLjRjMS45IDAgMi45LS45IDIuOS0yLjNzLTEtMi4zLTIuOC0yLjNjLS43IDAtMS4zIDAtMS42LjJ2NC41aC4xdi0uMXoiLz4KPC9zdmc+Cg==);
  --jp-icon-react: url(data:image/svg+xml;base64,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);
  --jp-icon-redo: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgICA8cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIi8+PHBhdGggZD0iTTE4LjQgMTAuNkMxNi41NSA4Ljk5IDE0LjE1IDggMTEuNSA4Yy00LjY1IDAtOC41OCAzLjAzLTkuOTYgNy4yMkwzLjkgMTZjMS4wNS0zLjE5IDQuMDUtNS41IDcuNi01LjUgMS45NSAwIDMuNzMuNzIgNS4xMiAxLjg4TDEzIDE2aDlWN2wtMy42IDMuNnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-refresh: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTkgMTMuNWMtMi40OSAwLTQuNS0yLjAxLTQuNS00LjVTNi41MSA0LjUgOSA0LjVjMS4yNCAwIDIuMzYuNTIgMy4xNyAxLjMzTDEwIDhoNVYzbC0xLjc2IDEuNzZDMTIuMTUgMy42OCAxMC42NiAzIDkgMyA1LjY5IDMgMy4wMSA1LjY5IDMuMDEgOVM1LjY5IDE1IDkgMTVjMi45NyAwIDUuNDMtMi4xNiA1LjktNWgtMS41MmMtLjQ2IDItMi4yNCAzLjUtNC4zOCAzLjV6Ii8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-regex: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KICA8ZyBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiM0MTQxNDEiPgogICAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiAgPC9nPgoKICA8ZyBjbGFzcz0ianAtaWNvbi1hY2NlbnQyIiBmaWxsPSIjRkZGIj4KICAgIDxjaXJjbGUgY2xhc3M9InN0MiIgY3g9IjUuNSIgY3k9IjE0LjUiIHI9IjEuNSIvPgogICAgPHJlY3QgeD0iMTIiIHk9IjQiIGNsYXNzPSJzdDIiIHdpZHRoPSIxIiBoZWlnaHQ9IjgiLz4KICAgIDxyZWN0IHg9IjguNSIgeT0iNy41IiB0cmFuc2Zvcm09Im1hdHJpeCgwLjg2NiAtMC41IDAuNSAwLjg2NiAtMi4zMjU1IDcuMzIxOSkiIGNsYXNzPSJzdDIiIHdpZHRoPSI4IiBoZWlnaHQ9IjEiLz4KICAgIDxyZWN0IHg9IjEyIiB5PSI0IiB0cmFuc2Zvcm09Im1hdHJpeCgwLjUgLTAuODY2IDAuODY2IDAuNSAtMC42Nzc5IDE0LjgyNTIpIiBjbGFzcz0ic3QyIiB3aWR0aD0iMSIgaGVpZ2h0PSI4Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-run: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTggNXYxNGwxMS03eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-running: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDUxMiA1MTIiPgogIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICA8cGF0aCBkPSJNMjU2IDhDMTE5IDggOCAxMTkgOCAyNTZzMTExIDI0OCAyNDggMjQ4IDI0OC0xMTEgMjQ4LTI0OFMzOTMgOCAyNTYgOHptOTYgMzI4YzAgOC44LTcuMiAxNi0xNiAxNkgxNzZjLTguOCAwLTE2LTcuMi0xNi0xNlYxNzZjMC04LjggNy4yLTE2IDE2LTE2aDE2MGM4LjggMCAxNiA3LjIgMTYgMTZ2MTYweiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-save: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTE3IDNINWMtMS4xMSAwLTIgLjktMiAydjE0YzAgMS4xLjg5IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjdsLTQtNHptLTUgMTZjLTEuNjYgMC0zLTEuMzQtMy0zczEuMzQtMyAzLTMgMyAxLjM0IDMgMy0xLjM0IDMtMyAzem0zLTEwSDVWNWgxMHY0eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-search: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjEsMTAuOWgtMC43bC0wLjItMC4yYzAuOC0wLjksMS4zLTIuMiwxLjMtMy41YzAtMy0yLjQtNS40LTUuNC01LjRTMS44LDQuMiwxLjgsNy4xczIuNCw1LjQsNS40LDUuNCBjMS4zLDAsMi41LTAuNSwzLjUtMS4zbDAuMiwwLjJ2MC43bDQuMSw0LjFsMS4yLTEuMkwxMi4xLDEwLjl6IE03LjEsMTAuOWMtMi4xLDAtMy43LTEuNy0zLjctMy43czEuNy0zLjcsMy43LTMuN3MzLjcsMS43LDMuNywzLjcgUzkuMiwxMC45LDcuMSwxMC45eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-settings: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkuNDMgMTIuOThjLjA0LS4zMi4wNy0uNjQuMDctLjk4cy0uMDMtLjY2LS4wNy0uOThsMi4xMS0xLjY1Yy4xOS0uMTUuMjQtLjQyLjEyLS42NGwtMi0zLjQ2Yy0uMTItLjIyLS4zOS0uMy0uNjEtLjIybC0yLjQ5IDFjLS41Mi0uNC0xLjA4LS43My0xLjY5LS45OGwtLjM4LTIuNjVBLjQ4OC40ODggMCAwMDE0IDJoLTRjLS4yNSAwLS40Ni4xOC0uNDkuNDJsLS4zOCAyLjY1Yy0uNjEuMjUtMS4xNy41OS0xLjY5Ljk4bC0yLjQ5LTFjLS4yMy0uMDktLjQ5IDAtLjYxLjIybC0yIDMuNDZjLS4xMy4yMi0uMDcuNDkuMTIuNjRsMi4xMSAxLjY1Yy0uMDQuMzItLjA3LjY1LS4wNy45OHMuMDMuNjYuMDcuOThsLTIuMTEgMS42NWMtLjE5LjE1LS4yNC40Mi0uMTIuNjRsMiAzLjQ2Yy4xMi4yMi4zOS4zLjYxLjIybDIuNDktMWMuNTIuNCAxLjA4LjczIDEuNjkuOThsLjM4IDIuNjVjLjAzLjI0LjI0LjQyLjQ5LjQyaDRjLjI1IDAgLjQ2LS4xOC40OS0uNDJsLjM4LTIuNjVjLjYxLS4yNSAxLjE3LS41OSAxLjY5LS45OGwyLjQ5IDFjLjIzLjA5LjQ5IDAgLjYxLS4yMmwyLTMuNDZjLjEyLS4yMi4wNy0uNDktLjEyLS42NGwtMi4xMS0xLjY1ek0xMiAxNS41Yy0xLjkzIDAtMy41LTEuNTctMy41LTMuNXMxLjU3LTMuNSAzLjUtMy41IDMuNSAxLjU3IDMuNSAzLjUtMS41NyAzLjUtMy41IDMuNXoiLz4KPC9zdmc+Cg==);
  --jp-icon-share: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIHZpZXdCb3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTSAxOCAyIEMgMTYuMzU0OTkgMiAxNSAzLjM1NDk5MDQgMTUgNSBDIDE1IDUuMTkwOTUyOSAxNS4wMjE3OTEgNS4zNzcxMjI0IDE1LjA1NjY0MSA1LjU1ODU5MzggTCA3LjkyMTg3NSA5LjcyMDcwMzEgQyA3LjM5ODUzOTkgOS4yNzc4NTM5IDYuNzMyMDc3MSA5IDYgOSBDIDQuMzU0OTkwNCA5IDMgMTAuMzU0OTkgMyAxMiBDIDMgMTMuNjQ1MDEgNC4zNTQ5OTA0IDE1IDYgMTUgQyA2LjczMjA3NzEgMTUgNy4zOTg1Mzk5IDE0LjcyMjE0NiA3LjkyMTg3NSAxNC4yNzkyOTcgTCAxNS4wNTY2NDEgMTguNDM5NDUzIEMgMTUuMDIxNTU1IDE4LjYyMTUxNCAxNSAxOC44MDgzODYgMTUgMTkgQyAxNSAyMC42NDUwMSAxNi4zNTQ5OSAyMiAxOCAyMiBDIDE5LjY0NTAxIDIyIDIxIDIwLjY0NTAxIDIxIDE5IEMgMjEgMTcuMzU0OTkgMTkuNjQ1MDEgMTYgMTggMTYgQyAxNy4yNjc0OCAxNiAxNi42MDE1OTMgMTYuMjc5MzI4IDE2LjA3ODEyNSAxNi43MjI2NTYgTCA4Ljk0MzM1OTQgMTIuNTU4NTk0IEMgOC45NzgyMDk1IDEyLjM3NzEyMiA5IDEyLjE5MDk1MyA5IDEyIEMgOSAxMS44MDkwNDcgOC45NzgyMDk1IDExLjYyMjg3OCA4Ljk0MzM1OTQgMTEuNDQxNDA2IEwgMTYuMDc4MTI1IDcuMjc5Mjk2OSBDIDE2LjYwMTQ2IDcuNzIyMTQ2MSAxNy4yNjc5MjMgOCAxOCA4IEMgMTkuNjQ1MDEgOCAyMSA2LjY0NTAwOTYgMjEgNSBDIDIxIDMuMzU0OTkwNCAxOS42NDUwMSAyIDE4IDIgeiBNIDE4IDQgQyAxOC41NjQxMjkgNCAxOSA0LjQzNTg3MDYgMTkgNSBDIDE5IDUuNTY0MTI5NCAxOC41NjQxMjkgNiAxOCA2IEMgMTcuNDM1ODcxIDYgMTcgNS41NjQxMjk0IDE3IDUgQyAxNyA0LjQzNTg3MDYgMTcuNDM1ODcxIDQgMTggNCB6IE0gNiAxMSBDIDYuNTY0MTI5NCAxMSA3IDExLjQzNTg3MSA3IDEyIEMgNyAxMi41NjQxMjkgNi41NjQxMjk0IDEzIDYgMTMgQyA1LjQzNTg3MDYgMTMgNSAxMi41NjQxMjkgNSAxMiBDIDUgMTEuNDM1ODcxIDUuNDM1ODcwNiAxMSA2IDExIHogTSAxOCAxOCBDIDE4LjU2NDEyOSAxOCAxOSAxOC40MzU4NzEgMTkgMTkgQyAxOSAxOS41NjQxMjkgMTguNTY0MTI5IDIwIDE4IDIwIEMgMTcuNDM1ODcxIDIwIDE3IDE5LjU2NDEyOSAxNyAxOSBDIDE3IDE4LjQzNTg3MSAxNy40MzU4NzEgMTggMTggMTggeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-spreadsheet: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDEganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNENBRjUwIiBkPSJNMi4yIDIuMnYxNy42aDE3LjZWMi4ySDIuMnptMTUuNCA3LjdoLTUuNVY0LjRoNS41djUuNXpNOS45IDQuNHY1LjVINC40VjQuNGg1LjV6bS01LjUgNy43aDUuNXY1LjVINC40di01LjV6bTcuNyA1LjV2LTUuNWg1LjV2NS41aC01LjV6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-stop: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik02IDZoMTJ2MTJINnoiLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-tab: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIxIDNIM2MtMS4xIDAtMiAuOS0yIDJ2MTRjMCAxLjEuOSAyIDIgMmgxOGMxLjEgMCAyLS45IDItMlY1YzAtMS4xLS45LTItMi0yem0wIDE2SDNWNWgxMHY0aDh2MTB6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-table-rows: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik0yMSw4SDNWNGgxOFY4eiBNMjEsMTBIM3Y0aDE4VjEweiBNMjEsMTZIM3Y0aDE4VjE2eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-tag: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjgiIGhlaWdodD0iMjgiIHZpZXdCb3g9IjAgMCA0MyAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTI4LjgzMzIgMTIuMzM0TDMyLjk5OTggMTYuNTAwN0wzNy4xNjY1IDEyLjMzNEgyOC44MzMyWiIvPgoJCTxwYXRoIGQ9Ik0xNi4yMDk1IDIxLjYxMDRDMTUuNjg3MyAyMi4xMjk5IDE0Ljg0NDMgMjIuMTI5OSAxNC4zMjQ4IDIxLjYxMDRMNi45ODI5IDE0LjcyNDVDNi41NzI0IDE0LjMzOTQgNi4wODMxMyAxMy42MDk4IDYuMDQ3ODYgMTMuMDQ4MkM1Ljk1MzQ3IDExLjUyODggNi4wMjAwMiA4LjYxOTQ0IDYuMDY2MjEgNy4wNzY5NUM2LjA4MjgxIDYuNTE0NzcgNi41NTU0OCA2LjA0MzQ3IDcuMTE4MDQgNi4wMzA1NUM5LjA4ODYzIDUuOTg0NzMgMTMuMjYzOCA1LjkzNTc5IDEzLjY1MTggNi4zMjQyNUwyMS43MzY5IDEzLjYzOUMyMi4yNTYgMTQuMTU4NSAyMS43ODUxIDE1LjQ3MjQgMjEuMjYyIDE1Ljk5NDZMMTYuMjA5NSAyMS42MTA0Wk05Ljc3NTg1IDguMjY1QzkuMzM1NTEgNy44MjU2NiA4LjYyMzUxIDcuODI1NjYgOC4xODI4IDguMjY1QzcuNzQzNDYgOC43MDU3MSA3Ljc0MzQ2IDkuNDE3MzMgOC4xODI4IDkuODU2NjdDOC42MjM4MiAxMC4yOTY0IDkuMzM1ODIgMTAuMjk2NCA5Ljc3NTg1IDkuODU2NjdDMTAuMjE1NiA5LjQxNzMzIDEwLjIxNTYgOC43MDUzMyA5Ljc3NTg1IDguMjY1WiIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-terminal: url(data:image/svg+xml;base64,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);
  --jp-icon-text-editor: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtdGV4dC1lZGl0b3ItaWNvbi1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xNSAxNUgzdjJoMTJ2LTJ6bTAtOEgzdjJoMTJWN3pNMyAxM2gxOHYtMkgzdjJ6bTAgOGgxOHYtMkgzdjJ6TTMgM3YyaDE4VjNIM3oiLz4KPC9zdmc+Cg==);
  --jp-icon-toc: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik03LDVIMjFWN0g3VjVNNywxM1YxMUgyMVYxM0g3TTQsNC41QTEuNSwxLjUgMCAwLDEgNS41LDZBMS41LDEuNSAwIDAsMSA0LDcuNUExLjUsMS41IDAgMCwxIDIuNSw2QTEuNSwxLjUgMCAwLDEgNCw0LjVNNCwxMC41QTEuNSwxLjUgMCAwLDEgNS41LDEyQTEuNSwxLjUgMCAwLDEgNCwxMy41QTEuNSwxLjUgMCAwLDEgMi41LDEyQTEuNSwxLjUgMCAwLDEgNCwxMC41TTcsMTlWMTdIMjFWMTlIN000LDE2LjVBMS41LDEuNSAwIDAsMSA1LjUsMThBMS41LDEuNSAwIDAsMSA0LDE5LjVBMS41LDEuNSAwIDAsMSAyLjUsMThBMS41LDEuNSAwIDAsMSA0LDE2LjVaIiAvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-tree-view: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik0yMiAxMVYzaC03djNIOVYzSDJ2OGg3VjhoMnYxMGg0djNoN3YtOGgtN3YzaC0yVjhoMnYzeiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-trusted: url(data:image/svg+xml;base64,PHN2ZyBmaWxsPSJub25lIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI1Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDIgMykiIGQ9Ik0xLjg2MDk0IDExLjQ0MDlDMC44MjY0NDggOC43NzAyNyAwLjg2Mzc3OSA2LjA1NzY0IDEuMjQ5MDcgNC4xOTkzMkMyLjQ4MjA2IDMuOTMzNDcgNC4wODA2OCAzLjQwMzQ3IDUuNjAxMDIgMi44NDQ5QzcuMjM1NDkgMi4yNDQ0IDguODU2NjYgMS41ODE1IDkuOTg3NiAxLjA5NTM5QzExLjA1OTcgMS41ODM0MSAxMi42MDk0IDIuMjQ0NCAxNC4yMTggMi44NDMzOUMxNS43NTAzIDMuNDEzOTQgMTcuMzk5NSAzLjk1MjU4IDE4Ljc1MzkgNC4yMTM4NUMxOS4xMzY0IDYuMDcxNzcgMTkuMTcwOSA4Ljc3NzIyIDE4LjEzOSAxMS40NDA5QzE3LjAzMDMgMTQuMzAzMiAxNC42NjY4IDE3LjE4NDQgOS45OTk5OSAxOC45MzU0QzUuMzMzMiAxNy4xODQ0IDIuOTY5NjggMTQuMzAzMiAxLjg2MDk0IDExLjQ0MDlaIi8+CiAgICA8cGF0aCBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiMzMzMzMzMiIHN0cm9rZT0iIzMzMzMzMyIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoOCA5Ljg2NzE5KSIgZD0iTTIuODYwMTUgNC44NjUzNUwwLjcyNjU0OSAyLjk5OTU5TDAgMy42MzA0NUwyLjg2MDE1IDYuMTMxNTdMOCAwLjYzMDg3Mkw3LjI3ODU3IDBMMi44NjAxNSA0Ljg2NTM1WiIvPgo8L3N2Zz4K);
  --jp-icon-undo: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjUgOGMtMi42NSAwLTUuMDUuOTktNi45IDIuNkwyIDd2OWg5bC0zLjYyLTMuNjJjMS4zOS0xLjE2IDMuMTYtMS44OCA1LjEyLTEuODggMy41NCAwIDYuNTUgMi4zMSA3LjYgNS41bDIuMzctLjc4QzIxLjA4IDExLjAzIDE3LjE1IDggMTIuNSA4eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-user: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIHZpZXdCb3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE2IDdhNCA0IDAgMTEtOCAwIDQgNCAwIDAxOCAwek0xMiAxNGE3IDcgMCAwMC03IDdoMTRhNyA3IDAgMDAtNy03eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-users: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjQiIGhlaWdodD0iMjQiIHZlcnNpb249IjEuMSIgdmlld0JveD0iMCAwIDM2IDI0IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPgogPGcgY2xhc3M9ImpwLWljb24zIiB0cmFuc2Zvcm09Im1hdHJpeCgxLjczMjcgMCAwIDEuNzMyNyAtMy42MjgyIC4wOTk1NzcpIiBmaWxsPSIjNjE2MTYxIj4KICA8cGF0aCB0cmFuc2Zvcm09Im1hdHJpeCgxLjUsMCwwLDEuNSwwLC02KSIgZD0ibTEyLjE4NiA3LjUwOThjLTEuMDUzNSAwLTEuOTc1NyAwLjU2NjUtMi40Nzg1IDEuNDEwMiAwLjc1MDYxIDAuMzEyNzcgMS4zOTc0IDAuODI2NDggMS44NzMgMS40NzI3aDMuNDg2M2MwLTEuNTkyLTEuMjg4OS0yLjg4MjgtMi44ODA5LTIuODgyOHoiLz4KICA8cGF0aCBkPSJtMjAuNDY1IDIuMzg5NWEyLjE4ODUgMi4xODg1IDAgMCAxLTIuMTg4NCAyLjE4ODUgMi4xODg1IDIuMTg4NSAwIDAgMS0yLjE4ODUtMi4xODg1IDIuMTg4NSAyLjE4ODUgMCAwIDEgMi4xODg1LTIuMTg4NSAyLjE4ODUgMi4xODg1IDAgMCAxIDIuMTg4NCAyLjE4ODV6Ii8+CiAgPHBhdGggdHJhbnNmb3JtPSJtYXRyaXgoMS41LDAsMCwxLjUsMCwtNikiIGQ9Im0zLjU4OTggOC40MjE5Yy0xLjExMjYgMC0yLjAxMzcgMC45MDExMS0yLjAxMzcgMi4wMTM3aDIuODE0NWMwLjI2Nzk3LTAuMzczMDkgMC41OTA3LTAuNzA0MzUgMC45NTg5OC0wLjk3ODUyLTAuMzQ0MzMtMC42MTY4OC0xLjAwMzEtMS4wMzUyLTEuNzU5OC0xLjAzNTJ6Ii8+CiAgPHBhdGggZD0ibTYuOTE1NCA0LjYyM2ExLjUyOTQgMS41Mjk0IDAgMCAxLTEuNTI5NCAxLjUyOTQgMS41Mjk0IDEuNTI5NCAwIDAgMS0xLjUyOTQtMS41Mjk0IDEuNTI5NCAxLjUyOTQgMCAwIDEgMS41Mjk0LTEuNTI5NCAxLjUyOTQgMS41Mjk0IDAgMCAxIDEuNTI5NCAxLjUyOTR6Ii8+CiAgPHBhdGggZD0ibTYuMTM1IDEzLjUzNWMwLTMuMjM5MiAyLjYyNTktNS44NjUgNS44NjUtNS44NjUgMy4yMzkyIDAgNS44NjUgMi42MjU5IDUuODY1IDUuODY1eiIvPgogIDxjaXJjbGUgY3g9IjEyIiBjeT0iMy43Njg1IiByPSIyLjk2ODUiLz4KIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-vega: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbjEganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMjEyMTIxIj4KICAgIDxwYXRoIGQ9Ik0xMC42IDUuNGwyLjItMy4ySDIuMnY3LjNsNC02LjZ6Ii8+CiAgICA8cGF0aCBkPSJNMTUuOCAyLjJsLTQuNCA2LjZMNyA2LjNsLTQuOCA4djUuNWgxNy42VjIuMmgtNHptLTcgMTUuNEg1LjV2LTQuNGgzLjN2NC40em00LjQgMEg5LjhWOS44aDMuNHY3Ljh6bTQuNCAwaC0zLjRWNi41aDMuNHYxMS4xeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-word: url(data:image/svg+xml;base64,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);
  --jp-icon-yaml: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1jb250cmFzdDIganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjRDgxQjYwIj4KICAgIDxwYXRoIGQ9Ik03LjIgMTguNnYtNS40TDMgNS42aDMuM2wxLjQgMy4xYy4zLjkuNiAxLjYgMSAyLjUuMy0uOC42LTEuNiAxLTIuNWwxLjQtMy4xaDMuNGwtNC40IDcuNnY1LjVsLTIuOS0uMXoiLz4KICAgIDxjaXJjbGUgY2xhc3M9InN0MCIgY3g9IjE3LjYiIGN5PSIxNi41IiByPSIyLjEiLz4KICAgIDxjaXJjbGUgY2xhc3M9InN0MCIgY3g9IjE3LjYiIGN5PSIxMSIgcj0iMi4xIi8+CiAgPC9nPgo8L3N2Zz4K);
}

/* Icon CSS class declarations */

.jp-AddAboveIcon {
  background-image: var(--jp-icon-add-above);
}

.jp-AddBelowIcon {
  background-image: var(--jp-icon-add-below);
}

.jp-AddIcon {
  background-image: var(--jp-icon-add);
}

.jp-BellIcon {
  background-image: var(--jp-icon-bell);
}

.jp-BugDotIcon {
  background-image: var(--jp-icon-bug-dot);
}

.jp-BugIcon {
  background-image: var(--jp-icon-bug);
}

.jp-BuildIcon {
  background-image: var(--jp-icon-build);
}

.jp-CaretDownEmptyIcon {
  background-image: var(--jp-icon-caret-down-empty);
}

.jp-CaretDownEmptyThinIcon {
  background-image: var(--jp-icon-caret-down-empty-thin);
}

.jp-CaretDownIcon {
  background-image: var(--jp-icon-caret-down);
}

.jp-CaretLeftIcon {
  background-image: var(--jp-icon-caret-left);
}

.jp-CaretRightIcon {
  background-image: var(--jp-icon-caret-right);
}

.jp-CaretUpEmptyThinIcon {
  background-image: var(--jp-icon-caret-up-empty-thin);
}

.jp-CaretUpIcon {
  background-image: var(--jp-icon-caret-up);
}

.jp-CaseSensitiveIcon {
  background-image: var(--jp-icon-case-sensitive);
}

.jp-CheckIcon {
  background-image: var(--jp-icon-check);
}

.jp-CircleEmptyIcon {
  background-image: var(--jp-icon-circle-empty);
}

.jp-CircleIcon {
  background-image: var(--jp-icon-circle);
}

.jp-ClearIcon {
  background-image: var(--jp-icon-clear);
}

.jp-CloseIcon {
  background-image: var(--jp-icon-close);
}

.jp-CodeCheckIcon {
  background-image: var(--jp-icon-code-check);
}

.jp-CodeIcon {
  background-image: var(--jp-icon-code);
}

.jp-CollapseAllIcon {
  background-image: var(--jp-icon-collapse-all);
}

.jp-ConsoleIcon {
  background-image: var(--jp-icon-console);
}

.jp-CopyIcon {
  background-image: var(--jp-icon-copy);
}

.jp-CopyrightIcon {
  background-image: var(--jp-icon-copyright);
}

.jp-CutIcon {
  background-image: var(--jp-icon-cut);
}

.jp-DeleteIcon {
  background-image: var(--jp-icon-delete);
}

.jp-DownloadIcon {
  background-image: var(--jp-icon-download);
}

.jp-DuplicateIcon {
  background-image: var(--jp-icon-duplicate);
}

.jp-EditIcon {
  background-image: var(--jp-icon-edit);
}

.jp-EllipsesIcon {
  background-image: var(--jp-icon-ellipses);
}

.jp-ErrorIcon {
  background-image: var(--jp-icon-error);
}

.jp-ExpandAllIcon {
  background-image: var(--jp-icon-expand-all);
}

.jp-ExtensionIcon {
  background-image: var(--jp-icon-extension);
}

.jp-FastForwardIcon {
  background-image: var(--jp-icon-fast-forward);
}

.jp-FileIcon {
  background-image: var(--jp-icon-file);
}

.jp-FileUploadIcon {
  background-image: var(--jp-icon-file-upload);
}

.jp-FilterDotIcon {
  background-image: var(--jp-icon-filter-dot);
}

.jp-FilterIcon {
  background-image: var(--jp-icon-filter);
}

.jp-FilterListIcon {
  background-image: var(--jp-icon-filter-list);
}

.jp-FolderFavoriteIcon {
  background-image: var(--jp-icon-folder-favorite);
}

.jp-FolderIcon {
  background-image: var(--jp-icon-folder);
}

.jp-HomeIcon {
  background-image: var(--jp-icon-home);
}

.jp-Html5Icon {
  background-image: var(--jp-icon-html5);
}

.jp-ImageIcon {
  background-image: var(--jp-icon-image);
}

.jp-InfoIcon {
  background-image: var(--jp-icon-info);
}

.jp-InspectorIcon {
  background-image: var(--jp-icon-inspector);
}

.jp-JsonIcon {
  background-image: var(--jp-icon-json);
}

.jp-JuliaIcon {
  background-image: var(--jp-icon-julia);
}

.jp-JupyterFaviconIcon {
  background-image: var(--jp-icon-jupyter-favicon);
}

.jp-JupyterIcon {
  background-image: var(--jp-icon-jupyter);
}

.jp-JupyterlabWordmarkIcon {
  background-image: var(--jp-icon-jupyterlab-wordmark);
}

.jp-KernelIcon {
  background-image: var(--jp-icon-kernel);
}

.jp-KeyboardIcon {
  background-image: var(--jp-icon-keyboard);
}

.jp-LaunchIcon {
  background-image: var(--jp-icon-launch);
}

.jp-LauncherIcon {
  background-image: var(--jp-icon-launcher);
}

.jp-LineFormIcon {
  background-image: var(--jp-icon-line-form);
}

.jp-LinkIcon {
  background-image: var(--jp-icon-link);
}

.jp-ListIcon {
  background-image: var(--jp-icon-list);
}

.jp-MarkdownIcon {
  background-image: var(--jp-icon-markdown);
}

.jp-MoveDownIcon {
  background-image: var(--jp-icon-move-down);
}

.jp-MoveUpIcon {
  background-image: var(--jp-icon-move-up);
}

.jp-NewFolderIcon {
  background-image: var(--jp-icon-new-folder);
}

.jp-NotTrustedIcon {
  background-image: var(--jp-icon-not-trusted);
}

.jp-NotebookIcon {
  background-image: var(--jp-icon-notebook);
}

.jp-NumberingIcon {
  background-image: var(--jp-icon-numbering);
}

.jp-OfflineBoltIcon {
  background-image: var(--jp-icon-offline-bolt);
}

.jp-PaletteIcon {
  background-image: var(--jp-icon-palette);
}

.jp-PasteIcon {
  background-image: var(--jp-icon-paste);
}

.jp-PdfIcon {
  background-image: var(--jp-icon-pdf);
}

.jp-PythonIcon {
  background-image: var(--jp-icon-python);
}

.jp-RKernelIcon {
  background-image: var(--jp-icon-r-kernel);
}

.jp-ReactIcon {
  background-image: var(--jp-icon-react);
}

.jp-RedoIcon {
  background-image: var(--jp-icon-redo);
}

.jp-RefreshIcon {
  background-image: var(--jp-icon-refresh);
}

.jp-RegexIcon {
  background-image: var(--jp-icon-regex);
}

.jp-RunIcon {
  background-image: var(--jp-icon-run);
}

.jp-RunningIcon {
  background-image: var(--jp-icon-running);
}

.jp-SaveIcon {
  background-image: var(--jp-icon-save);
}

.jp-SearchIcon {
  background-image: var(--jp-icon-search);
}

.jp-SettingsIcon {
  background-image: var(--jp-icon-settings);
}

.jp-ShareIcon {
  background-image: var(--jp-icon-share);
}

.jp-SpreadsheetIcon {
  background-image: var(--jp-icon-spreadsheet);
}

.jp-StopIcon {
  background-image: var(--jp-icon-stop);
}

.jp-TabIcon {
  background-image: var(--jp-icon-tab);
}

.jp-TableRowsIcon {
  background-image: var(--jp-icon-table-rows);
}

.jp-TagIcon {
  background-image: var(--jp-icon-tag);
}

.jp-TerminalIcon {
  background-image: var(--jp-icon-terminal);
}

.jp-TextEditorIcon {
  background-image: var(--jp-icon-text-editor);
}

.jp-TocIcon {
  background-image: var(--jp-icon-toc);
}

.jp-TreeViewIcon {
  background-image: var(--jp-icon-tree-view);
}

.jp-TrustedIcon {
  background-image: var(--jp-icon-trusted);
}

.jp-UndoIcon {
  background-image: var(--jp-icon-undo);
}

.jp-UserIcon {
  background-image: var(--jp-icon-user);
}

.jp-UsersIcon {
  background-image: var(--jp-icon-users);
}

.jp-VegaIcon {
  background-image: var(--jp-icon-vega);
}

.jp-WordIcon {
  background-image: var(--jp-icon-word);
}

.jp-YamlIcon {
  background-image: var(--jp-icon-yaml);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * (DEPRECATED) Support for consuming icons as CSS background images
 */

.jp-Icon,
.jp-MaterialIcon {
  background-position: center;
  background-repeat: no-repeat;
  background-size: 16px;
  min-width: 16px;
  min-height: 16px;
}

.jp-Icon-cover {
  background-position: center;
  background-repeat: no-repeat;
  background-size: cover;
}

/**
 * (DEPRECATED) Support for specific CSS icon sizes
 */

.jp-Icon-16 {
  background-size: 16px;
  min-width: 16px;
  min-height: 16px;
}

.jp-Icon-18 {
  background-size: 18px;
  min-width: 18px;
  min-height: 18px;
}

.jp-Icon-20 {
  background-size: 20px;
  min-width: 20px;
  min-height: 20px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.lm-TabBar .lm-TabBar-addButton {
  align-items: center;
  display: flex;
  padding: 4px;
  padding-bottom: 5px;
  margin-right: 1px;
  background-color: var(--jp-layout-color2);
}

.lm-TabBar .lm-TabBar-addButton:hover {
  background-color: var(--jp-layout-color1);
}

.lm-DockPanel-tabBar .lm-TabBar-tab {
  width: var(--jp-private-horizontal-tab-width);
}

.lm-DockPanel-tabBar .lm-TabBar-content {
  flex: unset;
}

.lm-DockPanel-tabBar[data-orientation='horizontal'] {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * Support for icons as inline SVG HTMLElements
 */

/* recolor the primary elements of an icon */
.jp-icon0[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon1[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon2[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon3[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon4[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon0[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon1[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon2[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon3[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon4[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/* recolor the accent elements of an icon */
.jp-icon-accent0[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-accent1[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-accent2[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-accent3[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-accent4[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-accent0[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-accent1[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-accent2[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-accent3[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-accent4[stroke] {
  stroke: var(--jp-layout-color4);
}

/* set the color of an icon to transparent */
.jp-icon-none[fill] {
  fill: none;
}

.jp-icon-none[stroke] {
  stroke: none;
}

/* brand icon colors. Same for light and dark */
.jp-icon-brand0[fill] {
  fill: var(--jp-brand-color0);
}

.jp-icon-brand1[fill] {
  fill: var(--jp-brand-color1);
}

.jp-icon-brand2[fill] {
  fill: var(--jp-brand-color2);
}

.jp-icon-brand3[fill] {
  fill: var(--jp-brand-color3);
}

.jp-icon-brand4[fill] {
  fill: var(--jp-brand-color4);
}

.jp-icon-brand0[stroke] {
  stroke: var(--jp-brand-color0);
}

.jp-icon-brand1[stroke] {
  stroke: var(--jp-brand-color1);
}

.jp-icon-brand2[stroke] {
  stroke: var(--jp-brand-color2);
}

.jp-icon-brand3[stroke] {
  stroke: var(--jp-brand-color3);
}

.jp-icon-brand4[stroke] {
  stroke: var(--jp-brand-color4);
}

/* warn icon colors. Same for light and dark */
.jp-icon-warn0[fill] {
  fill: var(--jp-warn-color0);
}

.jp-icon-warn1[fill] {
  fill: var(--jp-warn-color1);
}

.jp-icon-warn2[fill] {
  fill: var(--jp-warn-color2);
}

.jp-icon-warn3[fill] {
  fill: var(--jp-warn-color3);
}

.jp-icon-warn0[stroke] {
  stroke: var(--jp-warn-color0);
}

.jp-icon-warn1[stroke] {
  stroke: var(--jp-warn-color1);
}

.jp-icon-warn2[stroke] {
  stroke: var(--jp-warn-color2);
}

.jp-icon-warn3[stroke] {
  stroke: var(--jp-warn-color3);
}

/* icon colors that contrast well with each other and most backgrounds */
.jp-icon-contrast0[fill] {
  fill: var(--jp-icon-contrast-color0);
}

.jp-icon-contrast1[fill] {
  fill: var(--jp-icon-contrast-color1);
}

.jp-icon-contrast2[fill] {
  fill: var(--jp-icon-contrast-color2);
}

.jp-icon-contrast3[fill] {
  fill: var(--jp-icon-contrast-color3);
}

.jp-icon-contrast0[stroke] {
  stroke: var(--jp-icon-contrast-color0);
}

.jp-icon-contrast1[stroke] {
  stroke: var(--jp-icon-contrast-color1);
}

.jp-icon-contrast2[stroke] {
  stroke: var(--jp-icon-contrast-color2);
}

.jp-icon-contrast3[stroke] {
  stroke: var(--jp-icon-contrast-color3);
}

.jp-icon-dot[fill] {
  fill: var(--jp-warn-color0);
}

.jp-jupyter-icon-color[fill] {
  fill: var(--jp-jupyter-icon-color, var(--jp-warn-color0));
}

.jp-notebook-icon-color[fill] {
  fill: var(--jp-notebook-icon-color, var(--jp-warn-color0));
}

.jp-json-icon-color[fill] {
  fill: var(--jp-json-icon-color, var(--jp-warn-color1));
}

.jp-console-icon-color[fill] {
  fill: var(--jp-console-icon-color, white);
}

.jp-console-icon-background-color[fill] {
  fill: var(--jp-console-icon-background-color, var(--jp-brand-color1));
}

.jp-terminal-icon-color[fill] {
  fill: var(--jp-terminal-icon-color, var(--jp-layout-color2));
}

.jp-terminal-icon-background-color[fill] {
  fill: var(
    --jp-terminal-icon-background-color,
    var(--jp-inverse-layout-color2)
  );
}

.jp-text-editor-icon-color[fill] {
  fill: var(--jp-text-editor-icon-color, var(--jp-inverse-layout-color3));
}

.jp-inspector-icon-color[fill] {
  fill: var(--jp-inspector-icon-color, var(--jp-inverse-layout-color3));
}

/* CSS for icons in selected filebrowser listing items */
.jp-DirListing-item.jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}

.jp-DirListing-item.jp-mod-selected .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}

/* stylelint-disable selector-max-class, selector-max-compound-selectors */

/**
* TODO: come up with non css-hack solution for showing the busy icon on top
*  of the close icon
* CSS for complex behavior of close icon of tabs in the main area tabbar
*/
.lm-DockPanel-tabBar
  .lm-TabBar-tab.lm-mod-closable.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon3[fill] {
  fill: none;
}

.lm-DockPanel-tabBar
  .lm-TabBar-tab.lm-mod-closable.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon-busy[fill] {
  fill: var(--jp-inverse-layout-color3);
}

/* stylelint-enable selector-max-class, selector-max-compound-selectors */

/* CSS for icons in status bar */
#jp-main-statusbar .jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}

#jp-main-statusbar .jp-mod-selected .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}

/* special handling for splash icon CSS. While the theme CSS reloads during
   splash, the splash icon can loose theming. To prevent that, we set a
   default for its color variable */
:root {
  --jp-warn-color0: var(--md-orange-700);
}

/* not sure what to do with this one, used in filebrowser listing */
.jp-DragIcon {
  margin-right: 4px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * Support for alt colors for icons as inline SVG HTMLElements
 */

/* alt recolor the primary elements of an icon */
.jp-icon-alt .jp-icon0[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-alt .jp-icon1[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-alt .jp-icon2[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-alt .jp-icon3[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-alt .jp-icon4[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-alt .jp-icon0[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-alt .jp-icon1[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-alt .jp-icon2[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-alt .jp-icon3[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-alt .jp-icon4[stroke] {
  stroke: var(--jp-layout-color4);
}

/* alt recolor the accent elements of an icon */
.jp-icon-alt .jp-icon-accent0[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon-alt .jp-icon-accent1[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon-alt .jp-icon-accent2[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon-alt .jp-icon-accent3[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon-alt .jp-icon-accent4[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-alt .jp-icon-accent0[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon-alt .jp-icon-accent1[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon-alt .jp-icon-accent2[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon-alt .jp-icon-accent3[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon-alt .jp-icon-accent4[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-icon-hoverShow:not(:hover) .jp-icon-hoverShow-content {
  display: none !important;
}

/**
 * Support for hover colors for icons as inline SVG HTMLElements
 */

/**
 * regular colors
 */

/* recolor the primary elements of an icon */
.jp-icon-hover :hover .jp-icon0-hover[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon-hover :hover .jp-icon1-hover[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon-hover :hover .jp-icon2-hover[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon-hover :hover .jp-icon3-hover[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon-hover :hover .jp-icon4-hover[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-hover :hover .jp-icon0-hover[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon-hover :hover .jp-icon1-hover[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon-hover :hover .jp-icon2-hover[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon-hover :hover .jp-icon3-hover[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon-hover :hover .jp-icon4-hover[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/* recolor the accent elements of an icon */
.jp-icon-hover :hover .jp-icon-accent0-hover[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-hover :hover .jp-icon-accent1-hover[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-hover :hover .jp-icon-accent2-hover[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-hover :hover .jp-icon-accent3-hover[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-hover :hover .jp-icon-accent4-hover[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-hover :hover .jp-icon-accent0-hover[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-hover :hover .jp-icon-accent1-hover[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-hover :hover .jp-icon-accent2-hover[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-hover :hover .jp-icon-accent3-hover[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-hover :hover .jp-icon-accent4-hover[stroke] {
  stroke: var(--jp-layout-color4);
}

/* set the color of an icon to transparent */
.jp-icon-hover :hover .jp-icon-none-hover[fill] {
  fill: none;
}

.jp-icon-hover :hover .jp-icon-none-hover[stroke] {
  stroke: none;
}

/**
 * inverse colors
 */

/* inverse recolor the primary elements of an icon */
.jp-icon-hover.jp-icon-alt :hover .jp-icon0-hover[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon1-hover[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon2-hover[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon3-hover[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon4-hover[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon0-hover[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon1-hover[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon2-hover[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon3-hover[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon4-hover[stroke] {
  stroke: var(--jp-layout-color4);
}

/* inverse recolor the accent elements of an icon */
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent0-hover[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent1-hover[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent2-hover[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent3-hover[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent4-hover[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent0-hover[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent1-hover[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent2-hover[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent3-hover[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent4-hover[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-IFrame {
  width: 100%;
  height: 100%;
}

.jp-IFrame > iframe {
  border: none;
}

/*
When drag events occur, `lm-mod-override-cursor` is added to the body.
Because iframes steal all cursor events, the following two rules are necessary
to suppress pointer events while resize drags are occurring. There may be a
better solution to this problem.
*/
body.lm-mod-override-cursor .jp-IFrame {
  position: relative;
}

body.lm-mod-override-cursor .jp-IFrame::before {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-HoverBox {
  position: fixed;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-FormGroup-content fieldset {
  border: none;
  padding: 0;
  min-width: 0;
  width: 100%;
}

/* stylelint-disable selector-max-type */

.jp-FormGroup-content fieldset .jp-inputFieldWrapper input,
.jp-FormGroup-content fieldset .jp-inputFieldWrapper select,
.jp-FormGroup-content fieldset .jp-inputFieldWrapper textarea {
  font-size: var(--jp-content-font-size2);
  border-color: var(--jp-input-border-color);
  border-style: solid;
  border-radius: var(--jp-border-radius);
  border-width: 1px;
  padding: 6px 8px;
  background: none;
  color: var(--jp-ui-font-color0);
  height: inherit;
}

.jp-FormGroup-content fieldset input[type='checkbox'] {
  position: relative;
  top: 2px;
  margin-left: 0;
}

.jp-FormGroup-content button.jp-mod-styled {
  cursor: pointer;
}

.jp-FormGroup-content .checkbox label {
  cursor: pointer;
  font-size: var(--jp-content-font-size1);
}

.jp-FormGroup-content .jp-root > fieldset > legend {
  display: none;
}

.jp-FormGroup-content .jp-root > fieldset > p {
  display: none;
}

/** copy of `input.jp-mod-styled:focus` style */
.jp-FormGroup-content fieldset input:focus,
.jp-FormGroup-content fieldset select:focus {
  -moz-outline-radius: unset;
  outline: var(--jp-border-width) solid var(--md-blue-500);
  outline-offset: -1px;
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-FormGroup-content fieldset input:hover:not(:focus),
.jp-FormGroup-content fieldset select:hover:not(:focus) {
  background-color: var(--jp-border-color2);
}

/* stylelint-enable selector-max-type */

.jp-FormGroup-content .checkbox .field-description {
  /* Disable default description field for checkbox:
   because other widgets do not have description fields,
   we add descriptions to each widget on the field level.
  */
  display: none;
}

.jp-FormGroup-content #root__description {
  display: none;
}

.jp-FormGroup-content .jp-modifiedIndicator {
  width: 5px;
  background-color: var(--jp-brand-color2);
  margin-top: 0;
  margin-left: calc(var(--jp-private-settingeditor-modifier-indent) * -1);
  flex-shrink: 0;
}

.jp-FormGroup-content .jp-modifiedIndicator.jp-errorIndicator {
  background-color: var(--jp-error-color0);
  margin-right: 0.5em;
}

/* RJSF ARRAY style */

.jp-arrayFieldWrapper legend {
  font-size: var(--jp-content-font-size2);
  color: var(--jp-ui-font-color0);
  flex-basis: 100%;
  padding: 4px 0;
  font-weight: var(--jp-content-heading-font-weight);
  border-bottom: 1px solid var(--jp-border-color2);
}

.jp-arrayFieldWrapper .field-description {
  padding: 4px 0;
  white-space: pre-wrap;
}

.jp-arrayFieldWrapper .array-item {
  width: 100%;
  border: 1px solid var(--jp-border-color2);
  border-radius: 4px;
  margin: 4px;
}

.jp-ArrayOperations {
  display: flex;
  margin-left: 8px;
}

.jp-ArrayOperationsButton {
  margin: 2px;
}

.jp-ArrayOperationsButton .jp-icon3[fill] {
  fill: var(--jp-ui-font-color0);
}

button.jp-ArrayOperationsButton.jp-mod-styled:disabled {
  cursor: not-allowed;
  opacity: 0.5;
}

/* RJSF form validation error */

.jp-FormGroup-content .validationErrors {
  color: var(--jp-error-color0);
}

/* Hide panel level error as duplicated the field level error */
.jp-FormGroup-content .panel.errors {
  display: none;
}

/* RJSF normal content (settings-editor) */

.jp-FormGroup-contentNormal {
  display: flex;
  align-items: center;
  flex-wrap: wrap;
}

.jp-FormGroup-contentNormal .jp-FormGroup-contentItem {
  margin-left: 7px;
  color: var(--jp-ui-font-color0);
}

.jp-FormGroup-contentNormal .jp-FormGroup-description {
  flex-basis: 100%;
  padding: 4px 7px;
}

.jp-FormGroup-contentNormal .jp-FormGroup-default {
  flex-basis: 100%;
  padding: 4px 7px;
}

.jp-FormGroup-contentNormal .jp-FormGroup-fieldLabel {
  font-size: var(--jp-content-font-size1);
  font-weight: normal;
  min-width: 120px;
}

.jp-FormGroup-contentNormal fieldset:not(:first-child) {
  margin-left: 7px;
}

.jp-FormGroup-contentNormal .field-array-of-string .array-item {
  /* Display `jp-ArrayOperations` buttons side-by-side with content except
    for small screens where flex-wrap will place them one below the other.
  */
  display: flex;
  align-items: center;
  flex-wrap: wrap;
}

.jp-FormGroup-contentNormal .jp-objectFieldWrapper .form-group {
  padding: 2px 8px 2px var(--jp-private-settingeditor-modifier-indent);
  margin-top: 2px;
}

/* RJSF compact content (metadata-form) */

.jp-FormGroup-content.jp-FormGroup-contentCompact {
  width: 100%;
}

.jp-FormGroup-contentCompact .form-group {
  display: flex;
  padding: 0.5em 0.2em 0.5em 0;
}

.jp-FormGroup-contentCompact
  .jp-FormGroup-compactTitle
  .jp-FormGroup-description {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color2);
}

.jp-FormGroup-contentCompact .jp-FormGroup-fieldLabel {
  padding-bottom: 0.3em;
}

.jp-FormGroup-contentCompact .jp-inputFieldWrapper .form-control {
  width: 100%;
  box-sizing: border-box;
}

.jp-FormGroup-contentCompact .jp-arrayFieldWrapper .jp-FormGroup-compactTitle {
  padding-bottom: 7px;
}

.jp-FormGroup-contentCompact
  .jp-objectFieldWrapper
  .jp-objectFieldWrapper
  .form-group {
  padding: 2px 8px 2px var(--jp-private-settingeditor-modifier-indent);
  margin-top: 2px;
}

.jp-FormGroup-contentCompact ul.error-detail {
  margin-block-start: 0.5em;
  margin-block-end: 0.5em;
  padding-inline-start: 1em;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-SidePanel {
  display: flex;
  flex-direction: column;
  min-width: var(--jp-sidebar-min-width);
  overflow-y: auto;
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);
  font-size: var(--jp-ui-font-size1);
}

.jp-SidePanel-header {
  flex: 0 0 auto;
  display: flex;
  border-bottom: var(--jp-border-width) solid var(--jp-border-color2);
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  letter-spacing: 1px;
  margin: 0;
  padding: 2px;
  text-transform: uppercase;
}

.jp-SidePanel-toolbar {
  flex: 0 0 auto;
}

.jp-SidePanel-content {
  flex: 1 1 auto;
}

.jp-SidePanel-toolbar,
.jp-AccordionPanel-toolbar {
  height: var(--jp-private-toolbar-height);
}

.jp-SidePanel-toolbar.jp-Toolbar-micro {
  display: none;
}

.lm-AccordionPanel .jp-AccordionPanel-title {
  box-sizing: border-box;
  line-height: 25px;
  margin: 0;
  display: flex;
  align-items: center;
  background: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  font-size: var(--jp-ui-font-size0);
}

.jp-AccordionPanel-title {
  cursor: pointer;
  user-select: none;
  -moz-user-select: none;
  -webkit-user-select: none;
  text-transform: uppercase;
}

.lm-AccordionPanel[data-orientation='horizontal'] > .jp-AccordionPanel-title {
  /* Title is rotated for horizontal accordion panel using CSS */
  display: block;
  transform-origin: top left;
  transform: rotate(-90deg) translate(-100%);
}

.jp-AccordionPanel-title .lm-AccordionPanel-titleLabel {
  user-select: none;
  text-overflow: ellipsis;
  white-space: nowrap;
  overflow: hidden;
}

.jp-AccordionPanel-title .lm-AccordionPanel-titleCollapser {
  transform: rotate(-90deg);
  margin: auto 0;
  height: 16px;
}

.jp-AccordionPanel-title.lm-mod-expanded .lm-AccordionPanel-titleCollapser {
  transform: rotate(0deg);
}

.lm-AccordionPanel .jp-AccordionPanel-toolbar {
  background: none;
  box-shadow: none;
  border: none;
  margin-left: auto;
}

.lm-AccordionPanel .lm-SplitPanel-handle:hover {
  background: var(--jp-layout-color3);
}

.jp-text-truncated {
  overflow: hidden;
  text-overflow: ellipsis;
  white-space: nowrap;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Spinner {
  position: absolute;
  display: flex;
  justify-content: center;
  align-items: center;
  z-index: 10;
  left: 0;
  top: 0;
  width: 100%;
  height: 100%;
  background: var(--jp-layout-color0);
  outline: none;
}

.jp-SpinnerContent {
  font-size: 10px;
  margin: 50px auto;
  text-indent: -9999em;
  width: 3em;
  height: 3em;
  border-radius: 50%;
  background: var(--jp-brand-color3);
  background: linear-gradient(
    to right,
    #f37626 10%,
    rgba(255, 255, 255, 0) 42%
  );
  position: relative;
  animation: load3 1s infinite linear, fadeIn 1s;
}

.jp-SpinnerContent::before {
  width: 50%;
  height: 50%;
  background: #f37626;
  border-radius: 100% 0 0;
  position: absolute;
  top: 0;
  left: 0;
  content: '';
}

.jp-SpinnerContent::after {
  background: var(--jp-layout-color0);
  width: 75%;
  height: 75%;
  border-radius: 50%;
  content: '';
  margin: auto;
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  right: 0;
}

@keyframes fadeIn {
  0% {
    opacity: 0;
  }

  100% {
    opacity: 1;
  }
}

@keyframes load3 {
  0% {
    transform: rotate(0deg);
  }

  100% {
    transform: rotate(360deg);
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

button.jp-mod-styled {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  border: none;
  box-sizing: border-box;
  text-align: center;
  line-height: 32px;
  height: 32px;
  padding: 0 12px;
  letter-spacing: 0.8px;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

input.jp-mod-styled {
  background: var(--jp-input-background);
  height: 28px;
  box-sizing: border-box;
  border: var(--jp-border-width) solid var(--jp-border-color1);
  padding-left: 7px;
  padding-right: 7px;
  font-size: var(--jp-ui-font-size2);
  color: var(--jp-ui-font-color0);
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

input[type='checkbox'].jp-mod-styled {
  appearance: checkbox;
  -webkit-appearance: checkbox;
  -moz-appearance: checkbox;
  height: auto;
}

input.jp-mod-styled:focus {
  border: var(--jp-border-width) solid var(--md-blue-500);
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-select-wrapper {
  display: flex;
  position: relative;
  flex-direction: column;
  padding: 1px;
  background-color: var(--jp-layout-color1);
  box-sizing: border-box;
  margin-bottom: 12px;
}

.jp-select-wrapper:not(.multiple) {
  height: 28px;
}

.jp-select-wrapper.jp-mod-focused select.jp-mod-styled {
  border: var(--jp-border-width) solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
  background-color: var(--jp-input-active-background);
}

select.jp-mod-styled:hover {
  cursor: pointer;
  color: var(--jp-ui-font-color0);
  background-color: var(--jp-input-hover-background);
  box-shadow: inset 0 0 1px rgba(0, 0, 0, 0.5);
}

select.jp-mod-styled {
  flex: 1 1 auto;
  width: 100%;
  font-size: var(--jp-ui-font-size2);
  background: var(--jp-input-background);
  color: var(--jp-ui-font-color0);
  padding: 0 25px 0 8px;
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  border-radius: 0;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

select.jp-mod-styled:not([multiple]) {
  height: 32px;
}

select.jp-mod-styled[multiple] {
  max-height: 200px;
  overflow-y: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-switch {
  display: flex;
  align-items: center;
  padding-left: 4px;
  padding-right: 4px;
  font-size: var(--jp-ui-font-size1);
  background-color: transparent;
  color: var(--jp-ui-font-color1);
  border: none;
  height: 20px;
}

.jp-switch:hover {
  background-color: var(--jp-layout-color2);
}

.jp-switch-label {
  margin-right: 5px;
  font-family: var(--jp-ui-font-family);
}

.jp-switch-track {
  cursor: pointer;
  background-color: var(--jp-switch-color, var(--jp-border-color1));
  -webkit-transition: 0.4s;
  transition: 0.4s;
  border-radius: 34px;
  height: 16px;
  width: 35px;
  position: relative;
}

.jp-switch-track::before {
  content: '';
  position: absolute;
  height: 10px;
  width: 10px;
  margin: 3px;
  left: 0;
  background-color: var(--jp-ui-inverse-font-color1);
  -webkit-transition: 0.4s;
  transition: 0.4s;
  border-radius: 50%;
}

.jp-switch[aria-checked='true'] .jp-switch-track {
  background-color: var(--jp-switch-true-position-color, var(--jp-warn-color0));
}

.jp-switch[aria-checked='true'] .jp-switch-track::before {
  /* track width (35) - margins (3 + 3) - thumb width (10) */
  left: 19px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

:root {
  --jp-private-toolbar-height: calc(
    28px + var(--jp-border-width)
  ); /* leave 28px for content */
}

.jp-Toolbar {
  color: var(--jp-ui-font-color1);
  flex: 0 0 auto;
  display: flex;
  flex-direction: row;
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  background: var(--jp-toolbar-background);
  min-height: var(--jp-toolbar-micro-height);
  padding: 2px;
  z-index: 8;
  overflow-x: hidden;
}

/* Toolbar items */

.jp-Toolbar > .jp-Toolbar-item.jp-Toolbar-spacer {
  flex-grow: 1;
  flex-shrink: 1;
}

.jp-Toolbar-item.jp-Toolbar-kernelStatus {
  display: inline-block;
  width: 32px;
  background-repeat: no-repeat;
  background-position: center;
  background-size: 16px;
}

.jp-Toolbar > .jp-Toolbar-item {
  flex: 0 0 auto;
  display: flex;
  padding-left: 1px;
  padding-right: 1px;
  font-size: var(--jp-ui-font-size1);
  line-height: var(--jp-private-toolbar-height);
  height: 100%;
}

/* Toolbar buttons */

/* This is the div we use to wrap the react component into a Widget */
div.jp-ToolbarButton {
  color: transparent;
  border: none;
  box-sizing: border-box;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
  padding: 0;
  margin: 0;
}

button.jp-ToolbarButtonComponent {
  background: var(--jp-layout-color1);
  border: none;
  box-sizing: border-box;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
  padding: 0 6px;
  margin: 0;
  height: 24px;
  border-radius: var(--jp-border-radius);
  display: flex;
  align-items: center;
  text-align: center;
  font-size: 14px;
  min-width: unset;
  min-height: unset;
}

button.jp-ToolbarButtonComponent:disabled {
  opacity: 0.4;
}

button.jp-ToolbarButtonComponent > span {
  padding: 0;
  flex: 0 0 auto;
}

button.jp-ToolbarButtonComponent .jp-ToolbarButtonComponent-label {
  font-size: var(--jp-ui-font-size1);
  line-height: 100%;
  padding-left: 2px;
  color: var(--jp-ui-font-color1);
  font-family: var(--jp-ui-font-family);
}

#jp-main-dock-panel[data-mode='single-document']
  .jp-MainAreaWidget
  > .jp-Toolbar.jp-Toolbar-micro {
  padding: 0;
  min-height: 0;
}

#jp-main-dock-panel[data-mode='single-document']
  .jp-MainAreaWidget
  > .jp-Toolbar {
  border: none;
  box-shadow: none;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-WindowedPanel-outer {
  position: relative;
  overflow-y: auto;
}

.jp-WindowedPanel-inner {
  position: relative;
}

.jp-WindowedPanel-window {
  position: absolute;
  left: 0;
  right: 0;
  overflow: visible;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* Sibling imports */

body {
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
}

/* Disable native link decoration styles everywhere outside of dialog boxes */
a {
  text-decoration: unset;
  color: unset;
}

a:hover {
  text-decoration: unset;
  color: unset;
}

/* Accessibility for links inside dialog box text */
.jp-Dialog-content a {
  text-decoration: revert;
  color: var(--jp-content-link-color);
}

.jp-Dialog-content a:hover {
  text-decoration: revert;
}

/* Styles for ui-components */
.jp-Button {
  color: var(--jp-ui-font-color2);
  border-radius: var(--jp-border-radius);
  padding: 0 12px;
  font-size: var(--jp-ui-font-size1);

  /* Copy from blueprint 3 */
  display: inline-flex;
  flex-direction: row;
  border: none;
  cursor: pointer;
  align-items: center;
  justify-content: center;
  text-align: left;
  vertical-align: middle;
  min-height: 30px;
  min-width: 30px;
}

.jp-Button:disabled {
  cursor: not-allowed;
}

.jp-Button:empty {
  padding: 0 !important;
}

.jp-Button.jp-mod-small {
  min-height: 24px;
  min-width: 24px;
  font-size: 12px;
  padding: 0 7px;
}

/* Use our own theme for hover styles */
.jp-Button.jp-mod-minimal:hover {
  background-color: var(--jp-layout-color2);
}

.jp-Button.jp-mod-minimal {
  background: none;
}

.jp-InputGroup {
  display: block;
  position: relative;
}

.jp-InputGroup input {
  box-sizing: border-box;
  border: none;
  border-radius: 0;
  background-color: transparent;
  color: var(--jp-ui-font-color0);
  box-shadow: inset 0 0 0 var(--jp-border-width) var(--jp-input-border-color);
  padding-bottom: 0;
  padding-top: 0;
  padding-left: 10px;
  padding-right: 28px;
  position: relative;
  width: 100%;
  -webkit-appearance: none;
  -moz-appearance: none;
  appearance: none;
  font-size: 14px;
  font-weight: 400;
  height: 30px;
  line-height: 30px;
  outline: none;
  vertical-align: middle;
}

.jp-InputGroup input:focus {
  box-shadow: inset 0 0 0 var(--jp-border-width)
      var(--jp-input-active-box-shadow-color),
    inset 0 0 0 3px var(--jp-input-active-box-shadow-color);
}

.jp-InputGroup input:disabled {
  cursor: not-allowed;
  resize: block;
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color2);
}

.jp-InputGroup input:disabled ~ span {
  cursor: not-allowed;
  color: var(--jp-ui-font-color2);
}

.jp-InputGroup input::placeholder,
input::placeholder {
  color: var(--jp-ui-font-color2);
}

.jp-InputGroupAction {
  position: absolute;
  bottom: 1px;
  right: 0;
  padding: 6px;
}

.jp-HTMLSelect.jp-DefaultStyle select {
  background-color: initial;
  border: none;
  border-radius: 0;
  box-shadow: none;
  color: var(--jp-ui-font-color0);
  display: block;
  font-size: var(--jp-ui-font-size1);
  font-family: var(--jp-ui-font-family);
  height: 24px;
  line-height: 14px;
  padding: 0 25px 0 10px;
  text-align: left;
  -moz-appearance: none;
  -webkit-appearance: none;
}

.jp-HTMLSelect.jp-DefaultStyle select:disabled {
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color2);
  cursor: not-allowed;
  resize: block;
}

.jp-HTMLSelect.jp-DefaultStyle select:disabled ~ span {
  cursor: not-allowed;
}

/* Use our own theme for hover and option styles */
/* stylelint-disable-next-line selector-max-type */
.jp-HTMLSelect.jp-DefaultStyle select:hover,
.jp-HTMLSelect.jp-DefaultStyle select > option {
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color0);
}

select {
  box-sizing: border-box;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-StatusBar-Widget {
  display: flex;
  align-items: center;
  background: var(--jp-layout-color2);
  min-height: var(--jp-statusbar-height);
  justify-content: space-between;
  padding: 0 10px;
}

.jp-StatusBar-Left {
  display: flex;
  align-items: center;
  flex-direction: row;
}

.jp-StatusBar-Middle {
  display: flex;
  align-items: center;
}

.jp-StatusBar-Right {
  display: flex;
  align-items: center;
  flex-direction: row-reverse;
}

.jp-StatusBar-Item {
  max-height: var(--jp-statusbar-height);
  margin: 0 2px;
  height: var(--jp-statusbar-height);
  white-space: nowrap;
  text-overflow: ellipsis;
  color: var(--jp-ui-font-color1);
  padding: 0 6px;
}

.jp-mod-highlighted:hover {
  background-color: var(--jp-layout-color3);
}

.jp-mod-clicked {
  background-color: var(--jp-brand-color1);
}

.jp-mod-clicked:hover {
  background-color: var(--jp-brand-color0);
}

.jp-mod-clicked .jp-StatusBar-TextItem {
  color: var(--jp-ui-inverse-font-color1);
}

.jp-StatusBar-HoverItem {
  box-shadow: '0px 4px 4px rgba(0, 0, 0, 0.25)';
}

.jp-StatusBar-TextItem {
  font-size: var(--jp-ui-font-size1);
  font-family: var(--jp-ui-font-family);
  line-height: 24px;
  color: var(--jp-ui-font-color1);
}

.jp-StatusBar-GroupItem {
  display: flex;
  align-items: center;
  flex-direction: row;
}

.jp-Statusbar-ProgressCircle svg {
  display: block;
  margin: 0 auto;
  width: 16px;
  height: 24px;
  align-self: normal;
}

.jp-Statusbar-ProgressCircle path {
  fill: var(--jp-inverse-layout-color3);
}

.jp-Statusbar-ProgressBar-progress-bar {
  height: 10px;
  width: 100px;
  border: solid 0.25px var(--jp-brand-color2);
  border-radius: 3px;
  overflow: hidden;
  align-self: center;
}

.jp-Statusbar-ProgressBar-progress-bar > div {
  background-color: var(--jp-brand-color2);
  background-image: linear-gradient(
    -45deg,
    rgba(255, 255, 255, 0.2) 25%,
    transparent 25%,
    transparent 50%,
    rgba(255, 255, 255, 0.2) 50%,
    rgba(255, 255, 255, 0.2) 75%,
    transparent 75%,
    transparent
  );
  background-size: 40px 40px;
  float: left;
  width: 0%;
  height: 100%;
  font-size: 12px;
  line-height: 14px;
  color: #fff;
  text-align: center;
  animation: jp-Statusbar-ExecutionTime-progress-bar 2s linear infinite;
}

.jp-Statusbar-ProgressBar-progress-bar p {
  color: var(--jp-ui-font-color1);
  font-family: var(--jp-ui-font-family);
  font-size: var(--jp-ui-font-size1);
  line-height: 10px;
  width: 100px;
}

@keyframes jp-Statusbar-ExecutionTime-progress-bar {
  0% {
    background-position: 0 0;
  }

  100% {
    background-position: 40px 40px;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-commandpalette-search-height: 28px;
}

/*-----------------------------------------------------------------------------
| Overall styles
|----------------------------------------------------------------------------*/

.lm-CommandPalette {
  padding-bottom: 0;
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);

  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
}

/*-----------------------------------------------------------------------------
| Modal variant
|----------------------------------------------------------------------------*/

.jp-ModalCommandPalette {
  position: absolute;
  z-index: 10000;
  top: 38px;
  left: 30%;
  margin: 0;
  padding: 4px;
  width: 40%;
  box-shadow: var(--jp-elevation-z4);
  border-radius: 4px;
  background: var(--jp-layout-color0);
}

.jp-ModalCommandPalette .lm-CommandPalette {
  max-height: 40vh;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-close-icon::after {
  display: none;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-CommandPalette-header {
  display: none;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-CommandPalette-item {
  margin-left: 4px;
  margin-right: 4px;
}

.jp-ModalCommandPalette
  .lm-CommandPalette
  .lm-CommandPalette-item.lm-mod-disabled {
  display: none;
}

/*-----------------------------------------------------------------------------
| Search
|----------------------------------------------------------------------------*/

.lm-CommandPalette-search {
  padding: 4px;
  background-color: var(--jp-layout-color1);
  z-index: 2;
}

.lm-CommandPalette-wrapper {
  overflow: overlay;
  padding: 0 9px;
  background-color: var(--jp-input-active-background);
  height: 30px;
  box-shadow: inset 0 0 0 var(--jp-border-width) var(--jp-input-border-color);
}

.lm-CommandPalette.lm-mod-focused .lm-CommandPalette-wrapper {
  box-shadow: inset 0 0 0 1px var(--jp-input-active-box-shadow-color),
    inset 0 0 0 3px var(--jp-input-active-box-shadow-color);
}

.jp-SearchIconGroup {
  color: white;
  background-color: var(--jp-brand-color1);
  position: absolute;
  top: 4px;
  right: 4px;
  padding: 5px 5px 1px;
}

.jp-SearchIconGroup svg {
  height: 20px;
  width: 20px;
}

.jp-SearchIconGroup .jp-icon3[fill] {
  fill: var(--jp-layout-color0);
}

.lm-CommandPalette-input {
  background: transparent;
  width: calc(100% - 18px);
  float: left;
  border: none;
  outline: none;
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  line-height: var(--jp-private-commandpalette-search-height);
}

.lm-CommandPalette-input::-webkit-input-placeholder,
.lm-CommandPalette-input::-moz-placeholder,
.lm-CommandPalette-input:-ms-input-placeholder {
  color: var(--jp-ui-font-color2);
  font-size: var(--jp-ui-font-size1);
}

/*-----------------------------------------------------------------------------
| Results
|----------------------------------------------------------------------------*/

.lm-CommandPalette-header:first-child {
  margin-top: 0;
}

.lm-CommandPalette-header {
  border-bottom: solid var(--jp-border-width) var(--jp-border-color2);
  color: var(--jp-ui-font-color1);
  cursor: pointer;
  display: flex;
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  letter-spacing: 1px;
  margin-top: 8px;
  padding: 8px 0 8px 12px;
  text-transform: uppercase;
}

.lm-CommandPalette-header.lm-mod-active {
  background: var(--jp-layout-color2);
}

.lm-CommandPalette-header > mark {
  background-color: transparent;
  font-weight: bold;
  color: var(--jp-ui-font-color1);
}

.lm-CommandPalette-item {
  padding: 4px 12px 4px 4px;
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  font-weight: 400;
  display: flex;
}

.lm-CommandPalette-item.lm-mod-disabled {
  color: var(--jp-ui-font-color2);
}

.lm-CommandPalette-item.lm-mod-active {
  color: var(--jp-ui-inverse-font-color1);
  background: var(--jp-brand-color1);
}

.lm-CommandPalette-item.lm-mod-active .lm-CommandPalette-itemLabel > mark {
  color: var(--jp-ui-inverse-font-color0);
}

.lm-CommandPalette-item.lm-mod-active .jp-icon-selectable[fill] {
  fill: var(--jp-layout-color0);
}

.lm-CommandPalette-item.lm-mod-active:hover:not(.lm-mod-disabled) {
  color: var(--jp-ui-inverse-font-color1);
  background: var(--jp-brand-color1);
}

.lm-CommandPalette-item:hover:not(.lm-mod-active):not(.lm-mod-disabled) {
  background: var(--jp-layout-color2);
}

.lm-CommandPalette-itemContent {
  overflow: hidden;
}

.lm-CommandPalette-itemLabel > mark {
  color: var(--jp-ui-font-color0);
  background-color: transparent;
  font-weight: bold;
}

.lm-CommandPalette-item.lm-mod-disabled mark {
  color: var(--jp-ui-font-color2);
}

.lm-CommandPalette-item .lm-CommandPalette-itemIcon {
  margin: 0 4px 0 0;
  position: relative;
  width: 16px;
  top: 2px;
  flex: 0 0 auto;
}

.lm-CommandPalette-item.lm-mod-disabled .lm-CommandPalette-itemIcon {
  opacity: 0.6;
}

.lm-CommandPalette-item .lm-CommandPalette-itemShortcut {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemCaption {
  display: none;
}

.lm-CommandPalette-content {
  background-color: var(--jp-layout-color1);
}

.lm-CommandPalette-content:empty::after {
  content: 'No results';
  margin: auto;
  margin-top: 20px;
  width: 100px;
  display: block;
  font-size: var(--jp-ui-font-size2);
  font-family: var(--jp-ui-font-family);
  font-weight: lighter;
}

.lm-CommandPalette-emptyMessage {
  text-align: center;
  margin-top: 24px;
  line-height: 1.32;
  padding: 0 8px;
  color: var(--jp-content-font-color3);
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Dialog {
  position: absolute;
  z-index: 10000;
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  top: 0;
  left: 0;
  margin: 0;
  padding: 0;
  width: 100%;
  height: 100%;
  background: var(--jp-dialog-background);
}

.jp-Dialog-content {
  display: flex;
  flex-direction: column;
  margin-left: auto;
  margin-right: auto;
  background: var(--jp-layout-color1);
  padding: 24px 24px 12px;
  min-width: 300px;
  min-height: 150px;
  max-width: 1000px;
  max-height: 500px;
  box-sizing: border-box;
  box-shadow: var(--jp-elevation-z20);
  word-wrap: break-word;
  border-radius: var(--jp-border-radius);

  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color1);
  resize: both;
}

.jp-Dialog-content.jp-Dialog-content-small {
  max-width: 500px;
}

.jp-Dialog-button {
  overflow: visible;
}

button.jp-Dialog-button:focus {
  outline: 1px solid var(--jp-brand-color1);
  outline-offset: 4px;
  -moz-outline-radius: 0;
}

button.jp-Dialog-button:focus::-moz-focus-inner {
  border: 0;
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-accept:focus,
button.jp-Dialog-button.jp-mod-styled.jp-mod-warn:focus,
button.jp-Dialog-button.jp-mod-styled.jp-mod-reject:focus {
  outline-offset: 4px;
  -moz-outline-radius: 0;
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-accept:focus {
  outline: 1px solid var(--jp-accept-color-normal, var(--jp-brand-color1));
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-warn:focus {
  outline: 1px solid var(--jp-warn-color-normal, var(--jp-error-color1));
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-reject:focus {
  outline: 1px solid var(--jp-reject-color-normal, var(--md-grey-600));
}

button.jp-Dialog-close-button {
  padding: 0;
  height: 100%;
  min-width: unset;
  min-height: unset;
}

.jp-Dialog-header {
  display: flex;
  justify-content: space-between;
  flex: 0 0 auto;
  padding-bottom: 12px;
  font-size: var(--jp-ui-font-size3);
  font-weight: 400;
  color: var(--jp-ui-font-color1);
}

.jp-Dialog-body {
  display: flex;
  flex-direction: column;
  flex: 1 1 auto;
  font-size: var(--jp-ui-font-size1);
  background: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  overflow: auto;
}

.jp-Dialog-footer {
  display: flex;
  flex-direction: row;
  justify-content: flex-end;
  align-items: center;
  flex: 0 0 auto;
  margin-left: -12px;
  margin-right: -12px;
  padding: 12px;
}

.jp-Dialog-checkbox {
  padding-right: 5px;
}

.jp-Dialog-checkbox > input:focus-visible {
  outline: 1px solid var(--jp-input-active-border-color);
  outline-offset: 1px;
}

.jp-Dialog-spacer {
  flex: 1 1 auto;
}

.jp-Dialog-title {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.jp-Dialog-body > .jp-select-wrapper {
  width: 100%;
}

.jp-Dialog-body > button {
  padding: 0 16px;
}

.jp-Dialog-body > label {
  line-height: 1.4;
  color: var(--jp-ui-font-color0);
}

.jp-Dialog-button.jp-mod-styled:not(:last-child) {
  margin-right: 12px;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-Input-Boolean-Dialog {
  flex-direction: row-reverse;
  align-items: end;
  width: 100%;
}

.jp-Input-Boolean-Dialog > label {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-MainAreaWidget > :focus {
  outline: none;
}

.jp-MainAreaWidget .jp-MainAreaWidget-error {
  padding: 6px;
}

.jp-MainAreaWidget .jp-MainAreaWidget-error > pre {
  width: auto;
  padding: 10px;
  background: var(--jp-error-color3);
  border: var(--jp-border-width) solid var(--jp-error-color1);
  border-radius: var(--jp-border-radius);
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  white-space: pre-wrap;
  word-wrap: break-word;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/**
 * google-material-color v1.2.6
 * https://github.com/danlevan/google-material-color
 */
:root {
  --md-red-50: #ffebee;
  --md-red-100: #ffcdd2;
  --md-red-200: #ef9a9a;
  --md-red-300: #e57373;
  --md-red-400: #ef5350;
  --md-red-500: #f44336;
  --md-red-600: #e53935;
  --md-red-700: #d32f2f;
  --md-red-800: #c62828;
  --md-red-900: #b71c1c;
  --md-red-A100: #ff8a80;
  --md-red-A200: #ff5252;
  --md-red-A400: #ff1744;
  --md-red-A700: #d50000;
  --md-pink-50: #fce4ec;
  --md-pink-100: #f8bbd0;
  --md-pink-200: #f48fb1;
  --md-pink-300: #f06292;
  --md-pink-400: #ec407a;
  --md-pink-500: #e91e63;
  --md-pink-600: #d81b60;
  --md-pink-700: #c2185b;
  --md-pink-800: #ad1457;
  --md-pink-900: #880e4f;
  --md-pink-A100: #ff80ab;
  --md-pink-A200: #ff4081;
  --md-pink-A400: #f50057;
  --md-pink-A700: #c51162;
  --md-purple-50: #f3e5f5;
  --md-purple-100: #e1bee7;
  --md-purple-200: #ce93d8;
  --md-purple-300: #ba68c8;
  --md-purple-400: #ab47bc;
  --md-purple-500: #9c27b0;
  --md-purple-600: #8e24aa;
  --md-purple-700: #7b1fa2;
  --md-purple-800: #6a1b9a;
  --md-purple-900: #4a148c;
  --md-purple-A100: #ea80fc;
  --md-purple-A200: #e040fb;
  --md-purple-A400: #d500f9;
  --md-purple-A700: #a0f;
  --md-deep-purple-50: #ede7f6;
  --md-deep-purple-100: #d1c4e9;
  --md-deep-purple-200: #b39ddb;
  --md-deep-purple-300: #9575cd;
  --md-deep-purple-400: #7e57c2;
  --md-deep-purple-500: #673ab7;
  --md-deep-purple-600: #5e35b1;
  --md-deep-purple-700: #512da8;
  --md-deep-purple-800: #4527a0;
  --md-deep-purple-900: #311b92;
  --md-deep-purple-A100: #b388ff;
  --md-deep-purple-A200: #7c4dff;
  --md-deep-purple-A400: #651fff;
  --md-deep-purple-A700: #6200ea;
  --md-indigo-50: #e8eaf6;
  --md-indigo-100: #c5cae9;
  --md-indigo-200: #9fa8da;
  --md-indigo-300: #7986cb;
  --md-indigo-400: #5c6bc0;
  --md-indigo-500: #3f51b5;
  --md-indigo-600: #3949ab;
  --md-indigo-700: #303f9f;
  --md-indigo-800: #283593;
  --md-indigo-900: #1a237e;
  --md-indigo-A100: #8c9eff;
  --md-indigo-A200: #536dfe;
  --md-indigo-A400: #3d5afe;
  --md-indigo-A700: #304ffe;
  --md-blue-50: #e3f2fd;
  --md-blue-100: #bbdefb;
  --md-blue-200: #90caf9;
  --md-blue-300: #64b5f6;
  --md-blue-400: #42a5f5;
  --md-blue-500: #2196f3;
  --md-blue-600: #1e88e5;
  --md-blue-700: #1976d2;
  --md-blue-800: #1565c0;
  --md-blue-900: #0d47a1;
  --md-blue-A100: #82b1ff;
  --md-blue-A200: #448aff;
  --md-blue-A400: #2979ff;
  --md-blue-A700: #2962ff;
  --md-light-blue-50: #e1f5fe;
  --md-light-blue-100: #b3e5fc;
  --md-light-blue-200: #81d4fa;
  --md-light-blue-300: #4fc3f7;
  --md-light-blue-400: #29b6f6;
  --md-light-blue-500: #03a9f4;
  --md-light-blue-600: #039be5;
  --md-light-blue-700: #0288d1;
  --md-light-blue-800: #0277bd;
  --md-light-blue-900: #01579b;
  --md-light-blue-A100: #80d8ff;
  --md-light-blue-A200: #40c4ff;
  --md-light-blue-A400: #00b0ff;
  --md-light-blue-A700: #0091ea;
  --md-cyan-50: #e0f7fa;
  --md-cyan-100: #b2ebf2;
  --md-cyan-200: #80deea;
  --md-cyan-300: #4dd0e1;
  --md-cyan-400: #26c6da;
  --md-cyan-500: #00bcd4;
  --md-cyan-600: #00acc1;
  --md-cyan-700: #0097a7;
  --md-cyan-800: #00838f;
  --md-cyan-900: #006064;
  --md-cyan-A100: #84ffff;
  --md-cyan-A200: #18ffff;
  --md-cyan-A400: #00e5ff;
  --md-cyan-A700: #00b8d4;
  --md-teal-50: #e0f2f1;
  --md-teal-100: #b2dfdb;
  --md-teal-200: #80cbc4;
  --md-teal-300: #4db6ac;
  --md-teal-400: #26a69a;
  --md-teal-500: #009688;
  --md-teal-600: #00897b;
  --md-teal-700: #00796b;
  --md-teal-800: #00695c;
  --md-teal-900: #004d40;
  --md-teal-A100: #a7ffeb;
  --md-teal-A200: #64ffda;
  --md-teal-A400: #1de9b6;
  --md-teal-A700: #00bfa5;
  --md-green-50: #e8f5e9;
  --md-green-100: #c8e6c9;
  --md-green-200: #a5d6a7;
  --md-green-300: #81c784;
  --md-green-400: #66bb6a;
  --md-green-500: #4caf50;
  --md-green-600: #43a047;
  --md-green-700: #388e3c;
  --md-green-800: #2e7d32;
  --md-green-900: #1b5e20;
  --md-green-A100: #b9f6ca;
  --md-green-A200: #69f0ae;
  --md-green-A400: #00e676;
  --md-green-A700: #00c853;
  --md-light-green-50: #f1f8e9;
  --md-light-green-100: #dcedc8;
  --md-light-green-200: #c5e1a5;
  --md-light-green-300: #aed581;
  --md-light-green-400: #9ccc65;
  --md-light-green-500: #8bc34a;
  --md-light-green-600: #7cb342;
  --md-light-green-700: #689f38;
  --md-light-green-800: #558b2f;
  --md-light-green-900: #33691e;
  --md-light-green-A100: #ccff90;
  --md-light-green-A200: #b2ff59;
  --md-light-green-A400: #76ff03;
  --md-light-green-A700: #64dd17;
  --md-lime-50: #f9fbe7;
  --md-lime-100: #f0f4c3;
  --md-lime-200: #e6ee9c;
  --md-lime-300: #dce775;
  --md-lime-400: #d4e157;
  --md-lime-500: #cddc39;
  --md-lime-600: #c0ca33;
  --md-lime-700: #afb42b;
  --md-lime-800: #9e9d24;
  --md-lime-900: #827717;
  --md-lime-A100: #f4ff81;
  --md-lime-A200: #eeff41;
  --md-lime-A400: #c6ff00;
  --md-lime-A700: #aeea00;
  --md-yellow-50: #fffde7;
  --md-yellow-100: #fff9c4;
  --md-yellow-200: #fff59d;
  --md-yellow-300: #fff176;
  --md-yellow-400: #ffee58;
  --md-yellow-500: #ffeb3b;
  --md-yellow-600: #fdd835;
  --md-yellow-700: #fbc02d;
  --md-yellow-800: #f9a825;
  --md-yellow-900: #f57f17;
  --md-yellow-A100: #ffff8d;
  --md-yellow-A200: #ff0;
  --md-yellow-A400: #ffea00;
  --md-yellow-A700: #ffd600;
  --md-amber-50: #fff8e1;
  --md-amber-100: #ffecb3;
  --md-amber-200: #ffe082;
  --md-amber-300: #ffd54f;
  --md-amber-400: #ffca28;
  --md-amber-500: #ffc107;
  --md-amber-600: #ffb300;
  --md-amber-700: #ffa000;
  --md-amber-800: #ff8f00;
  --md-amber-900: #ff6f00;
  --md-amber-A100: #ffe57f;
  --md-amber-A200: #ffd740;
  --md-amber-A400: #ffc400;
  --md-amber-A700: #ffab00;
  --md-orange-50: #fff3e0;
  --md-orange-100: #ffe0b2;
  --md-orange-200: #ffcc80;
  --md-orange-300: #ffb74d;
  --md-orange-400: #ffa726;
  --md-orange-500: #ff9800;
  --md-orange-600: #fb8c00;
  --md-orange-700: #f57c00;
  --md-orange-800: #ef6c00;
  --md-orange-900: #e65100;
  --md-orange-A100: #ffd180;
  --md-orange-A200: #ffab40;
  --md-orange-A400: #ff9100;
  --md-orange-A700: #ff6d00;
  --md-deep-orange-50: #fbe9e7;
  --md-deep-orange-100: #ffccbc;
  --md-deep-orange-200: #ffab91;
  --md-deep-orange-300: #ff8a65;
  --md-deep-orange-400: #ff7043;
  --md-deep-orange-500: #ff5722;
  --md-deep-orange-600: #f4511e;
  --md-deep-orange-700: #e64a19;
  --md-deep-orange-800: #d84315;
  --md-deep-orange-900: #bf360c;
  --md-deep-orange-A100: #ff9e80;
  --md-deep-orange-A200: #ff6e40;
  --md-deep-orange-A400: #ff3d00;
  --md-deep-orange-A700: #dd2c00;
  --md-brown-50: #efebe9;
  --md-brown-100: #d7ccc8;
  --md-brown-200: #bcaaa4;
  --md-brown-300: #a1887f;
  --md-brown-400: #8d6e63;
  --md-brown-500: #795548;
  --md-brown-600: #6d4c41;
  --md-brown-700: #5d4037;
  --md-brown-800: #4e342e;
  --md-brown-900: #3e2723;
  --md-grey-50: #fafafa;
  --md-grey-100: #f5f5f5;
  --md-grey-200: #eee;
  --md-grey-300: #e0e0e0;
  --md-grey-400: #bdbdbd;
  --md-grey-500: #9e9e9e;
  --md-grey-600: #757575;
  --md-grey-700: #616161;
  --md-grey-800: #424242;
  --md-grey-900: #212121;
  --md-blue-grey-50: #eceff1;
  --md-blue-grey-100: #cfd8dc;
  --md-blue-grey-200: #b0bec5;
  --md-blue-grey-300: #90a4ae;
  --md-blue-grey-400: #78909c;
  --md-blue-grey-500: #607d8b;
  --md-blue-grey-600: #546e7a;
  --md-blue-grey-700: #455a64;
  --md-blue-grey-800: #37474f;
  --md-blue-grey-900: #263238;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| RenderedText
|----------------------------------------------------------------------------*/

:root {
  /* This is the padding value to fill the gaps between lines containing spans with background color. */
  --jp-private-code-span-padding: calc(
    (var(--jp-code-line-height) - 1) * var(--jp-code-font-size) / 2
  );
}

.jp-RenderedText {
  text-align: left;
  padding-left: var(--jp-code-padding);
  line-height: var(--jp-code-line-height);
  font-family: var(--jp-code-font-family);
}

.jp-RenderedText pre,
.jp-RenderedJavaScript pre,
.jp-RenderedHTMLCommon pre {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-code-font-size);
  border: none;
  margin: 0;
  padding: 0;
}

.jp-RenderedText pre a:link {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

.jp-RenderedText pre a:hover {
  text-decoration: underline;
  color: var(--jp-content-link-color);
}

.jp-RenderedText pre a:visited {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

/* console foregrounds and backgrounds */
.jp-RenderedText pre .ansi-black-fg {
  color: #3e424d;
}

.jp-RenderedText pre .ansi-red-fg {
  color: #e75c58;
}

.jp-RenderedText pre .ansi-green-fg {
  color: #00a250;
}

.jp-RenderedText pre .ansi-yellow-fg {
  color: #ddb62b;
}

.jp-RenderedText pre .ansi-blue-fg {
  color: #208ffb;
}

.jp-RenderedText pre .ansi-magenta-fg {
  color: #d160c4;
}

.jp-RenderedText pre .ansi-cyan-fg {
  color: #60c6c8;
}

.jp-RenderedText pre .ansi-white-fg {
  color: #c5c1b4;
}

.jp-RenderedText pre .ansi-black-bg {
  background-color: #3e424d;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-red-bg {
  background-color: #e75c58;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-green-bg {
  background-color: #00a250;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-yellow-bg {
  background-color: #ddb62b;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-blue-bg {
  background-color: #208ffb;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-magenta-bg {
  background-color: #d160c4;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-cyan-bg {
  background-color: #60c6c8;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-white-bg {
  background-color: #c5c1b4;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-black-intense-fg {
  color: #282c36;
}

.jp-RenderedText pre .ansi-red-intense-fg {
  color: #b22b31;
}

.jp-RenderedText pre .ansi-green-intense-fg {
  color: #007427;
}

.jp-RenderedText pre .ansi-yellow-intense-fg {
  color: #b27d12;
}

.jp-RenderedText pre .ansi-blue-intense-fg {
  color: #0065ca;
}

.jp-RenderedText pre .ansi-magenta-intense-fg {
  color: #a03196;
}

.jp-RenderedText pre .ansi-cyan-intense-fg {
  color: #258f8f;
}

.jp-RenderedText pre .ansi-white-intense-fg {
  color: #a1a6b2;
}

.jp-RenderedText pre .ansi-black-intense-bg {
  background-color: #282c36;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-red-intense-bg {
  background-color: #b22b31;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-green-intense-bg {
  background-color: #007427;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-yellow-intense-bg {
  background-color: #b27d12;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-blue-intense-bg {
  background-color: #0065ca;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-magenta-intense-bg {
  background-color: #a03196;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-cyan-intense-bg {
  background-color: #258f8f;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-white-intense-bg {
  background-color: #a1a6b2;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-default-inverse-fg {
  color: var(--jp-ui-inverse-font-color0);
}

.jp-RenderedText pre .ansi-default-inverse-bg {
  background-color: var(--jp-inverse-layout-color0);
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-bold {
  font-weight: bold;
}

.jp-RenderedText pre .ansi-underline {
  text-decoration: underline;
}

.jp-RenderedText[data-mime-type='application/vnd.jupyter.stderr'] {
  background: var(--jp-rendermime-error-background);
  padding-top: var(--jp-code-padding);
}

/*-----------------------------------------------------------------------------
| RenderedLatex
|----------------------------------------------------------------------------*/

.jp-RenderedLatex {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-content-font-size1);
  line-height: var(--jp-content-line-height);
}

/* Left-justify outputs.*/
.jp-OutputArea-output.jp-RenderedLatex {
  padding: var(--jp-code-padding);
  text-align: left;
}

/*-----------------------------------------------------------------------------
| RenderedHTML
|----------------------------------------------------------------------------*/

.jp-RenderedHTMLCommon {
  color: var(--jp-content-font-color1);
  font-family: var(--jp-content-font-family);
  font-size: var(--jp-content-font-size1);
  line-height: var(--jp-content-line-height);

  /* Give a bit more R padding on Markdown text to keep line lengths reasonable */
  padding-right: 20px;
}

.jp-RenderedHTMLCommon em {
  font-style: italic;
}

.jp-RenderedHTMLCommon strong {
  font-weight: bold;
}

.jp-RenderedHTMLCommon u {
  text-decoration: underline;
}

.jp-RenderedHTMLCommon a:link {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

.jp-RenderedHTMLCommon a:hover {
  text-decoration: underline;
  color: var(--jp-content-link-color);
}

.jp-RenderedHTMLCommon a:visited {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

/* Headings */

.jp-RenderedHTMLCommon h1,
.jp-RenderedHTMLCommon h2,
.jp-RenderedHTMLCommon h3,
.jp-RenderedHTMLCommon h4,
.jp-RenderedHTMLCommon h5,
.jp-RenderedHTMLCommon h6 {
  line-height: var(--jp-content-heading-line-height);
  font-weight: var(--jp-content-heading-font-weight);
  font-style: normal;
  margin: var(--jp-content-heading-margin-top) 0
    var(--jp-content-heading-margin-bottom) 0;
}

.jp-RenderedHTMLCommon h1:first-child,
.jp-RenderedHTMLCommon h2:first-child,
.jp-RenderedHTMLCommon h3:first-child,
.jp-RenderedHTMLCommon h4:first-child,
.jp-RenderedHTMLCommon h5:first-child,
.jp-RenderedHTMLCommon h6:first-child {
  margin-top: calc(0.5 * var(--jp-content-heading-margin-top));
}

.jp-RenderedHTMLCommon h1:last-child,
.jp-RenderedHTMLCommon h2:last-child,
.jp-RenderedHTMLCommon h3:last-child,
.jp-RenderedHTMLCommon h4:last-child,
.jp-RenderedHTMLCommon h5:last-child,
.jp-RenderedHTMLCommon h6:last-child {
  margin-bottom: calc(0.5 * var(--jp-content-heading-margin-bottom));
}

.jp-RenderedHTMLCommon h1 {
  font-size: var(--jp-content-font-size5);
}

.jp-RenderedHTMLCommon h2 {
  font-size: var(--jp-content-font-size4);
}

.jp-RenderedHTMLCommon h3 {
  font-size: var(--jp-content-font-size3);
}

.jp-RenderedHTMLCommon h4 {
  font-size: var(--jp-content-font-size2);
}

.jp-RenderedHTMLCommon h5 {
  font-size: var(--jp-content-font-size1);
}

.jp-RenderedHTMLCommon h6 {
  font-size: var(--jp-content-font-size0);
}

/* Lists */

/* stylelint-disable selector-max-type, selector-max-compound-selectors */

.jp-RenderedHTMLCommon ul:not(.list-inline),
.jp-RenderedHTMLCommon ol:not(.list-inline) {
  padding-left: 2em;
}

.jp-RenderedHTMLCommon ul {
  list-style: disc;
}

.jp-RenderedHTMLCommon ul ul {
  list-style: square;
}

.jp-RenderedHTMLCommon ul ul ul {
  list-style: circle;
}

.jp-RenderedHTMLCommon ol {
  list-style: decimal;
}

.jp-RenderedHTMLCommon ol ol {
  list-style: upper-alpha;
}

.jp-RenderedHTMLCommon ol ol ol {
  list-style: lower-alpha;
}

.jp-RenderedHTMLCommon ol ol ol ol {
  list-style: lower-roman;
}

.jp-RenderedHTMLCommon ol ol ol ol ol {
  list-style: decimal;
}

.jp-RenderedHTMLCommon ol,
.jp-RenderedHTMLCommon ul {
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon ul ul,
.jp-RenderedHTMLCommon ul ol,
.jp-RenderedHTMLCommon ol ul,
.jp-RenderedHTMLCommon ol ol {
  margin-bottom: 0;
}

/* stylelint-enable selector-max-type, selector-max-compound-selectors */

.jp-RenderedHTMLCommon hr {
  color: var(--jp-border-color2);
  background-color: var(--jp-border-color1);
  margin-top: 1em;
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon > pre {
  margin: 1.5em 2em;
}

.jp-RenderedHTMLCommon pre,
.jp-RenderedHTMLCommon code {
  border: 0;
  background-color: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
  font-family: var(--jp-code-font-family);
  font-size: inherit;
  line-height: var(--jp-code-line-height);
  padding: 0;
  white-space: pre-wrap;
}

.jp-RenderedHTMLCommon :not(pre) > code {
  background-color: var(--jp-layout-color2);
  padding: 1px 5px;
}

/* Tables */

.jp-RenderedHTMLCommon table {
  border-collapse: collapse;
  border-spacing: 0;
  border: none;
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  table-layout: fixed;
  margin-left: auto;
  margin-bottom: 1em;
  margin-right: auto;
}

.jp-RenderedHTMLCommon thead {
  border-bottom: var(--jp-border-width) solid var(--jp-border-color1);
  vertical-align: bottom;
}

.jp-RenderedHTMLCommon td,
.jp-RenderedHTMLCommon th,
.jp-RenderedHTMLCommon tr {
  vertical-align: middle;
  padding: 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}

.jp-RenderedMarkdown.jp-RenderedHTMLCommon td,
.jp-RenderedMarkdown.jp-RenderedHTMLCommon th {
  max-width: none;
}

:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon td,
:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon th,
:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon tr {
  text-align: right;
}

.jp-RenderedHTMLCommon th {
  font-weight: bold;
}

.jp-RenderedHTMLCommon tbody tr:nth-child(odd) {
  background: var(--jp-layout-color0);
}

.jp-RenderedHTMLCommon tbody tr:nth-child(even) {
  background: var(--jp-rendermime-table-row-background);
}

.jp-RenderedHTMLCommon tbody tr:hover {
  background: var(--jp-rendermime-table-row-hover-background);
}

.jp-RenderedHTMLCommon p {
  text-align: left;
  margin: 0;
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon img {
  -moz-force-broken-image-icon: 1;
}

/* Restrict to direct children as other images could be nested in other content. */
.jp-RenderedHTMLCommon > img {
  display: block;
  margin-left: 0;
  margin-right: 0;
  margin-bottom: 1em;
}

/* Change color behind transparent images if they need it... */
[data-jp-theme-light='false'] .jp-RenderedImage img.jp-needs-light-background {
  background-color: var(--jp-inverse-layout-color1);
}

[data-jp-theme-light='true'] .jp-RenderedImage img.jp-needs-dark-background {
  background-color: var(--jp-inverse-layout-color1);
}

.jp-RenderedHTMLCommon img,
.jp-RenderedImage img,
.jp-RenderedHTMLCommon svg,
.jp-RenderedSVG svg {
  max-width: 100%;
  height: auto;
}

.jp-RenderedHTMLCommon img.jp-mod-unconfined,
.jp-RenderedImage img.jp-mod-unconfined,
.jp-RenderedHTMLCommon svg.jp-mod-unconfined,
.jp-RenderedSVG svg.jp-mod-unconfined {
  max-width: none;
}

.jp-RenderedHTMLCommon .alert {
  padding: var(--jp-notebook-padding);
  border: var(--jp-border-width) solid transparent;
  border-radius: var(--jp-border-radius);
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon .alert-info {
  color: var(--jp-info-color0);
  background-color: var(--jp-info-color3);
  border-color: var(--jp-info-color2);
}

.jp-RenderedHTMLCommon .alert-info hr {
  border-color: var(--jp-info-color3);
}

.jp-RenderedHTMLCommon .alert-info > p:last-child,
.jp-RenderedHTMLCommon .alert-info > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-warning {
  color: var(--jp-warn-color0);
  background-color: var(--jp-warn-color3);
  border-color: var(--jp-warn-color2);
}

.jp-RenderedHTMLCommon .alert-warning hr {
  border-color: var(--jp-warn-color3);
}

.jp-RenderedHTMLCommon .alert-warning > p:last-child,
.jp-RenderedHTMLCommon .alert-warning > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-success {
  color: var(--jp-success-color0);
  background-color: var(--jp-success-color3);
  border-color: var(--jp-success-color2);
}

.jp-RenderedHTMLCommon .alert-success hr {
  border-color: var(--jp-success-color3);
}

.jp-RenderedHTMLCommon .alert-success > p:last-child,
.jp-RenderedHTMLCommon .alert-success > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-danger {
  color: var(--jp-error-color0);
  background-color: var(--jp-error-color3);
  border-color: var(--jp-error-color2);
}

.jp-RenderedHTMLCommon .alert-danger hr {
  border-color: var(--jp-error-color3);
}

.jp-RenderedHTMLCommon .alert-danger > p:last-child,
.jp-RenderedHTMLCommon .alert-danger > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon blockquote {
  margin: 1em 2em;
  padding: 0 1em;
  border-left: 5px solid var(--jp-border-color2);
}

a.jp-InternalAnchorLink {
  visibility: hidden;
  margin-left: 8px;
  color: var(--md-blue-800);
}

h1:hover .jp-InternalAnchorLink,
h2:hover .jp-InternalAnchorLink,
h3:hover .jp-InternalAnchorLink,
h4:hover .jp-InternalAnchorLink,
h5:hover .jp-InternalAnchorLink,
h6:hover .jp-InternalAnchorLink {
  visibility: visible;
}

.jp-RenderedHTMLCommon kbd {
  background-color: var(--jp-rendermime-table-row-background);
  border: 1px solid var(--jp-border-color0);
  border-bottom-color: var(--jp-border-color2);
  border-radius: 3px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
  display: inline-block;
  font-size: var(--jp-ui-font-size0);
  line-height: 1em;
  padding: 0.2em 0.5em;
}

/* Most direct children of .jp-RenderedHTMLCommon have a margin-bottom of 1.0.
 * At the bottom of cells this is a bit too much as there is also spacing
 * between cells. Going all the way to 0 gets too tight between markdown and
 * code cells.
 */
.jp-RenderedHTMLCommon > *:last-child {
  margin-bottom: 0.5em;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-cursor-backdrop {
  position: fixed;
  width: 200px;
  height: 200px;
  margin-top: -100px;
  margin-left: -100px;
  will-change: transform;
  z-index: 100;
}

.lm-mod-drag-image {
  will-change: transform;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-lineFormSearch {
  padding: 4px 12px;
  background-color: var(--jp-layout-color2);
  box-shadow: var(--jp-toolbar-box-shadow);
  z-index: 2;
  font-size: var(--jp-ui-font-size1);
}

.jp-lineFormCaption {
  font-size: var(--jp-ui-font-size0);
  line-height: var(--jp-ui-font-size1);
  margin-top: 4px;
  color: var(--jp-ui-font-color0);
}

.jp-baseLineForm {
  border: none;
  border-radius: 0;
  position: absolute;
  background-size: 16px;
  background-repeat: no-repeat;
  background-position: center;
  outline: none;
}

.jp-lineFormButtonContainer {
  top: 4px;
  right: 8px;
  height: 24px;
  padding: 0 12px;
  width: 12px;
}

.jp-lineFormButtonIcon {
  top: 0;
  right: 0;
  background-color: var(--jp-brand-color1);
  height: 100%;
  width: 100%;
  box-sizing: border-box;
  padding: 4px 6px;
}

.jp-lineFormButton {
  top: 0;
  right: 0;
  background-color: transparent;
  height: 100%;
  width: 100%;
  box-sizing: border-box;
}

.jp-lineFormWrapper {
  overflow: hidden;
  padding: 0 8px;
  border: 1px solid var(--jp-border-color0);
  background-color: var(--jp-input-active-background);
  height: 22px;
}

.jp-lineFormWrapperFocusWithin {
  border: var(--jp-border-width) solid var(--md-blue-500);
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-lineFormInput {
  background: transparent;
  width: 200px;
  height: 100%;
  border: none;
  outline: none;
  color: var(--jp-ui-font-color0);
  line-height: 28px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-JSONEditor {
  display: flex;
  flex-direction: column;
  width: 100%;
}

.jp-JSONEditor-host {
  flex: 1 1 auto;
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  border-radius: 0;
  background: var(--jp-layout-color0);
  min-height: 50px;
  padding: 1px;
}

.jp-JSONEditor.jp-mod-error .jp-JSONEditor-host {
  border-color: red;
  outline-color: red;
}

.jp-JSONEditor-header {
  display: flex;
  flex: 1 0 auto;
  padding: 0 0 0 12px;
}

.jp-JSONEditor-header label {
  flex: 0 0 auto;
}

.jp-JSONEditor-commitButton {
  height: 16px;
  width: 16px;
  background-size: 18px;
  background-repeat: no-repeat;
  background-position: center;
}

.jp-JSONEditor-host.jp-mod-focused {
  background-color: var(--jp-input-active-background);
  border: 1px solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
}

.jp-Editor.jp-mod-dropTarget {
  border: var(--jp-border-width) solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/
.jp-DocumentSearch-input {
  border: none;
  outline: none;
  color: var(--jp-ui-font-color0);
  font-size: var(--jp-ui-font-size1);
  background-color: var(--jp-layout-color0);
  font-family: var(--jp-ui-font-family);
  padding: 2px 1px;
  resize: none;
}

.jp-DocumentSearch-overlay {
  position: absolute;
  background-color: var(--jp-toolbar-background);
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  border-left: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  top: 0;
  right: 0;
  z-index: 7;
  min-width: 405px;
  padding: 2px;
  font-size: var(--jp-ui-font-size1);

  --jp-private-document-search-button-height: 20px;
}

.jp-DocumentSearch-overlay button {
  background-color: var(--jp-toolbar-background);
  outline: 0;
}

.jp-DocumentSearch-overlay button:hover {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-overlay button:active {
  background-color: var(--jp-layout-color3);
}

.jp-DocumentSearch-overlay-row {
  display: flex;
  align-items: center;
  margin-bottom: 2px;
}

.jp-DocumentSearch-button-content {
  display: inline-block;
  cursor: pointer;
  box-sizing: border-box;
  width: 100%;
  height: 100%;
}

.jp-DocumentSearch-button-content svg {
  width: 100%;
  height: 100%;
}

.jp-DocumentSearch-input-wrapper {
  border: var(--jp-border-width) solid var(--jp-border-color0);
  display: flex;
  background-color: var(--jp-layout-color0);
  margin: 2px;
}

.jp-DocumentSearch-input-wrapper:focus-within {
  border-color: var(--jp-cell-editor-active-border-color);
}

.jp-DocumentSearch-toggle-wrapper,
.jp-DocumentSearch-button-wrapper {
  all: initial;
  overflow: hidden;
  display: inline-block;
  border: none;
  box-sizing: border-box;
}

.jp-DocumentSearch-toggle-wrapper {
  width: 14px;
  height: 14px;
}

.jp-DocumentSearch-button-wrapper {
  width: var(--jp-private-document-search-button-height);
  height: var(--jp-private-document-search-button-height);
}

.jp-DocumentSearch-toggle-wrapper:focus,
.jp-DocumentSearch-button-wrapper:focus {
  outline: var(--jp-border-width) solid
    var(--jp-cell-editor-active-border-color);
  outline-offset: -1px;
}

.jp-DocumentSearch-toggle-wrapper,
.jp-DocumentSearch-button-wrapper,
.jp-DocumentSearch-button-content:focus {
  outline: none;
}

.jp-DocumentSearch-toggle-placeholder {
  width: 5px;
}

.jp-DocumentSearch-input-button::before {
  display: block;
  padding-top: 100%;
}

.jp-DocumentSearch-input-button-off {
  opacity: var(--jp-search-toggle-off-opacity);
}

.jp-DocumentSearch-input-button-off:hover {
  opacity: var(--jp-search-toggle-hover-opacity);
}

.jp-DocumentSearch-input-button-on {
  opacity: var(--jp-search-toggle-on-opacity);
}

.jp-DocumentSearch-index-counter {
  padding-left: 10px;
  padding-right: 10px;
  user-select: none;
  min-width: 35px;
  display: inline-block;
}

.jp-DocumentSearch-up-down-wrapper {
  display: inline-block;
  padding-right: 2px;
  margin-left: auto;
  white-space: nowrap;
}

.jp-DocumentSearch-spacer {
  margin-left: auto;
}

.jp-DocumentSearch-up-down-wrapper button {
  outline: 0;
  border: none;
  width: var(--jp-private-document-search-button-height);
  height: var(--jp-private-document-search-button-height);
  vertical-align: middle;
  margin: 1px 5px 2px;
}

.jp-DocumentSearch-up-down-button:hover {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-up-down-button:active {
  background-color: var(--jp-layout-color3);
}

.jp-DocumentSearch-filter-button {
  border-radius: var(--jp-border-radius);
}

.jp-DocumentSearch-filter-button:hover {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-filter-button-enabled {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-filter-button-enabled:hover {
  background-color: var(--jp-layout-color3);
}

.jp-DocumentSearch-search-options {
  padding: 0 8px;
  margin-left: 3px;
  width: 100%;
  display: grid;
  justify-content: start;
  grid-template-columns: 1fr 1fr;
  align-items: center;
  justify-items: stretch;
}

.jp-DocumentSearch-search-filter-disabled {
  color: var(--jp-ui-font-color2);
}

.jp-DocumentSearch-search-filter {
  display: flex;
  align-items: center;
  user-select: none;
}

.jp-DocumentSearch-regex-error {
  color: var(--jp-error-color0);
}

.jp-DocumentSearch-replace-button-wrapper {
  overflow: hidden;
  display: inline-block;
  box-sizing: border-box;
  border: var(--jp-border-width) solid var(--jp-border-color0);
  margin: auto 2px;
  padding: 1px 4px;
  height: calc(var(--jp-private-document-search-button-height) + 2px);
}

.jp-DocumentSearch-replace-button-wrapper:focus {
  border: var(--jp-border-width) solid var(--jp-cell-editor-active-border-color);
}

.jp-DocumentSearch-replace-button {
  display: inline-block;
  text-align: center;
  cursor: pointer;
  box-sizing: border-box;
  color: var(--jp-ui-font-color1);

  /* height - 2 * (padding of wrapper) */
  line-height: calc(var(--jp-private-document-search-button-height) - 2px);
  width: 100%;
  height: 100%;
}

.jp-DocumentSearch-replace-button:focus {
  outline: none;
}

.jp-DocumentSearch-replace-wrapper-class {
  margin-left: 14px;
  display: flex;
}

.jp-DocumentSearch-replace-toggle {
  border: none;
  background-color: var(--jp-toolbar-background);
  border-radius: var(--jp-border-radius);
}

.jp-DocumentSearch-replace-toggle:hover {
  background-color: var(--jp-layout-color2);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.cm-editor {
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  font-family: var(--jp-code-font-family);
  border: 0;
  border-radius: 0;
  height: auto;

  /* Changed to auto to autogrow */
}

.cm-editor pre {
  padding: 0 var(--jp-code-padding);
}

.jp-CodeMirrorEditor[data-type='inline'] .cm-dialog {
  background-color: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
}

.jp-CodeMirrorEditor {
  cursor: text;
}

/* When zoomed out 67% and 33% on a screen of 1440 width x 900 height */
@media screen and (min-width: 2138px) and (max-width: 4319px) {
  .jp-CodeMirrorEditor[data-type='inline'] .cm-cursor {
    border-left: var(--jp-code-cursor-width1) solid
      var(--jp-editor-cursor-color);
  }
}

/* When zoomed out less than 33% */
@media screen and (min-width: 4320px) {
  .jp-CodeMirrorEditor[data-type='inline'] .cm-cursor {
    border-left: var(--jp-code-cursor-width2) solid
      var(--jp-editor-cursor-color);
  }
}

.cm-editor.jp-mod-readOnly .cm-cursor {
  display: none;
}

.jp-CollaboratorCursor {
  border-left: 5px solid transparent;
  border-right: 5px solid transparent;
  border-top: none;
  border-bottom: 3px solid;
  background-clip: content-box;
  margin-left: -5px;
  margin-right: -5px;
}

.cm-searching,
.cm-searching span {
  /* `.cm-searching span`: we need to override syntax highlighting */
  background-color: var(--jp-search-unselected-match-background-color);
  color: var(--jp-search-unselected-match-color);
}

.cm-searching::selection,
.cm-searching span::selection {
  background-color: var(--jp-search-unselected-match-background-color);
  color: var(--jp-search-unselected-match-color);
}

.jp-current-match > .cm-searching,
.jp-current-match > .cm-searching span,
.cm-searching > .jp-current-match,
.cm-searching > .jp-current-match span {
  background-color: var(--jp-search-selected-match-background-color);
  color: var(--jp-search-selected-match-color);
}

.jp-current-match > .cm-searching::selection,
.cm-searching > .jp-current-match::selection,
.jp-current-match > .cm-searching span::selection {
  background-color: var(--jp-search-selected-match-background-color);
  color: var(--jp-search-selected-match-color);
}

.cm-trailingspace {
  background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAFCAYAAAB4ka1VAAAAsElEQVQIHQGlAFr/AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA7+r3zKmT0/+pk9P/7+r3zAAAAAAAAAAABAAAAAAAAAAA6OPzM+/q9wAAAAAA6OPzMwAAAAAAAAAAAgAAAAAAAAAAGR8NiRQaCgAZIA0AGR8NiQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQyoYJ/SY80UAAAAASUVORK5CYII=);
  background-position: center left;
  background-repeat: repeat-x;
}

.jp-CollaboratorCursor-hover {
  position: absolute;
  z-index: 1;
  transform: translateX(-50%);
  color: white;
  border-radius: 3px;
  padding-left: 4px;
  padding-right: 4px;
  padding-top: 1px;
  padding-bottom: 1px;
  text-align: center;
  font-size: var(--jp-ui-font-size1);
  white-space: nowrap;
}

.jp-CodeMirror-ruler {
  border-left: 1px dashed var(--jp-border-color2);
}

/* Styles for shared cursors (remote cursor locations and selected ranges) */
.jp-CodeMirrorEditor .cm-ySelectionCaret {
  position: relative;
  border-left: 1px solid black;
  margin-left: -1px;
  margin-right: -1px;
  box-sizing: border-box;
}

.jp-CodeMirrorEditor .cm-ySelectionCaret > .cm-ySelectionInfo {
  white-space: nowrap;
  position: absolute;
  top: -1.15em;
  padding-bottom: 0.05em;
  left: -1px;
  font-size: 0.95em;
  font-family: var(--jp-ui-font-family);
  font-weight: bold;
  line-height: normal;
  user-select: none;
  color: white;
  padding-left: 2px;
  padding-right: 2px;
  z-index: 101;
  transition: opacity 0.3s ease-in-out;
}

.jp-CodeMirrorEditor .cm-ySelectionInfo {
  transition-delay: 0.7s;
  opacity: 0;
}

.jp-CodeMirrorEditor .cm-ySelectionCaret:hover > .cm-ySelectionInfo {
  opacity: 1;
  transition-delay: 0s;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-MimeDocument {
  outline: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-filebrowser-button-height: 28px;
  --jp-private-filebrowser-button-width: 48px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-FileBrowser .jp-SidePanel-content {
  display: flex;
  flex-direction: column;
}

.jp-FileBrowser-toolbar.jp-Toolbar {
  flex-wrap: wrap;
  row-gap: 12px;
  border-bottom: none;
  height: auto;
  margin: 8px 12px 0;
  box-shadow: none;
  padding: 0;
  justify-content: flex-start;
}

.jp-FileBrowser-Panel {
  flex: 1 1 auto;
  display: flex;
  flex-direction: column;
}

.jp-BreadCrumbs {
  flex: 0 0 auto;
  margin: 8px 12px;
}

.jp-BreadCrumbs-item {
  margin: 0 2px;
  padding: 0 2px;
  border-radius: var(--jp-border-radius);
  cursor: pointer;
}

.jp-BreadCrumbs-item:hover {
  background-color: var(--jp-layout-color2);
}

.jp-BreadCrumbs-item:first-child {
  margin-left: 0;
}

.jp-BreadCrumbs-item.jp-mod-dropTarget {
  background-color: var(--jp-brand-color2);
  opacity: 0.7;
}

/*-----------------------------------------------------------------------------
| Buttons
|----------------------------------------------------------------------------*/

.jp-FileBrowser-toolbar > .jp-Toolbar-item {
  flex: 0 0 auto;
  padding-left: 0;
  padding-right: 2px;
  align-items: center;
  height: unset;
}

.jp-FileBrowser-toolbar > .jp-Toolbar-item .jp-ToolbarButtonComponent {
  width: 40px;
}

/*-----------------------------------------------------------------------------
| Other styles
|----------------------------------------------------------------------------*/

.jp-FileDialog.jp-mod-conflict input {
  color: var(--jp-error-color1);
}

.jp-FileDialog .jp-new-name-title {
  margin-top: 12px;
}

.jp-LastModified-hidden {
  display: none;
}

.jp-FileSize-hidden {
  display: none;
}

.jp-FileBrowser .lm-AccordionPanel > h3:first-child {
  display: none;
}

/*-----------------------------------------------------------------------------
| DirListing
|----------------------------------------------------------------------------*/

.jp-DirListing {
  flex: 1 1 auto;
  display: flex;
  flex-direction: column;
  outline: 0;
}

.jp-DirListing-header {
  flex: 0 0 auto;
  display: flex;
  flex-direction: row;
  align-items: center;
  overflow: hidden;
  border-top: var(--jp-border-width) solid var(--jp-border-color2);
  border-bottom: var(--jp-border-width) solid var(--jp-border-color1);
  box-shadow: var(--jp-toolbar-box-shadow);
  z-index: 2;
}

.jp-DirListing-headerItem {
  padding: 4px 12px 2px;
  font-weight: 500;
}

.jp-DirListing-headerItem:hover {
  background: var(--jp-layout-color2);
}

.jp-DirListing-headerItem.jp-id-name {
  flex: 1 0 84px;
}

.jp-DirListing-headerItem.jp-id-modified {
  flex: 0 0 112px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
}

.jp-DirListing-headerItem.jp-id-filesize {
  flex: 0 0 75px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
}

.jp-id-narrow {
  display: none;
  flex: 0 0 5px;
  padding: 4px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
  color: var(--jp-border-color2);
}

.jp-DirListing-narrow .jp-id-narrow {
  display: block;
}

.jp-DirListing-narrow .jp-id-modified,
.jp-DirListing-narrow .jp-DirListing-itemModified {
  display: none;
}

.jp-DirListing-headerItem.jp-mod-selected {
  font-weight: 600;
}

/* increase specificity to override bundled default */
.jp-DirListing-content {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  list-style-type: none;
  overflow: auto;
  background-color: var(--jp-layout-color1);
}

.jp-DirListing-content mark {
  color: var(--jp-ui-font-color0);
  background-color: transparent;
  font-weight: bold;
}

.jp-DirListing-content .jp-DirListing-item.jp-mod-selected mark {
  color: var(--jp-ui-inverse-font-color0);
}

/* Style the directory listing content when a user drops a file to upload */
.jp-DirListing.jp-mod-native-drop .jp-DirListing-content {
  outline: 5px dashed rgba(128, 128, 128, 0.5);
  outline-offset: -10px;
  cursor: copy;
}

.jp-DirListing-item {
  display: flex;
  flex-direction: row;
  align-items: center;
  padding: 4px 12px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-DirListing-checkboxWrapper {
  /* Increases hit area of checkbox. */
  padding: 4px;
}

.jp-DirListing-header
  .jp-DirListing-checkboxWrapper
  + .jp-DirListing-headerItem {
  padding-left: 4px;
}

.jp-DirListing-content .jp-DirListing-checkboxWrapper {
  position: relative;
  left: -4px;
  margin: -4px 0 -4px -8px;
}

.jp-DirListing-checkboxWrapper.jp-mod-visible {
  visibility: visible;
}

/* For devices that support hovering, hide checkboxes until hovered, selected...
*/
@media (hover: hover) {
  .jp-DirListing-checkboxWrapper {
    visibility: hidden;
  }

  .jp-DirListing-item:hover .jp-DirListing-checkboxWrapper,
  .jp-DirListing-item.jp-mod-selected .jp-DirListing-checkboxWrapper {
    visibility: visible;
  }
}

.jp-DirListing-item[data-is-dot] {
  opacity: 75%;
}

.jp-DirListing-item.jp-mod-selected {
  color: var(--jp-ui-inverse-font-color1);
  background: var(--jp-brand-color1);
}

.jp-DirListing-item.jp-mod-dropTarget {
  background: var(--jp-brand-color3);
}

.jp-DirListing-item:hover:not(.jp-mod-selected) {
  background: var(--jp-layout-color2);
}

.jp-DirListing-itemIcon {
  flex: 0 0 20px;
  margin-right: 4px;
}

.jp-DirListing-itemText {
  flex: 1 0 64px;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  user-select: none;
}

.jp-DirListing-itemText:focus {
  outline-width: 2px;
  outline-color: var(--jp-inverse-layout-color1);
  outline-style: solid;
  outline-offset: 1px;
}

.jp-DirListing-item.jp-mod-selected .jp-DirListing-itemText:focus {
  outline-color: var(--jp-layout-color1);
}

.jp-DirListing-itemModified {
  flex: 0 0 125px;
  text-align: right;
}

.jp-DirListing-itemFileSize {
  flex: 0 0 90px;
  text-align: right;
}

.jp-DirListing-editor {
  flex: 1 0 64px;
  outline: none;
  border: none;
  color: var(--jp-ui-font-color1);
  background-color: var(--jp-layout-color1);
}

.jp-DirListing-item.jp-mod-running .jp-DirListing-itemIcon::before {
  color: var(--jp-success-color1);
  content: '\25CF';
  font-size: 8px;
  position: absolute;
  left: -8px;
}

.jp-DirListing-item.jp-mod-running.jp-mod-selected
  .jp-DirListing-itemIcon::before {
  color: var(--jp-ui-inverse-font-color1);
}

.jp-DirListing-item.lm-mod-drag-image,
.jp-DirListing-item.jp-mod-selected.lm-mod-drag-image {
  font-size: var(--jp-ui-font-size1);
  padding-left: 4px;
  margin-left: 4px;
  width: 160px;
  background-color: var(--jp-ui-inverse-font-color2);
  box-shadow: var(--jp-elevation-z2);
  border-radius: 0;
  color: var(--jp-ui-font-color1);
  transform: translateX(-40%) translateY(-58%);
}

.jp-Document {
  min-width: 120px;
  min-height: 120px;
  outline: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Main OutputArea
| OutputArea has a list of Outputs
|----------------------------------------------------------------------------*/

.jp-OutputArea {
  overflow-y: auto;
}

.jp-OutputArea-child {
  display: table;
  table-layout: fixed;
  width: 100%;
  overflow: hidden;
}

.jp-OutputPrompt {
  width: var(--jp-cell-prompt-width);
  color: var(--jp-cell-outprompt-font-color);
  font-family: var(--jp-cell-prompt-font-family);
  padding: var(--jp-code-padding);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
  opacity: var(--jp-cell-prompt-opacity);

  /* Right align prompt text, don't wrap to handle large prompt numbers */
  text-align: right;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;

  /* Disable text selection */
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-OutputArea-prompt {
  display: table-cell;
  vertical-align: top;
}

.jp-OutputArea-output {
  display: table-cell;
  width: 100%;
  height: auto;
  overflow: auto;
  user-select: text;
  -moz-user-select: text;
  -webkit-user-select: text;
  -ms-user-select: text;
}

.jp-OutputArea .jp-RenderedText {
  padding-left: 1ch;
}

/**
 * Prompt overlay.
 */

.jp-OutputArea-promptOverlay {
  position: absolute;
  top: 0;
  width: var(--jp-cell-prompt-width);
  height: 100%;
  opacity: 0.5;
}

.jp-OutputArea-promptOverlay:hover {
  background: var(--jp-layout-color2);
  box-shadow: inset 0 0 1px var(--jp-inverse-layout-color0);
  cursor: zoom-out;
}

.jp-mod-outputsScrolled .jp-OutputArea-promptOverlay:hover {
  cursor: zoom-in;
}

/**
 * Isolated output.
 */
.jp-OutputArea-output.jp-mod-isolated {
  width: 100%;
  display: block;
}

/*
When drag events occur, `lm-mod-override-cursor` is added to the body.
Because iframes steal all cursor events, the following two rules are necessary
to suppress pointer events while resize drags are occurring. There may be a
better solution to this problem.
*/
body.lm-mod-override-cursor .jp-OutputArea-output.jp-mod-isolated {
  position: relative;
}

body.lm-mod-override-cursor .jp-OutputArea-output.jp-mod-isolated::before {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: transparent;
}

/* pre */

.jp-OutputArea-output pre {
  border: none;
  margin: 0;
  padding: 0;
  overflow-x: auto;
  overflow-y: auto;
  word-break: break-all;
  word-wrap: break-word;
  white-space: pre-wrap;
}

/* tables */

.jp-OutputArea-output.jp-RenderedHTMLCommon table {
  margin-left: 0;
  margin-right: 0;
}

/* description lists */

.jp-OutputArea-output dl,
.jp-OutputArea-output dt,
.jp-OutputArea-output dd {
  display: block;
}

.jp-OutputArea-output dl {
  width: 100%;
  overflow: hidden;
  padding: 0;
  margin: 0;
}

.jp-OutputArea-output dt {
  font-weight: bold;
  float: left;
  width: 20%;
  padding: 0;
  margin: 0;
}

.jp-OutputArea-output dd {
  float: left;
  width: 80%;
  padding: 0;
  margin: 0;
}

.jp-TrimmedOutputs pre {
  background: var(--jp-layout-color3);
  font-size: calc(var(--jp-code-font-size) * 1.4);
  text-align: center;
  text-transform: uppercase;
}

/* Hide the gutter in case of
 *  - nested output areas (e.g. in the case of output widgets)
 *  - mirrored output areas
 */
.jp-OutputArea .jp-OutputArea .jp-OutputArea-prompt {
  display: none;
}

/* Hide empty lines in the output area, for instance due to cleared widgets */
.jp-OutputArea-prompt:empty {
  padding: 0;
  border: 0;
}

/*-----------------------------------------------------------------------------
| executeResult is added to any Output-result for the display of the object
| returned by a cell
|----------------------------------------------------------------------------*/

.jp-OutputArea-output.jp-OutputArea-executeResult {
  margin-left: 0;
  width: 100%;
}

/* Text output with the Out[] prompt needs a top padding to match the
 * alignment of the Out[] prompt itself.
 */
.jp-OutputArea-executeResult .jp-RenderedText.jp-OutputArea-output {
  padding-top: var(--jp-code-padding);
  border-top: var(--jp-border-width) solid transparent;
}

/*-----------------------------------------------------------------------------
| The Stdin output
|----------------------------------------------------------------------------*/

.jp-Stdin-prompt {
  color: var(--jp-content-font-color0);
  padding-right: var(--jp-code-padding);
  vertical-align: baseline;
  flex: 0 0 auto;
}

.jp-Stdin-input {
  font-family: var(--jp-code-font-family);
  font-size: inherit;
  color: inherit;
  background-color: inherit;
  width: 42%;
  min-width: 200px;

  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;

  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0 0.25em;
  margin: 0 0.25em;
  flex: 0 0 70%;
}

.jp-Stdin-input::placeholder {
  opacity: 0;
}

.jp-Stdin-input:focus {
  box-shadow: none;
}

.jp-Stdin-input:focus::placeholder {
  opacity: 1;
}

/*-----------------------------------------------------------------------------
| Output Area View
|----------------------------------------------------------------------------*/

.jp-LinkedOutputView .jp-OutputArea {
  height: 100%;
  display: block;
}

.jp-LinkedOutputView .jp-OutputArea-output:only-child {
  height: 100%;
}

/*-----------------------------------------------------------------------------
| Printing
|----------------------------------------------------------------------------*/

@media print {
  .jp-OutputArea-child {
    break-inside: avoid-page;
  }
}

/*-----------------------------------------------------------------------------
| Mobile
|----------------------------------------------------------------------------*/
@media only screen and (max-width: 760px) {
  .jp-OutputPrompt {
    display: table-row;
    text-align: left;
  }

  .jp-OutputArea-child .jp-OutputArea-output {
    display: table-row;
    margin-left: var(--jp-notebook-padding);
  }
}

/* Trimmed outputs warning */
.jp-TrimmedOutputs > a {
  margin: 10px;
  text-decoration: none;
  cursor: pointer;
}

.jp-TrimmedOutputs > a:hover {
  text-decoration: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Table of Contents
|----------------------------------------------------------------------------*/

:root {
  --jp-private-toc-active-width: 4px;
}

.jp-TableOfContents {
  display: flex;
  flex-direction: column;
  background: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  height: 100%;
}

.jp-TableOfContents-placeholder {
  text-align: center;
}

.jp-TableOfContents-placeholderContent {
  color: var(--jp-content-font-color2);
  padding: 8px;
}

.jp-TableOfContents-placeholderContent > h3 {
  margin-bottom: var(--jp-content-heading-margin-bottom);
}

.jp-TableOfContents .jp-SidePanel-content {
  overflow-y: auto;
}

.jp-TableOfContents-tree {
  margin: 4px;
}

.jp-TableOfContents ol {
  list-style-type: none;
}

/* stylelint-disable-next-line selector-max-type */
.jp-TableOfContents li > ol {
  /* Align left border with triangle icon center */
  padding-left: 11px;
}

.jp-TableOfContents-content {
  /* left margin for the active heading indicator */
  margin: 0 0 0 var(--jp-private-toc-active-width);
  padding: 0;
  background-color: var(--jp-layout-color1);
}

.jp-tocItem {
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-tocItem-heading {
  display: flex;
  cursor: pointer;
}

.jp-tocItem-heading:hover {
  background-color: var(--jp-layout-color2);
}

.jp-tocItem-content {
  display: block;
  padding: 4px 0;
  white-space: nowrap;
  text-overflow: ellipsis;
  overflow-x: hidden;
}

.jp-tocItem-collapser {
  height: 20px;
  margin: 2px 2px 0;
  padding: 0;
  background: none;
  border: none;
  cursor: pointer;
}

.jp-tocItem-collapser:hover {
  background-color: var(--jp-layout-color3);
}

/* Active heading indicator */

.jp-tocItem-heading::before {
  content: ' ';
  background: transparent;
  width: var(--jp-private-toc-active-width);
  height: 24px;
  position: absolute;
  left: 0;
  border-radius: var(--jp-border-radius);
}

.jp-tocItem-heading.jp-tocItem-active::before {
  background-color: var(--jp-brand-color1);
}

.jp-tocItem-heading:hover.jp-tocItem-active::before {
  background: var(--jp-brand-color0);
  opacity: 1;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Collapser {
  flex: 0 0 var(--jp-cell-collapser-width);
  padding: 0;
  margin: 0;
  border: none;
  outline: none;
  background: transparent;
  border-radius: var(--jp-border-radius);
  opacity: 1;
}

.jp-Collapser-child {
  display: block;
  width: 100%;
  box-sizing: border-box;

  /* height: 100% doesn't work because the height of its parent is computed from content */
  position: absolute;
  top: 0;
  bottom: 0;
}

/*-----------------------------------------------------------------------------
| Printing
|----------------------------------------------------------------------------*/

/*
Hiding collapsers in print mode.

Note: input and output wrappers have "display: block" propery in print mode.
*/

@media print {
  .jp-Collapser {
    display: none;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Header/Footer
|----------------------------------------------------------------------------*/

/* Hidden by zero height by default */
.jp-CellHeader,
.jp-CellFooter {
  height: 0;
  width: 100%;
  padding: 0;
  margin: 0;
  border: none;
  outline: none;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Input
|----------------------------------------------------------------------------*/

/* All input areas */
.jp-InputArea {
  display: table;
  table-layout: fixed;
  width: 100%;
  overflow: hidden;
}

.jp-InputArea-editor {
  display: table-cell;
  overflow: hidden;
  vertical-align: top;

  /* This is the non-active, default styling */
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  border-radius: 0;
  background: var(--jp-cell-editor-background);
}

.jp-InputPrompt {
  display: table-cell;
  vertical-align: top;
  width: var(--jp-cell-prompt-width);
  color: var(--jp-cell-inprompt-font-color);
  font-family: var(--jp-cell-prompt-font-family);
  padding: var(--jp-code-padding);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  opacity: var(--jp-cell-prompt-opacity);
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;

  /* Right align prompt text, don't wrap to handle large prompt numbers */
  text-align: right;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;

  /* Disable text selection */
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

/*-----------------------------------------------------------------------------
| Mobile
|----------------------------------------------------------------------------*/
@media only screen and (max-width: 760px) {
  .jp-InputArea-editor {
    display: table-row;
    margin-left: var(--jp-notebook-padding);
  }

  .jp-InputPrompt {
    display: table-row;
    text-align: left;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Placeholder
|----------------------------------------------------------------------------*/

.jp-Placeholder {
  display: table;
  table-layout: fixed;
  width: 100%;
}

.jp-Placeholder-prompt {
  display: table-cell;
  box-sizing: border-box;
}

.jp-Placeholder-content {
  display: table-cell;
  padding: 4px 6px;
  border: 1px solid transparent;
  border-radius: 0;
  background: none;
  box-sizing: border-box;
  cursor: pointer;
}

.jp-Placeholder-contentContainer {
  display: flex;
}

.jp-Placeholder-content:hover,
.jp-InputPlaceholder > .jp-Placeholder-content:hover {
  border-color: var(--jp-layout-color3);
}

.jp-Placeholder-content .jp-MoreHorizIcon {
  width: 32px;
  height: 16px;
  border: 1px solid transparent;
  border-radius: var(--jp-border-radius);
}

.jp-Placeholder-content .jp-MoreHorizIcon:hover {
  border: 1px solid var(--jp-border-color1);
  box-shadow: 0 0 2px 0 rgba(0, 0, 0, 0.25);
  background-color: var(--jp-layout-color0);
}

.jp-PlaceholderText {
  white-space: nowrap;
  overflow-x: hidden;
  color: var(--jp-inverse-layout-color3);
  font-family: var(--jp-code-font-family);
}

.jp-InputPlaceholder > .jp-Placeholder-content {
  border-color: var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Private CSS variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-cell-scrolling-output-offset: 5px;
}

/*-----------------------------------------------------------------------------
| Cell
|----------------------------------------------------------------------------*/

.jp-Cell {
  padding: var(--jp-cell-padding);
  margin: 0;
  border: none;
  outline: none;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Common input/output
|----------------------------------------------------------------------------*/

.jp-Cell-inputWrapper,
.jp-Cell-outputWrapper {
  display: flex;
  flex-direction: row;
  padding: 0;
  margin: 0;

  /* Added to reveal the box-shadow on the input and output collapsers. */
  overflow: visible;
}

/* Only input/output areas inside cells */
.jp-Cell-inputArea,
.jp-Cell-outputArea {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Collapser
|----------------------------------------------------------------------------*/

/* Make the output collapser disappear when there is not output, but do so
 * in a manner that leaves it in the layout and preserves its width.
 */
.jp-Cell.jp-mod-noOutputs .jp-Cell-outputCollapser {
  border: none !important;
  background: transparent !important;
}

.jp-Cell:not(.jp-mod-noOutputs) .jp-Cell-outputCollapser {
  min-height: var(--jp-cell-collapser-min-height);
}

/*-----------------------------------------------------------------------------
| Output
|----------------------------------------------------------------------------*/

/* Put a space between input and output when there IS output */
.jp-Cell:not(.jp-mod-noOutputs) .jp-Cell-outputWrapper {
  margin-top: 5px;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea {
  overflow-y: auto;
  max-height: 24em;
  margin-left: var(--jp-private-cell-scrolling-output-offset);
  resize: vertical;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea[style*='height'] {
  max-height: unset;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea::after {
  content: ' ';
  box-shadow: inset 0 0 6px 2px rgb(0 0 0 / 30%);
  width: 100%;
  height: 100%;
  position: sticky;
  bottom: 0;
  top: 0;
  margin-top: -50%;
  float: left;
  display: block;
  pointer-events: none;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-child {
  padding-top: 6px;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-prompt {
  width: calc(
    var(--jp-cell-prompt-width) - var(--jp-private-cell-scrolling-output-offset)
  );
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-promptOverlay {
  left: calc(-1 * var(--jp-private-cell-scrolling-output-offset));
}

/*-----------------------------------------------------------------------------
| CodeCell
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| MarkdownCell
|----------------------------------------------------------------------------*/

.jp-MarkdownOutput {
  display: table-cell;
  width: 100%;
  margin-top: 0;
  margin-bottom: 0;
  padding-left: var(--jp-code-padding);
}

.jp-MarkdownOutput.jp-RenderedHTMLCommon {
  overflow: auto;
}

/* collapseHeadingButton (show always if hiddenCellsButton is _not_ shown) */
.jp-collapseHeadingButton {
  display: flex;
  min-height: var(--jp-cell-collapser-min-height);
  font-size: var(--jp-code-font-size);
  position: absolute;
  background-color: transparent;
  background-size: 25px;
  background-repeat: no-repeat;
  background-position-x: center;
  background-position-y: top;
  background-image: var(--jp-icon-caret-down);
  right: 0;
  top: 0;
  bottom: 0;
}

.jp-collapseHeadingButton.jp-mod-collapsed {
  background-image: var(--jp-icon-caret-right);
}

/*
 set the container font size to match that of content
 so that the nested collapse buttons have the right size
*/
.jp-MarkdownCell .jp-InputPrompt {
  font-size: var(--jp-content-font-size1);
}

/*
  Align collapseHeadingButton with cell top header
  The font sizes are identical to the ones in packages/rendermime/style/base.css
*/
.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='1'] {
  font-size: var(--jp-content-font-size5);
  background-position-y: calc(0.3 * var(--jp-content-font-size5));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='2'] {
  font-size: var(--jp-content-font-size4);
  background-position-y: calc(0.3 * var(--jp-content-font-size4));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='3'] {
  font-size: var(--jp-content-font-size3);
  background-position-y: calc(0.3 * var(--jp-content-font-size3));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='4'] {
  font-size: var(--jp-content-font-size2);
  background-position-y: calc(0.3 * var(--jp-content-font-size2));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='5'] {
  font-size: var(--jp-content-font-size1);
  background-position-y: top;
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='6'] {
  font-size: var(--jp-content-font-size0);
  background-position-y: top;
}

/* collapseHeadingButton (show only on (hover,active) if hiddenCellsButton is shown) */
.jp-Notebook.jp-mod-showHiddenCellsButton .jp-collapseHeadingButton {
  display: none;
}

.jp-Notebook.jp-mod-showHiddenCellsButton
  :is(.jp-MarkdownCell:hover, .jp-mod-active)
  .jp-collapseHeadingButton {
  display: flex;
}

/* showHiddenCellsButton (only show if jp-mod-showHiddenCellsButton is set, which
is a consequence of the showHiddenCellsButton option in Notebook Settings)*/
.jp-Notebook.jp-mod-showHiddenCellsButton .jp-showHiddenCellsButton {
  margin-left: calc(var(--jp-cell-prompt-width) + 2 * var(--jp-code-padding));
  margin-top: var(--jp-code-padding);
  border: 1px solid var(--jp-border-color2);
  background-color: var(--jp-border-color3) !important;
  color: var(--jp-content-font-color0) !important;
  display: flex;
}

.jp-Notebook.jp-mod-showHiddenCellsButton .jp-showHiddenCellsButton:hover {
  background-color: var(--jp-border-color2) !important;
}

.jp-showHiddenCellsButton {
  display: none;
}

/*-----------------------------------------------------------------------------
| Printing
|----------------------------------------------------------------------------*/

/*
Using block instead of flex to allow the use of the break-inside CSS property for
cell outputs.
*/

@media print {
  .jp-Cell-inputWrapper,
  .jp-Cell-outputWrapper {
    display: block;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-notebook-toolbar-padding: 2px 5px 2px 2px;
}

/*-----------------------------------------------------------------------------

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-NotebookPanel-toolbar {
  padding: var(--jp-notebook-toolbar-padding);

  /* disable paint containment from lumino 2.0 default strict CSS containment */
  contain: style size !important;
}

.jp-Toolbar-item.jp-Notebook-toolbarCellType .jp-select-wrapper.jp-mod-focused {
  border: none;
  box-shadow: none;
}

.jp-Notebook-toolbarCellTypeDropdown select {
  height: 24px;
  font-size: var(--jp-ui-font-size1);
  line-height: 14px;
  border-radius: 0;
  display: block;
}

.jp-Notebook-toolbarCellTypeDropdown span {
  top: 5px !important;
}

.jp-Toolbar-responsive-popup {
  position: absolute;
  height: fit-content;
  display: flex;
  flex-direction: row;
  flex-wrap: wrap;
  justify-content: flex-end;
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  background: var(--jp-toolbar-background);
  min-height: var(--jp-toolbar-micro-height);
  padding: var(--jp-notebook-toolbar-padding);
  z-index: 1;
  right: 0;
  top: 0;
}

.jp-Toolbar > .jp-Toolbar-responsive-opener {
  margin-left: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-Notebook-ExecutionIndicator {
  position: relative;
  display: inline-block;
  height: 100%;
  z-index: 9997;
}

.jp-Notebook-ExecutionIndicator-tooltip {
  visibility: hidden;
  height: auto;
  width: max-content;
  width: -moz-max-content;
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color1);
  text-align: justify;
  border-radius: 6px;
  padding: 0 5px;
  position: fixed;
  display: table;
}

.jp-Notebook-ExecutionIndicator-tooltip.up {
  transform: translateX(-50%) translateY(-100%) translateY(-32px);
}

.jp-Notebook-ExecutionIndicator-tooltip.down {
  transform: translateX(calc(-100% + 16px)) translateY(5px);
}

.jp-Notebook-ExecutionIndicator-tooltip.hidden {
  display: none;
}

.jp-Notebook-ExecutionIndicator:hover .jp-Notebook-ExecutionIndicator-tooltip {
  visibility: visible;
}

.jp-Notebook-ExecutionIndicator span {
  font-size: var(--jp-ui-font-size1);
  font-family: var(--jp-ui-font-family);
  color: var(--jp-ui-font-color1);
  line-height: 24px;
  display: block;
}

.jp-Notebook-ExecutionIndicator-progress-bar {
  display: flex;
  justify-content: center;
  height: 100%;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*
 * Execution indicator
 */
.jp-tocItem-content::after {
  content: '';

  /* Must be identical to form a circle */
  width: 12px;
  height: 12px;
  background: none;
  border: none;
  position: absolute;
  right: 0;
}

.jp-tocItem-content[data-running='0']::after {
  border-radius: 50%;
  border: var(--jp-border-width) solid var(--jp-inverse-layout-color3);
  background: none;
}

.jp-tocItem-content[data-running='1']::after {
  border-radius: 50%;
  border: var(--jp-border-width) solid var(--jp-inverse-layout-color3);
  background-color: var(--jp-inverse-layout-color3);
}

.jp-tocItem-content[data-running='0'],
.jp-tocItem-content[data-running='1'] {
  margin-right: 12px;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-Notebook-footer {
  height: 27px;
  margin-left: calc(
    var(--jp-cell-prompt-width) + var(--jp-cell-collapser-width) +
      var(--jp-cell-padding)
  );
  width: calc(
    100% -
      (
        var(--jp-cell-prompt-width) + var(--jp-cell-collapser-width) +
          var(--jp-cell-padding) + var(--jp-cell-padding)
      )
  );
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  color: var(--jp-ui-font-color3);
  margin-top: 6px;
  background: none;
  cursor: pointer;
}

.jp-Notebook-footer:focus {
  border-color: var(--jp-cell-editor-active-border-color);
}

/* For devices that support hovering, hide footer until hover */
@media (hover: hover) {
  .jp-Notebook-footer {
    opacity: 0;
  }

  .jp-Notebook-footer:focus,
  .jp-Notebook-footer:hover {
    opacity: 1;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Imports
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| CSS variables
|----------------------------------------------------------------------------*/

:root {
  --jp-side-by-side-output-size: 1fr;
  --jp-side-by-side-resized-cell: var(--jp-side-by-side-output-size);
  --jp-private-notebook-dragImage-width: 304px;
  --jp-private-notebook-dragImage-height: 36px;
  --jp-private-notebook-selected-color: var(--md-blue-400);
  --jp-private-notebook-active-color: var(--md-green-400);
}

/*-----------------------------------------------------------------------------
| Notebook
|----------------------------------------------------------------------------*/

/* stylelint-disable selector-max-class */

.jp-NotebookPanel {
  display: block;
  height: 100%;
}

.jp-NotebookPanel.jp-Document {
  min-width: 240px;
  min-height: 120px;
}

.jp-Notebook {
  padding: var(--jp-notebook-padding);
  outline: none;
  overflow: auto;
  background: var(--jp-layout-color0);
}

.jp-Notebook.jp-mod-scrollPastEnd::after {
  display: block;
  content: '';
  min-height: var(--jp-notebook-scroll-padding);
}

.jp-MainAreaWidget-ContainStrict .jp-Notebook * {
  contain: strict;
}

.jp-Notebook .jp-Cell {
  overflow: visible;
}

.jp-Notebook .jp-Cell .jp-InputPrompt {
  cursor: move;
}

/*-----------------------------------------------------------------------------
| Notebook state related styling
|
| The notebook and cells each have states, here are the possibilities:
|
| - Notebook
|   - Command
|   - Edit
| - Cell
|   - None
|   - Active (only one can be active)
|   - Selected (the cells actions are applied to)
|   - Multiselected (when multiple selected, the cursor)
|   - No outputs
|----------------------------------------------------------------------------*/

/* Command or edit modes */

.jp-Notebook .jp-Cell:not(.jp-mod-active) .jp-InputPrompt {
  opacity: var(--jp-cell-prompt-not-active-opacity);
  color: var(--jp-cell-prompt-not-active-font-color);
}

.jp-Notebook .jp-Cell:not(.jp-mod-active) .jp-OutputPrompt {
  opacity: var(--jp-cell-prompt-not-active-opacity);
  color: var(--jp-cell-prompt-not-active-font-color);
}

/* cell is active */
.jp-Notebook .jp-Cell.jp-mod-active .jp-Collapser {
  background: var(--jp-brand-color1);
}

/* cell is dirty */
.jp-Notebook .jp-Cell.jp-mod-dirty .jp-InputPrompt {
  color: var(--jp-warn-color1);
}

.jp-Notebook .jp-Cell.jp-mod-dirty .jp-InputPrompt::before {
  color: var(--jp-warn-color1);
  content: '•';
}

.jp-Notebook .jp-Cell.jp-mod-active.jp-mod-dirty .jp-Collapser {
  background: var(--jp-warn-color1);
}

/* collapser is hovered */
.jp-Notebook .jp-Cell .jp-Collapser:hover {
  box-shadow: var(--jp-elevation-z2);
  background: var(--jp-brand-color1);
  opacity: var(--jp-cell-collapser-not-active-hover-opacity);
}

/* cell is active and collapser is hovered */
.jp-Notebook .jp-Cell.jp-mod-active .jp-Collapser:hover {
  background: var(--jp-brand-color0);
  opacity: 1;
}

/* Command mode */

.jp-Notebook.jp-mod-commandMode .jp-Cell.jp-mod-selected {
  background: var(--jp-notebook-multiselected-color);
}

.jp-Notebook.jp-mod-commandMode
  .jp-Cell.jp-mod-active.jp-mod-selected:not(.jp-mod-multiSelected) {
  background: transparent;
}

/* Edit mode */

.jp-Notebook.jp-mod-editMode .jp-Cell.jp-mod-active .jp-InputArea-editor {
  border: var(--jp-border-width) solid var(--jp-cell-editor-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
  background-color: var(--jp-cell-editor-active-background);
}

/*-----------------------------------------------------------------------------
| Notebook drag and drop
|----------------------------------------------------------------------------*/

.jp-Notebook-cell.jp-mod-dropSource {
  opacity: 0.5;
}

.jp-Notebook-cell.jp-mod-dropTarget,
.jp-Notebook.jp-mod-commandMode
  .jp-Notebook-cell.jp-mod-active.jp-mod-selected.jp-mod-dropTarget {
  border-top-color: var(--jp-private-notebook-selected-color);
  border-top-style: solid;
  border-top-width: 2px;
}

.jp-dragImage {
  display: block;
  flex-direction: row;
  width: var(--jp-private-notebook-dragImage-width);
  height: var(--jp-private-notebook-dragImage-height);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background);
  overflow: visible;
}

.jp-dragImage-singlePrompt {
  box-shadow: 2px 2px 4px 0 rgba(0, 0, 0, 0.12);
}

.jp-dragImage .jp-dragImage-content {
  flex: 1 1 auto;
  z-index: 2;
  font-size: var(--jp-code-font-size);
  font-family: var(--jp-code-font-family);
  line-height: var(--jp-code-line-height);
  padding: var(--jp-code-padding);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background-color);
  color: var(--jp-content-font-color3);
  text-align: left;
  margin: 4px 4px 4px 0;
}

.jp-dragImage .jp-dragImage-prompt {
  flex: 0 0 auto;
  min-width: 36px;
  color: var(--jp-cell-inprompt-font-color);
  padding: var(--jp-code-padding);
  padding-left: 12px;
  font-family: var(--jp-cell-prompt-font-family);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  line-height: 1.9;
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
}

.jp-dragImage-multipleBack {
  z-index: -1;
  position: absolute;
  height: 32px;
  width: 300px;
  top: 8px;
  left: 8px;
  background: var(--jp-layout-color2);
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  box-shadow: 2px 2px 4px 0 rgba(0, 0, 0, 0.12);
}

/*-----------------------------------------------------------------------------
| Cell toolbar
|----------------------------------------------------------------------------*/

.jp-NotebookTools {
  display: block;
  min-width: var(--jp-sidebar-min-width);
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);

  /* This is needed so that all font sizing of children done in ems is
    * relative to this base size */
  font-size: var(--jp-ui-font-size1);
  overflow: auto;
}

.jp-ActiveCellTool {
  padding: 12px 0;
  display: flex;
}

.jp-ActiveCellTool-Content {
  flex: 1 1 auto;
}

.jp-ActiveCellTool .jp-ActiveCellTool-CellContent {
  background: var(--jp-cell-editor-background);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  border-radius: 0;
  min-height: 29px;
}

.jp-ActiveCellTool .jp-InputPrompt {
  min-width: calc(var(--jp-cell-prompt-width) * 0.75);
}

.jp-ActiveCellTool-CellContent > pre {
  padding: 5px 4px;
  margin: 0;
  white-space: normal;
}

.jp-MetadataEditorTool {
  flex-direction: column;
  padding: 12px 0;
}

.jp-RankedPanel > :not(:first-child) {
  margin-top: 12px;
}

.jp-KeySelector select.jp-mod-styled {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  border: var(--jp-border-width) solid var(--jp-border-color1);
}

.jp-KeySelector label,
.jp-MetadataEditorTool label,
.jp-NumberSetter label {
  line-height: 1.4;
}

.jp-NotebookTools .jp-select-wrapper {
  margin-top: 4px;
  margin-bottom: 0;
}

.jp-NumberSetter input {
  width: 100%;
  margin-top: 4px;
}

.jp-NotebookTools .jp-Collapse {
  margin-top: 16px;
}

/*-----------------------------------------------------------------------------
| Presentation Mode (.jp-mod-presentationMode)
|----------------------------------------------------------------------------*/

.jp-mod-presentationMode .jp-Notebook {
  --jp-content-font-size1: var(--jp-content-presentation-font-size1);
  --jp-code-font-size: var(--jp-code-presentation-font-size);
}

.jp-mod-presentationMode .jp-Notebook .jp-Cell .jp-InputPrompt,
.jp-mod-presentationMode .jp-Notebook .jp-Cell .jp-OutputPrompt {
  flex: 0 0 110px;
}

/*-----------------------------------------------------------------------------
| Side-by-side Mode (.jp-mod-sideBySide)
|----------------------------------------------------------------------------*/
.jp-mod-sideBySide.jp-Notebook .jp-Notebook-cell {
  margin-top: 3em;
  margin-bottom: 3em;
  margin-left: 5%;
  margin-right: 5%;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell {
  display: grid;
  grid-template-columns: minmax(0, 1fr) min-content minmax(
      0,
      var(--jp-side-by-side-output-size)
    );
  grid-template-rows: auto minmax(0, 1fr) auto;
  grid-template-areas:
    'header header header'
    'input handle output'
    'footer footer footer';
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell.jp-mod-resizedCell {
  grid-template-columns: minmax(0, 1fr) min-content minmax(
      0,
      var(--jp-side-by-side-resized-cell)
    );
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellHeader {
  grid-area: header;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-Cell-inputWrapper {
  grid-area: input;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-Cell-outputWrapper {
  /* overwrite the default margin (no vertical separation needed in side by side move */
  margin-top: 0;
  grid-area: output;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellFooter {
  grid-area: footer;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellResizeHandle {
  grid-area: handle;
  user-select: none;
  display: block;
  height: 100%;
  cursor: ew-resize;
  padding: 0 var(--jp-cell-padding);
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellResizeHandle::after {
  content: '';
  display: block;
  background: var(--jp-border-color2);
  height: 100%;
  width: 5px;
}

.jp-mod-sideBySide.jp-Notebook
  .jp-CodeCell.jp-mod-resizedCell
  .jp-CellResizeHandle::after {
  background: var(--jp-border-color0);
}

.jp-CellResizeHandle {
  display: none;
}

/*-----------------------------------------------------------------------------
| Placeholder
|----------------------------------------------------------------------------*/

.jp-Cell-Placeholder {
  padding-left: 55px;
}

.jp-Cell-Placeholder-wrapper {
  background: #fff;
  border: 1px solid;
  border-color: #e5e6e9 #dfe0e4 #d0d1d5;
  border-radius: 4px;
  -webkit-border-radius: 4px;
  margin: 10px 15px;
}

.jp-Cell-Placeholder-wrapper-inner {
  padding: 15px;
  position: relative;
}

.jp-Cell-Placeholder-wrapper-body {
  background-repeat: repeat;
  background-size: 50% auto;
}

.jp-Cell-Placeholder-wrapper-body div {
  background: #f6f7f8;
  background-image: -webkit-linear-gradient(
    left,
    #f6f7f8 0%,
    #edeef1 20%,
    #f6f7f8 40%,
    #f6f7f8 100%
  );
  background-repeat: no-repeat;
  background-size: 800px 104px;
  height: 104px;
  position: absolute;
  right: 15px;
  left: 15px;
  top: 15px;
}

div.jp-Cell-Placeholder-h1 {
  top: 20px;
  height: 20px;
  left: 15px;
  width: 150px;
}

div.jp-Cell-Placeholder-h2 {
  left: 15px;
  top: 50px;
  height: 10px;
  width: 100px;
}

div.jp-Cell-Placeholder-content-1,
div.jp-Cell-Placeholder-content-2,
div.jp-Cell-Placeholder-content-3 {
  left: 15px;
  right: 15px;
  height: 10px;
}

div.jp-Cell-Placeholder-content-1 {
  top: 100px;
}

div.jp-Cell-Placeholder-content-2 {
  top: 120px;
}

div.jp-Cell-Placeholder-content-3 {
  top: 140px;
}

</style>
<style type="text/css">
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*
The following CSS variables define the main, public API for styling JupyterLab.
These variables should be used by all plugins wherever possible. In other
words, plugins should not define custom colors, sizes, etc unless absolutely
necessary. This enables users to change the visual theme of JupyterLab
by changing these variables.

Many variables appear in an ordered sequence (0,1,2,3). These sequences
are designed to work well together, so for example, `--jp-border-color1` should
be used with `--jp-layout-color1`. The numbers have the following meanings:

* 0: super-primary, reserved for special emphasis
* 1: primary, most important under normal situations
* 2: secondary, next most important under normal situations
* 3: tertiary, next most important under normal situations

Throughout JupyterLab, we are mostly following principles from Google's
Material Design when selecting colors. We are not, however, following
all of MD as it is not optimized for dense, information rich UIs.
*/

:root {
  /* Elevation
   *
   * We style box-shadows using Material Design's idea of elevation. These particular numbers are taken from here:
   *
   * https://github.com/material-components/material-components-web
   * https://material-components-web.appspot.com/elevation.html
   */

  --jp-shadow-base-lightness: 0;
  --jp-shadow-umbra-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.2
  );
  --jp-shadow-penumbra-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.14
  );
  --jp-shadow-ambient-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.12
  );
  --jp-elevation-z0: none;
  --jp-elevation-z1: 0 2px 1px -1px var(--jp-shadow-umbra-color),
    0 1px 1px 0 var(--jp-shadow-penumbra-color),
    0 1px 3px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z2: 0 3px 1px -2px var(--jp-shadow-umbra-color),
    0 2px 2px 0 var(--jp-shadow-penumbra-color),
    0 1px 5px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z4: 0 2px 4px -1px var(--jp-shadow-umbra-color),
    0 4px 5px 0 var(--jp-shadow-penumbra-color),
    0 1px 10px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z6: 0 3px 5px -1px var(--jp-shadow-umbra-color),
    0 6px 10px 0 var(--jp-shadow-penumbra-color),
    0 1px 18px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z8: 0 5px 5px -3px var(--jp-shadow-umbra-color),
    0 8px 10px 1px var(--jp-shadow-penumbra-color),
    0 3px 14px 2px var(--jp-shadow-ambient-color);
  --jp-elevation-z12: 0 7px 8px -4px var(--jp-shadow-umbra-color),
    0 12px 17px 2px var(--jp-shadow-penumbra-color),
    0 5px 22px 4px var(--jp-shadow-ambient-color);
  --jp-elevation-z16: 0 8px 10px -5px var(--jp-shadow-umbra-color),
    0 16px 24px 2px var(--jp-shadow-penumbra-color),
    0 6px 30px 5px var(--jp-shadow-ambient-color);
  --jp-elevation-z20: 0 10px 13px -6px var(--jp-shadow-umbra-color),
    0 20px 31px 3px var(--jp-shadow-penumbra-color),
    0 8px 38px 7px var(--jp-shadow-ambient-color);
  --jp-elevation-z24: 0 11px 15px -7px var(--jp-shadow-umbra-color),
    0 24px 38px 3px var(--jp-shadow-penumbra-color),
    0 9px 46px 8px var(--jp-shadow-ambient-color);

  /* Borders
   *
   * The following variables, specify the visual styling of borders in JupyterLab.
   */

  --jp-border-width: 1px;
  --jp-border-color0: var(--md-grey-400);
  --jp-border-color1: var(--md-grey-400);
  --jp-border-color2: var(--md-grey-300);
  --jp-border-color3: var(--md-grey-200);
  --jp-inverse-border-color: var(--md-grey-600);
  --jp-border-radius: 2px;

  /* UI Fonts
   *
   * The UI font CSS variables are used for the typography all of the JupyterLab
   * user interface elements that are not directly user generated content.
   *
   * The font sizing here is done assuming that the body font size of --jp-ui-font-size1
   * is applied to a parent element. When children elements, such as headings, are sized
   * in em all things will be computed relative to that body size.
   */

  --jp-ui-font-scale-factor: 1.2;
  --jp-ui-font-size0: 0.83333em;
  --jp-ui-font-size1: 13px; /* Base font size */
  --jp-ui-font-size2: 1.2em;
  --jp-ui-font-size3: 1.44em;
  --jp-ui-font-family: system-ui, -apple-system, blinkmacsystemfont, 'Segoe UI',
    helvetica, arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji',
    'Segoe UI Symbol';

  /*
   * Use these font colors against the corresponding main layout colors.
   * In a light theme, these go from dark to light.
   */

  /* Defaults use Material Design specification */
  --jp-ui-font-color0: rgba(0, 0, 0, 1);
  --jp-ui-font-color1: rgba(0, 0, 0, 0.87);
  --jp-ui-font-color2: rgba(0, 0, 0, 0.54);
  --jp-ui-font-color3: rgba(0, 0, 0, 0.38);

  /*
   * Use these against the brand/accent/warn/error colors.
   * These will typically go from light to darker, in both a dark and light theme.
   */

  --jp-ui-inverse-font-color0: rgba(255, 255, 255, 1);
  --jp-ui-inverse-font-color1: rgba(255, 255, 255, 1);
  --jp-ui-inverse-font-color2: rgba(255, 255, 255, 0.7);
  --jp-ui-inverse-font-color3: rgba(255, 255, 255, 0.5);

  /* Content Fonts
   *
   * Content font variables are used for typography of user generated content.
   *
   * The font sizing here is done assuming that the body font size of --jp-content-font-size1
   * is applied to a parent element. When children elements, such as headings, are sized
   * in em all things will be computed relative to that body size.
   */

  --jp-content-line-height: 1.6;
  --jp-content-font-scale-factor: 1.2;
  --jp-content-font-size0: 0.83333em;
  --jp-content-font-size1: 14px; /* Base font size */
  --jp-content-font-size2: 1.2em;
  --jp-content-font-size3: 1.44em;
  --jp-content-font-size4: 1.728em;
  --jp-content-font-size5: 2.0736em;

  /* This gives a magnification of about 125% in presentation mode over normal. */
  --jp-content-presentation-font-size1: 17px;
  --jp-content-heading-line-height: 1;
  --jp-content-heading-margin-top: 1.2em;
  --jp-content-heading-margin-bottom: 0.8em;
  --jp-content-heading-font-weight: 500;

  /* Defaults use Material Design specification */
  --jp-content-font-color0: rgba(0, 0, 0, 1);
  --jp-content-font-color1: rgba(0, 0, 0, 0.87);
  --jp-content-font-color2: rgba(0, 0, 0, 0.54);
  --jp-content-font-color3: rgba(0, 0, 0, 0.38);
  --jp-content-link-color: var(--md-blue-900);
  --jp-content-font-family: system-ui, -apple-system, blinkmacsystemfont,
    'Segoe UI', helvetica, arial, sans-serif, 'Apple Color Emoji',
    'Segoe UI Emoji', 'Segoe UI Symbol';

  /*
   * Code Fonts
   *
   * Code font variables are used for typography of code and other monospaces content.
   */

  --jp-code-font-size: 13px;
  --jp-code-line-height: 1.3077; /* 17px for 13px base */
  --jp-code-padding: 5px; /* 5px for 13px base, codemirror highlighting needs integer px value */
  --jp-code-font-family-default: menlo, consolas, 'DejaVu Sans Mono', monospace;
  --jp-code-font-family: var(--jp-code-font-family-default);

  /* This gives a magnification of about 125% in presentation mode over normal. */
  --jp-code-presentation-font-size: 16px;

  /* may need to tweak cursor width if you change font size */
  --jp-code-cursor-width0: 1.4px;
  --jp-code-cursor-width1: 2px;
  --jp-code-cursor-width2: 4px;

  /* Layout
   *
   * The following are the main layout colors use in JupyterLab. In a light
   * theme these would go from light to dark.
   */

  --jp-layout-color0: white;
  --jp-layout-color1: white;
  --jp-layout-color2: var(--md-grey-200);
  --jp-layout-color3: var(--md-grey-400);
  --jp-layout-color4: var(--md-grey-600);

  /* Inverse Layout
   *
   * The following are the inverse layout colors use in JupyterLab. In a light
   * theme these would go from dark to light.
   */

  --jp-inverse-layout-color0: #111;
  --jp-inverse-layout-color1: var(--md-grey-900);
  --jp-inverse-layout-color2: var(--md-grey-800);
  --jp-inverse-layout-color3: var(--md-grey-700);
  --jp-inverse-layout-color4: var(--md-grey-600);

  /* Brand/accent */

  --jp-brand-color0: var(--md-blue-900);
  --jp-brand-color1: var(--md-blue-700);
  --jp-brand-color2: var(--md-blue-300);
  --jp-brand-color3: var(--md-blue-100);
  --jp-brand-color4: var(--md-blue-50);
  --jp-accent-color0: var(--md-green-900);
  --jp-accent-color1: var(--md-green-700);
  --jp-accent-color2: var(--md-green-300);
  --jp-accent-color3: var(--md-green-100);

  /* State colors (warn, error, success, info) */

  --jp-warn-color0: var(--md-orange-900);
  --jp-warn-color1: var(--md-orange-700);
  --jp-warn-color2: var(--md-orange-300);
  --jp-warn-color3: var(--md-orange-100);
  --jp-error-color0: var(--md-red-900);
  --jp-error-color1: var(--md-red-700);
  --jp-error-color2: var(--md-red-300);
  --jp-error-color3: var(--md-red-100);
  --jp-success-color0: var(--md-green-900);
  --jp-success-color1: var(--md-green-700);
  --jp-success-color2: var(--md-green-300);
  --jp-success-color3: var(--md-green-100);
  --jp-info-color0: var(--md-cyan-900);
  --jp-info-color1: var(--md-cyan-700);
  --jp-info-color2: var(--md-cyan-300);
  --jp-info-color3: var(--md-cyan-100);

  /* Cell specific styles */

  --jp-cell-padding: 5px;
  --jp-cell-collapser-width: 8px;
  --jp-cell-collapser-min-height: 20px;
  --jp-cell-collapser-not-active-hover-opacity: 0.6;
  --jp-cell-editor-background: var(--md-grey-100);
  --jp-cell-editor-border-color: var(--md-grey-300);
  --jp-cell-editor-box-shadow: inset 0 0 2px var(--md-blue-300);
  --jp-cell-editor-active-background: var(--jp-layout-color0);
  --jp-cell-editor-active-border-color: var(--jp-brand-color1);
  --jp-cell-prompt-width: 64px;
  --jp-cell-prompt-font-family: var(--jp-code-font-family-default);
  --jp-cell-prompt-letter-spacing: 0;
  --jp-cell-prompt-opacity: 1;
  --jp-cell-prompt-not-active-opacity: 0.5;
  --jp-cell-prompt-not-active-font-color: var(--md-grey-700);

  /* A custom blend of MD grey and blue 600
   * See https://meyerweb.com/eric/tools/color-blend/#546E7A:1E88E5:5:hex */
  --jp-cell-inprompt-font-color: #307fc1;

  /* A custom blend of MD grey and orange 600
   * https://meyerweb.com/eric/tools/color-blend/#546E7A:F4511E:5:hex */
  --jp-cell-outprompt-font-color: #bf5b3d;

  /* Notebook specific styles */

  --jp-notebook-padding: 10px;
  --jp-notebook-select-background: var(--jp-layout-color1);
  --jp-notebook-multiselected-color: var(--md-blue-50);

  /* The scroll padding is calculated to fill enough space at the bottom of the
  notebook to show one single-line cell (with appropriate padding) at the top
  when the notebook is scrolled all the way to the bottom. We also subtract one
  pixel so that no scrollbar appears if we have just one single-line cell in the
  notebook. This padding is to enable a 'scroll past end' feature in a notebook.
  */
  --jp-notebook-scroll-padding: calc(
    100% - var(--jp-code-font-size) * var(--jp-code-line-height) -
      var(--jp-code-padding) - var(--jp-cell-padding) - 1px
  );

  /* Rendermime styles */

  --jp-rendermime-error-background: #fdd;
  --jp-rendermime-table-row-background: var(--md-grey-100);
  --jp-rendermime-table-row-hover-background: var(--md-light-blue-50);

  /* Dialog specific styles */

  --jp-dialog-background: rgba(0, 0, 0, 0.25);

  /* Console specific styles */

  --jp-console-padding: 10px;

  /* Toolbar specific styles */

  --jp-toolbar-border-color: var(--jp-border-color1);
  --jp-toolbar-micro-height: 8px;
  --jp-toolbar-background: var(--jp-layout-color1);
  --jp-toolbar-box-shadow: 0 0 2px 0 rgba(0, 0, 0, 0.24);
  --jp-toolbar-header-margin: 4px 4px 0 4px;
  --jp-toolbar-active-background: var(--md-grey-300);

  /* Statusbar specific styles */

  --jp-statusbar-height: 24px;

  /* Input field styles */

  --jp-input-box-shadow: inset 0 0 2px var(--md-blue-300);
  --jp-input-active-background: var(--jp-layout-color1);
  --jp-input-hover-background: var(--jp-layout-color1);
  --jp-input-background: var(--md-grey-100);
  --jp-input-border-color: var(--jp-inverse-border-color);
  --jp-input-active-border-color: var(--jp-brand-color1);
  --jp-input-active-box-shadow-color: rgba(19, 124, 189, 0.3);

  /* General editor styles */

  --jp-editor-selected-background: #d9d9d9;
  --jp-editor-selected-focused-background: #d7d4f0;
  --jp-editor-cursor-color: var(--jp-ui-font-color0);

  /* Code mirror specific styles */

  --jp-mirror-editor-keyword-color: #008000;
  --jp-mirror-editor-atom-color: #88f;
  --jp-mirror-editor-number-color: #080;
  --jp-mirror-editor-def-color: #00f;
  --jp-mirror-editor-variable-color: var(--md-grey-900);
  --jp-mirror-editor-variable-2-color: rgb(0, 54, 109);
  --jp-mirror-editor-variable-3-color: #085;
  --jp-mirror-editor-punctuation-color: #05a;
  --jp-mirror-editor-property-color: #05a;
  --jp-mirror-editor-operator-color: #a2f;
  --jp-mirror-editor-comment-color: #408080;
  --jp-mirror-editor-string-color: #ba2121;
  --jp-mirror-editor-string-2-color: #708;
  --jp-mirror-editor-meta-color: #a2f;
  --jp-mirror-editor-qualifier-color: #555;
  --jp-mirror-editor-builtin-color: #008000;
  --jp-mirror-editor-bracket-color: #997;
  --jp-mirror-editor-tag-color: #170;
  --jp-mirror-editor-attribute-color: #00c;
  --jp-mirror-editor-header-color: blue;
  --jp-mirror-editor-quote-color: #090;
  --jp-mirror-editor-link-color: #00c;
  --jp-mirror-editor-error-color: #f00;
  --jp-mirror-editor-hr-color: #999;

  /*
    RTC user specific colors.
    These colors are used for the cursor, username in the editor,
    and the icon of the user.
  */

  --jp-collaborator-color1: #ffad8e;
  --jp-collaborator-color2: #dac83d;
  --jp-collaborator-color3: #72dd76;
  --jp-collaborator-color4: #00e4d0;
  --jp-collaborator-color5: #45d4ff;
  --jp-collaborator-color6: #e2b1ff;
  --jp-collaborator-color7: #ff9de6;

  /* Vega extension styles */

  --jp-vega-background: white;

  /* Sidebar-related styles */

  --jp-sidebar-min-width: 250px;

  /* Search-related styles */

  --jp-search-toggle-off-opacity: 0.5;
  --jp-search-toggle-hover-opacity: 0.8;
  --jp-search-toggle-on-opacity: 1;
  --jp-search-selected-match-background-color: rgb(245, 200, 0);
  --jp-search-selected-match-color: black;
  --jp-search-unselected-match-background-color: var(
    --jp-inverse-layout-color0
  );
  --jp-search-unselected-match-color: var(--jp-ui-inverse-font-color0);

  /* Icon colors that work well with light or dark backgrounds */
  --jp-icon-contrast-color0: var(--md-purple-600);
  --jp-icon-contrast-color1: var(--md-green-600);
  --jp-icon-contrast-color2: var(--md-pink-600);
  --jp-icon-contrast-color3: var(--md-blue-600);

  /* Button colors */
  --jp-accept-color-normal: var(--md-blue-700);
  --jp-accept-color-hover: var(--md-blue-800);
  --jp-accept-color-active: var(--md-blue-900);
  --jp-warn-color-normal: var(--md-red-700);
  --jp-warn-color-hover: var(--md-red-800);
  --jp-warn-color-active: var(--md-red-900);
  --jp-reject-color-normal: var(--md-grey-600);
  --jp-reject-color-hover: var(--md-grey-700);
  --jp-reject-color-active: var(--md-grey-800);

  /* File or activity icons and switch semantic variables */
  --jp-jupyter-icon-color: #f37626;
  --jp-notebook-icon-color: #f37626;
  --jp-json-icon-color: var(--md-orange-700);
  --jp-console-icon-background-color: var(--md-blue-700);
  --jp-console-icon-color: white;
  --jp-terminal-icon-background-color: var(--md-grey-800);
  --jp-terminal-icon-color: var(--md-grey-200);
  --jp-text-editor-icon-color: var(--md-grey-700);
  --jp-inspector-icon-color: var(--md-grey-700);
  --jp-switch-color: var(--md-grey-400);
  --jp-switch-true-position-color: var(--md-orange-900);
}
</style>
<style type="text/css">
/* Force rendering true colors when outputing to pdf */
* {
  -webkit-print-color-adjust: exact;
}

/* Misc */
a.anchor-link {
  display: none;
}

/* Input area styling */
.jp-InputArea {
  overflow: hidden;
}

.jp-InputArea-editor {
  overflow: hidden;
}

.cm-editor.cm-s-jupyter .highlight pre {
/* weird, but --jp-code-padding defined to be 5px but 4px horizontal padding is hardcoded for pre.cm-line */
  padding: var(--jp-code-padding) 4px;
  margin: 0;

  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
  color: inherit;

}

.jp-OutputArea-output pre {
  line-height: inherit;
  font-family: inherit;
}

.jp-RenderedText pre {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-code-font-size);
}

/* Hiding the collapser by default */
.jp-Collapser {
  display: none;
}

@page {
    margin: 0.5in; /* Margin for each printed piece of paper */
}

@media print {
  .jp-Cell-inputWrapper,
  .jp-Cell-outputWrapper {
    display: block;
  }
}
</style>
<!-- Load mathjax -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML-full,Safe"> </script>
<!-- MathJax configuration -->
<script type="text/x-mathjax-config">
    init_mathjax = function() {
        if (window.MathJax) {
        // MathJax loaded
            MathJax.Hub.Config({
                TeX: {
                    equationNumbers: {
                    autoNumber: "AMS",
                    useLabelIds: true
                    }
                },
                tex2jax: {
                    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                    processEscapes: true,
                    processEnvironments: true
                },
                displayAlign: 'center',
                CommonHTML: {
                    linebreaks: {
                    automatic: true
                    }
                }
            });

            MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
        }
    }
    init_mathjax();
    </script>
<!-- End of mathjax configuration --><script type="module">
  document.addEventListener("DOMContentLoaded", async () => {
    const diagrams = document.querySelectorAll(".jp-Mermaid > pre.mermaid");
    // do not load mermaidjs if not needed
    if (!diagrams.length) {
      return;
    }
    const mermaid = (await import("https://cdnjs.cloudflare.com/ajax/libs/mermaid/10.7.0/mermaid.esm.min.mjs")).default;
    const parser = new DOMParser();

    mermaid.initialize({
      maxTextSize: 100000,
      maxEdges: 100000,
      startOnLoad: false,
      fontFamily: window
        .getComputedStyle(document.body)
        .getPropertyValue("--jp-ui-font-family"),
      theme: document.querySelector("body[data-jp-theme-light='true']")
        ? "default"
        : "dark",
    });

    let _nextMermaidId = 0;

    function makeMermaidImage(svg) {
      const img = document.createElement("img");
      const doc = parser.parseFromString(svg, "image/svg+xml");
      const svgEl = doc.querySelector("svg");
      const { maxWidth } = svgEl?.style || {};
      const firstTitle = doc.querySelector("title");
      const firstDesc = doc.querySelector("desc");

      img.setAttribute("src", `data:image/svg+xml,${encodeURIComponent(svg)}`);
      if (maxWidth) {
        img.width = parseInt(maxWidth);
      }
      if (firstTitle) {
        img.setAttribute("alt", firstTitle.textContent);
      }
      if (firstDesc) {
        const caption = document.createElement("figcaption");
        caption.className = "sr-only";
        caption.textContent = firstDesc.textContent;
        return [img, caption];
      }
      return [img];
    }

    async function makeMermaidError(text) {
      let errorMessage = "";
      try {
        await mermaid.parse(text);
      } catch (err) {
        errorMessage = `${err}`;
      }

      const result = document.createElement("details");
      result.className = 'jp-RenderedMermaid-Details';
      const summary = document.createElement("summary");
      summary.className = 'jp-RenderedMermaid-Summary';
      const pre = document.createElement("pre");
      const code = document.createElement("code");
      code.innerText = text;
      pre.appendChild(code);
      summary.appendChild(pre);
      result.appendChild(summary);

      const warning = document.createElement("pre");
      warning.innerText = errorMessage;
      result.appendChild(warning);
      return [result];
    }

    async function renderOneMarmaid(src) {
      const id = `jp-mermaid-${_nextMermaidId++}`;
      const parent = src.parentNode;
      let raw = src.textContent.trim();
      const el = document.createElement("div");
      el.style.visibility = "hidden";
      document.body.appendChild(el);
      let results = null;
      let output = null;
      try {
        let { svg } = await mermaid.render(id, raw, el);
        svg = cleanMermaidSvg(svg);
        results = makeMermaidImage(svg);
        output = document.createElement("figure");
        results.map(output.appendChild, output);
      } catch (err) {
        parent.classList.add("jp-mod-warning");
        results = await makeMermaidError(raw);
        output = results[0];
      } finally {
        el.remove();
      }
      parent.classList.add("jp-RenderedMermaid");
      parent.appendChild(output);
    }


    /**
     * Post-process to ensure mermaid diagrams contain only valid SVG and XHTML.
     */
    function cleanMermaidSvg(svg) {
      return svg.replace(RE_VOID_ELEMENT, replaceVoidElement);
    }


    /**
     * A regular expression for all void elements, which may include attributes and
     * a slash.
     *
     * @see https://developer.mozilla.org/en-US/docs/Glossary/Void_element
     *
     * Of these, only `<br>` is generated by Mermaid in place of `\n`,
     * but _any_ "malformed" tag will break the SVG rendering entirely.
     */
    const RE_VOID_ELEMENT =
      /<\s*(area|base|br|col|embed|hr|img|input|link|meta|param|source|track|wbr)\s*([^>]*?)\s*>/gi;

    /**
     * Ensure a void element is closed with a slash, preserving any attributes.
     */
    function replaceVoidElement(match, tag, rest) {
      rest = rest.trim();
      if (!rest.endsWith('/')) {
        rest = `${rest} /`;
      }
      return `<${tag} ${rest}>`;
    }

    void Promise.all([...diagrams].map(renderOneMarmaid));
  });
</script>
<style>
  .jp-Mermaid:not(.jp-RenderedMermaid) {
    display: none;
  }

  .jp-RenderedMermaid {
    overflow: auto;
    display: flex;
  }

  .jp-RenderedMermaid.jp-mod-warning {
    width: auto;
    padding: 0.5em;
    margin-top: 0.5em;
    border: var(--jp-border-width) solid var(--jp-warn-color2);
    border-radius: var(--jp-border-radius);
    color: var(--jp-ui-font-color1);
    font-size: var(--jp-ui-font-size1);
    white-space: pre-wrap;
    word-wrap: break-word;
  }

  .jp-RenderedMermaid figure {
    margin: 0;
    overflow: auto;
    max-width: 100%;
  }

  .jp-RenderedMermaid img {
    max-width: 100%;
  }

  .jp-RenderedMermaid-Details > pre {
    margin-top: 1em;
  }

  .jp-RenderedMermaid-Summary {
    color: var(--jp-warn-color2);
  }

  .jp-RenderedMermaid:not(.jp-mod-warning) pre {
    display: none;
  }

  .jp-RenderedMermaid-Summary > pre {
    display: inline-block;
    white-space: normal;
  }
</style>
<!-- End of mermaid configuration --></head>
<body class="jp-Notebook" data-jp-theme-light="true" data-jp-theme-name="JupyterLab Light">
<main>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p><a href="https://colab.research.google.com/github/zphilip/zphilip.github.io/blob/main/Inspect_BERT_Vocabulary.ipynb" target="_parent"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg"/></a></p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Load-the-Model">Load the Model<a class="anchor-link" href="#Load-the-Model">¶</a></h2>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>Install the huggingface implementation.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [2]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>pytorch-pretrained-bert
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Requirement already satisfied: pytorch-pretrained-bert in /usr/local/lib/python3.10/dist-packages (0.6.2)
Requirement already satisfied: torch&gt;=0.4.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-bert) (2.0.0+cu118)
Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-bert) (1.22.4)
Requirement already satisfied: boto3 in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-bert) (1.26.133)
Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-bert) (2.27.1)
Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-bert) (4.65.0)
Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-bert) (2022.10.31)
Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch&gt;=0.4.1-&gt;pytorch-pretrained-bert) (3.12.0)
Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch&gt;=0.4.1-&gt;pytorch-pretrained-bert) (4.5.0)
Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch&gt;=0.4.1-&gt;pytorch-pretrained-bert) (1.11.1)
Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch&gt;=0.4.1-&gt;pytorch-pretrained-bert) (3.1)
Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch&gt;=0.4.1-&gt;pytorch-pretrained-bert) (3.1.2)
Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch&gt;=0.4.1-&gt;pytorch-pretrained-bert) (2.0.0)
Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0-&gt;torch&gt;=0.4.1-&gt;pytorch-pretrained-bert) (3.25.2)
Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0-&gt;torch&gt;=0.4.1-&gt;pytorch-pretrained-bert) (16.0.3)
Requirement already satisfied: botocore&lt;1.30.0,&gt;=1.29.133 in /usr/local/lib/python3.10/dist-packages (from boto3-&gt;pytorch-pretrained-bert) (1.29.133)
Requirement already satisfied: jmespath&lt;2.0.0,&gt;=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3-&gt;pytorch-pretrained-bert) (1.0.1)
Requirement already satisfied: s3transfer&lt;0.7.0,&gt;=0.6.0 in /usr/local/lib/python3.10/dist-packages (from boto3-&gt;pytorch-pretrained-bert) (0.6.1)
Requirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;pytorch-pretrained-bert) (1.26.15)
Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;pytorch-pretrained-bert) (2022.12.7)
Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;pytorch-pretrained-bert) (2.0.12)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;pytorch-pretrained-bert) (3.4)
Requirement already satisfied: python-dateutil&lt;3.0.0,&gt;=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore&lt;1.30.0,&gt;=1.29.133-&gt;boto3-&gt;pytorch-pretrained-bert) (2.8.2)
Requirement already satisfied: MarkupSafe&gt;=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-&gt;torch&gt;=0.4.1-&gt;pytorch-pretrained-bert) (2.1.2)
Requirement already satisfied: mpmath&gt;=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy-&gt;torch&gt;=0.4.1-&gt;pytorch-pretrained-bert) (1.3.0)
Requirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil&lt;3.0.0,&gt;=2.1-&gt;botocore&lt;1.30.0,&gt;=1.29.133-&gt;boto3-&gt;pytorch-pretrained-bert) (1.16.0)
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [3]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">pytorch_pretrained_bert</span> <span class="kn">import</span> <span class="n">BertTokenizer</span>

<span class="c1"># Load pre-trained model tokenizer (vocabulary)</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">BertTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">'bert-base-uncased'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>100%|██████████| 231508/231508 [00:00&lt;00:00, 3719237.97B/s]
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Inspect-BERT-Vocabulary">Inspect BERT Vocabulary<a class="anchor-link" href="#Inspect-BERT-Vocabulary">¶</a></h2><hr/>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="Vocab-Dump">Vocab Dump<a class="anchor-link" href="#Vocab-Dump">¶</a></h3><hr/>
<p>Retrieve the entire list of "tokens" and write these out to text files so we can peruse them.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [32]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">"vocabulary.txt"</span><span class="p">,</span> <span class="s1">'w'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    
    <span class="c1"># For each token...</span>
    <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        
        <span class="c1"># Write it out and escape any unicode characters.            </span>
        <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">token</span> <span class="o">+</span> <span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>From perusing the vocab, I'm seeing that:</p>
<ul>
<li>The first 999 tokens (1-indexed) appear to be reserved, and most are of the form [unused957].<ul>
<li>1   - [PAD]</li>
<li>101 - [UNK]</li>
<li>102 - [CLS]</li>
<li>103 - [SEP]</li>
<li>104 - [MASK]</li>
</ul>
</li>
<li>Rows 1000-1996 appear to be a dump of individual characters.<ul>
<li>They don't appear to be sorted by frequency (e.g., the letters of the alphabet are all in sequence).</li>
</ul>
</li>
<li>The first word is "the" at position 1997.<ul>
<li>From there, the words appear to be sorted by frequency.</li>
<li>The top ~18 words are whole words, and then number 2016 is ##s, presumably the most common subword.</li>
<li>The last whole word is at 29612, "necessitated"</li>
</ul>
</li>
</ul>
<p>Some funny inclusions:</p>
<ul>
<li>starbucks</li>
<li>triassic</li>
<li>abolitionist</li>
<li>1679</li>
</ul>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="Single-Characters">Single Characters<a class="anchor-link" href="#Single-Characters">¶</a></h3><hr/>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>The following code prints out all of the single character tokens in vocabulary, as well as all of the single-character tokens preceded by '##'.</p>
<p>It turns out that these are matching sets--for every standalone character there is also a '##' version. There are 997 single character tokens.</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>The following cell iterates over the vocabulary, pulling out all of the single character tokens.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [33]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">one_chars</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">one_chars_hashes</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># For each token in the vocabulary...</span>
<span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
    
    <span class="c1"># Record any single-character tokens.</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">token</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">one_chars</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">token</span><span class="p">)</span>
    
    <span class="c1"># Record single-character tokens preceded by the two hashes.    </span>
    <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">token</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span> <span class="ow">and</span> <span class="n">token</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">]</span> <span class="o">==</span> <span class="s1">'##'</span><span class="p">:</span>
        <span class="n">one_chars_hashes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">token</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [34]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">'Number of single character tokens:'</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">one_chars</span><span class="p">),</span> <span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>

<span class="c1"># Print all of the single characters, 40 per row.</span>

<span class="c1"># For every batch of 40 tokens...</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">one_chars</span><span class="p">),</span> <span class="mi">40</span><span class="p">):</span>
    
    <span class="c1"># Limit the end index so we don't go past the end of the list.</span>
    <span class="n">end</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">40</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">one_chars</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    
    <span class="c1"># Print out the tokens, separated by a space.</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">' '</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">one_chars</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">end</span><span class="p">]))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Number of single character tokens: 997 

! " # $ % &amp; ' ( ) * + , - . / 0 1 2 3 4 5 6 7 8 9 : ; &lt; = &gt; ? @ [ \ ] ^ _ ` a b
c d e f g h i j k l m n o p q r s t u v w x y z { | } ~ ¡ ¢ £ ¤ ¥ ¦ § ¨ © ª « ¬
® ° ± ² ³ ´ µ ¶ · ¹ º » ¼ ½ ¾ ¿ × ß æ ð ÷ ø þ đ ħ ı ł ŋ œ ƒ ɐ ɑ ɒ ɔ ɕ ə ɛ ɡ ɣ ɨ
ɪ ɫ ɬ ɯ ɲ ɴ ɹ ɾ ʀ ʁ ʂ ʃ ʉ ʊ ʋ ʌ ʎ ʐ ʑ ʒ ʔ ʰ ʲ ʳ ʷ ʸ ʻ ʼ ʾ ʿ ˈ ː ˡ ˢ ˣ ˤ α β γ δ
ε ζ η θ ι κ λ μ ν ξ ο π ρ ς σ τ υ φ χ ψ ω а б в г д е ж з и к л м н о п р с т у
ф х ц ч ш щ ъ ы ь э ю я ђ є і ј љ њ ћ ӏ ա բ գ դ ե թ ի լ կ հ մ յ ն ո պ ս վ տ ր ւ
ք ־ א ב ג ד ה ו ז ח ט י ך כ ל ם מ ן נ ס ע ף פ ץ צ ק ר ש ת ، ء ا ب ة ت ث ج ح خ د
ذ ر ز س ش ص ض ط ظ ع غ ـ ف ق ك ل م ن ه و ى ي ٹ پ چ ک گ ں ھ ہ ی ے अ आ उ ए क ख ग च
ज ट ड ण त थ द ध न प ब भ म य र ल व श ष स ह ा ि ी ो । ॥ ং অ আ ই উ এ ও ক খ গ চ ছ জ
ট ড ণ ত থ দ ধ ন প ব ভ ম য র ল শ ষ স হ া ি ী ে க ச ட த ந ன ப ம ய ர ல ள வ ா ி ு ே
ை ನ ರ ಾ ක ය ර ල ව ා ก ง ต ท น พ ม ย ร ล ว ส อ า เ ་ ། ག ང ད ན པ བ མ འ ར ལ ས မ ა
ბ გ დ ე ვ თ ი კ ლ მ ნ ო რ ს ტ უ ᄀ ᄂ ᄃ ᄅ ᄆ ᄇ ᄉ ᄊ ᄋ ᄌ ᄎ ᄏ ᄐ ᄑ ᄒ ᅡ ᅢ ᅥ ᅦ ᅧ ᅩ ᅪ ᅭ ᅮ
ᅯ ᅲ ᅳ ᅴ ᅵ ᆨ ᆫ ᆯ ᆷ ᆸ ᆼ ᴬ ᴮ ᴰ ᴵ ᴺ ᵀ ᵃ ᵇ ᵈ ᵉ ᵍ ᵏ ᵐ ᵒ ᵖ ᵗ ᵘ ᵢ ᵣ ᵤ ᵥ ᶜ ᶠ ‐ ‑ ‒ – — ―
‖ ‘ ’ ‚ “ ” „ † ‡ • … ‰ ′ ″ › ‿ ⁄ ⁰ ⁱ ⁴ ⁵ ⁶ ⁷ ⁸ ⁹ ⁺ ⁻ ⁿ ₀ ₁ ₂ ₃ ₄ ₅ ₆ ₇ ₈ ₉ ₊ ₍
₎ ₐ ₑ ₒ ₓ ₕ ₖ ₗ ₘ ₙ ₚ ₛ ₜ ₤ ₩ € ₱ ₹ ℓ № ℝ ™ ⅓ ⅔ ← ↑ → ↓ ↔ ↦ ⇄ ⇌ ⇒ ∂ ∅ ∆ ∇ ∈ − ∗
∘ √ ∞ ∧ ∨ ∩ ∪ ≈ ≡ ≤ ≥ ⊂ ⊆ ⊕ ⊗ ⋅ ─ │ ■ ▪ ● ★ ☆ ☉ ♠ ♣ ♥ ♦ ♭ ♯ ⟨ ⟩ ⱼ ⺩ ⺼ ⽥ 、 。 〈 〉
《 》 「 」 『 』 〜 あ い う え お か き く け こ さ し す せ そ た ち っ つ て と な に ぬ ね の は ひ ふ へ ほ ま み
む め も や ゆ よ ら り る れ ろ を ん ァ ア ィ イ ウ ェ エ オ カ キ ク ケ コ サ シ ス セ タ チ ッ ツ テ ト ナ ニ ノ ハ
ヒ フ ヘ ホ マ ミ ム メ モ ャ ュ ョ ラ リ ル レ ロ ワ ン ・ ー 一 三 上 下 不 世 中 主 久 之 也 事 二 五 井 京 人 亻 仁
介 代 仮 伊 会 佐 侍 保 信 健 元 光 八 公 内 出 分 前 劉 力 加 勝 北 区 十 千 南 博 原 口 古 史 司 合 吉 同 名 和 囗 四
国 國 土 地 坂 城 堂 場 士 夏 外 大 天 太 夫 奈 女 子 学 宀 宇 安 宗 定 宣 宮 家 宿 寺 將 小 尚 山 岡 島 崎 川 州 巿 帝
平 年 幸 广 弘 張 彳 後 御 德 心 忄 志 忠 愛 成 我 戦 戸 手 扌 政 文 新 方 日 明 星 春 昭 智 曲 書 月 有 朝 木 本 李 村
東 松 林 森 楊 樹 橋 歌 止 正 武 比 氏 民 水 氵 氷 永 江 沢 河 治 法 海 清 漢 瀬 火 版 犬 王 生 田 男 疒 発 白 的 皇 目
相 省 真 石 示 社 神 福 禾 秀 秋 空 立 章 竹 糹 美 義 耳 良 艹 花 英 華 葉 藤 行 街 西 見 訁 語 谷 貝 貴 車 軍 辶 道 郎
郡 部 都 里 野 金 鈴 镇 長 門 間 阝 阿 陳 陽 雄 青 面 風 食 香 馬 高 龍 龸 ﬁ ﬂ ！ （ ） ， － ． ／ ： ？ ～
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [35]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">'Number of single character tokens with hashes:'</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">one_chars_hashes</span><span class="p">),</span> <span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>

<span class="c1"># Print all of the single characters, 40 per row.</span>

<span class="c1"># Strip the hash marks, since they just clutter the display.</span>
<span class="n">tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">token</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">'##'</span><span class="p">,</span> <span class="s1">''</span><span class="p">)</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">one_chars_hashes</span><span class="p">]</span>

<span class="c1"># For every batch of 40 tokens...</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">),</span> <span class="mi">40</span><span class="p">):</span>
    
    <span class="c1"># Limit the end index so we don't go past the end of the list.</span>
    <span class="n">end</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">40</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    
    <span class="c1"># Print out the tokens, separated by a space.</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">' '</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tokens</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">end</span><span class="p">]))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Number of single character tokens with hashes: 997 

s a e i n o d r y t l m u h k c g p 2 z 1 b 3 f 4 6 7 x v 8 5 9 0 w j q ° ₂ а и
² ₃ ı ₁ ⁺ ½ о ه ي α е د ن ν ø р ₄ ₀ ر я ³ ι ł н ᵢ ₙ ß ة ς م − т ː ل ь к ♭ η ی в
ا × ¹ ы ה ɛ л ! " # $ % &amp; ' ( ) * + , - . / : ; &lt; = &gt; ? @ [ \ ] ^ _ ` { | } ~ ¡
¢ £ ¤ ¥ ¦ § ¨ © ª « ¬ ® ± ´ µ ¶ · º » ¼ ¾ ¿ æ ð ÷ þ đ ħ ŋ œ ƒ ɐ ɑ ɒ ɔ ɕ ə ɡ ɣ ɨ
ɪ ɫ ɬ ɯ ɲ ɴ ɹ ɾ ʀ ʁ ʂ ʃ ʉ ʊ ʋ ʌ ʎ ʐ ʑ ʒ ʔ ʰ ʲ ʳ ʷ ʸ ʻ ʼ ʾ ʿ ˈ ˡ ˢ ˣ ˤ β γ δ ε ζ
θ κ λ μ ξ ο π ρ σ τ υ φ χ ψ ω б г д ж з м п с у ф х ц ч ш щ ъ э ю ђ є і ј љ њ ћ
ӏ ա բ գ դ ե թ ի լ կ հ մ յ ն ո պ ս վ տ ր ւ ք ־ א ב ג ד ו ז ח ט י ך כ ל ם מ ן נ ס
ע ף פ ץ צ ק ר ש ת ، ء ب ت ث ج ح خ ذ ز س ش ص ض ط ظ ع غ ـ ف ق ك و ى ٹ پ چ ک گ ں ھ
ہ ے अ आ उ ए क ख ग च ज ट ड ण त थ द ध न प ब भ म य र ल व श ष स ह ा ि ी ो । ॥ ং অ আ
ই উ এ ও ক খ গ চ ছ জ ট ড ণ ত থ দ ধ ন প ব ভ ম য র ল শ ষ স হ া ি ী ে க ச ட த ந ன ப
ம ய ர ல ள வ ா ி ு ே ை ನ ರ ಾ ක ය ර ල ව ා ก ง ต ท น พ ม ย ร ล ว ส อ า เ ་ ། ག ང ད
ན པ བ མ འ ར ལ ས မ ა ბ გ დ ე ვ თ ი კ ლ მ ნ ო რ ს ტ უ ᄀ ᄂ ᄃ ᄅ ᄆ ᄇ ᄉ ᄊ ᄋ ᄌ ᄎ ᄏ ᄐ ᄑ
ᄒ ᅡ ᅢ ᅥ ᅦ ᅧ ᅩ ᅪ ᅭ ᅮ ᅯ ᅲ ᅳ ᅴ ᅵ ᆨ ᆫ ᆯ ᆷ ᆸ ᆼ ᴬ ᴮ ᴰ ᴵ ᴺ ᵀ ᵃ ᵇ ᵈ ᵉ ᵍ ᵏ ᵐ ᵒ ᵖ ᵗ ᵘ ᵣ ᵤ
ᵥ ᶜ ᶠ ‐ ‑ ‒ – — ― ‖ ‘ ’ ‚ “ ” „ † ‡ • … ‰ ′ ″ › ‿ ⁄ ⁰ ⁱ ⁴ ⁵ ⁶ ⁷ ⁸ ⁹ ⁻ ⁿ ₅ ₆ ₇ ₈
₉ ₊ ₍ ₎ ₐ ₑ ₒ ₓ ₕ ₖ ₗ ₘ ₚ ₛ ₜ ₤ ₩ € ₱ ₹ ℓ № ℝ ™ ⅓ ⅔ ← ↑ → ↓ ↔ ↦ ⇄ ⇌ ⇒ ∂ ∅ ∆ ∇ ∈
∗ ∘ √ ∞ ∧ ∨ ∩ ∪ ≈ ≡ ≤ ≥ ⊂ ⊆ ⊕ ⊗ ⋅ ─ │ ■ ▪ ● ★ ☆ ☉ ♠ ♣ ♥ ♦ ♯ ⟨ ⟩ ⱼ ⺩ ⺼ ⽥ 、 。 〈 〉
《 》 「 」 『 』 〜 あ い う え お か き く け こ さ し す せ そ た ち っ つ て と な に ぬ ね の は ひ ふ へ ほ ま み
む め も や ゆ よ ら り る れ ろ を ん ァ ア ィ イ ウ ェ エ オ カ キ ク ケ コ サ シ ス セ タ チ ッ ツ テ ト ナ ニ ノ ハ
ヒ フ ヘ ホ マ ミ ム メ モ ャ ュ ョ ラ リ ル レ ロ ワ ン ・ ー 一 三 上 下 不 世 中 主 久 之 也 事 二 五 井 京 人 亻 仁
介 代 仮 伊 会 佐 侍 保 信 健 元 光 八 公 内 出 分 前 劉 力 加 勝 北 区 十 千 南 博 原 口 古 史 司 合 吉 同 名 和 囗 四
国 國 土 地 坂 城 堂 場 士 夏 外 大 天 太 夫 奈 女 子 学 宀 宇 安 宗 定 宣 宮 家 宿 寺 將 小 尚 山 岡 島 崎 川 州 巿 帝
平 年 幸 广 弘 張 彳 後 御 德 心 忄 志 忠 愛 成 我 戦 戸 手 扌 政 文 新 方 日 明 星 春 昭 智 曲 書 月 有 朝 木 本 李 村
東 松 林 森 楊 樹 橋 歌 止 正 武 比 氏 民 水 氵 氷 永 江 沢 河 治 法 海 清 漢 瀬 火 版 犬 王 生 田 男 疒 発 白 的 皇 目
相 省 真 石 示 社 神 福 禾 秀 秋 空 立 章 竹 糹 美 義 耳 良 艹 花 英 華 葉 藤 行 街 西 見 訁 語 谷 貝 貴 車 軍 辶 道 郎
郡 部 都 里 野 金 鈴 镇 長 門 間 阝 阿 陳 陽 雄 青 面 風 食 香 馬 高 龍 龸 ﬁ ﬂ ！ （ ） ， － ． ／ ： ？ ～
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [36]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">'Are the two sets identical?'</span><span class="p">,</span> <span class="nb">set</span><span class="p">(</span><span class="n">one_chars</span><span class="p">)</span> <span class="o">==</span> <span class="nb">set</span><span class="p">(</span><span class="n">tokens</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Are the two sets identical? True
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="Subwords-vs.-Whole-words">Subwords vs. Whole-words<a class="anchor-link" href="#Subwords-vs.-Whole-words">¶</a></h3><p>Let's gather some statistics on the vocabulary.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [79]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>--upgrade<span class="w"> </span>matplotlib
<span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>-U<span class="w"> </span>seaborn
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)
Requirement already satisfied: contourpy&gt;=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.0.7)
Requirement already satisfied: cycler&gt;=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.11.0)
Requirement already satisfied: fonttools&gt;=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.39.3)
Requirement already satisfied: kiwisolver&gt;=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.4)
Requirement already satisfied: numpy&gt;=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.22.4)
Requirement already satisfied: packaging&gt;=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.1)
Requirement already satisfied: pillow&gt;=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (8.4.0)
Requirement already satisfied: pyparsing&gt;=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.0.9)
Requirement already satisfied: python-dateutil&gt;=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)
Requirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil&gt;=2.7-&gt;matplotlib) (1.16.0)
Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.12.2)
Requirement already satisfied: numpy!=1.24.0,&gt;=1.17 in /usr/local/lib/python3.10/dist-packages (from seaborn) (1.22.4)
Requirement already satisfied: pandas&gt;=0.25 in /usr/local/lib/python3.10/dist-packages (from seaborn) (1.5.3)
Requirement already satisfied: matplotlib!=3.6.1,&gt;=3.1 in /usr/local/lib/python3.10/dist-packages (from seaborn) (3.7.1)
Requirement already satisfied: contourpy&gt;=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,&gt;=3.1-&gt;seaborn) (1.0.7)
Requirement already satisfied: cycler&gt;=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,&gt;=3.1-&gt;seaborn) (0.11.0)
Requirement already satisfied: fonttools&gt;=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,&gt;=3.1-&gt;seaborn) (4.39.3)
Requirement already satisfied: kiwisolver&gt;=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,&gt;=3.1-&gt;seaborn) (1.4.4)
Requirement already satisfied: packaging&gt;=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,&gt;=3.1-&gt;seaborn) (23.1)
Requirement already satisfied: pillow&gt;=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,&gt;=3.1-&gt;seaborn) (8.4.0)
Requirement already satisfied: pyparsing&gt;=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,&gt;=3.1-&gt;seaborn) (3.0.9)
Requirement already satisfied: python-dateutil&gt;=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,&gt;=3.1-&gt;seaborn) (2.8.2)
Requirement already satisfied: pytz&gt;=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas&gt;=0.25-&gt;seaborn) (2022.7.1)
Requirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil&gt;=2.7-&gt;matplotlib!=3.6.1,&gt;=3.1-&gt;seaborn) (1.16.0)
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [86]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="s1">'darkgrid'</span><span class="p">)</span>

<span class="c1"># Increase the plot size and font size.</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s2">"figure.figsize"</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>

<span class="c1"># Measure the length of every token in the vocab.</span>
<span class="n">token_lengths</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">token</span><span class="p">)</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span><span class="o">.</span><span class="n">keys</span><span class="p">()]</span>

<span class="c1"># Plot the number of tokens of each length.</span>
<span class="c1">#sns.countplot(token_lengths)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">token_lengths</span><span class="p">,</span><span class="n">linewidth</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s2">"white"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Vocab Token Lengths'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Token Length'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'# of Tokens'</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">'Maximum token length:'</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="n">token_lengths</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Maximum token length: 18
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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
"/>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>Let's look at just the tokens which begin with '##'.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [87]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">num_subwords</span> <span class="o">=</span> <span class="mi">0</span>

<span class="n">subword_lengths</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># For each token in the vocabulary...</span>
<span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
    
    <span class="c1"># If it's a subword...</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">token</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">2</span> <span class="ow">and</span> <span class="n">token</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">]</span> <span class="o">==</span> <span class="s1">'##'</span><span class="p">:</span>
        
        <span class="c1"># Tally all subwords</span>
        <span class="n">num_subwords</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="c1"># Measure the sub word length (without the hashes)</span>
        <span class="n">length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">token</span><span class="p">)</span> <span class="o">-</span> <span class="mi">2</span>

        <span class="c1"># Record the lengths.        </span>
        <span class="n">subword_lengths</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">length</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>How many '##' tokens are there vs. the full vocab?</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [88]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">vocab_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">'Number of subwords: </span><span class="si">{:,}</span><span class="s1"> of </span><span class="si">{:,}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">num_subwords</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">))</span>

<span class="c1"># Calculate the percentage of words that are '##' subwords.</span>
<span class="n">prcnt</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">num_subwords</span><span class="p">)</span> <span class="o">/</span> <span class="n">vocab_size</span> <span class="o">*</span> <span class="mf">100.0</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="si">%.1f%%</span><span class="s1">'</span> <span class="o">%</span> <span class="n">prcnt</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Number of subwords: 5,828 of 30,522
19.1%
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>Plot the subword lengths (not including the two '##' characters).</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [91]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">subword_lengths</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">subword_lengths</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Subword Token Lengths (w/o "##")'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Subword Length'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'# of ## Subwords'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[91]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>Text(0, 0.5, '# of ## Subwords')</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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
"/>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="Misspellings">Misspellings<a class="anchor-link" href="#Misspellings">¶</a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [92]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="s1">'misspelled'</span> <span class="ow">in</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span> <span class="c1"># Right</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[92]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>False</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [42]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="s1">'mispelled'</span> <span class="ow">in</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span> <span class="c1"># Wrong</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[42]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>False</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [43]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="s1">'government'</span> <span class="ow">in</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span> <span class="c1"># Right</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[43]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>True</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [44]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="s1">'goverment'</span> <span class="ow">in</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span> <span class="c1"># Wrong</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[44]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>False</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [45]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="s1">'beginning'</span> <span class="ow">in</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span> <span class="c1"># Right</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[45]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>True</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [46]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="s1">'begining'</span> <span class="ow">in</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span> <span class="c1"># Wrong</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[46]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>False</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [47]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="s1">'separate'</span> <span class="ow">in</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span> <span class="c1"># Right</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[47]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>True</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [48]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="s1">'seperate'</span> <span class="ow">in</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span> <span class="c1"># Wrong</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[48]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>False</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>What about contractions?</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [49]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="s2">"can't"</span> <span class="ow">in</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[49]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>False</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [93]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="s2">"cannot"</span> <span class="ow">in</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[93]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>True</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [50]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="s2">"cant"</span> <span class="ow">in</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[50]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>False</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="Start-vs.-Mid-Subwords">Start vs. Mid Subwords<a class="anchor-link" href="#Start-vs.-Mid-Subwords">¶</a></h3><p>For single characters, there are both the individual character and the '##' version for every character. Is the same true of subwords?</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [51]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># For each token in the vocabulary...</span>
<span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
    
    <span class="c1"># If it's a subword...</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">token</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">2</span> <span class="ow">and</span> <span class="n">token</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">]</span> <span class="o">==</span> <span class="s1">'##'</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">token</span><span class="p">[</span><span class="mi">2</span><span class="p">:]</span> <span class="ow">in</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">'Did not find a token for'</span><span class="p">,</span> <span class="n">token</span><span class="p">[</span><span class="mi">2</span><span class="p">:])</span>
            <span class="k">break</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Did not find a token for ly
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [52]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="s1">'##ly'</span> <span class="ow">in</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[52]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>True</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [53]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="s1">'ly'</span> <span class="ow">in</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[53]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>False</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="Names">Names<a class="anchor-link" href="#Names">¶</a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [54]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>wget
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Requirement already satisfied: wget in /usr/local/lib/python3.10/dist-packages (3.2)
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [55]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">wget</span>
<span class="kn">import</span> <span class="nn">random</span> 

<span class="nb">print</span><span class="p">(</span><span class="s1">'Beginning file download with wget module'</span><span class="p">)</span>

<span class="n">url</span> <span class="o">=</span> <span class="s1">'http://www.gutenberg.org/files/3201/files/NAMES.TXT'</span>
<span class="n">wget</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="s1">'first-names.txt'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Beginning file download with wget module
</pre>
</div>
</div>
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[55]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>'first-names (1).txt'</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [56]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Read them in.</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">'first-names.txt'</span><span class="p">,</span> <span class="s1">'rb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">names_encoded</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">readlines</span><span class="p">()</span>

<span class="n">names</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Decode the names, convert to lowercase, and strip newlines.</span>
<span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">names_encoded</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">name</span><span class="o">.</span><span class="n">rstrip</span><span class="p">()</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s1">'utf-8'</span><span class="p">))</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="k">continue</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">'Number of names: </span><span class="si">{:,}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">names</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Example:'</span><span class="p">,</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">names</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Number of names: 21,985
Example: gabbey
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [57]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">num_names</span> <span class="o">=</span> <span class="mi">0</span>

<span class="c1"># For each name in our list...</span>
<span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">names</span><span class="p">:</span>

    <span class="c1"># If it's in the vocab...</span>
    <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span><span class="p">:</span>
        <span class="c1"># Tally it.</span>
        <span class="n">num_names</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="si">{:,}</span><span class="s1"> names in the vocabulary'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">num_names</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>3,869 names in the vocabulary
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p><strong>Further Research</strong></p>
<ul>
<li>Add more modern names<ul>
<li>This repo / file contains some more modern names. The file download isn't working, though.</li>
<li><code>https://raw.githubusercontent.com/arineng/arincli/master/lib/male-first-names.txt</code></li>
</ul>
</li>
<li>Add common names from other languages.</li>
</ul>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="Numbers">Numbers<a class="anchor-link" href="#Numbers">¶</a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [58]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Count how many numbers are in the vocabulary.</span>
<span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>

<span class="c1"># For each token in the vocabulary...</span>
<span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>

    <span class="c1"># Tally if it's a number.</span>
    <span class="k">if</span> <span class="n">token</span><span class="o">.</span><span class="n">isdigit</span><span class="p">():</span>
        <span class="n">count</span> <span class="o">+=</span> <span class="mi">1</span>
        
        <span class="c1"># Any numbers &gt;= 10,000?</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">token</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">4</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">token</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">'Vocab includes </span><span class="si">{:,}</span><span class="s1"> numbers.'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">count</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Vocab includes 881 numbers.
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [59]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Count how many dates between 1600 and 2021 are included.</span>
<span class="n">count</span> <span class="o">=</span> <span class="mi">0</span> 
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1600</span><span class="p">,</span> <span class="mi">2021</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="ow">in</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span><span class="p">:</span>
        <span class="n">count</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">'Vocab includes </span><span class="si">{:,}</span><span class="s1"> of 421 dates from 1600 - 2021'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">count</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Vocab includes 384 of 421 dates from 1600 - 2021
</pre>
</div>
</div>
</div>
</div>
</div>
</main>
</body>
</html>]]></content><author><name>Zhu Tianda</name></author><category term="coding" /><category term="AI" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">BERT Pytorch from Scratch</title><link href="http://0.0.0.0:8855/coding/2023/12/01/BERT-Pytorch-Scratch.html" rel="alternate" type="text/html" title="BERT Pytorch from Scratch" /><published>2023-12-01T00:00:00+08:00</published><updated>2023-12-01T00:00:00+08:00</updated><id>http://0.0.0.0:8855/coding/2023/12/01/BERT-Pytorch-Scratch</id><content type="html" xml:base="http://0.0.0.0:8855/coding/2023/12/01/BERT-Pytorch-Scratch.html"><![CDATA[<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">transformers</span> <span class="n">datasets</span> <span class="n">tokenizers</span>
<span class="err">!</span><span class="n">wget</span> <span class="n">http</span><span class="p">:</span><span class="o">//</span><span class="n">www</span><span class="p">.</span><span class="n">cs</span><span class="p">.</span><span class="n">cornell</span><span class="p">.</span><span class="n">edu</span><span class="o">/~</span><span class="n">cristian</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">cornell_movie_dialogs_corpus</span><span class="p">.</span><span class="nb">zip</span>
<span class="err">!</span><span class="n">unzip</span> <span class="o">-</span><span class="n">qq</span> <span class="n">cornell_movie_dialogs_corpus</span><span class="p">.</span><span class="nb">zip</span>
<span class="err">!</span><span class="n">rm</span> <span class="n">cornell_movie_dialogs_corpus</span><span class="p">.</span><span class="nb">zip</span>
<span class="err">!</span><span class="n">mkdir</span> <span class="n">datasets</span>
<span class="err">!</span><span class="n">mv</span> <span class="n">cornell</span>\ <span class="n">movie</span><span class="o">-</span><span class="n">dialogs</span>\ <span class="n">corpus</span><span class="o">/</span><span class="n">movie_conversations</span><span class="p">.</span><span class="n">txt</span> <span class="p">.</span><span class="o">/</span><span class="n">datasets</span>
<span class="err">!</span><span class="n">mv</span> <span class="n">cornell</span>\ <span class="n">movie</span><span class="o">-</span><span class="n">dialogs</span>\ <span class="n">corpus</span><span class="o">/</span><span class="n">movie_lines</span><span class="p">.</span><span class="n">txt</span> <span class="p">.</span><span class="o">/</span><span class="n">datasets</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Looking in indexes: http://mirrors.tencentyun.com/pypi/simple
Requirement already satisfied: transformers in /home/ubuntu/miniconda3/lib/python3.10/site-packages (4.29.1)
Collecting datasets
  Downloading http://mirrors.tencentyun.com/pypi/packages/fb/1c/85a22f3fa02dce5403094c5dbce494d62343b5a7e518bdf6e4200dda7337/datasets-2.12.0-py3-none-any.whl (474 kB)
[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m474.6/474.6 kB[0m [31m1.6 MB/s[0m eta [36m0:00:00[0m00:01[0m00:01[0m
[?25hRequirement already satisfied: tokenizers in /home/ubuntu/miniconda3/lib/python3.10/site-packages (0.13.3)
Requirement already satisfied: packaging&gt;=20.0 in /home/ubuntu/miniconda3/lib/python3.10/site-packages (from transformers) (23.0)
Requirement already satisfied: huggingface-hub&lt;1.0,&gt;=0.14.1 in /home/ubuntu/miniconda3/lib/python3.10/site-packages (from transformers) (0.14.1)
Requirement already satisfied: regex!=2019.12.17 in /home/ubuntu/miniconda3/lib/python3.10/site-packages (from transformers) (2023.5.5)
Requirement already satisfied: pyyaml&gt;=5.1 in /home/ubuntu/miniconda3/lib/python3.10/site-packages (from transformers) (6.0)
Requirement already satisfied: tqdm&gt;=4.27 in /home/ubuntu/miniconda3/lib/python3.10/site-packages (from transformers) (4.65.0)
Requirement already satisfied: filelock in /home/ubuntu/miniconda3/lib/python3.10/site-packages (from transformers) (3.12.0)
Requirement already satisfied: numpy&gt;=1.17 in /home/ubuntu/miniconda3/lib/python3.10/site-packages (from transformers) (1.24.3)
Requirement already satisfied: requests in /home/ubuntu/miniconda3/lib/python3.10/site-packages (from transformers) (2.28.1)
Collecting pyarrow&gt;=8.0.0
  Downloading http://mirrors.tencentyun.com/pypi/packages/21/68/c9ee59caec452530d32bb43104206ce1387d050adad05ee599616425ee7d/pyarrow-12.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.9 MB)
[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m38.9/38.9 MB[0m [31m9.5 MB/s[0m eta [36m0:00:00[0m:00:01[0m0:01[0mm
[?25hCollecting xxhash
  Downloading http://mirrors.tencentyun.com/pypi/packages/32/c3/4d24d4868fab9d9c8980ce00f01e3302565b06e712129d7dda779f9bb714/xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)
[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m212.5/212.5 kB[0m [31m2.8 MB/s[0m eta [36m0:00:00[0ma [36m0:00:01[0m
[?25hCollecting pandas
  Downloading http://mirrors.tencentyun.com/pypi/packages/a3/40/eca46f6af07a83ea3b8706586b2d8a28c01bdccee789d24f2ccc5e148b28/pandas-2.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)
[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m12.3/12.3 MB[0m [31m10.1 MB/s[0m eta [36m0:00:00[0m00:01[0m00:01[0m
[?25hCollecting dill&lt;0.3.7,&gt;=0.3.0
  Downloading http://mirrors.tencentyun.com/pypi/packages/be/e3/a84bf2e561beed15813080d693b4b27573262433fced9c1d1fea59e60553/dill-0.3.6-py3-none-any.whl (110 kB)
[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m110.5/110.5 kB[0m [31m435.8 kB/s[0m eta [36m0:00:00[0ma [36m0:00:01[0m
[?25hCollecting responses&lt;0.19
  Downloading http://mirrors.tencentyun.com/pypi/packages/79/f3/2b3a6dc5986303b3dd1bbbcf482022acb2583c428cd23f0b6d37b1a1a519/responses-0.18.0-py3-none-any.whl (38 kB)
Requirement already satisfied: fsspec[http]&gt;=2021.11.1 in /home/ubuntu/miniconda3/lib/python3.10/site-packages (from datasets) (2023.5.0)
Collecting aiohttp
  Downloading http://mirrors.tencentyun.com/pypi/packages/81/97/90debed02e5be15d4e63fb96ba930e35b66d4e518fa7065dd442345a448b/aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)
[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1.0/1.0 MB[0m [31m1.7 MB/s[0m eta [36m0:00:00[0m00:01[0m00:01[0m0m
[?25hCollecting multiprocess
  Downloading http://mirrors.tencentyun.com/pypi/packages/b8/0c/c26b346b41bb1f81ac921fa10074a9595c22e5f99cc89c0410fc4efd5df3/multiprocess-0.70.14-py310-none-any.whl (134 kB)
[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m134.3/134.3 kB[0m [31m417.7 kB/s[0m eta [36m0:00:00[0ma [36m0:00:01[0m
[?25hCollecting aiosignal&gt;=1.1.2
  Downloading http://mirrors.tencentyun.com/pypi/packages/76/ac/a7305707cb852b7e16ff80eaf5692309bde30e2b1100a1fcacdc8f731d97/aiosignal-1.3.1-py3-none-any.whl (7.6 kB)
Requirement already satisfied: charset-normalizer&lt;4.0,&gt;=2.0 in /home/ubuntu/miniconda3/lib/python3.10/site-packages (from aiohttp-&gt;datasets) (2.0.4)
Collecting multidict&lt;7.0,&gt;=4.5
  Downloading http://mirrors.tencentyun.com/pypi/packages/56/b5/ac112889bfc68e6cf4eda1e4325789b166c51c6cd29d5633e28fb2c2f966/multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)
[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m114.5/114.5 kB[0m [31m248.9 kB/s[0m eta [36m0:00:00[0m00:01[0m00:01[0m
[?25hRequirement already satisfied: attrs&gt;=17.3.0 in /home/ubuntu/miniconda3/lib/python3.10/site-packages (from aiohttp-&gt;datasets) (23.1.0)
Collecting async-timeout&lt;5.0,&gt;=4.0.0a3
  Downloading http://mirrors.tencentyun.com/pypi/packages/d6/c1/8991e7c5385b897b8c020cdaad718c5b087a6626d1d11a23e1ea87e325a7/async_timeout-4.0.2-py3-none-any.whl (5.8 kB)
Collecting yarl&lt;2.0,&gt;=1.0
  Downloading http://mirrors.tencentyun.com/pypi/packages/c9/d4/a5280faa1b8e9ad3a52ddc4c9aea94dd718f9c55f1e10cfb14580f5ebb45/yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)
[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m268.8/268.8 kB[0m [31m675.3 kB/s[0m eta [36m0:00:00[0m00:01[0m00:01[0m
[?25hCollecting frozenlist&gt;=1.1.1
  Downloading http://mirrors.tencentyun.com/pypi/packages/49/0e/c57ad9178618cf81be0fbb8430f17cf05423403143819d3631c7c09744c2/frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)
[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m149.6/149.6 kB[0m [31m412.1 kB/s[0m eta [36m0:00:00[0ma [36m0:00:01[0m
[?25hRequirement already satisfied: typing-extensions&gt;=3.7.4.3 in /home/ubuntu/miniconda3/lib/python3.10/site-packages (from huggingface-hub&lt;1.0,&gt;=0.14.1-&gt;transformers) (4.5.0)
Requirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /home/ubuntu/miniconda3/lib/python3.10/site-packages (from requests-&gt;transformers) (1.26.15)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /home/ubuntu/miniconda3/lib/python3.10/site-packages (from requests-&gt;transformers) (3.4)
Requirement already satisfied: certifi&gt;=2017.4.17 in /home/ubuntu/miniconda3/lib/python3.10/site-packages (from requests-&gt;transformers) (2022.12.7)
Collecting pytz&gt;=2020.1
  Downloading http://mirrors.tencentyun.com/pypi/packages/7f/99/ad6bd37e748257dd70d6f85d916cafe79c0b0f5e2e95b11f7fbc82bf3110/pytz-2023.3-py2.py3-none-any.whl (502 kB)
[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m502.3/502.3 kB[0m [31m846.1 kB/s[0m eta [36m0:00:00[0ma [36m0:00:01[0m
[?25hRequirement already satisfied: python-dateutil&gt;=2.8.2 in /home/ubuntu/miniconda3/lib/python3.10/site-packages (from pandas-&gt;datasets) (2.8.2)
Collecting tzdata&gt;=2022.1
  Downloading http://mirrors.tencentyun.com/pypi/packages/d5/fb/a79efcab32b8a1f1ddca7f35109a50e4a80d42ac1c9187ab46522b2407d7/tzdata-2023.3-py2.py3-none-any.whl (341 kB)
[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m341.8/341.8 kB[0m [31m814.0 kB/s[0m eta [36m0:00:00[0ma [36m0:00:01[0m
[?25hRequirement already satisfied: six&gt;=1.5 in /home/ubuntu/miniconda3/lib/python3.10/site-packages (from python-dateutil&gt;=2.8.2-&gt;pandas-&gt;datasets) (1.16.0)
Installing collected packages: pytz, xxhash, tzdata, pyarrow, multidict, frozenlist, dill, async-timeout, yarl, responses, pandas, multiprocess, aiosignal, aiohttp, datasets
Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.12.0 dill-0.3.6 frozenlist-1.3.3 multidict-6.0.4 multiprocess-0.70.14 pandas-2.0.1 pyarrow-12.0.0 pytz-2023.3 responses-0.18.0 tzdata-2023.3 xxhash-3.2.0 yarl-1.9.2
--2023-05-15 20:10:10--  http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip
Resolving www.cs.cornell.edu (www.cs.cornell.edu)... 132.236.207.36
Connecting to www.cs.cornell.edu (www.cs.cornell.edu)|132.236.207.36|:80... connected.
HTTP request sent, awaiting response... 200 OK
Length: 9916637 (9.5M) [application/zip]
Saving to: ‘cornell_movie_dialogs_corpus.zip’

cornell_movie_dialo  36%[======&gt;             ]   3.49M  37.2KB/s    in 70s     

2023-05-15 20:11:20 (51.4 KB/s) - Read error at byte 3659764/9916637 (Connection reset by peer). Retrying.

--2023-05-15 20:11:21--  (try: 2)  http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip
Connecting to www.cs.cornell.edu (www.cs.cornell.edu)|132.236.207.36|:80... connected.
HTTP request sent, awaiting response... 206 Partial Content
Length: 9916637 (9.5M), 6256873 (6.0M) remaining [application/zip]
Saving to: ‘cornell_movie_dialogs_corpus.zip’

cornell_movie_dialo 100%[+++++++============&gt;]   9.46M  3.06MB/s    in 1.9s    

2023-05-15 20:11:24 (3.06 MB/s) - ‘cornell_movie_dialogs_corpus.zip’ saved [9916637/9916637]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">transformers</span><span class="p">,</span> <span class="n">datasets</span>
<span class="kn">from</span> <span class="nn">tokenizers</span> <span class="kn">import</span> <span class="n">BertWordPieceTokenizer</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">BertTokenizer</span>
<span class="kn">import</span> <span class="nn">tqdm</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">DataLoader</span>
<span class="kn">import</span> <span class="nn">itertools</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="n">F</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>/home/ubuntu/miniconda3/envs/torch/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html
  from .autonotebook import tqdm as notebook_tqdm
</code></pre></div></div>

<h1 id="1--tokenization-word-piece-tokenizer">1 ) Tokenization (Word Piece Tokenizer)</h1>

<p>To begin our implementation of BERT, we first import the necessary libraries and preprocess the dataset by storing it into memory.</p>

<ul>
  <li>The data corpus is divided into two files, ‘movie_conversations.txt’ and ‘movie_lines.txt’.</li>
  <li>We then split the text in ‘movie_lines.txt’ using a special delimiter (‘+++ $ +++’) to separate the line’s ID, character ID, movie ID, and dialogue text, and store them in a dictionary called line_dic.</li>
  <li>Next, we generate question-answer pairs by iterating over each conversation in ‘movie_conversations.txt’ and pairing the current line’s text with the next line’s text for each conversation.</li>
  <li>Finally, we limit the maximum length of the input sequence to 64 tokens, which is a common length used in many NLP tasks, by splitting the text and taking only the first 64 tokens.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">### data processing
</span><span class="n">MAX_LEN</span> <span class="o">=</span> <span class="mi">64</span>

<span class="c1">### loading all data into memory
</span><span class="n">corpus_movie_conv</span> <span class="o">=</span> <span class="s">'./datasets/movie_conversations.txt'</span>
<span class="n">corpus_movie_lines</span> <span class="o">=</span> <span class="s">'./datasets/movie_lines.txt'</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">corpus_movie_conv</span><span class="p">,</span> <span class="s">'r'</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s">'iso-8859-1'</span><span class="p">)</span> <span class="k">as</span> <span class="n">c</span><span class="p">:</span>
    <span class="n">conv</span> <span class="o">=</span> <span class="n">c</span><span class="p">.</span><span class="n">readlines</span><span class="p">()</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">corpus_movie_lines</span><span class="p">,</span> <span class="s">'r'</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s">'iso-8859-1'</span><span class="p">)</span> <span class="k">as</span> <span class="n">l</span><span class="p">:</span>
    <span class="n">lines</span> <span class="o">=</span> <span class="n">l</span><span class="p">.</span><span class="n">readlines</span><span class="p">()</span>

<span class="c1">### splitting text using special lines
</span><span class="n">lines_dic</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">lines</span><span class="p">:</span>
    <span class="n">objects</span> <span class="o">=</span> <span class="n">line</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">" +++$+++ "</span><span class="p">)</span>
    <span class="n">lines_dic</span><span class="p">[</span><span class="n">objects</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">=</span> <span class="n">objects</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="c1">### generate question answer pairs
</span><span class="n">pairs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">con</span> <span class="ow">in</span> <span class="n">conv</span><span class="p">:</span>
    <span class="n">ids</span> <span class="o">=</span> <span class="nb">eval</span><span class="p">(</span><span class="n">con</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">" +++$+++ "</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ids</span><span class="p">)):</span>
        <span class="n">qa_pairs</span> <span class="o">=</span> <span class="p">[]</span>
        
        <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">ids</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">break</span>

        <span class="n">first</span> <span class="o">=</span> <span class="n">lines_dic</span><span class="p">[</span><span class="n">ids</span><span class="p">[</span><span class="n">i</span><span class="p">]].</span><span class="n">strip</span><span class="p">()</span>  
        <span class="n">second</span> <span class="o">=</span> <span class="n">lines_dic</span><span class="p">[</span><span class="n">ids</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]].</span><span class="n">strip</span><span class="p">()</span> 

        <span class="n">qa_pairs</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="s">' '</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">first</span><span class="p">.</span><span class="n">split</span><span class="p">()[:</span><span class="n">MAX_LEN</span><span class="p">]))</span>
        <span class="n">qa_pairs</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="s">' '</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">second</span><span class="p">.</span><span class="n">split</span><span class="p">()[:</span><span class="n">MAX_LEN</span><span class="p">]))</span>
        <span class="n">pairs</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">qa_pairs</span><span class="p">)</span>

<span class="c1"># sample
</span><span class="k">print</span><span class="p">(</span><span class="n">pairs</span><span class="p">[</span><span class="mi">20</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>["I really, really, really wanna go, but I can't. Not unless my sister goes.", "I'm workin' on it. But she doesn't seem to be goin' for him."]
</code></pre></div></div>

<p>WordPiece Tokenization
The initial stage of creating a fresh BERT model involves training a new tokenizer. Tokenization is the process of breaking down a text into smaller units called “tokens,” which are then converted into a numerical representation. An example of this would be splitting the sentence</p>

<p>“I like surfboarding!” → [‘[CLS]’, ‘i’, ‘like’, ‘surf’, ‘##board’, ‘##ing’, ‘!’, ‘[SEP]’] → [1, 48, 250, 4033, 3588, 154, 5, 2]
A tokenized BERT input always starts with a special [CLS] token and ends with a special [SEP] token, which are used for specific purposes that will be explained later. BERT employs a WordPiece tokenizer, which can split a single word into multiple tokens. For instance, in the example given earlier, the word “surfboarding” is broken down into [‘surf’, ‘##boarding’, ‘##ing’]. This technique helps the model to understand that words like surfboardand snowboardhave shared meaning through the common wordpiece ##board. By referring to the explanation from HuggingFace, WordPiece computes a score for each pair, using the following</p>

<p>score = (freq_of_pair) / (freq_of_first_element × freq_of_second_element)</p>

<p>By dividing the frequency of the pair by the product of the frequencies of each of its parts, the algorithm prioritizes the merging of pairs where the individual parts are less frequent in the vocabulary. For instance, it won’t necessarily merge (“un”, “##able”) even if that pair occurs very frequently in the vocabulary, because the two pairs “un” and “##able” will likely each appear in a lot of other words and have a high frequency. In contrast, a pair like (“hu”, “##gging”) will probably be merged faster (assuming the word “hugging” appears often in the vocabulary) since “hu” and “##gging” are likely to be less frequent individually.</p>

<p>To train the tokenizer, the BertWordPieceTokenizer from the transformer library was used with the steps below:</p>

<ul>
  <li>Saving the conversation text into multiple .txt files (with batch of N=10000)</li>
  <li>Define BertWordPieceTokenizer with some parameters likeclean_text to remove control characters, handle_chinese_chars to include spaces around Chinese characters, stripe_accents to remove accents and make é → e, ô → o, andlowercase to view capital and lowercase characters as equal.</li>
  <li>Train the tokenizer based on the file path to .txt files with parameters like vocab_size defines the total number of tokens, min_frequency for minimum frequency for a pair of tokens to be merged, special_tokens defines a list of the special tokens that BERT uses, limit_alphabet for a maximum number of different characters, workpieces_prefix the prefix added to pieces of words (like ##ing).</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># WordPiece tokenizer
</span>
<span class="c1">### save data as txt file
</span><span class="n">os</span><span class="p">.</span><span class="n">mkdir</span><span class="p">(</span><span class="s">'./data'</span><span class="p">)</span>
<span class="n">text_data</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">file_count</span> <span class="o">=</span> <span class="mi">0</span>

<span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">.</span><span class="n">tqdm</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">pairs</span><span class="p">]):</span>
    <span class="n">text_data</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>

    <span class="c1"># once we hit the 10K mark, save to file
</span>    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">text_data</span><span class="p">)</span> <span class="o">==</span> <span class="mi">10000</span><span class="p">:</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="sa">f</span><span class="s">'./data/text_</span><span class="si">{</span><span class="n">file_count</span><span class="si">}</span><span class="s">.txt'</span><span class="p">,</span> <span class="s">'w'</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s">'utf-8'</span><span class="p">)</span> <span class="k">as</span> <span class="n">fp</span><span class="p">:</span>
            <span class="n">fp</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="s">'</span><span class="se">\n</span><span class="s">'</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">text_data</span><span class="p">))</span>
        <span class="n">text_data</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">file_count</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="n">paths</span> <span class="o">=</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">Path</span><span class="p">(</span><span class="s">'./data'</span><span class="p">).</span><span class="n">glob</span><span class="p">(</span><span class="s">'**/*.txt'</span><span class="p">)]</span>
<span class="k">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">paths</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>100%|██████████| 221616/221616 [00:00&lt;00:00, 1797117.49it/s]

22
</code></pre></div></div>

<p>To specifically highlight these special tokens for BERT:</p>

<ul>
  <li>CLS stands for classification. It serves as the the Start of Sentence (SOS) and represent the meaning of the entire sentence.</li>
  <li>SEP serves as End of Sentence (EOS) and also the separation token between first and second sentences.</li>
  <li>PADto be added into sentences so that all of them would be in equal length. During the training process, please note that the [PAD] token with id of 0 will not contribute to the gradient .</li>
  <li>MASK for word replacement during masked language prediction</li>
  <li>UNK serves as a replacement for token if it’s not being found in the tokenizer’s vocab.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">### training own tokenizer
</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">BertWordPieceTokenizer</span><span class="p">(</span>
    <span class="n">clean_text</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">handle_chinese_chars</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
    <span class="n">strip_accents</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
    <span class="n">lowercase</span><span class="o">=</span><span class="bp">True</span>
<span class="p">)</span>

<span class="n">tokenizer</span><span class="p">.</span><span class="n">train</span><span class="p">(</span> 
    <span class="n">files</span><span class="o">=</span><span class="n">paths</span><span class="p">,</span>
    <span class="n">vocab_size</span><span class="o">=</span><span class="mi">30_000</span><span class="p">,</span> 
    <span class="n">min_frequency</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
    <span class="n">limit_alphabet</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> 
    <span class="n">wordpieces_prefix</span><span class="o">=</span><span class="s">'##'</span><span class="p">,</span>
    <span class="n">special_tokens</span><span class="o">=</span><span class="p">[</span><span class="s">'[PAD]'</span><span class="p">,</span> <span class="s">'[CLS]'</span><span class="p">,</span> <span class="s">'[SEP]'</span><span class="p">,</span> <span class="s">'[MASK]'</span><span class="p">,</span> <span class="s">'[UNK]'</span><span class="p">]</span>
    <span class="p">)</span>

<span class="n">os</span><span class="p">.</span><span class="n">mkdir</span><span class="p">(</span><span class="s">'./bert-it-1'</span><span class="p">)</span>
<span class="n">tokenizer</span><span class="p">.</span><span class="n">save_model</span><span class="p">(</span><span class="s">'./bert-it-1'</span><span class="p">,</span> <span class="s">'bert-it'</span><span class="p">)</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">BertTokenizer</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s">'./bert-it-1/bert-it-vocab.txt'</span><span class="p">,</span> <span class="n">local_files_only</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">token_ids</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="s">'I like surfboarding!'</span><span class="p">)[</span><span class="s">'input_ids'</span><span class="p">]</span>
<span class="k">print</span><span class="p">(</span><span class="n">token_ids</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">.</span><span class="n">convert_ids_to_tokens</span><span class="p">(</span><span class="n">token_ids</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[1, 48, 250, 4033, 3588, 154, 5, 2]
['[CLS]', 'i', 'like', 'surf', '##board', '##ing', '!', '[SEP]']


/home/ubuntu/miniconda3/envs/torch/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1714: FutureWarning: Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated and won't be possible anymore in v5. Use a model identifier or the path to a directory instead.
  warnings.warn(
</code></pre></div></div>

<h1 id="2-pre-processing">2) Pre-processing</h1>

<p>The code below defines a custom PyTorch Dataset class named BERTDataset, which is intended to be used for training a Bidirectional Encoder Representations from Transformers (BERT) model. The random_word method of the BERTDataset class performs the random replacement of tokens in each sentence using the given tokenizer object. The get_sent method returns a random sentence pair and corresponding is_next label. Finally, the get_corpus_line and get_random_line methods are used to retrieve individual sentences from the input pairs for negative sentence pairs.
It took multiple steps to prepare the data for the two training strategies</p>

<ul>
  <li>Step 1:
Select a random sentence pair, either positive or negative, and save the is_next indicating whether the two sentences are consecutive in the original text or not.</li>
  <li>Step 2:
Masking random words in first and second sentences based on predefined probabilities, at the same time recording the actual word as bert_label. After which, it converts the sequence string into integer (list of token ids).
<img src="2023-12-01-BERT-Pytorch-Scratch_files/0ae902d8-da32-4145-a744-989807b937d7.png" alt="image.png" /></li>
  <li>Step 3:
Add special [CLS] and [SEP] tokens to the start and end of each sentence.</li>
  <li>Step 4:
Combine first and second sentences as single output (but separated by SEPtoken) and then followed by padding with PAD token to the sentence pairs and labels to max length. At this step, a segment label is created by assigning 1 for first sentence and 2 for second, whereas 0 for padded tokens.</li>
</ul>

<p>By printing a sample output from the prepared dataset, we will see 4 keys output</p>

<ul>
  <li>bert_input for tokenized sentences</li>
  <li>bert_label stores original words of selected masking tokens</li>
  <li>segment_label as the identifier for sentence A or B, this allows the model to distinguish between sentences</li>
  <li>is_next as truth label for whether the two sentences are related</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">BERTDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_pair</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">seq_len</span><span class="o">=</span><span class="mi">64</span><span class="p">):</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">tokenizer</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">seq_len</span> <span class="o">=</span> <span class="n">seq_len</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">corpus_lines</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data_pair</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">lines</span> <span class="o">=</span> <span class="n">data_pair</span>

    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">corpus_lines</span>

    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">):</span>

        <span class="c1"># Step 1: get random sentence pair, either negative or positive (saved as is_next_label)
</span>        <span class="n">t1</span><span class="p">,</span> <span class="n">t2</span><span class="p">,</span> <span class="n">is_next_label</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">get_sent</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>

        <span class="c1"># Step 2: replace random words in sentence with mask / random words
</span>        <span class="n">t1_random</span><span class="p">,</span> <span class="n">t1_label</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">random_word</span><span class="p">(</span><span class="n">t1</span><span class="p">)</span>
        <span class="n">t2_random</span><span class="p">,</span> <span class="n">t2_label</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">random_word</span><span class="p">(</span><span class="n">t2</span><span class="p">)</span>

        <span class="c1"># Step 3: Adding CLS and SEP tokens to the start and end of sentences
</span>         <span class="c1"># Adding PAD token for labels
</span>        <span class="n">t1</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="p">.</span><span class="n">tokenizer</span><span class="p">.</span><span class="n">vocab</span><span class="p">[</span><span class="s">'[CLS]'</span><span class="p">]]</span> <span class="o">+</span> <span class="n">t1_random</span> <span class="o">+</span> <span class="p">[</span><span class="bp">self</span><span class="p">.</span><span class="n">tokenizer</span><span class="p">.</span><span class="n">vocab</span><span class="p">[</span><span class="s">'[SEP]'</span><span class="p">]]</span>
        <span class="n">t2</span> <span class="o">=</span> <span class="n">t2_random</span> <span class="o">+</span> <span class="p">[</span><span class="bp">self</span><span class="p">.</span><span class="n">tokenizer</span><span class="p">.</span><span class="n">vocab</span><span class="p">[</span><span class="s">'[SEP]'</span><span class="p">]]</span>
        <span class="n">t1_label</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="p">.</span><span class="n">tokenizer</span><span class="p">.</span><span class="n">vocab</span><span class="p">[</span><span class="s">'[PAD]'</span><span class="p">]]</span> <span class="o">+</span> <span class="n">t1_label</span> <span class="o">+</span> <span class="p">[</span><span class="bp">self</span><span class="p">.</span><span class="n">tokenizer</span><span class="p">.</span><span class="n">vocab</span><span class="p">[</span><span class="s">'[PAD]'</span><span class="p">]]</span>
        <span class="n">t2_label</span> <span class="o">=</span> <span class="n">t2_label</span> <span class="o">+</span> <span class="p">[</span><span class="bp">self</span><span class="p">.</span><span class="n">tokenizer</span><span class="p">.</span><span class="n">vocab</span><span class="p">[</span><span class="s">'[PAD]'</span><span class="p">]]</span>

        <span class="c1"># Step 4: combine sentence 1 and 2 as one input
</span>        <span class="c1"># adding PAD tokens to make the sentence same length as seq_len
</span>        <span class="n">segment_label</span> <span class="o">=</span> <span class="p">([</span><span class="mi">1</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">t1</span><span class="p">))]</span> <span class="o">+</span> <span class="p">[</span><span class="mi">2</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">t2</span><span class="p">))])[:</span><span class="bp">self</span><span class="p">.</span><span class="n">seq_len</span><span class="p">]</span>
        <span class="n">bert_input</span> <span class="o">=</span> <span class="p">(</span><span class="n">t1</span> <span class="o">+</span> <span class="n">t2</span><span class="p">)[:</span><span class="bp">self</span><span class="p">.</span><span class="n">seq_len</span><span class="p">]</span>
        <span class="n">bert_label</span> <span class="o">=</span> <span class="p">(</span><span class="n">t1_label</span> <span class="o">+</span> <span class="n">t2_label</span><span class="p">)[:</span><span class="bp">self</span><span class="p">.</span><span class="n">seq_len</span><span class="p">]</span>
        <span class="n">padding</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="p">.</span><span class="n">tokenizer</span><span class="p">.</span><span class="n">vocab</span><span class="p">[</span><span class="s">'[PAD]'</span><span class="p">]</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">seq_len</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">bert_input</span><span class="p">))]</span>
        <span class="n">bert_input</span><span class="p">.</span><span class="n">extend</span><span class="p">(</span><span class="n">padding</span><span class="p">),</span> <span class="n">bert_label</span><span class="p">.</span><span class="n">extend</span><span class="p">(</span><span class="n">padding</span><span class="p">),</span> <span class="n">segment_label</span><span class="p">.</span><span class="n">extend</span><span class="p">(</span><span class="n">padding</span><span class="p">)</span>

        <span class="n">output</span> <span class="o">=</span> <span class="p">{</span><span class="s">"bert_input"</span><span class="p">:</span> <span class="n">bert_input</span><span class="p">,</span>
                  <span class="s">"bert_label"</span><span class="p">:</span> <span class="n">bert_label</span><span class="p">,</span>
                  <span class="s">"segment_label"</span><span class="p">:</span> <span class="n">segment_label</span><span class="p">,</span>
                  <span class="s">"is_next"</span><span class="p">:</span> <span class="n">is_next_label</span><span class="p">}</span>

        <span class="k">return</span> <span class="p">{</span><span class="n">key</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">output</span><span class="p">.</span><span class="n">items</span><span class="p">()}</span>

    <span class="k">def</span> <span class="nf">random_word</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sentence</span><span class="p">):</span>
        <span class="n">tokens</span> <span class="o">=</span> <span class="n">sentence</span><span class="p">.</span><span class="n">split</span><span class="p">()</span>
        <span class="n">output_label</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">output</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># 15% of the tokens would be replaced
</span>        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">token</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">tokens</span><span class="p">):</span>
            <span class="n">prob</span> <span class="o">=</span> <span class="n">random</span><span class="p">.</span><span class="n">random</span><span class="p">()</span>

            <span class="c1"># remove cls and sep token
</span>            <span class="n">token_id</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">tokenizer</span><span class="p">(</span><span class="n">token</span><span class="p">)[</span><span class="s">'input_ids'</span><span class="p">][</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

            <span class="k">if</span> <span class="n">prob</span> <span class="o">&lt;</span> <span class="mf">0.15</span><span class="p">:</span>
                <span class="n">prob</span> <span class="o">/=</span> <span class="mf">0.15</span>

                <span class="c1"># 80% chance change token to mask token
</span>                <span class="k">if</span> <span class="n">prob</span> <span class="o">&lt;</span> <span class="mf">0.8</span><span class="p">:</span>
                    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">token_id</span><span class="p">)):</span>
                        <span class="n">output</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">tokenizer</span><span class="p">.</span><span class="n">vocab</span><span class="p">[</span><span class="s">'[MASK]'</span><span class="p">])</span>

                <span class="c1"># 10% chance change token to random token
</span>                <span class="k">elif</span> <span class="n">prob</span> <span class="o">&lt;</span> <span class="mf">0.9</span><span class="p">:</span>
                    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">token_id</span><span class="p">)):</span>
                        <span class="n">output</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">random</span><span class="p">.</span><span class="n">randrange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">tokenizer</span><span class="p">.</span><span class="n">vocab</span><span class="p">)))</span>

                <span class="c1"># 10% chance change token to current token
</span>                <span class="k">else</span><span class="p">:</span>
                    <span class="n">output</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">token_id</span><span class="p">)</span>

                <span class="n">output_label</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">token_id</span><span class="p">)</span>

            <span class="k">else</span><span class="p">:</span>
                <span class="n">output</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">token_id</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">token_id</span><span class="p">)):</span>
                    <span class="n">output_label</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="c1"># flattening
</span>        <span class="n">output</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">itertools</span><span class="p">.</span><span class="n">chain</span><span class="p">(</span><span class="o">*</span><span class="p">[[</span><span class="n">x</span><span class="p">]</span> <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="k">else</span> <span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">output</span><span class="p">]))</span>
        <span class="n">output_label</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">itertools</span><span class="p">.</span><span class="n">chain</span><span class="p">(</span><span class="o">*</span><span class="p">[[</span><span class="n">x</span><span class="p">]</span> <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="k">else</span> <span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">output_label</span><span class="p">]))</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">output</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">output_label</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">output_label</span>

    <span class="k">def</span> <span class="nf">get_sent</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="s">'''return random sentence pair'''</span>
        <span class="n">t1</span><span class="p">,</span> <span class="n">t2</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">get_corpus_line</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>

        <span class="c1"># negative or positive pair, for next sentence prediction
</span>        <span class="k">if</span> <span class="n">random</span><span class="p">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">t1</span><span class="p">,</span> <span class="n">t2</span><span class="p">,</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">t1</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">get_random_line</span><span class="p">(),</span> <span class="mi">0</span>

    <span class="k">def</span> <span class="nf">get_corpus_line</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">):</span>
        <span class="s">'''return sentence pair'''</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">lines</span><span class="p">[</span><span class="n">item</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="p">.</span><span class="n">lines</span><span class="p">[</span><span class="n">item</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">get_random_line</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="s">'''return random single sentence'''</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">lines</span><span class="p">[</span><span class="n">random</span><span class="p">.</span><span class="n">randrange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">lines</span><span class="p">))][</span><span class="mi">1</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># test
</span><span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">BERTDataset</span><span class="p">(</span><span class="n">pairs</span><span class="p">,</span> <span class="n">seq_len</span><span class="o">=</span><span class="n">MAX_LEN</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">)</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">pin_memory</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">sample_data</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">train_loader</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Batch Size'</span><span class="p">,</span> <span class="n">sample_data</span><span class="p">[</span><span class="s">'bert_input'</span><span class="p">].</span><span class="n">size</span><span class="p">())</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">train_data</span><span class="p">[</span><span class="n">random</span><span class="p">.</span><span class="n">randrange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_data</span><span class="p">))]</span>
<span class="n">result</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Batch Size torch.Size([32, 64])





{'bert_input': tensor([   1,  558,    3,    3,    2, 4039,   17, 6013,  162,   17,    2,    0,
            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
            0,    0,    0,    0]),
 'bert_label': tensor([  0,   0, 839,  17,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   0,   0]),
 'segment_label': tensor([1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),
 'is_next': tensor(1)}
</code></pre></div></div>

<h1 id="3-modeling">3) Modeling</h1>

<p>In NLP model, the order of the words and their position in a sentence matters and the meaning of the entire sentence can change if the words are re-ordered. As such, transformer model did a position embedding for each token in the input using the formula</p>

<p><img src="2023-12-01-BERT-Pytorch-Scratch_files/a8fb37fd-92a9-432b-8563-7dcd5ce74bfe.png" alt="image.png" />!</p>

<p>where</p>

<ul>
  <li>k: Position of an object in input sequence, 0 &lt; k &lt; L/2</li>
  <li>d: Dimension of the output embedding space</li>
  <li>n: User defined scalar. Default by 10,000</li>
  <li>i: Used for mapping to column indices 0 &lt; i &lt; d/2. A single value of i maps to both sine and cosine functions
For all three different type of embeddings, they must be in the similar output size (768 in this case), so that all three of them can be summed together to be a single embedded output. You may notice thepadding_idx is specified as 0, this is to make pad token remains as 0 and not being updated during training.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">### embedding
</span><span class="k">class</span> <span class="nc">PositionalEmbedding</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">max_len</span><span class="o">=</span><span class="mi">128</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>

        <span class="c1"># Compute the positional encodings once in log space.
</span>        <span class="n">pe</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">max_len</span><span class="p">,</span> <span class="n">d_model</span><span class="p">).</span><span class="nb">float</span><span class="p">()</span>
        <span class="n">pe</span><span class="p">.</span><span class="n">require_grad</span> <span class="o">=</span> <span class="bp">False</span>

        <span class="k">for</span> <span class="n">pos</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_len</span><span class="p">):</span>   
            <span class="c1"># for each dimension of the each position
</span>            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="mi">2</span><span class="p">):</span>   
                <span class="n">pe</span><span class="p">[</span><span class="n">pos</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">math</span><span class="p">.</span><span class="n">sin</span><span class="p">(</span><span class="n">pos</span> <span class="o">/</span> <span class="p">(</span><span class="mi">10000</span> <span class="o">**</span> <span class="p">((</span><span class="mi">2</span> <span class="o">*</span> <span class="n">i</span><span class="p">)</span><span class="o">/</span><span class="n">d_model</span><span class="p">)))</span>
                <span class="n">pe</span><span class="p">[</span><span class="n">pos</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">math</span><span class="p">.</span><span class="n">cos</span><span class="p">(</span><span class="n">pos</span> <span class="o">/</span> <span class="p">(</span><span class="mi">10000</span> <span class="o">**</span> <span class="p">((</span><span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span><span class="o">/</span><span class="n">d_model</span><span class="p">)))</span>

        <span class="c1"># include the batch size
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">pe</span> <span class="o">=</span> <span class="n">pe</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>   
        <span class="c1"># self.register_buffer('pe', pe)
</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">pe</span>

<span class="k">class</span> <span class="nc">BERTEmbedding</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="s">"""
    BERT Embedding which is consisted with under features
        1. TokenEmbedding : normal embedding matrix
        2. PositionalEmbedding : adding positional information using sin, cos
        2. SegmentEmbedding : adding sentence segment info, (sent_A:1, sent_B:2)
        sum of all these features are output of BERTEmbedding
    """</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">,</span> <span class="n">seq_len</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
        <span class="s">"""
        :param vocab_size: total vocab size
        :param embed_size: embedding size of token embedding
        :param dropout: dropout rate
        """</span>

        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">embed_size</span> <span class="o">=</span> <span class="n">embed_size</span>
        <span class="c1"># (m, seq_len) --&gt; (m, seq_len, embed_size)
</span>        <span class="c1"># padding_idx is not updated during training, remains as fixed pad (0)
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">token</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">,</span> <span class="n">padding_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">segment</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Embedding</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">,</span> <span class="n">padding_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">position</span> <span class="o">=</span> <span class="n">PositionalEmbedding</span><span class="p">(</span><span class="n">d_model</span><span class="o">=</span><span class="n">embed_size</span><span class="p">,</span> <span class="n">max_len</span><span class="o">=</span><span class="n">seq_len</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="n">dropout</span><span class="p">)</span>
       
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sequence</span><span class="p">,</span> <span class="n">segment_label</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">token</span><span class="p">(</span><span class="n">sequence</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="p">.</span><span class="n">position</span><span class="p">(</span><span class="n">sequence</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="p">.</span><span class="n">segment</span><span class="p">(</span><span class="n">segment_label</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="c1">### testing
</span><span class="n">embed_layer</span> <span class="o">=</span> <span class="n">BERTEmbedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">.</span><span class="n">vocab</span><span class="p">),</span> <span class="n">embed_size</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">seq_len</span><span class="o">=</span><span class="n">MAX_LEN</span><span class="p">)</span>
<span class="n">embed_result</span> <span class="o">=</span> <span class="n">embed_layer</span><span class="p">(</span><span class="n">sample_data</span><span class="p">[</span><span class="s">'bert_input'</span><span class="p">],</span> <span class="n">sample_data</span><span class="p">[</span><span class="s">'segment_label'</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="n">embed_result</span><span class="p">.</span><span class="n">size</span><span class="p">())</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>torch.Size([32, 64, 768])
</code></pre></div></div>

<h3 id="the-details-of-the-class-multiheadedattention">The details of the class MultiHeadedAttention</h3>

<ul>
  <li>It’s called multi-head attention because the hidden size: d_model(768) is split by heads(12), this allows the model to jointly attend to information at different positions from different representational spaces.</li>
  <li>It takes the query, key, and value as inputs, and the size is permuted from (batch_size, max_len, hidden_size) → (batch_size, num_heads, max_len, hidden_size / num_heads ). This indicates that all the 3 inpurs are linearly projected from the d_model dimensional space to heads sets of d_k dimensional vectors.</li>
  <li>Attention score matrix is computed using matrix multiplication between the query(Q) and key(K) tensors, followed by scaling by the square root of the key tensor’s dimension</li>
  <li>The mask is applied to the attention matrix and filled with -1e9 (close to negative infinity). This is done because the large negative inputs to softmax are near zero in the output.</li>
  <li>
    <p>The final output is a weighted sum of the value(V) tensors, where the weights are determined by the softmax of the scaled dot-product between the query and key vectors.
The EncoderLayer class contains 2 sublayers:.</p>
  </li>
  <li>MultiHeadedAttention: A multi-headed self-attention module that computes the attention weights between each element in the input sequence</li>
  <li>FeedForward: A feedforward network with one hidden layer that applies a non-linear activation function (GELU) to the output of the first linear layer and produces a d_model dimensional output.</li>
  <li>Each of these sublayers has a residual connection around it followed by a layer normalization LayerNorm(x + Sublayer(x)). Residual connections help in avoiding the vanishing gradient problem in deep networks.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">### attention layers
</span><span class="k">class</span> <span class="nc">MultiHeadedAttention</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">heads</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MultiHeadedAttention</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
        
        <span class="k">assert</span> <span class="n">d_model</span> <span class="o">%</span> <span class="n">heads</span> <span class="o">==</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">d_k</span> <span class="o">=</span> <span class="n">d_model</span> <span class="o">//</span> <span class="n">heads</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">heads</span> <span class="o">=</span> <span class="n">heads</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">query</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">key</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">value</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">output_linear</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">query</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">mask</span><span class="p">):</span>
        <span class="s">"""
        query, key, value of shape: (batch_size, max_len, d_model)
        mask of shape: (batch_size, 1, 1, max_words)
        """</span>
        <span class="c1"># (batch_size, max_len, d_model)
</span>        <span class="n">query</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">query</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
        <span class="n">key</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">key</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>        
        <span class="n">value</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">value</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>   
        
        <span class="c1"># (batch_size, max_len, d_model) --&gt; (batch_size, max_len, h, d_k) --&gt; (batch_size, h, max_len, d_k)
</span>        <span class="n">query</span> <span class="o">=</span> <span class="n">query</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="n">query</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">heads</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">d_k</span><span class="p">).</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>   
        <span class="n">key</span> <span class="o">=</span> <span class="n">key</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="n">key</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">heads</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">d_k</span><span class="p">).</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>  
        <span class="n">value</span> <span class="o">=</span> <span class="n">value</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="n">value</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">heads</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">d_k</span><span class="p">).</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>  
        
        <span class="c1"># (batch_size, h, max_len, d_k) matmul (batch_size, h, d_k, max_len) --&gt; (batch_size, h, max_len, max_len)
</span>        <span class="n">scores</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">key</span><span class="p">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span> <span class="o">/</span> <span class="n">math</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">query</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>

        <span class="c1"># fill 0 mask with super small number so it wont affect the softmax weight
</span>        <span class="c1"># (batch_size, h, max_len, max_len)
</span>        <span class="n">scores</span> <span class="o">=</span> <span class="n">scores</span><span class="p">.</span><span class="n">masked_fill</span><span class="p">(</span><span class="n">mask</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mf">1e9</span><span class="p">)</span>    

        <span class="c1"># (batch_size, h, max_len, max_len)
</span>        <span class="c1"># softmax to put attention weight for all non-pad tokens
</span>        <span class="c1"># max_len X max_len matrix of attention
</span>        <span class="n">weights</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>           
        <span class="n">weights</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>

        <span class="c1"># (batch_size, h, max_len, max_len) matmul (batch_size, h, max_len, d_k) --&gt; (batch_size, h, max_len, d_k)
</span>        <span class="n">context</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>

        <span class="c1"># (batch_size, h, max_len, d_k) --&gt; (batch_size, max_len, h, d_k) --&gt; (batch_size, max_len, d_model)
</span>        <span class="n">context</span> <span class="o">=</span> <span class="n">context</span><span class="p">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">).</span><span class="n">contiguous</span><span class="p">().</span><span class="n">view</span><span class="p">(</span><span class="n">context</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">heads</span> <span class="o">*</span> <span class="bp">self</span><span class="p">.</span><span class="n">d_k</span><span class="p">)</span>

        <span class="c1"># (batch_size, max_len, d_model)
</span>        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">output_linear</span><span class="p">(</span><span class="n">context</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">FeedForward</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="s">"Implements FFN equation."</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">middle_dim</span><span class="o">=</span><span class="mi">2048</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">FeedForward</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
        
        <span class="bp">self</span><span class="p">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">middle_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">middle_dim</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">GELU</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">activation</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">fc2</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">out</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">out</span>

<span class="k">class</span> <span class="nc">EncoderLayer</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> 
        <span class="n">d_model</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span>
        <span class="n">heads</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> 
        <span class="n">feed_forward_hidden</span><span class="o">=</span><span class="mi">768</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span> 
        <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span>
        <span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">EncoderLayer</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">layernorm</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">self_multihead</span> <span class="o">=</span> <span class="n">MultiHeadedAttention</span><span class="p">(</span><span class="n">heads</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">feed_forward</span> <span class="o">=</span> <span class="n">FeedForward</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">middle_dim</span><span class="o">=</span><span class="n">feed_forward_hidden</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">,</span> <span class="n">mask</span><span class="p">):</span>
        <span class="c1"># embeddings: (batch_size, max_len, d_model)
</span>        <span class="c1"># encoder mask: (batch_size, 1, 1, max_len)
</span>        <span class="c1"># result: (batch_size, max_len, d_model)
</span>        <span class="n">interacted</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">dropout</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">self_multihead</span><span class="p">(</span><span class="n">embeddings</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">,</span> <span class="n">mask</span><span class="p">))</span>
        <span class="c1"># residual layer
</span>        <span class="n">interacted</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">layernorm</span><span class="p">(</span><span class="n">interacted</span> <span class="o">+</span> <span class="n">embeddings</span><span class="p">)</span>
        <span class="c1"># bottleneck
</span>        <span class="n">feed_forward_out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">dropout</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">feed_forward</span><span class="p">(</span><span class="n">interacted</span><span class="p">))</span>
        <span class="n">encoded</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">layernorm</span><span class="p">(</span><span class="n">feed_forward_out</span> <span class="o">+</span> <span class="n">interacted</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">encoded</span>

<span class="c1">### testing
</span><span class="n">mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">sample_data</span><span class="p">[</span><span class="s">'bert_input'</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">).</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">).</span><span class="n">repeat</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">sample_data</span><span class="p">[</span><span class="s">'bert_input'</span><span class="p">].</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="mi">1</span><span class="p">).</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">transformer_block</span> <span class="o">=</span> <span class="n">EncoderLayer</span><span class="p">()</span>
<span class="n">transformer_result</span> <span class="o">=</span> <span class="n">transformer_block</span><span class="p">(</span><span class="n">embed_result</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>
<span class="n">transformer_result</span><span class="p">.</span><span class="n">size</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>torch.Size([32, 64, 768])
</code></pre></div></div>

<h3 id="the-details-of-the-class-multiheadedattention-1">The details of the class MultiHeadedAttention</h3>

<ul>
  <li>It’s called multi-head attention because the hidden size: <strong>d_model(768) is split by heads(12)</strong>, this allows the model to jointly attend to information at different positions from different representational spaces.</li>
  <li>It takes the query, key, and value as inputs, and the size is permuted from <strong>(batch_size, max_len, hidden_size) → (batch_size, num_heads, max_len, hidden_size / num_heads )</strong>. This indicates that all the 3 inpurs are linearly projected from the d_model dimensional space to heads sets of d_k dimensional vectors.</li>
  <li>Attention score matrix is computed using matrix multiplication between the query(Q) and key(K) tensors, followed by scaling by the square root of the key tensor’s dimension</li>
  <li><strong>The mask is applied to the attention matrix and filled with -1e9 (close to negative infinity)</strong>. This is done because the large negative inputs to softmax are near zero in the output. <br />
      ** per my understanding this means the mask for padding?? correct? not [mask] token… ..  “” def forward(self, query, key, value, mask): ““**</li>
  <li>The final output is a weighted sum of the value(V) tensors, where the weights are determined by the softmax of the scaled dot-product between the query and key vectors.</li>
</ul>

<p>The EncoderLayer class contains 2 sublayers:.</p>

<ul>
  <li>MultiHeadedAttention: A multi-headed self-attention module that computes the attention weights between each element in the input sequence</li>
  <li>FeedForward: A feedforward network with one hidden layer that applies a non-linear activation function (GELU) to the output of the first linear layer and produces a d_model dimensional output.
Each of these sublayers has a residual connection around it followed by a layer normalization LayerNorm(x + Sublayer(x)). Residual connections help in avoiding the vanishing gradient problem in deep networks.</li>
</ul>

<h3 id="final-bert-model">Final BERT Model</h3>
<p>Coming next, we are going to incorporate the encoder layer with attention mechanism into the final BERT’s construction.</p>
<ul>
  <li>The BERT class initializes the embedding layer for the input sequence, as well as multi layers of EncoderLayer blocks. The forward method of this class takes in the input sequence and a segment info tensor, applies attention masking to the input(for padded token), embeds the input sequence, and then passes it through the encoder blocks to obtain the output.</li>
  <li>The NextSentencePrediction class is a 2-class classification model that takes in the output of the BERT class and predicts whether the input sequence contains two consecutive sentences or not. The forward method applies applies linear transformation and log softmax function to obtain the predicted probabilities of the two classes.</li>
  <li>The MaskedLanguageModel class is a multi-class classification model that takes in the output of the BERT class and predicts the original tokens for the masked input sequence. The forward method applies a linear transformation and log softmax function to obtain the predicted probabilities of each token in the vocabulary.</li>
  <li>The BERTLM class combines the BERT, NextSentencePrediction, and MaskedLanguageModel classes to create a complete BERT language model.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">BERT</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="s">"""
    BERT model : Bidirectional Encoder Representations from Transformers.
    """</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">d_model</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">n_layers</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">heads</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
        <span class="s">"""
        :param vocab_size: vocab_size of total words
        :param hidden: BERT model hidden size
        :param n_layers: numbers of Transformer blocks(layers)
        :param attn_heads: number of attention heads
        :param dropout: dropout rate
        """</span>

        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">d_model</span> <span class="o">=</span> <span class="n">d_model</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">n_layers</span> <span class="o">=</span> <span class="n">n_layers</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">heads</span> <span class="o">=</span> <span class="n">heads</span>

        <span class="c1"># paper noted they used 4*hidden_size for ff_network_hidden_size
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">feed_forward_hidden</span> <span class="o">=</span> <span class="n">d_model</span> <span class="o">*</span> <span class="mi">4</span>

        <span class="c1"># embedding for BERT, sum of positional, segment, token embeddings
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">BERTEmbedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="o">=</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="o">=</span><span class="n">d_model</span><span class="p">)</span>

        <span class="c1"># multi-layers transformer blocks, deep network
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">encoder_blocks</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">ModuleList</span><span class="p">(</span>
            <span class="p">[</span><span class="n">EncoderLayer</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">heads</span><span class="p">,</span> <span class="n">d_model</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_layers</span><span class="p">)])</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">segment_info</span><span class="p">):</span>
        <span class="c1"># attention masking for padded token
</span>        <span class="c1"># (batch_size, 1, seq_len, seq_len)
</span>        <span class="n">mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">).</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">).</span><span class="n">repeat</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">x</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="mi">1</span><span class="p">).</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># embedding the indexed sequence to sequence of vectors
</span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">segment_info</span><span class="p">)</span>

        <span class="c1"># running over multiple transformer blocks
</span>        <span class="k">for</span> <span class="n">encoder</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">encoder_blocks</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="k">class</span> <span class="nc">NextSentencePrediction</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="s">"""
    2-class classification model : is_next, is_not_next
    """</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden</span><span class="p">):</span>
        <span class="s">"""
        :param hidden: BERT model output size
        """</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">softmax</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">LogSoftmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># use only the first token which is the [CLS]
</span>        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">softmax</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">linear</span><span class="p">(</span><span class="n">x</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]))</span>

<span class="k">class</span> <span class="nc">MaskedLanguageModel</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="s">"""
    predicting origin token from masked input sequence
    n-class classification problem, n-class = vocab_size
    """</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">):</span>
        <span class="s">"""
        :param hidden: output size of BERT model
        :param vocab_size: total vocab size
        """</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">softmax</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">LogSoftmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">softmax</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">linear</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>

<span class="k">class</span> <span class="nc">BERTLM</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="s">"""
    BERT Language Model
    Next Sentence Prediction Model + Masked Language Model
    """</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">bert</span><span class="p">:</span> <span class="n">BERT</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">):</span>
        <span class="s">"""
        :param bert: BERT model which should be trained
        :param vocab_size: total vocab size for masked_lm
        """</span>

        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">bert</span> <span class="o">=</span> <span class="n">bert</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">next_sentence</span> <span class="o">=</span> <span class="n">NextSentencePrediction</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">bert</span><span class="p">.</span><span class="n">d_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">mask_lm</span> <span class="o">=</span> <span class="n">MaskedLanguageModel</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">bert</span><span class="p">.</span><span class="n">d_model</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">segment_label</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">bert</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">segment_label</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">next_sentence</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="bp">self</span><span class="p">.</span><span class="n">mask_lm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="c1">### test
</span><span class="n">bert_model</span> <span class="o">=</span> <span class="n">BERT</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">.</span><span class="n">vocab</span><span class="p">))</span>
<span class="n">bert_result</span> <span class="o">=</span> <span class="n">bert_model</span><span class="p">(</span><span class="n">sample_data</span><span class="p">[</span><span class="s">'bert_input'</span><span class="p">],</span> <span class="n">sample_data</span><span class="p">[</span><span class="s">'segment_label'</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="n">bert_result</span><span class="p">.</span><span class="n">size</span><span class="p">())</span>

<span class="n">bert_lm</span> <span class="o">=</span> <span class="n">BERTLM</span><span class="p">(</span><span class="n">bert_model</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">.</span><span class="n">vocab</span><span class="p">))</span>
<span class="n">final_result</span> <span class="o">=</span> <span class="n">bert_lm</span><span class="p">(</span><span class="n">sample_data</span><span class="p">[</span><span class="s">'bert_input'</span><span class="p">],</span> <span class="n">sample_data</span><span class="p">[</span><span class="s">'segment_label'</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="n">final_result</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">size</span><span class="p">(),</span> <span class="n">final_result</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">size</span><span class="p">())</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>torch.Size([32, 64, 768])
torch.Size([32, 2]) torch.Size([32, 64, 21159])
</code></pre></div></div>

<h1 id="4-training">4) Training</h1>

<h3 id="optimizer">Optimizer</h3>
<p>The original BERT model was trained using Adam optimizer with a custom learning rate scheduler according to the formula in the <a href="https://arxiv.org/abs/1706.03762">paper</a>.
\(l r a t e=d_{\text {model }}^{-0.5} * \min \left(step\_num^{-0.5}, step\_num * warmup_steps^{-1.5}\right)\)</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">### optimizer
</span><span class="k">class</span> <span class="nc">ScheduledOptim</span><span class="p">():</span>
    <span class="s">'''A simple wrapper class for learning rate scheduling'''</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">n_warmup_steps</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">_optimizer</span> <span class="o">=</span> <span class="n">optimizer</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">n_warmup_steps</span> <span class="o">=</span> <span class="n">n_warmup_steps</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">n_current_steps</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">init_lr</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">power</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">step_and_update_lr</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="s">"Step with the inner optimizer"</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">_update_learning_rate</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">_optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">zero_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="s">"Zero out the gradients by the inner optimizer"</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">_optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_get_lr_scale</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nb">min</span><span class="p">([</span>
            <span class="n">np</span><span class="p">.</span><span class="n">power</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">n_current_steps</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">),</span>
            <span class="n">np</span><span class="p">.</span><span class="n">power</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">n_warmup_steps</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.5</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="p">.</span><span class="n">n_current_steps</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">_update_learning_rate</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="s">''' Learning rate scheduling per step '''</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">n_current_steps</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">lr</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">init_lr</span> <span class="o">*</span> <span class="bp">self</span><span class="p">.</span><span class="n">_get_lr_scale</span><span class="p">()</span>

        <span class="k">for</span> <span class="n">param_group</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">_optimizer</span><span class="p">.</span><span class="n">param_groups</span><span class="p">:</span>
            <span class="n">param_group</span><span class="p">[</span><span class="s">'lr'</span><span class="p">]</span> <span class="o">=</span> <span class="n">lr</span>
</code></pre></div></div>

<p>Trainer
We came a long way to finally combine what we have discussed above and start training a new BERT model</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">### trainer
</span><span class="k">class</span> <span class="nc">BERTTrainer</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> 
        <span class="n">model</span><span class="p">,</span> 
        <span class="n">train_dataloader</span><span class="p">,</span> 
        <span class="n">test_dataloader</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> 
        <span class="n">lr</span><span class="o">=</span> <span class="mf">1e-4</span><span class="p">,</span>
        <span class="n">weight_decay</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
        <span class="n">betas</span><span class="o">=</span><span class="p">(</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.999</span><span class="p">),</span>
        <span class="n">warmup_steps</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span>
        <span class="n">log_freq</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
        <span class="n">device</span><span class="o">=</span><span class="s">'cuda'</span>
        <span class="p">):</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">device</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">train_data</span> <span class="o">=</span> <span class="n">train_dataloader</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">test_data</span> <span class="o">=</span> <span class="n">test_dataloader</span>

        <span class="c1"># Setting the Adam optimizer with hyper-param
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">optim</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span> <span class="n">betas</span><span class="o">=</span><span class="n">betas</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="n">weight_decay</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">optim_schedule</span> <span class="o">=</span> <span class="n">ScheduledOptim</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">optim</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="n">bert</span><span class="p">.</span><span class="n">d_model</span><span class="p">,</span> <span class="n">n_warmup_steps</span><span class="o">=</span><span class="n">warmup_steps</span>
            <span class="p">)</span>

        <span class="c1"># Using Negative Log Likelihood Loss function for predicting the masked_token
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">criterion</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">NLLLoss</span><span class="p">(</span><span class="n">ignore_index</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">log_freq</span> <span class="o">=</span> <span class="n">log_freq</span>
        <span class="k">print</span><span class="p">(</span><span class="s">"Total Parameters:"</span><span class="p">,</span> <span class="nb">sum</span><span class="p">([</span><span class="n">p</span><span class="p">.</span><span class="n">nelement</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">()]))</span>
    
    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">iteration</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">train_data</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">test</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">iteration</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">test_data</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">iteration</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">data_loader</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
        
        <span class="n">avg_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="n">total_correct</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">total_element</span> <span class="o">=</span> <span class="mi">0</span>
        
        <span class="n">mode</span> <span class="o">=</span> <span class="s">"train"</span> <span class="k">if</span> <span class="n">train</span> <span class="k">else</span> <span class="s">"test"</span>

        <span class="c1"># progress bar
</span>        <span class="n">data_iter</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">.</span><span class="n">tqdm</span><span class="p">(</span>
            <span class="nb">enumerate</span><span class="p">(</span><span class="n">data_loader</span><span class="p">),</span>
            <span class="n">desc</span><span class="o">=</span><span class="s">"EP_%s:%d"</span> <span class="o">%</span> <span class="p">(</span><span class="n">mode</span><span class="p">,</span> <span class="n">epoch</span><span class="p">),</span>
            <span class="n">total</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">data_loader</span><span class="p">),</span>
            <span class="n">bar_format</span><span class="o">=</span><span class="s">"{l_bar}{r_bar}"</span>
        <span class="p">)</span>

        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">data_iter</span><span class="p">:</span>

            <span class="c1"># 0. batch_data will be sent into the device(GPU or cpu)
</span>            <span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="n">key</span><span class="p">:</span> <span class="n">value</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">data</span><span class="p">.</span><span class="n">items</span><span class="p">()}</span>

            <span class="c1"># 1. forward the next_sentence_prediction and masked_lm model
</span>            <span class="n">next_sent_output</span><span class="p">,</span> <span class="n">mask_lm_output</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="n">forward</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s">"bert_input"</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="s">"segment_label"</span><span class="p">])</span>

            <span class="c1"># 2-1. NLL(negative log likelihood) loss of is_next classification result
</span>            <span class="n">next_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">criterion</span><span class="p">(</span><span class="n">next_sent_output</span><span class="p">,</span> <span class="n">data</span><span class="p">[</span><span class="s">"is_next"</span><span class="p">])</span>

            <span class="c1"># 2-2. NLLLoss of predicting masked token word
</span>            <span class="c1"># transpose to (m, vocab_size, seq_len) vs (m, seq_len)
</span>            <span class="c1"># criterion(mask_lm_output.view(-1, mask_lm_output.size(-1)), data["bert_label"].view(-1))
</span>            <span class="n">mask_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">criterion</span><span class="p">(</span><span class="n">mask_lm_output</span><span class="p">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">data</span><span class="p">[</span><span class="s">"bert_label"</span><span class="p">])</span>

            <span class="c1"># 2-3. Adding next_loss and mask_loss : 3.4 Pre-training Procedure
</span>            <span class="n">loss</span> <span class="o">=</span> <span class="n">next_loss</span> <span class="o">+</span> <span class="n">mask_loss</span>

            <span class="c1"># 3. backward and optimization only in train
</span>            <span class="k">if</span> <span class="n">train</span><span class="p">:</span>
                <span class="bp">self</span><span class="p">.</span><span class="n">optim_schedule</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>
                <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
                <span class="bp">self</span><span class="p">.</span><span class="n">optim_schedule</span><span class="p">.</span><span class="n">step_and_update_lr</span><span class="p">()</span>

            <span class="c1"># next sentence prediction accuracy
</span>            <span class="n">correct</span> <span class="o">=</span> <span class="n">next_sent_output</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">).</span><span class="n">eq</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s">"is_next"</span><span class="p">]).</span><span class="nb">sum</span><span class="p">().</span><span class="n">item</span><span class="p">()</span>
            <span class="n">avg_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="p">.</span><span class="n">item</span><span class="p">()</span>
            <span class="n">total_correct</span> <span class="o">+=</span> <span class="n">correct</span>
            <span class="n">total_element</span> <span class="o">+=</span> <span class="n">data</span><span class="p">[</span><span class="s">"is_next"</span><span class="p">].</span><span class="n">nelement</span><span class="p">()</span>

            <span class="n">post_fix</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s">"epoch"</span><span class="p">:</span> <span class="n">epoch</span><span class="p">,</span>
                <span class="s">"iter"</span><span class="p">:</span> <span class="n">i</span><span class="p">,</span>
                <span class="s">"avg_loss"</span><span class="p">:</span> <span class="n">avg_loss</span> <span class="o">/</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span>
                <span class="s">"avg_acc"</span><span class="p">:</span> <span class="n">total_correct</span> <span class="o">/</span> <span class="n">total_element</span> <span class="o">*</span> <span class="mi">100</span><span class="p">,</span>
                <span class="s">"loss"</span><span class="p">:</span> <span class="n">loss</span><span class="p">.</span><span class="n">item</span><span class="p">()</span>
            <span class="p">}</span>

            <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="bp">self</span><span class="p">.</span><span class="n">log_freq</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">data_iter</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">post_fix</span><span class="p">))</span>
        <span class="k">print</span><span class="p">(</span>
            <span class="sa">f</span><span class="s">"EP</span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s">, </span><span class="si">{</span><span class="n">mode</span><span class="si">}</span><span class="s">: </span><span class="se">\
</span><span class="s">            avg_loss=</span><span class="si">{</span><span class="n">avg_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">data_iter</span><span class="p">)</span><span class="si">}</span><span class="s">, </span><span class="se">\
</span><span class="s">            total_acc=</span><span class="si">{</span><span class="n">total_correct</span> <span class="o">*</span> <span class="mf">100.0</span> <span class="o">/</span> <span class="n">total_element</span><span class="si">}</span><span class="s">"</span>
        <span class="p">)</span> 

<span class="c1">### test
</span><span class="n">train_data</span> <span class="o">=</span> <span class="n">BERTDataset</span><span class="p">(</span><span class="n">pairs</span><span class="p">,</span> <span class="n">seq_len</span><span class="o">=</span><span class="n">MAX_LEN</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">)</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">pin_memory</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">bert_model</span> <span class="o">=</span> <span class="n">BERT</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">.</span><span class="n">vocab</span><span class="p">))</span>
<span class="n">bert_lm</span> <span class="o">=</span> <span class="n">BERTLM</span><span class="p">(</span><span class="n">bert_model</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">.</span><span class="n">vocab</span><span class="p">))</span>
<span class="n">bert_trainer</span> <span class="o">=</span> <span class="n">BERTTrainer</span><span class="p">(</span><span class="n">bert_lm</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s">'cpu'</span><span class="p">)</span>   
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">2</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    <span class="n">bert_trainer</span><span class="p">.</span><span class="n">train</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Total Parameters: 117561257


EP_train:0:   0%|| 1/6926 [00:04&lt;9:01:10,  4.69s/it]

{'epoch': 0, 'iter': 0, 'avg_loss': 10.89798355102539, 'avg_acc': 53.125, 'loss': 10.89798355102539}


EP_train:0:   0%|| 11/6926 [00:39&lt;6:37:53,  3.45s/it]

{'epoch': 0, 'iter': 10, 'avg_loss': 10.867982777682217, 'avg_acc': 50.0, 'loss': 10.717849731445312}


EP_train:0:   0%|| 21/6926 [01:14&lt;6:35:39,  3.44s/it]

{'epoch': 0, 'iter': 20, 'avg_loss': 10.625354085649763, 'avg_acc': 50.0, 'loss': 10.077768325805664}


EP_train:0:   0%|| 31/6926 [01:48&lt;6:36:18,  3.45s/it]

{'epoch': 0, 'iter': 30, 'avg_loss': 10.422906321863975, 'avg_acc': 49.29435483870967, 'loss': 9.897195816040039}


EP_train:0:   1%|| 41/6926 [02:23&lt;6:41:40,  3.50s/it]

{'epoch': 0, 'iter': 40, 'avg_loss': 10.273156724325041, 'avg_acc': 49.84756097560975, 'loss': 9.698206901550293}


EP_train:0:   1%|| 51/6926 [02:57&lt;6:33:31,  3.43s/it]

{'epoch': 0, 'iter': 50, 'avg_loss': 10.160286865982355, 'avg_acc': 49.754901960784316, 'loss': 9.699801445007324}


EP_train:0:   1%|| 61/6926 [03:32&lt;6:38:19,  3.48s/it]

{'epoch': 0, 'iter': 60, 'avg_loss': 10.034004461569864, 'avg_acc': 50.25614754098361, 'loss': 9.232473373413086}


EP_train:0:   1%|| 71/6926 [04:06&lt;6:35:02,  3.46s/it]

{'epoch': 0, 'iter': 70, 'avg_loss': 9.914001276795293, 'avg_acc': 50.26408450704225, 'loss': 9.27730941772461}


EP_train:0:   1%|| 81/6926 [04:41&lt;6:33:04,  3.45s/it]

{'epoch': 0, 'iter': 80, 'avg_loss': 9.792469695762351, 'avg_acc': 50.1929012345679, 'loss': 8.917365074157715}


EP_train:0:   1%|| 91/6926 [05:15&lt;6:28:32,  3.41s/it]

{'epoch': 0, 'iter': 90, 'avg_loss': 9.684995368286804, 'avg_acc': 50.24038461538461, 'loss': 8.476027488708496}


EP_train:0:   1%|| 101/6926 [05:50&lt;6:35:22,  3.48s/it]

{'epoch': 0, 'iter': 100, 'avg_loss': 9.58456044149871, 'avg_acc': 49.93811881188119, 'loss': 8.499567985534668}


EP_train:0:   2%|| 111/6926 [06:24&lt;6:31:06,  3.44s/it]

{'epoch': 0, 'iter': 110, 'avg_loss': 9.4917702288241, 'avg_acc': 49.74662162162162, 'loss': 8.589751243591309}


EP_train:0:   2%|| 121/6926 [06:59&lt;6:29:42,  3.44s/it]

{'epoch': 0, 'iter': 120, 'avg_loss': 9.402804642669425, 'avg_acc': 49.43181818181818, 'loss': 8.433043479919434}


EP_train:0:   2%|| 131/6926 [07:33&lt;6:29:06,  3.44s/it]

{'epoch': 0, 'iter': 130, 'avg_loss': 9.320094690978072, 'avg_acc': 49.666030534351144, 'loss': 8.0137300491333}


EP_train:0:   2%|| 141/6926 [08:08&lt;6:28:28,  3.44s/it]

{'epoch': 0, 'iter': 140, 'avg_loss': 9.249869021963566, 'avg_acc': 49.933510638297875, 'loss': 8.34340763092041}


EP_train:0:   2%|| 151/6926 [08:42&lt;6:29:39,  3.45s/it]

{'epoch': 0, 'iter': 150, 'avg_loss': 9.182195328718779, 'avg_acc': 49.544701986754966, 'loss': 8.372312545776367}


EP_train:0:   2%|| 161/6926 [09:16&lt;6:28:02,  3.44s/it]

{'epoch': 0, 'iter': 160, 'avg_loss': 9.11899014881679, 'avg_acc': 49.631211180124225, 'loss': 8.272394180297852}


EP_train:0:   2%|| 171/6926 [09:51&lt;6:30:13,  3.47s/it]

{'epoch': 0, 'iter': 170, 'avg_loss': 9.060561514737314, 'avg_acc': 49.45175438596491, 'loss': 8.310636520385742}


EP_train:0:   3%|| 181/6926 [10:25&lt;6:27:49,  3.45s/it]

{'epoch': 0, 'iter': 180, 'avg_loss': 8.996443795894391, 'avg_acc': 49.51657458563536, 'loss': 8.046950340270996}


EP_train:0:   3%|| 191/6926 [11:00&lt;6:28:24,  3.46s/it]

{'epoch': 0, 'iter': 190, 'avg_loss': 8.946776854430194, 'avg_acc': 49.85274869109947, 'loss': 7.704115390777588}


EP_train:0:   3%|| 201/6926 [11:34&lt;6:25:56,  3.44s/it]

{'epoch': 0, 'iter': 200, 'avg_loss': 8.900923088415345, 'avg_acc': 49.98445273631841, 'loss': 7.938549518585205}


EP_train:0:   3%|| 211/6926 [12:09&lt;6:27:00,  3.46s/it]

{'epoch': 0, 'iter': 210, 'avg_loss': 8.856869426383792, 'avg_acc': 49.703791469194314, 'loss': 8.166866302490234}


EP_train:0:   3%|| 221/6926 [12:43&lt;6:23:55,  3.44s/it]

{'epoch': 0, 'iter': 220, 'avg_loss': 8.813115471628457, 'avg_acc': 49.872737556561084, 'loss': 8.149380683898926}


EP_train:0:   3%|| 231/6926 [13:18&lt;6:23:50,  3.44s/it]

{'epoch': 0, 'iter': 230, 'avg_loss': 8.776155362397562, 'avg_acc': 49.91883116883117, 'loss': 7.758193492889404}


EP_train:0:   3%|| 241/6926 [13:52&lt;6:28:36,  3.49s/it]

{'epoch': 0, 'iter': 240, 'avg_loss': 8.742853582152687, 'avg_acc': 49.7795643153527, 'loss': 8.106270790100098}


EP_train:0:   4%|| 251/6926 [14:27&lt;6:23:08,  3.44s/it]

{'epoch': 0, 'iter': 250, 'avg_loss': 8.702998539366096, 'avg_acc': 49.93774900398406, 'loss': 7.42200231552124}


EP_train:0:   4%|| 261/6926 [15:02&lt;6:21:51,  3.44s/it]

{'epoch': 0, 'iter': 260, 'avg_loss': 8.672737653228058, 'avg_acc': 49.724616858237546, 'loss': 7.538005352020264}


EP_train:0:   4%|| 271/6926 [15:36&lt;6:24:18,  3.46s/it]

{'epoch': 0, 'iter': 270, 'avg_loss': 8.637632560026162, 'avg_acc': 49.8270295202952, 'loss': 7.825370788574219}


EP_train:0:   4%|| 281/6926 [16:10&lt;6:20:35,  3.44s/it]

{'epoch': 0, 'iter': 280, 'avg_loss': 8.606602544886362, 'avg_acc': 50.011120996441285, 'loss': 7.539271354675293}


EP_train:0:   4%|| 291/6926 [16:45&lt;6:21:08,  3.45s/it]

{'epoch': 0, 'iter': 290, 'avg_loss': 8.573296895961171, 'avg_acc': 49.96778350515464, 'loss': 7.512895107269287}


EP_train:0:   4%|| 301/6926 [17:19&lt;6:17:24,  3.42s/it]

{'epoch': 0, 'iter': 300, 'avg_loss': 8.538208223260519, 'avg_acc': 49.91694352159469, 'loss': 7.337748050689697}


EP_train:0:   4%|| 311/6926 [17:54&lt;6:22:07,  3.47s/it]

{'epoch': 0, 'iter': 310, 'avg_loss': 8.508915681930983, 'avg_acc': 49.85932475884244, 'loss': 7.346322536468506}


EP_train:0:   5%|| 321/6926 [18:29&lt;6:22:02,  3.47s/it]

{'epoch': 0, 'iter': 320, 'avg_loss': 8.483167216042492, 'avg_acc': 49.84423676012461, 'loss': 7.777610778808594}


EP_train:0:   5%|| 331/6926 [19:04&lt;6:25:17,  3.51s/it]

{'epoch': 0, 'iter': 330, 'avg_loss': 8.454026497382772, 'avg_acc': 49.94335347432024, 'loss': 7.688755512237549}


EP_train:0:   5%|| 341/6926 [19:39&lt;6:25:37,  3.51s/it]

{'epoch': 0, 'iter': 340, 'avg_loss': 8.425729666287598, 'avg_acc': 50.0274926686217, 'loss': 7.76571798324585}


EP_train:0:   5%|| 351/6926 [20:13&lt;6:18:38,  3.46s/it]

{'epoch': 0, 'iter': 350, 'avg_loss': 8.397578780128066, 'avg_acc': 50.089031339031344, 'loss': 7.333456039428711}


EP_train:0:   5%|| 361/6926 [20:48&lt;6:15:35,  3.43s/it]

{'epoch': 0, 'iter': 360, 'avg_loss': 8.373832571869741, 'avg_acc': 50.181786703601105, 'loss': 7.28127384185791}


EP_train:0:   5%|| 371/6926 [21:23&lt;6:23:48,  3.51s/it]

{'epoch': 0, 'iter': 370, 'avg_loss': 8.34467096919962, 'avg_acc': 50.10950134770889, 'loss': 7.208791255950928}


EP_train:0:   6%|| 381/6926 [21:58&lt;6:23:20,  3.51s/it]

{'epoch': 0, 'iter': 380, 'avg_loss': 8.318920097951814, 'avg_acc': 50.14763779527559, 'loss': 7.3540472984313965}


EP_train:0:   6%|| 391/6926 [22:33&lt;6:16:44,  3.46s/it]

{'epoch': 0, 'iter': 390, 'avg_loss': 8.294580609597208, 'avg_acc': 50.22378516624041, 'loss': 7.1569037437438965}


EP_train:0:   6%|| 401/6926 [23:08&lt;6:16:49,  3.47s/it]

{'epoch': 0, 'iter': 400, 'avg_loss': 8.26598995522668, 'avg_acc': 50.194825436408976, 'loss': 7.342164993286133}


EP_train:0:   6%|| 411/6926 [23:42&lt;6:17:28,  3.48s/it]

{'epoch': 0, 'iter': 410, 'avg_loss': 8.244329189152033, 'avg_acc': 50.159671532846716, 'loss': 7.136423587799072}


EP_train:0:   6%|| 421/6926 [24:17&lt;6:15:41,  3.47s/it]

{'epoch': 0, 'iter': 420, 'avg_loss': 8.217572627894386, 'avg_acc': 50.24495249406176, 'loss': 6.9360151290893555}


EP_train:0:   6%|| 431/6926 [24:52&lt;6:17:11,  3.48s/it]

{'epoch': 0, 'iter': 430, 'avg_loss': 8.190027959385494, 'avg_acc': 50.16676334106729, 'loss': 6.8516340255737305}


EP_train:0:   6%|| 441/6926 [25:26&lt;6:16:11,  3.48s/it]

{'epoch': 0, 'iter': 440, 'avg_loss': 8.163161752445628, 'avg_acc': 50.09920634920635, 'loss': 6.856698036193848}


EP_train:0:   7%|| 451/6926 [26:01&lt;6:14:24,  3.47s/it]

{'epoch': 0, 'iter': 450, 'avg_loss': 8.137615378310041, 'avg_acc': 50.0, 'loss': 7.232318878173828}


EP_train:0:   7%|| 461/6926 [26:36&lt;6:09:12,  3.43s/it]

{'epoch': 0, 'iter': 460, 'avg_loss': 8.112295510712, 'avg_acc': 50.074566160520604, 'loss': 7.3403191566467285}


EP_train:0:   7%|| 471/6926 [27:10&lt;6:11:22,  3.45s/it]

{'epoch': 0, 'iter': 470, 'avg_loss': 8.08871301622654, 'avg_acc': 50.1526008492569, 'loss': 6.741003513336182}


EP_train:0:   7%|| 481/6926 [27:44&lt;6:10:50,  3.45s/it]

{'epoch': 0, 'iter': 480, 'avg_loss': 8.062562408169688, 'avg_acc': 50.11044698544699, 'loss': 7.173391819000244}


EP_train:0:   7%|| 491/6926 [28:19&lt;6:07:40,  3.43s/it]

{'epoch': 0, 'iter': 490, 'avg_loss': 8.039472820802521, 'avg_acc': 50.10819755600815, 'loss': 6.775766372680664}


EP_train:0:   7%|| 501/6926 [28:53&lt;6:10:09,  3.46s/it]

{'epoch': 0, 'iter': 500, 'avg_loss': 8.015938852123634, 'avg_acc': 50.1746506986028, 'loss': 6.762749195098877}


EP_train:0:   7%|| 511/6926 [29:28&lt;6:06:51,  3.43s/it]

{'epoch': 0, 'iter': 510, 'avg_loss': 7.990972069144949, 'avg_acc': 50.28131115459883, 'loss': 6.97685432434082}


EP_train:0:   8%|| 521/6926 [30:02&lt;6:05:00,  3.42s/it]

{'epoch': 0, 'iter': 520, 'avg_loss': 7.968726086753802, 'avg_acc': 50.38987523992322, 'loss': 6.717159748077393}


EP_train:0:   8%|| 531/6926 [30:37&lt;6:08:22,  3.46s/it]

{'epoch': 0, 'iter': 530, 'avg_loss': 7.9469300663403875, 'avg_acc': 50.32956685499058, 'loss': 6.882143020629883}


EP_train:0:   8%|| 541/6926 [31:11&lt;6:07:26,  3.45s/it]

{'epoch': 0, 'iter': 540, 'avg_loss': 7.923942721925689, 'avg_acc': 50.27148798521257, 'loss': 6.626901626586914}


EP_train:0:   8%|| 551/6926 [31:46&lt;6:07:35,  3.46s/it]

{'epoch': 0, 'iter': 550, 'avg_loss': 7.900415689672619, 'avg_acc': 50.25521778584392, 'loss': 6.582065105438232}


EP_train:0:   8%|| 561/6926 [32:20&lt;6:04:30,  3.44s/it]

{'epoch': 0, 'iter': 560, 'avg_loss': 7.878857596460298, 'avg_acc': 50.217245989304814, 'loss': 6.515105247497559}


EP_train:0:   8%|| 571/6926 [32:55&lt;6:05:31,  3.45s/it]

{'epoch': 0, 'iter': 570, 'avg_loss': 7.854935056482639, 'avg_acc': 50.333844133099824, 'loss': 6.567478179931641}


EP_train:0:   8%|| 581/6926 [33:29&lt;6:01:53,  3.42s/it]

{'epoch': 0, 'iter': 580, 'avg_loss': 7.830255449331156, 'avg_acc': 50.371127366609294, 'loss': 6.469046592712402}


EP_train:0:   9%|| 591/6926 [34:04&lt;6:06:36,  3.47s/it]

{'epoch': 0, 'iter': 590, 'avg_loss': 7.807632289763836, 'avg_acc': 50.34369712351946, 'loss': 6.447710037231445}


EP_train:0:   9%|| 601/6926 [34:38&lt;6:03:22,  3.45s/it]

{'epoch': 0, 'iter': 600, 'avg_loss': 7.785173703350759, 'avg_acc': 50.33797836938436, 'loss': 6.640997886657715}


EP_train:0:   9%|| 611/6926 [35:13&lt;6:02:34,  3.44s/it]

{'epoch': 0, 'iter': 610, 'avg_loss': 7.764555183448104, 'avg_acc': 50.32221767594108, 'loss': 6.900795936584473}


EP_train:0:   9%|| 621/6926 [35:47&lt;6:01:05,  3.44s/it]

{'epoch': 0, 'iter': 620, 'avg_loss': 7.744011157952645, 'avg_acc': 50.31702898550725, 'loss': 6.4761457443237305}


EP_train:0:   9%|| 631/6926 [36:22&lt;6:00:15,  3.43s/it]

{'epoch': 0, 'iter': 630, 'avg_loss': 7.723728686996194, 'avg_acc': 50.38629160063392, 'loss': 6.653886795043945}


EP_train:0:   9%|| 641/6926 [36:56&lt;6:02:31,  3.46s/it]

{'epoch': 0, 'iter': 640, 'avg_loss': 7.703406612884236, 'avg_acc': 50.35588923556942, 'loss': 6.2323832511901855}


EP_train:0:   9%|| 651/6926 [37:31&lt;6:02:14,  3.46s/it]

{'epoch': 0, 'iter': 650, 'avg_loss': 7.682767451999741, 'avg_acc': 50.360023041474655, 'loss': 6.42466402053833}


EP_train:0:  10%|| 661/6926 [38:06&lt;5:58:39,  3.43s/it]

{'epoch': 0, 'iter': 660, 'avg_loss': 7.663271325438899, 'avg_acc': 50.34512102874432, 'loss': 6.657591342926025}


EP_train:0:  10%|| 671/6926 [38:40&lt;6:00:59,  3.46s/it]

{'epoch': 0, 'iter': 670, 'avg_loss': 7.643598909704944, 'avg_acc': 50.293405365126674, 'loss': 6.493916034698486}


EP_train:0:  10%|| 681/6926 [39:15&lt;6:01:43,  3.48s/it]

{'epoch': 0, 'iter': 680, 'avg_loss': 7.625312284225934, 'avg_acc': 50.293685756240826, 'loss': 6.703272819519043}


EP_train:0:  10%|| 691/6926 [39:50&lt;5:57:29,  3.44s/it]

{'epoch': 0, 'iter': 690, 'avg_loss': 7.606728428179552, 'avg_acc': 50.23064399421129, 'loss': 6.424178600311279}


EP_train:0:  10%|| 701/6926 [40:24&lt;6:01:32,  3.48s/it]

{'epoch': 0, 'iter': 700, 'avg_loss': 7.587192697973973, 'avg_acc': 50.17831669044222, 'loss': 6.348569869995117}


EP_train:0:  10%|| 711/6926 [40:59&lt;5:56:46,  3.44s/it]

{'epoch': 0, 'iter': 710, 'avg_loss': 7.569472739465126, 'avg_acc': 50.210970464135016, 'loss': 6.120439052581787}


EP_train:0:  10%|| 721/6926 [41:33&lt;6:00:29,  3.49s/it]

{'epoch': 0, 'iter': 720, 'avg_loss': 7.552519568788526, 'avg_acc': 50.186373092926495, 'loss': 5.9562296867370605}


EP_train:0:  11%|| 731/6926 [42:08&lt;5:57:57,  3.47s/it]

{'epoch': 0, 'iter': 730, 'avg_loss': 7.534771291077871, 'avg_acc': 50.14962380300958, 'loss': 6.235836505889893}


EP_train:0:  11%|| 741/6926 [42:43&lt;5:58:59,  3.48s/it]

{'epoch': 0, 'iter': 740, 'avg_loss': 7.516607673222881, 'avg_acc': 50.10964912280702, 'loss': 5.814441204071045}


EP_train:0:  11%|| 751/6926 [43:18&lt;5:58:59,  3.49s/it]

{'epoch': 0, 'iter': 750, 'avg_loss': 7.499122726298204, 'avg_acc': 50.178928095872166, 'loss': 5.808696269989014}


EP_train:0:  11%|| 761/6926 [43:52&lt;5:54:51,  3.45s/it]

{'epoch': 0, 'iter': 760, 'avg_loss': 7.481864879698383, 'avg_acc': 50.193002628120894, 'loss': 6.158096790313721}


EP_train:0:  11%|| 771/6926 [44:27&lt;5:55:41,  3.47s/it]

{'epoch': 0, 'iter': 770, 'avg_loss': 7.4656713172774065, 'avg_acc': 50.15402075226978, 'loss': 6.347654819488525}


EP_train:0:  11%|| 781/6926 [45:01&lt;6:02:42,  3.54s/it]

{'epoch': 0, 'iter': 780, 'avg_loss': 7.4503515539034995, 'avg_acc': 50.11203585147247, 'loss': 6.144024848937988}


EP_train:0:  11%|| 791/6926 [45:36&lt;5:50:23,  3.43s/it]

{'epoch': 0, 'iter': 790, 'avg_loss': 7.433421123494994, 'avg_acc': 50.11061946902655, 'loss': 5.9156012535095215}


EP_train:0:  12%|| 801/6926 [46:10&lt;5:50:32,  3.43s/it]

{'epoch': 0, 'iter': 800, 'avg_loss': 7.416626945714676, 'avg_acc': 50.105337078651694, 'loss': 6.050990581512451}


EP_train:0:  12%|| 811/6926 [46:44&lt;5:48:55,  3.42s/it]

{'epoch': 0, 'iter': 810, 'avg_loss': 7.4007179522484945, 'avg_acc': 50.1040382244143, 'loss': 6.308589458465576}


EP_train:0:  12%|| 821/6926 [47:19&lt;5:50:34,  3.45s/it]

{'epoch': 0, 'iter': 820, 'avg_loss': 7.385387445628716, 'avg_acc': 50.106577344701584, 'loss': 5.797635078430176}


EP_train:0:  12%|| 831/6926 [47:54&lt;5:50:21,  3.45s/it]

{'epoch': 0, 'iter': 830, 'avg_loss': 7.3701629587028865, 'avg_acc': 50.157942238267154, 'loss': 6.100361347198486}


EP_train:0:  12%|| 841/6926 [48:28&lt;5:53:21,  3.48s/it]

{'epoch': 0, 'iter': 840, 'avg_loss': 7.355489640683822, 'avg_acc': 50.182074910820454, 'loss': 6.523128986358643}


EP_train:0:  12%|| 851/6926 [49:03&lt;5:51:57,  3.48s/it]

{'epoch': 0, 'iter': 850, 'avg_loss': 7.338581892634391, 'avg_acc': 50.146886016451234, 'loss': 5.890628814697266}


EP_train:0:  12%|| 861/6926 [49:38&lt;5:55:22,  3.52s/it]

{'epoch': 0, 'iter': 860, 'avg_loss': 7.3246063903649095, 'avg_acc': 50.13792102206737, 'loss': 5.798765659332275}


EP_train:0:  13%|| 871/6926 [50:13&lt;6:16:19,  3.73s/it]

{'epoch': 0, 'iter': 870, 'avg_loss': 7.309846629505179, 'avg_acc': 50.11839839265212, 'loss': 6.017465591430664}


EP_train:0:  13%|| 881/6926 [50:48&lt;5:49:03,  3.46s/it]

{'epoch': 0, 'iter': 880, 'avg_loss': 7.294576557756959, 'avg_acc': 50.152525539160045, 'loss': 6.191736698150635}


EP_train:0:  13%|| 891/6926 [51:22&lt;5:46:13,  3.44s/it]

{'epoch': 0, 'iter': 890, 'avg_loss': 7.280248526370887, 'avg_acc': 50.14029180695847, 'loss': 5.8434906005859375}


EP_train:0:  13%|| 901/6926 [51:57&lt;5:47:59,  3.47s/it]

{'epoch': 0, 'iter': 900, 'avg_loss': 7.267267483849901, 'avg_acc': 50.11098779134295, 'loss': 6.437450885772705}


EP_train:0:  13%|| 911/6926 [52:32&lt;5:49:36,  3.49s/it]

{'epoch': 0, 'iter': 910, 'avg_loss': 7.252066610149965, 'avg_acc': 50.12692096597146, 'loss': 5.577602863311768}


EP_train:0:  13%|| 921/6926 [53:07&lt;5:55:37,  3.55s/it]

{'epoch': 0, 'iter': 920, 'avg_loss': 7.2393625836160105, 'avg_acc': 50.139115092290986, 'loss': 6.020793914794922}


EP_train:0:  13%|| 931/6926 [53:42&lt;5:50:26,  3.51s/it]

{'epoch': 0, 'iter': 930, 'avg_loss': 7.2262739520579995, 'avg_acc': 50.137620837808804, 'loss': 6.0215888023376465}


EP_train:0:  14%|| 941/6926 [54:16&lt;5:43:23,  3.44s/it]

{'epoch': 0, 'iter': 940, 'avg_loss': 7.215727404250855, 'avg_acc': 50.13283740701382, 'loss': 6.280351161956787}


EP_train:0:  14%|| 951/6926 [54:51&lt;5:43:46,  3.45s/it]

{'epoch': 0, 'iter': 950, 'avg_loss': 7.203543867598572, 'avg_acc': 50.1215825446898, 'loss': 6.030501842498779}


EP_train:0:  14%|| 961/6926 [55:25&lt;5:49:09,  3.51s/it]

{'epoch': 0, 'iter': 960, 'avg_loss': 7.191026379985194, 'avg_acc': 50.11381373569199, 'loss': 6.155196189880371}


EP_train:0:  14%|| 971/6926 [56:00&lt;5:42:05,  3.45s/it]

{'epoch': 0, 'iter': 970, 'avg_loss': 7.177859566115941, 'avg_acc': 50.13838825952626, 'loss': 6.143617153167725}


EP_train:0:  14%|| 981/6926 [56:35&lt;5:48:32,  3.52s/it]

{'epoch': 0, 'iter': 980, 'avg_loss': 7.165363018179766, 'avg_acc': 50.11786442405708, 'loss': 6.266634464263916}


EP_train:0:  14%|| 991/6926 [57:09&lt;5:45:55,  3.50s/it]

{'epoch': 0, 'iter': 990, 'avg_loss': 7.1547578408427, 'avg_acc': 50.12613521695257, 'loss': 5.8587799072265625}


EP_train:0:  14%|| 1001/6926 [57:44&lt;5:40:42,  3.45s/it]

{'epoch': 0, 'iter': 1000, 'avg_loss': 7.143188433690028, 'avg_acc': 50.19043456543456, 'loss': 5.374644756317139}


EP_train:0:  15%|| 1011/6926 [58:19&lt;5:40:44,  3.46s/it]

{'epoch': 0, 'iter': 1010, 'avg_loss': 7.130960667758266, 'avg_acc': 50.09891196834817, 'loss': 5.900915622711182}


EP_train:0:  15%|| 1021/6926 [58:53&lt;5:41:47,  3.47s/it]

{'epoch': 0, 'iter': 1020, 'avg_loss': 7.118152967746298, 'avg_acc': 50.0765181194907, 'loss': 5.907759666442871}


EP_train:0:  15%|| 1031/6926 [59:28&lt;5:40:24,  3.46s/it]

{'epoch': 0, 'iter': 1030, 'avg_loss': 7.106619142537899, 'avg_acc': 50.054558680892335, 'loss': 5.74845552444458}


EP_train:0:  15%|| 1041/6926 [1:00:02&lt;5:35:59,  3.43s/it]

{'epoch': 0, 'iter': 1040, 'avg_loss': 7.0948704202855355, 'avg_acc': 50.03302113352546, 'loss': 6.052654266357422}


EP_train:0:  15%|| 1051/6926 [1:00:37&lt;5:40:52,  3.48s/it]

{'epoch': 0, 'iter': 1050, 'avg_loss': 7.082714090338216, 'avg_acc': 50.04757373929591, 'loss': 5.714799880981445}


EP_train:0:  15%|| 1061/6926 [1:01:12&lt;5:42:37,  3.51s/it]

{'epoch': 0, 'iter': 1060, 'avg_loss': 7.0725709513377515, 'avg_acc': 50.047125353440144, 'loss': 5.841132164001465}


EP_train:0:  15%|| 1071/6926 [1:01:47&lt;5:42:38,  3.51s/it]

{'epoch': 0, 'iter': 1070, 'avg_loss': 7.062578005839685, 'avg_acc': 50.04668534080299, 'loss': 6.043107986450195}


EP_train:0:  16%|| 1081/6926 [1:02:21&lt;5:36:16,  3.45s/it]

{'epoch': 0, 'iter': 1080, 'avg_loss': 7.052328350144774, 'avg_acc': 50.01156336725254, 'loss': 5.979182243347168}


EP_train:0:  16%|| 1091/6926 [1:02:56&lt;5:35:00,  3.44s/it]

{'epoch': 0, 'iter': 1090, 'avg_loss': 7.042487336341446, 'avg_acc': 50.01432172318974, 'loss': 5.883883953094482}


EP_train:0:  16%|| 1101/6926 [1:03:31&lt;5:37:29,  3.48s/it]

{'epoch': 0, 'iter': 1100, 'avg_loss': 7.031923555223429, 'avg_acc': 50.00851498637602, 'loss': 5.748727321624756}


EP_train:0:  16%|| 1111/6926 [1:04:05&lt;5:37:39,  3.48s/it]

{'epoch': 0, 'iter': 1110, 'avg_loss': 7.0224045612702595, 'avg_acc': 49.991561656165615, 'loss': 5.702943801879883}


EP_train:0:  16%|| 1121/6926 [1:04:40&lt;5:34:33,  3.46s/it]

{'epoch': 0, 'iter': 1120, 'avg_loss': 7.012452934598625, 'avg_acc': 49.99442462087422, 'loss': 5.645112991333008}


EP_train:0:  16%|| 1131/6926 [1:05:15&lt;5:37:45,  3.50s/it]

{'epoch': 0, 'iter': 1130, 'avg_loss': 7.002737390583959, 'avg_acc': 49.98065870910698, 'loss': 6.049877643585205}


EP_train:0:  16%|| 1141/6926 [1:05:50&lt;5:31:52,  3.44s/it]

{'epoch': 0, 'iter': 1140, 'avg_loss': 6.99303060660333, 'avg_acc': 49.98904469763366, 'loss': 5.958681106567383}


EP_train:0:  17%|| 1151/6926 [1:06:25&lt;5:33:18,  3.46s/it]

{'epoch': 0, 'iter': 1150, 'avg_loss': 6.98393302332516, 'avg_acc': 50.00271503040834, 'loss': 5.5045552253723145}


EP_train:0:  17%|| 1161/6926 [1:06:59&lt;5:33:59,  3.48s/it]

{'epoch': 0, 'iter': 1160, 'avg_loss': 6.974377678551621, 'avg_acc': 50.00538329026701, 'loss': 5.9710164070129395}


EP_train:0:  17%|| 1171/6926 [1:07:34&lt;5:30:32,  3.45s/it]

{'epoch': 0, 'iter': 1170, 'avg_loss': 6.963725277341196, 'avg_acc': 50.00266865926558, 'loss': 5.79750394821167}


EP_train:0:  17%|| 1181/6926 [1:08:08&lt;5:28:49,  3.43s/it]

{'epoch': 0, 'iter': 1180, 'avg_loss': 6.954753385167521, 'avg_acc': 50.04498306519899, 'loss': 5.537152290344238}


EP_train:0:  17%|| 1191/6926 [1:08:43&lt;5:30:47,  3.46s/it]

{'epoch': 0, 'iter': 1190, 'avg_loss': 6.94566969907554, 'avg_acc': 50.07871536523929, 'loss': 5.853878021240234}


EP_train:0:  17%|| 1201/6926 [1:09:17&lt;5:29:13,  3.45s/it]

{'epoch': 0, 'iter': 1200, 'avg_loss': 6.937208781532205, 'avg_acc': 50.07285595337218, 'loss': 6.008646488189697}


EP_train:0:  17%|| 1211/6926 [1:09:52&lt;5:32:25,  3.49s/it]

{'epoch': 0, 'iter': 1210, 'avg_loss': 6.928555098769095, 'avg_acc': 50.05677126341867, 'loss': 5.945259094238281}


EP_train:0:  18%|| 1221/6926 [1:10:26&lt;5:28:31,  3.46s/it]

{'epoch': 0, 'iter': 1220, 'avg_loss': 6.920036094487446, 'avg_acc': 50.05374692874693, 'loss': 6.105030536651611}


EP_train:0:  18%|| 1231/6926 [1:11:01&lt;5:31:22,  3.49s/it]

{'epoch': 0, 'iter': 1230, 'avg_loss': 6.91204860518368, 'avg_acc': 50.00507717303005, 'loss': 5.601499557495117}


EP_train:0:  18%|| 1241/6926 [1:11:36&lt;5:27:26,  3.46s/it]

{'epoch': 0, 'iter': 1240, 'avg_loss': 6.90380984136503, 'avg_acc': 49.97481869460113, 'loss': 5.824779987335205}


EP_train:0:  18%|| 1251/6926 [1:12:10&lt;5:26:24,  3.45s/it]

{'epoch': 0, 'iter': 1250, 'avg_loss': 6.8957438419381685, 'avg_acc': 49.95503597122302, 'loss': 5.898371696472168}


EP_train:0:  18%|| 1261/6926 [1:12:45&lt;5:27:33,  3.47s/it]

{'epoch': 0, 'iter': 1260, 'avg_loss': 6.8863400270974795, 'avg_acc': 49.960348929421095, 'loss': 5.912337779998779}


EP_train:0:  18%|| 1271/6926 [1:13:19&lt;5:23:54,  3.44s/it]

{'epoch': 0, 'iter': 1270, 'avg_loss': 6.878045447880035, 'avg_acc': 49.955743509048, 'loss': 5.8559770584106445}


EP_train:0:  18%|| 1281/6926 [1:13:54&lt;5:25:14,  3.46s/it]

{'epoch': 0, 'iter': 1280, 'avg_loss': 6.870755708189703, 'avg_acc': 49.98536299765808, 'loss': 5.950345993041992}


EP_train:0:  19%|| 1291/6926 [1:14:29&lt;5:24:31,  3.46s/it]

{'epoch': 0, 'iter': 1290, 'avg_loss': 6.863620923158275, 'avg_acc': 49.961270333075134, 'loss': 5.999393463134766}


EP_train:0:  19%|| 1301/6926 [1:15:03&lt;5:21:48,  3.43s/it]

{'epoch': 0, 'iter': 1300, 'avg_loss': 6.856247264178875, 'avg_acc': 50.00240199846272, 'loss': 5.7338080406188965}


EP_train:0:  19%|| 1311/6926 [1:15:38&lt;5:23:22,  3.46s/it]

{'epoch': 0, 'iter': 1310, 'avg_loss': 6.849443752105503, 'avg_acc': 50.030987795575896, 'loss': 6.524251937866211}


EP_train:0:  19%|| 1321/6926 [1:16:13&lt;5:25:18,  3.48s/it]

{'epoch': 0, 'iter': 1320, 'avg_loss': 6.8420479512413195, 'avg_acc': 50.021290688872064, 'loss': 6.1805219650268555}


EP_train:0:  19%|| 1331/6926 [1:16:47&lt;5:24:17,  3.48s/it]

{'epoch': 0, 'iter': 1330, 'avg_loss': 6.834033288246344, 'avg_acc': 50.02347858752817, 'loss': 5.730384826660156}


EP_train:0:  19%|| 1341/6926 [1:17:22&lt;5:22:45,  3.47s/it]

{'epoch': 0, 'iter': 1340, 'avg_loss': 6.826291152205954, 'avg_acc': 50.044276659209544, 'loss': 5.616055011749268}


EP_train:0:  20%|| 1351/6926 [1:17:56&lt;5:22:55,  3.48s/it]

{'epoch': 0, 'iter': 1350, 'avg_loss': 6.8185702647922835, 'avg_acc': 50.03932272390822, 'loss': 5.9452009201049805}


EP_train:0:  20%|| 1361/6926 [1:18:31&lt;5:22:40,  3.48s/it]

{'epoch': 0, 'iter': 1360, 'avg_loss': 6.811983755631625, 'avg_acc': 50.04362601028656, 'loss': 5.786157608032227}


EP_train:0:  20%|| 1371/6926 [1:19:06&lt;5:19:56,  3.46s/it]

{'epoch': 0, 'iter': 1370, 'avg_loss': 6.805471073181241, 'avg_acc': 50.0, 'loss': 5.986886024475098}


EP_train:0:  20%|| 1381/6926 [1:19:41&lt;5:18:20,  3.44s/it]

{'epoch': 0, 'iter': 1380, 'avg_loss': 6.8000097996423765, 'avg_acc': 49.97963432295438, 'loss': 6.026611328125}


EP_train:0:  20%|| 1391/6926 [1:20:15&lt;5:17:38,  3.44s/it]

{'epoch': 0, 'iter': 1390, 'avg_loss': 6.793595924212896, 'avg_acc': 49.96630122214235, 'loss': 6.366022109985352}


EP_train:0:  20%|| 1401/6926 [1:20:50&lt;5:18:58,  3.46s/it]

{'epoch': 0, 'iter': 1400, 'avg_loss': 6.786099822243821, 'avg_acc': 49.95538900785154, 'loss': 5.348405838012695}


EP_train:0:  20%|| 1411/6926 [1:21:24&lt;5:18:42,  3.47s/it]

{'epoch': 0, 'iter': 1410, 'avg_loss': 6.779374823174859, 'avg_acc': 49.96456413890857, 'loss': 6.062073707580566}


EP_train:0:  21%|| 1421/6926 [1:21:59&lt;5:15:47,  3.44s/it]

{'epoch': 0, 'iter': 1420, 'avg_loss': 6.772841719319332, 'avg_acc': 49.931826178747365, 'loss': 5.9784393310546875}


EP_train:0:  21%|| 1431/6926 [1:22:34&lt;5:17:28,  3.47s/it]

{'epoch': 0, 'iter': 1430, 'avg_loss': 6.76654654328928, 'avg_acc': 49.951956673654784, 'loss': 5.905849933624268}


EP_train:0:  21%|| 1441/6926 [1:23:08&lt;5:16:11,  3.46s/it]

{'epoch': 0, 'iter': 1440, 'avg_loss': 6.760677034204656, 'avg_acc': 49.97831367106176, 'loss': 6.101155757904053}


EP_train:0:  21%|| 1451/6926 [1:23:43&lt;5:13:33,  3.44s/it]

{'epoch': 0, 'iter': 1450, 'avg_loss': 6.754288878135235, 'avg_acc': 49.956926257753274, 'loss': 5.826649188995361}


EP_train:0:  21%|| 1461/6926 [1:24:18&lt;5:16:22,  3.47s/it]

{'epoch': 0, 'iter': 1460, 'avg_loss': 6.748312718080054, 'avg_acc': 49.9679158110883, 'loss': 5.891135215759277}


EP_train:0:  21%|| 1471/6926 [1:24:52&lt;5:17:34,  3.49s/it]

{'epoch': 0, 'iter': 1470, 'avg_loss': 6.743577530236571, 'avg_acc': 49.98725356900068, 'loss': 5.77427864074707}


EP_train:0:  21%|| 1481/6926 [1:25:27&lt;5:15:40,  3.48s/it]

{'epoch': 0, 'iter': 1480, 'avg_loss': 6.737167069591597, 'avg_acc': 49.99366981769075, 'loss': 5.330727577209473}


EP_train:0:  22%|| 1491/6926 [1:26:02&lt;5:13:14,  3.46s/it]

{'epoch': 0, 'iter': 1490, 'avg_loss': 6.7310639086543596, 'avg_acc': 50.046109993293086, 'loss': 6.10654878616333}


EP_train:0:  22%|| 1501/6926 [1:26:36&lt;5:12:21,  3.45s/it]

{'epoch': 0, 'iter': 1500, 'avg_loss': 6.724842217348163, 'avg_acc': 50.03331112591606, 'loss': 5.758561611175537}


EP_train:0:  22%|| 1511/6926 [1:27:11&lt;5:16:13,  3.50s/it]

{'epoch': 0, 'iter': 1510, 'avg_loss': 6.719215481743601, 'avg_acc': 50.018613500992714, 'loss': 5.708592414855957}


EP_train:0:  22%|| 1521/6926 [1:27:46&lt;5:11:33,  3.46s/it]

{'epoch': 0, 'iter': 1520, 'avg_loss': 6.712945926824265, 'avg_acc': 50.055473372781066, 'loss': 5.535630226135254}


EP_train:0:  22%|| 1531/6926 [1:28:20&lt;5:10:00,  3.45s/it]

{'epoch': 0, 'iter': 1530, 'avg_loss': 6.707054874151069, 'avg_acc': 50.03878184193338, 'loss': 5.712316036224365}


EP_train:0:  22%|| 1541/6926 [1:28:55&lt;5:12:20,  3.48s/it]

{'epoch': 0, 'iter': 1540, 'avg_loss': 6.701259867700951, 'avg_acc': 50.05069759896171, 'loss': 5.39851188659668}


EP_train:0:  22%|| 1551/6926 [1:29:30&lt;5:13:45,  3.50s/it]

{'epoch': 0, 'iter': 1550, 'avg_loss': 6.695485569445415, 'avg_acc': 50.04029658284978, 'loss': 5.813269138336182}


EP_train:0:  23%|| 1561/6926 [1:30:05&lt;5:15:53,  3.53s/it]

{'epoch': 0, 'iter': 1560, 'avg_loss': 6.690367103615761, 'avg_acc': 50.03002882767456, 'loss': 5.805647850036621}


EP_train:0:  23%|| 1571/6926 [1:30:40&lt;5:12:01,  3.50s/it]

{'epoch': 0, 'iter': 1570, 'avg_loss': 6.685033302865614, 'avg_acc': 50.08553469127944, 'loss': 6.341202735900879}


EP_train:0:  23%|| 1581/6926 [1:31:14&lt;5:06:20,  3.44s/it]

{'epoch': 0, 'iter': 1580, 'avg_loss': 6.679796560891892, 'avg_acc': 50.1166192283365, 'loss': 5.751227378845215}


EP_train:0:  23%|| 1591/6926 [1:31:49&lt;5:11:54,  3.51s/it]

{'epoch': 0, 'iter': 1590, 'avg_loss': 6.674660406945862, 'avg_acc': 50.133563796354494, 'loss': 5.759082317352295}


EP_train:0:  23%|| 1601/6926 [1:32:24&lt;5:08:01,  3.47s/it]

{'epoch': 0, 'iter': 1600, 'avg_loss': 6.668804914783046, 'avg_acc': 50.119066208619614, 'loss': 5.621526718139648}


EP_train:0:  23%|| 1611/6926 [1:32:58&lt;5:03:46,  3.43s/it]

{'epoch': 0, 'iter': 1610, 'avg_loss': 6.663902772575487, 'avg_acc': 50.11444754810677, 'loss': 5.824803829193115}


EP_train:0:  23%|| 1621/6926 [1:33:32&lt;5:03:55,  3.44s/it]

{'epoch': 0, 'iter': 1620, 'avg_loss': 6.659484281428135, 'avg_acc': 50.113741517581744, 'loss': 5.608224391937256}


EP_train:0:  24%|| 1631/6926 [1:34:07&lt;5:02:43,  3.43s/it]

{'epoch': 0, 'iter': 1630, 'avg_loss': 6.6549554376935465, 'avg_acc': 50.12837216431637, 'loss': 6.16309928894043}


EP_train:0:  24%|| 1641/6926 [1:34:41&lt;5:03:30,  3.45s/it]

{'epoch': 0, 'iter': 1640, 'avg_loss': 6.6503012007434945, 'avg_acc': 50.114259597806225, 'loss': 5.619045257568359}


EP_train:0:  24%|| 1651/6926 [1:35:16&lt;5:06:07,  3.48s/it]

{'epoch': 0, 'iter': 1650, 'avg_loss': 6.644976955843578, 'avg_acc': 50.111674742580256, 'loss': 5.851489067077637}


EP_train:0:  24%|| 1661/6926 [1:35:50&lt;5:01:16,  3.43s/it]

{'epoch': 0, 'iter': 1660, 'avg_loss': 6.640191291772336, 'avg_acc': 50.109121011438894, 'loss': 5.876086235046387}


EP_train:0:  24%|| 1671/6926 [1:36:25&lt;5:03:36,  3.47s/it]

{'epoch': 0, 'iter': 1670, 'avg_loss': 6.6346327164157435, 'avg_acc': 50.11407839616996, 'loss': 5.317509651184082}


EP_train:0:  24%|| 1681/6926 [1:36:59&lt;5:06:07,  3.50s/it]

{'epoch': 0, 'iter': 1680, 'avg_loss': 6.630361939100621, 'avg_acc': 50.10596371207614, 'loss': 6.142337322235107}


EP_train:0:  24%|| 1691/6926 [1:37:34&lt;4:59:59,  3.44s/it]

{'epoch': 0, 'iter': 1690, 'avg_loss': 6.625920400613867, 'avg_acc': 50.114577173270256, 'loss': 5.6801605224609375}


EP_train:0:  25%|| 1701/6926 [1:38:09&lt;5:01:27,  3.46s/it]

{'epoch': 0, 'iter': 1700, 'avg_loss': 6.62068870556768, 'avg_acc': 50.10288065843621, 'loss': 6.168246269226074}


EP_train:0:  25%|| 1711/6926 [1:38:43&lt;5:00:26,  3.46s/it]

{'epoch': 0, 'iter': 1710, 'avg_loss': 6.6155091547116, 'avg_acc': 50.08218877849211, 'loss': 5.276941299438477}


EP_train:0:  25%|| 1721/6926 [1:39:18&lt;4:58:53,  3.45s/it]

{'epoch': 0, 'iter': 1720, 'avg_loss': 6.61112783011969, 'avg_acc': 50.063553166763505, 'loss': 5.9864277839660645}


EP_train:0:  25%|| 1731/6926 [1:39:52&lt;4:58:41,  3.45s/it]

{'epoch': 0, 'iter': 1730, 'avg_loss': 6.607044134024318, 'avg_acc': 50.036106296938186, 'loss': 6.244937419891357}


EP_train:0:  25%|| 1741/6926 [1:40:27&lt;4:59:28,  3.47s/it]

{'epoch': 0, 'iter': 1740, 'avg_loss': 6.601897341023226, 'avg_acc': 50.05743825387709, 'loss': 5.8550496101379395}


EP_train:0:  25%|| 1751/6926 [1:41:01&lt;5:00:35,  3.49s/it]

{'epoch': 0, 'iter': 1750, 'avg_loss': 6.5980474860378155, 'avg_acc': 50.057110222729875, 'loss': 6.101003646850586}


EP_train:0:  25%|| 1761/6926 [1:41:36&lt;4:57:21,  3.45s/it]

{'epoch': 0, 'iter': 1760, 'avg_loss': 6.592984796856562, 'avg_acc': 50.03371663827371, 'loss': 5.774938106536865}


EP_train:0:  26%|| 1771/6926 [1:42:11&lt;5:00:09,  3.49s/it]

{'epoch': 0, 'iter': 1770, 'avg_loss': 6.589065146540465, 'avg_acc': 50.01588085827217, 'loss': 5.664983749389648}


EP_train:0:  26%|| 1781/6926 [1:42:46&lt;4:59:42,  3.50s/it]

{'epoch': 0, 'iter': 1780, 'avg_loss': 6.585036697312729, 'avg_acc': 50.00701852891633, 'loss': 5.618933200836182}


EP_train:0:  26%|| 1791/6926 [1:43:21&lt;4:57:17,  3.47s/it]

{'epoch': 0, 'iter': 1790, 'avg_loss': 6.581039176847201, 'avg_acc': 50.0034896705751, 'loss': 5.975118160247803}


EP_train:0:  26%|| 1801/6926 [1:43:55&lt;4:57:44,  3.49s/it]

{'epoch': 0, 'iter': 1800, 'avg_loss': 6.576796160745065, 'avg_acc': 50.01041088284287, 'loss': 5.964684009552002}


EP_train:0:  26%|| 1811/6926 [1:44:30&lt;4:56:40,  3.48s/it]

{'epoch': 0, 'iter': 1810, 'avg_loss': 6.572977085787574, 'avg_acc': 50.00690226394258, 'loss': 5.743773937225342}


EP_train:0:  26%|| 1821/6926 [1:45:05&lt;4:52:57,  3.44s/it]

{'epoch': 0, 'iter': 1820, 'avg_loss': 6.568574661870764, 'avg_acc': 49.98970345963756, 'loss': 5.717203617095947}


EP_train:0:  26%|| 1831/6926 [1:45:39&lt;4:51:06,  3.43s/it]

{'epoch': 0, 'iter': 1830, 'avg_loss': 6.564488740907478, 'avg_acc': 50.006826870562534, 'loss': 5.563779830932617}


EP_train:0:  27%|| 1841/6926 [1:46:14&lt;4:58:22,  3.52s/it]

{'epoch': 0, 'iter': 1840, 'avg_loss': 6.559978160309053, 'avg_acc': 50.025461705594786, 'loss': 5.8036932945251465}


EP_train:0:  27%|| 1851/6926 [1:46:49&lt;4:51:01,  3.44s/it]

{'epoch': 0, 'iter': 1850, 'avg_loss': 6.556545357263649, 'avg_acc': 50.047271745002696, 'loss': 5.616850852966309}


EP_train:0:  27%|| 1861/6926 [1:47:23&lt;4:50:29,  3.44s/it]

{'epoch': 0, 'iter': 1860, 'avg_loss': 6.553398664762486, 'avg_acc': 50.06380977968834, 'loss': 5.406038761138916}


EP_train:0:  27%|| 1871/6926 [1:47:58&lt;4:52:47,  3.48s/it]

{'epoch': 0, 'iter': 1870, 'avg_loss': 6.550090259182969, 'avg_acc': 50.058458043826825, 'loss': 5.88486385345459}


EP_train:0:  27%|| 1881/6926 [1:48:33&lt;4:52:38,  3.48s/it]

{'epoch': 0, 'iter': 1880, 'avg_loss': 6.546166201717735, 'avg_acc': 50.063131313131315, 'loss': 5.72655725479126}


EP_train:0:  27%|| 1891/6926 [1:49:07&lt;4:51:40,  3.48s/it]

{'epoch': 0, 'iter': 1890, 'avg_loss': 6.541274296676337, 'avg_acc': 50.0462718138551, 'loss': 5.617991924285889}


EP_train:0:  27%|| 1901/6926 [1:49:42&lt;4:50:29,  3.47s/it]

{'epoch': 0, 'iter': 1900, 'avg_loss': 6.537737650221614, 'avg_acc': 50.05589163598106, 'loss': 5.472006797790527}


EP_train:0:  28%|| 1911/6926 [1:50:17&lt;4:47:35,  3.44s/it]

{'epoch': 0, 'iter': 1910, 'avg_loss': 6.534674536926094, 'avg_acc': 50.05069335426479, 'loss': 6.121761798858643}


EP_train:0:  28%|| 1921/6926 [1:50:51&lt;4:48:22,  3.46s/it]

{'epoch': 0, 'iter': 1920, 'avg_loss': 6.531029757579622, 'avg_acc': 50.06832378969287, 'loss': 5.909574031829834}


EP_train:0:  28%|| 1931/6926 [1:51:26&lt;4:51:06,  3.50s/it]

{'epoch': 0, 'iter': 1930, 'avg_loss': 6.5268044886596455, 'avg_acc': 50.074443293630246, 'loss': 5.91326904296875}


EP_train:0:  28%|| 1941/6926 [1:52:01&lt;4:47:34,  3.46s/it]

{'epoch': 0, 'iter': 1940, 'avg_loss': 6.52398176969541, 'avg_acc': 50.08049974240082, 'loss': 5.717437744140625}


EP_train:0:  28%|| 1951/6926 [1:52:36&lt;4:44:04,  3.43s/it]

{'epoch': 0, 'iter': 1950, 'avg_loss': 6.520226235880966, 'avg_acc': 50.08489236289082, 'loss': 5.268540382385254}


EP_train:0:  28%|| 1961/6926 [1:53:10&lt;4:44:00,  3.43s/it]

{'epoch': 0, 'iter': 1960, 'avg_loss': 6.516827085564053, 'avg_acc': 50.08605303416624, 'loss': 5.840364933013916}


EP_train:0:  28%|| 1971/6926 [1:53:44&lt;4:42:27,  3.42s/it]

{'epoch': 0, 'iter': 1970, 'avg_loss': 6.513644299974059, 'avg_acc': 50.06817605276509, 'loss': 5.865345001220703}


EP_train:0:  29%|| 1981/6926 [1:54:19&lt;4:46:37,  3.48s/it]

{'epoch': 0, 'iter': 1980, 'avg_loss': 6.510300359961843, 'avg_acc': 50.075719333669866, 'loss': 5.67856502532959}


EP_train:0:  29%|| 1991/6926 [1:54:54&lt;4:44:53,  3.46s/it]

{'epoch': 0, 'iter': 1990, 'avg_loss': 6.50666828457283, 'avg_acc': 50.08632596685083, 'loss': 6.040983200073242}


EP_train:0:  29%|| 2001/6926 [1:55:28&lt;4:43:45,  3.46s/it]

{'epoch': 0, 'iter': 2000, 'avg_loss': 6.504097387112718, 'avg_acc': 50.08277111444278, 'loss': 6.24128532409668}


EP_train:0:  29%|| 2011/6926 [1:56:03&lt;4:45:20,  3.48s/it]

{'epoch': 0, 'iter': 2010, 'avg_loss': 6.501077034057284, 'avg_acc': 50.083913475882646, 'loss': 5.284446716308594}


EP_train:0:  29%|| 2021/6926 [1:56:38&lt;4:43:23,  3.47s/it]

{'epoch': 0, 'iter': 2020, 'avg_loss': 6.49810962945975, 'avg_acc': 50.07267441860465, 'loss': 5.207293510437012}


EP_train:0:  29%|| 2031/6926 [1:57:12&lt;4:39:20,  3.42s/it]

{'epoch': 0, 'iter': 2030, 'avg_loss': 6.495085201141342, 'avg_acc': 50.0492368291482, 'loss': 5.453665256500244}


EP_train:0:  29%|| 2041/6926 [1:57:47&lt;4:42:35,  3.47s/it]

{'epoch': 0, 'iter': 2040, 'avg_loss': 6.4921762126733835, 'avg_acc': 50.045933365997065, 'loss': 6.171324729919434}


EP_train:0:  30%|| 2051/6926 [1:58:22&lt;4:46:53,  3.53s/it]

{'epoch': 0, 'iter': 2050, 'avg_loss': 6.4887599893920545, 'avg_acc': 50.0365675280351, 'loss': 5.483743667602539}


EP_train:0:  30%|| 2061/6926 [1:58:56&lt;4:40:38,  3.46s/it]

{'epoch': 0, 'iter': 2060, 'avg_loss': 6.484664882981968, 'avg_acc': 50.06823144104804, 'loss': 5.602869033813477}


EP_train:0:  30%|| 2071/6926 [1:59:31&lt;4:39:56,  3.46s/it]

{'epoch': 0, 'iter': 2070, 'avg_loss': 6.482191278300154, 'avg_acc': 50.05733944954128, 'loss': 6.08825159072876}


EP_train:0:  30%|| 2081/6926 [2:00:05&lt;4:38:57,  3.45s/it]

{'epoch': 0, 'iter': 2080, 'avg_loss': 6.479258142257756, 'avg_acc': 50.066074002883234, 'loss': 6.080234050750732}


EP_train:0:  30%|| 2091/6926 [2:00:40&lt;4:36:59,  3.44s/it]

{'epoch': 0, 'iter': 2090, 'avg_loss': 6.47677060874782, 'avg_acc': 50.058285509325685, 'loss': 6.058839321136475}


EP_train:0:  30%|| 2101/6926 [2:01:14&lt;4:34:48,  3.42s/it]

{'epoch': 0, 'iter': 2100, 'avg_loss': 6.473212983368806, 'avg_acc': 50.068419800095185, 'loss': 5.553353309631348}


EP_train:0:  30%|| 2111/6926 [2:01:49&lt;4:39:11,  3.48s/it]

{'epoch': 0, 'iter': 2110, 'avg_loss': 6.470080981939001, 'avg_acc': 50.07549739459971, 'loss': 6.045713901519775}


EP_train:0:  31%|| 2121/6926 [2:02:23&lt;4:37:06,  3.46s/it]

{'epoch': 0, 'iter': 2120, 'avg_loss': 6.467039516769114, 'avg_acc': 50.079561527581326, 'loss': 6.144732475280762}


EP_train:0:  31%|| 2131/6926 [2:02:58&lt;4:35:43,  3.45s/it]

{'epoch': 0, 'iter': 2130, 'avg_loss': 6.464385775767934, 'avg_acc': 50.07625527921164, 'loss': 5.405893802642822}


EP_train:0:  31%|| 2141/6926 [2:03:33&lt;4:33:47,  3.43s/it]

{'epoch': 0, 'iter': 2140, 'avg_loss': 6.461514957816397, 'avg_acc': 50.086116300794025, 'loss': 6.083144187927246}


EP_train:0:  41%|| 2871/6926 [2:45:37&lt;3:52:44,  3.44s/it]

{'epoch': 0, 'iter': 2870, 'avg_loss': 6.30501551480295, 'avg_acc': 50.143678160919535, 'loss': 6.170657634735107}


EP_train:0:  42%|| 2881/6926 [2:46:13&lt;3:55:59,  3.50s/it]

{'epoch': 0, 'iter': 2880, 'avg_loss': 6.303754466724495, 'avg_acc': 50.14209475876432, 'loss': 5.637953758239746}


EP_train:0:  42%|| 2891/6926 [2:46:47&lt;3:53:27,  3.47s/it]

{'epoch': 0, 'iter': 2890, 'avg_loss': 6.302581706454456, 'avg_acc': 50.12971290211, 'loss': 6.26906156539917}


EP_train:0:  42%|| 2901/6926 [2:47:22&lt;3:54:26,  3.49s/it]

{'epoch': 0, 'iter': 2900, 'avg_loss': 6.301098016162282, 'avg_acc': 50.13249741468459, 'loss': 5.8243937492370605}


EP_train:0:  42%|| 2911/6926 [2:47:57&lt;3:51:17,  3.46s/it]

{'epoch': 0, 'iter': 2910, 'avg_loss': 6.29952759531428, 'avg_acc': 50.12667468223978, 'loss': 5.761030197143555}


EP_train:0:  42%|| 2921/6926 [2:48:31&lt;3:49:00,  3.43s/it]

{'epoch': 0, 'iter': 2920, 'avg_loss': 6.298045401130788, 'avg_acc': 50.11875213967819, 'loss': 6.2981743812561035}


EP_train:0:  42%|| 2931/6926 [2:49:06&lt;3:50:01,  3.45s/it]

{'epoch': 0, 'iter': 2930, 'avg_loss': 6.296928513298178, 'avg_acc': 50.12474411463664, 'loss': 5.463428497314453}


EP_train:0:  42%|| 2941/6926 [2:49:40&lt;3:47:51,  3.43s/it]

{'epoch': 0, 'iter': 2940, 'avg_loss': 6.295126533151605, 'avg_acc': 50.113694321659295, 'loss': 5.533849716186523}


EP_train:0:  43%|| 2951/6926 [2:50:15&lt;3:49:19,  3.46s/it]

{'epoch': 0, 'iter': 2950, 'avg_loss': 6.293472126030348, 'avg_acc': 50.101660454083365, 'loss': 5.400457859039307}


EP_train:0:  43%|| 2961/6926 [2:50:49&lt;3:48:26,  3.46s/it]

{'epoch': 0, 'iter': 2960, 'avg_loss': 6.2923729253032645, 'avg_acc': 50.11292637622425, 'loss': 6.580233097076416}


EP_train:0:  43%|| 2971/6926 [2:51:24&lt;3:47:24,  3.45s/it]

{'epoch': 0, 'iter': 2970, 'avg_loss': 6.291031072052269, 'avg_acc': 50.115701783911135, 'loss': 5.922897815704346}


EP_train:0:  43%|| 2981/6926 [2:51:58&lt;3:47:07,  3.45s/it]

{'epoch': 0, 'iter': 2980, 'avg_loss': 6.289031018510196, 'avg_acc': 50.121603488762155, 'loss': 6.050359725952148}


EP_train:0:  43%|| 2991/6926 [2:52:33&lt;3:48:34,  3.49s/it]

{'epoch': 0, 'iter': 2990, 'avg_loss': 6.287773423591851, 'avg_acc': 50.118062520896025, 'loss': 6.4279704093933105}


EP_train:0:  43%|| 3001/6926 [2:53:08&lt;3:45:44,  3.45s/it]

{'epoch': 0, 'iter': 3000, 'avg_loss': 6.286346402020504, 'avg_acc': 50.11037987337554, 'loss': 5.731723785400391}


EP_train:0:  43%|| 3011/6926 [2:53:43&lt;3:47:59,  3.49s/it]

{'epoch': 0, 'iter': 3010, 'avg_loss': 6.284757147909042, 'avg_acc': 50.122467618731314, 'loss': 5.829910755157471}


EP_train:0:  44%|| 3021/6926 [2:54:18&lt;3:45:44,  3.47s/it]

{'epoch': 0, 'iter': 3020, 'avg_loss': 6.282995776126259, 'avg_acc': 50.13137206223105, 'loss': 5.287047386169434}


EP_train:0:  44%|| 3031/6926 [2:54:52&lt;3:46:00,  3.48s/it]

{'epoch': 0, 'iter': 3030, 'avg_loss': 6.281364510610763, 'avg_acc': 50.122690531177824, 'loss': 5.5934367179870605}


EP_train:0:  44%|| 3041/6926 [2:55:27&lt;3:44:25,  3.47s/it]

{'epoch': 0, 'iter': 3040, 'avg_loss': 6.279620425084122, 'avg_acc': 50.10790036172311, 'loss': 5.831112861633301}


EP_train:0:  44%|| 3051/6926 [2:56:01&lt;3:41:25,  3.43s/it]

{'epoch': 0, 'iter': 3050, 'avg_loss': 6.278026736161624, 'avg_acc': 50.11266797771222, 'loss': 5.961607933044434}


EP_train:0:  44%|| 3061/6926 [2:56:36&lt;3:41:55,  3.45s/it]

{'epoch': 0, 'iter': 3060, 'avg_loss': 6.276269334159385, 'avg_acc': 50.12046716759229, 'loss': 5.718508720397949}


EP_train:0:  44%|| 3071/6926 [2:57:10&lt;3:40:21,  3.43s/it]

{'epoch': 0, 'iter': 3070, 'avg_loss': 6.274964790629937, 'avg_acc': 50.117022142624556, 'loss': 5.907179355621338}


EP_train:0:  44%|| 3081/6926 [2:57:45&lt;3:45:56,  3.53s/it]

{'epoch': 0, 'iter': 3080, 'avg_loss': 6.273098578046027, 'avg_acc': 50.12272801038624, 'loss': 5.667904376983643}


EP_train:0:  45%|| 3091/6926 [2:58:20&lt;3:43:04,  3.49s/it]

{'epoch': 0, 'iter': 3090, 'avg_loss': 6.271562425884295, 'avg_acc': 50.11424296344226, 'loss': 5.675585746765137}


EP_train:0:  45%|| 3101/6926 [2:58:55&lt;3:40:41,  3.46s/it]

{'epoch': 0, 'iter': 3100, 'avg_loss': 6.269683937379061, 'avg_acc': 50.12193647210578, 'loss': 6.055880069732666}


EP_train:0:  45%|| 3111/6926 [2:59:30&lt;3:40:51,  3.47s/it]

{'epoch': 0, 'iter': 3110, 'avg_loss': 6.268129614226422, 'avg_acc': 50.12455801992929, 'loss': 5.9486918449401855}


EP_train:0:  45%|| 3121/6926 [3:00:04&lt;3:39:49,  3.47s/it]

{'epoch': 0, 'iter': 3120, 'avg_loss': 6.266449210048677, 'avg_acc': 50.11815123357898, 'loss': 6.4969987869262695}


EP_train:0:  45%|| 3131/6926 [3:00:39&lt;3:40:10,  3.48s/it]

{'epoch': 0, 'iter': 3130, 'avg_loss': 6.264453706860124, 'avg_acc': 50.1287527946343, 'loss': 5.43622350692749}


EP_train:0:  45%|| 3141/6926 [3:01:14&lt;3:38:18,  3.46s/it]

{'epoch': 0, 'iter': 3140, 'avg_loss': 6.26304022956904, 'avg_acc': 50.13033269659344, 'loss': 5.587998390197754}


EP_train:0:  45%|| 3151/6926 [3:01:48&lt;3:37:03,  3.45s/it]

{'epoch': 0, 'iter': 3150, 'avg_loss': 6.2617480554341585, 'avg_acc': 50.13289431926372, 'loss': 6.050402641296387}


EP_train:0:  46%|| 3161/6926 [3:02:23&lt;3:34:28,  3.42s/it]

{'epoch': 0, 'iter': 3160, 'avg_loss': 6.260293862820426, 'avg_acc': 50.12654223347042, 'loss': 5.674601078033447}


EP_train:0:  46%|| 3171/6926 [3:02:58&lt;3:36:37,  3.46s/it]

{'epoch': 0, 'iter': 3170, 'avg_loss': 6.258769833676937, 'avg_acc': 50.13599810785241, 'loss': 5.690023899078369}


EP_train:0:  46%|| 3181/6926 [3:03:32&lt;3:38:46,  3.50s/it]

{'epoch': 0, 'iter': 3180, 'avg_loss': 6.257336515182596, 'avg_acc': 50.141464948129524, 'loss': 6.035431861877441}


EP_train:0:  46%|| 3191/6926 [3:04:07&lt;3:36:37,  3.48s/it]

{'epoch': 0, 'iter': 3190, 'avg_loss': 6.255578008052213, 'avg_acc': 50.140042306487, 'loss': 6.241879940032959}


EP_train:0:  46%|| 3201/6926 [3:04:42&lt;3:32:27,  3.42s/it]

{'epoch': 0, 'iter': 3200, 'avg_loss': 6.254713234697346, 'avg_acc': 50.131794751640115, 'loss': 5.585864067077637}


EP_train:0:  46%|| 3211/6926 [3:05:16&lt;3:33:26,  3.45s/it]

{'epoch': 0, 'iter': 3210, 'avg_loss': 6.253378930473506, 'avg_acc': 50.13138430395515, 'loss': 5.481635570526123}


EP_train:0:  47%|| 3221/6926 [3:05:50&lt;3:31:02,  3.42s/it]

{'epoch': 0, 'iter': 3220, 'avg_loss': 6.25171201090678, 'avg_acc': 50.1397081651661, 'loss': 5.6242523193359375}


EP_train:0:  47%|| 3231/6926 [3:06:25&lt;3:31:05,  3.43s/it]

{'epoch': 0, 'iter': 3230, 'avg_loss': 6.250507676317315, 'avg_acc': 50.125735066542866, 'loss': 5.807900428771973}


EP_train:0:  47%|| 3241/6926 [3:07:00&lt;3:32:40,  3.46s/it]

{'epoch': 0, 'iter': 3240, 'avg_loss': 6.248571161354298, 'avg_acc': 50.121490280777536, 'loss': 6.13726806640625}


EP_train:0:  47%|| 3251/6926 [3:07:34&lt;3:30:37,  3.44s/it]

{'epoch': 0, 'iter': 3250, 'avg_loss': 6.247323126691703, 'avg_acc': 50.10285296831745, 'loss': 6.156318187713623}


EP_train:0:  47%|| 3261/6926 [3:08:09&lt;3:30:17,  3.44s/it]

{'epoch': 0, 'iter': 3260, 'avg_loss': 6.245429852885434, 'avg_acc': 50.10732904017172, 'loss': 5.416029930114746}


EP_train:0:  47%|| 3271/6926 [3:08:44&lt;3:30:44,  3.46s/it]

{'epoch': 0, 'iter': 3270, 'avg_loss': 6.244244876238812, 'avg_acc': 50.108911647814125, 'loss': 6.065566062927246}


EP_train:0:  47%|| 3281/6926 [3:09:18&lt;3:29:30,  3.45s/it]

{'epoch': 0, 'iter': 3280, 'avg_loss': 6.242680059123134, 'avg_acc': 50.106674794270035, 'loss': 5.227103233337402}


EP_train:0:  48%|| 3291/6926 [3:09:53&lt;3:28:19,  3.44s/it]

{'epoch': 0, 'iter': 3290, 'avg_loss': 6.241573854624337, 'avg_acc': 50.10445153448799, 'loss': 6.120715618133545}


EP_train:0:  48%|| 3301/6926 [3:10:27&lt;3:28:53,  3.46s/it]

{'epoch': 0, 'iter': 3300, 'avg_loss': 6.240098802438832, 'avg_acc': 50.11360193880642, 'loss': 5.652524948120117}


EP_train:0:  48%|| 3311/6926 [3:11:02&lt;3:28:46,  3.47s/it]

{'epoch': 0, 'iter': 3310, 'avg_loss': 6.23900456429968, 'avg_acc': 50.110427363334345, 'loss': 5.927626132965088}


EP_train:0:  48%|| 3321/6926 [3:11:36&lt;3:25:19,  3.42s/it]

{'epoch': 0, 'iter': 3320, 'avg_loss': 6.237606107309187, 'avg_acc': 50.11385877747666, 'loss': 5.536543846130371}


EP_train:0:  48%|| 3331/6926 [3:12:11&lt;3:28:12,  3.47s/it]

{'epoch': 0, 'iter': 3330, 'avg_loss': 6.23606965564028, 'avg_acc': 50.116331432002404, 'loss': 6.248320579528809}


EP_train:0:  48%|| 3341/6926 [3:12:46&lt;3:28:05,  3.48s/it]

{'epoch': 0, 'iter': 3340, 'avg_loss': 6.234930654586842, 'avg_acc': 50.11691858724932, 'loss': 5.643083572387695}


EP_train:0:  48%|| 3351/6926 [3:13:20&lt;3:26:52,  3.47s/it]

{'epoch': 0, 'iter': 3350, 'avg_loss': 6.23354035183694, 'avg_acc': 50.11750223813787, 'loss': 6.102465629577637}


EP_train:0:  49%|| 3361/6926 [3:13:55&lt;3:24:27,  3.44s/it]

{'epoch': 0, 'iter': 3360, 'avg_loss': 6.232676638694294, 'avg_acc': 50.109714370723005, 'loss': 5.754641056060791}


EP_train:0:  49%|| 3371/6926 [3:14:30&lt;3:23:22,  3.43s/it]

{'epoch': 0, 'iter': 3370, 'avg_loss': 6.231407767267264, 'avg_acc': 50.09919163452982, 'loss': 6.043362140655518}


EP_train:0:  49%|| 3381/6926 [3:15:05&lt;3:25:20,  3.48s/it]

{'epoch': 0, 'iter': 3380, 'avg_loss': 6.23005606654973, 'avg_acc': 50.09612540668441, 'loss': 5.88515567779541}


EP_train:0:  49%|| 3391/6926 [3:15:40&lt;3:23:18,  3.45s/it]

{'epoch': 0, 'iter': 3390, 'avg_loss': 6.228594171652855, 'avg_acc': 50.104135948097905, 'loss': 5.32595682144165}


EP_train:0:  49%|| 3401/6926 [3:16:14&lt;3:22:35,  3.45s/it]

{'epoch': 0, 'iter': 3400, 'avg_loss': 6.226963288852026, 'avg_acc': 50.10566745074978, 'loss': 6.132233142852783}


EP_train:0:  49%|| 3411/6926 [3:16:49&lt;3:24:39,  3.49s/it]

{'epoch': 0, 'iter': 3410, 'avg_loss': 6.225550739201099, 'avg_acc': 50.08886690120199, 'loss': 5.387300968170166}


EP_train:0:  49%|| 3421/6926 [3:17:23&lt;3:21:58,  3.46s/it]

{'epoch': 0, 'iter': 3420, 'avg_loss': 6.224329726105718, 'avg_acc': 50.083126278865834, 'loss': 5.836758136749268}


EP_train:0:  50%|| 3431/6926 [3:17:58&lt;3:22:44,  3.48s/it]

{'epoch': 0, 'iter': 3430, 'avg_loss': 6.22317759673125, 'avg_acc': 50.08197318566015, 'loss': 5.096984386444092}


EP_train:0:  50%|| 3441/6926 [3:18:33&lt;3:19:53,  3.44s/it]

{'epoch': 0, 'iter': 3440, 'avg_loss': 6.222500560797082, 'avg_acc': 50.08264312699796, 'loss': 5.920487880706787}


EP_train:0:  50%|| 3451/6926 [3:19:08&lt;3:21:19,  3.48s/it]

{'epoch': 0, 'iter': 3450, 'avg_loss': 6.221058753496389, 'avg_acc': 50.08783685888149, 'loss': 5.709464073181152}


EP_train:0:  50%|| 3461/6926 [3:19:43&lt;3:19:30,  3.45s/it]

{'epoch': 0, 'iter': 3460, 'avg_loss': 6.219895183609524, 'avg_acc': 50.09480641433112, 'loss': 5.588047504425049}


EP_train:0:  50%|| 3471/6926 [3:20:18&lt;3:21:18,  3.50s/it]

{'epoch': 0, 'iter': 3470, 'avg_loss': 6.2184577888042565, 'avg_acc': 50.101735811005476, 'loss': 5.708352565765381}


EP_train:0:  50%|| 3481/6926 [3:20:53&lt;3:20:55,  3.50s/it]

{'epoch': 0, 'iter': 3480, 'avg_loss': 6.217134620087888, 'avg_acc': 50.10144355070382, 'loss': 5.452094554901123}


EP_train:0:  50%|| 3491/6926 [3:21:27&lt;3:17:30,  3.45s/it]

{'epoch': 0, 'iter': 3490, 'avg_loss': 6.216033760984318, 'avg_acc': 50.11189487252936, 'loss': 5.774087429046631}


EP_train:0:  51%|| 3501/6926 [3:22:02&lt;3:17:42,  3.46s/it]

{'epoch': 0, 'iter': 3500, 'avg_loss': 6.214568872514435, 'avg_acc': 50.11514567266495, 'loss': 5.287735462188721}


EP_train:0:  51%|| 3511/6926 [3:22:36&lt;3:16:18,  3.45s/it]

{'epoch': 0, 'iter': 3510, 'avg_loss': 6.2134798007010055, 'avg_acc': 50.11570777556251, 'loss': 6.348851680755615}


EP_train:0:  51%|| 3521/6926 [3:23:11&lt;3:16:45,  3.47s/it]

{'epoch': 0, 'iter': 3520, 'avg_loss': 6.21255720721426, 'avg_acc': 50.10916642999148, 'loss': 6.2176971435546875}


EP_train:0:  51%|| 3531/6926 [3:23:45&lt;3:15:46,  3.46s/it]

{'epoch': 0, 'iter': 3530, 'avg_loss': 6.212049034829519, 'avg_acc': 50.10974228263948, 'loss': 5.880690574645996}


EP_train:0:  51%|| 3541/6926 [3:24:20&lt;3:15:22,  3.46s/it]

{'epoch': 0, 'iter': 3540, 'avg_loss': 6.211238995880368, 'avg_acc': 50.10413724936459, 'loss': 5.573653221130371}


EP_train:0:  51%|| 3551/6926 [3:24:55&lt;3:15:41,  3.48s/it]

{'epoch': 0, 'iter': 3550, 'avg_loss': 6.209664390846495, 'avg_acc': 50.095923683469444, 'loss': 5.674375057220459}


EP_train:0:  51%|| 3561/6926 [3:25:29&lt;3:13:05,  3.44s/it]

{'epoch': 0, 'iter': 3560, 'avg_loss': 6.208728829383582, 'avg_acc': 50.099164560516705, 'loss': 5.379258632659912}


EP_train:0:  52%|| 3571/6926 [3:26:04&lt;3:13:15,  3.46s/it]

{'epoch': 0, 'iter': 3570, 'avg_loss': 6.207470196029846, 'avg_acc': 50.086635396247544, 'loss': 5.845820903778076}


EP_train:0:  52%|| 3581/6926 [3:26:38&lt;3:12:16,  3.45s/it]

{'epoch': 0, 'iter': 3580, 'avg_loss': 6.206407408380069, 'avg_acc': 50.09337475565484, 'loss': 5.866831302642822}


EP_train:0:  52%|| 3591/6926 [3:27:13&lt;3:11:23,  3.44s/it]

{'epoch': 0, 'iter': 3590, 'avg_loss': 6.205047326843508, 'avg_acc': 50.09224450013924, 'loss': 5.758725166320801}


EP_train:0:  52%|| 3601/6926 [3:27:48&lt;3:12:51,  3.48s/it]

{'epoch': 0, 'iter': 3600, 'avg_loss': 6.204162875866433, 'avg_acc': 50.098063038044984, 'loss': 6.484498500823975}


EP_train:0:  52%|| 3611/6926 [3:28:23&lt;3:12:40,  3.49s/it]

{'epoch': 0, 'iter': 3610, 'avg_loss': 6.203004776028443, 'avg_acc': 50.09000276931598, 'loss': 6.100214004516602}


EP_train:0:  52%|| 3621/6926 [3:28:58&lt;3:12:27,  3.49s/it]

{'epoch': 0, 'iter': 3620, 'avg_loss': 6.201920005242096, 'avg_acc': 50.08716514774923, 'loss': 5.938502311706543}


EP_train:0:  52%|| 3631/6926 [3:29:32&lt;3:11:30,  3.49s/it]

{'epoch': 0, 'iter': 3630, 'avg_loss': 6.200789731844369, 'avg_acc': 50.07659735610025, 'loss': 5.771533489227295}


EP_train:0:  53%|| 3641/6926 [3:30:07&lt;3:09:35,  3.46s/it]

{'epoch': 0, 'iter': 3640, 'avg_loss': 6.199535256327917, 'avg_acc': 50.0781035429827, 'loss': 5.855103492736816}


EP_train:0:  53%|| 3651/6926 [3:30:42&lt;3:08:25,  3.45s/it]

{'epoch': 0, 'iter': 3650, 'avg_loss': 6.198270769257704, 'avg_acc': 50.06676253081348, 'loss': 5.2879838943481445}


EP_train:0:  53%|| 3661/6926 [3:31:17&lt;3:08:31,  3.46s/it]

{'epoch': 0, 'iter': 3660, 'avg_loss': 6.196909987968814, 'avg_acc': 50.07084812892653, 'loss': 5.845424652099609}


EP_train:0:  53%|| 3671/6926 [3:31:52&lt;3:10:26,  3.51s/it]

{'epoch': 0, 'iter': 3670, 'avg_loss': 6.195943700036507, 'avg_acc': 50.07065513484065, 'loss': 5.753200531005859}


EP_train:0:  53%|| 3681/6926 [3:32:26&lt;3:09:28,  3.50s/it]

{'epoch': 0, 'iter': 3680, 'avg_loss': 6.194556915704986, 'avg_acc': 50.06791632708503, 'loss': 5.695070743560791}


EP_train:0:  53%|| 3691/6926 [3:33:01&lt;3:07:07,  3.47s/it]

{'epoch': 0, 'iter': 3690, 'avg_loss': 6.193383834123676, 'avg_acc': 50.071965591980494, 'loss': 5.697078704833984}


EP_train:0:  53%|| 3701/6926 [3:33:36&lt;3:06:18,  3.47s/it]

{'epoch': 0, 'iter': 3700, 'avg_loss': 6.192638800228586, 'avg_acc': 50.075148608484184, 'loss': 6.033320903778076}


EP_train:0:  54%|| 3711/6926 [3:34:11&lt;3:07:59,  3.51s/it]

{'epoch': 0, 'iter': 3710, 'avg_loss': 6.191417550565226, 'avg_acc': 50.077472379412555, 'loss': 5.891236305236816}


EP_train:0:  54%|| 3721/6926 [3:34:46&lt;3:08:51,  3.54s/it]

{'epoch': 0, 'iter': 3720, 'avg_loss': 6.190265684991522, 'avg_acc': 50.06298710024188, 'loss': 5.223845958709717}


EP_train:0:  54%|| 3731/6926 [3:35:21&lt;3:07:19,  3.52s/it]

{'epoch': 0, 'iter': 3730, 'avg_loss': 6.189020359685484, 'avg_acc': 50.06030554811043, 'loss': 5.904521465301514}


EP_train:0:  54%|| 3741/6926 [3:35:56&lt;3:04:07,  3.47s/it]

{'epoch': 0, 'iter': 3740, 'avg_loss': 6.187715866896469, 'avg_acc': 50.05095562683775, 'loss': 5.292939186096191}


EP_train:0:  54%|| 3751/6926 [3:36:31&lt;3:06:14,  3.52s/it]

{'epoch': 0, 'iter': 3750, 'avg_loss': 6.186928363394273, 'avg_acc': 50.05165289256198, 'loss': 6.4447832107543945}


EP_train:0:  54%|| 3761/6926 [3:37:06&lt;3:05:05,  3.51s/it]

{'epoch': 0, 'iter': 3760, 'avg_loss': 6.185825161273351, 'avg_acc': 50.04819197022069, 'loss': 5.809656620025635}


EP_train:0:  54%|| 3771/6926 [3:37:41&lt;3:04:04,  3.50s/it]

{'epoch': 0, 'iter': 3770, 'avg_loss': 6.184727871711992, 'avg_acc': 50.05137894457704, 'loss': 5.74653434753418}


EP_train:0:  55%|| 3781/6926 [3:38:17&lt;3:09:17,  3.61s/it]

{'epoch': 0, 'iter': 3780, 'avg_loss': 6.1832064308523655, 'avg_acc': 50.04959005554086, 'loss': 5.981086254119873}


EP_train:0:  55%|| 3791/6926 [3:38:53&lt;3:06:29,  3.57s/it]

{'epoch': 0, 'iter': 3790, 'avg_loss': 6.182036062244123, 'avg_acc': 50.052756528620414, 'loss': 5.522501468658447}


EP_train:0:  55%|| 3801/6926 [3:39:29&lt;3:06:51,  3.59s/it]

{'epoch': 0, 'iter': 3800, 'avg_loss': 6.180774577069803, 'avg_acc': 50.056728492501975, 'loss': 5.973437786102295}


EP_train:0:  55%|| 3811/6926 [3:40:05&lt;3:09:11,  3.64s/it]

{'epoch': 0, 'iter': 3810, 'avg_loss': 6.179361567601104, 'avg_acc': 50.064779585410655, 'loss': 6.320959568023682}


EP_train:0:  55%|| 3821/6926 [3:40:42&lt;3:06:18,  3.60s/it]

{'epoch': 0, 'iter': 3820, 'avg_loss': 6.1784018083755585, 'avg_acc': 50.0711528395708, 'loss': 5.407601356506348}


EP_train:0:  55%|| 3831/6926 [3:41:19&lt;3:12:49,  3.74s/it]

{'epoch': 0, 'iter': 3830, 'avg_loss': 6.1772821021123585, 'avg_acc': 50.0693356825894, 'loss': 6.021275043487549}


EP_train:0:  55%|| 3841/6926 [3:41:57&lt;3:17:26,  3.84s/it]

{'epoch': 0, 'iter': 3840, 'avg_loss': 6.176352686138396, 'avg_acc': 50.0561377245509, 'loss': 5.442045211791992}


EP_train:0:  56%|| 3851/6926 [3:42:35&lt;3:14:48,  3.80s/it]

{'epoch': 0, 'iter': 3850, 'avg_loss': 6.175828560765023, 'avg_acc': 50.05355751752791, 'loss': 5.861415386199951}


EP_train:0:  56%|| 3861/6926 [3:43:13&lt;3:12:28,  3.77s/it]

{'epoch': 0, 'iter': 3860, 'avg_loss': 6.174891271420755, 'avg_acc': 50.03965941465941, 'loss': 5.797309875488281}


EP_train:0:  56%|| 3871/6926 [3:43:52&lt;3:23:00,  3.99s/it]

{'epoch': 0, 'iter': 3870, 'avg_loss': 6.174061799474355, 'avg_acc': 50.04036424696461, 'loss': 5.4632720947265625}


EP_train:0:  56%|| 3881/6926 [3:44:33&lt;3:31:56,  4.18s/it]

{'epoch': 0, 'iter': 3880, 'avg_loss': 6.172991682223148, 'avg_acc': 50.03703942282917, 'loss': 6.058238506317139}


EP_train:0:  56%|| 3891/6926 [3:45:14&lt;3:25:46,  4.07s/it]

{'epoch': 0, 'iter': 3890, 'avg_loss': 6.1719814577252174, 'avg_acc': 50.028912875867384, 'loss': 6.011285305023193}


EP_train:0:  56%|| 3901/6926 [3:45:56&lt;3:37:35,  4.32s/it]

{'epoch': 0, 'iter': 3900, 'avg_loss': 6.170856231727591, 'avg_acc': 50.02483337605742, 'loss': 5.179987907409668}


EP_train:0:  56%|| 3911/6926 [3:46:41&lt;3:45:07,  4.48s/it]

{'epoch': 0, 'iter': 3910, 'avg_loss': 6.169618224097896, 'avg_acc': 50.02556890820762, 'loss': 5.848067283630371}


EP_train:0:  57%|| 3921/6926 [3:47:25&lt;3:42:56,  4.45s/it]

{'epoch': 0, 'iter': 3920, 'avg_loss': 6.168895365844664, 'avg_acc': 50.018330782963524, 'loss': 5.656007766723633}


EP_train:0:  57%|| 3931/6926 [3:48:12&lt;3:52:49,  4.66s/it]

{'epoch': 0, 'iter': 3930, 'avg_loss': 6.167847494107414, 'avg_acc': 50.025438819638765, 'loss': 6.014158248901367}


EP_train:0:  57%|| 3941/6926 [3:48:59&lt;3:55:27,  4.73s/it]

{'epoch': 0, 'iter': 3940, 'avg_loss': 6.166905548934917, 'avg_acc': 50.016651865008875, 'loss': 5.993920803070068}


EP_train:0:  57%|| 3951/6926 [3:49:49&lt;4:15:00,  5.14s/it]

{'epoch': 0, 'iter': 3950, 'avg_loss': 6.165852081078694, 'avg_acc': 50.00237281700836, 'loss': 5.804994583129883}


EP_train:0:  57%|| 3961/6926 [3:50:41&lt;4:22:36,  5.31s/it]

{'epoch': 0, 'iter': 3960, 'avg_loss': 6.164667328028208, 'avg_acc': 50.00157788437263, 'loss': 5.279772758483887}


EP_train:0:  57%|| 3971/6926 [3:51:34&lt;4:23:10,  5.34s/it]

{'epoch': 0, 'iter': 3970, 'avg_loss': 6.163366601617833, 'avg_acc': 50.00944346512214, 'loss': 5.7298736572265625}


EP_train:0:  57%|| 3981/6926 [3:52:29&lt;4:27:33,  5.45s/it]

{'epoch': 0, 'iter': 3980, 'avg_loss': 6.162418046509073, 'avg_acc': 50.00549485054007, 'loss': 5.988441467285156}


EP_train:0:  58%|| 3991/6926 [3:53:27&lt;4:50:22,  5.94s/it]

{'epoch': 0, 'iter': 3990, 'avg_loss': 6.161358871068073, 'avg_acc': 50.007830117764975, 'loss': 5.854517936706543}


EP_train:0:  58%|| 4001/6926 [3:54:24&lt;4:42:07,  5.79s/it]

{'epoch': 0, 'iter': 4000, 'avg_loss': 6.160307237905909, 'avg_acc': 50.007810547363164, 'loss': 5.7460832595825195}


EP_train:0:  58%|| 4011/6926 [3:55:26&lt;5:18:21,  6.55s/it]

{'epoch': 0, 'iter': 4010, 'avg_loss': 6.159289666049589, 'avg_acc': 50.0, 'loss': 5.876718044281006}


EP_train:0:  58%|| 4021/6926 [3:56:29&lt;5:02:01,  6.24s/it]

{'epoch': 0, 'iter': 4020, 'avg_loss': 6.158182346473965, 'avg_acc': 50.00466301914946, 'loss': 5.27029275894165}


EP_train:0:  58%|| 4031/6926 [3:57:34&lt;5:20:27,  6.64s/it]

{'epoch': 0, 'iter': 4030, 'avg_loss': 6.15733044462741, 'avg_acc': 50.01162862813197, 'loss': 5.8875732421875}


EP_train:0:  58%|| 4041/6926 [3:58:39&lt;5:16:20,  6.58s/it]

{'epoch': 0, 'iter': 4040, 'avg_loss': 6.1566401381092595, 'avg_acc': 50.02242637960901, 'loss': 5.774832725524902}


EP_train:0:  58%|| 4051/6926 [3:59:46&lt;5:20:28,  6.69s/it]

{'epoch': 0, 'iter': 4050, 'avg_loss': 6.155588622741774, 'avg_acc': 50.035485065415955, 'loss': 6.138017177581787}


EP_train:0:  59%|| 4061/6926 [4:00:55&lt;5:34:05,  7.00s/it]

{'epoch': 0, 'iter': 4060, 'avg_loss': 6.154778440372605, 'avg_acc': 50.032319625707956, 'loss': 5.674389362335205}


EP_train:0:  59%|| 4071/6926 [4:02:08&lt;5:44:06,  7.23s/it]

{'epoch': 0, 'iter': 4070, 'avg_loss': 6.153988276322097, 'avg_acc': 50.02609923851633, 'loss': 5.415286064147949}


EP_train:0:  59%|| 4081/6926 [4:03:24&lt;5:55:47,  7.50s/it]

{'epoch': 0, 'iter': 4080, 'avg_loss': 6.153260077719769, 'avg_acc': 50.01454913011517, 'loss': 5.970011234283447}


EP_train:0:  59%|| 4091/6926 [4:04:36&lt;5:45:08,  7.30s/it]

{'epoch': 0, 'iter': 4090, 'avg_loss': 6.152195111197558, 'avg_acc': 50.013749694451235, 'loss': 5.845784664154053}


EP_train:0:  59%|| 4101/6926 [4:05:53&lt;6:02:36,  7.70s/it]

{'epoch': 0, 'iter': 4100, 'avg_loss': 6.151107918544677, 'avg_acc': 50.023622287247015, 'loss': 5.969123363494873}


EP_train:0:  59%|| 4111/6926 [4:07:07&lt;5:53:23,  7.53s/it]

{'epoch': 0, 'iter': 4110, 'avg_loss': 6.149992354273999, 'avg_acc': 50.02204451471661, 'loss': 5.289840221405029}


EP_train:0:  60%|| 4121/6926 [4:08:27&lt;6:13:04,  7.98s/it]

{'epoch': 0, 'iter': 4120, 'avg_loss': 6.148857050166492, 'avg_acc': 50.03109075467119, 'loss': 5.793868541717529}


EP_train:0:  60%|| 4131/6926 [4:09:44&lt;6:00:25,  7.74s/it]

{'epoch': 0, 'iter': 4130, 'avg_loss': 6.1480596452785505, 'avg_acc': 50.03631082062454, 'loss': 5.535717010498047}


EP_train:0:  60%|| 4141/6926 [4:11:07&lt;6:19:39,  8.18s/it]

{'epoch': 0, 'iter': 4140, 'avg_loss': 6.147115438751943, 'avg_acc': 50.02943129678822, 'loss': 5.722696304321289}


EP_train:0:  60%|| 4151/6926 [4:12:24&lt;5:52:41,  7.63s/it]

{'epoch': 0, 'iter': 4150, 'avg_loss': 6.146216990085603, 'avg_acc': 50.02484341122621, 'loss': 5.767571449279785}


EP_train:0:  60%|| 4161/6926 [4:13:46&lt;6:18:56,  8.22s/it]

{'epoch': 0, 'iter': 4160, 'avg_loss': 6.145457845443546, 'avg_acc': 50.03304494111992, 'loss': 5.451801300048828}


EP_train:0:  60%|| 4171/6926 [4:15:07&lt;6:13:32,  8.14s/it]

{'epoch': 0, 'iter': 4170, 'avg_loss': 6.14477330882096, 'avg_acc': 50.03521337808679, 'loss': 5.747236251831055}


EP_train:0:  60%|| 4181/6926 [4:16:33&lt;6:16:33,  8.23s/it]

{'epoch': 0, 'iter': 4180, 'avg_loss': 6.143900096202632, 'avg_acc': 50.036624013393926, 'loss': 5.488006591796875}


EP_train:0:  61%|| 4191/6926 [4:17:56&lt;6:14:32,  8.22s/it]

{'epoch': 0, 'iter': 4190, 'avg_loss': 6.142865265277598, 'avg_acc': 50.03802791696492, 'loss': 5.668560981750488}


EP_train:0:  61%|| 4201/6926 [4:19:20&lt;6:25:45,  8.49s/it]

{'epoch': 0, 'iter': 4200, 'avg_loss': 6.1420037670948195, 'avg_acc': 50.026779338252794, 'loss': 5.94446325302124}


EP_train:0:  61%|| 4211/6926 [4:20:46&lt;6:26:24,  8.54s/it]

{'epoch': 0, 'iter': 4210, 'avg_loss': 6.141215065204454, 'avg_acc': 50.02226312039896, 'loss': 5.621335506439209}


EP_train:0:  61%|| 4221/6926 [4:22:11&lt;6:23:34,  8.51s/it]

{'epoch': 0, 'iter': 4220, 'avg_loss': 6.140289033371475, 'avg_acc': 50.01406657190239, 'loss': 5.930065631866455}


EP_train:0:  61%|| 4231/6926 [4:23:40&lt;6:42:31,  8.96s/it]

{'epoch': 0, 'iter': 4230, 'avg_loss': 6.139495749080246, 'avg_acc': 50.02068069014417, 'loss': 6.0438127517700195}


EP_train:0:  61%|| 4241/6926 [4:25:07&lt;6:25:31,  8.62s/it]

{'epoch': 0, 'iter': 4240, 'avg_loss': 6.138515166926007, 'avg_acc': 50.01252652676256, 'loss': 6.2702460289001465}


EP_train:0:  61%|| 4251/6926 [4:26:37&lt;6:36:09,  8.89s/it]

{'epoch': 0, 'iter': 4250, 'avg_loss': 6.137436031538075, 'avg_acc': 50.02131851329099, 'loss': 5.432215690612793}


EP_train:0:  62%|| 4261/6926 [4:28:08&lt;6:50:01,  9.23s/it]

{'epoch': 0, 'iter': 4260, 'avg_loss': 6.136874010461621, 'avg_acc': 50.023468669326455, 'loss': 5.911162376403809}


EP_train:0:  62%|| 4271/6926 [4:29:40&lt;6:59:10,  9.47s/it]

{'epoch': 0, 'iter': 4270, 'avg_loss': 6.13604357348089, 'avg_acc': 50.02048700538515, 'loss': 5.512773036956787}


EP_train:0:  62%|| 4281/6926 [4:31:09&lt;6:40:25,  9.08s/it]

{'epoch': 0, 'iter': 4280, 'avg_loss': 6.135322889249142, 'avg_acc': 50.01459939266526, 'loss': 5.481927871704102}


EP_train:0:  62%|| 4291/6926 [4:32:35&lt;6:29:58,  8.88s/it]

{'epoch': 0, 'iter': 4290, 'avg_loss': 6.134688405383859, 'avg_acc': 50.023304591004425, 'loss': 5.839148044586182}


EP_train:0:  62%|| 4301/6926 [4:34:03&lt;6:17:36,  8.63s/it]

{'epoch': 0, 'iter': 4300, 'avg_loss': 6.133672989404249, 'avg_acc': 50.01307835387119, 'loss': 5.7530717849731445}


EP_train:0:  62%|| 4311/6926 [4:35:32&lt;6:29:21,  8.93s/it]

{'epoch': 0, 'iter': 4310, 'avg_loss': 6.133218464954246, 'avg_acc': 50.0152226861517, 'loss': 6.094731330871582}


EP_train:0:  62%|| 4321/6926 [4:37:04&lt;6:54:45,  9.55s/it]

{'epoch': 0, 'iter': 4320, 'avg_loss': 6.132279896730627, 'avg_acc': 50.02314279102059, 'loss': 5.431138038635254}


EP_train:0:  63%|| 4331/6926 [4:38:31&lt;6:33:19,  9.09s/it]

{'epoch': 0, 'iter': 4330, 'avg_loss': 6.131346632222661, 'avg_acc': 50.04112791503117, 'loss': 5.826376914978027}


EP_train:0:  63%|| 4341/6926 [4:40:00&lt;6:34:02,  9.15s/it]

{'epoch': 0, 'iter': 4340, 'avg_loss': 6.130246740858337, 'avg_acc': 50.04247293250403, 'loss': 5.552226543426514}


EP_train:0:  63%|| 4351/6926 [4:41:29&lt;6:26:04,  9.00s/it]

{'epoch': 0, 'iter': 4350, 'avg_loss': 6.129379989305766, 'avg_acc': 50.0423753160193, 'loss': 5.709573745727539}


EP_train:0:  63%|| 4361/6926 [4:42:56&lt;6:18:54,  8.86s/it]

{'epoch': 0, 'iter': 4360, 'avg_loss': 6.128431880454956, 'avg_acc': 50.03654551708324, 'loss': 5.882369041442871}


EP_train:0:  63%|| 4371/6926 [4:44:20&lt;6:04:57,  8.57s/it]

{'epoch': 0, 'iter': 4370, 'avg_loss': 6.127559314082837, 'avg_acc': 50.03932166552276, 'loss': 5.3647308349609375}


EP_train:0:  63%|| 4381/6926 [4:45:44&lt;5:52:51,  8.32s/it]

{'epoch': 0, 'iter': 4380, 'avg_loss': 6.126560695093534, 'avg_acc': 50.02781899109793, 'loss': 5.55737829208374}


EP_train:0:  63%|| 4391/6926 [4:47:11&lt;6:10:30,  8.77s/it]

{'epoch': 0, 'iter': 4390, 'avg_loss': 6.125727731148276, 'avg_acc': 50.02775563652927, 'loss': 5.657538890838623}


EP_train:0:  64%|| 4401/6926 [4:48:37&lt;6:02:49,  8.62s/it]

{'epoch': 0, 'iter': 4400, 'avg_loss': 6.1247635921330055, 'avg_acc': 50.018461713246985, 'loss': 5.667081832885742}


EP_train:0:  64%|| 4411/6926 [4:50:03&lt;6:07:42,  8.77s/it]

{'epoch': 0, 'iter': 4410, 'avg_loss': 6.123572657206139, 'avg_acc': 50.0184198594423, 'loss': 5.8721442222595215}


EP_train:0:  64%|| 4421/6926 [4:51:33&lt;6:21:36,  9.14s/it]

{'epoch': 0, 'iter': 4420, 'avg_loss': 6.123023362214736, 'avg_acc': 50.02261931689663, 'loss': 5.535576820373535}


EP_train:0:  64%|| 4431/6926 [4:53:00&lt;6:02:01,  8.71s/it]

{'epoch': 0, 'iter': 4430, 'avg_loss': 6.122202802635267, 'avg_acc': 50.03244188670729, 'loss': 5.904573440551758}


EP_train:0:  64%|| 4441/6926 [4:54:28&lt;6:11:12,  8.96s/it]

{'epoch': 0, 'iter': 4440, 'avg_loss': 6.120835080390523, 'avg_acc': 50.03166516550327, 'loss': 5.762210845947266}


EP_train:0:  64%|| 4451/6926 [4:55:56&lt;5:57:42,  8.67s/it]

{'epoch': 0, 'iter': 4450, 'avg_loss': 6.120343457176776, 'avg_acc': 50.03089193439676, 'loss': 5.757116794586182}


EP_train:0:  64%|| 4461/6926 [4:57:24&lt;6:08:39,  8.97s/it]

{'epoch': 0, 'iter': 4460, 'avg_loss': 6.119431651619298, 'avg_acc': 50.01891392064559, 'loss': 5.837987899780273}


EP_train:0:  65%|| 4471/6926 [4:58:54&lt;6:08:38,  9.01s/it]

{'epoch': 0, 'iter': 4470, 'avg_loss': 6.1184872946358455, 'avg_acc': 50.01328002683964, 'loss': 5.809126377105713}


EP_train:0:  65%|| 4481/6926 [5:00:20&lt;5:46:45,  8.51s/it]

{'epoch': 0, 'iter': 4480, 'avg_loss': 6.117713194291418, 'avg_acc': 50.0251060031243, 'loss': 5.521522521972656}


EP_train:0:  65%|| 4491/6926 [5:01:50&lt;5:50:37,  8.64s/it]

{'epoch': 0, 'iter': 4490, 'avg_loss': 6.116802253268711, 'avg_acc': 50.02017924738366, 'loss': 6.110646724700928}


EP_train:0:  65%|| 4501/6926 [5:03:23&lt;6:00:07,  8.91s/it]

{'epoch': 0, 'iter': 4500, 'avg_loss': 6.116173224458692, 'avg_acc': 50.01805154410132, 'loss': 6.085875034332275}


EP_train:0:  65%|| 4511/6926 [5:05:00&lt;6:19:40,  9.43s/it]

{'epoch': 0, 'iter': 4510, 'avg_loss': 6.1152781693905265, 'avg_acc': 50.01246951895367, 'loss': 6.162149906158447}


EP_train:0:  65%|| 4521/6926 [5:06:35&lt;6:15:37,  9.37s/it]

{'epoch': 0, 'iter': 4520, 'avg_loss': 6.114330110864232, 'avg_acc': 50.01520681265207, 'loss': 6.03239107131958}


EP_train:0:  65%|| 4531/6926 [5:08:17&lt;6:49:36, 10.26s/it]

{'epoch': 0, 'iter': 4530, 'avg_loss': 6.113296936269207, 'avg_acc': 50.02069079673361, 'loss': 5.511043548583984}


EP_train:0:  66%|| 4541/6926 [5:10:00&lt;6:42:09, 10.12s/it]

{'epoch': 0, 'iter': 4540, 'avg_loss': 6.112421222994229, 'avg_acc': 50.01926888350584, 'loss': 5.17509126663208}


EP_train:0:  66%|| 4551/6926 [5:11:43&lt;6:58:53, 10.58s/it]

{'epoch': 0, 'iter': 4550, 'avg_loss': 6.111743990705972, 'avg_acc': 50.02471984179301, 'loss': 5.924271583557129}


EP_train:0:  66%|| 4561/6926 [5:13:32&lt;7:05:25, 10.79s/it]

{'epoch': 0, 'iter': 4560, 'avg_loss': 6.11097088029473, 'avg_acc': 50.030832054374045, 'loss': 5.890345573425293}


EP_train:0:  66%|| 4571/6926 [5:15:17&lt;6:53:51, 10.54s/it]

{'epoch': 0, 'iter': 4570, 'avg_loss': 6.110327378687987, 'avg_acc': 50.039652154889524, 'loss': 5.677709579467773}


EP_train:0:  66%|| 4581/6926 [5:17:07&lt;7:03:23, 10.83s/it]

{'epoch': 0, 'iter': 4580, 'avg_loss': 6.109236018154408, 'avg_acc': 50.04502292075966, 'loss': 5.508075714111328}


EP_train:0:  66%|| 4591/6926 [5:19:01&lt;7:37:03, 11.74s/it]

{'epoch': 0, 'iter': 4590, 'avg_loss': 6.108820357890826, 'avg_acc': 50.041521455020685, 'loss': 6.13588285446167}


EP_train:0:  66%|| 4601/6926 [5:20:52&lt;7:10:36, 11.11s/it]

{'epoch': 0, 'iter': 4600, 'avg_loss': 6.1080951874112595, 'avg_acc': 50.042789610954145, 'loss': 5.552509784698486}


EP_train:0:  67%|| 4611/6926 [5:22:48&lt;7:14:30, 11.26s/it]

{'epoch': 0, 'iter': 4610, 'avg_loss': 6.107930664487734, 'avg_acc': 50.05150726523531, 'loss': 6.015118598937988}


EP_train:0:  67%|| 4621/6926 [5:24:45&lt;7:33:41, 11.81s/it]

{'epoch': 0, 'iter': 4620, 'avg_loss': 6.107511350226799, 'avg_acc': 50.05207206232417, 'loss': 5.898167610168457}


EP_train:0:  67%|| 4631/6926 [5:26:44&lt;7:20:35, 11.52s/it]

{'epoch': 0, 'iter': 4630, 'avg_loss': 6.106834995646221, 'avg_acc': 50.0580328222846, 'loss': 5.948448657989502}


EP_train:0:  67%|| 4641/6926 [5:28:51&lt;8:11:31, 12.91s/it]

{'epoch': 0, 'iter': 4640, 'avg_loss': 6.105808212951811, 'avg_acc': 50.05992781728076, 'loss': 5.264282703399658}


EP_train:0:  67%|| 4651/6926 [5:30:57&lt;8:10:50, 12.95s/it]

{'epoch': 0, 'iter': 4650, 'avg_loss': 6.105038179169161, 'avg_acc': 50.05240808428295, 'loss': 5.927124500274658}


EP_train:0:  67%|| 4661/6926 [5:33:06&lt;8:04:19, 12.83s/it]

{'epoch': 0, 'iter': 4660, 'avg_loss': 6.104328574348585, 'avg_acc': 50.06436387041408, 'loss': 6.021064758300781}


EP_train:0:  67%|| 4671/6926 [5:35:09&lt;7:41:16, 12.27s/it]

{'epoch': 0, 'iter': 4670, 'avg_loss': 6.103573122822838, 'avg_acc': 50.06355705416399, 'loss': 5.581331729888916}


EP_train:0:  68%|| 4681/6926 [5:37:11&lt;7:33:17, 12.11s/it]

{'epoch': 0, 'iter': 4680, 'avg_loss': 6.102721853608684, 'avg_acc': 50.06809442426832, 'loss': 5.77381706237793}


EP_train:0:  68%|| 4691/6926 [5:39:22&lt;7:59:51, 12.88s/it]

{'epoch': 0, 'iter': 4690, 'avg_loss': 6.102065182829991, 'avg_acc': 50.06861543380943, 'loss': 5.896530628204346}


EP_train:0:  68%|| 4701/6926 [5:41:28&lt;7:48:29, 12.63s/it]

{'epoch': 0, 'iter': 4700, 'avg_loss': 6.101369438767813, 'avg_acc': 50.07312273984259, 'loss': 5.971706390380859}


EP_train:0:  68%|| 4711/6926 [5:43:36&lt;7:43:28, 12.55s/it]

{'epoch': 0, 'iter': 4710, 'avg_loss': 6.100448183890893, 'avg_acc': 50.07495754616854, 'loss': 5.855482578277588}


EP_train:0:  68%|| 4721/6926 [5:45:46&lt;8:19:06, 13.58s/it]

{'epoch': 0, 'iter': 4720, 'avg_loss': 6.0997356430147445, 'avg_acc': 50.07347489938573, 'loss': 5.568177223205566}


EP_train:0:  68%|| 4731/6926 [5:47:59&lt;8:01:24, 13.16s/it]

{'epoch': 0, 'iter': 4730, 'avg_loss': 6.0991575538016, 'avg_acc': 50.06407207778483, 'loss': 5.6837592124938965}


EP_train:0:  68%|| 4741/6926 [5:50:17&lt;8:27:48, 13.94s/it]

{'epoch': 0, 'iter': 4740, 'avg_loss': 6.098652768653044, 'avg_acc': 50.06195950221473, 'loss': 5.796774387359619}


EP_train:0:  69%|| 4751/6926 [5:52:35&lt;8:25:23, 13.94s/it]

{'epoch': 0, 'iter': 4750, 'avg_loss': 6.098018825694, 'avg_acc': 50.069722163755, 'loss': 5.777691841125488}


EP_train:0:  69%|| 4761/6926 [5:55:04&lt;9:06:08, 15.14s/it]

{'epoch': 0, 'iter': 4760, 'avg_loss': 6.097104172425169, 'avg_acc': 50.0676065952531, 'loss': 5.552586078643799}


EP_train:0:  69%|| 4771/6926 [5:57:44&lt;9:37:48, 16.09s/it]

{'epoch': 0, 'iter': 4770, 'avg_loss': 6.096467465680742, 'avg_acc': 50.070084887864176, 'loss': 5.810379505157471}


EP_train:0:  69%|| 4781/6926 [6:00:38&lt;10:15:23, 17.21s/it]

{'epoch': 0, 'iter': 4780, 'avg_loss': 6.09603063971945, 'avg_acc': 50.06405563689604, 'loss': 5.595292091369629}


EP_train:0:  69%|| 4791/6926 [6:03:43&lt;11:05:09, 18.69s/it]

{'epoch': 0, 'iter': 4790, 'avg_loss': 6.095529262170093, 'avg_acc': 50.070444583594245, 'loss': 5.8601884841918945}


EP_train:0:  69%|| 4801/6926 [6:07:02&lt;11:54:08, 20.16s/it]

{'epoch': 0, 'iter': 4800, 'avg_loss': 6.094917712919763, 'avg_acc': 50.06964694855238, 'loss': 5.623406410217285}


EP_train:0:  69%|| 4811/6926 [6:10:34&lt;12:47:40, 21.78s/it]

{'epoch': 0, 'iter': 4810, 'avg_loss': 6.0942052355726455, 'avg_acc': 50.07664726668052, 'loss': 6.030642986297607}


EP_train:0:  70%|| 4821/6926 [6:14:13&lt;12:45:07, 21.81s/it]

{'epoch': 0, 'iter': 4820, 'avg_loss': 6.093401744884466, 'avg_acc': 50.079081103505494, 'loss': 5.665616035461426}


EP_train:0:  70%|| 4831/6926 [6:18:04&lt;13:35:32, 23.36s/it]

{'epoch': 0, 'iter': 4830, 'avg_loss': 6.092756156767409, 'avg_acc': 50.08344545642724, 'loss': 5.4798479080200195}


EP_train:0:  70%|| 4841/6926 [6:21:59&lt;13:43:32, 23.70s/it]

{'epoch': 0, 'iter': 4840, 'avg_loss': 6.092291939137914, 'avg_acc': 50.08262755629003, 'loss': 5.376607894897461}


EP_train:0:  70%|| 4851/6926 [6:25:57&lt;13:38:42, 23.67s/it]

{'epoch': 0, 'iter': 4850, 'avg_loss': 6.09143973773004, 'avg_acc': 50.07923623995053, 'loss': 5.781012058258057}


EP_train:0:  70%|| 4861/6926 [6:29:55&lt;13:35:57, 23.71s/it]

{'epoch': 0, 'iter': 4860, 'avg_loss': 6.090944552269524, 'avg_acc': 50.07521600493725, 'loss': 6.19387674331665}


EP_train:0:  70%|| 4871/6926 [6:33:57&lt;13:52:03, 24.29s/it]

{'epoch': 0, 'iter': 4870, 'avg_loss': 6.090154030611323, 'avg_acc': 50.075703141038794, 'loss': 5.867021083831787}


EP_train:0:  70%|| 4881/6926 [6:37:55&lt;13:23:16, 23.57s/it]

{'epoch': 0, 'iter': 4880, 'avg_loss': 6.089595957726539, 'avg_acc': 50.08002970702725, 'loss': 5.85502815246582}


EP_train:0:  71%|| 4891/6926 [6:41:47&lt;13:09:13, 23.27s/it]

{'epoch': 0, 'iter': 4890, 'avg_loss': 6.0889315922990015, 'avg_acc': 50.06708750766714, 'loss': 5.50833797454834}


EP_train:0:  71%|| 4901/6926 [6:45:43&lt;13:12:40, 23.49s/it]

{'epoch': 0, 'iter': 4900, 'avg_loss': 6.0882990747003065, 'avg_acc': 50.07268924709243, 'loss': 5.293552398681641}


EP_train:0:  71%|| 4911/6926 [6:49:39&lt;13:06:28, 23.42s/it]

{'epoch': 0, 'iter': 4910, 'avg_loss': 6.0876276060511, 'avg_acc': 50.06681429444105, 'loss': 6.01899528503418}


EP_train:0:  71%|| 4921/6926 [6:53:30&lt;12:36:35, 22.64s/it]

{'epoch': 0, 'iter': 4920, 'avg_loss': 6.087292747947167, 'avg_acc': 50.066043487096124, 'loss': 5.781203269958496}


EP_train:0:  71%|| 4931/6926 [6:57:16&lt;12:33:19, 22.66s/it]

{'epoch': 0, 'iter': 4930, 'avg_loss': 6.086437698794388, 'avg_acc': 50.06527580612452, 'loss': 6.0631184577941895}


EP_train:0:  71%|| 4941/6926 [7:00:58&lt;12:13:23, 22.17s/it]

{'epoch': 0, 'iter': 4940, 'avg_loss': 6.085821283464368, 'avg_acc': 50.06640862173649, 'loss': 5.635220050811768}


EP_train:0:  71%|| 4951/6926 [7:04:38&lt;12:05:48, 22.05s/it]

{'epoch': 0, 'iter': 4950, 'avg_loss': 6.0850673654156004, 'avg_acc': 50.074479903049884, 'loss': 5.9276885986328125}


EP_train:0:  72%|| 4961/6926 [7:08:18&lt;11:56:45, 21.89s/it]

{'epoch': 0, 'iter': 4960, 'avg_loss': 6.084530617291589, 'avg_acc': 50.084408385406164, 'loss': 5.963618278503418}


EP_train:0:  72%|| 4971/6926 [7:11:52&lt;11:40:34, 21.50s/it]

{'epoch': 0, 'iter': 4970, 'avg_loss': 6.083843590243917, 'avg_acc': 50.0779521223094, 'loss': 5.6765336990356445}


EP_train:0:  72%|| 4981/6926 [7:15:29&lt;11:42:25, 21.67s/it]

{'epoch': 0, 'iter': 4980, 'avg_loss': 6.0829357622235065, 'avg_acc': 50.07340393495282, 'loss': 5.715503215789795}


EP_train:0:  72%|| 4991/6926 [7:19:05&lt;11:33:31, 21.50s/it]

{'epoch': 0, 'iter': 4990, 'avg_loss': 6.082450271297662, 'avg_acc': 50.08014425966741, 'loss': 5.585351943969727}


EP_train:0:  72%|| 5001/6926 [7:22:38&lt;11:20:36, 21.21s/it]

{'epoch': 0, 'iter': 5000, 'avg_loss': 6.081787624160806, 'avg_acc': 50.084983003399316, 'loss': 5.853309631347656}


EP_train:0:  72%|| 5011/6926 [7:26:09&lt;11:10:31, 21.01s/it]

{'epoch': 0, 'iter': 5010, 'avg_loss': 6.081495600578386, 'avg_acc': 50.08980243464378, 'loss': 5.8602190017700195}


EP_train:0:  72%|| 5021/6926 [7:29:41&lt;11:10:15, 21.11s/it]

{'epoch': 0, 'iter': 5020, 'avg_loss': 6.080860076399824, 'avg_acc': 50.09086835291775, 'loss': 5.634836673736572}


EP_train:0:  73%|| 5031/6926 [7:33:12&lt;11:02:16, 20.97s/it]

{'epoch': 0, 'iter': 5030, 'avg_loss': 6.080404411748872, 'avg_acc': 50.09006658715961, 'loss': 5.9641618728637695}


EP_train:0:  73%|| 5041/6926 [7:36:41&lt;10:53:40, 20.81s/it]

{'epoch': 0, 'iter': 5040, 'avg_loss': 6.0797398177859945, 'avg_acc': 50.09918666931165, 'loss': 5.676470756530762}


EP_train:0:  73%|| 5051/6926 [7:40:07&lt;10:41:11, 20.52s/it]

{'epoch': 0, 'iter': 5050, 'avg_loss': 6.079021374368828, 'avg_acc': 50.09465947337161, 'loss': 5.772432804107666}


EP_train:0:  73%|| 5061/6926 [7:43:33&lt;10:38:00, 20.53s/it]

{'epoch': 0, 'iter': 5060, 'avg_loss': 6.078650245598667, 'avg_acc': 50.09262003556609, 'loss': 5.78647518157959}


EP_train:0:  73%|| 5071/6926 [7:47:00&lt;10:40:41, 20.72s/it]

{'epoch': 0, 'iter': 5070, 'avg_loss': 6.078217857524832, 'avg_acc': 50.09428613685664, 'loss': 6.273963928222656}


EP_train:0:  73%|| 5081/6926 [7:50:26&lt;10:32:48, 20.58s/it]

{'epoch': 0, 'iter': 5080, 'avg_loss': 6.07775627827696, 'avg_acc': 50.09717575280457, 'loss': 5.673422336578369}


EP_train:0:  74%|| 5091/6926 [7:53:53&lt;10:35:43, 20.79s/it]

{'epoch': 0, 'iter': 5090, 'avg_loss': 6.077203060784056, 'avg_acc': 50.102509330190536, 'loss': 5.872105121612549}


EP_train:0:  74%|| 5101/6926 [7:57:19&lt;10:25:31, 20.57s/it]

{'epoch': 0, 'iter': 5100, 'avg_loss': 6.0764456864689596, 'avg_acc': 50.10047049598118, 'loss': 5.70937442779541}


EP_train:0:  74%|| 5111/6926 [8:00:44&lt;10:17:25, 20.41s/it]

{'epoch': 0, 'iter': 5110, 'avg_loss': 6.075798931244977, 'avg_acc': 50.10271962433966, 'loss': 5.772765159606934}


EP_train:0:  74%|| 5121/6926 [8:04:07&lt;10:16:09, 20.48s/it]

{'epoch': 0, 'iter': 5120, 'avg_loss': 6.075373151623116, 'avg_acc': 50.0994678773677, 'loss': 5.413810729980469}


EP_train:0:  74%|| 5131/6926 [8:07:30&lt;10:03:30, 20.17s/it]

{'epoch': 0, 'iter': 5130, 'avg_loss': 6.074517063731177, 'avg_acc': 50.101101149873315, 'loss': 5.70771598815918}


EP_train:0:  74%|| 5141/6926 [8:10:53&lt;10:02:44, 20.26s/it]

{'epoch': 0, 'iter': 5140, 'avg_loss': 6.073841538695458, 'avg_acc': 50.09847305971601, 'loss': 5.845581531524658}


EP_train:0:  74%|| 5151/6926 [8:14:14&lt;9:51:51, 20.01s/it] 

{'epoch': 0, 'iter': 5150, 'avg_loss': 6.073580761692682, 'avg_acc': 50.09828188701223, 'loss': 5.733440399169922}


EP_train:0:  75%|| 5161/6926 [8:17:36&lt;9:50:40, 20.08s/it]

{'epoch': 0, 'iter': 5160, 'avg_loss': 6.072867002766207, 'avg_acc': 50.087192404572754, 'loss': 5.919801235198975}


EP_train:0:  75%|| 5171/6926 [8:20:58&lt;9:53:42, 20.30s/it]

{'epoch': 0, 'iter': 5170, 'avg_loss': 6.072219424357476, 'avg_acc': 50.085815122800234, 'loss': 5.778360366821289}


EP_train:0:  75%|| 5181/6926 [8:24:19&lt;9:45:01, 20.12s/it]

{'epoch': 0, 'iter': 5180, 'avg_loss': 6.071556362998092, 'avg_acc': 50.09349063887281, 'loss': 5.578665256500244}


EP_train:0:  75%|| 5191/6926 [8:27:38&lt;9:38:07, 19.99s/it]

{'epoch': 0, 'iter': 5190, 'avg_loss': 6.0709186734732485, 'avg_acc': 50.0993305721441, 'loss': 6.053485870361328}


EP_train:0:  75%|| 5201/6926 [8:30:58&lt;9:32:31, 19.91s/it]

{'epoch': 0, 'iter': 5200, 'avg_loss': 6.070428849733511, 'avg_acc': 50.10634974043453, 'loss': 5.696314811706543}


EP_train:0:  75%|| 5211/6926 [8:34:17&lt;9:27:50, 19.87s/it]

{'epoch': 0, 'iter': 5210, 'avg_loss': 6.069478024083945, 'avg_acc': 50.10614565342545, 'loss': 5.324738025665283}


EP_train:0:  75%|| 5221/6926 [8:37:36&lt;9:25:46, 19.91s/it]

{'epoch': 0, 'iter': 5220, 'avg_loss': 6.069184598007597, 'avg_acc': 50.10235108216816, 'loss': 5.764991283416748}


EP_train:0:  76%|| 5231/6926 [8:40:55&lt;9:22:40, 19.92s/it]

{'epoch': 0, 'iter': 5230, 'avg_loss': 6.069119955608708, 'avg_acc': 50.10096061938444, 'loss': 6.385601997375488}


EP_train:0:  76%|| 5241/6926 [8:44:14&lt;9:14:32, 19.75s/it]

{'epoch': 0, 'iter': 5240, 'avg_loss': 6.068350166338269, 'avg_acc': 50.100767983209316, 'loss': 5.714400768280029}


EP_train:0:  76%|| 5251/6926 [8:47:32&lt;9:11:35, 19.76s/it]

{'epoch': 0, 'iter': 5250, 'avg_loss': 6.067922578269335, 'avg_acc': 50.09581508284137, 'loss': 5.966418266296387}


EP_train:0:  76%|| 5261/6926 [8:50:49&lt;9:07:37, 19.73s/it]

{'epoch': 0, 'iter': 5260, 'avg_loss': 6.067496065630293, 'avg_acc': 50.087911043527846, 'loss': 5.884022235870361}


EP_train:0:  76%|| 5271/6926 [8:54:06&lt;9:02:55, 19.68s/it]

{'epoch': 0, 'iter': 5270, 'avg_loss': 6.066774628642297, 'avg_acc': 50.0818155947638, 'loss': 5.430381774902344}


EP_train:0:  76%|| 5281/6926 [8:57:23&lt;8:58:15, 19.63s/it]

{'epoch': 0, 'iter': 5280, 'avg_loss': 6.066137432578025, 'avg_acc': 50.089945086157925, 'loss': 5.879445552825928}


EP_train:0:  76%|| 5291/6926 [9:00:38&lt;8:53:16, 19.57s/it]

{'epoch': 0, 'iter': 5290, 'avg_loss': 6.065570325712652, 'avg_acc': 50.08918446418447, 'loss': 5.868078231811523}


EP_train:0:  77%|| 5301/6926 [9:03:55&lt;8:52:29, 19.66s/it]

{'epoch': 0, 'iter': 5300, 'avg_loss': 6.0650617345462, 'avg_acc': 50.08547915487643, 'loss': 5.8117451667785645}


EP_train:0:  77%|| 5311/6926 [9:07:12&lt;8:49:28, 19.67s/it]

{'epoch': 0, 'iter': 5310, 'avg_loss': 6.064686179497758, 'avg_acc': 50.08708341178686, 'loss': 5.709105014801025}


EP_train:0:  77%|| 5321/6926 [9:10:27&lt;8:42:24, 19.53s/it]

{'epoch': 0, 'iter': 5320, 'avg_loss': 6.064325973114289, 'avg_acc': 50.08339597819958, 'loss': 5.776423931121826}


EP_train:0:  77%|| 5331/6926 [9:13:42&lt;8:40:33, 19.58s/it]

{'epoch': 0, 'iter': 5330, 'avg_loss': 6.0636539949393145, 'avg_acc': 50.079722378540616, 'loss': 5.148025989532471}


EP_train:0:  77%|| 5341/6926 [9:16:58&lt;8:40:46, 19.71s/it]

{'epoch': 0, 'iter': 5340, 'avg_loss': 6.062986289354505, 'avg_acc': 50.07430724583411, 'loss': 6.282643795013428}


EP_train:0:  77%|| 5351/6926 [9:20:15&lt;8:35:25, 19.63s/it]

{'epoch': 0, 'iter': 5350, 'avg_loss': 6.062770438225464, 'avg_acc': 50.07008035881144, 'loss': 6.184378147125244}


EP_train:0:  77%|| 5361/6926 [9:23:30&lt;8:28:24, 19.49s/it]

{'epoch': 0, 'iter': 5360, 'avg_loss': 6.062225062863592, 'avg_acc': 50.061205931729155, 'loss': 5.738152503967285}


EP_train:0:  78%|| 5371/6926 [9:26:45&lt;8:27:35, 19.59s/it]

{'epoch': 0, 'iter': 5370, 'avg_loss': 6.061937043174555, 'avg_acc': 50.063419288773034, 'loss': 5.628539085388184}


EP_train:0:  78%|| 5381/6926 [9:30:02&lt;8:26:10, 19.66s/it]

{'epoch': 0, 'iter': 5380, 'avg_loss': 6.061433275754823, 'avg_acc': 50.05400947779223, 'loss': 5.4939422607421875}


EP_train:0:  78%|| 5391/6926 [9:33:17&lt;8:20:35, 19.57s/it]

{'epoch': 0, 'iter': 5390, 'avg_loss': 6.0608886586251005, 'avg_acc': 50.059126321647184, 'loss': 6.1512346267700195}


EP_train:0:  78%|| 5401/6926 [9:36:33&lt;8:15:32, 19.50s/it]

{'epoch': 0, 'iter': 5400, 'avg_loss': 6.060428837894665, 'avg_acc': 50.061909831512686, 'loss': 6.008522987365723}


EP_train:0:  78%|| 5411/6926 [9:39:47&lt;8:11:39, 19.47s/it]

{'epoch': 0, 'iter': 5410, 'avg_loss': 6.060002618566544, 'avg_acc': 50.06237294400295, 'loss': 5.748854160308838}


EP_train:0:  78%|| 5421/6926 [9:43:02&lt;8:09:10, 19.50s/it]

{'epoch': 0, 'iter': 5420, 'avg_loss': 6.05946754243756, 'avg_acc': 50.05706972883232, 'loss': 6.189664840698242}


EP_train:0:  78%|| 5431/6926 [9:46:17&lt;8:06:19, 19.52s/it]

{'epoch': 0, 'iter': 5430, 'avg_loss': 6.0591200932330835, 'avg_acc': 50.058115448352055, 'loss': 5.9671311378479}


EP_train:0:  79%|| 5441/6926 [9:49:31&lt;8:00:03, 19.40s/it]

{'epoch': 0, 'iter': 5440, 'avg_loss': 6.058608655521174, 'avg_acc': 50.064900753537955, 'loss': 5.550085067749023}


EP_train:0:  79%|| 5451/6926 [9:52:44&lt;7:54:18, 19.29s/it]

{'epoch': 0, 'iter': 5450, 'avg_loss': 6.058155152365125, 'avg_acc': 50.05790221977618, 'loss': 6.0328145027160645}


EP_train:0:  79%|| 5461/6926 [9:55:58&lt;7:53:11, 19.38s/it]

{'epoch': 0, 'iter': 5460, 'avg_loss': 6.057945248234121, 'avg_acc': 50.05836843069035, 'loss': 6.305117130279541}


EP_train:0:  79%|| 5471/6926 [9:59:12&lt;7:48:24, 19.32s/it]

{'epoch': 0, 'iter': 5470, 'avg_loss': 6.057664112512208, 'avg_acc': 50.05312100164504, 'loss': 5.615352630615234}


EP_train:0:  79%|| 5481/6926 [10:02:24&lt;7:45:19, 19.32s/it]

{'epoch': 0, 'iter': 5480, 'avg_loss': 6.057026087683149, 'avg_acc': 50.05416438606094, 'loss': 5.559899806976318}


EP_train:0:  79%|| 5491/6926 [10:05:37&lt;7:39:49, 19.23s/it]

{'epoch': 0, 'iter': 5490, 'avg_loss': 6.05657900966727, 'avg_acc': 50.04894372609725, 'loss': 5.771035671234131}


EP_train:0:  79%|| 5501/6926 [10:08:49&lt;7:36:18, 19.21s/it]

{'epoch': 0, 'iter': 5500, 'avg_loss': 6.0561153448791725, 'avg_acc': 50.05908016724232, 'loss': 5.7838664054870605}


EP_train:0:  80%|| 5511/6926 [10:12:01&lt;7:32:20, 19.18s/it]

{'epoch': 0, 'iter': 5510, 'avg_loss': 6.055715451632496, 'avg_acc': 50.06010705861005, 'loss': 5.436075687408447}


EP_train:0:  80%|| 5521/6926 [10:15:13&lt;7:29:45, 19.21s/it]

{'epoch': 0, 'iter': 5520, 'avg_loss': 6.055223534923817, 'avg_acc': 50.05377196160116, 'loss': 6.087020397186279}


EP_train:0:  80%|| 5531/6926 [10:18:25&lt;7:25:30, 19.16s/it]

{'epoch': 0, 'iter': 5530, 'avg_loss': 6.054754813440323, 'avg_acc': 50.05367474236123, 'loss': 5.598529815673828}


EP_train:0:  80%|| 5541/6926 [10:21:37&lt;7:22:04, 19.15s/it]

{'epoch': 0, 'iter': 5540, 'avg_loss': 6.054398222577161, 'avg_acc': 50.05132196354448, 'loss': 5.5578155517578125}


EP_train:0:  80%|| 5551/6926 [10:24:48&lt;7:18:26, 19.13s/it]

{'epoch': 0, 'iter': 5550, 'avg_loss': 6.053861262669028, 'avg_acc': 50.0444739686543, 'loss': 5.696660041809082}


EP_train:0:  80%|| 5561/6926 [10:28:00&lt;7:15:21, 19.14s/it]

{'epoch': 0, 'iter': 5560, 'avg_loss': 6.053380429583945, 'avg_acc': 50.04495594317569, 'loss': 5.97573184967041}


EP_train:0:  80%|| 5571/6926 [10:31:10&lt;7:10:42, 19.07s/it]

{'epoch': 0, 'iter': 5570, 'avg_loss': 6.052962116483854, 'avg_acc': 50.047679949739724, 'loss': 6.062566757202148}


EP_train:0:  81%|| 5581/6926 [10:34:21&lt;7:06:29, 19.03s/it]

{'epoch': 0, 'iter': 5580, 'avg_loss': 6.052793034941593, 'avg_acc': 50.04927432359793, 'loss': 6.089478492736816}


EP_train:0:  81%|| 5591/6926 [10:37:31&lt;7:02:17, 18.98s/it]

{'epoch': 0, 'iter': 5590, 'avg_loss': 6.05223103350805, 'avg_acc': 50.04471472008585, 'loss': 5.812742710113525}


EP_train:0:  81%|| 5601/6926 [10:40:44&lt;7:04:37, 19.23s/it]

{'epoch': 0, 'iter': 5600, 'avg_loss': 6.051796140723559, 'avg_acc': 50.05579360828424, 'loss': 6.247024059295654}


EP_train:0:  81%|| 5611/6926 [10:43:55&lt;7:01:27, 19.23s/it]

{'epoch': 0, 'iter': 5610, 'avg_loss': 6.051140494576922, 'avg_acc': 50.04956781322403, 'loss': 5.793033599853516}


EP_train:0:  81%|| 5621/6926 [10:47:05&lt;6:54:00, 19.03s/it]

{'epoch': 0, 'iter': 5620, 'avg_loss': 6.050951790330334, 'avg_acc': 50.05059153175592, 'loss': 6.803011417388916}


EP_train:0:  81%|| 5631/6926 [10:50:16&lt;6:50:25, 19.02s/it]

{'epoch': 0, 'iter': 5630, 'avg_loss': 6.0504347828814415, 'avg_acc': 50.05771621381637, 'loss': 5.808588981628418}


EP_train:0:  81%|| 5641/6926 [10:53:27&lt;6:50:41, 19.18s/it]

{'epoch': 0, 'iter': 5640, 'avg_loss': 6.050119936962834, 'avg_acc': 50.05484399929091, 'loss': 5.763957977294922}


EP_train:0:  82%|| 5651/6926 [10:56:36&lt;6:42:50, 18.96s/it]

{'epoch': 0, 'iter': 5650, 'avg_loss': 6.049732971984588, 'avg_acc': 50.05474694744293, 'loss': 5.428714275360107}


EP_train:0:  82%|| 5661/6926 [10:59:47&lt;6:42:56, 19.11s/it]

{'epoch': 0, 'iter': 5660, 'avg_loss': 6.049299944291539, 'avg_acc': 50.05796237413884, 'loss': 6.474251747131348}


EP_train:0:  82%|| 5671/6926 [11:02:57&lt;6:38:57, 19.07s/it]

{'epoch': 0, 'iter': 5670, 'avg_loss': 6.04898352682685, 'avg_acc': 50.05345177217422, 'loss': 5.9161858558654785}


EP_train:0:  82%|| 5681/6926 [11:06:07&lt;6:33:51, 18.98s/it]

{'epoch': 0, 'iter': 5680, 'avg_loss': 6.048277414258444, 'avg_acc': 50.05335768350643, 'loss': 5.432251930236816}


EP_train:0:  82%|| 5691/6926 [11:09:17&lt;6:31:56, 19.04s/it]

{'epoch': 0, 'iter': 5690, 'avg_loss': 6.047640271774182, 'avg_acc': 50.05436215076436, 'loss': 6.023947715759277}


EP_train:0:  82%|| 5701/6926 [11:12:27&lt;6:28:32, 19.03s/it]

{'epoch': 0, 'iter': 5700, 'avg_loss': 6.047283367239954, 'avg_acc': 50.051526048061746, 'loss': 6.204166412353516}


EP_train:0:  82%|| 5711/6926 [11:15:37&lt;6:24:31, 18.99s/it]

{'epoch': 0, 'iter': 5710, 'avg_loss': 6.046686040063055, 'avg_acc': 50.05636053230608, 'loss': 5.616063594818115}


EP_train:0:  83%|| 5721/6926 [11:18:47&lt;6:21:48, 19.01s/it]

{'epoch': 0, 'iter': 5720, 'avg_loss': 6.046054969194823, 'avg_acc': 50.051892151721724, 'loss': 5.643561840057373}


EP_train:0:  83%|| 5731/6926 [11:21:57&lt;6:18:18, 18.99s/it]

{'epoch': 0, 'iter': 5730, 'avg_loss': 6.045337284033553, 'avg_acc': 50.05779968591869, 'loss': 5.545201301574707}


EP_train:0:  83%|| 5741/6926 [11:25:08&lt;6:16:15, 19.05s/it]

{'epoch': 0, 'iter': 5740, 'avg_loss': 6.045013471589107, 'avg_acc': 50.05606601637346, 'loss': 5.711957931518555}


EP_train:0:  83%|| 5751/6926 [11:28:18&lt;6:11:46, 18.98s/it]

{'epoch': 0, 'iter': 5750, 'avg_loss': 6.044551691248653, 'avg_acc': 50.04781777082247, 'loss': 5.949689865112305}


EP_train:0:  83%|| 5761/6926 [11:31:28&lt;6:09:32, 19.03s/it]

{'epoch': 0, 'iter': 5760, 'avg_loss': 6.043848627372203, 'avg_acc': 50.049904530463465, 'loss': 5.838766098022461}


EP_train:0:  83%|| 5771/6926 [11:34:39&lt;6:06:35, 19.04s/it]

{'epoch': 0, 'iter': 5770, 'avg_loss': 6.043492621430242, 'avg_acc': 50.04873505458326, 'loss': 5.7118821144104}


EP_train:0:  83%|| 5781/6926 [11:37:49&lt;6:05:26, 19.15s/it]

{'epoch': 0, 'iter': 5780, 'avg_loss': 6.043258738092971, 'avg_acc': 50.045947932883585, 'loss': 6.598991870880127}


EP_train:0:  84%|| 5791/6926 [11:41:00&lt;6:00:30, 19.06s/it]

{'epoch': 0, 'iter': 5790, 'avg_loss': 6.042884248214113, 'avg_acc': 50.04263080642376, 'loss': 6.095027446746826}


EP_train:0:  84%|| 5801/6926 [11:44:10&lt;5:56:30, 19.01s/it]

{'epoch': 0, 'iter': 5800, 'avg_loss': 6.042668266884933, 'avg_acc': 50.03663161523875, 'loss': 6.164670467376709}


EP_train:0:  84%|| 5811/6926 [11:47:20&lt;5:53:52, 19.04s/it]

{'epoch': 0, 'iter': 5810, 'avg_loss': 6.042545654875874, 'avg_acc': 50.02796420581655, 'loss': 6.297694683074951}


EP_train:0:  84%|| 5821/6926 [11:50:30&lt;5:49:56, 19.00s/it]

{'epoch': 0, 'iter': 5820, 'avg_loss': 6.0420319640417315, 'avg_acc': 50.0327478096547, 'loss': 5.990520000457764}


EP_train:0:  84%|| 5831/6926 [11:53:40&lt;5:47:46, 19.06s/it]

{'epoch': 0, 'iter': 5830, 'avg_loss': 6.041855342840784, 'avg_acc': 50.030547933459104, 'loss': 6.198580741882324}


EP_train:0:  84%|| 5841/6926 [11:56:51&lt;5:44:20, 19.04s/it]

{'epoch': 0, 'iter': 5840, 'avg_loss': 6.041508391098992, 'avg_acc': 50.026215545283335, 'loss': 5.53244161605835}


EP_train:0:  84%|| 5851/6926 [12:00:01&lt;5:41:38, 19.07s/it]

{'epoch': 0, 'iter': 5850, 'avg_loss': 6.041253163577797, 'avg_acc': 50.02082977268842, 'loss': 5.799931526184082}


EP_train:0:  85%|| 5861/6926 [12:03:12&lt;5:37:18, 19.00s/it]

{'epoch': 0, 'iter': 5860, 'avg_loss': 6.040680655154163, 'avg_acc': 50.0170619348234, 'loss': 4.953822612762451}


EP_train:0:  85%|| 5871/6926 [12:06:22&lt;5:34:07, 19.00s/it]

{'epoch': 0, 'iter': 5870, 'avg_loss': 6.040281329807158, 'avg_acc': 50.02288792369273, 'loss': 6.154869556427002}


EP_train:0:  85%|| 5881/6926 [12:09:33&lt;5:30:49, 18.99s/it]

{'epoch': 0, 'iter': 5880, 'avg_loss': 6.039676517232951, 'avg_acc': 50.02072351640877, 'loss': 5.802964687347412}


EP_train:0:  85%|| 5891/6926 [12:12:44&lt;5:28:52, 19.07s/it]

{'epoch': 0, 'iter': 5890, 'avg_loss': 6.039148722373251, 'avg_acc': 50.018566457307756, 'loss': 5.647651195526123}


EP_train:0:  85%|| 5901/6926 [12:15:54&lt;5:25:20, 19.04s/it]

{'epoch': 0, 'iter': 5900, 'avg_loss': 6.038776549620661, 'avg_acc': 50.01429842399593, 'loss': 5.790339469909668}


EP_train:0:  85%|| 5911/6926 [12:19:04&lt;5:22:08, 19.04s/it]

{'epoch': 0, 'iter': 5910, 'avg_loss': 6.038495293286342, 'avg_acc': 50.00634410421249, 'loss': 6.066430568695068}


EP_train:0:  85%|| 5921/6926 [12:22:14&lt;5:18:34, 19.02s/it]

{'epoch': 0, 'iter': 5920, 'avg_loss': 6.03806191846902, 'avg_acc': 50.013194561729435, 'loss': 5.983713626861572}


EP_train:0:  86%|| 5931/6926 [12:25:24&lt;5:14:44, 18.98s/it]

{'epoch': 0, 'iter': 5930, 'avg_loss': 6.0374118405838795, 'avg_acc': 50.01317231495533, 'loss': 5.995700359344482}


EP_train:0:  86%|| 5941/6926 [12:28:34&lt;5:12:03, 19.01s/it]

{'epoch': 0, 'iter': 5940, 'avg_loss': 6.037050577310415, 'avg_acc': 50.00841609156708, 'loss': 5.815313339233398}


EP_train:0:  86%|| 5951/6926 [12:31:45&lt;5:09:58, 19.08s/it]

{'epoch': 0, 'iter': 5950, 'avg_loss': 6.036335761638033, 'avg_acc': 50.01417828936313, 'loss': 5.6513352394104}


EP_train:0:  86%|| 5961/6926 [12:34:57&lt;5:09:24, 19.24s/it]

{'epoch': 0, 'iter': 5960, 'avg_loss': 6.035792850404153, 'avg_acc': 50.01310602247945, 'loss': 5.454611778259277}


EP_train:0:  86%|| 5971/6926 [12:38:09&lt;5:03:42, 19.08s/it]

{'epoch': 0, 'iter': 5970, 'avg_loss': 6.035440462674952, 'avg_acc': 50.017270976385866, 'loss': 5.517047882080078}


EP_train:0:  86%|| 5981/6926 [12:41:19&lt;5:00:04, 19.05s/it]

{'epoch': 0, 'iter': 5980, 'avg_loss': 6.035089520701715, 'avg_acc': 50.012017221200466, 'loss': 5.950679779052734}


EP_train:0:  87%|| 5991/6926 [12:44:29&lt;4:55:27, 18.96s/it]

{'epoch': 0, 'iter': 5990, 'avg_loss': 6.034344943213236, 'avg_acc': 50.014605241195135, 'loss': 5.059428691864014}


EP_train:0:  87%|| 6001/6926 [12:47:40&lt;4:54:13, 19.09s/it]

{'epoch': 0, 'iter': 6000, 'avg_loss': 6.0341623494116945, 'avg_acc': 50.01406015664056, 'loss': 6.380976676940918}


EP_train:0:  87%|| 6011/6926 [12:50:51&lt;4:50:01, 19.02s/it]

{'epoch': 0, 'iter': 6010, 'avg_loss': 6.033997507465003, 'avg_acc': 50.01923556812511, 'loss': 5.880812168121338}


EP_train:0:  87%|| 6021/6926 [12:54:01&lt;4:48:12, 19.11s/it]

{'epoch': 0, 'iter': 6020, 'avg_loss': 6.033575561271912, 'avg_acc': 50.02179870453413, 'loss': 5.8794379234313965}


EP_train:0:  87%|| 6031/6926 [12:57:12&lt;4:45:13, 19.12s/it]

{'epoch': 0, 'iter': 6030, 'avg_loss': 6.03301862554751, 'avg_acc': 50.03005305919417, 'loss': 5.894796371459961}


EP_train:0:  87%|| 6041/6926 [13:00:23&lt;4:41:16, 19.07s/it]

{'epoch': 0, 'iter': 6040, 'avg_loss': 6.032567908207009, 'avg_acc': 50.01500165535507, 'loss': 5.722947597503662}


EP_train:0:  87%|| 6051/6926 [13:03:33&lt;4:37:25, 19.02s/it]

{'epoch': 0, 'iter': 6050, 'avg_loss': 6.032233718051888, 'avg_acc': 50.013427532639234, 'loss': 5.412944316864014}


EP_train:0:  88%|| 6061/6926 [13:06:44&lt;4:34:27, 19.04s/it]

{'epoch': 0, 'iter': 6060, 'avg_loss': 6.032118993906116, 'avg_acc': 50.01082742121762, 'loss': 5.759841442108154}


EP_train:0:  88%|| 6071/6926 [13:09:54&lt;4:31:13, 19.03s/it]

{'epoch': 0, 'iter': 6070, 'avg_loss': 6.031723793835955, 'avg_acc': 50.01029484434195, 'loss': 5.889526844024658}


EP_train:0:  88%|| 6081/6926 [13:13:06&lt;4:30:01, 19.17s/it]

{'epoch': 0, 'iter': 6080, 'avg_loss': 6.031357279891854, 'avg_acc': 50.0128473935208, 'loss': 5.590921401977539}


EP_train:0:  88%|| 6091/6926 [13:16:16&lt;4:25:44, 19.10s/it]

{'epoch': 0, 'iter': 6090, 'avg_loss': 6.030790824840034, 'avg_acc': 50.00923493679199, 'loss': 5.659143924713135}


EP_train:0:  88%|| 6101/6926 [13:19:27&lt;4:21:50, 19.04s/it]

{'epoch': 0, 'iter': 6100, 'avg_loss': 6.030299226254093, 'avg_acc': 50.0158785445009, 'loss': 5.879879474639893}


EP_train:0:  88%|| 6111/6926 [13:22:39&lt;4:21:44, 19.27s/it]

{'epoch': 0, 'iter': 6110, 'avg_loss': 6.030024196098526, 'avg_acc': 50.014829815087545, 'loss': 5.886487007141113}


EP_train:0:  88%|| 6121/6926 [13:25:51&lt;4:17:06, 19.16s/it]

{'epoch': 0, 'iter': 6120, 'avg_loss': 6.029531428946757, 'avg_acc': 50.01327397484071, 'loss': 5.961380481719971}


EP_train:0:  89%|| 6131/6926 [13:29:02&lt;4:12:34, 19.06s/it]

{'epoch': 0, 'iter': 6130, 'avg_loss': 6.029220996605321, 'avg_acc': 50.01529114336976, 'loss': 5.741018295288086}


EP_train:0:  89%|| 6141/6926 [13:32:13&lt;4:09:38, 19.08s/it]

{'epoch': 0, 'iter': 6140, 'avg_loss': 6.0290389252765, 'avg_acc': 50.01424849373066, 'loss': 5.700308322906494}


EP_train:0:  89%|| 6151/6926 [13:35:24&lt;4:05:52, 19.04s/it]

{'epoch': 0, 'iter': 6150, 'avg_loss': 6.028690724038745, 'avg_acc': 50.010668996911065, 'loss': 6.073245525360107}


EP_train:0:  89%|| 6161/6926 [13:38:35&lt;4:03:32, 19.10s/it]

{'epoch': 0, 'iter': 6160, 'avg_loss': 6.028311000050633, 'avg_acc': 50.01166612562896, 'loss': 5.587075710296631}


EP_train:0:  89%|| 6171/6926 [13:41:47&lt;4:00:30, 19.11s/it]

{'epoch': 0, 'iter': 6170, 'avg_loss': 6.028168549087171, 'avg_acc': 50.00962161724194, 'loss': 5.567011833190918}


EP_train:0:  89%|| 6181/6926 [13:44:57&lt;3:56:41, 19.06s/it]

{'epoch': 0, 'iter': 6180, 'avg_loss': 6.027922423559762, 'avg_acc': 50.012133958906325, 'loss': 6.1278181076049805}


EP_train:0:  89%|| 6191/6926 [13:48:09&lt;3:55:01, 19.19s/it]

{'epoch': 0, 'iter': 6190, 'avg_loss': 6.027708585727121, 'avg_acc': 50.006057179777095, 'loss': 5.852789878845215}


EP_train:0:  90%|| 6201/6926 [13:51:21&lt;3:50:49, 19.10s/it]

{'epoch': 0, 'iter': 6200, 'avg_loss': 6.027192727190278, 'avg_acc': 50.016630382196425, 'loss': 5.914374351501465}


EP_train:0:  90%|| 6211/6926 [13:54:33&lt;3:48:46, 19.20s/it]

{'epoch': 0, 'iter': 6210, 'avg_loss': 6.026688819806024, 'avg_acc': 50.01710674609564, 'loss': 5.38663911819458}


EP_train:0:  90%|| 6221/6926 [13:57:44&lt;3:44:51, 19.14s/it]

{'epoch': 0, 'iter': 6220, 'avg_loss': 6.026326997125672, 'avg_acc': 50.025618871564056, 'loss': 5.984750270843506}


EP_train:0:  90%|| 6231/6926 [14:00:56&lt;3:41:50, 19.15s/it]

{'epoch': 0, 'iter': 6230, 'avg_loss': 6.025808269149935, 'avg_acc': 50.02357165783984, 'loss': 6.185163974761963}


EP_train:0:  90%|| 6241/6926 [14:04:07&lt;3:38:55, 19.18s/it]

{'epoch': 0, 'iter': 6240, 'avg_loss': 6.025444647265329, 'avg_acc': 50.02403460983816, 'loss': 5.641790866851807}


EP_train:0:  90%|| 6251/6926 [14:07:20&lt;3:36:25, 19.24s/it]

{'epoch': 0, 'iter': 6250, 'avg_loss': 6.0252187642988595, 'avg_acc': 50.012997920332744, 'loss': 5.41579008102417}


EP_train:0:  90%|| 6261/6926 [14:10:31&lt;3:32:02, 19.13s/it]

{'epoch': 0, 'iter': 6260, 'avg_loss': 6.024968230063648, 'avg_acc': 50.017469254112754, 'loss': 5.893710136413574}


EP_train:0:  91%|| 6271/6926 [14:13:43&lt;3:29:27, 19.19s/it]

{'epoch': 0, 'iter': 6270, 'avg_loss': 6.024743533176282, 'avg_acc': 50.019434699409985, 'loss': 5.925285816192627}


EP_train:0:  91%|| 6281/6926 [14:16:54&lt;3:26:03, 19.17s/it]

{'epoch': 0, 'iter': 6280, 'avg_loss': 6.024407376986441, 'avg_acc': 50.01940375736348, 'loss': 5.84910249710083}


EP_train:0:  91%|| 6291/6926 [14:20:05&lt;3:21:53, 19.08s/it]

{'epoch': 0, 'iter': 6290, 'avg_loss': 6.024231166533381, 'avg_acc': 50.013908758543955, 'loss': 5.5846381187438965}


EP_train:0:  91%|| 6301/6926 [14:23:16&lt;3:19:10, 19.12s/it]

{'epoch': 0, 'iter': 6300, 'avg_loss': 6.023935518611369, 'avg_acc': 50.01289477860658, 'loss': 6.034008979797363}


EP_train:0:  91%|| 6311/6926 [14:26:28&lt;3:15:59, 19.12s/it]

{'epoch': 0, 'iter': 6310, 'avg_loss': 6.023718788513875, 'avg_acc': 50.00891300903185, 'loss': 6.074720859527588}


EP_train:0:  91%|| 6321/6926 [14:29:39&lt;3:12:45, 19.12s/it]

{'epoch': 0, 'iter': 6320, 'avg_loss': 6.02339181890972, 'avg_acc': 50.00593260560038, 'loss': 6.016669273376465}


EP_train:0:  91%|| 6331/6926 [14:32:50&lt;3:09:16, 19.09s/it]

{'epoch': 0, 'iter': 6330, 'avg_loss': 6.022894253532688, 'avg_acc': 50.01579529300268, 'loss': 5.54511022567749}


EP_train:0:  92%|| 6341/6926 [14:36:02&lt;3:07:13, 19.20s/it]

{'epoch': 0, 'iter': 6340, 'avg_loss': 6.022788465220438, 'avg_acc': 50.0241483993061, 'loss': 6.032009124755859}


EP_train:0:  92%|| 6351/6926 [14:39:13&lt;3:03:30, 19.15s/it]

{'epoch': 0, 'iter': 6350, 'avg_loss': 6.022524105021567, 'avg_acc': 50.022142182333496, 'loss': 5.417093276977539}


EP_train:0:  92%|| 6361/6926 [14:42:24&lt;2:59:32, 19.07s/it]

{'epoch': 0, 'iter': 6360, 'avg_loss': 6.022403193652077, 'avg_acc': 50.018668448357175, 'loss': 5.7805705070495605}


EP_train:0:  92%|| 6371/6926 [14:45:36&lt;2:57:37, 19.20s/it]

{'epoch': 0, 'iter': 6370, 'avg_loss': 6.022453367307822, 'avg_acc': 50.014715115366506, 'loss': 5.773720741271973}


EP_train:0:  92%|| 6381/6926 [14:48:47&lt;2:53:45, 19.13s/it]

{'epoch': 0, 'iter': 6380, 'avg_loss': 6.022148494529156, 'avg_acc': 50.01812020059552, 'loss': 5.828519344329834}


EP_train:0:  92%|| 6391/6926 [14:51:59&lt;2:50:43, 19.15s/it]

{'epoch': 0, 'iter': 6390, 'avg_loss': 6.021771567283037, 'avg_acc': 50.02151462994836, 'loss': 6.139357566833496}


EP_train:0:  92%|| 6401/6926 [14:55:10&lt;2:48:02, 19.20s/it]

{'epoch': 0, 'iter': 6400, 'avg_loss': 6.021559764958605, 'avg_acc': 50.02099281362287, 'loss': 6.213183403015137}


EP_train:0:  93%|| 6411/6926 [14:58:22&lt;2:44:22, 19.15s/it]

{'epoch': 0, 'iter': 6410, 'avg_loss': 6.021199776701986, 'avg_acc': 50.025347059741065, 'loss': 6.391252040863037}


EP_train:0:  93%|| 6421/6926 [15:01:33&lt;2:41:03, 19.14s/it]

{'epoch': 0, 'iter': 6420, 'avg_loss': 6.020786032166516, 'avg_acc': 50.02287416290297, 'loss': 5.490016937255859}


EP_train:0:  93%|| 6431/6926 [15:04:44&lt;2:37:48, 19.13s/it]

{'epoch': 0, 'iter': 6430, 'avg_loss': 6.020458819280051, 'avg_acc': 50.02235266677033, 'loss': 5.519053936004639}


EP_train:0:  93%|| 6441/6926 [15:07:55&lt;2:34:36, 19.13s/it]

{'epoch': 0, 'iter': 6440, 'avg_loss': 6.020114336338052, 'avg_acc': 50.01698105884179, 'loss': 5.88951301574707}


EP_train:0:  93%|| 6451/6926 [15:11:07&lt;2:31:29, 19.14s/it]

{'epoch': 0, 'iter': 6450, 'avg_loss': 6.019951528032664, 'avg_acc': 50.01259494651992, 'loss': 6.402599334716797}


EP_train:0:  93%|| 6461/6926 [15:14:18&lt;2:28:34, 19.17s/it]

{'epoch': 0, 'iter': 6460, 'avg_loss': 6.019697615318375, 'avg_acc': 50.01354279523294, 'loss': 6.159534454345703}


EP_train:0:  93%|| 6471/6926 [15:17:30&lt;2:25:04, 19.13s/it]

{'epoch': 0, 'iter': 6470, 'avg_loss': 6.019480395991326, 'avg_acc': 50.00193169525575, 'loss': 5.5013275146484375}


EP_train:0:  94%|| 6481/6926 [15:20:41&lt;2:21:50, 19.12s/it]

{'epoch': 0, 'iter': 6480, 'avg_loss': 6.019170306270054, 'avg_acc': 50.002410893380656, 'loss': 5.37006139755249}


EP_train:0:  94%|| 6491/6926 [15:23:53&lt;2:19:25, 19.23s/it]

{'epoch': 0, 'iter': 6490, 'avg_loss': 6.018963563425701, 'avg_acc': 50.001925743336926, 'loss': 6.374922275543213}


EP_train:0:  94%|| 6501/6926 [15:27:06&lt;2:16:49, 19.32s/it]

{'epoch': 0, 'iter': 6500, 'avg_loss': 6.018632433667878, 'avg_acc': 50.002403476388245, 'loss': 5.702291011810303}


EP_train:0:  94%|| 6511/6926 [15:30:19&lt;2:13:16, 19.27s/it]

{'epoch': 0, 'iter': 6510, 'avg_loss': 6.018304113784413, 'avg_acc': 50.00047995699586, 'loss': 5.912711143493652}


EP_train:0:  94%|| 6521/6926 [15:33:31&lt;2:09:32, 19.19s/it]

{'epoch': 0, 'iter': 6520, 'avg_loss': 6.017902231677107, 'avg_acc': 50.0129389664162, 'loss': 6.289568901062012}


EP_train:0:  94%|| 6531/6926 [15:36:44&lt;2:07:07, 19.31s/it]

{'epoch': 0, 'iter': 6530, 'avg_loss': 6.0176445086760575, 'avg_acc': 50.01291915480019, 'loss': 5.743828296661377}


EP_train:0:  94%|| 6541/6926 [15:39:56&lt;2:03:06, 19.19s/it]

{'epoch': 0, 'iter': 6540, 'avg_loss': 6.017163850174568, 'avg_acc': 50.008121846812415, 'loss': 5.398609161376953}


EP_train:0:  95%|| 6551/6926 [15:43:14&lt;2:06:39, 20.26s/it]

{'epoch': 0, 'iter': 6550, 'avg_loss': 6.017079152218023, 'avg_acc': 50.004293237673636, 'loss': 5.756030082702637}


EP_train:0:  95%|| 6561/6926 [15:48:33&lt;3:15:52, 32.20s/it]

{'epoch': 0, 'iter': 6560, 'avg_loss': 6.016903623613783, 'avg_acc': 50.002857796067666, 'loss': 6.09950590133667}


EP_train:0:  95%|| 6571/6926 [15:53:55&lt;3:12:46, 32.58s/it]

{'epoch': 0, 'iter': 6570, 'avg_loss': 6.01651362657293, 'avg_acc': 50.00095114898798, 'loss': 5.890357494354248}


EP_train:0:  95%|| 6581/6926 [15:59:16&lt;3:05:18, 32.23s/it]

{'epoch': 0, 'iter': 6580, 'avg_loss': 6.016133970736806, 'avg_acc': 50.00047485184622, 'loss': 5.606696128845215}


EP_train:0:  95%|| 6591/6926 [16:04:38&lt;2:58:55, 32.05s/it]

{'epoch': 0, 'iter': 6590, 'avg_loss': 6.015973757872757, 'avg_acc': 50.00379305113033, 'loss': 6.242420196533203}


EP_train:0:  95%|| 6601/6926 [16:10:02&lt;2:56:25, 32.57s/it]

{'epoch': 0, 'iter': 6600, 'avg_loss': 6.01564334201336, 'avg_acc': 50.00047341311923, 'loss': 5.982399940490723}


EP_train:0:  95%|| 6611/6926 [16:15:23&lt;2:47:34, 31.92s/it]

{'epoch': 0, 'iter': 6610, 'avg_loss': 6.015625978053527, 'avg_acc': 50.000945394040244, 'loss': 6.09565544128418}


EP_train:0:  96%|| 6621/6926 [16:20:51&lt;2:46:23, 32.73s/it]

{'epoch': 0, 'iter': 6620, 'avg_loss': 6.01537481828536, 'avg_acc': 49.99386421990636, 'loss': 5.418523788452148}


EP_train:0:  96%|| 6631/6926 [16:24:03&lt;1:36:19, 19.59s/it]

{'epoch': 0, 'iter': 6630, 'avg_loss': 6.015127572407821, 'avg_acc': 49.99387347308099, 'loss': 5.733451843261719}


EP_train:0:  96%|| 6641/6926 [16:27:15&lt;1:31:34, 19.28s/it]

{'epoch': 0, 'iter': 6640, 'avg_loss': 6.014838525355356, 'avg_acc': 49.993882698388795, 'loss': 5.605808734893799}


EP_train:0:  96%|| 6651/6926 [16:30:28&lt;1:28:27, 19.30s/it]

{'epoch': 0, 'iter': 6650, 'avg_loss': 6.014767191173833, 'avg_acc': 49.99718087505639, 'loss': 5.6949782371521}


EP_train:0:  96%|| 6661/6926 [16:33:41&lt;1:24:59, 19.24s/it]

{'epoch': 0, 'iter': 6660, 'avg_loss': 6.014458387504019, 'avg_acc': 49.99014787569434, 'loss': 6.062519550323486}


EP_train:0:  96%|| 6671/6926 [16:36:53&lt;1:21:47, 19.25s/it]

{'epoch': 0, 'iter': 6670, 'avg_loss': 6.014176159636976, 'avg_acc': 49.98688352570829, 'loss': 5.965818405151367}


EP_train:0:  96%|| 6681/6926 [16:40:06&lt;1:18:49, 19.30s/it]

{'epoch': 0, 'iter': 6680, 'avg_loss': 6.014068628852729, 'avg_acc': 49.9864354138602, 'loss': 6.070623397827148}


EP_train:0:  97%|| 6691/6926 [16:43:18&lt;1:15:06, 19.18s/it]

{'epoch': 0, 'iter': 6690, 'avg_loss': 6.013976595252463, 'avg_acc': 49.982719324465705, 'loss': 5.54081916809082}


EP_train:0:  97%|| 6701/6926 [16:46:30&lt;1:11:46, 19.14s/it]

{'epoch': 0, 'iter': 6700, 'avg_loss': 6.01353130815919, 'avg_acc': 49.98461050589464, 'loss': 5.863101005554199}


EP_train:0:  97%|| 6711/6926 [16:49:42&lt;1:08:45, 19.19s/it]

{'epoch': 0, 'iter': 6710, 'avg_loss': 6.0132572604369665, 'avg_acc': 49.9878930114737, 'loss': 5.598949432373047}


EP_train:0:  97%|| 6721/6926 [16:52:53&lt;1:05:14, 19.09s/it]

{'epoch': 0, 'iter': 6720, 'avg_loss': 6.013212072017416, 'avg_acc': 49.98279645886029, 'loss': 5.909557342529297}


EP_train:0:  97%|| 6731/6926 [16:56:05&lt;1:02:20, 19.18s/it]

{'epoch': 0, 'iter': 6730, 'avg_loss': 6.012646399959734, 'avg_acc': 49.98096493834497, 'loss': 5.427638053894043}


EP_train:0:  97%|| 6741/6926 [16:59:17&lt;58:58, 19.13s/it]  

{'epoch': 0, 'iter': 6740, 'avg_loss': 6.012475981625335, 'avg_acc': 49.97821168966029, 'loss': 5.700652122497559}


EP_train:0:  97%|| 6751/6926 [17:02:28&lt;55:46, 19.12s/it]

{'epoch': 0, 'iter': 6750, 'avg_loss': 6.012365468677424, 'avg_acc': 49.97963264701526, 'loss': 6.176610946655273}


EP_train:0:  98%|| 6761/6926 [17:05:40&lt;52:38, 19.14s/it]

{'epoch': 0, 'iter': 6760, 'avg_loss': 6.0121523709431886, 'avg_acc': 49.97550288418873, 'loss': 5.579730033874512}


EP_train:0:  98%|| 6771/6926 [17:08:52&lt;49:36, 19.20s/it]

{'epoch': 0, 'iter': 6770, 'avg_loss': 6.011860047392366, 'avg_acc': 49.983846551469505, 'loss': 5.901065826416016}


EP_train:0:  98%|| 6781/6926 [17:12:04&lt;46:35, 19.28s/it]

{'epoch': 0, 'iter': 6780, 'avg_loss': 6.011770728133348, 'avg_acc': 49.98018360123876, 'loss': 5.47562313079834}


EP_train:0:  98%|| 6791/6926 [17:15:16&lt;43:03, 19.14s/it]

{'epoch': 0, 'iter': 6790, 'avg_loss': 6.011512113941065, 'avg_acc': 49.97883227801502, 'loss': 6.059812545776367}


EP_train:0:  98%|| 6801/6926 [17:18:29&lt;40:03, 19.23s/it]

{'epoch': 0, 'iter': 6800, 'avg_loss': 6.011380450407594, 'avg_acc': 49.982998823702395, 'loss': 6.518869876861572}


EP_train:0:  98%|| 6811/6926 [17:21:41&lt;36:53, 19.25s/it]

{'epoch': 0, 'iter': 6810, 'avg_loss': 6.011360747438576, 'avg_acc': 49.98210615181324, 'loss': 6.399105548858643}


EP_train:0:  98%|| 6821/6926 [17:24:53&lt;33:36, 19.21s/it]

{'epoch': 0, 'iter': 6820, 'avg_loss': 6.01107167086107, 'avg_acc': 49.98946268875532, 'loss': 5.806404113769531}


EP_train:0:  99%|| 6831/6926 [17:28:05&lt;30:33, 19.30s/it]

{'epoch': 0, 'iter': 6830, 'avg_loss': 6.0108459484104255, 'avg_acc': 49.99039306104523, 'loss': 5.857755661010742}


EP_train:0:  99%|| 6841/6926 [17:31:17&lt;27:16, 19.25s/it]

{'epoch': 0, 'iter': 6840, 'avg_loss': 6.010873877362643, 'avg_acc': 49.98172781757053, 'loss': 5.758935928344727}


EP_train:0:  99%|| 6851/6926 [17:34:29&lt;23:59, 19.19s/it]

{'epoch': 0, 'iter': 6850, 'avg_loss': 6.010545881068405, 'avg_acc': 49.986772004086994, 'loss': 5.64037561416626}


EP_train:0:  99%|| 6861/6926 [17:37:42&lt;20:47, 19.20s/it]

{'epoch': 0, 'iter': 6860, 'avg_loss': 6.010220855200817, 'avg_acc': 49.983147500364375, 'loss': 5.707495212554932}


EP_train:0:  99%|| 6871/6926 [17:40:55&lt;17:38, 19.25s/it]

{'epoch': 0, 'iter': 6870, 'avg_loss': 6.010123378757548, 'avg_acc': 49.98317202736137, 'loss': 5.717169284820557}


EP_train:0:  99%|| 6881/6926 [17:44:08&lt;14:31, 19.37s/it]

{'epoch': 0, 'iter': 6880, 'avg_loss': 6.009998554997, 'avg_acc': 49.98728382502543, 'loss': 5.7754130363464355}


EP_train:0:  99%|| 6891/6926 [17:47:20&lt;11:12, 19.21s/it]

{'epoch': 0, 'iter': 6890, 'avg_loss': 6.009924337179217, 'avg_acc': 49.99093019881004, 'loss': 6.444478988647461}


EP_train:0: 100%|| 6901/6926 [17:50:32&lt;07:58, 19.14s/it]

{'epoch': 0, 'iter': 6900, 'avg_loss': 6.009942910305367, 'avg_acc': 49.985056513548756, 'loss': 6.345350742340088}


EP_train:0: 100%|| 6911/6926 [17:53:44&lt;04:49, 19.29s/it]

{'epoch': 0, 'iter': 6910, 'avg_loss': 6.009896017090316, 'avg_acc': 49.982817247865725, 'loss': 5.79774808883667}


EP_train:0: 100%|| 6921/6926 [17:56:57&lt;01:36, 19.38s/it]

{'epoch': 0, 'iter': 6920, 'avg_loss': 6.009602792241329, 'avg_acc': 49.977875307036555, 'loss': 5.463503837585449}


EP_train:0: 100%|| 6926/6926 [17:58:24&lt;00:00,  9.34s/it]


EP0, train:             avg_loss=6.009420036340153,             total_acc=49.97337737347484


EP_train:1:   0%|| 1/6926 [00:19&lt;36:46:00, 19.11s/it]

{'epoch': 1, 'iter': 0, 'avg_loss': 5.7898664474487305, 'avg_acc': 50.0, 'loss': 5.7898664474487305}


EP_train:1:   0%|| 11/6926 [03:30&lt;36:52:25, 19.20s/it]

{'epoch': 1, 'iter': 10, 'avg_loss': 5.765929655595259, 'avg_acc': 48.57954545454545, 'loss': 5.726385116577148}


EP_train:1:   0%|| 21/6926 [06:43&lt;36:49:29, 19.20s/it]

{'epoch': 1, 'iter': 20, 'avg_loss': 5.850452173323858, 'avg_acc': 49.107142857142854, 'loss': 6.110977649688721}


EP_train:1:   0%|| 31/6926 [09:55&lt;36:45:52, 19.20s/it]

{'epoch': 1, 'iter': 30, 'avg_loss': 5.828610743245771, 'avg_acc': 49.79838709677419, 'loss': 5.774191379547119}


EP_train:1:   1%|| 41/6926 [13:08&lt;36:47:37, 19.24s/it]

{'epoch': 1, 'iter': 40, 'avg_loss': 5.866406952462545, 'avg_acc': 49.390243902439025, 'loss': 6.16168737411499}


EP_train:1:   1%|| 51/6926 [16:20&lt;36:43:34, 19.23s/it]

{'epoch': 1, 'iter': 50, 'avg_loss': 5.8676528650171615, 'avg_acc': 50.18382352941176, 'loss': 6.630732536315918}


EP_train:1:   1%|| 61/6926 [19:33&lt;36:41:51, 19.24s/it]

{'epoch': 1, 'iter': 60, 'avg_loss': 5.888651972911397, 'avg_acc': 49.795081967213115, 'loss': 6.124413013458252}


EP_train:1:   1%|| 71/6926 [22:45&lt;36:27:43, 19.15s/it]

{'epoch': 1, 'iter': 70, 'avg_loss': 5.882588467127841, 'avg_acc': 49.603873239436616, 'loss': 6.333876132965088}


EP_train:1:   1%|| 81/6926 [25:57&lt;36:28:39, 19.18s/it]

{'epoch': 1, 'iter': 80, 'avg_loss': 5.870515434830277, 'avg_acc': 49.57561728395062, 'loss': 5.677712440490723}


EP_train:1:   1%|| 91/6926 [29:09&lt;36:19:29, 19.13s/it]

{'epoch': 1, 'iter': 90, 'avg_loss': 5.8840242218185255, 'avg_acc': 49.38186813186813, 'loss': 6.505983829498291}


EP_train:1:   1%|| 101/6926 [32:21&lt;36:33:20, 19.28s/it]

{'epoch': 1, 'iter': 100, 'avg_loss': 5.885297610027956, 'avg_acc': 49.597772277227726, 'loss': 5.711908340454102}


EP_train:1:   2%|| 111/6926 [35:34&lt;36:20:00, 19.19s/it]

{'epoch': 1, 'iter': 110, 'avg_loss': 5.881839593251546, 'avg_acc': 49.971846846846844, 'loss': 6.196578025817871}


EP_train:1:   2%|| 121/6926 [38:46&lt;36:19:01, 19.21s/it]

{'epoch': 1, 'iter': 120, 'avg_loss': 5.888786520839723, 'avg_acc': 50.15495867768595, 'loss': 6.299873352050781}


EP_train:1:   2%|| 131/6926 [41:59&lt;36:29:14, 19.33s/it]

{'epoch': 1, 'iter': 130, 'avg_loss': 5.88999764245885, 'avg_acc': 49.833015267175576, 'loss': 5.836378574371338}


EP_train:1:   2%|| 141/6926 [45:11&lt;36:15:45, 19.24s/it]

{'epoch': 1, 'iter': 140, 'avg_loss': 5.884459282489533, 'avg_acc': 49.75620567375886, 'loss': 5.787635326385498}


EP_train:1:   2%|| 151/6926 [48:25&lt;37:37:42, 19.99s/it]

{'epoch': 1, 'iter': 150, 'avg_loss': 5.880914773372625, 'avg_acc': 49.71026490066225, 'loss': 6.034032821655273}


EP_train:1:   2%|| 161/6926 [51:43&lt;36:35:31, 19.47s/it]

{'epoch': 1, 'iter': 160, 'avg_loss': 5.874822672849857, 'avg_acc': 49.767080745341616, 'loss': 5.685953140258789}


EP_train:1:   2%|| 171/6926 [54:55&lt;36:01:50, 19.20s/it]

{'epoch': 1, 'iter': 170, 'avg_loss': 5.86680287366722, 'avg_acc': 49.56140350877193, 'loss': 5.6062517166137695}


EP_train:1:   3%|| 181/6926 [58:06&lt;35:48:39, 19.11s/it]

{'epoch': 1, 'iter': 180, 'avg_loss': 5.8650890134316125, 'avg_acc': 49.568370165745854, 'loss': 5.928098201751709}


EP_train:1:   3%|| 191/6926 [1:01:18&lt;35:49:32, 19.15s/it]

{'epoch': 1, 'iter': 190, 'avg_loss': 5.858440072124541, 'avg_acc': 49.721858638743456, 'loss': 5.673971176147461}


EP_train:1:   3%|| 201/6926 [1:04:30&lt;35:50:35, 19.19s/it]

{'epoch': 1, 'iter': 200, 'avg_loss': 5.862566321643431, 'avg_acc': 49.93781094527363, 'loss': 5.701019763946533}


EP_train:1:   3%|| 211/6926 [1:07:42&lt;35:44:34, 19.16s/it]

{'epoch': 1, 'iter': 210, 'avg_loss': 5.860975496011887, 'avg_acc': 50.133293838862556, 'loss': 5.544591903686523}


EP_train:1:   3%|| 221/6926 [1:10:53&lt;35:38:59, 19.14s/it]

{'epoch': 1, 'iter': 220, 'avg_loss': 5.857743077688088, 'avg_acc': 50.04242081447964, 'loss': 5.729083061218262}


EP_train:1:   3%|| 231/6926 [1:14:05&lt;35:36:27, 19.15s/it]

{'epoch': 1, 'iter': 230, 'avg_loss': 5.858985324958702, 'avg_acc': 49.8241341991342, 'loss': 5.8883867263793945}


EP_train:1:   3%|| 241/6926 [1:17:17&lt;35:31:52, 19.13s/it]

{'epoch': 1, 'iter': 240, 'avg_loss': 5.85954476985694, 'avg_acc': 49.71473029045643, 'loss': 5.887384414672852}


EP_train:1:   4%|| 251/6926 [1:20:28&lt;35:27:21, 19.12s/it]

{'epoch': 1, 'iter': 250, 'avg_loss': 5.858979394236409, 'avg_acc': 49.813247011952186, 'loss': 5.831138610839844}


EP_train:1:   4%|| 261/6926 [1:23:39&lt;35:22:47, 19.11s/it]

{'epoch': 1, 'iter': 260, 'avg_loss': 5.859414310747637, 'avg_acc': 49.9161877394636, 'loss': 5.701999187469482}


EP_train:1:   4%|| 271/6926 [1:26:50&lt;35:19:55, 19.11s/it]

{'epoch': 1, 'iter': 270, 'avg_loss': 5.854931660683833, 'avg_acc': 50.04612546125461, 'loss': 6.198373794555664}


EP_train:1:   4%|| 281/6926 [1:30:02&lt;35:16:02, 19.11s/it]

{'epoch': 1, 'iter': 280, 'avg_loss': 5.85461603449757, 'avg_acc': 50.055604982206404, 'loss': 5.955772876739502}


EP_train:1:   4%|| 291/6926 [1:33:13&lt;35:13:11, 19.11s/it]

{'epoch': 1, 'iter': 290, 'avg_loss': 5.856383528496392, 'avg_acc': 50.2147766323024, 'loss': 6.128197193145752}


EP_train:1:   4%|| 301/6926 [1:36:24&lt;35:09:50, 19.11s/it]

{'epoch': 1, 'iter': 300, 'avg_loss': 5.856983832742685, 'avg_acc': 50.36337209302325, 'loss': 5.785074710845947}


EP_train:1:   4%|| 311/6926 [1:40:00&lt;36:27:03, 19.84s/it]

{'epoch': 1, 'iter': 310, 'avg_loss': 5.856134589462035, 'avg_acc': 50.34163987138264, 'loss': 6.169585704803467}


EP_train:1:   5%|| 321/6926 [1:43:12&lt;35:13:36, 19.20s/it]

{'epoch': 1, 'iter': 320, 'avg_loss': 5.855534742183032, 'avg_acc': 50.28232087227414, 'loss': 5.786722660064697}


EP_train:1:   5%|| 331/6926 [1:46:24&lt;35:08:30, 19.18s/it]

{'epoch': 1, 'iter': 330, 'avg_loss': 5.855514389510601, 'avg_acc': 50.16993957703928, 'loss': 5.721573352813721}


EP_train:1:   5%|| 341/6926 [1:49:36&lt;35:01:51, 19.15s/it]

{'epoch': 1, 'iter': 340, 'avg_loss': 5.854255662286037, 'avg_acc': 50.1741202346041, 'loss': 6.028651714324951}


EP_train:1:   5%|| 351/6926 [1:52:48&lt;35:03:42, 19.20s/it]

{'epoch': 1, 'iter': 350, 'avg_loss': 5.858589369347293, 'avg_acc': 50.32941595441596, 'loss': 5.835811138153076}


EP_train:1:   5%|| 361/6926 [1:56:01&lt;35:11:13, 19.30s/it]

{'epoch': 1, 'iter': 360, 'avg_loss': 5.859188112855948, 'avg_acc': 50.3722299168975, 'loss': 5.411815166473389}


EP_train:1:   5%|| 371/6926 [1:59:13&lt;34:54:57, 19.18s/it]

{'epoch': 1, 'iter': 370, 'avg_loss': 5.860896775022028, 'avg_acc': 50.19373315363881, 'loss': 6.040600776672363}


EP_train:1:   6%|| 381/6926 [2:02:25&lt;34:55:23, 19.21s/it]

{'epoch': 1, 'iter': 380, 'avg_loss': 5.861102593539581, 'avg_acc': 50.22145669291339, 'loss': 5.881434440612793}


EP_train:1:   6%|| 391/6926 [2:05:36&lt;34:45:56, 19.15s/it]

{'epoch': 1, 'iter': 390, 'avg_loss': 5.863249294593206, 'avg_acc': 50.1358695652174, 'loss': 5.768378257751465}


EP_train:1:   6%|| 401/6926 [2:08:48&lt;34:51:26, 19.23s/it]

{'epoch': 1, 'iter': 400, 'avg_loss': 5.861934682080276, 'avg_acc': 50.093516209476306, 'loss': 6.008617401123047}


EP_train:1:   6%|| 411/6926 [2:12:01&lt;34:48:24, 19.23s/it]

{'epoch': 1, 'iter': 410, 'avg_loss': 5.8630056404429345, 'avg_acc': 50.04562043795621, 'loss': 5.907751083374023}


EP_train:1:   6%|| 421/6926 [2:15:14&lt;34:50:33, 19.28s/it]

{'epoch': 1, 'iter': 420, 'avg_loss': 5.867002961754515, 'avg_acc': 50.0, 'loss': 5.6928911209106445}


EP_train:1:   6%|| 431/6926 [2:18:27&lt;34:44:33, 19.26s/it]

{'epoch': 1, 'iter': 430, 'avg_loss': 5.86686744048258, 'avg_acc': 50.050754060324834, 'loss': 5.937226295471191}


EP_train:1:   6%|| 441/6926 [2:21:39&lt;34:33:30, 19.18s/it]

{'epoch': 1, 'iter': 440, 'avg_loss': 5.867215950202509, 'avg_acc': 50.05668934240363, 'loss': 5.970946311950684}


EP_train:1:   7%|| 451/6926 [2:24:50&lt;34:21:58, 19.11s/it]

{'epoch': 1, 'iter': 450, 'avg_loss': 5.867052065559607, 'avg_acc': 50.0069290465632, 'loss': 6.138850688934326}


EP_train:1:   7%|| 461/6926 [2:28:02&lt;34:31:22, 19.22s/it]

{'epoch': 1, 'iter': 460, 'avg_loss': 5.865982198404904, 'avg_acc': 49.97966377440347, 'loss': 5.222504138946533}


EP_train:1:   7%|| 471/6926 [2:31:15&lt;34:41:26, 19.35s/it]

{'epoch': 1, 'iter': 470, 'avg_loss': 5.867836634318034, 'avg_acc': 49.90047770700637, 'loss': 5.999167442321777}


EP_train:1:   7%|| 481/6926 [2:34:27&lt;34:24:09, 19.22s/it]

{'epoch': 1, 'iter': 480, 'avg_loss': 5.866187658726302, 'avg_acc': 49.95452182952183, 'loss': 5.776668071746826}


EP_train:1:   7%|| 491/6926 [2:37:40&lt;34:26:38, 19.27s/it]

{'epoch': 1, 'iter': 490, 'avg_loss': 5.867664511966122, 'avg_acc': 49.980906313645626, 'loss': 5.901947498321533}


EP_train:1:   7%|| 501/6926 [2:40:52&lt;34:19:01, 19.23s/it]

{'epoch': 1, 'iter': 500, 'avg_loss': 5.86596357893801, 'avg_acc': 49.962574850299404, 'loss': 5.214600086212158}


EP_train:1:   7%|| 511/6926 [2:44:04&lt;34:05:07, 19.13s/it]

{'epoch': 1, 'iter': 510, 'avg_loss': 5.864071903863298, 'avg_acc': 49.97553816046967, 'loss': 5.491891860961914}


EP_train:1:   8%|| 521/6926 [2:47:16&lt;34:13:17, 19.23s/it]

{'epoch': 1, 'iter': 520, 'avg_loss': 5.865162833867283, 'avg_acc': 50.03598848368522, 'loss': 6.381423473358154}


EP_train:1:   8%|| 531/6926 [2:50:28&lt;34:06:15, 19.20s/it]

{'epoch': 1, 'iter': 530, 'avg_loss': 5.864204099622824, 'avg_acc': 50.02354048964218, 'loss': 5.515666961669922}


EP_train:1:   8%|| 541/6926 [2:53:40&lt;33:57:02, 19.14s/it]

{'epoch': 1, 'iter': 540, 'avg_loss': 5.861967081503595, 'avg_acc': 49.98844731977819, 'loss': 5.428747177124023}


EP_train:1:   8%|| 551/6926 [2:56:52&lt;34:08:43, 19.28s/it]

{'epoch': 1, 'iter': 550, 'avg_loss': 5.862547218475065, 'avg_acc': 49.96029945553539, 'loss': 6.113502502441406}


EP_train:1:   8%|| 561/6926 [3:00:05&lt;33:59:46, 19.23s/it]

{'epoch': 1, 'iter': 560, 'avg_loss': 5.861968838594814, 'avg_acc': 49.94986631016043, 'loss': 5.945765972137451}


EP_train:1:   8%|| 571/6926 [3:03:18&lt;34:13:21, 19.39s/it]

{'epoch': 1, 'iter': 570, 'avg_loss': 5.860212508099718, 'avg_acc': 49.91243432574431, 'loss': 5.618706226348877}


EP_train:1:   8%|| 581/6926 [3:06:31&lt;34:11:43, 19.40s/it]

{'epoch': 1, 'iter': 580, 'avg_loss': 5.860705601368837, 'avg_acc': 49.87091222030981, 'loss': 5.72037935256958}


EP_train:1:   9%|| 591/6926 [3:09:42&lt;33:43:02, 19.16s/it]

{'epoch': 1, 'iter': 590, 'avg_loss': 5.861424665564006, 'avg_acc': 49.84137055837564, 'loss': 6.172145366668701}


EP_train:1:   9%|| 601/6926 [3:12:54&lt;33:43:10, 19.19s/it]

{'epoch': 1, 'iter': 600, 'avg_loss': 5.8617067448113005, 'avg_acc': 49.802412645590685, 'loss': 5.886046886444092}


EP_train:1:   9%|| 611/6926 [3:16:05&lt;33:27:18, 19.07s/it]

{'epoch': 1, 'iter': 610, 'avg_loss': 5.859487274469603, 'avg_acc': 49.86190671031097, 'loss': 5.65408182144165}


EP_train:1:   9%|| 621/6926 [3:19:18&lt;33:41:21, 19.24s/it]

{'epoch': 1, 'iter': 620, 'avg_loss': 5.857120867128725, 'avg_acc': 49.81884057971014, 'loss': 5.547512054443359}


EP_train:1:   9%|| 631/6926 [3:22:30&lt;33:32:23, 19.18s/it]

{'epoch': 1, 'iter': 630, 'avg_loss': 5.8560241882094495, 'avg_acc': 49.74247226624406, 'loss': 5.398869037628174}


EP_train:1:   9%|| 641/6926 [3:25:42&lt;33:37:38, 19.26s/it]

{'epoch': 1, 'iter': 640, 'avg_loss': 5.856239571772202, 'avg_acc': 49.765990639625585, 'loss': 5.919886112213135}


EP_train:1:   9%|| 651/6926 [3:28:54&lt;33:31:15, 19.23s/it]

{'epoch': 1, 'iter': 650, 'avg_loss': 5.854985670743083, 'avg_acc': 49.78878648233487, 'loss': 5.877474784851074}


EP_train:1:  10%|| 661/6926 [3:32:06&lt;33:25:43, 19.21s/it]

{'epoch': 1, 'iter': 660, 'avg_loss': 5.854530731235799, 'avg_acc': 49.787254160363084, 'loss': 5.628725051879883}


EP_train:1:  10%|| 671/6926 [3:35:20&lt;33:41:36, 19.39s/it]

{'epoch': 1, 'iter': 670, 'avg_loss': 5.853959171676067, 'avg_acc': 49.72056631892697, 'loss': 5.894036293029785}


EP_train:1:  10%|| 681/6926 [3:38:34&lt;33:38:06, 19.39s/it]

{'epoch': 1, 'iter': 680, 'avg_loss': 5.852304049000341, 'avg_acc': 49.70172540381792, 'loss': 5.862987041473389}


EP_train:1:  10%|| 691/6926 [3:41:47&lt;33:26:31, 19.31s/it]

{'epoch': 1, 'iter': 690, 'avg_loss': 5.85155159623164, 'avg_acc': 49.696997105643995, 'loss': 5.2892937660217285}


EP_train:1:  10%|| 701/6926 [3:45:01&lt;33:45:03, 19.52s/it]

{'epoch': 1, 'iter': 700, 'avg_loss': 5.851237080066588, 'avg_acc': 49.67011412268189, 'loss': 6.079766750335693}


EP_train:1:  10%|| 711/6926 [3:48:13&lt;33:09:23, 19.21s/it]

{'epoch': 1, 'iter': 710, 'avg_loss': 5.850454349222733, 'avg_acc': 49.67475386779184, 'loss': 5.564901351928711}


EP_train:1:  10%|| 721/6926 [3:51:26&lt;33:13:57, 19.28s/it]

{'epoch': 1, 'iter': 720, 'avg_loss': 5.852251948992852, 'avg_acc': 49.71393897364771, 'loss': 5.800187110900879}


EP_train:1:  11%|| 731/6926 [3:54:38&lt;32:59:39, 19.17s/it]

{'epoch': 1, 'iter': 730, 'avg_loss': 5.850966430069158, 'avg_acc': 49.64517783857729, 'loss': 5.609173774719238}


EP_train:1:  11%|| 741/6926 [3:57:50&lt;32:54:25, 19.15s/it]

{'epoch': 1, 'iter': 740, 'avg_loss': 5.850172593043401, 'avg_acc': 49.61201079622132, 'loss': 6.199341773986816}


EP_train:1:  11%|| 751/6926 [4:01:02&lt;32:54:09, 19.18s/it]

{'epoch': 1, 'iter': 750, 'avg_loss': 5.850118440889646, 'avg_acc': 49.604693741677764, 'loss': 5.561918258666992}


EP_train:1:  11%|| 761/6926 [4:04:14&lt;32:55:36, 19.23s/it]

{'epoch': 1, 'iter': 760, 'avg_loss': 5.848167900656902, 'avg_acc': 49.5811432325887, 'loss': 5.6837334632873535}


EP_train:1:  11%|| 771/6926 [4:07:26&lt;32:47:00, 19.17s/it]

{'epoch': 1, 'iter': 770, 'avg_loss': 5.847578158174508, 'avg_acc': 49.54199092088197, 'loss': 5.642725944519043}


EP_train:1:  11%|| 781/6926 [4:10:39&lt;33:14:22, 19.47s/it]

{'epoch': 1, 'iter': 780, 'avg_loss': 5.848220976610953, 'avg_acc': 49.51984635083227, 'loss': 5.483386039733887}


EP_train:1:  11%|| 791/6926 [4:13:52&lt;33:04:24, 19.41s/it]

{'epoch': 1, 'iter': 790, 'avg_loss': 5.848804213455142, 'avg_acc': 49.48245891276864, 'loss': 5.911666393280029}


EP_train:1:  12%|| 801/6926 [4:17:04&lt;32:46:01, 19.26s/it]

{'epoch': 1, 'iter': 800, 'avg_loss': 5.849996216734697, 'avg_acc': 49.51622971285893, 'loss': 5.937110424041748}


EP_train:1:  12%|| 811/6926 [4:20:17&lt;32:40:29, 19.24s/it]

{'epoch': 1, 'iter': 810, 'avg_loss': 5.850373899598598, 'avg_acc': 49.533754623921084, 'loss': 5.817855358123779}


EP_train:1:  12%|| 821/6926 [4:23:28&lt;32:27:11, 19.14s/it]

{'epoch': 1, 'iter': 820, 'avg_loss': 5.85045076839526, 'avg_acc': 49.57369062119367, 'loss': 6.1385698318481445}


EP_train:1:  12%|| 831/6926 [4:26:40&lt;32:26:16, 19.16s/it]

{'epoch': 1, 'iter': 830, 'avg_loss': 5.850518212278254, 'avg_acc': 49.575060168471715, 'loss': 5.991103649139404}


EP_train:1:  12%|| 841/6926 [4:29:51&lt;32:25:23, 19.18s/it]

{'epoch': 1, 'iter': 840, 'avg_loss': 5.849334524587842, 'avg_acc': 49.60240784780024, 'loss': 5.678135871887207}


EP_train:1:  12%|| 851/6926 [4:33:03&lt;32:18:04, 19.14s/it]

{'epoch': 1, 'iter': 850, 'avg_loss': 5.850284370216164, 'avg_acc': 49.61075205640423, 'loss': 6.211353302001953}


EP_train:1:  12%|| 861/6926 [4:36:15&lt;32:28:07, 19.27s/it]

{'epoch': 1, 'iter': 860, 'avg_loss': 5.849237011700142, 'avg_acc': 49.60075493612079, 'loss': 5.670510768890381}


EP_train:1:  13%|| 871/6926 [4:39:27&lt;32:17:37, 19.20s/it]

{'epoch': 1, 'iter': 870, 'avg_loss': 5.849724954086111, 'avg_acc': 49.60533869115958, 'loss': 5.823276519775391}


EP_train:1:  13%|| 881/6926 [4:42:40&lt;32:22:11, 19.28s/it]

{'epoch': 1, 'iter': 880, 'avg_loss': 5.848760309338434, 'avg_acc': 49.5849886492622, 'loss': 5.7896904945373535}


EP_train:1:  13%|| 891/6926 [4:45:53&lt;32:20:24, 19.29s/it]

{'epoch': 1, 'iter': 890, 'avg_loss': 5.848237068698596, 'avg_acc': 49.56509539842873, 'loss': 5.874814510345459}


EP_train:1:  13%|| 901/6926 [4:49:05&lt;32:04:59, 19.17s/it]

{'epoch': 1, 'iter': 900, 'avg_loss': 5.847013555541552, 'avg_acc': 49.55951720310765, 'loss': 5.768845558166504}


EP_train:1:  13%|| 911/6926 [4:52:17&lt;32:02:40, 19.18s/it]

{'epoch': 1, 'iter': 910, 'avg_loss': 5.846529427265624, 'avg_acc': 49.58493413830955, 'loss': 5.537152290344238}


EP_train:1:  13%|| 921/6926 [4:55:28&lt;31:56:22, 19.15s/it]

{'epoch': 1, 'iter': 920, 'avg_loss': 5.845628834184943, 'avg_acc': 49.582654723127035, 'loss': 5.630972385406494}


EP_train:1:  13%|| 931/6926 [4:58:40&lt;31:58:08, 19.20s/it]

{'epoch': 1, 'iter': 930, 'avg_loss': 5.845260304103732, 'avg_acc': 49.57706766917293, 'loss': 5.698583126068115}


EP_train:1:  14%|| 941/6926 [5:01:52&lt;31:54:49, 19.20s/it]

{'epoch': 1, 'iter': 940, 'avg_loss': 5.846199887465215, 'avg_acc': 49.58488310308183, 'loss': 5.645341396331787}


EP_train:1:  14%|| 951/6926 [5:05:05&lt;31:50:53, 19.19s/it]

{'epoch': 1, 'iter': 950, 'avg_loss': 5.845864964333744, 'avg_acc': 49.66811251314406, 'loss': 5.785149574279785}


EP_train:1:  14%|| 961/6926 [5:08:17&lt;31:49:16, 19.20s/it]

{'epoch': 1, 'iter': 960, 'avg_loss': 5.844765096499694, 'avg_acc': 49.69107700312175, 'loss': 5.350743293762207}


EP_train:1:  14%|| 971/6926 [5:11:30&lt;31:49:19, 19.24s/it]

{'epoch': 1, 'iter': 970, 'avg_loss': 5.844221463777992, 'avg_acc': 49.70391349124614, 'loss': 6.132320404052734}


EP_train:1:  14%|| 981/6926 [5:14:42&lt;31:50:05, 19.28s/it]

{'epoch': 1, 'iter': 980, 'avg_loss': 5.84315927799081, 'avg_acc': 49.691004077471966, 'loss': 5.966439723968506}


EP_train:1:  14%|| 991/6926 [5:17:54&lt;31:34:07, 19.15s/it]

{'epoch': 1, 'iter': 990, 'avg_loss': 5.8421003638074085, 'avg_acc': 49.70358224016145, 'loss': 5.977272033691406}


EP_train:1:  14%|| 1001/6926 [5:21:06&lt;31:38:48, 19.23s/it]

{'epoch': 1, 'iter': 1000, 'avg_loss': 5.842337221532435, 'avg_acc': 49.72215284715284, 'loss': 5.648003101348877}


EP_train:1:  15%|| 1011/6926 [5:24:19&lt;31:33:44, 19.21s/it]

{'epoch': 1, 'iter': 1010, 'avg_loss': 5.842143786531292, 'avg_acc': 49.78363006923838, 'loss': 5.270914554595947}


EP_train:1:  15%|| 1021/6926 [5:27:30&lt;31:27:52, 19.18s/it]

{'epoch': 1, 'iter': 1020, 'avg_loss': 5.842267990579335, 'avg_acc': 49.767384916748284, 'loss': 5.850009918212891}


EP_train:1:  15%|| 1031/6926 [5:30:43&lt;31:43:02, 19.37s/it]

{'epoch': 1, 'iter': 1030, 'avg_loss': 5.8431478721441055, 'avg_acc': 49.73326867119302, 'loss': 6.137674331665039}


EP_train:1:  15%|| 1041/6926 [5:33:55&lt;31:20:01, 19.17s/it]

{'epoch': 1, 'iter': 1040, 'avg_loss': 5.843129161226417, 'avg_acc': 49.74183477425552, 'loss': 5.970772743225098}


EP_train:1:  15%|| 1051/6926 [5:37:07&lt;31:25:16, 19.25s/it]

{'epoch': 1, 'iter': 1050, 'avg_loss': 5.8425049609393875, 'avg_acc': 49.72942435775452, 'loss': 5.395400047302246}


EP_train:1:  15%|| 1061/6926 [5:40:20&lt;31:27:50, 19.31s/it]

{'epoch': 1, 'iter': 1060, 'avg_loss': 5.841531728372385, 'avg_acc': 49.7496465598492, 'loss': 6.239808082580566}


EP_train:1:  15%|| 1071/6926 [5:43:32&lt;31:13:34, 19.20s/it]

{'epoch': 1, 'iter': 1070, 'avg_loss': 5.840466057664317, 'avg_acc': 49.78699813258637, 'loss': 6.059412002563477}


EP_train:1:  16%|| 1081/6926 [5:46:45&lt;31:21:29, 19.31s/it]

{'epoch': 1, 'iter': 1080, 'avg_loss': 5.840707620573088, 'avg_acc': 49.77740518038853, 'loss': 5.7304911613464355}


EP_train:1:  16%|| 1091/6926 [5:49:57&lt;31:07:16, 19.20s/it]

{'epoch': 1, 'iter': 1090, 'avg_loss': 5.839890107662715, 'avg_acc': 49.785174152153985, 'loss': 6.10009241104126}


EP_train:1:  16%|| 1101/6926 [5:53:09&lt;31:07:11, 19.23s/it]

{'epoch': 1, 'iter': 1100, 'avg_loss': 5.841028182318166, 'avg_acc': 49.77861035422343, 'loss': 5.7616424560546875}


EP_train:1:  16%|| 1111/6926 [5:56:22&lt;31:19:14, 19.39s/it]

{'epoch': 1, 'iter': 1110, 'avg_loss': 5.839225487060959, 'avg_acc': 49.78622862286229, 'loss': 5.515673637390137}


EP_train:1:  16%|| 1121/6926 [5:59:34&lt;30:58:29, 19.21s/it]

{'epoch': 1, 'iter': 1120, 'avg_loss': 5.8397217451941215, 'avg_acc': 49.79371097234612, 'loss': 6.025796890258789}


EP_train:1:  16%|| 1131/6926 [6:02:47&lt;31:00:03, 19.26s/it]

{'epoch': 1, 'iter': 1130, 'avg_loss': 5.837902028195948, 'avg_acc': 49.798297966401414, 'loss': 5.794040679931641}


EP_train:1:  16%|| 1141/6926 [6:06:00&lt;30:55:24, 19.24s/it]

{'epoch': 1, 'iter': 1140, 'avg_loss': 5.837508106733184, 'avg_acc': 49.772677475898334, 'loss': 6.092175006866455}


EP_train:1:  17%|| 1151/6926 [6:09:12&lt;30:51:07, 19.23s/it]

{'epoch': 1, 'iter': 1150, 'avg_loss': 5.837949460739679, 'avg_acc': 49.80180278019114, 'loss': 6.035767555236816}


EP_train:1:  17%|| 1161/6926 [6:12:25&lt;30:54:28, 19.30s/it]

{'epoch': 1, 'iter': 1160, 'avg_loss': 5.8369841148481605, 'avg_acc': 49.822351421188635, 'loss': 5.83712100982666}


EP_train:1:  17%|| 1171/6926 [6:15:38&lt;30:57:23, 19.36s/it]

{'epoch': 1, 'iter': 1170, 'avg_loss': 5.837335775083807, 'avg_acc': 49.82386848847139, 'loss': 5.484726428985596}


EP_train:1:  17%|| 1181/6926 [6:18:51&lt;30:41:29, 19.23s/it]

{'epoch': 1, 'iter': 1180, 'avg_loss': 5.8367451983523715, 'avg_acc': 49.8174216765453, 'loss': 5.847054958343506}


EP_train:1:  17%|| 1191/6926 [6:22:03&lt;30:35:54, 19.21s/it]

{'epoch': 1, 'iter': 1190, 'avg_loss': 5.836948211006914, 'avg_acc': 49.78222082283795, 'loss': 5.790893077850342}


EP_train:1:  17%|| 1201/6926 [6:25:16&lt;30:32:44, 19.21s/it]

{'epoch': 1, 'iter': 1200, 'avg_loss': 5.837502387441465, 'avg_acc': 49.76842214820982, 'loss': 5.365159511566162}


EP_train:1:  17%|| 1211/6926 [6:28:28&lt;30:27:13, 19.18s/it]

{'epoch': 1, 'iter': 1210, 'avg_loss': 5.83753428707233, 'avg_acc': 49.744529314616024, 'loss': 6.047626972198486}


EP_train:1:  18%|| 1221/6926 [6:31:40&lt;30:25:00, 19.19s/it]

{'epoch': 1, 'iter': 1220, 'avg_loss': 5.836108738042408, 'avg_acc': 49.74662162162162, 'loss': 5.518049240112305}


EP_train:1:  18%|| 1231/6926 [6:34:52&lt;30:21:39, 19.19s/it]

{'epoch': 1, 'iter': 1230, 'avg_loss': 5.836604392208964, 'avg_acc': 49.77406580016247, 'loss': 5.829573154449463}


EP_train:1:  18%|| 1241/6926 [6:38:06&lt;30:44:37, 19.47s/it]

{'epoch': 1, 'iter': 1240, 'avg_loss': 5.83546933505345, 'avg_acc': 49.77840451248993, 'loss': 5.50302267074585}


EP_train:1:  18%|| 1251/6926 [6:41:20&lt;30:47:25, 19.53s/it]

{'epoch': 1, 'iter': 1250, 'avg_loss': 5.836626249156315, 'avg_acc': 49.80515587529976, 'loss': 6.165284156799316}


EP_train:1:  18%|| 1261/6926 [6:44:34&lt;30:22:26, 19.30s/it]

{'epoch': 1, 'iter': 1260, 'avg_loss': 5.835903795818598, 'avg_acc': 49.79926645519429, 'loss': 6.05486536026001}


EP_train:1:  18%|| 1271/6926 [6:47:47&lt;30:15:58, 19.27s/it]

{'epoch': 1, 'iter': 1270, 'avg_loss': 5.837218529215767, 'avg_acc': 49.795928402832416, 'loss': 5.663443088531494}


EP_train:1:  18%|| 1281/6926 [6:51:00&lt;30:19:22, 19.34s/it]

{'epoch': 1, 'iter': 1280, 'avg_loss': 5.838011113672309, 'avg_acc': 49.799960967993755, 'loss': 5.5717453956604}


EP_train:1:  19%|| 1291/6926 [6:54:13&lt;30:18:35, 19.36s/it]

{'epoch': 1, 'iter': 1290, 'avg_loss': 5.8368172656649495, 'avg_acc': 49.80877226955848, 'loss': 5.385322093963623}


EP_train:1:  19%|| 1301/6926 [6:57:27&lt;30:20:54, 19.42s/it]

{'epoch': 1, 'iter': 1300, 'avg_loss': 5.835430765042023, 'avg_acc': 49.80784012298232, 'loss': 5.272273540496826}


EP_train:1:  19%|| 1311/6926 [7:00:41&lt;30:13:15, 19.38s/it]

{'epoch': 1, 'iter': 1310, 'avg_loss': 5.834374673306533, 'avg_acc': 49.82360793287567, 'loss': 5.6404571533203125}


EP_train:1:  19%|| 1321/6926 [7:03:56&lt;30:15:11, 19.43s/it]

{'epoch': 1, 'iter': 1320, 'avg_loss': 5.834086731471048, 'avg_acc': 49.81311506434519, 'loss': 6.042065620422363}


EP_train:1:  19%|| 1331/6926 [7:07:10&lt;30:05:33, 19.36s/it]

{'epoch': 1, 'iter': 1330, 'avg_loss': 5.833662637456927, 'avg_acc': 49.7980841472577, 'loss': 5.997086524963379}


EP_train:1:  19%|| 1341/6926 [7:10:25&lt;30:11:19, 19.46s/it]

{'epoch': 1, 'iter': 1340, 'avg_loss': 5.831286788075651, 'avg_acc': 49.79026845637584, 'loss': 5.13810396194458}


EP_train:1:  20%|| 1351/6926 [7:13:38&lt;30:01:40, 19.39s/it]

{'epoch': 1, 'iter': 1350, 'avg_loss': 5.830443996045433, 'avg_acc': 49.78025536639527, 'loss': 6.180279731750488}


EP_train:1:  20%|| 1361/6926 [7:16:53&lt;30:06:20, 19.48s/it]

{'epoch': 1, 'iter': 1360, 'avg_loss': 5.831139720423444, 'avg_acc': 49.81171932402645, 'loss': 5.738363742828369}


EP_train:1:  20%|| 1371/6926 [7:20:14&lt;33:19:54, 21.60s/it]

{'epoch': 1, 'iter': 1370, 'avg_loss': 5.831161075052251, 'avg_acc': 49.80625455871627, 'loss': 5.848499298095703}


EP_train:1:  20%|| 1381/6926 [7:24:08&lt;31:00:36, 20.13s/it]

{'epoch': 1, 'iter': 1380, 'avg_loss': 5.831336831114242, 'avg_acc': 49.82349746560463, 'loss': 5.313791275024414}


EP_train:1:  20%|| 1391/6926 [7:27:23&lt;29:51:22, 19.42s/it]

{'epoch': 1, 'iter': 1390, 'avg_loss': 5.830504140092862, 'avg_acc': 49.800053918044576, 'loss': 5.489503860473633}


EP_train:1:  20%|| 1401/6926 [7:30:36&lt;29:45:56, 19.39s/it]

{'epoch': 1, 'iter': 1400, 'avg_loss': 5.8311854865532275, 'avg_acc': 49.81486438258387, 'loss': 5.570352077484131}


EP_train:1:  20%|| 1411/6926 [7:33:50&lt;29:44:40, 19.42s/it]

{'epoch': 1, 'iter': 1410, 'avg_loss': 5.831230178105755, 'avg_acc': 49.81839121190645, 'loss': 5.9099040031433105}


EP_train:1:  21%|| 1421/6926 [7:37:04&lt;29:36:52, 19.37s/it]

{'epoch': 1, 'iter': 1420, 'avg_loss': 5.830774644157737, 'avg_acc': 49.80207600281492, 'loss': 5.86726188659668}


EP_train:1:  21%|| 1431/6926 [7:40:19&lt;29:42:58, 19.47s/it]

{'epoch': 1, 'iter': 1430, 'avg_loss': 5.8307352695824965, 'avg_acc': 49.79472396925227, 'loss': 5.561969757080078}


EP_train:1:  21%|| 1441/6926 [7:43:34&lt;29:48:26, 19.56s/it]

{'epoch': 1, 'iter': 1440, 'avg_loss': 5.83044555797749, 'avg_acc': 49.8265093684941, 'loss': 5.945946216583252}


EP_train:1:  21%|| 1451/6926 [7:46:49&lt;29:32:47, 19.43s/it]

{'epoch': 1, 'iter': 1450, 'avg_loss': 5.830807990488885, 'avg_acc': 49.825551343900756, 'loss': 5.711259365081787}


EP_train:1:  21%|| 1461/6926 [7:50:03&lt;29:25:33, 19.38s/it]

{'epoch': 1, 'iter': 1460, 'avg_loss': 5.8303068593134215, 'avg_acc': 49.841718001368925, 'loss': 5.9310078620910645}


EP_train:1:  21%|| 1471/6926 [7:53:23&lt;29:56:43, 19.76s/it]

{'epoch': 1, 'iter': 1470, 'avg_loss': 5.829525811100071, 'avg_acc': 49.83642080217539, 'loss': 5.824807167053223}


EP_train:1:  21%|| 1481/6926 [7:58:23&lt;48:14:59, 31.90s/it]

{'epoch': 1, 'iter': 1480, 'avg_loss': 5.828599950093663, 'avg_acc': 49.80376434841323, 'loss': 5.627674102783203}


EP_train:1:  22%|| 1491/6926 [8:03:48&lt;48:43:50, 32.28s/it]

{'epoch': 1, 'iter': 1490, 'avg_loss': 5.828133173711663, 'avg_acc': 49.80508048289739, 'loss': 5.458308219909668}


EP_train:1:  22%|| 1501/6926 [8:09:13&lt;49:11:50, 32.65s/it]

{'epoch': 1, 'iter': 1500, 'avg_loss': 5.827345010362253, 'avg_acc': 49.81054297135243, 'loss': 6.186519145965576}


EP_train:1:  22%|| 1511/6926 [8:14:37&lt;48:40:35, 32.36s/it]

{'epoch': 1, 'iter': 1510, 'avg_loss': 5.828246969958949, 'avg_acc': 49.82834215751158, 'loss': 5.6483941078186035}


EP_train:1:  22%|| 1521/6926 [8:18:31&lt;30:54:09, 20.58s/it]

{'epoch': 1, 'iter': 1520, 'avg_loss': 5.827747987650634, 'avg_acc': 49.80481591058514, 'loss': 5.682420253753662}


EP_train:1:  22%|| 1531/6926 [8:21:45&lt;29:04:30, 19.40s/it]

{'epoch': 1, 'iter': 1530, 'avg_loss': 5.8276047756436755, 'avg_acc': 49.781596995427826, 'loss': 5.823483943939209}


EP_train:1:  22%|| 1541/6926 [8:25:00&lt;29:08:31, 19.48s/it]

{'epoch': 1, 'iter': 1540, 'avg_loss': 5.827125796863276, 'avg_acc': 49.748539909149905, 'loss': 5.908112049102783}


EP_train:1:  22%|| 1551/6926 [8:28:13&lt;28:53:38, 19.35s/it]

{'epoch': 1, 'iter': 1550, 'avg_loss': 5.826776943538821, 'avg_acc': 49.715909090909086, 'loss': 5.829923629760742}


EP_train:1:  23%|| 1561/6926 [8:31:29&lt;28:59:51, 19.46s/it]

{'epoch': 1, 'iter': 1560, 'avg_loss': 5.825906138936348, 'avg_acc': 49.70771941063421, 'loss': 5.758691787719727}


EP_train:1:  23%|| 1571/6926 [8:34:44&lt;28:56:01, 19.45s/it]

{'epoch': 1, 'iter': 1570, 'avg_loss': 5.824675731185438, 'avg_acc': 49.699633991088476, 'loss': 5.4692864418029785}


EP_train:1:  23%|| 1581/6926 [8:37:59&lt;28:52:12, 19.44s/it]

{'epoch': 1, 'iter': 1580, 'avg_loss': 5.823218187601185, 'avg_acc': 49.68967425679949, 'loss': 5.819296360015869}


EP_train:1:  23%|| 1591/6926 [8:41:14&lt;28:57:14, 19.54s/it]

{'epoch': 1, 'iter': 1590, 'avg_loss': 5.822140803657786, 'avg_acc': 49.679839723444374, 'loss': 5.727397441864014}


EP_train:1:  23%|| 1601/6926 [8:44:29&lt;28:46:20, 19.45s/it]

{'epoch': 1, 'iter': 1600, 'avg_loss': 5.822034669026667, 'avg_acc': 49.691599000624606, 'loss': 5.708556175231934}


EP_train:1:  23%|| 1611/6926 [8:47:43&lt;28:40:23, 19.42s/it]

{'epoch': 1, 'iter': 1610, 'avg_loss': 5.82130381041325, 'avg_acc': 49.72454996896338, 'loss': 5.713103294372559}


EP_train:1:  23%|| 1621/6926 [8:50:58&lt;28:45:25, 19.51s/it]

{'epoch': 1, 'iter': 1620, 'avg_loss': 5.820537564785373, 'avg_acc': 49.747455274521904, 'loss': 5.773373126983643}


EP_train:1:  24%|| 1631/6926 [8:54:14&lt;28:42:51, 19.52s/it]

{'epoch': 1, 'iter': 1630, 'avg_loss': 5.820567112916237, 'avg_acc': 49.77582771305947, 'loss': 6.175393104553223}


EP_train:1:  24%|| 1641/6926 [8:57:28&lt;28:35:08, 19.47s/it]

{'epoch': 1, 'iter': 1640, 'avg_loss': 5.820892861381963, 'avg_acc': 49.79433272394881, 'loss': 6.086596965789795}


EP_train:1:  24%|| 1651/6926 [9:00:43&lt;28:27:31, 19.42s/it]

{'epoch': 1, 'iter': 1650, 'avg_loss': 5.82148897048562, 'avg_acc': 49.77475772259237, 'loss': 5.665853500366211}


EP_train:1:  24%|| 1661/6926 [9:03:58&lt;28:42:11, 19.63s/it]

{'epoch': 1, 'iter': 1660, 'avg_loss': 5.821362611976178, 'avg_acc': 49.772350993377486, 'loss': 6.048189640045166}


EP_train:1:  24%|| 1671/6926 [9:07:12&lt;28:19:47, 19.41s/it]

{'epoch': 1, 'iter': 1670, 'avg_loss': 5.821244932376718, 'avg_acc': 49.741921005386, 'loss': 5.851042747497559}


EP_train:1:  24%|| 1681/6926 [9:10:26&lt;28:13:33, 19.37s/it]

{'epoch': 1, 'iter': 1680, 'avg_loss': 5.821554210056938, 'avg_acc': 49.7267251635931, 'loss': 5.589755058288574}


EP_train:1:  24%|| 1691/6926 [9:13:40&lt;28:08:00, 19.35s/it]

{'epoch': 1, 'iter': 1690, 'avg_loss': 5.82084716106575, 'avg_acc': 49.74312536960379, 'loss': 6.045618057250977}


EP_train:1:  25%|| 1701/6926 [9:16:54&lt;28:12:40, 19.44s/it]

{'epoch': 1, 'iter': 1700, 'avg_loss': 5.8202199764913285, 'avg_acc': 49.76300705467372, 'loss': 5.553305625915527}


EP_train:1:  25%|| 1711/6926 [9:20:08&lt;28:06:45, 19.41s/it]

{'epoch': 1, 'iter': 1710, 'avg_loss': 5.820620152770532, 'avg_acc': 49.77535067212157, 'loss': 5.491093635559082}


EP_train:1:  25%|| 1721/6926 [9:23:23&lt;28:16:31, 19.56s/it]

{'epoch': 1, 'iter': 1720, 'avg_loss': 5.820222318484158, 'avg_acc': 49.756682161533995, 'loss': 5.753364086151123}


EP_train:1:  25%|| 1731/6926 [9:26:38&lt;28:10:18, 19.52s/it]

{'epoch': 1, 'iter': 1730, 'avg_loss': 5.819994436392958, 'avg_acc': 49.76530906990179, 'loss': 5.770174026489258}


EP_train:1:  25%|| 1741/6926 [9:29:54&lt;28:17:53, 19.65s/it]

{'epoch': 1, 'iter': 1740, 'avg_loss': 5.820441535257321, 'avg_acc': 49.763067202757036, 'loss': 6.412217617034912}


EP_train:1:  25%|| 1751/6926 [9:33:10&lt;28:08:19, 19.57s/it]

{'epoch': 1, 'iter': 1750, 'avg_loss': 5.8209615562521755, 'avg_acc': 49.77155910908053, 'loss': 6.034691333770752}


EP_train:1:  25%|| 1761/6926 [9:36:25&lt;27:53:42, 19.44s/it]

{'epoch': 1, 'iter': 1760, 'avg_loss': 5.820453921073814, 'avg_acc': 49.755110732538334, 'loss': 5.652312278747559}


EP_train:1:  26%|| 1771/6926 [9:39:41&lt;28:07:38, 19.64s/it]

{'epoch': 1, 'iter': 1770, 'avg_loss': 5.8203765439960256, 'avg_acc': 49.76002258610954, 'loss': 5.796370506286621}


EP_train:1:  26%|| 1781/6926 [9:42:57&lt;27:58:54, 19.58s/it]

{'epoch': 1, 'iter': 1780, 'avg_loss': 5.820226957395062, 'avg_acc': 49.74908759124087, 'loss': 5.988513469696045}


EP_train:1:  26%|| 1791/6926 [9:46:12&lt;27:40:50, 19.41s/it]

{'epoch': 1, 'iter': 1790, 'avg_loss': 5.820003282418137, 'avg_acc': 49.75223338916806, 'loss': 5.468523979187012}


EP_train:1:  26%|| 1801/6926 [9:49:26&lt;27:32:35, 19.35s/it]

{'epoch': 1, 'iter': 1800, 'avg_loss': 5.819864340585712, 'avg_acc': 49.74840366463076, 'loss': 5.617454528808594}


EP_train:1:  26%|| 1811/6926 [9:52:41&lt;27:41:44, 19.49s/it]

{'epoch': 1, 'iter': 1810, 'avg_loss': 5.819467352872919, 'avg_acc': 49.76532302595251, 'loss': 5.4071149826049805}


EP_train:1:  26%|| 1821/6926 [9:55:55&lt;27:38:52, 19.50s/it]

{'epoch': 1, 'iter': 1820, 'avg_loss': 5.819182623748528, 'avg_acc': 49.75288303130148, 'loss': 5.931480884552002}


EP_train:1:  27%|| 1881/6926 [10:15:31&lt;27:26:32, 19.58s/it]

{'epoch': 1, 'iter': 1880, 'avg_loss': 5.818567064326853, 'avg_acc': 49.76408825093036, 'loss': 6.084392070770264}


EP_train:1:  27%|| 1891/6926 [10:18:46&lt;27:18:08, 19.52s/it]

{'epoch': 1, 'iter': 1890, 'avg_loss': 5.818359741138315, 'avg_acc': 49.75542041248017, 'loss': 5.704246520996094}


EP_train:1:  27%|| 1901/6926 [10:22:03&lt;27:25:51, 19.65s/it]

{'epoch': 1, 'iter': 1900, 'avg_loss': 5.817869842836319, 'avg_acc': 49.753419253024724, 'loss': 5.708099842071533}


EP_train:1:  28%|| 1911/6926 [10:25:20&lt;27:34:19, 19.79s/it]

{'epoch': 1, 'iter': 1910, 'avg_loss': 5.817352183634919, 'avg_acc': 49.739992150706435, 'loss': 5.804592132568359}


EP_train:1:  28%|| 1921/6926 [10:28:37&lt;27:22:08, 19.69s/it]

{'epoch': 1, 'iter': 1920, 'avg_loss': 5.817291461819475, 'avg_acc': 49.73971889640812, 'loss': 5.680202960968018}


EP_train:1:  28%|| 1931/6926 [10:31:53&lt;27:12:45, 19.61s/it]

{'epoch': 1, 'iter': 1930, 'avg_loss': 5.816651209471202, 'avg_acc': 49.73944847229414, 'loss': 5.508451461791992}


EP_train:1:  28%|| 1941/6926 [10:35:11&lt;27:18:43, 19.72s/it]

{'epoch': 1, 'iter': 1940, 'avg_loss': 5.816490153195255, 'avg_acc': 49.75367078825348, 'loss': 5.697039604187012}


EP_train:1:  28%|| 1951/6926 [10:38:28&lt;27:18:48, 19.76s/it]

{'epoch': 1, 'iter': 1950, 'avg_loss': 5.816306221002435, 'avg_acc': 49.754933367503845, 'loss': 5.570111274719238}


EP_train:1:  28%|| 1961/6926 [10:41:45&lt;27:20:12, 19.82s/it]

{'epoch': 1, 'iter': 1960, 'avg_loss': 5.816004560773072, 'avg_acc': 49.76255736868944, 'loss': 5.424126625061035}


EP_train:1:  28%|| 1971/6926 [10:45:04&lt;27:20:51, 19.87s/it]

{'epoch': 1, 'iter': 1970, 'avg_loss': 5.815267153042697, 'avg_acc': 49.75266362252664, 'loss': 5.304238319396973}


EP_train:1:  29%|| 1981/6926 [10:48:55&lt;29:40:40, 21.61s/it]

{'epoch': 1, 'iter': 1980, 'avg_loss': 5.815337210457352, 'avg_acc': 49.7649545683998, 'loss': 6.371850967407227}


EP_train:1:  29%|| 1991/6926 [10:52:24&lt;27:34:43, 20.12s/it]

{'epoch': 1, 'iter': 1990, 'avg_loss': 5.815152885086389, 'avg_acc': 49.75985685585133, 'loss': 5.692751884460449}


EP_train:1:  29%|| 2001/6926 [10:55:41&lt;26:57:10, 19.70s/it]

{'epoch': 1, 'iter': 2000, 'avg_loss': 5.815084245310969, 'avg_acc': 49.7641804097951, 'loss': 5.7164435386657715}


EP_train:1:  29%|| 2011/6926 [10:58:58&lt;26:57:53, 19.75s/it]

{'epoch': 1, 'iter': 2010, 'avg_loss': 5.815105802203102, 'avg_acc': 49.77156887120835, 'loss': 5.837700843811035}


EP_train:1:  29%|| 2021/6926 [11:02:17&lt;27:02:48, 19.85s/it]

{'epoch': 1, 'iter': 2020, 'avg_loss': 5.815062510619241, 'avg_acc': 49.75105145967343, 'loss': 5.568780422210693}


EP_train:1:  29%|| 2031/6926 [11:05:53&lt;29:32:35, 21.73s/it]

{'epoch': 1, 'iter': 2030, 'avg_loss': 5.81544689801102, 'avg_acc': 49.7445839487937, 'loss': 5.928976058959961}


EP_train:1:  29%|| 2041/6926 [11:09:45&lt;28:09:58, 20.76s/it]

{'epoch': 1, 'iter': 2040, 'avg_loss': 5.815306768179057, 'avg_acc': 49.74583537481627, 'loss': 5.518974304199219}


EP_train:1:  30%|| 2051/6926 [11:13:02&lt;26:42:20, 19.72s/it]

{'epoch': 1, 'iter': 2050, 'avg_loss': 5.814903688919015, 'avg_acc': 49.71964895173086, 'loss': 5.489553928375244}


EP_train:1:  30%|| 2061/6926 [11:16:20&lt;26:50:07, 19.86s/it]

{'epoch': 1, 'iter': 2060, 'avg_loss': 5.814639778405587, 'avg_acc': 49.725557981562346, 'loss': 5.28331995010376}


EP_train:1:  30%|| 2071/6926 [11:19:37&lt;26:39:10, 19.76s/it]

{'epoch': 1, 'iter': 2070, 'avg_loss': 5.813812052783386, 'avg_acc': 49.73744567841622, 'loss': 6.101926803588867}


EP_train:1:  30%|| 2081/6926 [11:22:55&lt;26:40:25, 19.82s/it]

{'epoch': 1, 'iter': 2080, 'avg_loss': 5.8142264005027675, 'avg_acc': 49.758229216722725, 'loss': 5.813886642456055}


EP_train:1:  30%|| 2091/6926 [11:26:12&lt;26:35:24, 19.80s/it]

{'epoch': 1, 'iter': 2090, 'avg_loss': 5.8136649193346415, 'avg_acc': 49.757890961262554, 'loss': 5.670198917388916}


EP_train:1:  30%|| 2101/6926 [11:29:30&lt;26:22:43, 19.68s/it]

{'epoch': 1, 'iter': 2100, 'avg_loss': 5.814033971293548, 'avg_acc': 49.756068538791055, 'loss': 5.676214694976807}


EP_train:1:  30%|| 2111/6926 [11:32:47&lt;26:20:32, 19.70s/it]

{'epoch': 1, 'iter': 2110, 'avg_loss': 5.813995209761222, 'avg_acc': 49.74982235907153, 'loss': 5.68745231628418}


EP_train:1:  31%|| 2121/6926 [11:36:05&lt;26:20:38, 19.74s/it]

{'epoch': 1, 'iter': 2120, 'avg_loss': 5.813585028227968, 'avg_acc': 49.75247524752475, 'loss': 5.451981544494629}


EP_train:1:  31%|| 2131/6926 [11:39:21&lt;26:12:21, 19.67s/it]

{'epoch': 1, 'iter': 2130, 'avg_loss': 5.8135437112859245, 'avg_acc': 49.75217034256218, 'loss': 5.650767803192139}


EP_train:1:  31%|| 2141/6926 [11:42:39&lt;26:16:27, 19.77s/it]

{'epoch': 1, 'iter': 2140, 'avg_loss': 5.813377936718231, 'avg_acc': 49.769383465670245, 'loss': 5.65677547454834}


EP_train:1:  31%|| 2151/6926 [11:45:55&lt;26:06:23, 19.68s/it]

{'epoch': 1, 'iter': 2150, 'avg_loss': 5.813167368296078, 'avg_acc': 49.73994653649466, 'loss': 5.920616149902344}


EP_train:1:  31%|| 2161/6926 [11:49:12&lt;26:02:14, 19.67s/it]

{'epoch': 1, 'iter': 2160, 'avg_loss': 5.812986291376102, 'avg_acc': 49.731027302174915, 'loss': 5.761153697967529}


EP_train:1:  31%|| 2171/6926 [11:52:30&lt;26:12:51, 19.85s/it]

{'epoch': 1, 'iter': 2170, 'avg_loss': 5.812540080678018, 'avg_acc': 49.725069092584064, 'loss': 5.7599263191223145}


EP_train:1:  31%|| 2181/6926 [11:55:48&lt;26:05:08, 19.79s/it]

{'epoch': 1, 'iter': 2180, 'avg_loss': 5.812452738244618, 'avg_acc': 49.74352361302155, 'loss': 5.98489236831665}


EP_train:1:  32%|| 2191/6926 [11:59:06&lt;26:01:10, 19.78s/it]

{'epoch': 1, 'iter': 2190, 'avg_loss': 5.812447594921647, 'avg_acc': 49.74184162482885, 'loss': 5.562654495239258}


EP_train:1:  32%|| 2201/6926 [12:02:24&lt;26:04:17, 19.86s/it]

{'epoch': 1, 'iter': 2200, 'avg_loss': 5.812213972231195, 'avg_acc': 49.744434348023624, 'loss': 5.945650577545166}


EP_train:1:  32%|| 2211/6926 [12:05:43&lt;26:02:51, 19.89s/it]

{'epoch': 1, 'iter': 2210, 'avg_loss': 5.812122378398907, 'avg_acc': 49.75124378109453, 'loss': 5.539562702178955}


EP_train:1:  32%|| 2221/6926 [12:09:02&lt;25:59:40, 19.89s/it]

{'epoch': 1, 'iter': 2220, 'avg_loss': 5.812053891894303, 'avg_acc': 49.76502701485817, 'loss': 5.630687713623047}


EP_train:1:  32%|| 2231/6926 [12:12:20&lt;25:50:03, 19.81s/it]

{'epoch': 1, 'iter': 2230, 'avg_loss': 5.811385647804948, 'avg_acc': 49.75487449574182, 'loss': 5.983824729919434}


EP_train:1:  32%|| 2241/6926 [12:15:38&lt;25:50:48, 19.86s/it]

{'epoch': 1, 'iter': 2240, 'avg_loss': 5.810250847640712, 'avg_acc': 49.76851851851852, 'loss': 6.013811111450195}


EP_train:1:  33%|| 2251/6926 [12:18:57&lt;25:46:48, 19.85s/it]

{'epoch': 1, 'iter': 2250, 'avg_loss': 5.810296357763655, 'avg_acc': 49.776488227454465, 'loss': 5.763908863067627}


EP_train:1:  33%|| 2261/6926 [12:22:16&lt;25:53:24, 19.98s/it]

{'epoch': 1, 'iter': 2260, 'avg_loss': 5.810534973895323, 'avg_acc': 49.780241043785935, 'loss': 5.905952453613281}


EP_train:1:  33%|| 2271/6926 [12:25:35&lt;25:41:41, 19.87s/it]

{'epoch': 1, 'iter': 2270, 'avg_loss': 5.810524367068319, 'avg_acc': 49.785336856010574, 'loss': 5.680035591125488}


EP_train:1:  33%|| 2281/6926 [12:28:54&lt;25:39:13, 19.88s/it]

{'epoch': 1, 'iter': 2280, 'avg_loss': 5.81014431489763, 'avg_acc': 49.77942788250767, 'loss': 5.456300258636475}


EP_train:1:  33%|| 2291/6926 [12:32:14&lt;25:43:00, 19.97s/it]

{'epoch': 1, 'iter': 2290, 'avg_loss': 5.809880057259555, 'avg_acc': 49.774934526407684, 'loss': 5.729395866394043}


EP_train:1:  33%|| 2301/6926 [12:35:34&lt;25:29:41, 19.84s/it]

{'epoch': 1, 'iter': 2300, 'avg_loss': 5.809157367376388, 'avg_acc': 49.76233159495872, 'loss': 5.143627166748047}


EP_train:1:  33%|| 2311/6926 [12:38:51&lt;25:21:23, 19.78s/it]

{'epoch': 1, 'iter': 2310, 'avg_loss': 5.808825852911176, 'avg_acc': 49.768768931198615, 'loss': 5.558385848999023}


EP_train:1:  34%|| 2321/6926 [12:42:10&lt;25:14:51, 19.74s/it]

{'epoch': 1, 'iter': 2320, 'avg_loss': 5.808508661788684, 'avg_acc': 49.758993968117196, 'loss': 6.150199890136719}


EP_train:1:  34%|| 2331/6926 [12:45:29&lt;25:30:12, 19.98s/it]

{'epoch': 1, 'iter': 2330, 'avg_loss': 5.808087570684655, 'avg_acc': 49.73589661089661, 'loss': 5.794741630554199}


EP_train:1:  34%|| 2341/6926 [12:48:49&lt;25:24:44, 19.95s/it]

{'epoch': 1, 'iter': 2340, 'avg_loss': 5.807202406389904, 'avg_acc': 49.75571337035455, 'loss': 5.584786891937256}


EP_train:1:  34%|| 2351/6926 [12:52:09&lt;25:24:53, 20.00s/it]

{'epoch': 1, 'iter': 2350, 'avg_loss': 5.806677556656513, 'avg_acc': 49.75409400255211, 'loss': 5.515694618225098}


EP_train:1:  34%|| 2361/6926 [12:55:30&lt;25:25:39, 20.05s/it]

{'epoch': 1, 'iter': 2360, 'avg_loss': 5.805700262741031, 'avg_acc': 49.75248835239305, 'loss': 5.311631679534912}


EP_train:1:  34%|| 2371/6926 [12:58:50&lt;25:19:21, 20.01s/it]

{'epoch': 1, 'iter': 2370, 'avg_loss': 5.805741113834068, 'avg_acc': 49.76539434837621, 'loss': 6.047265529632568}


EP_train:1:  34%|| 2381/6926 [13:02:12&lt;25:24:44, 20.13s/it]

{'epoch': 1, 'iter': 2380, 'avg_loss': 5.805614596602798, 'avg_acc': 49.77687946241075, 'loss': 5.547722816467285}


EP_train:1:  35%|| 2391/6926 [13:05:32&lt;25:06:58, 19.94s/it]

{'epoch': 1, 'iter': 2390, 'avg_loss': 5.805619691914965, 'avg_acc': 49.77519866164785, 'loss': 5.432829856872559}


EP_train:1:  35%|| 2401/6926 [13:08:53&lt;25:12:20, 20.05s/it]

{'epoch': 1, 'iter': 2400, 'avg_loss': 5.805759970717806, 'avg_acc': 49.780039566847144, 'loss': 5.861325263977051}


EP_train:1:  35%|| 2411/6926 [13:12:14&lt;25:10:20, 20.07s/it]

{'epoch': 1, 'iter': 2410, 'avg_loss': 5.806004341486231, 'avg_acc': 49.80428245541269, 'loss': 5.867797374725342}


EP_train:1:  35%|| 2421/6926 [13:15:36&lt;25:16:42, 20.20s/it]

{'epoch': 1, 'iter': 2420, 'avg_loss': 5.805987544810166, 'avg_acc': 49.79476456009913, 'loss': 5.692656517028809}


EP_train:1:  35%|| 2431/6926 [13:18:57&lt;24:58:30, 20.00s/it]

{'epoch': 1, 'iter': 2430, 'avg_loss': 5.806068894501235, 'avg_acc': 49.80075071986837, 'loss': 5.708716869354248}


EP_train:1:  35%|| 2441/6926 [13:22:19&lt;25:11:32, 20.22s/it]

{'epoch': 1, 'iter': 2440, 'avg_loss': 5.805675500536101, 'avg_acc': 49.80028676771815, 'loss': 5.948583126068115}


EP_train:1:  35%|| 2451/6926 [13:25:43&lt;25:10:30, 20.25s/it]

{'epoch': 1, 'iter': 2450, 'avg_loss': 5.80541812930969, 'avg_acc': 49.78452672378621, 'loss': 5.5749430656433105}


EP_train:1:  36%|| 2461/6926 [13:29:05&lt;25:02:48, 20.19s/it]

{'epoch': 1, 'iter': 2460, 'avg_loss': 5.805113396185387, 'avg_acc': 49.812068264932954, 'loss': 5.6128315925598145}


EP_train:1:  36%|| 2471/6926 [13:32:28&lt;24:57:45, 20.17s/it]

{'epoch': 1, 'iter': 2470, 'avg_loss': 5.804539583608333, 'avg_acc': 49.81282881424525, 'loss': 5.324734210968018}


EP_train:1:  36%|| 2481/6926 [13:35:50&lt;25:05:24, 20.32s/it]

{'epoch': 1, 'iter': 2480, 'avg_loss': 5.804087520846913, 'avg_acc': 49.819881096332125, 'loss': 5.382660865783691}


EP_train:1:  36%|| 2491/6926 [13:39:12&lt;24:54:25, 20.22s/it]

{'epoch': 1, 'iter': 2490, 'avg_loss': 5.804366817535621, 'avg_acc': 49.84443998394219, 'loss': 6.087839126586914}


EP_train:1:  36%|| 2501/6926 [13:42:35&lt;24:53:42, 20.25s/it]

{'epoch': 1, 'iter': 2500, 'avg_loss': 5.8043414020195145, 'avg_acc': 49.84756097560975, 'loss': 5.833101749420166}


EP_train:1:  36%|| 2511/6926 [13:45:57&lt;24:44:28, 20.17s/it]

{'epoch': 1, 'iter': 2510, 'avg_loss': 5.803561097262438, 'avg_acc': 49.83945639187575, 'loss': 5.380828857421875}


EP_train:1:  36%|| 2521/6926 [13:49:19&lt;24:35:44, 20.10s/it]

{'epoch': 1, 'iter': 2520, 'avg_loss': 5.803822430766135, 'avg_acc': 49.84257239190797, 'loss': 6.243338108062744}


EP_train:1:  37%|| 2531/6926 [13:52:41&lt;24:39:04, 20.19s/it]

{'epoch': 1, 'iter': 2530, 'avg_loss': 5.803207256915493, 'avg_acc': 49.83949032003161, 'loss': 6.056561470031738}


EP_train:1:  37%|| 2541/6926 [13:56:04&lt;24:48:26, 20.37s/it]

{'epoch': 1, 'iter': 2540, 'avg_loss': 5.803235923619966, 'avg_acc': 49.86471861471862, 'loss': 5.26930046081543}


EP_train:1:  37%|| 2551/6926 [13:59:30&lt;25:20:51, 20.86s/it]

{'epoch': 1, 'iter': 2550, 'avg_loss': 5.803682241660387, 'avg_acc': 49.90444923559389, 'loss': 5.970859527587891}


EP_train:1:  37%|| 2561/6926 [14:02:54&lt;24:46:13, 20.43s/it]

{'epoch': 1, 'iter': 2560, 'avg_loss': 5.803817744741027, 'avg_acc': 49.90726278797345, 'loss': 5.6861090660095215}


EP_train:1:  37%|| 2571/6926 [14:06:18&lt;24:37:49, 20.36s/it]

{'epoch': 1, 'iter': 2570, 'avg_loss': 5.803871367516475, 'avg_acc': 49.886960326721116, 'loss': 5.429114818572998}


EP_train:1:  37%|| 2581/6926 [14:09:40&lt;24:22:00, 20.19s/it]

{'epoch': 1, 'iter': 2580, 'avg_loss': 5.803580724560258, 'avg_acc': 49.88134444013948, 'loss': 5.6898698806762695}


EP_train:1:  37%|| 2591/6926 [14:13:04&lt;24:28:55, 20.33s/it]

{'epoch': 1, 'iter': 2590, 'avg_loss': 5.8033536022485155, 'avg_acc': 49.875771902740254, 'loss': 5.311685562133789}


EP_train:1:  38%|| 2601/6926 [14:16:29&lt;24:31:04, 20.41s/it]

{'epoch': 1, 'iter': 2600, 'avg_loss': 5.803310167509883, 'avg_acc': 49.88586120722799, 'loss': 5.9250898361206055}


EP_train:1:  38%|| 2611/6926 [14:19:53&lt;24:28:04, 20.41s/it]

{'epoch': 1, 'iter': 2610, 'avg_loss': 5.803713341592053, 'avg_acc': 49.90185752585216, 'loss': 6.0624098777771}


EP_train:1:  38%|| 2621/6926 [14:23:17&lt;24:29:41, 20.48s/it]

{'epoch': 1, 'iter': 2620, 'avg_loss': 5.803969218593569, 'avg_acc': 49.905808851583366, 'loss': 5.931776523590088}


EP_train:1:  38%|| 2631/6926 [14:26:41&lt;24:09:23, 20.25s/it]

{'epoch': 1, 'iter': 2630, 'avg_loss': 5.804032856409471, 'avg_acc': 49.89310148232612, 'loss': 5.649225234985352}


EP_train:1:  38%|| 2641/6926 [14:30:05&lt;24:16:44, 20.40s/it]

{'epoch': 1, 'iter': 2640, 'avg_loss': 5.804332307413283, 'avg_acc': 49.88877319197273, 'loss': 5.363492488861084}


EP_train:1:  38%|| 2651/6926 [14:33:28&lt;24:06:14, 20.30s/it]

{'epoch': 1, 'iter': 2650, 'avg_loss': 5.80409545459553, 'avg_acc': 49.88211995473406, 'loss': 5.785643100738525}


EP_train:1:  38%|| 2661/6926 [14:36:53&lt;24:05:45, 20.34s/it]

{'epoch': 1, 'iter': 2660, 'avg_loss': 5.8036675842038585, 'avg_acc': 49.8837373167982, 'loss': 5.403915882110596}


EP_train:1:  39%|| 2671/6926 [14:40:16&lt;24:08:42, 20.43s/it]

{'epoch': 1, 'iter': 2670, 'avg_loss': 5.803600825784984, 'avg_acc': 49.878322725570946, 'loss': 5.855526447296143}


EP_train:1:  39%|| 2681/6926 [14:43:41&lt;24:10:25, 20.50s/it]

{'epoch': 1, 'iter': 2680, 'avg_loss': 5.803370747002414, 'avg_acc': 49.88693584483402, 'loss': 5.916980266571045}


EP_train:1:  39%|| 2691/6926 [14:47:07&lt;24:04:11, 20.46s/it]

{'epoch': 1, 'iter': 2690, 'avg_loss': 5.803192461170436, 'avg_acc': 49.882710888145674, 'loss': 5.771810054779053}


EP_train:1:  39%|| 2701/6926 [14:50:32&lt;24:03:29, 20.50s/it]

{'epoch': 1, 'iter': 2700, 'avg_loss': 5.803469681554439, 'avg_acc': 49.872732321362456, 'loss': 6.208793640136719}


EP_train:1:  39%|| 2711/6926 [14:53:58&lt;24:10:04, 20.64s/it]

{'epoch': 1, 'iter': 2710, 'avg_loss': 5.803627242289184, 'avg_acc': 49.87435448174106, 'loss': 6.089566707611084}


EP_train:1:  39%|| 2721/6926 [14:57:22&lt;23:49:14, 20.39s/it]

{'epoch': 1, 'iter': 2720, 'avg_loss': 5.803495487716433, 'avg_acc': 49.88400404263139, 'loss': 5.7707648277282715}


EP_train:1:  39%|| 2731/6926 [15:00:47&lt;23:56:46, 20.55s/it]

{'epoch': 1, 'iter': 2730, 'avg_loss': 5.803271200228243, 'avg_acc': 49.89015012815818, 'loss': 5.9853196144104}


EP_train:1:  40%|| 2741/6926 [15:04:12&lt;23:54:24, 20.56s/it]

{'epoch': 1, 'iter': 2740, 'avg_loss': 5.802916974231563, 'avg_acc': 49.88827070412258, 'loss': 6.10043478012085}


EP_train:1:  40%|| 2751/6926 [15:07:36&lt;23:42:31, 20.44s/it]

{'epoch': 1, 'iter': 2750, 'avg_loss': 5.802925791405886, 'avg_acc': 49.89208469647401, 'loss': 5.7196044921875}


EP_train:1:  40%|| 2761/6926 [15:11:03&lt;23:50:10, 20.60s/it]

{'epoch': 1, 'iter': 2760, 'avg_loss': 5.803030003157701, 'avg_acc': 49.88568453458891, 'loss': 5.646425247192383}


EP_train:1:  40%|| 2771/6926 [15:14:28&lt;23:44:25, 20.57s/it]

{'epoch': 1, 'iter': 2770, 'avg_loss': 5.802530446666881, 'avg_acc': 49.86692529772645, 'loss': 5.583689212799072}


EP_train:1:  40%|| 2781/6926 [15:17:54&lt;23:43:20, 20.60s/it]

{'epoch': 1, 'iter': 2780, 'avg_loss': 5.80263057161432, 'avg_acc': 49.8584142394822, 'loss': 5.739715576171875}


EP_train:1:  40%|| 2791/6926 [15:21:20&lt;23:33:52, 20.52s/it]

{'epoch': 1, 'iter': 2790, 'avg_loss': 5.802805198387876, 'avg_acc': 49.856682192762456, 'loss': 5.3376030921936035}


EP_train:1:  40%|| 2801/6926 [15:24:45&lt;23:45:00, 20.73s/it]

{'epoch': 1, 'iter': 2800, 'avg_loss': 5.802788054334483, 'avg_acc': 49.846037129596574, 'loss': 5.699147701263428}


EP_train:1:  41%|| 2811/6926 [15:28:10&lt;23:24:40, 20.48s/it]

{'epoch': 1, 'iter': 2810, 'avg_loss': 5.802020575897586, 'avg_acc': 49.85103166133049, 'loss': 5.489011764526367}


EP_train:1:  41%|| 2821/6926 [15:31:35&lt;23:27:22, 20.57s/it]

{'epoch': 1, 'iter': 2820, 'avg_loss': 5.80217228963501, 'avg_acc': 49.86485288904643, 'loss': 6.136548042297363}


EP_train:1:  41%|| 2831/6926 [15:35:00&lt;23:13:04, 20.41s/it]

{'epoch': 1, 'iter': 2830, 'avg_loss': 5.801999372208089, 'avg_acc': 49.8675379724479, 'loss': 5.894773006439209}


EP_train:1:  41%|| 2841/6926 [15:38:25&lt;23:16:41, 20.51s/it]

{'epoch': 1, 'iter': 2840, 'avg_loss': 5.801592723620857, 'avg_acc': 49.86360436466033, 'loss': 5.720633506774902}


EP_train:1:  41%|| 2851/6926 [15:41:51&lt;23:11:01, 20.48s/it]

{'epoch': 1, 'iter': 2850, 'avg_loss': 5.801943971833945, 'avg_acc': 49.87504384426517, 'loss': 5.807015419006348}


EP_train:1:  41%|| 2861/6926 [15:45:16&lt;23:16:56, 20.62s/it]

{'epoch': 1, 'iter': 2860, 'avg_loss': 5.801992543882859, 'avg_acc': 49.86674239776302, 'loss': 6.230549335479736}


EP_train:1:  41%|| 2871/6926 [15:48:41&lt;23:04:49, 20.49s/it]

{'epoch': 1, 'iter': 2870, 'avg_loss': 5.801884959940709, 'avg_acc': 49.86067572274469, 'loss': 5.754544258117676}


EP_train:1:  42%|| 2881/6926 [15:52:06&lt;22:59:33, 20.46s/it]

{'epoch': 1, 'iter': 2880, 'avg_loss': 5.801832714994431, 'avg_acc': 49.86332870531066, 'loss': 5.754513263702393}


EP_train:1:  42%|| 2891/6926 [15:55:29&lt;22:47:39, 20.34s/it]

{'epoch': 1, 'iter': 2890, 'avg_loss': 5.801836648642172, 'avg_acc': 49.87244897959184, 'loss': 5.542731761932373}


EP_train:1:  42%|| 2901/6926 [15:58:55&lt;23:05:01, 20.65s/it]

{'epoch': 1, 'iter': 2900, 'avg_loss': 5.801939054671258, 'avg_acc': 49.886892450879, 'loss': 6.0265045166015625}


EP_train:1:  42%|| 2911/6926 [16:02:23&lt;23:16:36, 20.87s/it]

{'epoch': 1, 'iter': 2910, 'avg_loss': 5.8020411515637225, 'avg_acc': 49.89694263139815, 'loss': 5.593013286590576}


EP_train:1:  42%|| 2921/6926 [16:05:50&lt;22:51:02, 20.54s/it]

{'epoch': 1, 'iter': 2920, 'avg_loss': 5.802139006343372, 'avg_acc': 49.88873673399521, 'loss': 5.587180137634277}


EP_train:1:  42%|| 2931/6926 [16:09:16&lt;22:58:59, 20.71s/it]

{'epoch': 1, 'iter': 2930, 'avg_loss': 5.801907398480273, 'avg_acc': 49.88911634254521, 'loss': 5.605075836181641}


EP_train:1:  42%|| 2941/6926 [16:12:42&lt;22:51:57, 20.66s/it]

{'epoch': 1, 'iter': 2940, 'avg_loss': 5.802057036977364, 'avg_acc': 49.904369262155726, 'loss': 5.779245376586914}


EP_train:1:  43%|| 2951/6926 [16:16:05&lt;22:31:04, 20.39s/it]

{'epoch': 1, 'iter': 2950, 'avg_loss': 5.801865979074745, 'avg_acc': 49.90681125042358, 'loss': 5.421384334564209}


EP_train:1:  43%|| 2961/6926 [16:19:31&lt;22:31:31, 20.45s/it]

{'epoch': 1, 'iter': 2960, 'avg_loss': 5.801866229906633, 'avg_acc': 49.91451367781155, 'loss': 6.421411991119385}


EP_train:1:  43%|| 2971/6926 [16:22:55&lt;22:24:54, 20.40s/it]

{'epoch': 1, 'iter': 2970, 'avg_loss': 5.801617084870391, 'avg_acc': 49.89692022887917, 'loss': 5.8181610107421875}


EP_train:1:  43%|| 2981/6926 [16:26:20&lt;22:23:48, 20.44s/it]

{'epoch': 1, 'iter': 2980, 'avg_loss': 5.801531334204867, 'avg_acc': 49.90250754780275, 'loss': 6.25356388092041}


EP_train:1:  43%|| 2991/6926 [16:29:43&lt;22:11:19, 20.30s/it]

{'epoch': 1, 'iter': 2990, 'avg_loss': 5.801264963114951, 'avg_acc': 49.89447509194249, 'loss': 5.840907573699951}


EP_train:1:  43%|| 3001/6926 [16:33:07&lt;22:16:55, 20.44s/it]

{'epoch': 1, 'iter': 3000, 'avg_loss': 5.8012425353709, 'avg_acc': 49.88337220926358, 'loss': 5.5747480392456055}


EP_train:1:  43%|| 3011/6926 [16:36:32&lt;22:16:53, 20.49s/it]

{'epoch': 1, 'iter': 3010, 'avg_loss': 5.80091211083956, 'avg_acc': 49.87441879774161, 'loss': 5.703753471374512}


EP_train:1:  44%|| 3021/6926 [16:39:56&lt;22:07:26, 20.40s/it]

{'epoch': 1, 'iter': 3020, 'avg_loss': 5.801163221186891, 'avg_acc': 49.86966236345581, 'loss': 5.810041427612305}


EP_train:1:  44%|| 3031/6926 [16:43:21&lt;22:08:17, 20.46s/it]

{'epoch': 1, 'iter': 3030, 'avg_loss': 5.80099582404675, 'avg_acc': 49.87834048168921, 'loss': 6.274641990661621}


EP_train:1:  44%|| 3041/6926 [16:46:44&lt;22:00:07, 20.39s/it]

{'epoch': 1, 'iter': 3040, 'avg_loss': 5.800807579376713, 'avg_acc': 49.874630055902664, 'loss': 5.624147415161133}


EP_train:1:  44%|| 3051/6926 [16:50:07&lt;21:53:55, 20.34s/it]

{'epoch': 1, 'iter': 3050, 'avg_loss': 5.800946569958502, 'avg_acc': 49.87299246148804, 'loss': 5.570043563842773}


EP_train:1:  44%|| 3061/6926 [16:53:29&lt;21:41:34, 20.21s/it]

{'epoch': 1, 'iter': 3060, 'avg_loss': 5.800996650788021, 'avg_acc': 49.86830284220843, 'loss': 6.268154144287109}


EP_train:1:  44%|| 3071/6926 [16:56:53&lt;21:52:58, 20.44s/it]

{'epoch': 1, 'iter': 3070, 'avg_loss': 5.801088010632072, 'avg_acc': 49.8666965157929, 'loss': 5.92355489730835}


EP_train:1:  44%|| 3081/6926 [17:00:15&lt;21:31:36, 20.16s/it]

{'epoch': 1, 'iter': 3080, 'avg_loss': 5.800997397451577, 'avg_acc': 49.875243427458614, 'loss': 5.917311668395996}


EP_train:1:  45%|| 3091/6926 [17:03:38&lt;21:37:46, 20.30s/it]

{'epoch': 1, 'iter': 3090, 'avg_loss': 5.80108144714469, 'avg_acc': 49.888790035587185, 'loss': 5.845328330993652}


EP_train:1:  45%|| 3101/6926 [17:07:00&lt;21:31:30, 20.26s/it]

{'epoch': 1, 'iter': 3100, 'avg_loss': 5.8006915970795845, 'avg_acc': 49.890156401160915, 'loss': 5.792585849761963}


EP_train:1:  45%|| 3111/6926 [17:10:23&lt;21:32:38, 20.33s/it]

{'epoch': 1, 'iter': 3110, 'avg_loss': 5.800643468431934, 'avg_acc': 49.88347798135648, 'loss': 5.319636344909668}


EP_train:1:  45%|| 3121/6926 [17:13:46&lt;21:26:54, 20.29s/it]

{'epoch': 1, 'iter': 3120, 'avg_loss': 5.800560562857371, 'avg_acc': 49.90487824415252, 'loss': 5.848810195922852}


EP_train:1:  45%|| 3131/6926 [17:17:08&lt;21:16:29, 20.18s/it]

{'epoch': 1, 'iter': 3130, 'avg_loss': 5.799761191453084, 'avg_acc': 49.906180134142446, 'loss': 5.522349834442139}


EP_train:1:  45%|| 3141/6926 [17:20:30&lt;21:20:26, 20.30s/it]

{'epoch': 1, 'iter': 3140, 'avg_loss': 5.799490795056556, 'avg_acc': 49.90846864056033, 'loss': 5.382495880126953}


EP_train:1:  45%|| 3151/6926 [17:23:51&lt;21:02:39, 20.07s/it]

{'epoch': 1, 'iter': 3150, 'avg_loss': 5.799324041243698, 'avg_acc': 49.8998333862266, 'loss': 5.682802200317383}


EP_train:1:  46%|| 3161/6926 [17:27:13&lt;21:05:27, 20.17s/it]

{'epoch': 1, 'iter': 3160, 'avg_loss': 5.799414351860657, 'avg_acc': 49.903116102499204, 'loss': 5.818331718444824}


EP_train:1:  46%|| 3171/6926 [17:30:34&lt;20:57:38, 20.10s/it]

{'epoch': 1, 'iter': 3170, 'avg_loss': 5.798695234950128, 'avg_acc': 49.9083491012299, 'loss': 6.04541540145874}


EP_train:1:  46%|| 3181/6926 [17:33:55&lt;20:55:41, 20.12s/it]

{'epoch': 1, 'iter': 3180, 'avg_loss': 5.798833204867217, 'avg_acc': 49.91747878025778, 'loss': 5.4481658935546875}


EP_train:1:  46%|| 3191/6926 [17:37:16&lt;20:44:59, 20.00s/it]

{'epoch': 1, 'iter': 3190, 'avg_loss': 5.798147868004311, 'avg_acc': 49.90696490128486, 'loss': 5.371510028839111}


EP_train:1:  46%|| 3201/6926 [17:40:35&lt;20:37:30, 19.93s/it]

{'epoch': 1, 'iter': 3200, 'avg_loss': 5.798515476982358, 'avg_acc': 49.91213683223992, 'loss': 5.820341110229492}


EP_train:1:  46%|| 3211/6926 [17:43:56&lt;20:36:00, 19.96s/it]

{'epoch': 1, 'iter': 3210, 'avg_loss': 5.798679115689829, 'avg_acc': 49.916303332295236, 'loss': 6.057877063751221}


EP_train:1:  47%|| 3221/6926 [17:47:14&lt;20:21:11, 19.78s/it]

{'epoch': 1, 'iter': 3220, 'avg_loss': 5.798803051744548, 'avg_acc': 49.910742005588325, 'loss': 5.672614097595215}


EP_train:1:  47%|| 3231/6926 [17:50:35&lt;20:35:24, 20.06s/it]

{'epoch': 1, 'iter': 3230, 'avg_loss': 5.798637440609733, 'avg_acc': 49.90521510368307, 'loss': 5.771320819854736}


EP_train:1:  47%|| 3241/6926 [17:53:55&lt;20:29:09, 20.01s/it]

{'epoch': 1, 'iter': 3240, 'avg_loss': 5.7986973548001695, 'avg_acc': 49.90261493366245, 'loss': 6.0871100425720215}


EP_train:1:  47%|| 3251/6926 [17:57:15&lt;20:18:36, 19.90s/it]

{'epoch': 1, 'iter': 3250, 'avg_loss': 5.798550034625388, 'avg_acc': 49.90579821593356, 'loss': 5.959145545959473}


EP_train:1:  47%|| 3261/6926 [18:00:34&lt;20:12:48, 19.86s/it]

{'epoch': 1, 'iter': 3260, 'avg_loss': 5.798477939358887, 'avg_acc': 49.91567003986507, 'loss': 6.048858165740967}


EP_train:1:  47%|| 3271/6926 [18:03:52&lt;20:02:53, 19.75s/it]

{'epoch': 1, 'iter': 3270, 'avg_loss': 5.798104361852205, 'avg_acc': 49.92930296545399, 'loss': 5.471917152404785}


EP_train:1:  47%|| 3281/6926 [18:07:10&lt;20:05:53, 19.85s/it]

{'epoch': 1, 'iter': 3280, 'avg_loss': 5.797959458933339, 'avg_acc': 49.923803718378544, 'loss': 5.832575798034668}


EP_train:1:  48%|| 3291/6926 [18:10:30&lt;19:59:10, 19.79s/it]

{'epoch': 1, 'iter': 3290, 'avg_loss': 5.797657301707748, 'avg_acc': 49.92783348526284, 'loss': 5.882083415985107}


EP_train:1:  48%|| 3301/6926 [18:13:47&lt;19:55:06, 19.78s/it]

{'epoch': 1, 'iter': 3300, 'avg_loss': 5.797738103280101, 'avg_acc': 49.942252347773405, 'loss': 5.842111587524414}


EP_train:1:  48%|| 3311/6926 [18:17:06&lt;19:55:55, 19.85s/it]

{'epoch': 1, 'iter': 3310, 'avg_loss': 5.797788564548936, 'avg_acc': 49.93204469948656, 'loss': 5.644682884216309}


EP_train:1:  48%|| 3321/6926 [18:20:24&lt;19:46:51, 19.75s/it]

{'epoch': 1, 'iter': 3320, 'avg_loss': 5.797738609957214, 'avg_acc': 49.93977717554953, 'loss': 5.707881927490234}


EP_train:1:  48%|| 3331/6926 [18:23:42&lt;19:48:14, 19.83s/it]

{'epoch': 1, 'iter': 3330, 'avg_loss': 5.79758222823886, 'avg_acc': 49.935267187030924, 'loss': 6.302088260650635}


EP_train:1:  48%|| 3341/6926 [18:27:00&lt;19:35:10, 19.67s/it]

{'epoch': 1, 'iter': 3340, 'avg_loss': 5.797448237760807, 'avg_acc': 49.919560011972465, 'loss': 5.805854320526123}


EP_train:1:  48%|| 3351/6926 [18:30:16&lt;19:31:35, 19.66s/it]

{'epoch': 1, 'iter': 3350, 'avg_loss': 5.797970459305397, 'avg_acc': 49.92073261712922, 'loss': 6.262275218963623}


EP_train:1:  49%|| 3361/6926 [18:33:33&lt;19:24:11, 19.59s/it]

{'epoch': 1, 'iter': 3360, 'avg_loss': 5.797864862865935, 'avg_acc': 49.91724933055639, 'loss': 6.109804153442383}


EP_train:1:  49%|| 3371/6926 [18:36:50&lt;19:33:27, 19.81s/it]

{'epoch': 1, 'iter': 3370, 'avg_loss': 5.797793220320854, 'avg_acc': 49.9147137347968, 'loss': 5.812377452850342}


EP_train:1:  49%|| 3381/6926 [18:40:06&lt;19:17:50, 19.60s/it]

{'epoch': 1, 'iter': 3380, 'avg_loss': 5.797807161640888, 'avg_acc': 49.91404170363798, 'loss': 5.877485752105713}


EP_train:1:  49%|| 3391/6926 [18:43:30&lt;19:27:50, 19.82s/it]

{'epoch': 1, 'iter': 3390, 'avg_loss': 5.797511611776484, 'avg_acc': 49.92074609259806, 'loss': 5.540976047515869}


EP_train:1:  49%|| 3401/6926 [18:46:46&lt;19:03:32, 19.46s/it]

{'epoch': 1, 'iter': 3400, 'avg_loss': 5.797180272522691, 'avg_acc': 49.923735665980594, 'loss': 5.785827159881592}


EP_train:1:  49%|| 3411/6926 [18:50:02&lt;19:07:56, 19.60s/it]

{'epoch': 1, 'iter': 3410, 'avg_loss': 5.797631775238967, 'avg_acc': 49.92304309586631, 'loss': 5.969135761260986}


EP_train:1:  49%|| 3421/6926 [18:53:15&lt;18:49:32, 19.34s/it]

{'epoch': 1, 'iter': 3420, 'avg_loss': 5.797375422686521, 'avg_acc': 49.90225811166326, 'loss': 5.652700901031494}


EP_train:1:  50%|| 3431/6926 [18:56:29&lt;18:44:42, 19.31s/it]

{'epoch': 1, 'iter': 3430, 'avg_loss': 5.797165639822284, 'avg_acc': 49.89070241911979, 'loss': 5.90446662902832}


EP_train:1:  50%|| 3441/6926 [18:59:42&lt;18:41:07, 19.30s/it]

{'epoch': 1, 'iter': 3440, 'avg_loss': 5.7970707328539195, 'avg_acc': 49.88012205754141, 'loss': 5.610228538513184}


EP_train:1:  50%|| 3451/6926 [19:02:56&lt;18:52:37, 19.56s/it]

{'epoch': 1, 'iter': 3450, 'avg_loss': 5.796945811492469, 'avg_acc': 49.88590263691683, 'loss': 5.920961856842041}


EP_train:1:  50%|| 3461/6926 [19:06:10&lt;18:36:27, 19.33s/it]

{'epoch': 1, 'iter': 3460, 'avg_loss': 5.79697771232206, 'avg_acc': 49.88984397572956, 'loss': 5.862846374511719}


EP_train:1:  50%|| 3471/6926 [19:09:23&lt;18:29:37, 19.27s/it]

{'epoch': 1, 'iter': 3470, 'avg_loss': 5.797259839595617, 'avg_acc': 49.89736387208297, 'loss': 5.542323112487793}


EP_train:1:  50%|| 3481/6926 [19:12:34&lt;18:17:58, 19.12s/it]

{'epoch': 1, 'iter': 3480, 'avg_loss': 5.797178803213503, 'avg_acc': 49.89855644929618, 'loss': 5.552881717681885}


EP_train:1:  50%|| 3491/6926 [19:15:44&lt;18:08:34, 19.01s/it]

{'epoch': 1, 'iter': 3490, 'avg_loss': 5.797389878956236, 'avg_acc': 49.89168576339158, 'loss': 5.8328142166137695}


EP_train:1:  51%|| 3501/6926 [19:18:53&lt;17:59:26, 18.91s/it]

{'epoch': 1, 'iter': 3500, 'avg_loss': 5.797299477414587, 'avg_acc': 49.88396172522137, 'loss': 5.669032573699951}


EP_train:1:  51%|| 3511/6926 [19:22:03&lt;17:58:31, 18.95s/it]

{'epoch': 1, 'iter': 3510, 'avg_loss': 5.79730965805271, 'avg_acc': 49.86916120763315, 'loss': 6.08472204208374}


EP_train:1:  51%|| 3521/6926 [19:25:12&lt;17:53:36, 18.92s/it]

{'epoch': 1, 'iter': 3520, 'avg_loss': 5.797139988064732, 'avg_acc': 49.861545015620564, 'loss': 5.721656799316406}


EP_train:1:  51%|| 3531/6926 [19:28:22&lt;17:49:56, 18.91s/it]

{'epoch': 1, 'iter': 3530, 'avg_loss': 5.796997390229585, 'avg_acc': 49.8548569810252, 'loss': 5.389169692993164}


EP_train:1:  51%|| 3541/6926 [19:31:30&lt;17:42:49, 18.84s/it]

{'epoch': 1, 'iter': 3540, 'avg_loss': 5.796650430571053, 'avg_acc': 49.8570319118893, 'loss': 5.669034481048584}


EP_train:1:  51%|| 3551/6926 [19:34:39&lt;17:44:43, 18.93s/it]

{'epoch': 1, 'iter': 3550, 'avg_loss': 5.796759259361711, 'avg_acc': 49.85479442410588, 'loss': 5.946142196655273}


EP_train:1:  51%|| 3561/6926 [19:37:47&lt;17:30:43, 18.73s/it]

{'epoch': 1, 'iter': 3560, 'avg_loss': 5.796634467456221, 'avg_acc': 49.85520219039596, 'loss': 5.647500514984131}


EP_train:1:  52%|| 3571/6926 [19:40:53&lt;17:20:25, 18.61s/it]

{'epoch': 1, 'iter': 3570, 'avg_loss': 5.7965164471660735, 'avg_acc': 49.85385746289555, 'loss': 5.817470073699951}


EP_train:1:  52%|| 3581/6926 [19:44:00&lt;17:23:51, 18.72s/it]

{'epoch': 1, 'iter': 3580, 'avg_loss': 5.796583670872079, 'avg_acc': 49.86211951968723, 'loss': 6.430782318115234}


EP_train:1:  52%|| 3591/6926 [19:47:06&lt;17:17:14, 18.66s/it]

{'epoch': 1, 'iter': 3590, 'avg_loss': 5.796288941637515, 'avg_acc': 49.87207602339181, 'loss': 5.8473734855651855}


EP_train:1:  52%|| 3601/6926 [19:50:12&lt;17:06:33, 18.52s/it]

{'epoch': 1, 'iter': 3600, 'avg_loss': 5.7958874981855555, 'avg_acc': 49.87590252707581, 'loss': 5.566928386688232}


EP_train:1:  52%|| 3611/6926 [19:53:17&lt;17:06:04, 18.57s/it]

{'epoch': 1, 'iter': 3610, 'avg_loss': 5.796095670342479, 'avg_acc': 49.87711160343395, 'loss': 5.474966526031494}


EP_train:1:  52%|| 3621/6926 [19:57:09&lt;20:14:31, 22.05s/it]

{'epoch': 1, 'iter': 3620, 'avg_loss': 5.796189312248789, 'avg_acc': 49.883492129246065, 'loss': 5.988002777099609}


EP_train:1:  52%|| 3631/6926 [20:00:59&lt;23:19:53, 25.49s/it]

{'epoch': 1, 'iter': 3630, 'avg_loss': 5.796312926131416, 'avg_acc': 49.88897686587717, 'loss': 5.757579803466797}


EP_train:1:  53%|| 3641/6926 [20:04:05&lt;17:04:46, 18.72s/it]

{'epoch': 1, 'iter': 3640, 'avg_loss': 5.796070382412369, 'avg_acc': 49.88842351002472, 'loss': 5.555129051208496}


EP_train:1:  53%|| 3651/6926 [20:07:25&lt;17:51:29, 19.63s/it]

{'epoch': 1, 'iter': 3650, 'avg_loss': 5.795582013664361, 'avg_acc': 49.89044097507532, 'loss': 5.464755535125732}


EP_train:1:  53%|| 3661/6926 [20:10:35&lt;17:00:01, 18.74s/it]

{'epoch': 1, 'iter': 3660, 'avg_loss': 5.795854019617259, 'avg_acc': 49.88903305107894, 'loss': 5.79459285736084}


EP_train:1:  53%|| 3671/6926 [20:13:38&lt;16:34:25, 18.33s/it]

{'epoch': 1, 'iter': 3670, 'avg_loss': 5.795935146557281, 'avg_acc': 49.88763279760283, 'loss': 6.025897979736328}


EP_train:1:  53%|| 3681/6926 [20:16:41&lt;16:28:18, 18.27s/it]

{'epoch': 1, 'iter': 3680, 'avg_loss': 5.7961370896399265, 'avg_acc': 49.894729693018206, 'loss': 6.070523262023926}


EP_train:1:  53%|| 3691/6926 [20:19:42&lt;16:11:59, 18.03s/it]

{'epoch': 1, 'iter': 3690, 'avg_loss': 5.796098995260416, 'avg_acc': 49.894168247087514, 'loss': 5.607734680175781}


EP_train:1:  53%|| 3701/6926 [20:22:42&lt;16:06:22, 17.98s/it]

{'epoch': 1, 'iter': 3700, 'avg_loss': 5.796049712252469, 'avg_acc': 49.896987300729535, 'loss': 6.21684455871582}


EP_train:1:  54%|| 3711/6926 [20:25:42&lt;16:00:13, 17.92s/it]

{'epoch': 1, 'iter': 3710, 'avg_loss': 5.795763020244322, 'avg_acc': 49.89389652384802, 'loss': 5.917003154754639}


EP_train:1:  54%|| 3721/6926 [20:28:39&lt;15:49:20, 17.77s/it]

{'epoch': 1, 'iter': 3720, 'avg_loss': 5.795843896478839, 'avg_acc': 49.909298575651704, 'loss': 6.046869277954102}


EP_train:1:  54%|| 3731/6926 [20:31:36&lt;15:42:15, 17.69s/it]

{'epoch': 1, 'iter': 3730, 'avg_loss': 5.795734848486646, 'avg_acc': 49.91037925489145, 'loss': 6.020778179168701}


EP_train:1:  54%|| 3741/6926 [20:34:32&lt;15:29:33, 17.51s/it]

{'epoch': 1, 'iter': 3740, 'avg_loss': 5.795458523164743, 'avg_acc': 49.92147821438118, 'loss': 5.970174312591553}


EP_train:1:  54%|| 3751/6926 [20:37:25&lt;15:12:40, 17.25s/it]

{'epoch': 1, 'iter': 3750, 'avg_loss': 5.795276692313405, 'avg_acc': 49.915855771794185, 'loss': 6.3066253662109375}


EP_train:1:  54%|| 3761/6926 [20:40:17&lt;15:01:38, 17.09s/it]

{'epoch': 1, 'iter': 3760, 'avg_loss': 5.795042146871902, 'avg_acc': 49.91358681201808, 'loss': 5.656373023986816}


EP_train:1:  54%|| 3771/6926 [20:43:08&lt;14:58:57, 17.10s/it]

{'epoch': 1, 'iter': 3770, 'avg_loss': 5.795108221848679, 'avg_acc': 49.90801511535402, 'loss': 5.706948280334473}


EP_train:1:  55%|| 3781/6926 [20:45:59&lt;14:57:48, 17.13s/it]

{'epoch': 1, 'iter': 3780, 'avg_loss': 5.795098736562983, 'avg_acc': 49.908258397249405, 'loss': 6.0315070152282715}


EP_train:1:  55%|| 3791/6926 [20:48:50&lt;14:49:26, 17.02s/it]

{'epoch': 1, 'iter': 3790, 'avg_loss': 5.795354385547039, 'avg_acc': 49.91427064099182, 'loss': 6.394899368286133}


EP_train:1:  55%|| 3801/6926 [20:51:39&lt;14:40:22, 16.90s/it]

{'epoch': 1, 'iter': 3800, 'avg_loss': 5.795517491905415, 'avg_acc': 49.903808208366215, 'loss': 5.58576774597168}


EP_train:1:  55%|| 3811/6926 [20:54:28&lt;14:37:55, 16.91s/it]

{'epoch': 1, 'iter': 3810, 'avg_loss': 5.795274944700803, 'avg_acc': 49.9048806087641, 'loss': 5.320634365081787}


EP_train:1:  55%|| 3821/6926 [20:57:17&lt;14:35:43, 16.92s/it]

{'epoch': 1, 'iter': 3820, 'avg_loss': 5.7953101960316715, 'avg_acc': 49.91249018581524, 'loss': 5.8170318603515625}


EP_train:1:  55%|| 3831/6926 [21:00:05&lt;14:21:10, 16.69s/it]

{'epoch': 1, 'iter': 3830, 'avg_loss': 5.795442255941703, 'avg_acc': 49.92332289219525, 'loss': 5.72982120513916}


EP_train:1:  55%|| 3841/6926 [21:02:51&lt;14:13:10, 16.59s/it]

{'epoch': 1, 'iter': 3840, 'avg_loss': 5.7952990185559585, 'avg_acc': 49.93409919291851, 'loss': 5.5230255126953125}


EP_train:1:  56%|| 3851/6926 [21:05:36&lt;14:06:31, 16.52s/it]

{'epoch': 1, 'iter': 3850, 'avg_loss': 5.7952710199715165, 'avg_acc': 49.93264736432096, 'loss': 5.660543441772461}


EP_train:1:  56%|| 3861/6926 [21:08:20&lt;13:54:19, 16.33s/it]

{'epoch': 1, 'iter': 3860, 'avg_loss': 5.794991210531429, 'avg_acc': 49.921490546490546, 'loss': 5.702726364135742}


EP_train:1:  56%|| 3871/6926 [21:11:03&lt;13:45:22, 16.21s/it]

{'epoch': 1, 'iter': 3870, 'avg_loss': 5.795202156457135, 'avg_acc': 49.92492250064583, 'loss': 5.88737154006958}


EP_train:1:  56%|| 3881/6926 [21:13:44&lt;13:38:04, 16.12s/it]

{'epoch': 1, 'iter': 3880, 'avg_loss': 5.795012125370583, 'avg_acc': 49.93236279309456, 'loss': 5.569786548614502}


EP_train:1:  56%|| 3891/6926 [21:16:24&lt;13:28:15, 15.98s/it]

{'epoch': 1, 'iter': 3890, 'avg_loss': 5.79500720912097, 'avg_acc': 49.92852094577229, 'loss': 5.793521404266357}


EP_train:1:  56%|| 3901/6926 [21:19:03&lt;13:20:24, 15.88s/it]

{'epoch': 1, 'iter': 3900, 'avg_loss': 5.79471958615602, 'avg_acc': 49.930306331709815, 'loss': 5.839369297027588}


EP_train:1:  56%|| 3911/6926 [21:21:41&lt;13:07:56, 15.68s/it]

{'epoch': 1, 'iter': 3910, 'avg_loss': 5.794606451791926, 'avg_acc': 49.933680644336484, 'loss': 5.522931098937988}


EP_train:1:  57%|| 3921/6926 [21:24:18&lt;13:00:51, 15.59s/it]

{'epoch': 1, 'iter': 3920, 'avg_loss': 5.7943557105907155, 'avg_acc': 49.923488905891354, 'loss': 5.36496114730835}


EP_train:1:  57%|| 3931/6926 [21:26:53&lt;12:52:24, 15.47s/it]

{'epoch': 1, 'iter': 3930, 'avg_loss': 5.794669412468808, 'avg_acc': 49.93560798778937, 'loss': 5.800092697143555}


EP_train:1:  57%|| 3941/6926 [21:29:27&lt;12:45:45, 15.39s/it]

{'epoch': 1, 'iter': 3940, 'avg_loss': 5.794817465448464, 'avg_acc': 49.92704897234205, 'loss': 6.14797306060791}


EP_train:1:  57%|| 3951/6926 [21:32:01&lt;12:41:35, 15.36s/it]

{'epoch': 1, 'iter': 3950, 'avg_loss': 5.794826054385993, 'avg_acc': 49.92802455074665, 'loss': 5.839995384216309}


EP_train:1:  57%|| 3961/6926 [21:34:34&lt;12:39:14, 15.36s/it]

{'epoch': 1, 'iter': 3960, 'avg_loss': 5.794849992490604, 'avg_acc': 49.92899520323151, 'loss': 5.774095058441162}


EP_train:1:  57%|| 3971/6926 [21:37:06&lt;12:25:51, 15.14s/it]

{'epoch': 1, 'iter': 3970, 'avg_loss': 5.794746690239543, 'avg_acc': 49.92917401158398, 'loss': 5.460506439208984}


EP_train:1:  57%|| 3981/6926 [21:39:38&lt;12:23:54, 15.16s/it]

{'epoch': 1, 'iter': 3980, 'avg_loss': 5.794556604082097, 'avg_acc': 49.9222871137905, 'loss': 5.621820449829102}


EP_train:1:  58%|| 3991/6926 [21:42:08&lt;12:13:49, 15.00s/it]

{'epoch': 1, 'iter': 3990, 'avg_loss': 5.794708291380903, 'avg_acc': 49.926396893009276, 'loss': 5.9321208000183105}


EP_train:1:  58%|| 4001/6926 [21:44:38&lt;12:02:50, 14.83s/it]

{'epoch': 1, 'iter': 4000, 'avg_loss': 5.794589236091894, 'avg_acc': 49.9265808547863, 'loss': 5.453184604644775}


EP_train:1:  58%|| 4011/6926 [21:47:05&lt;11:53:06, 14.68s/it]

{'epoch': 1, 'iter': 4010, 'avg_loss': 5.794481540314725, 'avg_acc': 49.926763899276985, 'loss': 5.48418664932251}


EP_train:1:  58%|| 4021/6926 [21:49:31&lt;11:47:59, 14.62s/it]

{'epoch': 1, 'iter': 4020, 'avg_loss': 5.794357808660258, 'avg_acc': 49.92539169360855, 'loss': 5.723490238189697}


EP_train:1:  58%|| 4031/6926 [21:51:57&lt;11:46:30, 14.64s/it]

{'epoch': 1, 'iter': 4030, 'avg_loss': 5.794494402967532, 'avg_acc': 49.92325105432895, 'loss': 5.922822952270508}


EP_train:1:  58%|| 4041/6926 [21:54:21&lt;11:25:22, 14.25s/it]

{'epoch': 1, 'iter': 4040, 'avg_loss': 5.794372910469129, 'avg_acc': 49.929627567433805, 'loss': 5.785887241363525}


EP_train:1:  58%|| 4051/6926 [21:56:42&lt;11:19:09, 14.17s/it]

{'epoch': 1, 'iter': 4050, 'avg_loss': 5.794430562402843, 'avg_acc': 49.929029869168104, 'loss': 5.535454273223877}


EP_train:1:  59%|| 4061/6926 [21:59:02&lt;11:07:50, 13.99s/it]

{'epoch': 1, 'iter': 4060, 'avg_loss': 5.794532713059926, 'avg_acc': 49.921509480423545, 'loss': 5.970178604125977}


EP_train:1:  59%|| 4071/6926 [22:01:22&lt;11:01:04, 13.89s/it]

{'epoch': 1, 'iter': 4070, 'avg_loss': 5.794323054791317, 'avg_acc': 49.91939941046426, 'loss': 5.706122875213623}


EP_train:1:  59%|| 4081/6926 [22:03:39&lt;10:46:51, 13.64s/it]

{'epoch': 1, 'iter': 4080, 'avg_loss': 5.79427270204581, 'avg_acc': 49.91883116883117, 'loss': 5.926842212677002}


EP_train:1:  59%|| 4091/6926 [22:05:55&lt;10:42:52, 13.61s/it]

{'epoch': 1, 'iter': 4090, 'avg_loss': 5.794327908173018, 'avg_acc': 49.924376680518215, 'loss': 5.8620381355285645}


EP_train:1:  59%|| 4101/6926 [22:08:10&lt;10:34:33, 13.48s/it]

{'epoch': 1, 'iter': 4100, 'avg_loss': 5.794293555013438, 'avg_acc': 49.925323091928796, 'loss': 6.033656120300293}


EP_train:1:  59%|| 4111/6926 [22:10:23&lt;10:24:16, 13.31s/it]

{'epoch': 1, 'iter': 4110, 'avg_loss': 5.794242945415671, 'avg_acc': 49.92018365361226, 'loss': 5.560708522796631}


EP_train:1:  60%|| 4121/6926 [22:12:34&lt;10:12:20, 13.10s/it]

{'epoch': 1, 'iter': 4120, 'avg_loss': 5.794160013724172, 'avg_acc': 49.91582746906091, 'loss': 6.027267932891846}


EP_train:1:  60%|| 4131/6926 [22:14:44&lt;10:08:10, 13.06s/it]

{'epoch': 1, 'iter': 4130, 'avg_loss': 5.793972036042649, 'avg_acc': 49.90846647300896, 'loss': 5.352296352386475}


EP_train:1:  60%|| 4141/6926 [22:16:53&lt;9:58:12, 12.89s/it] 

{'epoch': 1, 'iter': 4140, 'avg_loss': 5.79385355399214, 'avg_acc': 49.901895677372615, 'loss': 5.622790813446045}


EP_train:1:  60%|| 4151/6926 [22:19:02&lt;9:59:10, 12.96s/it]

{'epoch': 1, 'iter': 4150, 'avg_loss': 5.793552322291202, 'avg_acc': 49.90137918573838, 'loss': 5.768672943115234}


EP_train:1:  60%|| 4161/6926 [22:21:10&lt;9:45:22, 12.70s/it]

{'epoch': 1, 'iter': 4160, 'avg_loss': 5.793569183555883, 'avg_acc': 49.895608026916605, 'loss': 5.898829460144043}


EP_train:1:  60%|| 4171/6926 [22:23:16&lt;9:38:30, 12.60s/it]

{'epoch': 1, 'iter': 4170, 'avg_loss': 5.793333467777557, 'avg_acc': 49.89585830736035, 'loss': 5.702149391174316}


EP_train:1:  60%|| 4181/6926 [22:25:22&lt;9:30:18, 12.47s/it]

{'epoch': 1, 'iter': 4180, 'avg_loss': 5.793202239399006, 'avg_acc': 49.89237024635255, 'loss': 6.27134895324707}


EP_train:1:  61%|| 4191/6926 [22:27:26&lt;9:24:02, 12.37s/it]

{'epoch': 1, 'iter': 4190, 'avg_loss': 5.793524647805777, 'avg_acc': 49.89784657599618, 'loss': 6.174899101257324}


EP_train:1:  61%|| 4201/6926 [22:29:29&lt;9:16:32, 12.25s/it]

{'epoch': 1, 'iter': 4200, 'avg_loss': 5.793787608229526, 'avg_acc': 49.89808974053796, 'loss': 5.691822052001953}


EP_train:1:  61%|| 4211/6926 [22:31:31&lt;9:13:11, 12.23s/it]

{'epoch': 1, 'iter': 4210, 'avg_loss': 5.7935389137358655, 'avg_acc': 49.89016860603182, 'loss': 5.811758041381836}


EP_train:1:  61%|| 4221/6926 [22:33:31&lt;8:58:32, 11.95s/it]

{'epoch': 1, 'iter': 4220, 'avg_loss': 5.793146554227972, 'avg_acc': 49.895611229566455, 'loss': 5.675384998321533}


EP_train:1:  61%|| 4231/6926 [22:35:30&lt;8:57:14, 11.96s/it]

{'epoch': 1, 'iter': 4230, 'avg_loss': 5.793019925750646, 'avg_acc': 49.88994918458993, 'loss': 5.687623977661133}


EP_train:1:  61%|| 4241/6926 [22:37:28&lt;8:43:06, 11.69s/it]

{'epoch': 1, 'iter': 4240, 'avg_loss': 5.792919600130786, 'avg_acc': 49.901261494930445, 'loss': 6.263227462768555}


EP_train:1:  61%|| 4251/6926 [22:39:23&lt;8:31:24, 11.47s/it]

{'epoch': 1, 'iter': 4250, 'avg_loss': 5.792667934962425, 'avg_acc': 49.90810985650435, 'loss': 5.616147041320801}


EP_train:1:  62%|| 4261/6926 [22:41:17&lt;8:19:48, 11.25s/it]

{'epoch': 1, 'iter': 4260, 'avg_loss': 5.7923400158670635, 'avg_acc': 49.90832551044356, 'loss': 5.353346824645996}


EP_train:1:  62%|| 4271/6926 [22:43:09&lt;8:12:14, 11.12s/it]

{'epoch': 1, 'iter': 4270, 'avg_loss': 5.7925298052631256, 'avg_acc': 49.91000351205807, 'loss': 6.090911865234375}


EP_train:1:  62%|| 4281/6926 [22:44:59&lt;8:06:40, 11.04s/it]

{'epoch': 1, 'iter': 4280, 'avg_loss': 5.792039564796988, 'avg_acc': 49.9145935529082, 'loss': 5.736459255218506}


EP_train:1:  62%|| 4291/6926 [22:46:48&lt;7:57:58, 10.88s/it]

{'epoch': 1, 'iter': 4290, 'avg_loss': 5.792303221344087, 'avg_acc': 49.91115124679562, 'loss': 5.262261867523193}


EP_train:1:  62%|| 4301/6926 [22:48:38&lt;7:59:20, 10.96s/it]

{'epoch': 1, 'iter': 4300, 'avg_loss': 5.792396713151291, 'avg_acc': 49.90263892118112, 'loss': 5.961178302764893}


EP_train:1:  62%|| 4311/6926 [22:50:27&lt;7:52:27, 10.84s/it]

{'epoch': 1, 'iter': 4310, 'avg_loss': 5.792013904551181, 'avg_acc': 49.90866388308977, 'loss': 5.368079662322998}


EP_train:1:  62%|| 4321/6926 [22:52:15&lt;7:47:57, 10.78s/it]

{'epoch': 1, 'iter': 4320, 'avg_loss': 5.791845591800463, 'avg_acc': 49.919000231427916, 'loss': 5.8557209968566895}


EP_train:1:  63%|| 4331/6926 [22:54:02&lt;7:44:36, 10.74s/it]

{'epoch': 1, 'iter': 4330, 'avg_loss': 5.791850880865301, 'avg_acc': 49.922794966520435, 'loss': 5.736635684967041}


EP_train:1:  63%|| 4341/6926 [22:55:49&lt;7:42:25, 10.73s/it]

{'epoch': 1, 'iter': 4340, 'avg_loss': 5.791390453937058, 'avg_acc': 49.93305114029026, 'loss': 5.70697021484375}


EP_train:1:  63%|| 4351/6926 [22:57:35&lt;7:33:16, 10.56s/it]

{'epoch': 1, 'iter': 4350, 'avg_loss': 5.791365481003814, 'avg_acc': 49.92817743047575, 'loss': 5.999698638916016}


EP_train:1:  63%|| 4361/6926 [22:59:19&lt;7:25:05, 10.41s/it]

{'epoch': 1, 'iter': 4360, 'avg_loss': 5.791415565195939, 'avg_acc': 49.93264159596423, 'loss': 5.592486381530762}


EP_train:1:  63%|| 4371/6926 [23:01:02&lt;7:13:48, 10.19s/it]

{'epoch': 1, 'iter': 4370, 'avg_loss': 5.791266237126693, 'avg_acc': 49.928506062685884, 'loss': 5.677746772766113}


EP_train:1:  63%|| 4381/6926 [23:02:43&lt;7:11:54, 10.18s/it]

{'epoch': 1, 'iter': 4380, 'avg_loss': 5.791361003236612, 'avg_acc': 49.94150878794796, 'loss': 5.427810192108154}


EP_train:1:  63%|| 4391/6926 [23:04:26&lt;7:11:05, 10.20s/it]

{'epoch': 1, 'iter': 4390, 'avg_loss': 5.791563838089118, 'avg_acc': 49.93737189706217, 'loss': 6.359541893005371}


EP_train:1:  64%|| 4401/6926 [23:06:08&lt;7:10:25, 10.23s/it]

{'epoch': 1, 'iter': 4400, 'avg_loss': 5.791609601577935, 'avg_acc': 49.928283344694385, 'loss': 6.141855716705322}


EP_train:1:  64%|| 4411/6926 [23:07:47&lt;6:54:27,  9.89s/it]

{'epoch': 1, 'iter': 4410, 'avg_loss': 5.791563305933711, 'avg_acc': 49.93127975515756, 'loss': 5.503215789794922}


EP_train:1:  64%|| 4421/6926 [23:09:25&lt;6:48:06,  9.77s/it]

{'epoch': 1, 'iter': 4420, 'avg_loss': 5.791686383018503, 'avg_acc': 49.93779687853427, 'loss': 5.017365455627441}


EP_train:1:  64%|| 4431/6926 [23:11:03&lt;6:42:23,  9.68s/it]

{'epoch': 1, 'iter': 4430, 'avg_loss': 5.791787002781287, 'avg_acc': 49.929474159331974, 'loss': 5.570000648498535}


EP_train:1:  64%|| 4441/6926 [23:12:39&lt;6:32:18,  9.47s/it]

{'epoch': 1, 'iter': 4440, 'avg_loss': 5.79137702472466, 'avg_acc': 49.933151317270884, 'loss': 5.4280686378479}


EP_train:1:  64%|| 4451/6926 [23:14:13&lt;6:26:55,  9.38s/it]

{'epoch': 1, 'iter': 4450, 'avg_loss': 5.791135346265461, 'avg_acc': 49.93119523702539, 'loss': 5.561283111572266}


EP_train:1:  64%|| 4461/6926 [23:15:48&lt;6:32:12,  9.55s/it]

{'epoch': 1, 'iter': 4460, 'avg_loss': 5.790786760480274, 'avg_acc': 49.932750504371214, 'loss': 5.831860065460205}


EP_train:1:  65%|| 4471/6926 [23:17:21&lt;6:19:34,  9.28s/it]

{'epoch': 1, 'iter': 4470, 'avg_loss': 5.7904958413554315, 'avg_acc': 49.93220196823977, 'loss': 5.783606052398682}


EP_train:1:  65%|| 4481/6926 [23:18:54&lt;6:15:03,  9.20s/it]

{'epoch': 1, 'iter': 4480, 'avg_loss': 5.790014457234419, 'avg_acc': 49.92537937960277, 'loss': 5.5710649490356445}


EP_train:1:  65%|| 4491/6926 [23:20:24&lt;6:09:03,  9.09s/it]

{'epoch': 1, 'iter': 4490, 'avg_loss': 5.789725657959766, 'avg_acc': 49.92624137163215, 'loss': 5.569758892059326}


EP_train:1:  65%|| 4501/6926 [23:21:54&lt;6:00:42,  8.92s/it]

{'epoch': 1, 'iter': 4500, 'avg_loss': 5.78943614423659, 'avg_acc': 49.929876694067985, 'loss': 5.799868106842041}


EP_train:1:  65%|| 4511/6926 [23:23:24&lt;5:59:54,  8.94s/it]

{'epoch': 1, 'iter': 4510, 'avg_loss': 5.789443961481539, 'avg_acc': 49.93280314786078, 'loss': 6.369606971740723}


EP_train:1:  65%|| 4521/6926 [23:24:52&lt;5:55:48,  8.88s/it]

{'epoch': 1, 'iter': 4520, 'avg_loss': 5.789692890430493, 'avg_acc': 49.930878124308784, 'loss': 6.097248554229736}


EP_train:1:  65%|| 4531/6926 [23:26:18&lt;5:46:32,  8.68s/it]

{'epoch': 1, 'iter': 4530, 'avg_loss': 5.789552313948382, 'avg_acc': 49.93447914367689, 'loss': 6.212596416473389}


EP_train:1:  66%|| 4541/6926 [23:27:43&lt;5:36:53,  8.48s/it]

{'epoch': 1, 'iter': 4540, 'avg_loss': 5.789276582032829, 'avg_acc': 49.94081700066065, 'loss': 5.68822717666626}


EP_train:1:  66%|| 4551/6926 [23:29:07&lt;5:32:37,  8.40s/it]

{'epoch': 1, 'iter': 4550, 'avg_loss': 5.788956431445643, 'avg_acc': 49.92790046143705, 'loss': 5.529911994934082}


EP_train:1:  66%|| 4561/6926 [23:30:32&lt;5:35:45,  8.52s/it]

{'epoch': 1, 'iter': 4560, 'avg_loss': 5.788553897917885, 'avg_acc': 49.94244683183513, 'loss': 5.255894660949707}


EP_train:1:  66%|| 4571/6926 [23:31:55&lt;5:26:48,  8.33s/it]

{'epoch': 1, 'iter': 4570, 'avg_loss': 5.788283214034984, 'avg_acc': 49.952143950995406, 'loss': 5.589775085449219}


EP_train:1:  66%|| 4581/6926 [23:33:18&lt;5:22:50,  8.26s/it]

{'epoch': 1, 'iter': 4580, 'avg_loss': 5.78847688016244, 'avg_acc': 49.95361274830823, 'loss': 5.636112213134766}


EP_train:1:  66%|| 4591/6926 [23:34:40&lt;5:19:28,  8.21s/it]

{'epoch': 1, 'iter': 4590, 'avg_loss': 5.788426787680308, 'avg_acc': 49.949629710302766, 'loss': 6.208221912384033}


EP_train:1:  66%|| 4601/6926 [23:36:01&lt;5:13:15,  8.08s/it]

{'epoch': 1, 'iter': 4600, 'avg_loss': 5.788588617553247, 'avg_acc': 49.93819278417735, 'loss': 5.983859539031982}


EP_train:1:  67%|| 4611/6926 [23:37:20&lt;5:05:21,  7.91s/it]

{'epoch': 1, 'iter': 4610, 'avg_loss': 5.788734662406125, 'avg_acc': 49.93697137280416, 'loss': 6.003018856048584}


EP_train:1:  67%|| 4621/6926 [23:38:39&lt;5:02:50,  7.88s/it]

{'epoch': 1, 'iter': 4620, 'avg_loss': 5.788934172605751, 'avg_acc': 49.939812811079854, 'loss': 6.00796365737915}


EP_train:1:  67%|| 4631/6926 [23:39:58&lt;5:02:32,  7.91s/it]

{'epoch': 1, 'iter': 4630, 'avg_loss': 5.789179396459439, 'avg_acc': 49.93589397538329, 'loss': 6.413631916046143}


EP_train:1:  67%|| 4641/6926 [23:41:17&lt;5:02:06,  7.93s/it]

{'epoch': 1, 'iter': 4640, 'avg_loss': 5.789161979882426, 'avg_acc': 49.9306453350571, 'loss': 5.865474224090576}


EP_train:1:  67%|| 4651/6926 [23:42:37&lt;5:01:00,  7.94s/it]

{'epoch': 1, 'iter': 4650, 'avg_loss': 5.788921422226355, 'avg_acc': 49.92945065577295, 'loss': 5.805312156677246}


EP_train:1:  67%|| 4661/6926 [23:43:55&lt;4:53:35,  7.78s/it]

{'epoch': 1, 'iter': 4660, 'avg_loss': 5.788980215257188, 'avg_acc': 49.932283844668525, 'loss': 5.606457710266113}


EP_train:1:  67%|| 4671/6926 [23:45:12&lt;4:49:20,  7.70s/it]

{'epoch': 1, 'iter': 4670, 'avg_loss': 5.789101604424102, 'avg_acc': 49.93242881609934, 'loss': 5.404266357421875}


EP_train:1:  68%|| 4681/6926 [23:46:29&lt;4:48:08,  7.70s/it]

{'epoch': 1, 'iter': 4680, 'avg_loss': 5.789283708944404, 'avg_acc': 49.94125186925871, 'loss': 5.393746852874756}


EP_train:1:  68%|| 4691/6926 [23:47:45&lt;4:39:49,  7.51s/it]

{'epoch': 1, 'iter': 4690, 'avg_loss': 5.789118626610198, 'avg_acc': 49.934715412492004, 'loss': 5.847562789916992}


EP_train:1:  68%|| 4701/6926 [23:49:00&lt;4:41:44,  7.60s/it]

{'epoch': 1, 'iter': 4700, 'avg_loss': 5.78872311822761, 'avg_acc': 49.93418953414167, 'loss': 5.54182767868042}


EP_train:1:  68%|| 4711/6926 [23:50:15&lt;4:36:25,  7.49s/it]

{'epoch': 1, 'iter': 4710, 'avg_loss': 5.788682299544922, 'avg_acc': 49.93432922946296, 'loss': 5.763123035430908}


EP_train:1:  68%|| 4721/6926 [23:51:30&lt;4:35:43,  7.50s/it]

{'epoch': 1, 'iter': 4720, 'avg_loss': 5.7887042617676645, 'avg_acc': 49.93579220504131, 'loss': 5.008922100067139}


EP_train:1:  68%|| 4731/6926 [23:52:43&lt;4:24:42,  7.24s/it]

{'epoch': 1, 'iter': 4730, 'avg_loss': 5.788827963143468, 'avg_acc': 49.9385700697527, 'loss': 6.348005294799805}


EP_train:1:  68%|| 4741/6926 [23:53:56&lt;4:24:02,  7.25s/it]

{'epoch': 1, 'iter': 4740, 'avg_loss': 5.788779858973579, 'avg_acc': 49.936063066863525, 'loss': 5.833249568939209}


EP_train:1:  69%|| 4751/6926 [23:55:08&lt;4:19:19,  7.15s/it]

{'epoch': 1, 'iter': 4750, 'avg_loss': 5.7885240177635495, 'avg_acc': 49.93882866764891, 'loss': 5.320862770080566}


EP_train:1:  69%|| 4761/6926 [23:56:20&lt;4:18:29,  7.16s/it]

{'epoch': 1, 'iter': 4760, 'avg_loss': 5.788583486777748, 'avg_acc': 49.930424280613316, 'loss': 6.05222749710083}


EP_train:1:  69%|| 4771/6926 [23:57:31&lt;4:16:08,  7.13s/it]

{'epoch': 1, 'iter': 4770, 'avg_loss': 5.788538340226931, 'avg_acc': 49.922055124711804, 'loss': 5.370018482208252}


EP_train:1:  69%|| 4781/6926 [23:58:43&lt;4:16:44,  7.18s/it]

{'epoch': 1, 'iter': 4780, 'avg_loss': 5.788333303084111, 'avg_acc': 49.92156452624974, 'loss': 6.177128314971924}


EP_train:1:  69%|| 4791/6926 [23:59:54&lt;4:11:23,  7.06s/it]

{'epoch': 1, 'iter': 4790, 'avg_loss': 5.788014187889441, 'avg_acc': 49.91846691713629, 'loss': 5.8995232582092285}


EP_train:1:  69%|| 4801/6926 [24:01:04&lt;4:08:19,  7.01s/it]

{'epoch': 1, 'iter': 4800, 'avg_loss': 5.788256717209914, 'avg_acc': 49.92254217871277, 'loss': 5.670840263366699}


EP_train:1:  69%|| 4811/6926 [24:02:13&lt;4:02:50,  6.89s/it]

{'epoch': 1, 'iter': 4810, 'avg_loss': 5.788121572330771, 'avg_acc': 49.910361671170236, 'loss': 5.873446941375732}


EP_train:1:  70%|| 4821/6926 [24:03:23&lt;4:03:00,  6.93s/it]

{'epoch': 1, 'iter': 4820, 'avg_loss': 5.787842813059394, 'avg_acc': 49.912492221530805, 'loss': 5.583961009979248}


EP_train:1:  70%|| 4831/6926 [24:04:30&lt;3:54:22,  6.71s/it]

{'epoch': 1, 'iter': 4830, 'avg_loss': 5.787578386836999, 'avg_acc': 49.912026495549576, 'loss': 5.802366733551025}


EP_train:1:  70%|| 4841/6926 [24:05:37&lt;3:51:06,  6.65s/it]

{'epoch': 1, 'iter': 4840, 'avg_loss': 5.787446636080963, 'avg_acc': 49.906398471390204, 'loss': 6.0409369468688965}


EP_train:1:  70%|| 4851/6926 [24:06:43&lt;3:50:05,  6.65s/it]

{'epoch': 1, 'iter': 4850, 'avg_loss': 5.787142503730933, 'avg_acc': 49.904658833230265, 'loss': 5.501993179321289}


EP_train:1:  70%|| 4861/6926 [24:07:48&lt;3:45:09,  6.54s/it]

{'epoch': 1, 'iter': 4860, 'avg_loss': 5.787131439092056, 'avg_acc': 49.90871219913598, 'loss': 5.414707183837891}


EP_train:1:  70%|| 4871/6926 [24:08:54&lt;3:46:09,  6.60s/it]

{'epoch': 1, 'iter': 4870, 'avg_loss': 5.787226953390956, 'avg_acc': 49.91146581810717, 'loss': 5.188268661499023}


EP_train:1:  70%|| 4881/6926 [24:09:59&lt;3:41:48,  6.51s/it]

{'epoch': 1, 'iter': 4880, 'avg_loss': 5.787362124875441, 'avg_acc': 49.9039643515673, 'loss': 5.624892234802246}


EP_train:1:  71%|| 4891/6926 [24:11:03&lt;3:35:34,  6.36s/it]

{'epoch': 1, 'iter': 4890, 'avg_loss': 5.787320288820175, 'avg_acc': 49.91821713351053, 'loss': 5.858331680297852}


EP_train:1:  71%|| 4901/6926 [24:12:07&lt;3:35:56,  6.40s/it]

{'epoch': 1, 'iter': 4900, 'avg_loss': 5.787399033871604, 'avg_acc': 49.92093450316262, 'loss': 5.9390363693237305}


EP_train:1:  71%|| 4911/6926 [24:13:10&lt;3:33:10,  6.35s/it]

{'epoch': 1, 'iter': 4910, 'avg_loss': 5.787554553219705, 'avg_acc': 49.92236815312563, 'loss': 6.048376083374023}


EP_train:1:  71%|| 4921/6926 [24:14:13&lt;3:29:15,  6.26s/it]

{'epoch': 1, 'iter': 4920, 'avg_loss': 5.787447882483486, 'avg_acc': 49.92697114407641, 'loss': 5.413477897644043}


EP_train:1:  71%|| 4931/6926 [24:15:16&lt;3:28:16,  6.26s/it]

{'epoch': 1, 'iter': 4930, 'avg_loss': 5.787312490513155, 'avg_acc': 49.92521800851754, 'loss': 5.5958638191223145}


EP_train:1:  71%|| 4941/6926 [24:16:18&lt;3:26:48,  6.25s/it]

{'epoch': 1, 'iter': 4940, 'avg_loss': 5.787154680899439, 'avg_acc': 49.92663428455778, 'loss': 5.397399425506592}


EP_train:1:  71%|| 4951/6926 [24:17:21&lt;3:24:41,  6.22s/it]

{'epoch': 1, 'iter': 4950, 'avg_loss': 5.787053776519319, 'avg_acc': 49.917945869521304, 'loss': 5.379844665527344}


EP_train:1:  72%|| 4961/6926 [24:18:23&lt;3:23:33,  6.22s/it]

{'epoch': 1, 'iter': 4960, 'avg_loss': 5.787061457046696, 'avg_acc': 49.91874118121346, 'loss': 5.6148505210876465}


EP_train:1:  72%|| 4971/6926 [24:19:24&lt;3:19:40,  6.13s/it]

{'epoch': 1, 'iter': 4970, 'avg_loss': 5.786740227931223, 'avg_acc': 49.920161939247635, 'loss': 5.569698333740234}


EP_train:1:  72%|| 4981/6926 [24:20:26&lt;3:20:32,  6.19s/it]

{'epoch': 1, 'iter': 4980, 'avg_loss': 5.78702146129612, 'avg_acc': 49.92659606504718, 'loss': 5.415506839752197}


EP_train:1:  72%|| 4991/6926 [24:21:27&lt;3:16:27,  6.09s/it]

{'epoch': 1, 'iter': 4990, 'avg_loss': 5.786872534731828, 'avg_acc': 49.92987377279102, 'loss': 5.665578842163086}


EP_train:1:  72%|| 5001/6926 [24:22:27&lt;3:14:32,  6.06s/it]

{'epoch': 1, 'iter': 5000, 'avg_loss': 5.786735336057331, 'avg_acc': 49.92314037192562, 'loss': 5.924252510070801}


EP_train:1:  72%|| 5011/6926 [24:23:28&lt;3:11:49,  6.01s/it]

{'epoch': 1, 'iter': 5010, 'avg_loss': 5.786793859151042, 'avg_acc': 49.9351426860906, 'loss': 6.492675304412842}


EP_train:1:  72%|| 5021/6926 [24:24:28&lt;3:10:16,  5.99s/it]

{'epoch': 1, 'iter': 5020, 'avg_loss': 5.786595426501328, 'avg_acc': 49.937761402111136, 'loss': 5.4357686042785645}


EP_train:1:  73%|| 5031/6926 [24:25:27&lt;3:07:46,  5.95s/it]

{'epoch': 1, 'iter': 5030, 'avg_loss': 5.7865324396661535, 'avg_acc': 49.939127410057644, 'loss': 5.767693519592285}


EP_train:1:  73%|| 5041/6926 [24:26:26&lt;3:04:39,  5.88s/it]

{'epoch': 1, 'iter': 5040, 'avg_loss': 5.786570438055073, 'avg_acc': 49.93304899821464, 'loss': 5.453466415405273}


EP_train:1:  73%|| 5051/6926 [24:27:24&lt;3:02:07,  5.83s/it]

{'epoch': 1, 'iter': 5050, 'avg_loss': 5.7864458643547545, 'avg_acc': 49.933181548208275, 'loss': 5.8941731452941895}


EP_train:1:  73%|| 5061/6926 [24:28:23&lt;3:02:16,  5.86s/it]

{'epoch': 1, 'iter': 5060, 'avg_loss': 5.786396266678722, 'avg_acc': 49.93146117368109, 'loss': 5.800904750823975}


EP_train:1:  73%|| 5071/6926 [24:29:21&lt;2:59:03,  5.79s/it]

{'epoch': 1, 'iter': 5070, 'avg_loss': 5.786205190945555, 'avg_acc': 49.9346775783869, 'loss': 5.469834327697754}


EP_train:1:  73%|| 5081/6926 [24:30:18&lt;2:56:08,  5.73s/it]

{'epoch': 1, 'iter': 5080, 'avg_loss': 5.785916267054167, 'avg_acc': 49.93542117693367, 'loss': 5.56289529800415}


EP_train:1:  74%|| 5091/6926 [24:31:15&lt;2:54:03,  5.69s/it]

{'epoch': 1, 'iter': 5090, 'avg_loss': 5.7859456138745715, 'avg_acc': 49.93677568257709, 'loss': 5.786680221557617}


EP_train:1:  74%|| 5101/6926 [24:32:12&lt;2:52:22,  5.67s/it]

{'epoch': 1, 'iter': 5100, 'avg_loss': 5.785936889917657, 'avg_acc': 49.9387375024505, 'loss': 5.944669723510742}


EP_train:1:  74%|| 5111/6926 [24:33:09&lt;2:52:03,  5.69s/it]

{'epoch': 1, 'iter': 5110, 'avg_loss': 5.785903461104012, 'avg_acc': 49.92968597143416, 'loss': 5.812314510345459}


EP_train:1:  74%|| 5121/6926 [24:34:06&lt;2:49:20,  5.63s/it]

{'epoch': 1, 'iter': 5120, 'avg_loss': 5.785528050947645, 'avg_acc': 49.91944932630346, 'loss': 5.632965564727783}


EP_train:1:  74%|| 5131/6926 [24:35:02&lt;2:47:46,  5.61s/it]

{'epoch': 1, 'iter': 5130, 'avg_loss': 5.785435689678203, 'avg_acc': 49.93117813291756, 'loss': 5.793095588684082}


EP_train:1:  74%|| 5141/6926 [24:35:59&lt;2:48:35,  5.67s/it]

{'epoch': 1, 'iter': 5140, 'avg_loss': 5.785562406553645, 'avg_acc': 49.94103773584906, 'loss': 6.014484882354736}


EP_train:1:  74%|| 5151/6926 [24:36:55&lt;2:46:17,  5.62s/it]

{'epoch': 1, 'iter': 5150, 'avg_loss': 5.785854521965986, 'avg_acc': 49.95328576975345, 'loss': 6.094200611114502}


EP_train:1:  75%|| 5161/6926 [24:37:50&lt;2:42:45,  5.53s/it]

{'epoch': 1, 'iter': 5160, 'avg_loss': 5.78595069091788, 'avg_acc': 49.95216527804689, 'loss': 5.796298503875732}


EP_train:1:  75%|| 5171/6926 [24:38:46&lt;2:42:56,  5.57s/it]

{'epoch': 1, 'iter': 5170, 'avg_loss': 5.785935990977762, 'avg_acc': 49.95165345194353, 'loss': 5.894540309906006}


EP_train:1:  75%|| 5181/6926 [24:39:41&lt;2:40:25,  5.52s/it]

{'epoch': 1, 'iter': 5180, 'avg_loss': 5.785864553817841, 'avg_acc': 49.95295309785755, 'loss': 5.792293548583984}


EP_train:1:  75%|| 5191/6926 [24:40:35&lt;2:36:49,  5.42s/it]

{'epoch': 1, 'iter': 5190, 'avg_loss': 5.785756077065539, 'avg_acc': 49.9488297052591, 'loss': 5.8627824783325195}


EP_train:1:  75%|| 5201/6926 [24:41:29&lt;2:34:54,  5.39s/it]

{'epoch': 1, 'iter': 5200, 'avg_loss': 5.785612379810118, 'avg_acc': 49.94952893674293, 'loss': 5.686365127563477}


EP_train:1:  75%|| 5211/6926 [24:42:23&lt;2:33:07,  5.36s/it]

{'epoch': 1, 'iter': 5210, 'avg_loss': 5.785322140741431, 'avg_acc': 49.95082517750912, 'loss': 5.074163436889648}


EP_train:1:  75%|| 5221/6926 [24:43:17&lt;2:32:20,  5.36s/it]

{'epoch': 1, 'iter': 5220, 'avg_loss': 5.785333730141977, 'avg_acc': 49.94493392070485, 'loss': 6.03475284576416}


EP_train:1:  76%|| 5231/6926 [24:44:10&lt;2:29:47,  5.30s/it]

{'epoch': 1, 'iter': 5230, 'avg_loss': 5.7852302342339925, 'avg_acc': 49.94503918944753, 'loss': 5.761468410491943}


EP_train:1:  76%|| 5241/6926 [24:45:04&lt;2:30:22,  5.35s/it]

{'epoch': 1, 'iter': 5240, 'avg_loss': 5.785118418098338, 'avg_acc': 49.94037397443236, 'loss': 5.688961982727051}


EP_train:1:  76%|| 5251/6926 [24:45:57&lt;2:27:52,  5.30s/it]

{'epoch': 1, 'iter': 5250, 'avg_loss': 5.78509274066641, 'avg_acc': 49.936321653018474, 'loss': 5.434635162353516}


EP_train:1:  76%|| 5261/6926 [24:46:50&lt;2:27:38,  5.32s/it]

{'epoch': 1, 'iter': 5260, 'avg_loss': 5.7850141297771644, 'avg_acc': 49.935254704428814, 'loss': 5.639525413513184}


EP_train:1:  76%|| 5271/6926 [24:47:44&lt;2:27:15,  5.34s/it]

{'epoch': 1, 'iter': 5270, 'avg_loss': 5.785223968384999, 'avg_acc': 49.92944887118193, 'loss': 5.607095241546631}


EP_train:1:  76%|| 5281/6926 [24:48:37&lt;2:24:16,  5.26s/it]

{'epoch': 1, 'iter': 5280, 'avg_loss': 5.785083117301752, 'avg_acc': 49.92780723347851, 'loss': 5.321253299713135}


EP_train:1:  76%|| 5291/6926 [24:49:29&lt;2:23:46,  5.28s/it]

{'epoch': 1, 'iter': 5290, 'avg_loss': 5.785107800154397, 'avg_acc': 49.92026554526554, 'loss': 5.930552959442139}


EP_train:1:  77%|| 5301/6926 [24:50:23&lt;2:23:56,  5.32s/it]

{'epoch': 1, 'iter': 5300, 'avg_loss': 5.785208872097255, 'avg_acc': 49.91687889077532, 'loss': 5.997699737548828}


EP_train:1:  77%|| 5311/6926 [24:51:16&lt;2:22:08,  5.28s/it]

{'epoch': 1, 'iter': 5310, 'avg_loss': 5.7851737416906115, 'avg_acc': 49.92056580681604, 'loss': 5.9337663650512695}


EP_train:1:  77%|| 5321/6926 [24:52:08&lt;2:18:40,  5.18s/it]

{'epoch': 1, 'iter': 5320, 'avg_loss': 5.785334258302668, 'avg_acc': 49.923064273632775, 'loss': 5.717741966247559}


EP_train:1:  77%|| 5331/6926 [24:52:59&lt;2:16:15,  5.13s/it]

{'epoch': 1, 'iter': 5330, 'avg_loss': 5.785141843811161, 'avg_acc': 49.926139561057965, 'loss': 6.1371846199035645}


EP_train:1:  77%|| 5341/6926 [24:53:51&lt;2:17:27,  5.20s/it]

{'epoch': 1, 'iter': 5340, 'avg_loss': 5.784899124155507, 'avg_acc': 49.921597079198655, 'loss': 5.609897613525391}


EP_train:1:  77%|| 5351/6926 [24:54:42&lt;2:14:15,  5.11s/it]

{'epoch': 1, 'iter': 5350, 'avg_loss': 5.784700462916614, 'avg_acc': 49.91707157540647, 'loss': 5.650408744812012}


EP_train:1:  77%|| 5361/6926 [24:55:33&lt;2:13:07,  5.10s/it]

{'epoch': 1, 'iter': 5360, 'avg_loss': 5.784607118511573, 'avg_acc': 49.91722626375677, 'loss': 5.6946563720703125}


EP_train:1:  78%|| 5371/6926 [24:56:24&lt;2:11:34,  5.08s/it]

{'epoch': 1, 'iter': 5370, 'avg_loss': 5.784720784746453, 'avg_acc': 49.916216719419104, 'loss': 6.1461615562438965}


EP_train:1:  78%|| 5381/6926 [24:57:14&lt;2:10:16,  5.06s/it]

{'epoch': 1, 'iter': 5380, 'avg_loss': 5.784454568215317, 'avg_acc': 49.917533915629065, 'loss': 5.918368816375732}


EP_train:1:  78%|| 5391/6926 [24:58:05&lt;2:09:56,  5.08s/it]

{'epoch': 1, 'iter': 5390, 'avg_loss': 5.784659076546323, 'avg_acc': 49.911890187349286, 'loss': 6.016552925109863}


EP_train:1:  78%|| 5401/6926 [24:58:56&lt;2:08:24,  5.05s/it]

{'epoch': 1, 'iter': 5400, 'avg_loss': 5.784735913145125, 'avg_acc': 49.91089613034623, 'loss': 6.018709182739258}


EP_train:1:  78%|| 5411/6926 [24:59:47&lt;2:08:12,  5.08s/it]

{'epoch': 1, 'iter': 5410, 'avg_loss': 5.784527376605323, 'avg_acc': 49.909328220292, 'loss': 5.77882719039917}


EP_train:1:  78%|| 5421/6926 [25:00:38&lt;2:08:26,  5.12s/it]

{'epoch': 1, 'iter': 5420, 'avg_loss': 5.784672113037532, 'avg_acc': 49.91698948533481, 'loss': 5.923573970794678}


EP_train:1:  78%|| 5431/6926 [25:01:29&lt;2:06:12,  5.07s/it]

{'epoch': 1, 'iter': 5430, 'avg_loss': 5.784611293699307, 'avg_acc': 49.92174553489229, 'loss': 6.211486339569092}


EP_train:1:  79%|| 5441/6926 [25:02:20&lt;2:05:04,  5.05s/it]

{'epoch': 1, 'iter': 5440, 'avg_loss': 5.7847099865081, 'avg_acc': 49.91442290020217, 'loss': 6.249625205993652}


EP_train:1:  79%|| 5451/6926 [25:03:10&lt;2:03:36,  5.03s/it]

{'epoch': 1, 'iter': 5450, 'avg_loss': 5.7844880132407495, 'avg_acc': 49.90942028985507, 'loss': 6.039062023162842}


EP_train:1:  79%|| 5461/6926 [25:04:00&lt;2:03:24,  5.05s/it]

{'epoch': 1, 'iter': 5460, 'avg_loss': 5.784443095105403, 'avg_acc': 49.90844167734847, 'loss': 5.641089916229248}


EP_train:1:  79%|| 5471/6926 [25:04:51&lt;2:00:24,  4.97s/it]

{'epoch': 1, 'iter': 5470, 'avg_loss': 5.784420987845469, 'avg_acc': 49.91603454578687, 'loss': 5.327508926391602}


EP_train:1:  79%|| 5481/6926 [25:05:41&lt;2:00:36,  5.01s/it]

{'epoch': 1, 'iter': 5480, 'avg_loss': 5.784344418078003, 'avg_acc': 49.91162652800584, 'loss': 5.988985061645508}


EP_train:1:  79%|| 5491/6926 [25:06:31&lt;1:59:13,  4.99s/it]

{'epoch': 1, 'iter': 5490, 'avg_loss': 5.7845592009003015, 'avg_acc': 49.91634037515935, 'loss': 5.780298233032227}


EP_train:1:  79%|| 5501/6926 [25:07:21&lt;1:58:58,  5.01s/it]

{'epoch': 1, 'iter': 5500, 'avg_loss': 5.784604727799319, 'avg_acc': 49.927285948009455, 'loss': 5.699859142303467}


EP_train:1:  80%|| 5511/6926 [25:08:10&lt;1:57:29,  4.98s/it]

{'epoch': 1, 'iter': 5510, 'avg_loss': 5.784727857368565, 'avg_acc': 49.93875884594448, 'loss': 5.810672760009766}


EP_train:1:  80%|| 5521/6926 [25:09:00&lt;1:55:16,  4.92s/it]

{'epoch': 1, 'iter': 5520, 'avg_loss': 5.78466478540206, 'avg_acc': 49.94509599710197, 'loss': 5.763308525085449}


EP_train:1:  80%|| 5531/6926 [25:09:49&lt;1:53:46,  4.89s/it]

{'epoch': 1, 'iter': 5530, 'avg_loss': 5.784506014211982, 'avg_acc': 49.94406526848671, 'loss': 5.884986400604248}


EP_train:1:  80%|| 5541/6926 [25:10:38&lt;1:53:32,  4.92s/it]

{'epoch': 1, 'iter': 5540, 'avg_loss': 5.784547121983921, 'avg_acc': 49.93063075257174, 'loss': 5.656123161315918}


EP_train:1:  80%|| 5551/6926 [25:11:28&lt;1:53:49,  4.97s/it]

{'epoch': 1, 'iter': 5550, 'avg_loss': 5.7843577021243355, 'avg_acc': 49.929066834804544, 'loss': 5.350888252258301}


EP_train:1:  80%|| 5561/6926 [25:12:17&lt;1:52:25,  4.94s/it]

{'epoch': 1, 'iter': 5560, 'avg_loss': 5.784318096323465, 'avg_acc': 49.926946592339505, 'loss': 5.604388236999512}


EP_train:1:  80%|| 5571/6926 [25:13:07&lt;1:51:44,  4.95s/it]

{'epoch': 1, 'iter': 5570, 'avg_loss': 5.7842132499542815, 'avg_acc': 49.92315113983127, 'loss': 5.612821578979492}


EP_train:1:  81%|| 5581/6926 [25:13:56&lt;1:50:24,  4.93s/it]

{'epoch': 1, 'iter': 5580, 'avg_loss': 5.78414215458014, 'avg_acc': 49.930008063071135, 'loss': 5.800327301025391}


EP_train:1:  81%|| 5591/6926 [25:14:45&lt;1:48:47,  4.89s/it]

{'epoch': 1, 'iter': 5590, 'avg_loss': 5.7843216540582745, 'avg_acc': 49.929015381863714, 'loss': 5.423799991607666}


EP_train:1:  81%|| 5601/6926 [25:15:34&lt;1:48:39,  4.92s/it]

{'epoch': 1, 'iter': 5600, 'avg_loss': 5.784348123564377, 'avg_acc': 49.93081592572755, 'loss': 5.427426338195801}


EP_train:1:  81%|| 5611/6926 [25:16:23&lt;1:48:28,  4.95s/it]

{'epoch': 1, 'iter': 5610, 'avg_loss': 5.78420087824189, 'avg_acc': 49.93650864373552, 'loss': 5.6833176612854}


EP_train:1:  81%|| 5621/6926 [25:17:13&lt;1:47:30,  4.94s/it]

{'epoch': 1, 'iter': 5620, 'avg_loss': 5.78432444766034, 'avg_acc': 49.93550969578367, 'loss': 5.740802764892578}


EP_train:1:  81%|| 5631/6926 [25:18:02&lt;1:45:13,  4.88s/it]

{'epoch': 1, 'iter': 5630, 'avg_loss': 5.784201818299196, 'avg_acc': 49.927299769135146, 'loss': 5.6963396072387695}


EP_train:1:  81%|| 5641/6926 [25:18:51&lt;1:45:29,  4.93s/it]

{'epoch': 1, 'iter': 5640, 'avg_loss': 5.784294325205224, 'avg_acc': 49.93019854635703, 'loss': 5.713461875915527}


EP_train:1:  82%|| 5651/6926 [25:19:40&lt;1:42:47,  4.84s/it]

{'epoch': 1, 'iter': 5650, 'avg_loss': 5.784053106853085, 'avg_acc': 49.93364006370554, 'loss': 5.680525302886963}


EP_train:1:  82%|| 5661/6926 [25:20:29&lt;1:43:21,  4.90s/it]

{'epoch': 1, 'iter': 5660, 'avg_loss': 5.783927380333223, 'avg_acc': 49.926580992757465, 'loss': 5.957330703735352}


EP_train:1:  82%|| 5671/6926 [25:21:17&lt;1:41:19,  4.84s/it]

{'epoch': 1, 'iter': 5670, 'avg_loss': 5.783729803875375, 'avg_acc': 49.9283636043026, 'loss': 5.475937843322754}


EP_train:1:  82%|| 5681/6926 [25:22:06&lt;1:40:05,  4.82s/it]

{'epoch': 1, 'iter': 5680, 'avg_loss': 5.783408293567101, 'avg_acc': 49.926839464882946, 'loss': 5.761279582977295}


EP_train:1:  82%|| 5691/6926 [25:22:55&lt;1:39:54,  4.85s/it]

{'epoch': 1, 'iter': 5690, 'avg_loss': 5.783462573513795, 'avg_acc': 49.92641890704621, 'loss': 5.531265735626221}


EP_train:1:  82%|| 5701/6926 [25:23:43&lt;1:39:27,  4.87s/it]

{'epoch': 1, 'iter': 5700, 'avg_loss': 5.783237645885773, 'avg_acc': 49.92325907735485, 'loss': 5.559386730194092}


EP_train:1:  82%|| 5711/6926 [25:24:32&lt;1:39:24,  4.91s/it]

{'epoch': 1, 'iter': 5710, 'avg_loss': 5.783113932738974, 'avg_acc': 49.93050691647697, 'loss': 5.662935733795166}


EP_train:1:  83%|| 5721/6926 [25:25:21&lt;1:38:12,  4.89s/it]

{'epoch': 1, 'iter': 5720, 'avg_loss': 5.78305008452665, 'avg_acc': 49.932267086173745, 'loss': 5.837520599365234}


EP_train:1:  83%|| 5731/6926 [25:26:10&lt;1:36:28,  4.84s/it]

{'epoch': 1, 'iter': 5730, 'avg_loss': 5.783110486048717, 'avg_acc': 49.93402111324376, 'loss': 5.914923191070557}


EP_train:1:  83%|| 5741/6926 [25:26:58&lt;1:35:05,  4.81s/it]

{'epoch': 1, 'iter': 5740, 'avg_loss': 5.782980721454923, 'avg_acc': 49.93359170876154, 'loss': 6.288550853729248}


EP_train:1:  83%|| 5751/6926 [25:27:46&lt;1:33:55,  4.80s/it]

{'epoch': 1, 'iter': 5750, 'avg_loss': 5.78316503208713, 'avg_acc': 49.93914101895322, 'loss': 5.9080986976623535}


EP_train:1:  83%|| 5761/6926 [25:28:35&lt;1:34:06,  4.85s/it]

{'epoch': 1, 'iter': 5760, 'avg_loss': 5.782785179755316, 'avg_acc': 49.94738326679396, 'loss': 5.55677604675293}


EP_train:1:  83%|| 5771/6926 [25:29:23&lt;1:34:51,  4.93s/it]

{'epoch': 1, 'iter': 5770, 'avg_loss': 5.78283761176012, 'avg_acc': 49.95126494541674, 'loss': 5.984116554260254}


EP_train:1:  83%|| 5781/6926 [25:30:12&lt;1:32:41,  4.86s/it]

{'epoch': 1, 'iter': 5780, 'avg_loss': 5.782416016806824, 'avg_acc': 49.95351150320014, 'loss': 5.6232075691223145}


EP_train:1:  84%|| 5791/6926 [25:31:00&lt;1:31:07,  4.82s/it]

{'epoch': 1, 'iter': 5790, 'avg_loss': 5.782243973273025, 'avg_acc': 49.94819547573822, 'loss': 5.683053016662598}


EP_train:1:  84%|| 5801/6926 [25:31:48&lt;1:30:01,  4.80s/it]

{'epoch': 1, 'iter': 5800, 'avg_loss': 5.782278052446576, 'avg_acc': 49.93912687467678, 'loss': 6.064216136932373}


EP_train:1:  84%|| 5811/6926 [25:32:37&lt;1:29:20,  4.81s/it]

{'epoch': 1, 'iter': 5810, 'avg_loss': 5.782294087269655, 'avg_acc': 49.938156083290316, 'loss': 5.709198951721191}


EP_train:1:  84%|| 5821/6926 [25:33:25&lt;1:28:47,  4.82s/it]

{'epoch': 1, 'iter': 5820, 'avg_loss': 5.782214635918792, 'avg_acc': 49.931283284658996, 'loss': 5.346830368041992}


EP_train:1:  84%|| 5831/6926 [25:34:13&lt;1:27:29,  4.79s/it]

{'epoch': 1, 'iter': 5830, 'avg_loss': 5.782174025201773, 'avg_acc': 49.92389813068085, 'loss': 5.908675193786621}


EP_train:1:  84%|| 5841/6926 [25:35:01&lt;1:26:51,  4.80s/it]

{'epoch': 1, 'iter': 5840, 'avg_loss': 5.781947762238369, 'avg_acc': 49.92884351994522, 'loss': 5.71120023727417}


EP_train:1:  84%|| 5851/6926 [25:35:49&lt;1:27:01,  4.86s/it]

{'epoch': 1, 'iter': 5850, 'avg_loss': 5.781698381201953, 'avg_acc': 49.92736284395829, 'loss': 5.3460693359375}


EP_train:1:  85%|| 5861/6926 [25:36:37&lt;1:25:10,  4.80s/it]

{'epoch': 1, 'iter': 5860, 'avg_loss': 5.781845590356795, 'avg_acc': 49.91788943866234, 'loss': 5.871155261993408}


EP_train:1:  85%|| 5871/6926 [25:37:25&lt;1:24:24,  4.80s/it]

{'epoch': 1, 'iter': 5870, 'avg_loss': 5.781756310259092, 'avg_acc': 49.919093851132686, 'loss': 5.670632362365723}


EP_train:1:  85%|| 5881/6926 [25:38:13&lt;1:23:59,  4.82s/it]

{'epoch': 1, 'iter': 5880, 'avg_loss': 5.781726860833845, 'avg_acc': 49.92188828430539, 'loss': 5.868326187133789}


EP_train:1:  85%|| 5891/6926 [25:39:01&lt;1:21:48,  4.74s/it]

{'epoch': 1, 'iter': 5890, 'avg_loss': 5.781478759368679, 'avg_acc': 49.9156552368019, 'loss': 5.818526744842529}


EP_train:1:  85%|| 5901/6926 [25:39:48&lt;1:20:41,  4.72s/it]

{'epoch': 1, 'iter': 5900, 'avg_loss': 5.7811871450081895, 'avg_acc': 49.90467717336045, 'loss': 5.347582817077637}


EP_train:1:  85%|| 5911/6926 [25:40:35&lt;1:19:07,  4.68s/it]

{'epoch': 1, 'iter': 5910, 'avg_loss': 5.781136796793504, 'avg_acc': 49.90378108611064, 'loss': 6.000991344451904}


EP_train:1:  85%|| 5921/6926 [25:41:22&lt;1:19:11,  4.73s/it]

{'epoch': 1, 'iter': 5920, 'avg_loss': 5.781358487661214, 'avg_acc': 49.90763806789394, 'loss': 5.775269985198975}


EP_train:1:  86%|| 5931/6926 [25:42:09&lt;1:17:40,  4.68s/it]

{'epoch': 1, 'iter': 5930, 'avg_loss': 5.781212314026209, 'avg_acc': 49.90674001011634, 'loss': 5.669227600097656}


EP_train:1:  86%|| 5941/6926 [25:42:55&lt;1:16:33,  4.66s/it]

{'epoch': 1, 'iter': 5940, 'avg_loss': 5.781081504401204, 'avg_acc': 49.90900100993099, 'loss': 6.182577610015869}


EP_train:1:  86%|| 5951/6926 [25:43:42&lt;1:16:03,  4.68s/it]

{'epoch': 1, 'iter': 5950, 'avg_loss': 5.78110646159884, 'avg_acc': 49.90810368005377, 'loss': 5.681771278381348}


EP_train:1:  86%|| 5961/6926 [25:44:29&lt;1:14:51,  4.65s/it]

{'epoch': 1, 'iter': 5960, 'avg_loss': 5.7811979621153835, 'avg_acc': 49.907733601744674, 'loss': 5.719395160675049}


EP_train:1:  86%|| 5971/6926 [25:45:15&lt;1:14:02,  4.65s/it]

{'epoch': 1, 'iter': 5970, 'avg_loss': 5.780883351995046, 'avg_acc': 49.90893485178362, 'loss': 5.446839809417725}


EP_train:1:  86%|| 5981/6926 [25:46:02&lt;1:13:12,  4.65s/it]

{'epoch': 1, 'iter': 5980, 'avg_loss': 5.780823045940109, 'avg_acc': 49.91169954857047, 'loss': 5.8073954582214355}


EP_train:1:  87%|| 5991/6926 [25:46:48&lt;1:13:27,  4.71s/it]

{'epoch': 1, 'iter': 5990, 'avg_loss': 5.7807477352675285, 'avg_acc': 49.90923885828743, 'loss': 5.797297477722168}


EP_train:1:  87%|| 6001/6926 [25:47:35&lt;1:11:38,  4.65s/it]

{'epoch': 1, 'iter': 6000, 'avg_loss': 5.780810562178922, 'avg_acc': 49.912514580903185, 'loss': 5.653048992156982}


EP_train:1:  87%|| 6011/6926 [25:48:21&lt;1:10:25,  4.62s/it]

{'epoch': 1, 'iter': 6010, 'avg_loss': 5.780854975596142, 'avg_acc': 49.91889868574281, 'loss': 5.777438640594482}


EP_train:1:  87%|| 6021/6926 [25:49:08&lt;1:09:43,  4.62s/it]

{'epoch': 1, 'iter': 6020, 'avg_loss': 5.780711438999958, 'avg_acc': 49.9179953496097, 'loss': 5.75351095199585}


EP_train:1:  87%|| 6031/6926 [25:49:54&lt;1:09:18,  4.65s/it]

{'epoch': 1, 'iter': 6030, 'avg_loss': 5.780518743296481, 'avg_acc': 49.926939976786606, 'loss': 5.70479679107666}


EP_train:1:  87%|| 6041/6926 [25:50:41&lt;1:08:30,  4.64s/it]

{'epoch': 1, 'iter': 6040, 'avg_loss': 5.7802501204708046, 'avg_acc': 49.92861281244827, 'loss': 5.732730865478516}


EP_train:1:  87%|| 6051/6926 [25:51:28&lt;1:08:24,  4.69s/it]

{'epoch': 1, 'iter': 6050, 'avg_loss': 5.780145037254998, 'avg_acc': 49.926665014047266, 'loss': 6.207437992095947}


EP_train:1:  88%|| 6061/6926 [25:52:14&lt;1:06:47,  4.63s/it]

{'epoch': 1, 'iter': 6060, 'avg_loss': 5.780249950536071, 'avg_acc': 49.92523923444976, 'loss': 6.00528621673584}


EP_train:1:  88%|| 6071/6926 [25:53:01&lt;1:06:21,  4.66s/it]

{'epoch': 1, 'iter': 6070, 'avg_loss': 5.780045858935182, 'avg_acc': 49.92072969856696, 'loss': 5.68556547164917}


EP_train:1:  88%|| 6081/6926 [25:53:47&lt;1:05:29,  4.65s/it]

{'epoch': 1, 'iter': 6080, 'avg_loss': 5.779607152178224, 'avg_acc': 49.92137395165269, 'loss': 5.5342278480529785}


EP_train:1:  88%|| 6091/6926 [25:54:33&lt;1:04:26,  4.63s/it]

{'epoch': 1, 'iter': 6090, 'avg_loss': 5.779395503023931, 'avg_acc': 49.9173986209161, 'loss': 5.9122514724731445}


EP_train:1:  88%|| 6101/6926 [25:55:19&lt;1:03:46,  4.64s/it]

{'epoch': 1, 'iter': 6100, 'avg_loss': 5.779381259780031, 'avg_acc': 49.924704966398956, 'loss': 5.792469501495361}


EP_train:1:  88%|| 6111/6926 [25:56:06&lt;1:03:35,  4.68s/it]

{'epoch': 1, 'iter': 6110, 'avg_loss': 5.779114612638024, 'avg_acc': 49.92380543282605, 'loss': 5.879085063934326}


EP_train:1:  88%|| 6121/6926 [25:56:52&lt;1:02:13,  4.64s/it]

{'epoch': 1, 'iter': 6120, 'avg_loss': 5.7791698663341045, 'avg_acc': 49.92750367586996, 'loss': 5.887377738952637}


EP_train:1:  89%|| 6131/6926 [25:57:38&lt;1:00:48,  4.59s/it]

{'epoch': 1, 'iter': 6130, 'avg_loss': 5.7788901533588195, 'avg_acc': 49.930680150057086, 'loss': 5.180190563201904}


EP_train:1:  89%|| 6141/6926 [25:58:24&lt;1:00:01,  4.59s/it]

{'epoch': 1, 'iter': 6140, 'avg_loss': 5.77883395844301, 'avg_acc': 49.931810780003254, 'loss': 6.083118915557861}


EP_train:1:  89%|| 6151/6926 [25:59:10&lt;59:26,  4.60s/it]  

{'epoch': 1, 'iter': 6150, 'avg_loss': 5.7788775052855295, 'avg_acc': 49.93039749634206, 'loss': 5.849542140960693}


EP_train:1:  89%|| 6161/6926 [25:59:56&lt;58:46,  4.61s/it]

{'epoch': 1, 'iter': 6160, 'avg_loss': 5.778919962353761, 'avg_acc': 49.93304658334686, 'loss': 5.840837478637695}


EP_train:1:  89%|| 6171/6926 [26:00:42&lt;57:56,  4.60s/it]

{'epoch': 1, 'iter': 6170, 'avg_loss': 5.778584497903352, 'avg_acc': 49.93011667476908, 'loss': 5.556150913238525}


EP_train:1:  89%|| 6181/6926 [26:01:28&lt;57:28,  4.63s/it]

{'epoch': 1, 'iter': 6180, 'avg_loss': 5.778414422843549, 'avg_acc': 49.92972415466753, 'loss': 5.839237213134766}


EP_train:1:  89%|| 6191/6926 [26:02:14&lt;56:13,  4.59s/it]

{'epoch': 1, 'iter': 6190, 'avg_loss': 5.778344067247132, 'avg_acc': 49.935390082377644, 'loss': 5.642001628875732}


EP_train:1:  90%|| 6201/6926 [26:03:02&lt;58:27,  4.84s/it]

{'epoch': 1, 'iter': 6200, 'avg_loss': 5.778295888225602, 'avg_acc': 49.9435574907273, 'loss': 6.1009368896484375}


EP_train:1:  90%|| 6211/6926 [26:03:48&lt;54:59,  4.61s/it]

{'epoch': 1, 'iter': 6210, 'avg_loss': 5.778387287737494, 'avg_acc': 49.94817662212204, 'loss': 5.893352031707764}


EP_train:1:  90%|| 6221/6926 [26:04:33&lt;53:29,  4.55s/it]

{'epoch': 1, 'iter': 6220, 'avg_loss': 5.7782907649992055, 'avg_acc': 49.94876225687189, 'loss': 5.663171768188477}


EP_train:1:  90%|| 6231/6926 [26:05:19&lt;52:31,  4.53s/it]

{'epoch': 1, 'iter': 6230, 'avg_loss': 5.778239460248584, 'avg_acc': 49.95335820895522, 'loss': 5.583588600158691}


EP_train:1:  90%|| 6241/6926 [26:06:04&lt;52:02,  4.56s/it]

{'epoch': 1, 'iter': 6240, 'avg_loss': 5.7781203764597775, 'avg_acc': 49.95793943278321, 'loss': 6.1364006996154785}


EP_train:1:  90%|| 6251/6926 [26:06:49&lt;50:47,  4.51s/it]

{'epoch': 1, 'iter': 6250, 'avg_loss': 5.778017304188117, 'avg_acc': 49.96050631898896, 'loss': 5.472578048706055}


EP_train:1:  90%|| 6261/6926 [26:07:35&lt;50:26,  4.55s/it]

{'epoch': 1, 'iter': 6260, 'avg_loss': 5.77785077823882, 'avg_acc': 49.956576425491136, 'loss': 5.628420829772949}


EP_train:1:  91%|| 6271/6926 [26:08:20&lt;49:10,  4.50s/it]

{'epoch': 1, 'iter': 6270, 'avg_loss': 5.777695393566119, 'avg_acc': 49.962625578057725, 'loss': 6.0225067138671875}


EP_train:1:  91%|| 6281/6926 [26:09:05&lt;48:10,  4.48s/it]

{'epoch': 1, 'iter': 6280, 'avg_loss': 5.777665248173017, 'avg_acc': 49.957709759592426, 'loss': 5.661037445068359}


EP_train:1:  91%|| 6291/6926 [26:09:49&lt;46:48,  4.42s/it]

{'epoch': 1, 'iter': 6290, 'avg_loss': 5.7775033164187315, 'avg_acc': 49.95330631060245, 'loss': 5.781978607177734}


EP_train:1:  91%|| 6301/6926 [26:10:34&lt;46:17,  4.44s/it]

{'epoch': 1, 'iter': 6300, 'avg_loss': 5.777581789440209, 'avg_acc': 49.94594112045707, 'loss': 5.737508296966553}


EP_train:1:  91%|| 6311/6926 [26:11:18&lt;45:21,  4.43s/it]

{'epoch': 1, 'iter': 6310, 'avg_loss': 5.777420561507432, 'avg_acc': 49.941075106956106, 'loss': 5.739945888519287}


EP_train:1:  91%|| 6321/6926 [26:12:02&lt;44:53,  4.45s/it]

{'epoch': 1, 'iter': 6320, 'avg_loss': 5.777400415393677, 'avg_acc': 49.93919079259611, 'loss': 5.752358436584473}


EP_train:1:  91%|| 6331/6926 [26:12:46&lt;43:51,  4.42s/it]

{'epoch': 1, 'iter': 6330, 'avg_loss': 5.777687952842706, 'avg_acc': 49.936325225082925, 'loss': 5.815260410308838}


EP_train:1:  92%|| 6341/6926 [26:13:30&lt;42:52,  4.40s/it]

{'epoch': 1, 'iter': 6340, 'avg_loss': 5.7778140435627146, 'avg_acc': 49.93346869578931, 'loss': 6.343088626861572}


EP_train:1:  92%|| 6351/6926 [26:14:15&lt;42:49,  4.47s/it]

{'epoch': 1, 'iter': 6350, 'avg_loss': 5.77768568301122, 'avg_acc': 49.93455754999213, 'loss': 5.540189743041992}


EP_train:1:  92%|| 6361/6926 [26:14:59&lt;41:47,  4.44s/it]

{'epoch': 1, 'iter': 6360, 'avg_loss': 5.7775874545675014, 'avg_acc': 49.93564298066342, 'loss': 6.135932445526123}


EP_train:1:  92%|| 6371/6926 [26:15:43&lt;40:47,  4.41s/it]

{'epoch': 1, 'iter': 6370, 'avg_loss': 5.777595979642352, 'avg_acc': 49.93034845393188, 'loss': 5.408830165863037}


EP_train:1:  92%|| 6381/6926 [26:16:27&lt;40:30,  4.46s/it]

{'epoch': 1, 'iter': 6380, 'avg_loss': 5.77757071253088, 'avg_acc': 49.944170192759756, 'loss': 5.634832859039307}


EP_train:1:  92%|| 6391/6926 [26:17:12&lt;39:21,  4.41s/it]

{'epoch': 1, 'iter': 6390, 'avg_loss': 5.777440669260158, 'avg_acc': 49.94670239399155, 'loss': 5.383371829986572}


EP_train:1:  92%|| 6401/6926 [26:17:56&lt;38:19,  4.38s/it]

{'epoch': 1, 'iter': 6400, 'avg_loss': 5.777283759251961, 'avg_acc': 49.94580924855491, 'loss': 5.011127948760986}


EP_train:1:  93%|| 6411/6926 [26:18:41&lt;38:11,  4.45s/it]

{'epoch': 1, 'iter': 6410, 'avg_loss': 5.777359984851148, 'avg_acc': 49.946868663235065, 'loss': 5.4994916915893555}


EP_train:1:  93%|| 6421/6926 [26:19:25&lt;37:21,  4.44s/it]

{'epoch': 1, 'iter': 6420, 'avg_loss': 5.777320318960212, 'avg_acc': 49.94549135648653, 'loss': 5.719225883483887}


EP_train:1:  93%|| 6431/6926 [26:20:09&lt;36:02,  4.37s/it]

{'epoch': 1, 'iter': 6430, 'avg_loss': 5.77764610160919, 'avg_acc': 49.94071684030477, 'loss': 6.161487579345703}


EP_train:1:  93%|| 6441/6926 [26:20:53&lt;35:16,  4.36s/it]

{'epoch': 1, 'iter': 6440, 'avg_loss': 5.777708658278497, 'avg_acc': 49.94469026548673, 'loss': 6.02605676651001}


EP_train:1:  93%|| 6451/6926 [26:21:36&lt;34:38,  4.38s/it]

{'epoch': 1, 'iter': 6450, 'avg_loss': 5.777484106659021, 'avg_acc': 49.94186947760037, 'loss': 5.899960517883301}


EP_train:1:  93%|| 6461/6926 [26:22:20&lt;33:36,  4.34s/it]

{'epoch': 1, 'iter': 6460, 'avg_loss': 5.77741036040922, 'avg_acc': 49.95018186039313, 'loss': 5.4888787269592285}


EP_train:1:  93%|| 6471/6926 [26:23:04&lt;33:04,  4.36s/it]

{'epoch': 1, 'iter': 6470, 'avg_loss': 5.77723308531399, 'avg_acc': 49.94591253283882, 'loss': 5.877783298492432}


EP_train:1:  94%|| 6481/6926 [26:23:48&lt;32:49,  4.43s/it]

{'epoch': 1, 'iter': 6480, 'avg_loss': 5.7769616072127485, 'avg_acc': 49.94647816694954, 'loss': 5.616131782531738}


EP_train:1:  94%|| 6491/6926 [26:24:31&lt;31:47,  4.39s/it]

{'epoch': 1, 'iter': 6490, 'avg_loss': 5.777087825892097, 'avg_acc': 49.941264828223694, 'loss': 5.8958916664123535}


EP_train:1:  94%|| 6501/6926 [26:25:15&lt;30:39,  4.33s/it]

{'epoch': 1, 'iter': 6500, 'avg_loss': 5.7769701031607275, 'avg_acc': 49.94616212890325, 'loss': 5.841654300689697}


EP_train:1:  94%|| 6511/6926 [26:25:58&lt;30:04,  4.35s/it]

{'epoch': 1, 'iter': 6510, 'avg_loss': 5.777001203543725, 'avg_acc': 49.949124558439564, 'loss': 5.653926849365234}


EP_train:1:  94%|| 6521/6926 [26:26:42&lt;29:17,  4.34s/it]

{'epoch': 1, 'iter': 6520, 'avg_loss': 5.77680205348225, 'avg_acc': 49.94584802944333, 'loss': 5.291003704071045}


EP_train:1:  94%|| 6531/6926 [26:27:25&lt;28:23,  4.31s/it]

{'epoch': 1, 'iter': 6530, 'avg_loss': 5.776695243944674, 'avg_acc': 49.95693615066605, 'loss': 6.052003860473633}


EP_train:1:  94%|| 6541/6926 [26:28:08&lt;27:32,  4.29s/it]

{'epoch': 1, 'iter': 6540, 'avg_loss': 5.776760118376897, 'avg_acc': 49.95317994190491, 'loss': 5.720389366149902}


EP_train:1:  95%|| 6551/6926 [26:28:52&lt;27:18,  4.37s/it]

{'epoch': 1, 'iter': 6550, 'avg_loss': 5.776665815159194, 'avg_acc': 49.954205464814535, 'loss': 5.827826023101807}


EP_train:1:  95%|| 6561/6926 [26:29:35&lt;26:18,  4.32s/it]

{'epoch': 1, 'iter': 6560, 'avg_loss': 5.776401111763836, 'avg_acc': 49.95379896357262, 'loss': 5.450952529907227}


EP_train:1:  95%|| 6571/6926 [26:30:18&lt;25:25,  4.30s/it]

{'epoch': 1, 'iter': 6570, 'avg_loss': 5.776434445341253, 'avg_acc': 49.94768680566124, 'loss': 5.8960280418396}


EP_train:1:  95%|| 6581/6926 [26:31:01&lt;24:43,  4.30s/it]

{'epoch': 1, 'iter': 6580, 'avg_loss': 5.776199127435503, 'avg_acc': 49.944442333991795, 'loss': 5.734650611877441}


EP_train:1:  95%|| 6591/6926 [26:31:44&lt;24:03,  4.31s/it]

{'epoch': 1, 'iter': 6590, 'avg_loss': 5.776165728684062, 'avg_acc': 49.93741465634957, 'loss': 5.232611656188965}


EP_train:1:  95%|| 6601/6926 [26:32:28&lt;23:25,  4.32s/it]

{'epoch': 1, 'iter': 6600, 'avg_loss': 5.775830157542478, 'avg_acc': 49.94034994697773, 'loss': 5.430495738983154}


EP_train:1:  95%|| 6611/6926 [26:33:11&lt;22:40,  4.32s/it]

{'epoch': 1, 'iter': 6610, 'avg_loss': 5.775653046786992, 'avg_acc': 49.937603993344425, 'loss': 5.380129337310791}


EP_train:1:  96%|| 6621/6926 [26:33:54&lt;21:50,  4.30s/it]

{'epoch': 1, 'iter': 6620, 'avg_loss': 5.775762736878354, 'avg_acc': 49.94053013140009, 'loss': 5.624420642852783}


EP_train:1:  96%|| 6631/6926 [26:34:37&lt;21:21,  4.34s/it]

{'epoch': 1, 'iter': 6630, 'avg_loss': 5.77552282100097, 'avg_acc': 49.93873473080983, 'loss': 5.898670196533203}


EP_train:1:  96%|| 6641/6926 [26:35:20&lt;20:19,  4.28s/it]

{'epoch': 1, 'iter': 6640, 'avg_loss': 5.775653746702139, 'avg_acc': 49.93788586056317, 'loss': 5.747555732727051}


EP_train:1:  96%|| 6651/6926 [26:36:03&lt;19:29,  4.25s/it]

{'epoch': 1, 'iter': 6650, 'avg_loss': 5.775573407056869, 'avg_acc': 49.94549691775673, 'loss': 5.552094459533691}


EP_train:1:  96%|| 6661/6926 [26:36:45&lt;18:49,  4.26s/it]

{'epoch': 1, 'iter': 6660, 'avg_loss': 5.775592314733469, 'avg_acc': 49.94464044437772, 'loss': 5.8559770584106445}


EP_train:1:  96%|| 6671/6926 [26:37:28&lt;18:12,  4.28s/it]

{'epoch': 1, 'iter': 6670, 'avg_loss': 5.77529502804893, 'avg_acc': 49.946597211812325, 'loss': 5.930022239685059}


EP_train:1:  96%|| 6681/6926 [26:38:11&lt;17:18,  4.24s/it]

{'epoch': 1, 'iter': 6680, 'avg_loss': 5.775084311332982, 'avg_acc': 49.94293518934291, 'loss': 5.836806774139404}


EP_train:1:  97%|| 6691/6926 [26:38:53&lt;16:33,  4.23s/it]

{'epoch': 1, 'iter': 6690, 'avg_loss': 5.775097164546868, 'avg_acc': 49.93694888656404, 'loss': 5.301206111907959}


EP_train:1:  97%|| 6701/6926 [26:39:35&lt;15:51,  4.23s/it]

{'epoch': 1, 'iter': 6700, 'avg_loss': 5.775078065109652, 'avg_acc': 49.93331219221012, 'loss': 5.591684341430664}


EP_train:1:  97%|| 6711/6926 [26:40:18&lt;15:10,  4.24s/it]

{'epoch': 1, 'iter': 6710, 'avg_loss': 5.774972334648454, 'avg_acc': 49.94132767098793, 'loss': 5.595386981964111}


EP_train:1:  97%|| 6721/6926 [26:41:00&lt;14:25,  4.22s/it]

{'epoch': 1, 'iter': 6720, 'avg_loss': 5.774984706886608, 'avg_acc': 49.94048504686803, 'loss': 5.732786178588867}


EP_train:1:  97%|| 6731/6926 [26:41:42&lt;13:37,  4.19s/it]

{'epoch': 1, 'iter': 6730, 'avg_loss': 5.7750621846518815, 'avg_acc': 49.93732357747734, 'loss': 5.633825302124023}


EP_train:1:  97%|| 6741/6926 [26:42:24&lt;12:47,  4.15s/it]

{'epoch': 1, 'iter': 6740, 'avg_loss': 5.77519698136639, 'avg_acc': 49.93324432576769, 'loss': 6.02584171295166}


EP_train:1:  97%|| 6751/6926 [26:43:05&lt;12:04,  4.14s/it]

{'epoch': 1, 'iter': 6750, 'avg_loss': 5.775010837305742, 'avg_acc': 49.93473189157162, 'loss': 5.970997333526611}


EP_train:1:  98%|| 6761/6926 [26:43:46&lt;11:19,  4.12s/it]

{'epoch': 1, 'iter': 6760, 'avg_loss': 5.774941228088799, 'avg_acc': 49.93297958881822, 'loss': 5.925961494445801}


EP_train:1:  98%|| 6771/6926 [26:44:28&lt;10:38,  4.12s/it]

{'epoch': 1, 'iter': 6770, 'avg_loss': 5.775033120231533, 'avg_acc': 49.93446315167627, 'loss': 5.306178092956543}


EP_train:1:  98%|| 6781/6926 [26:45:09&lt;10:05,  4.18s/it]

{'epoch': 1, 'iter': 6780, 'avg_loss': 5.775017764360534, 'avg_acc': 49.932255567025514, 'loss': 5.493859767913818}


EP_train:1:  98%|| 6791/6926 [26:45:51&lt;09:13,  4.10s/it]

{'epoch': 1, 'iter': 6790, 'avg_loss': 5.774907826850699, 'avg_acc': 49.933735826829626, 'loss': 5.780702114105225}


EP_train:1:  98%|| 6801/6926 [26:46:32&lt;08:49,  4.24s/it]

{'epoch': 1, 'iter': 6800, 'avg_loss': 5.774968336792733, 'avg_acc': 49.9347522423173, 'loss': 5.785495281219482}


EP_train:1:  98%|| 6811/6926 [26:47:13&lt;07:51,  4.10s/it]

{'epoch': 1, 'iter': 6810, 'avg_loss': 5.774826055895545, 'avg_acc': 49.93622448979592, 'loss': 5.582895755767822}


EP_train:1:  98%|| 6821/6926 [26:47:54&lt;07:06,  4.06s/it]

{'epoch': 1, 'iter': 6820, 'avg_loss': 5.774791732069999, 'avg_acc': 49.93815056443337, 'loss': 5.51682186126709}


EP_train:1:  99%|| 6831/6926 [26:48:34&lt;06:25,  4.06s/it]

{'epoch': 1, 'iter': 6830, 'avg_loss': 5.7745794972813576, 'avg_acc': 49.94556067925633, 'loss': 5.5028533935546875}


EP_train:1:  99%|| 6841/6926 [26:49:15&lt;05:43,  4.04s/it]

{'epoch': 1, 'iter': 6840, 'avg_loss': 5.774490070872759, 'avg_acc': 49.947467475515275, 'loss': 5.823716640472412}


EP_train:1:  99%|| 6851/6926 [26:49:55&lt;05:00,  4.01s/it]

{'epoch': 1, 'iter': 6850, 'avg_loss': 5.774343690286151, 'avg_acc': 49.947088016347976, 'loss': 5.5767927169799805}


EP_train:1:  99%|| 6861/6926 [26:50:35&lt;04:20,  4.00s/it]

{'epoch': 1, 'iter': 6860, 'avg_loss': 5.774208201800503, 'avg_acc': 49.95080891998251, 'loss': 5.940675258636475}


EP_train:1:  99%|| 6871/6926 [26:51:16&lt;03:40,  4.02s/it]

{'epoch': 1, 'iter': 6870, 'avg_loss': 5.774142305501561, 'avg_acc': 49.9549738029399, 'loss': 5.632803916931152}


EP_train:1:  99%|| 6881/6926 [26:51:56&lt;02:59,  3.99s/it]

{'epoch': 1, 'iter': 6880, 'avg_loss': 5.774009880051504, 'avg_acc': 49.95367679116408, 'loss': 5.485649108886719}


EP_train:1:  99%|| 6891/6926 [26:52:35&lt;02:18,  3.97s/it]

{'epoch': 1, 'iter': 6890, 'avg_loss': 5.773817592289257, 'avg_acc': 49.953290523871715, 'loss': 6.408249378204346}


EP_train:1: 100%|| 6901/6926 [26:53:15&lt;01:39,  3.97s/it]

{'epoch': 1, 'iter': 6900, 'avg_loss': 5.773691588494246, 'avg_acc': 49.94928271265034, 'loss': 5.580688953399658}


EP_train:1: 100%|| 6911/6926 [26:53:55&lt;00:59,  3.95s/it]

{'epoch': 1, 'iter': 6910, 'avg_loss': 5.773572737876353, 'avg_acc': 49.94890392128491, 'loss': 5.805022716522217}


EP_train:1: 100%|| 6921/6926 [26:54:35&lt;00:19,  3.97s/it]

{'epoch': 1, 'iter': 6920, 'avg_loss': 5.773589925844534, 'avg_acc': 49.94581707845687, 'loss': 5.892418384552002}


EP_train:1: 100%|| 6926/6926 [26:54:53&lt;00:00, 13.99s/it]

EP1, train:             avg_loss=5.773454445757137,             total_acc=49.949010901739946
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">bert_lm</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>BERTLM(
  (bert): BERT(
    (embedding): BERTEmbedding(
      (token): Embedding(21159, 768, padding_idx=0)
      (segment): Embedding(3, 768, padding_idx=0)
      (position): PositionalEmbedding()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder_blocks): ModuleList(
      (0-11): 12 x EncoderLayer(
        (layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (self_multihead): MultiHeadedAttention(
          (dropout): Dropout(p=0.1, inplace=False)
          (query): Linear(in_features=768, out_features=768, bias=True)
          (key): Linear(in_features=768, out_features=768, bias=True)
          (value): Linear(in_features=768, out_features=768, bias=True)
          (output_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): FeedForward(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU(approximate='none')
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (next_sentence): NextSentencePrediction(
    (linear): Linear(in_features=768, out_features=2, bias=True)
    (softmax): LogSoftmax(dim=-1)
  )
  (mask_lm): MaskedLanguageModel(
    (linear): Linear(in_features=768, out_features=21159, bias=True)
    (softmax): LogSoftmax(dim=-1)
  )
)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">os</span>

<span class="c1"># Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()
</span>
<span class="n">output_dir</span> <span class="o">=</span> <span class="s">'./model_save/'</span>

<span class="c1"># Create output directory if needed
</span><span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">exists</span><span class="p">(</span><span class="n">output_dir</span><span class="p">):</span>
    <span class="n">os</span><span class="p">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">output_dir</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Saving model to %s"</span> <span class="o">%</span> <span class="n">output_dir</span><span class="p">)</span>

<span class="c1"># Save a trained model, configuration and tokenizer using `save_pretrained()`.
# They can then be reloaded using `from_pretrained()`
#model_to_save = model.module if hasattr(model, 'nanoGPT-module') else model  # Take care of distributed/parallel training
</span><span class="n">torch</span><span class="p">.</span><span class="n">save</span><span class="p">(</span><span class="n">bert_lm</span><span class="p">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">output_dir</span><span class="o">+</span><span class="s">"mybert.path"</span><span class="p">)</span>

<span class="c1"># Good practice: save your training arguments together with the trained model
# torch.save(args, os.path.join(output_dir, 'training_args.bin'))
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Saving model to ./model_save/
</code></pre></div></div>

<h1 id="5-reference">5) Reference</h1>

<p>BERT vs Roberta vs XLM : https://towardsdatascience.com/bert-roberta-distilbert-xlnet-which-one-to-use-3d5ab82ba5f8</p>

<p>StructBert vs Albert vs LongForm: https://towardsdatascience.com/advancing-over-bert-bigbird-convbert-dynabert-bca78a45629c</p>

<p>BART: https://medium.com/analytics-vidhya/revealing-bart-a-denoising-objective-for-pretraining-c6e8f8009564</p>

<p>BLOOM: https://www.infoq.com/news/2022/07/bigscience-bloom-nlp-ai/</p>

<p>PaLM: https://www.infoq.com/news/2022/04/google-palm-ai/</p>]]></content><author><name>Zhu Tianda</name></author><category term="coding" /><category term="AI" /><summary type="html"><![CDATA[!pip install transformers datasets tokenizers !wget http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip !unzip -qq cornell_movie_dialogs_corpus.zip !rm cornell_movie_dialogs_corpus.zip !mkdir datasets !mv cornell\ movie-dialogs\ corpus/movie_conversations.txt ./datasets !mv cornell\ movie-dialogs\ corpus/movie_lines.txt ./datasets]]></summary></entry><entry><title type="html">Convolutional Neural Networks: Application</title><link href="http://0.0.0.0:8855/coding/2023/12/01/Convolution-model-Application-v1a.html" rel="alternate" type="text/html" title="Convolutional Neural Networks: Application" /><published>2023-12-01T00:00:00+08:00</published><updated>2023-12-01T00:00:00+08:00</updated><id>http://0.0.0.0:8855/coding/2023/12/01/Convolution-model-Application-v1a</id><content type="html" xml:base="http://0.0.0.0:8855/coding/2023/12/01/Convolution-model-Application-v1a.html"><![CDATA[<h1 id="convolutional-neural-networks-application">Convolutional Neural Networks: Application</h1>

<p>Welcome to Course 4’s second assignment! In this notebook, you will:</p>

<ul>
  <li>Implement helper functions that you will use when implementing a TensorFlow model</li>
  <li>Implement a fully functioning ConvNet using TensorFlow</li>
</ul>

<p><strong>After this assignment you will be able to:</strong></p>

<ul>
  <li>Build and train a ConvNet in TensorFlow for a classification problem</li>
</ul>

<p>We assume here that you are already familiar with TensorFlow. If you are not, please refer the <em>TensorFlow Tutorial</em> of the third week of Course 2 (“<em>Improving deep neural networks</em>”).</p>

<h3 id="-updates-to-assignment-"><font color="darkblue"> Updates to Assignment <font></font></font></h3>

<h4 id="if-you-were-working-on-a-previous-version">If you were working on a previous version</h4>
<ul>
  <li>The current notebook filename is version “1a”.</li>
  <li>You can find your work in the file directory as version “1”.</li>
  <li>To view the file directory, go to the menu “File-&gt;Open”, and this will open a new tab that shows the file directory.</li>
</ul>

<h4 id="list-of-updates">List of Updates</h4>
<ul>
  <li><code class="language-plaintext highlighter-rouge">initialize_parameters</code>: added details about tf.get_variable, <code class="language-plaintext highlighter-rouge">eval</code>. Clarified test case.</li>
  <li>Added explanations for the kernel (filter) stride values, max pooling, and flatten functions.</li>
  <li>Added details about softmax cross entropy with logits.</li>
  <li>Added instructions for creating the Adam Optimizer.</li>
  <li>Added explanation of how to evaluate tensors (optimizer and cost).</li>
  <li><code class="language-plaintext highlighter-rouge">forward_propagation</code>: clarified instructions, use “F” to store “flatten” layer.</li>
  <li>Updated print statements and ‘expected output’ for easier visual comparisons.</li>
  <li>Many thanks to Kevin P. Brown (mentor for the deep learning specialization) for his suggestions on the assignments in this course!</li>
</ul>

<h2 id="10---tensorflow-model">1.0 - TensorFlow model</h2>

<p>In the previous assignment, you built helper functions using numpy to understand the mechanics behind convolutional neural networks. Most practical applications of deep learning today are built using programming frameworks, which have many built-in functions you can simply call.</p>

<p>As usual, we will start by loading in the packages.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">h5py</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">scipy</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">ndimage</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.framework</span> <span class="kn">import</span> <span class="n">ops</span>
<span class="kn">from</span> <span class="nn">cnn_utils</span> <span class="kn">import</span> <span class="o">*</span>

<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<p>Run the next cell to load the “SIGNS” dataset you are going to use.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Loading the data (signs)
</span><span class="n">X_train_orig</span><span class="p">,</span> <span class="n">Y_train_orig</span><span class="p">,</span> <span class="n">X_test_orig</span><span class="p">,</span> <span class="n">Y_test_orig</span><span class="p">,</span> <span class="n">classes</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">()</span>
</code></pre></div></div>

<p>As a reminder, the SIGNS dataset is a collection of 6 signs representing numbers from 0 to 5.</p>

<p><img src="/assets/2023-12-01-Convolution-model-Application-v1a_files/SIGNS.png" style="width:800px;height:300px;" /></p>

<p>The next cell will show you an example of a labelled image in the dataset. Feel free to change the value of <code class="language-plaintext highlighter-rouge">index</code> below and re-run to see different examples.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Example of a picture
</span><span class="n">index</span> <span class="o">=</span> <span class="mi">6</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">X_train_orig</span><span class="p">[</span><span class="n">index</span><span class="p">])</span>
<span class="k">print</span> <span class="p">(</span><span class="s">"y = "</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">Y_train_orig</span><span class="p">[:,</span> <span class="n">index</span><span class="p">])))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>y = 2
</code></pre></div></div>

<p><img src="/assets/2023-12-01-Convolution-model-Application-v1a_files/2023-12-01-Convolution-model-Application-v1a_7_1.png" alt="png" /></p>

<p>In Course 2, you had built a fully-connected network for this dataset. But since this is an image dataset, it is more natural to apply a ConvNet to it.</p>

<p>To get started, let’s examine the shapes of your data.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X_train</span> <span class="o">=</span> <span class="n">X_train_orig</span><span class="o">/</span><span class="mf">255.</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">X_test_orig</span><span class="o">/</span><span class="mf">255.</span>
<span class="n">Y_train</span> <span class="o">=</span> <span class="n">convert_to_one_hot</span><span class="p">(</span><span class="n">Y_train_orig</span><span class="p">,</span> <span class="mi">6</span><span class="p">).</span><span class="n">T</span>
<span class="n">Y_test</span> <span class="o">=</span> <span class="n">convert_to_one_hot</span><span class="p">(</span><span class="n">Y_test_orig</span><span class="p">,</span> <span class="mi">6</span><span class="p">).</span><span class="n">T</span>
<span class="k">print</span> <span class="p">(</span><span class="s">"number of training examples = "</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">X_train</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
<span class="k">print</span> <span class="p">(</span><span class="s">"number of test examples = "</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">X_test</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
<span class="k">print</span> <span class="p">(</span><span class="s">"X_train shape: "</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">X_train</span><span class="p">.</span><span class="n">shape</span><span class="p">))</span>
<span class="k">print</span> <span class="p">(</span><span class="s">"Y_train shape: "</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">Y_train</span><span class="p">.</span><span class="n">shape</span><span class="p">))</span>
<span class="k">print</span> <span class="p">(</span><span class="s">"X_test shape: "</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">X_test</span><span class="p">.</span><span class="n">shape</span><span class="p">))</span>
<span class="k">print</span> <span class="p">(</span><span class="s">"Y_test shape: "</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">Y_test</span><span class="p">.</span><span class="n">shape</span><span class="p">))</span>
<span class="n">conv_layers</span> <span class="o">=</span> <span class="p">{}</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>number of training examples = 1080
number of test examples = 120
X_train shape: (1080, 64, 64, 3)
Y_train shape: (1080, 6)
X_test shape: (120, 64, 64, 3)
Y_test shape: (120, 6)
</code></pre></div></div>

<h3 id="11---create-placeholders">1.1 - Create placeholders</h3>

<p>TensorFlow requires that you create placeholders for the input data that will be fed into the model when running the session.</p>

<p><strong>Exercise</strong>: Implement the function below to create placeholders for the input image X and the output Y. You should not define the number of training examples for the moment. To do so, you could use “None” as the batch size, it will give you the flexibility to choose it later. Hence X should be of dimension <strong>[None, n_H0, n_W0, n_C0]</strong> and Y should be of dimension <strong>[None, n_y]</strong>.  <a href="https://www.tensorflow.org/api_docs/python/tf/placeholder">Hint: search for the tf.placeholder documentation”</a>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># GRADED FUNCTION: create_placeholders
</span>
<span class="k">def</span> <span class="nf">create_placeholders</span><span class="p">(</span><span class="n">n_H0</span><span class="p">,</span> <span class="n">n_W0</span><span class="p">,</span> <span class="n">n_C0</span><span class="p">,</span> <span class="n">n_y</span><span class="p">):</span>
    <span class="s">"""
    Creates the placeholders for the tensorflow session.
    
    Arguments:
    n_H0 -- scalar, height of an input image
    n_W0 -- scalar, width of an input image
    n_C0 -- scalar, number of channels of the input
    n_y -- scalar, number of classes
        
    Returns:
    X -- placeholder for the data input, of shape [None, n_H0, n_W0, n_C0] and dtype "float"
    Y -- placeholder for the input labels, of shape [None, n_y] and dtype "float"
    """</span>

    <span class="c1">### START CODE HERE ### (≈2 lines)
</span>    <span class="n">X</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="n">n_H0</span><span class="p">,</span> <span class="n">n_W0</span><span class="p">,</span> <span class="n">n_C0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="s">"float"</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s">"X"</span><span class="p">)</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="n">n_y</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="s">"float"</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s">"Y"</span><span class="p">)</span>
    <span class="c1">### END CODE HERE ###
</span>    
    <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">create_placeholders</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
<span class="k">print</span> <span class="p">(</span><span class="s">"X = "</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
<span class="k">print</span> <span class="p">(</span><span class="s">"Y = "</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">Y</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>X = Tensor("X:0", shape=(?, 64, 64, 3), dtype=float32)
Y = Tensor("Y:0", shape=(?, 6), dtype=float32)
</code></pre></div></div>

<p><strong>Expected Output</strong></p>

<table> 
<tr>
<td>
    X = Tensor("Placeholder:0", shape=(?, 64, 64, 3), dtype=float32)

</td>
</tr>
<tr>
<td>
    Y = Tensor("Placeholder_1:0", shape=(?, 6), dtype=float32)

</td>
</tr>
</table>

<h3 id="12---initialize-parameters">1.2 - Initialize parameters</h3>

<p>You will initialize weights/filters $W1$ and $W2$ using <code class="language-plaintext highlighter-rouge">tf.contrib.layers.xavier_initializer(seed = 0)</code>. You don’t need to worry about bias variables as you will soon see that TensorFlow functions take care of the bias. Note also that you will only initialize the weights/filters for the conv2d functions. TensorFlow initializes the layers for the fully connected part automatically. We will talk more about that later in this assignment.</p>

<p><strong>Exercise:</strong> Implement initialize_parameters(). The dimensions for each group of filters are provided below. Reminder - to initialize a parameter $W$ of shape [1,2,3,4] in Tensorflow, use:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">W</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">get_variable</span><span class="p">(</span><span class="s">"W"</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">],</span> <span class="n">initializer</span> <span class="o">=</span> <span class="p">...)</span>
</code></pre></div></div>
<h4 id="tfget_variable">tf.get_variable()</h4>
<p><a href="https://www.tensorflow.org/api_docs/python/tf/get_variable">Search for the tf.get_variable documentation</a>.  Notice that the documentation says:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Gets an existing variable with these parameters or create a new one.
</code></pre></div></div>
<p>So we can use this function to create a tensorflow variable with the specified name, but if the variables already exist, it will get the existing variable with that same name.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># GRADED FUNCTION: initialize_parameters
</span>
<span class="k">def</span> <span class="nf">initialize_parameters</span><span class="p">():</span>
    <span class="s">"""
    Initializes weight parameters to build a neural network with tensorflow. The shapes are:
                        W1 : [4, 4, 3, 8]
                        W2 : [2, 2, 8, 16]
    Note that we will hard code the shape values in the function to make the grading simpler.
    Normally, functions should take values as inputs rather than hard coding.
    Returns:
    parameters -- a dictionary of tensors containing W1, W2
    """</span>
    
    <span class="n">tf</span><span class="p">.</span><span class="n">set_random_seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>                              <span class="c1"># so that your "random" numbers match ours
</span>        
    <span class="c1">### START CODE HERE ### (approx. 2 lines of code)
</span>    <span class="n">W1</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">get_variable</span><span class="p">(</span><span class="s">"W1"</span><span class="p">,</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span> <span class="n">initializer</span> <span class="o">=</span>  <span class="n">tf</span><span class="p">.</span><span class="n">contrib</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">xavier_initializer</span><span class="p">(</span><span class="n">seed</span> <span class="o">=</span> <span class="mi">0</span><span class="p">))</span>
    <span class="n">W2</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">get_variable</span><span class="p">(</span><span class="s">"W2"</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">16</span><span class="p">],</span> <span class="n">initializer</span> <span class="o">=</span>  <span class="n">tf</span><span class="p">.</span><span class="n">contrib</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">xavier_initializer</span><span class="p">(</span><span class="n">seed</span> <span class="o">=</span> <span class="mi">0</span><span class="p">))</span>
    <span class="c1">### END CODE HERE ###
</span>
    <span class="n">parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s">"W1"</span><span class="p">:</span> <span class="n">W1</span><span class="p">,</span>
                  <span class="s">"W2"</span><span class="p">:</span> <span class="n">W2</span><span class="p">}</span>
    
    <span class="k">return</span> <span class="n">parameters</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">tf</span><span class="p">.</span><span class="n">reset_default_graph</span><span class="p">()</span>
<span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess_test</span><span class="p">:</span>
    <span class="n">parameters</span> <span class="o">=</span> <span class="n">initialize_parameters</span><span class="p">()</span>
    <span class="n">init</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">global_variables_initializer</span><span class="p">()</span>
    <span class="n">sess_test</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">init</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"W1[1,1,1] = </span><span class="se">\n</span><span class="s">"</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">parameters</span><span class="p">[</span><span class="s">"W1"</span><span class="p">].</span><span class="nb">eval</span><span class="p">()[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]))</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"W1.shape: "</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">parameters</span><span class="p">[</span><span class="s">"W1"</span><span class="p">].</span><span class="n">shape</span><span class="p">))</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"W2[1,1,1] = </span><span class="se">\n</span><span class="s">"</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">parameters</span><span class="p">[</span><span class="s">"W2"</span><span class="p">].</span><span class="nb">eval</span><span class="p">()[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]))</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"W2.shape: "</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">parameters</span><span class="p">[</span><span class="s">"W2"</span><span class="p">].</span><span class="n">shape</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>W1[1,1,1] = 
[ 0.00131723  0.14176141 -0.04434952  0.09197326  0.14984085 -0.03514394
 -0.06847463  0.05245192]
W1.shape: (4, 4, 3, 8)


W2[1,1,1] = 
[-0.08566415  0.17750949  0.11974221  0.16773748 -0.0830943  -0.08058
 -0.00577033 -0.14643836  0.24162132 -0.05857408 -0.19055021  0.1345228
 -0.22779644 -0.1601823  -0.16117483 -0.10286498]
W2.shape: (2, 2, 8, 16)
</code></pre></div></div>

<p>** Expected Output:**</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>W1[1,1,1] = 
[ 0.00131723  0.14176141 -0.04434952  0.09197326  0.14984085 -0.03514394
 -0.06847463  0.05245192]
W1.shape: (4, 4, 3, 8)


W2[1,1,1] = 
[-0.08566415  0.17750949  0.11974221  0.16773748 -0.0830943  -0.08058
 -0.00577033 -0.14643836  0.24162132 -0.05857408 -0.19055021  0.1345228
 -0.22779644 -0.1601823  -0.16117483 -0.10286498]
W2.shape: (2, 2, 8, 16)
</code></pre></div></div>

<h3 id="13---forward-propagation">1.3 - Forward propagation</h3>

<p>In TensorFlow, there are built-in functions that implement the convolution steps for you.</p>

<ul>
  <li>
    <p><strong>tf.nn.conv2d(X,W, strides = [1,s,s,1], padding = ‘SAME’):</strong> given an input $X$ and a group of filters $W$, this function convolves $W$’s filters on X. The third parameter ([1,s,s,1]) represents the strides for each dimension of the input (m, n_H_prev, n_W_prev, n_C_prev). Normally, you’ll choose a stride of 1 for the number of examples (the first value) and for the channels (the fourth value), which is why we wrote the value as <code class="language-plaintext highlighter-rouge">[1,s,s,1]</code>. You can read the full documentation on <a href="https://www.tensorflow.org/api_docs/python/tf/nn/conv2d">conv2d</a>.</p>
  </li>
  <li>
    <p><strong>tf.nn.max_pool(A, ksize = [1,f,f,1], strides = [1,s,s,1], padding = ‘SAME’):</strong> given an input A, this function uses a window of size (f, f) and strides of size (s, s) to carry out max pooling over each window.  For max pooling, we usually operate on a single example at a time and a single channel at a time.  So the first and fourth value in <code class="language-plaintext highlighter-rouge">[1,f,f,1]</code> are both 1.  You can read the full documentation on <a href="https://www.tensorflow.org/api_docs/python/tf/nn/max_pool">max_pool</a>.</p>
  </li>
  <li>
    <p><strong>tf.nn.relu(Z):</strong> computes the elementwise ReLU of Z (which can be any shape). You can read the full documentation on <a href="https://www.tensorflow.org/api_docs/python/tf/nn/relu">relu</a>.</p>
  </li>
  <li><strong>tf.contrib.layers.flatten(P)</strong>: given a tensor “P”, this function takes each training (or test) example in the batch and flattens it into a 1D vector.
    <ul>
      <li>If a tensor P has the shape (m,h,w,c), where m is the number of examples (the batch size), it returns a flattened tensor with shape (batch_size, k), where $k=h \times w \times c$.  “k” equals the product of all the dimension sizes other than the first dimension.</li>
      <li>For example, given a tensor with dimensions [100,2,3,4], it flattens the tensor to be of shape [100, 24], where 24 = 2 * 3 * 4.  You can read the full documentation on <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/layers/flatten">flatten</a>.</li>
    </ul>
  </li>
  <li><strong>tf.contrib.layers.fully_connected(F, num_outputs):</strong> given the flattened input F, it returns the output computed using a fully connected layer. You can read the full documentation on <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/layers/fully_connected">full_connected</a>.</li>
</ul>

<p>In the last function above (<code class="language-plaintext highlighter-rouge">tf.contrib.layers.fully_connected</code>), the fully connected layer automatically initializes weights in the graph and keeps on training them as you train the model. Hence, you did not need to initialize those weights when initializing the parameters.</p>

<h4 id="window-kernel-filter">Window, kernel, filter</h4>
<p>The words “window”, “kernel”, and “filter” are used to refer to the same thing.  This is why the parameter <code class="language-plaintext highlighter-rouge">ksize</code> refers to “kernel size”, and we use <code class="language-plaintext highlighter-rouge">(f,f)</code> to refer to the filter size.  Both “kernel” and “filter” refer to the “window.”</p>

<p><strong>Exercise</strong></p>

<p>Implement the <code class="language-plaintext highlighter-rouge">forward_propagation</code> function below to build the following model: <code class="language-plaintext highlighter-rouge">CONV2D -&gt; RELU -&gt; MAXPOOL -&gt; CONV2D -&gt; RELU -&gt; MAXPOOL -&gt; FLATTEN -&gt; FULLYCONNECTED</code>. You should use the functions above.</p>

<p>In detail, we will use the following parameters for all the steps:</p>
<ul>
  <li>Conv2D: stride 1, padding is “SAME”</li>
  <li>ReLU</li>
  <li>Max pool: Use an 8 by 8 filter size and an 8 by 8 stride, padding is “SAME”</li>
  <li>Conv2D: stride 1, padding is “SAME”</li>
  <li>ReLU</li>
  <li>Max pool: Use a 4 by 4 filter size and a 4 by 4 stride, padding is “SAME”</li>
  <li>Flatten the previous output.</li>
  <li>FULLYCONNECTED (FC) layer: Apply a fully connected layer without an non-linear activation function. Do not call the softmax here. This will result in 6 neurons in the output layer, which then get passed later to a softmax. In TensorFlow, the softmax and cost function are lumped together into a single function, which you’ll call in a different function when computing the cost.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># GRADED FUNCTION: forward_propagation
</span>
<span class="k">def</span> <span class="nf">forward_propagation</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">parameters</span><span class="p">):</span>
    <span class="s">"""
    Implements the forward propagation for the model:
    CONV2D -&gt; RELU -&gt; MAXPOOL -&gt; CONV2D -&gt; RELU -&gt; MAXPOOL -&gt; FLATTEN -&gt; FULLYCONNECTED
    
    Note that for simplicity and grading purposes, we'll hard-code some values
    such as the stride and kernel (filter) sizes. 
    Normally, functions should take these values as function parameters.
    
    Arguments:
    X -- input dataset placeholder, of shape (input size, number of examples)
    parameters -- python dictionary containing your parameters "W1", "W2"
                  the shapes are given in initialize_parameters

    Returns:
    Z3 -- the output of the last LINEAR unit
    """</span>
    
    <span class="c1"># Retrieve the parameters from the dictionary "parameters" 
</span>    <span class="n">W1</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="s">'W1'</span><span class="p">]</span>
    <span class="n">W2</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="s">'W2'</span><span class="p">]</span>
    
    <span class="c1">### START CODE HERE ###
</span>    <span class="c1"># CONV2D: stride of 1, padding 'SAME'
</span>    <span class="n">s</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">Z1</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">conv2d</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">W1</span><span class="p">,</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="n">s</span><span class="p">,</span><span class="n">s</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="n">padding</span> <span class="o">=</span> <span class="s">'SAME'</span><span class="p">)</span>
    <span class="c1"># RELU
</span>    <span class="n">A1</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">relu</span><span class="p">(</span><span class="n">Z1</span><span class="p">)</span>
    <span class="c1"># MAXPOOL: window 8x8, stride 8, padding 'SAME'
</span>    <span class="n">f</span> <span class="o">=</span> <span class="mi">8</span>
    <span class="n">s</span> <span class="o">=</span> <span class="mi">8</span>
    <span class="n">P1</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">max_pool</span><span class="p">(</span><span class="n">A1</span><span class="p">,</span> <span class="n">ksize</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="n">f</span><span class="p">,</span><span class="n">f</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="n">s</span><span class="p">,</span><span class="n">s</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="n">padding</span> <span class="o">=</span> <span class="s">'SAME'</span><span class="p">)</span>
    <span class="c1"># CONV2D: filters W2, stride 1, padding 'SAME'
</span>    <span class="n">s</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">Z2</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">conv2d</span><span class="p">(</span><span class="n">P1</span><span class="p">,</span> <span class="n">W2</span><span class="p">,</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="n">s</span><span class="p">,</span><span class="n">s</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="n">padding</span> <span class="o">=</span> <span class="s">'SAME'</span><span class="p">)</span>
    <span class="c1"># RELU
</span>    <span class="n">A2</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">relu</span><span class="p">(</span><span class="n">Z2</span><span class="p">)</span>
    <span class="c1"># MAXPOOL: window 4x4, stride 4, padding 'SAME'
</span>    <span class="n">f</span> <span class="o">=</span> <span class="mi">4</span>
    <span class="n">s</span> <span class="o">=</span> <span class="mi">4</span>
    <span class="n">P2</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">max_pool</span><span class="p">(</span><span class="n">A2</span><span class="p">,</span> <span class="n">ksize</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="n">f</span><span class="p">,</span><span class="n">f</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="n">s</span><span class="p">,</span><span class="n">s</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="n">padding</span> <span class="o">=</span> <span class="s">'SAME'</span><span class="p">)</span>
    <span class="c1"># FLATTEN
</span>    <span class="n">F</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">contrib</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">P2</span><span class="p">)</span>
    <span class="c1"># FULLY-CONNECTED without non-linear activation function (not not call softmax).
</span>    <span class="c1"># 6 neurons in output layer. Hint: one of the arguments should be "activation_fn=None" 
</span>    <span class="n">num_outputs</span> <span class="o">=</span> <span class="mi">6</span>
    <span class="n">Z3</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">contrib</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">fully_connected</span><span class="p">(</span><span class="n">F</span><span class="p">,</span> <span class="n">num_outputs</span><span class="p">,</span> <span class="n">activation_fn</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
    <span class="c1">### END CODE HERE ###
</span>
    <span class="k">return</span> <span class="n">Z3</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">tf</span><span class="p">.</span><span class="n">reset_default_graph</span><span class="p">()</span>

<span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">create_placeholders</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
    <span class="n">parameters</span> <span class="o">=</span> <span class="n">initialize_parameters</span><span class="p">()</span>
    <span class="n">Z3</span> <span class="o">=</span> <span class="n">forward_propagation</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">parameters</span><span class="p">)</span>
    <span class="n">init</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">global_variables_initializer</span><span class="p">()</span>
    <span class="n">sess</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">init</span><span class="p">)</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">sess</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">Z3</span><span class="p">,</span> <span class="p">{</span><span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">64</span><span class="p">,</span><span class="mi">64</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">Y</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">6</span><span class="p">)})</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"Z3 = </span><span class="se">\n</span><span class="s">"</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">a</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Z3 = 
[[-0.44670227 -1.57208765 -1.53049231 -2.31013036 -1.29104376  0.46852064]
 [-0.17601591 -1.57972014 -1.4737016  -2.61672091 -1.00810647  0.5747785 ]]
</code></pre></div></div>

<p><strong>Expected Output</strong>:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Z3 = 
[[-0.44670227 -1.57208765 -1.53049231 -2.31013036 -1.29104376  0.46852064]
 [-0.17601591 -1.57972014 -1.4737016  -2.61672091 -1.00810647  0.5747785 ]]
</code></pre></div></div>

<h3 id="14---compute-cost">1.4 - Compute cost</h3>

<p>Implement the compute cost function below. Remember that the cost function helps the neural network see how much the model’s predictions differ from the correct labels.  By adjusting the weights of the network to reduce the cost, the neural network can improve its predictions.</p>

<p>You might find these two functions helpful:</p>

<ul>
  <li><strong>tf.nn.softmax_cross_entropy_with_logits(logits = Z, labels = Y):</strong> computes the softmax entropy loss. This function both computes the softmax activation function as well as the resulting loss. You can check the full documentation  <a href="https://www.tensorflow.org/api_docs/python/tf/nn/softmax_cross_entropy_with_logits">softmax_cross_entropy_with_logits</a>.</li>
  <li><strong>tf.reduce_mean:</strong> computes the mean of elements across dimensions of a tensor. Use this to calculate the sum of the losses over all the examples to get the overall cost. You can check the full documentation <a href="https://www.tensorflow.org/api_docs/python/tf/reduce_mean">reduce_mean</a>.</li>
</ul>

<h4 id="details-on-softmax_cross_entropy_with_logits-optional-reading">Details on softmax_cross_entropy_with_logits (optional reading)</h4>
<ul>
  <li>Softmax is used to format outputs so that they can be used for classification.  It assigns a value between 0 and 1 for each category, where the sum of all prediction values (across all possible categories) equals 1.</li>
  <li>Cross Entropy is compares the model’s predicted classifications with the actual labels and results in a numerical value representing the “loss” of the model’s predictions.</li>
  <li>“Logits” are the result of multiplying the weights and adding the biases.  Logits are passed through an activation function (such as a relu), and the result is called the “activation.”</li>
  <li>The function is named <code class="language-plaintext highlighter-rouge">softmax_cross_entropy_with_logits</code> takes logits as input (and not activations); then uses the model to predict using softmax, and then compares the predictions with the true labels using cross entropy.  These are done with a single function to optimize the calculations.</li>
</ul>

<p>** Exercise**: Compute the cost below using the function above.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># GRADED FUNCTION: compute_cost 
</span>
<span class="k">def</span> <span class="nf">compute_cost</span><span class="p">(</span><span class="n">Z3</span><span class="p">,</span> <span class="n">Y</span><span class="p">):</span>
    <span class="s">"""
    Computes the cost
    
    Arguments:
    Z3 -- output of forward propagation (output of the last LINEAR unit), of shape (number of examples, 6)
    Y -- "true" labels vector placeholder, same shape as Z3
    
    Returns:
    cost - Tensor of the cost function
    """</span>
    
    <span class="c1">### START CODE HERE ### (1 line of code)
</span>    <span class="n">cost</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">softmax_cross_entropy_with_logits</span><span class="p">(</span><span class="n">logits</span> <span class="o">=</span> <span class="n">Z3</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">Y</span><span class="p">))</span>
    <span class="c1">### END CODE HERE ###
</span>    
    <span class="k">return</span> <span class="n">cost</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">tf</span><span class="p">.</span><span class="n">reset_default_graph</span><span class="p">()</span>

<span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">create_placeholders</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
    <span class="n">parameters</span> <span class="o">=</span> <span class="n">initialize_parameters</span><span class="p">()</span>
    <span class="n">Z3</span> <span class="o">=</span> <span class="n">forward_propagation</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">parameters</span><span class="p">)</span>
    <span class="n">cost</span> <span class="o">=</span> <span class="n">compute_cost</span><span class="p">(</span><span class="n">Z3</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
    <span class="n">init</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">global_variables_initializer</span><span class="p">()</span>
    <span class="n">sess</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">init</span><span class="p">)</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">sess</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">cost</span><span class="p">,</span> <span class="p">{</span><span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">64</span><span class="p">,</span><span class="mi">64</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">Y</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">6</span><span class="p">)})</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"cost = "</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">a</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cost = 2.91034
</code></pre></div></div>

<p><strong>Expected Output</strong>:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cost = 2.91034
</code></pre></div></div>

<h2 id="15-model">1.5 Model</h2>

<p>Finally you will merge the helper functions you implemented above to build a model. You will train it on the SIGNS dataset.</p>

<p><strong>Exercise</strong>: Complete the function below.</p>

<p>The model below should:</p>

<ul>
  <li>create placeholders</li>
  <li>initialize parameters</li>
  <li>forward propagate</li>
  <li>compute the cost</li>
  <li>create an optimizer</li>
</ul>

<p>Finally you will create a session and run a for loop  for num_epochs, get the mini-batches, and then for each mini-batch you will optimize the function. <a href="https://www.tensorflow.org/api_docs/python/tf/global_variables_initializer">Hint for initializing the variables</a></p>

<h4 id="adam-optimizer">Adam Optimizer</h4>
<p>You can use <code class="language-plaintext highlighter-rouge">tf.train.AdamOptimizer(learning_rate = ...)</code> to create the optimizer.  The optimizer has a <code class="language-plaintext highlighter-rouge">minimize(loss=...)</code> function that you’ll call to set the cost function that the optimizer will minimize.</p>

<p>For details, check out the documentation for <a href="https://www.tensorflow.org/api_docs/python/tf/train/AdamOptimizer">Adam Optimizer</a></p>

<h4 id="random-mini-batches">Random mini batches</h4>
<p>If you took course 2 of the deep learning specialization, you implemented <code class="language-plaintext highlighter-rouge">random_mini_batches()</code> in the “Optimization” programming assignment. This function returns a list of mini-batches. It is already implemented in the <code class="language-plaintext highlighter-rouge">cnn_utils.py</code> file and imported here, so you can call it like this:</p>
<pre><code class="language-Python">minibatches = random_mini_batches(X, Y, mini_batch_size = 64, seed = 0)
</code></pre>
<p>(You will want to choose the correct variable names when you use it in your code).</p>

<h4 id="evaluating-the-optimizer-and-cost">Evaluating the optimizer and cost</h4>

<p>Within a loop, for each mini-batch, you’ll use the <code class="language-plaintext highlighter-rouge">tf.Session</code> object (named <code class="language-plaintext highlighter-rouge">sess</code>) to feed a mini-batch of inputs and labels into the neural network and evaluate the tensors for the optimizer as well as the cost.  Remember that we built a graph data structure and need to feed it inputs and labels and use <code class="language-plaintext highlighter-rouge">sess.run()</code> in order to get values for the optimizer and cost.</p>

<p>You’ll use this kind of syntax:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>output_for_var1, output_for_var2 = sess.run(
                                                fetches=[var1, var2],
                                                feed_dict={var_inputs: the_batch_of_inputs,
                                                           var_labels: the_batch_of_labels}
                                                )
</code></pre></div></div>
<ul>
  <li>Notice that <code class="language-plaintext highlighter-rouge">sess.run</code> takes its first argument <code class="language-plaintext highlighter-rouge">fetches</code> as a list of objects that you want it to evaluate (in this case, we want to evaluate the optimizer and the cost).</li>
  <li>It also takes a dictionary for the <code class="language-plaintext highlighter-rouge">feed_dict</code> parameter.</li>
  <li>The keys are the <code class="language-plaintext highlighter-rouge">tf.placeholder</code> variables that we created in the <code class="language-plaintext highlighter-rouge">create_placeholders</code> function above.</li>
  <li>The values are the variables holding the actual numpy arrays for each mini-batch.</li>
  <li>The sess.run outputs a tuple of the evaluated tensors, in the same order as the list given to <code class="language-plaintext highlighter-rouge">fetches</code>.</li>
</ul>

<p>For more information on how to use sess.run, see the documentation <a href="https://www.tensorflow.org/api_docs/python/tf/Session#run">tf.Sesssion#run</a> documentation.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># GRADED FUNCTION: model
</span>
<span class="k">def</span> <span class="nf">model</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">,</span> <span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.009</span><span class="p">,</span>
          <span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n">minibatch_size</span> <span class="o">=</span> <span class="mi">64</span><span class="p">,</span> <span class="n">print_cost</span> <span class="o">=</span> <span class="bp">True</span><span class="p">):</span>
    <span class="s">"""
    Implements a three-layer ConvNet in Tensorflow:
    CONV2D -&gt; RELU -&gt; MAXPOOL -&gt; CONV2D -&gt; RELU -&gt; MAXPOOL -&gt; FLATTEN -&gt; FULLYCONNECTED
    
    Arguments:
    X_train -- training set, of shape (None, 64, 64, 3)
    Y_train -- test set, of shape (None, n_y = 6)
    X_test -- training set, of shape (None, 64, 64, 3)
    Y_test -- test set, of shape (None, n_y = 6)
    learning_rate -- learning rate of the optimization
    num_epochs -- number of epochs of the optimization loop
    minibatch_size -- size of a minibatch
    print_cost -- True to print the cost every 100 epochs
    
    Returns:
    train_accuracy -- real number, accuracy on the train set (X_train)
    test_accuracy -- real number, testing accuracy on the test set (X_test)
    parameters -- parameters learnt by the model. They can then be used to predict.
    """</span>
    
    <span class="n">ops</span><span class="p">.</span><span class="n">reset_default_graph</span><span class="p">()</span>                         <span class="c1"># to be able to rerun the model without overwriting tf variables
</span>    <span class="n">tf</span><span class="p">.</span><span class="n">set_random_seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>                             <span class="c1"># to keep results consistent (tensorflow seed)
</span>    <span class="n">seed</span> <span class="o">=</span> <span class="mi">3</span>                                          <span class="c1"># to keep results consistent (numpy seed)
</span>    <span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">n_H0</span><span class="p">,</span> <span class="n">n_W0</span><span class="p">,</span> <span class="n">n_C0</span><span class="p">)</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">.</span><span class="n">shape</span>             
    <span class="n">n_y</span> <span class="o">=</span> <span class="n">Y_train</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>                            
    <span class="n">costs</span> <span class="o">=</span> <span class="p">[]</span>                                        <span class="c1"># To keep track of the cost
</span>    
    <span class="c1"># Create Placeholders of the correct shape
</span>    <span class="c1">### START CODE HERE ### (1 line)
</span>    <span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">create_placeholders</span><span class="p">(</span><span class="n">n_H0</span><span class="p">,</span> <span class="n">n_W0</span><span class="p">,</span> <span class="n">n_C0</span><span class="p">,</span> <span class="n">n_y</span><span class="p">)</span>
    <span class="c1">### END CODE HERE ###
</span>
    <span class="c1"># Initialize parameters
</span>    <span class="c1">### START CODE HERE ### (1 line)
</span>    <span class="n">parameters</span> <span class="o">=</span> <span class="n">initialize_parameters</span><span class="p">()</span>
    <span class="c1">### END CODE HERE ###
</span>    
    <span class="c1"># Forward propagation: Build the forward propagation in the tensorflow graph
</span>    <span class="c1">### START CODE HERE ### (1 line)
</span>    <span class="n">Z3</span> <span class="o">=</span> <span class="n">forward_propagation</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">parameters</span><span class="p">)</span>
    <span class="c1">### END CODE HERE ###
</span>    
    <span class="c1"># Cost function: Add cost function to tensorflow graph
</span>    <span class="c1">### START CODE HERE ### (1 line)
</span>    <span class="n">cost</span> <span class="o">=</span> <span class="n">compute_cost</span><span class="p">(</span><span class="n">Z3</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
    <span class="c1">### END CODE HERE ###
</span>    
    <span class="c1"># Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer that minimizes the cost.
</span>    <span class="c1">### START CODE HERE ### (1 line)
</span>    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">train</span><span class="p">.</span><span class="n">AdamOptimizer</span><span class="p">(</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">learning_rate</span><span class="p">).</span><span class="n">minimize</span><span class="p">(</span><span class="n">loss</span> <span class="o">=</span> <span class="n">cost</span><span class="p">)</span>
    <span class="c1">### END CODE HERE ###
</span>    
    <span class="c1"># Initialize all the variables globally
</span>    <span class="n">init</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">global_variables_initializer</span><span class="p">()</span>
     
    <span class="c1"># Start the session to compute the tensorflow graph
</span>    <span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
        
        <span class="c1"># Run the initialization
</span>        <span class="n">sess</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">init</span><span class="p">)</span>
        
        <span class="c1"># Do the training loop
</span>        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>

            <span class="n">minibatch_cost</span> <span class="o">=</span> <span class="mf">0.</span>
            <span class="n">num_minibatches</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">m</span> <span class="o">/</span> <span class="n">minibatch_size</span><span class="p">)</span> <span class="c1"># number of minibatches of size minibatch_size in the train set
</span>            <span class="n">seed</span> <span class="o">=</span> <span class="n">seed</span> <span class="o">+</span> <span class="mi">1</span>
            <span class="n">minibatches</span> <span class="o">=</span> <span class="n">random_mini_batches</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">minibatch_size</span><span class="p">,</span> <span class="n">seed</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">minibatch</span> <span class="ow">in</span> <span class="n">minibatches</span><span class="p">:</span>

                <span class="c1"># Select a minibatch
</span>                <span class="p">(</span><span class="n">minibatch_X</span><span class="p">,</span> <span class="n">minibatch_Y</span><span class="p">)</span> <span class="o">=</span> <span class="n">minibatch</span>
                <span class="s">"""
                # IMPORTANT: The line that runs the graph on a minibatch.
                # Run the session to execute the optimizer and the cost.
                # The feedict should contain a minibatch for (X,Y).
                """</span>
                <span class="c1">### START CODE HERE ### (1 line)
</span>                <span class="n">_</span> <span class="p">,</span> <span class="n">temp_cost</span> <span class="o">=</span> <span class="n">sess</span><span class="p">.</span><span class="n">run</span><span class="p">([</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">cost</span><span class="p">],</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">X</span><span class="p">:</span><span class="n">minibatch_X</span><span class="p">,</span> <span class="n">Y</span><span class="p">:</span><span class="n">minibatch_Y</span><span class="p">})</span>
                <span class="c1">### END CODE HERE ###
</span>                
                <span class="n">minibatch_cost</span> <span class="o">+=</span> <span class="n">temp_cost</span> <span class="o">/</span> <span class="n">num_minibatches</span>
                

            <span class="c1"># Print the cost every epoch
</span>            <span class="k">if</span> <span class="n">print_cost</span> <span class="o">==</span> <span class="bp">True</span> <span class="ow">and</span> <span class="n">epoch</span> <span class="o">%</span> <span class="mi">5</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">print</span> <span class="p">(</span><span class="s">"Cost after epoch %i: %f"</span> <span class="o">%</span> <span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">minibatch_cost</span><span class="p">))</span>
            <span class="k">if</span> <span class="n">print_cost</span> <span class="o">==</span> <span class="bp">True</span> <span class="ow">and</span> <span class="n">epoch</span> <span class="o">%</span> <span class="mi">1</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">costs</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">minibatch_cost</span><span class="p">)</span>
        
        
        <span class="c1"># plot the cost
</span>        <span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">costs</span><span class="p">))</span>
        <span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'cost'</span><span class="p">)</span>
        <span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'iterations (per tens)'</span><span class="p">)</span>
        <span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Learning rate ="</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">learning_rate</span><span class="p">))</span>
        <span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>

        <span class="c1"># Calculate the correct predictions
</span>        <span class="n">predict_op</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">Z3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">correct_prediction</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">equal</span><span class="p">(</span><span class="n">predict_op</span><span class="p">,</span> <span class="n">tf</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        
        <span class="c1"># Calculate accuracy on the test set
</span>        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">cast</span><span class="p">(</span><span class="n">correct_prediction</span><span class="p">,</span> <span class="s">"float"</span><span class="p">))</span>
        <span class="k">print</span><span class="p">(</span><span class="n">accuracy</span><span class="p">)</span>
        <span class="n">train_accuracy</span> <span class="o">=</span> <span class="n">accuracy</span><span class="p">.</span><span class="nb">eval</span><span class="p">({</span><span class="n">X</span><span class="p">:</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">Y</span><span class="p">:</span> <span class="n">Y_train</span><span class="p">})</span>
        <span class="n">test_accuracy</span> <span class="o">=</span> <span class="n">accuracy</span><span class="p">.</span><span class="nb">eval</span><span class="p">({</span><span class="n">X</span><span class="p">:</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">Y</span><span class="p">:</span> <span class="n">Y_test</span><span class="p">})</span>
        <span class="k">print</span><span class="p">(</span><span class="s">"Train Accuracy:"</span><span class="p">,</span> <span class="n">train_accuracy</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s">"Test Accuracy:"</span><span class="p">,</span> <span class="n">test_accuracy</span><span class="p">)</span>
                
        <span class="k">return</span> <span class="n">train_accuracy</span><span class="p">,</span> <span class="n">test_accuracy</span><span class="p">,</span> <span class="n">parameters</span>
</code></pre></div></div>

<p>Run the following cell to train your model for 100 epochs. Check if your cost after epoch 0 and 5 matches our output. If not, stop the cell and go back to your code!</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">parameters</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Cost after epoch 0: 1.917929
Cost after epoch 5: 1.506757
Cost after epoch 10: 0.955359
Cost after epoch 15: 0.845802
Cost after epoch 20: 0.701174
Cost after epoch 25: 0.571977
Cost after epoch 30: 0.518435
Cost after epoch 35: 0.495806
Cost after epoch 40: 0.429827
Cost after epoch 45: 0.407291
Cost after epoch 50: 0.366394
Cost after epoch 55: 0.376922
Cost after epoch 60: 0.299491
Cost after epoch 65: 0.338870
Cost after epoch 70: 0.316400
Cost after epoch 75: 0.310413
Cost after epoch 80: 0.249549
Cost after epoch 85: 0.243457
Cost after epoch 90: 0.200031
Cost after epoch 95: 0.175452
</code></pre></div></div>

<p><img src="/assets/2023-12-01-Convolution-model-Application-v1a_files/2023-12-01-Convolution-model-Application-v1a_33_1.png" alt="png" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Tensor("Mean_1:0", shape=(), dtype=float32)
Train Accuracy: 0.940741
Test Accuracy: 0.783333
</code></pre></div></div>

<p><strong>Expected output</strong>: although it may not match perfectly, your expected output should be close to ours and your cost value should decrease.</p>

<table> 
<tr>
    <td> 
    **Cost after epoch 0 =**
    </td>

    <td> 
      1.917929
    </td> 
</tr>
<tr>
    <td> 
    **Cost after epoch 5 =**
    </td>

    <td> 
      1.506757
    </td> 
</tr>
<tr>
    <td> 
    **Train Accuracy   =**
    </td>

    <td> 
      0.940741
    </td> 
</tr> 

<tr>
    <td> 
    **Test Accuracy   =**
    </td>

    <td> 
      0.783333
    </td> 
</tr> 
</table>

<p>Congratulations! You have finished the assignment and built a model that recognizes SIGN language with almost 80% accuracy on the test set. If you wish, feel free to play around with this dataset further. You can actually improve its accuracy by spending more time tuning the hyperparameters, or using regularization (as this model clearly has a high variance).</p>

<p>Once again, here’s a thumbs up for your work!</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fname</span> <span class="o">=</span> <span class="s">"/assets/2023-12-01-Convolution-model-Application-v1a_files/thumbs_up.jpg"</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">ndimage</span><span class="p">.</span><span class="n">imread</span><span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="n">flatten</span><span class="o">=</span><span class="bp">False</span><span class="p">))</span>
<span class="n">my_image</span> <span class="o">=</span> <span class="n">scipy</span><span class="p">.</span><span class="n">misc</span><span class="p">.</span><span class="n">imresize</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span><span class="mi">64</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">my_image</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;matplotlib.image.AxesImage at 0x7fd681a816a0&gt;
</code></pre></div></div>

<p><img src="/assets/2023-12-01-Convolution-model-Application-v1a_files/2023-12-01-Convolution-model-Application-v1a_36_1.png" alt="png" /></p>]]></content><author><name>Zhu Tianda</name></author><category term="coding" /><category term="AI" /><summary type="html"><![CDATA[Convolutional Neural Networks: Application]]></summary></entry><entry><title type="html">Convolutional Neural Networks: Step by Step</title><link href="http://0.0.0.0:8855/coding/2023/12/01/convolutional-neural-networks-step-by-step.html" rel="alternate" type="text/html" title="Convolutional Neural Networks: Step by Step" /><published>2023-12-01T00:00:00+08:00</published><updated>2023-12-01T00:00:00+08:00</updated><id>http://0.0.0.0:8855/coding/2023/12/01/convolutional-neural-networks-step-by-step</id><content type="html" xml:base="http://0.0.0.0:8855/coding/2023/12/01/convolutional-neural-networks-step-by-step.html"><![CDATA[<p>卷积的数学表示
\(f∗g(n)=∫_{−∞}^{+∞}​f(τ)g(n−τ)dτ\)
上面公式是连续的定义，再看看离散的定义：</p>

\[f∗g(n)=τ=∑_{−∞}^{+∞}​f(τ)g(n−τ)\]

<p>互相关与卷积
一些深度学习教程都使用这种互相关运算来解释卷积的计算过程。但实际上，计算过程并非学术上严格意义上的卷积。
我们将这种互相关的矩阵乘法转换成公式，如果输入矩阵为I，核矩阵为K，核矩阵K形状为m×n。我们想要得到输出矩阵O中(i,j)位置的元素，其实就是对矩阵中各个数字做乘法，最后累加到一起。
\(O(i,j)=(K∗I)(i,j)=\sum_m\sum_n​I(i+m,j+n)K(m,n)\)</p>

<p>上面公式中，$I(i+m,j+n)K(m,n)$表示输入矩阵的某个元素I(i+m,j+n)与核矩阵的元素K(m,n)相乘。$\sum_m$和$\sum_n$​分别在矩阵的横向和纵向做累加。
但这个公式依然与最初看到的卷积公式有些区别，我们将输入矩阵的加号改为减号：\(O(i,j)=(K∗I)(i,j)=\sum_m\sum_n​I(i−m,j−n)K(m,n)\)</p>

<p>这就出现了卷积公式中的减号，那么这两个矩阵实际的计算类似于：</p>

<p><img src="/assets/2023-12-01-convolutional-neural-networks-step-by-step_files/j1ni4qxh.png" style="width:700px;height:400px;" /></p>

<p>图4 两个矩阵之间进行卷积运算</p>

<p>也就是说，输入矩阵深色区域的最后一个元素与核矩阵的第一个元素相乘，输入矩阵深色区域的倒数第二个元素与核矩阵的第二个元素相乘，以此类推…又或者说，<strong>把核矩阵旋转180度，再与输入矩阵相乘。</strong></p>

<p>卷积数学公式中的减号，在二维矩阵的场景下，可以被解释为：先旋转、再相乘。<strong>由于在深度学习中，核矩阵是一个需要训练的参数，卷积神经网络都是针对图像，图像即使旋转180度，对于计算机来说区别不大</strong>。旋转与否，或者说是否使用减号，对于深度学习来说关系不大，反而不旋转的互相关运算计算起来更方便。因此，很多深度学习框架直接使用互相关运算来表示卷积的过程。</p>

<h1 id="convolutional-neural-networks-step-by-step">Convolutional Neural Networks: Step by Step</h1>

<p>Welcome to Course 4’s first assignment! In this assignment, you will implement convolutional (CONV) and pooling (POOL) layers in numpy, including both forward propagation and (optionally) backward propagation.</p>

<p><strong>Notation</strong>:</p>
<ul>
  <li>Superscript $[l]$ denotes an object of the $l^{th}$ layer.
    <ul>
      <li>Example: $a^{[4]}$ is the $4^{th}$ layer activation. $W^{[5]}$ and $b^{[5]}$ are the $5^{th}$ layer parameters.</li>
    </ul>
  </li>
  <li>Superscript $(i)$ denotes an object from the $i^{th}$ example.
    <ul>
      <li>Example: $x^{(i)}$ is the $i^{th}$ training example input.</li>
    </ul>
  </li>
  <li>Lowerscript $i$ denotes the $i^{th}$ entry of a vector.
    <ul>
      <li>Example: $a^{[l]}_i$ denotes the $i^{th}$ entry of the activations in layer $l$, assuming this is a fully connected (FC) layer.</li>
    </ul>
  </li>
  <li>$n_H$, $n_W$ and $n_C$ denote respectively the height, width and number of channels of a given layer. If you want to reference a specific layer $l$, you can also write $n_H^{[l]}$, $n_W^{[l]}$, $n_C^{[l]}$.</li>
  <li>$n_{H_{prev}}$, $n_{W_{prev}}$ and $n_{C_{prev}}$ denote respectively the height, width and number of channels of the previous layer. If referencing a specific layer $l$, this could also be denoted $n_H^{[l-1]}$, $n_W^{[l-1]}$, $n_C^{[l-1]}$.</li>
</ul>

<p>We assume that you are already familiar with <code class="language-plaintext highlighter-rouge">numpy</code> and/or have completed the previous courses of the specialization. Let’s get started!</p>

<h2 id="1---packages">1 - Packages</h2>

<p>Let’s first import all the packages that you will need during this assignment.</p>
<ul>
  <li><a href="www.numpy.org">numpy</a> is the fundamental package for scientific computing with Python.</li>
  <li><a href="http://matplotlib.org">matplotlib</a> is a library to plot graphs in Python.</li>
  <li>np.random.seed(1) is used to keep all the random function calls consistent. It will help us grade your work.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">h5py</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="n">plt</span><span class="p">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s">'figure.figsize'</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mf">5.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">)</span> <span class="c1"># set default size of plots
</span><span class="n">plt</span><span class="p">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s">'image.interpolation'</span><span class="p">]</span> <span class="o">=</span> <span class="s">'nearest'</span>
<span class="n">plt</span><span class="p">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s">'image.cmap'</span><span class="p">]</span> <span class="o">=</span> <span class="s">'gray'</span>

<span class="o">%</span><span class="n">load_ext</span> <span class="n">autoreload</span>
<span class="o">%</span><span class="n">autoreload</span> <span class="mi">2</span>

<span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="2---outline-of-the-assignment">2 - Outline of the Assignment</h2>

<p>You will be implementing the building blocks of a convolutional neural network! Each function you will implement will have detailed instructions that will walk you through the steps needed:</p>

<ul>
  <li>Convolution functions, including:
    <ul>
      <li>Zero Padding</li>
      <li>Convolve window</li>
      <li>Convolution forward</li>
      <li>Convolution backward (optional)</li>
    </ul>
  </li>
  <li>Pooling functions, including:
    <ul>
      <li>Pooling forward</li>
      <li>Create mask</li>
      <li>Distribute value</li>
      <li>Pooling backward (optional)</li>
    </ul>
  </li>
</ul>

<p>This notebook will ask you to implement these functions from scratch in <code class="language-plaintext highlighter-rouge">numpy</code>. In the next notebook, you will use the TensorFlow equivalents of these functions to build the following model:</p>

<p><img src="/assets/2023-12-01-convolutional-neural-networks-step-by-step_files/da1b0164-5374-428a-b22e-f6449c637892.png" alt="model.png" /><br />
<strong>Note</strong> that for every forward function, there is its corresponding backward equivalent. Hence, at every step of your forward module you will store some parameters in a cache. These parameters are used to compute gradients during backpropagation.</p>

<h2 id="3---convolutional-neural-networks">3 - Convolutional Neural Networks</h2>

<p>Although programming frameworks make convolutions easy to use, they remain one of the hardest concepts to understand in Deep Learning. A convolution layer transforms an input volume into an output volume of different size, as shown below.</p>

<p><img src="/assets/2023-12-01-convolutional-neural-networks-step-by-step_files/ba23f49b-6548-40e9-afc6-7f5d5953554d.png" style="width:350px;height:200px;" /></p>

<p><img src="/assets/2023-12-01-convolutional-neural-networks-step-by-step_files/ba23f49b-6548-40e9-afc6-7f5d5953554d.png" alt="conv_nn.png" /></p>

<p>In this part, you will build every step of the convolution layer. You will first implement two helper functions: one for zero padding and the other for computing the convolution function itself.</p>

<h3 id="31---zero-padding">3.1 - Zero-Padding</h3>

<p>Zero-padding adds zeros around the border of an image:</p>

<p><img src="/assets/2023-12-01-convolutional-neural-networks-step-by-step_files/aee3a50b-9668-4d72-9897-74c140a78058.png" style="width:600px;height:400px;" /></p>
<caption><center> <u>  **Figure 1** </u>&gt;  : **Zero-Padding** Image (3 channels, RGB) with a padding of 2. </center></caption>

<p><img src="/assets/2023-12-01-convolutional-neural-networks-step-by-step_files/aee3a50b-9668-4d72-9897-74c140a78058.png" alt="PAD.png" /></p>

<p><strong>The main benefits of padding are the following:</strong></p>

<ul>
  <li>
    <p><strong>It allows you to use a CONV layer without necessarily shrinking the height and width of the volumes.</strong> This is important for building deeper networks, since otherwise the height/width would shrink as you go to deeper layers. An important special case is the “same” convolution, in which the height/width is exactly preserved after one layer.</p>
  </li>
  <li>
    <p><strong>It helps us keep more of the information at the border of an image</strong>. Without padding, very few values at the next layer would be affected by pixels as the edges of an image.</p>
  </li>
</ul>

<p><strong>Exercise</strong>: Implement the following function, which pads all the images of a batch of examples X with zeros. <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.pad.html">Use np.pad</a>. Note if you want to pad the array “a” of shape $(5,5,5,5,5)$ with <code class="language-plaintext highlighter-rouge">pad = 1</code> for the 2nd dimension, <code class="language-plaintext highlighter-rouge">pad = 3</code> for the 4th dimension and <code class="language-plaintext highlighter-rouge">pad = 0</code> for the rest, you would do:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">pad</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="p">((</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">)),</span> <span class="s">'constant'</span><span class="p">,</span> <span class="n">constant_values</span> <span class="o">=</span> <span class="p">(..,..))</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># GRADED FUNCTION: zero_pad
</span>
<span class="k">def</span> <span class="nf">zero_pad</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">pad</span><span class="p">):</span>
    <span class="s">"""
    Pad with zeros all images of the dataset X. The padding is applied to the height and width of an image, 
    as illustrated in Figure 1.
    
    Argument:
    X -- python numpy array of shape (m, n_H, n_W, n_C) representing a batch of m images
    pad -- integer, amount of padding around each image on vertical and horizontal dimensions
    
    Returns:
    X_pad -- padded image of shape (m, n_H + 2*pad, n_W + 2*pad, n_C)
    """</span>
    
    <span class="c1">### START CODE HERE ### (≈ 1 line)
</span>    <span class="n">X_pad</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">pad</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="p">((</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">),(</span><span class="n">pad</span><span class="p">,</span><span class="n">pad</span><span class="p">),(</span><span class="n">pad</span><span class="p">,</span><span class="n">pad</span><span class="p">),(</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">)),</span><span class="s">'constant'</span><span class="p">,</span> <span class="n">constant_values</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">))</span>
    <span class="c1">### END CODE HERE ###
</span>    
    <span class="k">return</span> <span class="n">X_pad</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">x_pad</span> <span class="o">=</span> <span class="n">zero_pad</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="k">print</span> <span class="p">(</span><span class="s">"x.shape ="</span><span class="p">,</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
<span class="k">print</span> <span class="p">(</span><span class="s">"x_pad.shape ="</span><span class="p">,</span> <span class="n">x_pad</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
<span class="k">print</span> <span class="p">(</span><span class="s">"x[1,1] ="</span><span class="p">,</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>  <span class="c1">#the first 3x2 
</span><span class="k">print</span> <span class="p">(</span><span class="s">"x_pad[1,1] ="</span><span class="p">,</span> <span class="n">x_pad</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axarr</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">axarr</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">'x'</span><span class="p">)</span>
<span class="n">axarr</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">imshow</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">,:,:,</span><span class="mi">0</span><span class="p">])</span>
<span class="n">axarr</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">'x_pad'</span><span class="p">)</span>
<span class="n">axarr</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">imshow</span><span class="p">(</span><span class="n">x_pad</span><span class="p">[</span><span class="mi">0</span><span class="p">,:,:,</span><span class="mi">0</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>x.shape = (4, 3, 3, 2)
x_pad.shape = (4, 7, 7, 2)
x[1,1] = [[ 0.90085595 -0.68372786]
 [-0.12289023 -0.93576943]
 [-0.26788808  0.53035547]]
x_pad[1,1] = [[0. 0.]
 [0. 0.]
 [0. 0.]
 [0. 0.]
 [0. 0.]
 [0. 0.]
 [0. 0.]]





&lt;matplotlib.image.AxesImage at 0x7f4ddd522dd0&gt;
</code></pre></div></div>

<p><img src="/assets/2023-12-01-convolutional-neural-networks-step-by-step_files/2023-12-01-convolutional-neural-networks-step-by-step_8_2.png" alt="png" /></p>

<p><strong>Expected Output</strong>:</p>

<table>
    <tr>
        <td>
            **x.shape**:
        </td>
        <td>
           (4, 3, 3, 2)
        </td>
    </tr>
        <tr>
        <td>
            **x_pad.shape**:
        </td>
        <td>
           (4, 7, 7, 2)
        </td>
    </tr>
        <tr>
        <td>
            **x[1,1]**:
        </td>
        <td>
           [[ 0.90085595 -0.68372786]
 [-0.12289023 -0.93576943]
 [-0.26788808  0.53035547]]
        </td>
    </tr>
        <tr>
        <td>
            **x_pad[1,1]**:
        </td>
        <td>
           [[ 0.  0.]
 [ 0.  0.]
 [ 0.  0.]
 [ 0.  0.]
 [ 0.  0.]
 [ 0.  0.]
 [ 0.  0.]]
        </td>
    </tr>

</table>

<h3 id="32---single-step-of-convolution">3.2 - Single step of convolution</h3>

<p>In this part, <strong>implement a single step of convolution</strong>, in which you apply the filter to a single position of the input. This will be used to build a convolutional unit, which:</p>

<ul>
  <li>Takes an input volume</li>
  <li>Applies a filter at every position of the input</li>
  <li>Outputs another volume (usually of different size)</li>
</ul>

<p><img src="/assets/2023-12-01-convolutional-neural-networks-step-by-step_files/23c61b52-6461-4a00-8a7f-07945136cd78.gif" style="width:500px;height:300px;" /></p>
<caption><center> <u>  **Figure 2** </u> : **Convolution operation** with a filter of 2x2 and a stride of 1 (stride = amount you move the window each time you slide) </center></caption>

<p><img src="/assets/2023-12-01-convolutional-neural-networks-step-by-step_files/23c61b52-6461-4a00-8a7f-07945136cd78.gif" alt="Convolution_schematic.gif" /></p>

<p>In a computer vision application, each value in the matrix on the left corresponds to a single pixel value, and we convolve a 3x3 filter with the image by multiplying its values element-wise with the original matrix, then summing them up and adding a bias. In this first step of the exercise, you will implement a single step of convolution, corresponding to applying a filter to just one of the positions to get a single real-valued output.</p>

<p>Later in this notebook, you’ll apply this function to multiple positions of the input to implement the full convolutional operation.</p>

<p><strong>Exercise</strong>: Implement conv_single_step(). <a href="https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.sum.html">Hint</a>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># GRADED FUNCTION: conv_single_step
</span>
<span class="k">def</span> <span class="nf">conv_single_step</span><span class="p">(</span><span class="n">a_slice_prev</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
    <span class="s">"""
    Apply one filter defined by parameters W on a single slice (a_slice_prev) of the output activation 
    of the previous layer.
    
    Arguments:
    a_slice_prev -- slice of input data of shape (f, f, n_C_prev)
    W -- Weight parameters contained in a window - matrix of shape (f, f, n_C_prev)
    b -- Bias parameters contained in a window - matrix of shape (1, 1, 1)
    
    Returns:
    Z -- a scalar value, result of convolving the sliding window (W, b) on a slice x of the input data
    """</span>

    <span class="c1">### START CODE HERE ### (≈ 2 lines of code)
</span>    <span class="c1"># Element-wise product between a_slice and W. Do not add the bias yet.
</span>    <span class="n">s</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">a_slice_prev</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span>
    <span class="c1"># Sum over all entries of the volume s.
</span>    <span class="n">Z</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
    <span class="c1"># Add bias b to Z. Cast b to a float() so that Z results in a scalar value.
</span>    <span class="n">Z</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">squeeze</span><span class="p">(</span> <span class="n">Z</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span>
    <span class="c1">### END CODE HERE ###
</span>
    <span class="k">return</span> <span class="n">Z</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">a_slice_prev</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">b</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">conv_single_step</span><span class="p">(</span><span class="n">a_slice_prev</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Z ="</span><span class="p">,</span> <span class="n">Z</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(1, 1, 1)
Z = -6.999089450680221
</code></pre></div></div>

<p><strong>Expected Output</strong>:</p>
<table>
    <tr>
        <td>
            **Z**
        </td>
        <td>
            -6.99908945068
        </td>
    </tr>

</table>

<h3 id="33---convolutional-neural-networks---forward-pass">3.3 - Convolutional Neural Networks - Forward pass</h3>

<p>In the forward pass, you will take many filters and convolve them on the input. Each ‘convolution’ gives you a 2D matrix output. You will then stack these outputs to get a 3D volume:</p>

<p><img src="/assets/2023-12-01-convolutional-neural-networks-step-by-step_files/738f8421-f255-4656-9e6a-22bd2537e5a5.png" style="width:600px;height:400px;" /></p>

<p><img src="/assets/2023-12-01-convolutional-neural-networks-step-by-step_files/738f8421-f255-4656-9e6a-22bd2537e5a5.png" alt="image.png" /></p>

<p><strong>Exercise</strong>: Implement the function below to convolve the filters W on an input activation A_prev. This function takes as input A_prev, the activations output by the previous layer (for a batch of m inputs), F filters/weights denoted by W, and a bias vector denoted by b, where each filter has its own (single) bias. Finally you also have access to the hyperparameters dictionary which contains the stride and the padding.</p>

<p><strong>Hint</strong>:</p>
<ol>
  <li>To select a 2x2 slice at the upper left corner of a matrix “a_prev” (shape (5,5,3)), you would do:
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">a_slice_prev</span> <span class="o">=</span> <span class="n">a_prev</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">,:]</span>
</code></pre></div>    </div>
    <p>This will be useful when you will define <code class="language-plaintext highlighter-rouge">a_slice_prev</code> below, using the <code class="language-plaintext highlighter-rouge">start/end</code> indexes you will define.</p>
  </li>
  <li>To define a_slice you will need to first define its corners <code class="language-plaintext highlighter-rouge">vert_start</code>, <code class="language-plaintext highlighter-rouge">vert_end</code>, <code class="language-plaintext highlighter-rouge">horiz_start</code> and <code class="language-plaintext highlighter-rouge">horiz_end</code>. This figure may be helpful for you to find how each of the corner can be defined using h, w, f and s in the code below.</li>
</ol>

<p><img src="/assets/2023-12-01-convolutional-neural-networks-step-by-step_files/85771fb2-5211-4c2f-a587-b75842931ce4.png" style="width:400px;height:300px;" /></p>
<caption><center> <u> **Figure 3** </u>:

![vert_horiz_kiank.png](/assets/2023-12-01-convolutional-neural-networks-step-by-step_files/85771fb2-5211-4c2f-a587-b75842931ce4.png)
**Definition of a slice using vertical and horizontal start/end (with a 2x2 filter)** <br /> This figure shows only a single channel.  </center></caption>

<p><strong>Reminder</strong>:
The formulas relating the output shape of the convolution to the input shape is:
\(n_H = \lfloor \frac{n_{H_{prev}} - f + 2 \times pad}{stride} \rfloor +1\)
\(n_W = \lfloor \frac{n_{W_{prev}} - f + 2 \times pad}{stride} \rfloor +1\)
\(n_C = \text{number of filters used in the convolution}\)</p>

<p>For this exercise, we won’t worry about vectorization, and will just implement everything with for-loops.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># GRADED FUNCTION: conv_forward
</span>
<span class="k">def</span> <span class="nf">conv_forward</span><span class="p">(</span><span class="n">A_prev</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">hparameters</span><span class="p">):</span>
    <span class="s">"""
    Implements the forward propagation for a convolution function
    
    Arguments:
    A_prev -- output activations of the previous layer, numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)
    W -- Weights, numpy array of shape (f, f, n_C_prev, n_C)
    b -- Biases, numpy array of shape (1, 1, 1, n_C)
    hparameters -- python dictionary containing "stride" and "pad"
        
    Returns:
    Z -- conv output, numpy array of shape (m, n_H, n_W, n_C)
    cache -- cache of values needed for the conv_backward() function
    """</span>
    
    <span class="c1">### START CODE HERE ###
</span>    <span class="c1"># Retrieve dimensions from A_prev's shape (≈1 line)  
</span>    <span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">n_H_prev</span><span class="p">,</span> <span class="n">n_W_prev</span><span class="p">,</span> <span class="n">n_C_prev</span><span class="p">)</span> <span class="o">=</span> <span class="n">A_prev</span><span class="p">.</span><span class="n">shape</span>
    
    <span class="c1"># Retrieve dimensions from W's shape (≈1 line)
</span>    <span class="c1"># n_c is the filter number 
</span>    <span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">n_C_prev</span><span class="p">,</span> <span class="n">n_C</span><span class="p">)</span> <span class="o">=</span> <span class="n">W</span><span class="p">.</span><span class="n">shape</span>  
    
    <span class="c1"># Retrieve information from "hparameters" (≈2 lines)
</span>    <span class="n">stride</span> <span class="o">=</span> <span class="n">hparameters</span><span class="p">[</span><span class="s">'stride'</span><span class="p">]</span>
    <span class="n">pad</span> <span class="o">=</span> <span class="n">hparameters</span><span class="p">[</span><span class="s">'pad'</span><span class="p">]</span>
    
    <span class="c1"># Compute the dimensions of the CONV output volume using the formula given above. Hint: use int() to floor. (≈2 lines)
</span>    <span class="n">n_H</span> <span class="o">=</span> <span class="nb">int</span><span class="p">((</span><span class="n">n_H_prev</span> <span class="o">-</span> <span class="n">f</span> <span class="o">+</span> <span class="mi">2</span><span class="o">*</span><span class="n">pad</span><span class="p">)</span><span class="o">/</span><span class="n">stride</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">n_W</span> <span class="o">=</span> <span class="nb">int</span><span class="p">((</span><span class="n">n_W_prev</span> <span class="o">-</span> <span class="n">f</span> <span class="o">+</span> <span class="mi">2</span><span class="o">*</span><span class="n">pad</span><span class="p">)</span><span class="o">/</span><span class="n">stride</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
    
    <span class="c1"># Initialize the output volume Z with zeros. (≈1 line)
</span>    <span class="n">Z</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">m</span><span class="p">,</span> <span class="n">n_H</span><span class="p">,</span> <span class="n">n_W</span><span class="p">,</span> <span class="n">n_C</span><span class="p">))</span>
    
    <span class="c1"># Create A_prev_pad by padding A_prev
</span>    <span class="n">A_prev_pad</span> <span class="o">=</span> <span class="n">zero_pad</span><span class="p">(</span><span class="n">A_prev</span><span class="p">,</span> <span class="n">pad</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>                               <span class="c1"># loop over the batch of training examples
</span>        <span class="n">a_prev_pad</span> <span class="o">=</span> <span class="n">A_prev_pad</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>                               <span class="c1"># Select ith training example's padded activation
</span>        <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_H</span><span class="p">):</span>                           <span class="c1"># loop over vertical axis of the output volume
</span>            <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_W</span><span class="p">):</span>                       <span class="c1"># loop over horizontal axis of the output volume
</span>                <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_C</span><span class="p">):</span>                   <span class="c1"># loop over channels (= #filters) of the output volume
</span>                    
                    <span class="c1"># Find the corners of the current "slice" (≈4 lines)
</span>                    <span class="n">vert_start</span> <span class="o">=</span> <span class="n">h</span> <span class="o">*</span> <span class="n">stride</span>
                    <span class="n">vert_end</span> <span class="o">=</span> <span class="n">vert_start</span> <span class="o">+</span> <span class="n">f</span>
                    <span class="n">horiz_start</span> <span class="o">=</span> <span class="n">w</span> <span class="o">*</span> <span class="n">stride</span>
                    <span class="n">horiz_end</span> <span class="o">=</span> <span class="n">horiz_start</span> <span class="o">+</span> <span class="n">f</span>
                    
                    <span class="c1"># Use the corners to define the (3D) slice of a_prev_pad (See Hint above the cell). (≈1 line)
</span>                    <span class="n">a_slice_prev</span> <span class="o">=</span> <span class="n">a_prev_pad</span><span class="p">[</span><span class="n">vert_start</span><span class="p">:</span><span class="n">vert_end</span><span class="p">,</span> <span class="n">horiz_start</span><span class="p">:</span><span class="n">horiz_end</span><span class="p">,</span> <span class="p">:]</span>
                    
                    <span class="c1"># Convolve the (3D) slice with the correct filter W and bias b, to get back one output neuron. (≈1 line)
</span>                    <span class="n">Z</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="n">conv_single_step</span><span class="p">(</span><span class="n">a_slice_prev</span><span class="p">,</span> <span class="n">W</span><span class="p">[:,:,:,</span><span class="n">c</span><span class="p">],</span> <span class="n">b</span><span class="p">[:,:,:,</span><span class="n">c</span><span class="p">])</span>
                                        
    <span class="c1">### END CODE HERE ###
</span>    
    <span class="c1"># Making sure your output shape is correct
</span>    <span class="k">assert</span><span class="p">(</span><span class="n">Z</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">n_H</span><span class="p">,</span> <span class="n">n_W</span><span class="p">,</span> <span class="n">n_C</span><span class="p">))</span>
    
    <span class="c1"># Save information in "cache" for the backprop
</span>    <span class="n">cache</span> <span class="o">=</span> <span class="p">(</span><span class="n">A_prev</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">hparameters</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">Z</span><span class="p">,</span> <span class="n">cache</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#the im2col function copied from internet for reference
</span><span class="k">def</span> <span class="nf">im2col</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">ksize</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">N</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">C</span> <span class="o">=</span> <span class="n">img</span><span class="p">.</span><span class="n">shape</span>
    <span class="n">out_h</span> <span class="o">=</span> <span class="p">(</span><span class="n">H</span> <span class="o">-</span> <span class="n">ksize</span><span class="p">)</span> <span class="o">//</span> <span class="n">stride</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">out_w</span> <span class="o">=</span> <span class="p">(</span><span class="n">W</span> <span class="o">-</span> <span class="n">ksize</span><span class="p">)</span> <span class="o">//</span> <span class="n">stride</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">col</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">empty</span><span class="p">((</span><span class="n">N</span> <span class="o">*</span> <span class="n">out_h</span> <span class="o">*</span> <span class="n">out_w</span><span class="p">,</span> <span class="n">ksize</span> <span class="o">*</span> <span class="n">ksize</span> <span class="o">*</span> <span class="n">C</span><span class="p">))</span>
    <span class="n">outsize</span> <span class="o">=</span> <span class="n">out_w</span> <span class="o">*</span> <span class="n">out_h</span>
    <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">out_h</span><span class="p">):</span>
        <span class="n">y_min</span> <span class="o">=</span> <span class="n">y</span> <span class="o">*</span> <span class="n">stride</span>
        <span class="n">y_max</span> <span class="o">=</span> <span class="n">y_min</span> <span class="o">+</span> <span class="n">ksize</span>
        <span class="n">y_start</span> <span class="o">=</span> <span class="n">y</span> <span class="o">*</span> <span class="n">out_w</span>
        <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">out_w</span><span class="p">):</span>
            <span class="n">x_min</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="n">stride</span>
            <span class="n">x_max</span> <span class="o">=</span> <span class="n">x_min</span> <span class="o">+</span> <span class="n">ksize</span>
            <span class="n">col</span><span class="p">[</span><span class="n">y_start</span><span class="o">+</span><span class="n">x</span><span class="p">::</span><span class="n">outsize</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">img</span><span class="p">[:,</span> <span class="n">y_min</span><span class="p">:</span><span class="n">y_max</span><span class="p">,</span> <span class="n">x_min</span><span class="p">:</span><span class="n">x_max</span><span class="p">,</span> <span class="p">:].</span><span class="n">reshape</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">col</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">A_prev</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">8</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">8</span><span class="p">)</span>
<span class="n">hparameters</span> <span class="o">=</span> <span class="p">{</span><span class="s">"pad"</span> <span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
               <span class="s">"stride"</span><span class="p">:</span> <span class="mi">2</span><span class="p">}</span>

<span class="n">Z</span><span class="p">,</span> <span class="n">cache_conv</span> <span class="o">=</span> <span class="n">conv_forward</span><span class="p">(</span><span class="n">A_prev</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">hparameters</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Z's mean ="</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">Z</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Z[3,2,1] ="</span><span class="p">,</span> <span class="n">Z</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="s">"cache_conv[0][1][2][3] ="</span><span class="p">,</span> <span class="n">cache_conv</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">][</span><span class="mi">2</span><span class="p">][</span><span class="mi">3</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Z's mean = 0.048995203528855794
Z[3,2,1] = [-0.61490741 -6.7439236  -2.55153897  1.75698377  3.56208902  0.53036437
  5.18531798  8.75898442]
cache_conv[0][1][2][3] = [-0.20075807  0.18656139  0.41005165]
</code></pre></div></div>

<p><strong>Expected Output</strong>:</p>

<table>
    <tr>
        <td>
            **Z's mean**
        </td>
        <td>
            0.0489952035289
        </td>
    </tr>
    <tr>
        <td>
            **Z[3,2,1]**
        </td>
        <td>
            [-0.61490741 -6.7439236  -2.55153897  1.75698377  3.56208902  0.53036437
  5.18531798  8.75898442]
        </td>
    </tr>
    <tr>
        <td>
            **cache_conv[0][1][2][3]**
        </td>
        <td>
            [-0.20075807  0.18656139  0.41005165]
        </td>
    </tr>

</table>

<h1 id="finally-conv-layer-should-also-contain-an-activation-in-which-case-we-would-add-the-following-line-of-code"><strong>Finally, CONV layer should also contain an activation, in which case we would add the following line of code:</strong></h1>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Convolve the window to get back one output neuron
</span><span class="n">Z</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="p">...</span>
<span class="c1"># Apply activation
</span><span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="n">activation</span><span class="p">(</span><span class="n">Z</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">c</span><span class="p">])</span>
</code></pre></div></div>

<p>You don’t need to do it here.</p>

<h2 id="4---pooling-layer">4 - Pooling layer</h2>

<p>The pooling (POOL) layer reduces the height and width of the input. It helps reduce computation, as well as helps make feature detectors more invariant to its position in the input. The two types of pooling layers are:</p>

<ul>
  <li>
    <p>Max-pooling layer: slides an ($f, f$) window over the input and stores the max value of the window in the output.</p>
  </li>
  <li>
    <p>Average-pooling layer: slides an ($f, f$) window over the input and stores the average value of the window in the output.</p>
  </li>
</ul>

<table>
<td>
<img src="/assets/2023-12-01-convolutional-neural-networks-step-by-step_files/67cccc08-1d30-457c-867b-f685ea713011.png" style="width:500px;height:300px;" />
</td>

<td>
<img src="/assets/2023-12-01-convolutional-neural-networks-step-by-step_files/c68d5db2-b26d-417b-9f69-dad7f2a2293a.png" style="width:500px;height:300px;" />
</td>
</table>

<p><img src="/assets/2023-12-01-convolutional-neural-networks-step-by-step_files/67cccc08-1d30-457c-867b-f685ea713011.png" alt="max_pool1.png" /><img src="/assets/2023-12-01-convolutional-neural-networks-step-by-step_files/c68d5db2-b26d-417b-9f69-dad7f2a2293a.png" alt="ave_pool1.png" /></p>

<p>These pooling layers have no parameters for backpropagation to train. However, they have hyperparameters such as the window size $f$. This specifies the height and width of the fxf window you would compute a max or average over.</p>

<h3 id="41---forward-pooling">4.1 - Forward Pooling</h3>
<p>Now, you are going to implement MAX-POOL and AVG-POOL, in the same function.</p>

<p><strong>Exercise</strong>: Implement the forward pass of the pooling layer. Follow the hints in the comments below.</p>

<p><strong>Reminder</strong>:
As there’s no padding, the formulas binding the output shape of the pooling to the input shape is:
\(n_H = \lfloor \frac{n_{H_{prev}} - f}{stride} \rfloor +1\)
\(n_W = \lfloor \frac{n_{W_{prev}} - f}{stride} \rfloor +1\)
\(n_C = n_{C_{prev}}\)</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># GRADED FUNCTION: pool_forward
</span>
<span class="k">def</span> <span class="nf">pool_forward</span><span class="p">(</span><span class="n">A_prev</span><span class="p">,</span> <span class="n">hparameters</span><span class="p">,</span> <span class="n">mode</span> <span class="o">=</span> <span class="s">"max"</span><span class="p">):</span>
    <span class="s">"""
    Implements the forward pass of the pooling layer
    
    Arguments:
    A_prev -- Input data, numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)
    hparameters -- python dictionary containing "f" and "stride"
    mode -- the pooling mode you would like to use, defined as a string ("max" or "average")
    
    Returns:
    A -- output of the pool layer, a numpy array of shape (m, n_H, n_W, n_C)
    cache -- cache used in the backward pass of the pooling layer, contains the input and hparameters 
    """</span>
    
    <span class="c1"># Retrieve dimensions from the input shape
</span>    <span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">n_H_prev</span><span class="p">,</span> <span class="n">n_W_prev</span><span class="p">,</span> <span class="n">n_C_prev</span><span class="p">)</span> <span class="o">=</span> <span class="n">A_prev</span><span class="p">.</span><span class="n">shape</span>
    
    <span class="c1"># Retrieve hyperparameters from "hparameters"
</span>    <span class="n">f</span> <span class="o">=</span> <span class="n">hparameters</span><span class="p">[</span><span class="s">"f"</span><span class="p">]</span>
    <span class="n">stride</span> <span class="o">=</span> <span class="n">hparameters</span><span class="p">[</span><span class="s">"stride"</span><span class="p">]</span>
    
    <span class="c1"># Define the dimensions of the output
</span>    <span class="n">n_H</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="p">(</span><span class="n">n_H_prev</span> <span class="o">-</span> <span class="n">f</span><span class="p">)</span> <span class="o">/</span> <span class="n">stride</span><span class="p">)</span>
    <span class="n">n_W</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="p">(</span><span class="n">n_W_prev</span> <span class="o">-</span> <span class="n">f</span><span class="p">)</span> <span class="o">/</span> <span class="n">stride</span><span class="p">)</span>
    <span class="n">n_C</span> <span class="o">=</span> <span class="n">n_C_prev</span>
    
    <span class="c1"># Initialize output matrix A
</span>    <span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">m</span><span class="p">,</span> <span class="n">n_H</span><span class="p">,</span> <span class="n">n_W</span><span class="p">,</span> <span class="n">n_C</span><span class="p">))</span>              
    
    <span class="c1">### START CODE HERE ###
</span>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>                         <span class="c1"># loop over the training examples
</span>        <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_H</span><span class="p">):</span>                     <span class="c1"># loop on the vertical axis of the output volume
</span>            <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_W</span><span class="p">):</span>                 <span class="c1"># loop on the horizontal axis of the output volume
</span>                <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">range</span> <span class="p">(</span><span class="n">n_C</span><span class="p">):</span>            <span class="c1"># loop over the channels of the output volume
</span>                    
                    <span class="c1"># Find the corners of the current "slice" (≈4 lines)
</span>                    <span class="n">vert_start</span> <span class="o">=</span> <span class="n">h</span> <span class="o">*</span> <span class="n">stride</span>
                    <span class="n">vert_end</span> <span class="o">=</span> <span class="n">vert_start</span> <span class="o">+</span> <span class="n">f</span>
                    <span class="n">horiz_start</span> <span class="o">=</span> <span class="n">w</span> <span class="o">*</span> <span class="n">stride</span>
                    <span class="n">horiz_end</span> <span class="o">=</span> <span class="n">horiz_start</span> <span class="o">+</span> <span class="n">f</span>
                    
                    <span class="c1"># Use the corners to define the current slice on the ith training example of A_prev, channel c. (≈1 line)
</span>                    <span class="n">a_prev_slice</span> <span class="o">=</span> <span class="n">A_prev</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">vert_start</span><span class="p">:</span><span class="n">vert_end</span><span class="p">,</span> <span class="n">horiz_start</span><span class="p">:</span><span class="n">horiz_end</span><span class="p">,</span> <span class="n">c</span><span class="p">]</span>
                    
                    <span class="c1"># Compute the pooling operation on the slice. Use an if statment to differentiate the modes. Use np.max/np.mean.
</span>                    <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s">"max"</span><span class="p">:</span>
                        <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">max</span><span class="p">(</span><span class="n">a_prev_slice</span><span class="p">)</span>
                    <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s">"average"</span><span class="p">:</span>
                        <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">a_prev_slice</span><span class="p">)</span>
    
    <span class="c1">### END CODE HERE ###
</span>    
    <span class="c1"># Store the input and hparameters in "cache" for pool_backward()
</span>    <span class="n">cache</span> <span class="o">=</span> <span class="p">(</span><span class="n">A_prev</span><span class="p">,</span> <span class="n">hparameters</span><span class="p">)</span>
    
    <span class="c1"># Making sure your output shape is correct
</span>    <span class="k">assert</span><span class="p">(</span><span class="n">A</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">n_H</span><span class="p">,</span> <span class="n">n_W</span><span class="p">,</span> <span class="n">n_C</span><span class="p">))</span>
    
    <span class="k">return</span> <span class="n">A</span><span class="p">,</span> <span class="n">cache</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">A_prev</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">hparameters</span> <span class="o">=</span> <span class="p">{</span><span class="s">"stride"</span> <span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s">"f"</span><span class="p">:</span> <span class="mi">3</span><span class="p">}</span>

<span class="n">A</span><span class="p">,</span> <span class="n">cache</span> <span class="o">=</span> <span class="n">pool_forward</span><span class="p">(</span><span class="n">A_prev</span><span class="p">,</span> <span class="n">hparameters</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"mode = max"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"A ="</span><span class="p">,</span> <span class="n">A</span><span class="p">)</span>
<span class="k">print</span><span class="p">()</span>
<span class="n">A</span><span class="p">,</span> <span class="n">cache</span> <span class="o">=</span> <span class="n">pool_forward</span><span class="p">(</span><span class="n">A_prev</span><span class="p">,</span> <span class="n">hparameters</span><span class="p">,</span> <span class="n">mode</span> <span class="o">=</span> <span class="s">"average"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"mode = average"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"A ="</span><span class="p">,</span> <span class="n">A</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>mode = max
A = [[[[1.74481176 0.86540763 1.13376944]]]


 [[[1.13162939 1.51981682 2.18557541]]]]

mode = average
A = [[[[ 0.02105773 -0.20328806 -0.40389855]]]


 [[[-0.22154621  0.51716526  0.48155844]]]]
</code></pre></div></div>

<p><strong>Expected Output:</strong></p>
<table>
    <tr>
    <td>
    A  =
    </td>
    <td>
         [[[[ 1.74481176  0.86540763  1.13376944]]]
         [[[ 1.13162939  1.51981682  2.18557541]]]]
    </td>
    </tr>
    <tr>
    <td>
    A  =
    </td>
    <td>
         [[[[ 0.02105773 -0.20328806 -0.40389855]]]
         [[[-0.22154621  0.51716526  0.48155844]]]]
    </td>
    </tr>
</table>

<p>Congratulations! You have now implemented the forward passes of all the layers of a convolutional network.</p>

<p>The remainer of this notebook is optional, and will not be graded.</p>

<h2 id="5---backpropagation-in-convolutional-neural-networks-optional--ungraded">5 - Backpropagation in convolutional neural networks (OPTIONAL / UNGRADED)</h2>

<p>In modern deep learning frameworks, you only have to implement the forward pass, and the framework takes care of the backward pass, so most deep learning engineers don’t need to bother with the details of the backward pass. The backward pass for convolutional networks is complicated. If you wish however, you can work through this optional portion of the notebook to get a sense of what backprop in a convolutional network looks like.</p>

<p>When in an earlier course you implemented a simple (fully connected) neural network, you used backpropagation to compute the derivatives with respect to the cost to update the parameters. Similarly, in convolutional neural networks you can to calculate the derivatives with respect to the cost in order to update the parameters. The backprop equations are not trivial and we did not derive them in lecture, but we briefly presented them below.</p>

<h3 id="51---convolutional-layer-backward-pass">5.1 - Convolutional layer backward pass</h3>

<p>Let’s start by implementing the backward pass for a CONV layer.</p>

<p><img src="/assets/2023-12-01-convolutional-neural-networks-step-by-step_files/401809ec-dbb3-47a2-8cc1-972d4d089531.png" alt="image.png" />
<img src="/assets/2023-12-01-convolutional-neural-networks-step-by-step_files/03129698-2f26-478b-9ccf-29663bcc6675.png" alt="image.png" /></p>

<h4 id="511---computing-da--the-previouse-a-the-x-above">5.1.1 - Computing dA – the previouse A, the X above:</h4>
<p>Activation formula like such: 
\(A[m, h, w, c] = activation(Z[m, h, w, c])=activation(conv(X[m, h, w, c],W[f, f, c])+b)\) 
\(Z[m, h, w, c]= \sum_m\sum_n​X(i−m,j−n,c)W(f,f,c)+b,   i,j [0, m-1]\)
This is the formula for computing $dA$ with respect to the cost for a certain filter $W_c$ and a given training example:</p>

\[dA += \sum _{h=0} ^{n_H} \sum_{w=0} ^{n_W} W_c \times dZ_{hw} \tag{1}\]

<p>Where $W_c$ is a filter and $dZ_{hw}$ is a scalar corresponding to the gradient of the cost with respect to the output of the conv layer Z at the hth row and wth column (corresponding to the dot product taken at the ith stride left and jth stride down). <font color="red">**Note that at each time, we multiply the the same filter $W_c$ by a different dZ when updating dA**. We do so mainly because when computing the forward propagation, each filter is dotted and summed by a different a_slice. Therefore when computing the backprop for dA, we are just adding the gradients of all the a_slices. </font></p>

<p>In code, inside the appropriate for-loops, this formula translates into:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">da_prev_pad</span><span class="p">[</span><span class="n">vert_start</span><span class="p">:</span><span class="n">vert_end</span><span class="p">,</span> <span class="n">horiz_start</span><span class="p">:</span><span class="n">horiz_end</span><span class="p">,</span> <span class="p">:]</span> <span class="o">+=</span> <span class="n">W</span><span class="p">[:,:,:,</span><span class="n">c</span><span class="p">]</span> <span class="o">*</span> <span class="n">dZ</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">c</span><span class="p">]</span>
</code></pre></div></div>

<h4 id="512---computing-dw">5.1.2 - Computing dW:</h4>
<p>This is the formula for computing $dW_c$ ($dW_c$ is the derivative of one filter) with respect to the loss:</p>

\[dW_c  += \sum _{h=0} ^{n_H} \sum_{w=0} ^ {n_W} a_{slice} \times dZ_{hw}  \tag{2}\]

<p>Where $a_{slice}$ corresponds to the slice which was used to generate the acitivation $Z_{ij}$. Hence, this ends up giving us the gradient for $W$ with respect to that slice. Since it is the same $W$, we will just add up all such gradients to get $dW$.</p>

<p>In code, inside the appropriate for-loops, this formula translates into:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">dW</span><span class="p">[:,:,:,</span><span class="n">c</span><span class="p">]</span> <span class="o">+=</span> <span class="n">a_slice</span> <span class="o">*</span> <span class="n">dZ</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">c</span><span class="p">]</span>
</code></pre></div></div>

<h4 id="513---computing-db">5.1.3 - Computing db:</h4>

<p>This is the formula for computing $db$ with respect to the cost for a certain filter $W_c$:</p>

\[db = \sum_h \sum_w dZ_{hw} \tag{3}\]

<p>As you have previously seen in basic neural networks, db is computed by summing $dZ$. In this case, you are just summing over all the gradients of the conv output (Z) with respect to the cost.</p>

<p>In code, inside the appropriate for-loops, this formula translates into:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">db</span><span class="p">[:,:,:,</span><span class="n">c</span><span class="p">]</span> <span class="o">+=</span> <span class="n">dZ</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">c</span><span class="p">]</span>
</code></pre></div></div>

<p><strong>Exercise</strong>: Implement the <code class="language-plaintext highlighter-rouge">conv_backward</code> function below. You should sum over all the training examples, filters, heights, and widths. You should then compute the derivatives using formulas 1, 2 and 3 above.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">conv_backward</span><span class="p">(</span><span class="n">dZ</span><span class="p">,</span> <span class="n">cache</span><span class="p">):</span>
    <span class="s">"""
    Implement the backward propagation for a convolution function
    
    Arguments:
    dZ -- gradient of the cost with respect to the output of the conv layer (Z), numpy array of shape (m, n_H, n_W, n_C)
    cache -- cache of values needed for the conv_backward(), output of conv_forward()
    
    Returns:
    dA_prev -- gradient of the cost with respect to the input of the conv layer (A_prev),
               numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)
    dW -- gradient of the cost with respect to the weights of the conv layer (W)
          numpy array of shape (f, f, n_C_prev, n_C)
    db -- gradient of the cost with respect to the biases of the conv layer (b)
          numpy array of shape (1, 1, 1, n_C)
    """</span>
    
    <span class="c1">### START CODE HERE ###
</span>    <span class="c1"># Retrieve information from "cache"
</span>    <span class="p">(</span><span class="n">A_prev</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">hparameters</span><span class="p">)</span> <span class="o">=</span> <span class="n">cache</span>
    
    <span class="c1"># Retrieve dimensions from A_prev's shape
</span>    <span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">n_H_prev</span><span class="p">,</span> <span class="n">n_W_prev</span><span class="p">,</span> <span class="n">n_C_prev</span><span class="p">)</span> <span class="o">=</span> <span class="n">A_prev</span><span class="p">.</span><span class="n">shape</span>
    
    <span class="c1"># Retrieve dimensions from W's shape
</span>    <span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">n_C_prev</span><span class="p">,</span> <span class="n">n_C</span><span class="p">)</span> <span class="o">=</span> <span class="n">W</span><span class="p">.</span><span class="n">shape</span>
    
    <span class="c1"># Retrieve information from "hparameters"
</span>    <span class="n">stride</span> <span class="o">=</span> <span class="n">hparameters</span><span class="p">[</span><span class="s">'stride'</span><span class="p">]</span>
    <span class="n">pad</span> <span class="o">=</span> <span class="n">hparameters</span><span class="p">[</span><span class="s">'pad'</span><span class="p">]</span>
    
    <span class="c1"># Retrieve dimensions from dZ's shape
</span>    <span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">n_H</span><span class="p">,</span> <span class="n">n_W</span><span class="p">,</span> <span class="n">n_C</span><span class="p">)</span> <span class="o">=</span> <span class="n">dZ</span><span class="p">.</span><span class="n">shape</span>
    
    <span class="c1"># Initialize dA_prev, dW, db with the correct shapes
</span>    <span class="n">dA_prev</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">m</span><span class="p">,</span> <span class="n">n_H_prev</span><span class="p">,</span> <span class="n">n_W_prev</span><span class="p">,</span> <span class="n">n_C_prev</span><span class="p">))</span>         
    <span class="n">dW</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">f</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">n_C_prev</span><span class="p">,</span> <span class="n">n_C</span><span class="p">))</span>
    <span class="n">db</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n_C</span><span class="p">))</span>

    <span class="c1"># Pad A_prev and dA_prev
</span>    <span class="n">A_prev_pad</span> <span class="o">=</span> <span class="n">zero_pad</span><span class="p">(</span><span class="n">A_prev</span><span class="p">,</span> <span class="n">pad</span><span class="p">)</span>
    <span class="n">dA_prev_pad</span> <span class="o">=</span> <span class="n">zero_pad</span><span class="p">(</span><span class="n">dA_prev</span><span class="p">,</span> <span class="n">pad</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>                       <span class="c1"># loop over the training examples #how to elimiated this loop???
</span>        
        <span class="c1"># select ith training example from A_prev_pad and dA_prev_pad
</span>        <span class="n">a_prev_pad</span> <span class="o">=</span> <span class="n">A_prev_pad</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">da_prev_pad</span> <span class="o">=</span> <span class="n">dA_prev_pad</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        
        <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_H</span><span class="p">):</span>                   <span class="c1"># loop over vertical axis of the output volume
</span>            <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_W</span><span class="p">):</span>               <span class="c1"># loop over horizontal axis of the output volume
</span>                <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_C</span><span class="p">):</span>           <span class="c1"># loop over the channels of the output volume
</span>                    
                    <span class="c1"># Find the corners of the current "slice"
</span>                    <span class="n">vert_start</span> <span class="o">=</span> <span class="n">h</span> <span class="o">*</span> <span class="n">stride</span>
                    <span class="n">vert_end</span> <span class="o">=</span> <span class="n">vert_start</span> <span class="o">+</span> <span class="n">f</span>
                    <span class="n">horiz_start</span> <span class="o">=</span> <span class="n">w</span> <span class="o">*</span> <span class="n">stride</span>
                    <span class="n">horiz_end</span> <span class="o">=</span> <span class="n">horiz_start</span> <span class="o">+</span> <span class="n">f</span>
                    
                    <span class="c1"># Use the corners to define the slice from a_prev_pad
</span>                    <span class="n">a_slice</span> <span class="o">=</span> <span class="n">a_prev_pad</span><span class="p">[</span><span class="n">vert_start</span><span class="p">:</span><span class="n">vert_end</span><span class="p">,</span> <span class="n">horiz_start</span><span class="p">:</span><span class="n">horiz_end</span><span class="p">,</span> <span class="p">:]</span>

                    <span class="c1"># Update gradients for the window and the filter's parameters using the code formulas given above
</span>                    <span class="n">da_prev_pad</span><span class="p">[</span><span class="n">vert_start</span><span class="p">:</span><span class="n">vert_end</span><span class="p">,</span> <span class="n">horiz_start</span><span class="p">:</span><span class="n">horiz_end</span><span class="p">,</span> <span class="p">:]</span> <span class="o">+=</span> <span class="n">W</span><span class="p">[:,:,:,</span><span class="n">c</span><span class="p">]</span> <span class="o">*</span> <span class="n">dZ</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">h</span><span class="p">,</span><span class="n">w</span><span class="p">,</span><span class="n">c</span><span class="p">]</span>
                    <span class="n">dW</span><span class="p">[:,:,:,</span><span class="n">c</span><span class="p">]</span> <span class="o">+=</span> <span class="n">a_slice</span> <span class="o">*</span> <span class="n">dZ</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">h</span><span class="p">,</span><span class="n">w</span><span class="p">,</span><span class="n">c</span><span class="p">]</span>
                    <span class="n">db</span><span class="p">[:,:,:,</span><span class="n">c</span><span class="p">]</span> <span class="o">+=</span> <span class="n">dZ</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">h</span><span class="p">,</span><span class="n">w</span><span class="p">,</span><span class="n">c</span><span class="p">]</span>
                    
        <span class="c1"># Set the ith training example's dA_prev to the unpaded da_prev_pad (Hint: use X[pad:-pad, pad:-pad, :])
</span>        <span class="n">dA_prev</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">da_prev_pad</span><span class="p">[</span><span class="n">pad</span><span class="p">:</span><span class="o">-</span><span class="n">pad</span><span class="p">,</span> <span class="n">pad</span><span class="p">:</span><span class="o">-</span><span class="n">pad</span><span class="p">,</span> <span class="p">:]</span>
    <span class="c1">### END CODE HERE ###
</span>    
    <span class="c1"># Making sure your output shape is correct
</span>    <span class="k">assert</span><span class="p">(</span><span class="n">dA_prev</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">n_H_prev</span><span class="p">,</span> <span class="n">n_W_prev</span><span class="p">,</span> <span class="n">n_C_prev</span><span class="p">))</span>
    
    <span class="k">return</span> <span class="n">dA_prev</span><span class="p">,</span> <span class="n">dW</span><span class="p">,</span> <span class="n">db</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">dA</span><span class="p">,</span> <span class="n">dW</span><span class="p">,</span> <span class="n">db</span> <span class="o">=</span> <span class="n">conv_backward</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">cache_conv</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"dA_mean ="</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dA</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">"dW_mean ="</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dW</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">"db_mean ="</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">db</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>dA_mean = 1.4524377775388075
dW_mean = 1.7269914583139097
db_mean = 7.839232564616838
</code></pre></div></div>

<p>** Expected Output: **</p>
<table>
    <tr>
        <td>
            **dA_mean**
        </td>
        <td>
            1.45243777754
        </td>
    </tr>
    <tr>
        <td>
            **dW_mean**
        </td>
        <td>
            1.72699145831
        </td>
    </tr>
    <tr>
        <td>
            **db_mean**
        </td>
        <td>
            7.83923256462
        </td>
    </tr>

</table>

<h2 id="52-pooling-layer---backward-pass">5.2 Pooling layer - backward pass</h2>

<p>Next, let’s implement the backward pass for the pooling layer, starting with the MAX-POOL layer. Even though a pooling layer has no parameters for backprop to update, you still need to backpropagation the gradient through the pooling layer in order to compute gradients for layers that came before the pooling layer.</p>

<h3 id="521-max-pooling---backward-pass">5.2.1 Max pooling - backward pass</h3>

<p>Before jumping into the backpropagation of the pooling layer, you are going to build a helper function called <code class="language-plaintext highlighter-rouge">create_mask_from_window()</code> which does the following:</p>

\[X = \begin{bmatrix}
1 &amp;&amp; 3 \\
4 &amp;&amp; 2
\end{bmatrix} \quad \rightarrow  \quad M =\begin{bmatrix}
0 &amp;&amp; 0 \\
1 &amp;&amp; 0
\end{bmatrix}\tag{4}\]

<p>As you can see, this function creates a “mask” matrix which keeps track of where the maximum of the matrix is. True (1) indicates the position of the maximum in X, the other entries are False (0). You’ll see later that the backward pass for average pooling will be similar to this but using a different mask.</p>

<p><strong>Exercise</strong>: Implement <code class="language-plaintext highlighter-rouge">create_mask_from_window()</code>. This function will be helpful for pooling backward. 
Hints:</p>
<ul>
  <li><a href="">np.max()</a> may be helpful. It computes the maximum of an array.</li>
  <li>If you have a matrix X and a scalar x: <code class="language-plaintext highlighter-rouge">A = (X == x)</code> will return a matrix A of the same size as X such that:
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>A[i,j] = True if X[i,j] = x
A[i,j] = False if X[i,j] != x
</code></pre></div>    </div>
  </li>
  <li>Here, you don’t need to consider cases where there are several maxima in a matrix.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">create_mask_from_window</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="s">"""
    Creates a mask from an input matrix x, to identify the max entry of x.
    
    Arguments:
    x -- Array of shape (f, f)
    
    Returns:
    mask -- Array of the same shape as window, contains a True at the position corresponding to the max entry of x.
    """</span>
    
    <span class="c1">### START CODE HERE ### (≈1 line)
</span>    <span class="n">mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">==</span> <span class="n">np</span><span class="p">.</span><span class="nb">max</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    <span class="c1">### END CODE HERE ###
</span>    
    <span class="k">return</span> <span class="n">mask</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="n">mask</span> <span class="o">=</span> <span class="n">create_mask_from_window</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'x = '</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"mask = "</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>x =  [[ 1.62434536 -0.61175641 -0.52817175]
 [-1.07296862  0.86540763 -2.3015387 ]]
mask =  [[ True False False]
 [False False False]]
</code></pre></div></div>

<p><strong>Expected Output:</strong></p>

<table> 
<tr> 
<td>

**x =**
</td>

<td>

[[ 1.62434536 -0.61175641 -0.52817175] <br />
 [-1.07296862  0.86540763 -2.3015387 ]]

  </td>
</tr>

<tr> 
<td>
**mask =**
</td>
<td>
[[ True False False] <br />
 [False False False]]
</td>
</tr>


</table>

<font size="3">**Why do we keep track of the position of the max? It's because this is the input value that ultimately influenced the output, and therefore the cost. Backprop is computing gradients with respect to the cost, so anything that influences the ultimate cost should have a non-zero gradient. So, backprop will "propagate" the gradient back to this particular input value that had influenced the cost**. </font>

<h3 id="522---average-pooling---backward-pass">5.2.2 - Average pooling - backward pass</h3>

<p>In max pooling, for each input window, all the “influence” on the output came from a single input value–the max. In average pooling, every element of the input window has equal influence on the output. So to implement backprop, you will now implement a helper function that reflects this.</p>

<p>For example if we did average pooling in the forward pass using a 2x2 filter, then the mask you’ll use for the backward pass will look like: 
\(dZ = 1 \quad \rightarrow  \quad dZ =\begin{bmatrix}
1/4 &amp;&amp; 1/4 \\
1/4 &amp;&amp; 1/4
\end{bmatrix}\tag{5}\)</p>

<p>This implies that each position in the $dZ$ matrix contributes equally to output because in the forward pass, we took an average.</p>

<p><strong>Exercise</strong>: Implement the function below to equally distribute a value dz through a matrix of dimension shape. <a href="https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.ones.html">Hint</a></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">distribute_value</span><span class="p">(</span><span class="n">dz</span><span class="p">,</span> <span class="n">shape</span><span class="p">):</span>
    <span class="s">"""
    Distributes the input value in the matrix of dimension shape
    
    Arguments:
    dz -- input scalar
    shape -- the shape (n_H, n_W) of the output matrix for which we want to distribute the value of dz
    
    Returns:
    a -- Array of size (n_H, n_W) for which we distributed the value of dz
    """</span>
    
    <span class="c1">### START CODE HERE ###
</span>    <span class="c1"># Retrieve dimensions from shape (≈1 line)
</span>    <span class="p">(</span><span class="n">n_H</span><span class="p">,</span> <span class="n">n_W</span><span class="p">)</span> <span class="o">=</span> <span class="n">shape</span>
    
    <span class="c1"># Compute the value to distribute on the matrix (≈1 line)
</span>    <span class="c1"># I think it should be n_h*n_w instead of n_h+nw, right?2
</span>    <span class="n">average</span> <span class="o">=</span> <span class="n">dz</span> <span class="o">/</span> <span class="p">(</span><span class="n">n_H</span> <span class="o">*</span> <span class="n">n_W</span><span class="p">)</span>
    
    <span class="c1"># Create a matrix where every entry is the "average" value (≈1 line)
</span>    <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="o">*</span> <span class="n">average</span>
    <span class="c1">### END CODE HERE ###
</span>    
    <span class="k">return</span> <span class="n">a</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">a</span> <span class="o">=</span> <span class="n">distribute_value</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'distributed value ='</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>distributed value = [[0.5 0.5]
 [0.5 0.5]]
</code></pre></div></div>

<p><strong>Expected Output</strong>:</p>

<table> 
<tr> 
<td>
distributed_value =
</td>
<td>
[[ 0.5  0.5]
&lt;br\&gt; 
[ 0.5  0.5]]
</td>
</tr>
</table>

<h3 id="523-putting-it-together-pooling-backward">5.2.3 Putting it together: Pooling backward</h3>

<p>You now have everything you need to compute backward propagation on a pooling layer.</p>

<p><strong>Exercise</strong>: Implement the <code class="language-plaintext highlighter-rouge">pool_backward</code> function in both modes (<code class="language-plaintext highlighter-rouge">"max"</code> and <code class="language-plaintext highlighter-rouge">"average"</code>). You will once again use 4 for-loops (iterating over training examples, height, width, and channels). You should use an <code class="language-plaintext highlighter-rouge">if/elif</code> statement to see if the mode is equal to <code class="language-plaintext highlighter-rouge">'max'</code> or <code class="language-plaintext highlighter-rouge">'average'</code>. If it is equal to ‘average’ you should use the <code class="language-plaintext highlighter-rouge">distribute_value()</code> function you implemented above to create a matrix of the same shape as <code class="language-plaintext highlighter-rouge">a_slice</code>. Otherwise, the mode is equal to ‘<code class="language-plaintext highlighter-rouge">max</code>’, and you will create a mask with <code class="language-plaintext highlighter-rouge">create_mask_from_window()</code> and multiply it by the corresponding value of dZ.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">pool_backward</span><span class="p">(</span><span class="n">dA</span><span class="p">,</span> <span class="n">cache</span><span class="p">,</span> <span class="n">mode</span> <span class="o">=</span> <span class="s">"max"</span><span class="p">):</span>
    <span class="s">"""
    Implements the backward pass of the pooling layer
    
    Arguments:
    dA -- gradient of cost with respect to the output of the pooling layer, same shape as A
    cache -- cache output from the forward pass of the pooling layer, contains the layer's input and hparameters 
    mode -- the pooling mode you would like to use, defined as a string ("max" or "average")
    
    Returns:
    dA_prev -- gradient of cost with respect to the input of the pooling layer, same shape as A_prev
    """</span>
    
    <span class="c1">### START CODE HERE ###
</span>    
    <span class="c1"># Retrieve information from cache (≈1 line)
</span>    <span class="p">(</span><span class="n">A_prev</span><span class="p">,</span> <span class="n">hparameters</span><span class="p">)</span> <span class="o">=</span> <span class="n">cache</span>
    
    <span class="c1"># Retrieve hyperparameters from "hparameters" (≈2 lines)
</span>    <span class="n">stride</span> <span class="o">=</span> <span class="n">hparameters</span><span class="p">[</span><span class="s">'stride'</span><span class="p">]</span>
    <span class="n">f</span> <span class="o">=</span> <span class="n">hparameters</span><span class="p">[</span><span class="s">'f'</span><span class="p">]</span>
    
    <span class="c1"># Retrieve dimensions from A_prev's shape and dA's shape (≈2 lines)
</span>    <span class="n">m</span><span class="p">,</span> <span class="n">n_H_prev</span><span class="p">,</span> <span class="n">n_W_prev</span><span class="p">,</span> <span class="n">n_C_prev</span> <span class="o">=</span> <span class="n">A_prev</span><span class="p">.</span><span class="n">shape</span>
    <span class="n">m</span><span class="p">,</span> <span class="n">n_H</span><span class="p">,</span> <span class="n">n_W</span><span class="p">,</span> <span class="n">n_C</span> <span class="o">=</span> <span class="n">dA</span><span class="p">.</span><span class="n">shape</span>
    
    <span class="c1"># Initialize dA_prev with zeros (≈1 line)
</span>    <span class="n">dA_prev</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span> <span class="o">=</span> <span class="n">A_prev</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>                       <span class="c1"># loop over the training examples
</span>        
        <span class="c1"># select training example from A_prev (≈1 line)
</span>        <span class="n">a_prev</span> <span class="o">=</span> <span class="n">A_prev</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        
        <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_H</span><span class="p">):</span>                   <span class="c1"># loop on the vertical axis
</span>            <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_W</span><span class="p">):</span>               <span class="c1"># loop on the horizontal axis
</span>                <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_C</span><span class="p">):</span>           <span class="c1"># loop over the channels (depth)
</span>                    
                    <span class="c1"># Find the corners of the current "slice" (≈4 lines)
</span>                    <span class="n">vert_start</span> <span class="o">=</span> <span class="n">h</span> <span class="o">*</span> <span class="n">stride</span>
                    <span class="n">vert_end</span> <span class="o">=</span> <span class="n">vert_start</span> <span class="o">+</span> <span class="n">f</span>
                    <span class="n">horiz_start</span> <span class="o">=</span> <span class="n">w</span> <span class="o">*</span> <span class="n">stride</span>
                    <span class="n">horiz_end</span> <span class="o">=</span> <span class="n">horiz_start</span> <span class="o">+</span> <span class="n">f</span>
                    
                    <span class="c1"># Compute the backward propagation in both modes.
</span>                    <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s">"max"</span><span class="p">:</span>
                        
                        <span class="c1"># Use the corners and "c" to define the current slice from a_prev (≈1 line)
</span>                        <span class="n">a_prev_slice</span> <span class="o">=</span> <span class="n">a_prev</span><span class="p">[</span><span class="n">vert_start</span><span class="p">:</span><span class="n">vert_end</span><span class="p">,</span> <span class="n">horiz_start</span><span class="p">:</span><span class="n">horiz_end</span><span class="p">,</span> <span class="n">c</span><span class="p">]</span>
                        <span class="c1"># Create the mask from a_prev_slice (≈1 line)
</span>                        <span class="n">mask</span> <span class="o">=</span> <span class="n">create_mask_from_window</span><span class="p">(</span><span class="n">a_prev_slice</span><span class="p">)</span>
                        <span class="c1"># Set dA_prev to be dA_prev + (the mask multiplied by the correct entry of dA) (≈1 line)
</span>                        <span class="n">dA_prev</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">vert_start</span><span class="p">:</span> <span class="n">vert_end</span><span class="p">,</span> <span class="n">horiz_start</span><span class="p">:</span> <span class="n">horiz_end</span><span class="p">,</span> <span class="n">c</span><span class="p">]</span> <span class="o">+=</span> <span class="n">np</span><span class="p">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">dA</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">h</span><span class="p">,</span><span class="n">w</span><span class="p">,</span><span class="n">c</span><span class="p">])</span>
                        
                    <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s">"average"</span><span class="p">:</span>
                        
                        <span class="c1"># Get the value a from dA (≈1 line)
</span>                        <span class="n">da</span> <span class="o">=</span> <span class="n">dA</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">h</span><span class="p">,</span><span class="n">w</span><span class="p">,</span><span class="n">c</span><span class="p">]</span>
                        <span class="c1"># Define the shape of the filter as fxf (≈1 line)
</span>                        <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">f</span><span class="p">,</span><span class="n">f</span><span class="p">)</span>
                        <span class="c1"># Distribute it to get the correct slice of dA_prev. i.e. Add the distributed value of da. (≈1 line)
</span>                        <span class="n">dA_prev</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">vert_start</span><span class="p">:</span> <span class="n">vert_end</span><span class="p">,</span> <span class="n">horiz_start</span><span class="p">:</span> <span class="n">horiz_end</span><span class="p">,</span> <span class="n">c</span><span class="p">]</span> <span class="o">+=</span> <span class="n">distribute_value</span><span class="p">(</span><span class="n">da</span><span class="p">,</span> <span class="n">shape</span><span class="p">)</span>
                        
    <span class="c1">### END CODE ###
</span>    
    <span class="c1"># Making sure your output shape is correct
</span>    <span class="k">assert</span><span class="p">(</span><span class="n">dA_prev</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">A_prev</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">dA_prev</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">A_prev</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">hparameters</span> <span class="o">=</span> <span class="p">{</span><span class="s">"stride"</span> <span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s">"f"</span><span class="p">:</span> <span class="mi">2</span><span class="p">}</span>
<span class="n">A</span><span class="p">,</span> <span class="n">cache</span> <span class="o">=</span> <span class="n">pool_forward</span><span class="p">(</span><span class="n">A_prev</span><span class="p">,</span> <span class="n">hparameters</span><span class="p">)</span>
<span class="n">dA</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

<span class="n">dA_prev</span> <span class="o">=</span> <span class="n">pool_backward</span><span class="p">(</span><span class="n">dA</span><span class="p">,</span> <span class="n">cache</span><span class="p">,</span> <span class="n">mode</span> <span class="o">=</span> <span class="s">"max"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"mode = max"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'mean of dA = '</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dA</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'dA_prev[1,1] = '</span><span class="p">,</span> <span class="n">dA_prev</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>  
<span class="k">print</span><span class="p">()</span>
<span class="n">dA_prev</span> <span class="o">=</span> <span class="n">pool_backward</span><span class="p">(</span><span class="n">dA</span><span class="p">,</span> <span class="n">cache</span><span class="p">,</span> <span class="n">mode</span> <span class="o">=</span> <span class="s">"average"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"mode = average"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'mean of dA = '</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dA</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'dA_prev[1,1] = '</span><span class="p">,</span> <span class="n">dA_prev</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span> 
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>mode = max
mean of dA =  0.14571390272918056
dA_prev[1,1] =  [[ 0.          0.        ]
 [ 5.05844394 -1.68282702]
 [ 0.          0.        ]]

mode = average
mean of dA =  0.14571390272918056
dA_prev[1,1] =  [[ 0.08485462  0.2787552 ]
 [ 1.26461098 -0.25749373]
 [ 1.17975636 -0.53624893]]
</code></pre></div></div>

<p><strong>Expected Output</strong>:</p>

<p>mode = max:</p>
<table> 
<tr> 
<td>

**mean of dA =**
</td>

<td>

0.145713902729

  </td>
</tr>

<tr> 
<td>
**dA_prev[1,1] =** 
</td>
<td>
[[ 0.          0.        ] <br />
 [ 5.05844394 -1.68282702] <br />
 [ 0.          0.        ]]
</td>
</tr>
</table>

<p>mode = average</p>
<table> 
<tr> 
<td>

**mean of dA =**
</td>

<td>

0.145713902729

  </td>
</tr>

<tr> 
<td>
**dA_prev[1,1] =** 
</td>
<td>
[[ 0.08485462  0.2787552 ] <br />
 [ 1.26461098 -0.25749373] <br />
 [ 1.17975636 -0.53624893]]
</td>
</tr>
</table>

<h3 id="congratulations-">Congratulations !</h3>

<p>Congratulation on completing this assignment. You now understand how convolutional neural networks work. You have implemented all the building blocks of a neural network. In the next assignment you will implement a ConvNet using TensorFlow.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
</code></pre></div></div>]]></content><author><name>Zhu Tianda</name></author><category term="coding" /><category term="AI" /><summary type="html"><![CDATA[卷积的数学表示 \(f∗g(n)=∫_{−∞}^{+∞}​f(τ)g(n−τ)dτ\) 上面公式是连续的定义，再看看离散的定义：]]></summary></entry><entry><title type="html">Diffusion Models Tutorial 01</title><link href="http://0.0.0.0:8855/coding/2023/12/01/diffusion-model-demo1.html" rel="alternate" type="text/html" title="Diffusion Models Tutorial 01" /><published>2023-12-01T00:00:00+08:00</published><updated>2023-12-01T00:00:00+08:00</updated><id>http://0.0.0.0:8855/coding/2023/12/01/diffusion-model-demo1</id><content type="html" xml:base="http://0.0.0.0:8855/coding/2023/12/01/diffusion-model-demo1.html"><![CDATA[<p><a href="https://colab.research.google.com/github/azad-academy/denoising-diffusion-model/blob/main/diffusion_model_demo.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" /></a></p>

<h1 id="diffusion-models-tutorial">Diffusion Models Tutorial</h1>

<h4 id="author--j-rafid-siddiqui-jrsazaditechcom">Author : J. Rafid Siddiqui (jrs@azaditech.com)</h4>

<h2 id="loading-data">Loading Data</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="kn">import</span> <span class="nn">matplotlib</span> <span class="k">as</span> <span class="n">mpl</span>
<span class="kn">import</span> <span class="nn">matplotlib.font_manager</span>
<span class="c1">#font_manager._rebuild()
</span><span class="kn">import</span> <span class="nn">logging</span>
<span class="n">logging</span><span class="p">.</span><span class="n">getLogger</span><span class="p">(</span><span class="s">"matplotlib.font_manager"</span><span class="p">).</span><span class="n">setLevel</span><span class="p">(</span><span class="n">logging</span><span class="p">.</span><span class="n">ERROR</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">hdr_plot_style</span><span class="p">():</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">style</span><span class="p">.</span><span class="n">use</span><span class="p">(</span><span class="s">'dark_background'</span><span class="p">)</span>
    <span class="n">mpl</span><span class="p">.</span><span class="n">rcParams</span><span class="p">.</span><span class="n">update</span><span class="p">({</span><span class="s">'font.size'</span><span class="p">:</span> <span class="mi">18</span><span class="p">,</span> <span class="s">'lines.linewidth'</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="s">'lines.markersize'</span><span class="p">:</span> <span class="mi">15</span><span class="p">})</span>
    <span class="c1"># avoid type 3 (i.e. bitmap) fonts in figures
</span>    <span class="n">mpl</span><span class="p">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s">'ps.useafm'</span><span class="p">]</span> <span class="o">=</span> <span class="bp">True</span>
    <span class="n">mpl</span><span class="p">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s">'pdf.use14corefonts'</span><span class="p">]</span> <span class="o">=</span> <span class="bp">True</span>
    <span class="n">mpl</span><span class="p">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s">'text.usetex'</span><span class="p">]</span> <span class="o">=</span> <span class="bp">False</span>
    <span class="n">mpl</span><span class="p">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s">'font.family'</span><span class="p">]</span> <span class="o">=</span> <span class="s">'sans-serif'</span>
    <span class="n">mpl</span><span class="p">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s">'font.sans-serif'</span><span class="p">]</span> <span class="o">=</span> <span class="s">'Courier New'</span>
    <span class="c1"># mpl.rcParams['text.hinting'] = False
</span>    <span class="c1"># Set colors cycle
</span>    <span class="n">colors</span> <span class="o">=</span> <span class="n">mpl</span><span class="p">.</span><span class="n">cycler</span><span class="p">(</span><span class="s">'color'</span><span class="p">,</span> <span class="p">[</span><span class="s">'#3388BB'</span><span class="p">,</span> <span class="s">'#EE6666'</span><span class="p">,</span> <span class="s">'#9988DD'</span><span class="p">,</span> <span class="s">'#EECC55'</span><span class="p">,</span> <span class="s">'#88BB44'</span><span class="p">,</span> <span class="s">'#FFBBBB'</span><span class="p">])</span>
    <span class="c1">#plt.rc('figure', facecolor='#00000000', edgecolor='black')
</span>    <span class="c1">#plt.rc('axes', facecolor='#FFFFFF88', edgecolor='white', axisbelow=True, grid=True, prop_cycle=colors)
</span>    <span class="n">plt</span><span class="p">.</span><span class="n">rc</span><span class="p">(</span><span class="s">'legend'</span><span class="p">,</span> <span class="n">facecolor</span><span class="o">=</span><span class="s">'#666666EE'</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s">'white'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">rc</span><span class="p">(</span><span class="s">'grid'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'white'</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s">'solid'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">rc</span><span class="p">(</span><span class="s">'text'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'white'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">rc</span><span class="p">(</span><span class="s">'xtick'</span><span class="p">,</span> <span class="n">direction</span><span class="o">=</span><span class="s">'out'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'white'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">rc</span><span class="p">(</span><span class="s">'ytick'</span><span class="p">,</span> <span class="n">direction</span><span class="o">=</span><span class="s">'out'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'white'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">rc</span><span class="p">(</span><span class="s">'patch'</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s">'#E6E6E6'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_checkerboard</span><span class="p">,</span><span class="n">make_circles</span><span class="p">,</span><span class="n">make_moons</span><span class="p">,</span><span class="n">make_s_curve</span><span class="p">,</span><span class="n">make_swiss_roll</span>
<span class="c1">#from helper_plot import hdr_plot_style
</span><span class="kn">import</span> <span class="nn">torch</span>
<span class="c1">#from utils import * 
</span>
<span class="n">hdr_plot_style</span><span class="p">()</span>
<span class="n">swiss_roll</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">make_swiss_roll</span><span class="p">(</span><span class="mi">10</span><span class="o">**</span><span class="mi">4</span><span class="p">,</span><span class="n">noise</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">swiss_roll</span> <span class="o">=</span> <span class="n">swiss_roll</span><span class="p">[:,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]]</span><span class="o">/</span><span class="mf">10.0</span>

<span class="n">s_curve</span><span class="p">,</span> <span class="n">_</span><span class="o">=</span> <span class="n">make_s_curve</span><span class="p">(</span><span class="mi">10</span><span class="o">**</span><span class="mi">4</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">s_curve</span> <span class="o">=</span> <span class="n">s_curve</span><span class="p">[:,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]]</span><span class="o">/</span><span class="mf">10.0</span>

<span class="n">moons</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">make_moons</span><span class="p">(</span><span class="mi">10</span><span class="o">**</span><span class="mi">4</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">s_curve</span><span class="p">.</span><span class="n">T</span>
<span class="c1">#dataset = torch.Tensor(data.T).float()
</span>

<span class="n">fig</span><span class="p">,</span><span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">scatter</span><span class="p">(</span><span class="o">*</span><span class="n">data</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'white'</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s">'gray'</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">5</span><span class="p">);</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">axis</span><span class="p">(</span><span class="s">'off'</span><span class="p">)</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">swiss_roll</span><span class="p">.</span><span class="n">T</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">scatter</span><span class="p">(</span><span class="o">*</span><span class="n">data</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'white'</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s">'gray'</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">5</span><span class="p">);</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">axis</span><span class="p">(</span><span class="s">'off'</span><span class="p">)</span>
<span class="c1">#dataset = torch.Tensor(data.T).float()
</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">moons</span><span class="p">.</span><span class="n">T</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">].</span><span class="n">scatter</span><span class="p">(</span><span class="o">*</span><span class="n">data</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'white'</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s">'gray'</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">3</span><span class="p">);</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">].</span><span class="n">axis</span><span class="p">(</span><span class="s">'off'</span><span class="p">)</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">T</span><span class="p">).</span><span class="nb">float</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/assets/2023-12-01-diffusion-model-demo1_files/2023-12-01-diffusion-model-demo1_4_0.png" alt="png" /></p>

<h2 id="diffusion-models">Diffusion Models</h2>

<p><img src="images/diffusion.png" alt="diffusion-image" /></p>

<h3 id="forward-diffusion">Forward Diffusion</h3>

\[q(\mathbf{x}_{t}\mid\mathbf{x}_{t-1}) = \mathcal{N}(\mathbf{x}_{t} ; \sqrt{1-\beta_{t}}\mathbf{x}_{t-1},\beta_{t}\mathbf{I})\]

<p>Substituting $\alpha_{t}=1-\beta_{t}$ and $\bar{\alpha}<em>{t} = \prod</em>{s=1}^{t} \alpha_{s}$:</p>

\[q(\mathbf{x}_{t}\mid\mathbf{x}_{0}) = \mathcal{N}(\mathbf{x}_{t} ; \sqrt{\bar{\alpha}_{t}}\mathbf{x}_{t-1},(1-\bar{\alpha}_{t})\mathbf{I})\]

<p>Given the initial state, this makes it possible to draw sample at any desrired timestep without going through intermediate steps. Forward diffusion can also be written in terms of $x_0$ and the random noise $\epsilon \sim \mathcal{N}(0,1)$ [1]. This would be useful when performing denoising step later in the reverse diffusion.</p>

\[x_t(x_0,\epsilon) = \sqrt{\bar{\alpha}_{t}}\mathbf{x}_{0} + \sqrt{1-\bar{\alpha_{t}}}\epsilon\]

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">make_beta_schedule</span><span class="p">(</span><span class="n">schedule</span><span class="o">=</span><span class="s">'linear'</span><span class="p">,</span> <span class="n">n_timesteps</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">schedule</span> <span class="o">==</span> <span class="s">'linear'</span><span class="p">:</span>
        <span class="n">betas</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">n_timesteps</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">schedule</span> <span class="o">==</span> <span class="s">"quad"</span><span class="p">:</span>
        <span class="n">betas</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">start</span> <span class="o">**</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">end</span> <span class="o">**</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">n_timesteps</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>
    <span class="k">elif</span> <span class="n">schedule</span> <span class="o">==</span> <span class="s">"sigmoid"</span><span class="p">:</span>
        <span class="n">betas</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="n">n_timesteps</span><span class="p">)</span>
        <span class="n">betas</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">betas</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">)</span> <span class="o">+</span> <span class="n">start</span>
    <span class="k">return</span> <span class="n">betas</span>

<span class="k">def</span> <span class="nf">extract</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="n">shape</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">gather</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">t</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="nb">input</span><span class="p">.</span><span class="n">device</span><span class="p">))</span>
    <span class="n">reshape</span> <span class="o">=</span> <span class="p">[</span><span class="n">t</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">out</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">*</span><span class="n">reshape</span><span class="p">)</span>    
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">num_steps</span> <span class="o">=</span> <span class="mi">100</span>
<span class="c1">#betas = torch.tensor([1.7e-5] * num_steps)
</span><span class="n">betas</span> <span class="o">=</span> <span class="n">make_beta_schedule</span><span class="p">(</span><span class="n">schedule</span><span class="o">=</span><span class="s">'sigmoid'</span><span class="p">,</span> <span class="n">n_timesteps</span><span class="o">=</span><span class="n">num_steps</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="mf">0.5e-2</span><span class="p">)</span>

<span class="n">alphas</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">betas</span>
<span class="n">alphas_prod</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cumprod</span><span class="p">(</span><span class="n">alphas</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">alphas_prod_p</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">([</span><span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">]).</span><span class="nb">float</span><span class="p">(),</span> <span class="n">alphas_prod</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]],</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">alphas_bar_sqrt</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">alphas_prod</span><span class="p">)</span>
<span class="n">one_minus_alphas_bar_log</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alphas_prod</span><span class="p">)</span>
<span class="n">one_minus_alphas_bar_sqrt</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alphas_prod</span><span class="p">)</span>
</code></pre></div></div>

<p>Following code which do the step by step add noise seems not necessary , due to the result don’t use at all in training, the useful cacluation above is done.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">q_x</span><span class="p">(</span><span class="n">x_0</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">noise</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">noise</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">x_0</span><span class="p">)</span>
    <span class="n">alphas_t</span> <span class="o">=</span> <span class="n">extract</span><span class="p">(</span><span class="n">alphas_bar_sqrt</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_0</span><span class="p">)</span>
    <span class="n">alphas_1_m_t</span> <span class="o">=</span> <span class="n">extract</span><span class="p">(</span><span class="n">one_minus_alphas_bar_sqrt</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_0</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">alphas_t</span> <span class="o">*</span> <span class="n">x_0</span> <span class="o">+</span> <span class="n">alphas_1_m_t</span> <span class="o">*</span> <span class="n">noise</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">q_i</span> <span class="o">=</span> <span class="n">q_x</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">i</span> <span class="o">*</span> <span class="mi">10</span><span class="p">]))</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">scatter</span><span class="p">(</span><span class="n">q_i</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">q_i</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s">'white'</span><span class="p">,</span><span class="n">edgecolor</span><span class="o">=</span><span class="s">'gray'</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">5</span><span class="p">);</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">set_axis_off</span><span class="p">();</span> <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">'$q(\mathbf{x}_{'</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="o">*</span><span class="mi">10</span><span class="p">)</span><span class="o">+</span><span class="s">'})$'</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/assets/2023-12-01-diffusion-model-demo1_files/2023-12-01-diffusion-model-demo1_12_0.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">posterior_mean_coef_1</span> <span class="o">=</span> <span class="p">(</span><span class="n">betas</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">alphas_prod_p</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alphas_prod</span><span class="p">))</span>
<span class="n">posterior_mean_coef_2</span> <span class="o">=</span> <span class="p">((</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alphas_prod_p</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">alphas</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alphas_prod</span><span class="p">))</span>
<span class="n">posterior_variance</span> <span class="o">=</span> <span class="n">betas</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alphas_prod_p</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alphas_prod</span><span class="p">)</span>
<span class="n">posterior_log_variance_clipped</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">((</span><span class="n">posterior_variance</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">posterior_variance</span><span class="p">[</span><span class="mi">1</span><span class="p">:].</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="mi">0</span><span class="p">)).</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">q_posterior_mean_variance</span><span class="p">(</span><span class="n">x_0</span><span class="p">,</span> <span class="n">x_t</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
    <span class="n">coef_1</span> <span class="o">=</span> <span class="n">extract</span><span class="p">(</span><span class="n">posterior_mean_coef_1</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_0</span><span class="p">)</span>
    <span class="n">coef_2</span> <span class="o">=</span> <span class="n">extract</span><span class="p">(</span><span class="n">posterior_mean_coef_2</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_0</span><span class="p">)</span>
    <span class="n">mean</span> <span class="o">=</span> <span class="n">coef_1</span> <span class="o">*</span> <span class="n">x_0</span> <span class="o">+</span> <span class="n">coef_2</span> <span class="o">*</span> <span class="n">x_t</span>
    <span class="n">var</span> <span class="o">=</span> <span class="n">extract</span><span class="p">(</span><span class="n">posterior_log_variance_clipped</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">mean</span><span class="p">,</span> <span class="n">var</span>
</code></pre></div></div>

<h2 id="reverse-diffusionreconstruction">Reverse Diffusion/Reconstruction</h2>

<p>Unlike the forward diffusion, the reverse diffusion process requires training of a neural network model. We setup the necessary loss functions and training parameters and then perform the training.</p>

<h2 id="training">Training</h2>

<h3 id="training-loss">Training Loss</h3>

<p>The original loss was proposed in Sohl-Dickstein et al. [1] as following:</p>

<p>\begin{align}
K = -\mathbb{E}<em>{q}[ &amp;D</em>{KL}(q(\mathbf{x}<em>{t-1}\mid\mathbf{x}</em>{t},\mathbf{x}<em>{0}) \Vert p</em>{\theta}(\mathbf{x}<em>{t-1}\mid\mathbf{x}</em>{t}))  <br />
&amp;+ H_{q}(\mathbf{X}<em>{T}\vert\mathbf{X}</em>{0}) - H_{q}(\mathbf{X}<em>{1}\vert\mathbf{X}</em>{0}) - H_{p}(\mathbf{X}_{T})]
\end{align}</p>

<p>In order to improve the results, the authors in Ho et al. [2] proposed multiple improvements. Following Parameterization of mean is proposed:</p>

\[\mathbf{\mu}_{\theta}(\mathbf{x}_{t}, t) = \frac{1}{\sqrt{\alpha_{t}}} \left( (\mathbf{x}_{t} - \frac{\beta_{t}}{\sqrt{1 - \bar{\alpha}}_{t}} \mathbf{\epsilon}_{\theta} (\mathbf{x}_{t}, t) \right)\]

<p>further, variance is taken as constant and the step for reverse diffusion then becomes:</p>

\[\mathbf{x}_{t-1} = \frac{1}{\sqrt{\alpha_{t}}} \left( \mathbf{x}_{t} - \frac{1-\alpha_{t}}{\sqrt{1-\bar{\alpha_{t}}}} \mathbf{\epsilon}_{\theta}(\mathbf{x}_{t}, t) \right) + \sigma_{t}\mathbf{z}\]

<p>After further improvements and simplifications the loss function becomes:</p>

\[\mathcal{L}_{\text{simple}}=\mathbb{E}_{t, \mathbf{x}_{0},\mathbf{\epsilon}}\left[ \Vert \epsilon - \epsilon_{\theta}(\sqrt{\bar{\alpha}_{t}}\mathbf{x}_{0} + \sqrt{1 - \bar{\alpha}_{t}}\mathbf{\epsilon}, t) \Vert^{2} \right].\]

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">p_sample</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span><span class="n">alphas</span><span class="p">,</span><span class="n">betas</span><span class="p">,</span><span class="n">one_minus_alphas_bar_sqrt</span><span class="p">):</span>
    <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">t</span><span class="p">])</span>
    <span class="c1"># Factor to the model output
</span>    <span class="n">eps_factor</span> <span class="o">=</span> <span class="p">((</span><span class="mi">1</span> <span class="o">-</span> <span class="n">extract</span><span class="p">(</span><span class="n">alphas</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x</span><span class="p">))</span> <span class="o">/</span> <span class="n">extract</span><span class="p">(</span><span class="n">one_minus_alphas_bar_sqrt</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x</span><span class="p">))</span>
    <span class="c1"># Model output
</span>    <span class="n">eps_theta</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
    <span class="c1"># Final values
</span>    <span class="n">mean</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">extract</span><span class="p">(</span><span class="n">alphas</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x</span><span class="p">).</span><span class="n">sqrt</span><span class="p">())</span> <span class="o">*</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="p">(</span><span class="n">eps_factor</span> <span class="o">*</span> <span class="n">eps_theta</span><span class="p">))</span>
    <span class="c1"># Generate z
</span>    <span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="c1"># Fixed sigma
</span>    <span class="n">sigma_t</span> <span class="o">=</span> <span class="n">extract</span><span class="p">(</span><span class="n">betas</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x</span><span class="p">).</span><span class="n">sqrt</span><span class="p">()</span>
    <span class="n">sample</span> <span class="o">=</span> <span class="n">mean</span> <span class="o">+</span> <span class="n">sigma_t</span> <span class="o">*</span> <span class="n">z</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">sample</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">p_sample_loop</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span><span class="n">n_steps</span><span class="p">,</span><span class="n">alphas</span><span class="p">,</span><span class="n">betas</span><span class="p">,</span><span class="n">one_minus_alphas_bar_sqrt</span><span class="p">):</span>
    <span class="n">cur_x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">x_seq</span> <span class="o">=</span> <span class="p">[</span><span class="n">cur_x</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n_steps</span><span class="p">)):</span>
        <span class="n">cur_x</span> <span class="o">=</span> <span class="n">p_sample</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">cur_x</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span><span class="n">alphas</span><span class="p">,</span><span class="n">betas</span><span class="p">,</span><span class="n">one_minus_alphas_bar_sqrt</span><span class="p">)</span>
        <span class="n">x_seq</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">cur_x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x_seq</span>
<span class="k">def</span> <span class="nf">noise_estimation_loss</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">x_0</span><span class="p">,</span><span class="n">alphas_bar_sqrt</span><span class="p">,</span><span class="n">one_minus_alphas_bar_sqrt</span><span class="p">,</span><span class="n">n_steps</span><span class="p">):</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">x_0</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="c1"># Select a random step for each example
</span>    <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size</span> <span class="o">//</span> <span class="mi">2</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,))</span>
    <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">([</span><span class="n">t</span><span class="p">,</span> <span class="n">n_steps</span> <span class="o">-</span> <span class="n">t</span> <span class="o">-</span> <span class="mi">1</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)[:</span><span class="n">batch_size</span><span class="p">].</span><span class="nb">long</span><span class="p">()</span>
    <span class="c1"># x0 multiplier
</span>    <span class="n">a</span> <span class="o">=</span> <span class="n">extract</span><span class="p">(</span><span class="n">alphas_bar_sqrt</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_0</span><span class="p">)</span>
    <span class="c1"># eps multiplier
</span>    <span class="n">am1</span> <span class="o">=</span> <span class="n">extract</span><span class="p">(</span><span class="n">one_minus_alphas_bar_sqrt</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_0</span><span class="p">)</span>
    <span class="n">e</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">x_0</span><span class="p">)</span>
    <span class="c1"># model input
</span>    <span class="n">x</span> <span class="o">=</span> <span class="n">x_0</span> <span class="o">*</span> <span class="n">a</span> <span class="o">+</span> <span class="n">e</span> <span class="o">*</span> <span class="n">am1</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">e</span> <span class="o">-</span> <span class="n">output</span><span class="p">).</span><span class="n">square</span><span class="p">().</span><span class="n">mean</span><span class="p">()</span>    

<span class="c1">#An Implementation of Diffusion Network Model
#Oringinal source: https://github.com/acids-ircam/diffusion_models
</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="n">F</span>

<span class="k">class</span> <span class="nc">ConditionalLinear</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_in</span><span class="p">,</span> <span class="n">num_out</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ConditionalLinear</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">num_out</span> <span class="o">=</span> <span class="n">num_out</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">lin</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">num_in</span><span class="p">,</span> <span class="n">num_out</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">embed</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">n_steps</span><span class="p">,</span> <span class="n">num_out</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">embed</span><span class="p">.</span><span class="n">weight</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">uniform_</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">lin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">gamma</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">embed</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">gamma</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">num_out</span><span class="p">)</span> <span class="o">*</span> <span class="n">out</span>
        <span class="k">return</span> <span class="n">out</span>
        
<span class="k">class</span> <span class="nc">ConditionalModel</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ConditionalModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">lin1</span> <span class="o">=</span> <span class="n">ConditionalLinear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">lin2</span> <span class="o">=</span> <span class="n">ConditionalLinear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">lin3</span> <span class="o">=</span> <span class="n">ConditionalLinear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">lin4</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">softplus</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">lin1</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">softplus</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">lin2</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">softplus</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">lin3</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">lin4</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#from model import ConditionalModel
</span><span class="kn">from</span> <span class="nn">ema</span> <span class="kn">import</span> <span class="n">EMA</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="n">optim</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">ConditionalModel</span><span class="p">(</span><span class="n">num_steps</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="p">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
<span class="c1">#dataset = torch.tensor(data.T).float()
# Create EMA model
</span><span class="n">ema</span> <span class="o">=</span> <span class="n">EMA</span><span class="p">(</span><span class="mf">0.9</span><span class="p">)</span>
<span class="n">ema</span><span class="p">.</span><span class="n">register</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="c1"># Batch size
</span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">):</span>
    <span class="c1"># X is a torch Variable
</span>    <span class="n">permutation</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randperm</span><span class="p">(</span><span class="n">dataset</span><span class="p">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">0</span><span class="p">])</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">dataset</span><span class="p">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">0</span><span class="p">],</span> <span class="n">batch_size</span><span class="p">):</span>
        <span class="c1"># Retrieve current batch
</span>        <span class="n">indices</span> <span class="o">=</span> <span class="n">permutation</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">batch_size</span><span class="p">]</span>
        <span class="n">batch_x</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>
        <span class="c1"># Compute the loss.
</span>        <span class="n">loss</span> <span class="o">=</span> <span class="n">noise_estimation_loss</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">batch_x</span><span class="p">,</span><span class="n">alphas_bar_sqrt</span><span class="p">,</span><span class="n">one_minus_alphas_bar_sqrt</span><span class="p">,</span><span class="n">num_steps</span><span class="p">)</span>
        <span class="c1"># Before the backward pass, zero all of the network gradients
</span>        <span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="c1"># Backward pass: compute gradient of the loss with respect to parameters
</span>        <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="c1"># Perform gradient clipping
</span>        <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="mf">1.</span><span class="p">)</span>
        <span class="c1"># Calling the step function to update the parameters
</span>        <span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
        <span class="c1"># Update the exponential moving average
</span>        <span class="n">ema</span><span class="p">.</span><span class="n">update</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
    <span class="c1"># Print loss
</span>    <span class="k">if</span> <span class="p">(</span><span class="n">t</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
        <span class="k">print</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
        <span class="n">x_seq</span> <span class="o">=</span> <span class="n">p_sample_loop</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dataset</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span><span class="n">num_steps</span><span class="p">,</span><span class="n">alphas</span><span class="p">,</span><span class="n">betas</span><span class="p">,</span><span class="n">one_minus_alphas_bar_sqrt</span><span class="p">)</span>
        <span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">11</span><span class="p">):</span>
            <span class="n">cur_x</span> <span class="o">=</span> <span class="n">x_seq</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="mi">10</span><span class="p">].</span><span class="n">detach</span><span class="p">()</span>
            <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">].</span><span class="n">scatter</span><span class="p">(</span><span class="n">cur_x</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">cur_x</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s">'white'</span><span class="p">,</span><span class="n">edgecolor</span><span class="o">=</span><span class="s">'gray'</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">5</span><span class="p">);</span>
            <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">].</span><span class="n">set_axis_off</span><span class="p">();</span> 
            <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">'$q(\mathbf{x}_{'</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span><span class="o">+</span><span class="s">'})$'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensor(0.9140, grad_fn=&lt;MeanBackward0&gt;)
tensor(0.6532, grad_fn=&lt;MeanBackward0&gt;)
tensor(0.6371, grad_fn=&lt;MeanBackward0&gt;)
tensor(0.8389, grad_fn=&lt;MeanBackward0&gt;)
tensor(0.6238, grad_fn=&lt;MeanBackward0&gt;)
tensor(0.5684, grad_fn=&lt;MeanBackward0&gt;)
tensor(0.8178, grad_fn=&lt;MeanBackward0&gt;)
tensor(0.7874, grad_fn=&lt;MeanBackward0&gt;)
tensor(0.7548, grad_fn=&lt;MeanBackward0&gt;)
tensor(0.8650, grad_fn=&lt;MeanBackward0&gt;)
</code></pre></div></div>

<p><img src="/assets/2023-12-01-diffusion-model-demo1_files/2023-12-01-diffusion-model-demo1_21_1.png" alt="png" /></p>

<p><img src="/assets/2023-12-01-diffusion-model-demo1_files/2023-12-01-diffusion-model-demo1_21_2.png" alt="png" /></p>

<p><img src="/assets/2023-12-01-diffusion-model-demo1_files/2023-12-01-diffusion-model-demo1_21_3.png" alt="png" /></p>

<p><img src="/assets/2023-12-01-diffusion-model-demo1_files/2023-12-01-diffusion-model-demo1_21_4.png" alt="png" /></p>

<p><img src="/assets/2023-12-01-diffusion-model-demo1_files/2023-12-01-diffusion-model-demo1_21_5.png" alt="png" /></p>

<p><img src="/assets/2023-12-01-diffusion-model-demo1_files/2023-12-01-diffusion-model-demo1_21_6.png" alt="png" /></p>

<p><img src="/assets/2023-12-01-diffusion-model-demo1_files/2023-12-01-diffusion-model-demo1_21_7.png" alt="png" /></p>

<p><img src="/assets/2023-12-01-diffusion-model-demo1_files/2023-12-01-diffusion-model-demo1_21_8.png" alt="png" /></p>

<p><img src="/assets/2023-12-01-diffusion-model-demo1_files/2023-12-01-diffusion-model-demo1_21_9.png" alt="png" /></p>

<p><img src="/assets/2023-12-01-diffusion-model-demo1_files/2023-12-01-diffusion-model-demo1_21_10.png" alt="png" /></p>

<h2 id="animation">Animation</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Generating the forward image sequence
</span>
<span class="kn">import</span> <span class="nn">io</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>

<span class="n">imgs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="c1">#fig, axs = plt.subplots(1, 10, figsize=(28, 3))
</span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">clf</span><span class="p">()</span>
    <span class="n">q_i</span> <span class="o">=</span> <span class="n">q_x</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">i</span><span class="p">]))</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">q_i</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">q_i</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s">'white'</span><span class="p">,</span><span class="n">edgecolor</span><span class="o">=</span><span class="s">'gray'</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">5</span><span class="p">);</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">axis</span><span class="p">(</span><span class="s">'off'</span><span class="p">);</span> 
    
    <span class="n">img_buf</span> <span class="o">=</span> <span class="n">io</span><span class="p">.</span><span class="n">BytesIO</span><span class="p">()</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">img_buf</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s">'png'</span><span class="p">)</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">Image</span><span class="p">.</span><span class="nb">open</span><span class="p">(</span><span class="n">img_buf</span><span class="p">)</span>
    <span class="n">imgs</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
    
</code></pre></div></div>

<p><img src="/assets/2023-12-01-diffusion-model-demo1_files/2023-12-01-diffusion-model-demo1_23_0.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Generating the reverse diffusion sequence
</span>
<span class="n">reverse</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>  
    <span class="n">plt</span><span class="p">.</span><span class="n">clf</span><span class="p">()</span>
    <span class="n">cur_x</span> <span class="o">=</span> <span class="n">x_seq</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">detach</span><span class="p">()</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">cur_x</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">cur_x</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s">'white'</span><span class="p">,</span><span class="n">edgecolor</span><span class="o">=</span><span class="s">'gray'</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">5</span><span class="p">);</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">axis</span><span class="p">(</span><span class="s">'off'</span><span class="p">)</span>
    
    <span class="n">img_buf</span> <span class="o">=</span> <span class="n">io</span><span class="p">.</span><span class="n">BytesIO</span><span class="p">()</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">img_buf</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s">'png'</span><span class="p">)</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">Image</span><span class="p">.</span><span class="nb">open</span><span class="p">(</span><span class="n">img_buf</span><span class="p">)</span>
    <span class="n">reverse</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/assets/2023-12-01-diffusion-model-demo1_files/2023-12-01-diffusion-model-demo1_24_0.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">imgs</span> <span class="o">=</span> <span class="n">imgs</span> <span class="o">+</span> <span class="n">reverse</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">imgs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">save</span><span class="p">(</span><span class="s">"diffusion.gif"</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s">'GIF'</span><span class="p">,</span> <span class="n">append_images</span><span class="o">=</span><span class="n">imgs</span><span class="p">,</span><span class="n">save_all</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">duration</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">loop</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div></div>

<h1 id="references">References</h1>

<p>[1] Ho, J., Jain, A., &amp; Abbeel, P. (2020). Denoising diffusion probabilistic models. arXiv preprint arXiv:2006.11239.</p>

<p>[2] Sohl-Dickstein, J., Weiss, E. A., Maheswaranathan, N., &amp; Ganguli, S. (2015). Deep unsupervised learning using nonequilibrium thermodynamics. arXiv preprint arXiv:1503.03585.</p>]]></content><author><name>Zhu Tianda</name></author><category term="coding" /><category term="AI" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">working todo</title><link href="http://0.0.0.0:8855/working/2023/12/01/My-Tasks-and-Notes.html" rel="alternate" type="text/html" title="working todo" /><published>2023-12-01T00:00:00+08:00</published><updated>2023-12-01T00:00:00+08:00</updated><id>http://0.0.0.0:8855/working/2023/12/01/My-Tasks-and-Notes</id><content type="html" xml:base="http://0.0.0.0:8855/working/2023/12/01/My-Tasks-and-Notes.html"><![CDATA[<p>#todo</p>
<ul class="task-list">
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" checked="checked" />#task compare the nougat small model and code with the nougat big model what’s the different between them.  🔼 🛫 2024-01-09 : ✅ 2024-01-21</li>
  <li class="task-list-item">transformer version change to  4.34.1, then it work (static saving safe is in newer version)</li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" />#task based work output of above task let’s partially loading the Chinese Bart pre-trained model data 🔼 🛫 2024-01-09</li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" checked="checked" />prepare one small set dataset include Chinese data for training 🔼 🛫 2024-01-09 ✅ 2024-01-21</li>
  <li class="task-list-item">small set dataset — nougat-dataset-test include - ocrpadded, ocrset</li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" />adding authentication function to android and pc side client. let’s start this after Chinese supporting in server side.</li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" />adding authentication and security function to server side. let’s start this after Chinese supporting in server side.</li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" />today’s work 📅 2024-01-11 , ⏫  try to modify the ocr padding method to scale the ocr png to size fit  swin-transformer , then padding.  I suspect the training error is caused by too small png 🛫 padding.  current size is 672(w)x896(h)x8.. arxiv size is 816x1056x24.. something wrong.</li>
  <li class="task-list-item">notice that the orignal code has the resize function to make the small picture to fit the 886*672 size , so using the original un-padding figure (latex ocr dataset image) to feed the current training. but still have the “repetition error”</li>
  <li class="task-list-item">put the original un-padding figure  and the padded figure together into the training , it seems that the training have no “repetition error” still unclear why it is so????
    <ul>
      <li>this have the repetition error… while using bigger dataset from arXiv orignal data</li>
      <li>I am think the VIT how to train the all blank image… it is lead to some error , or how it is treated , get some test ???</li>
      <li>how about using all back or white image as training data</li>
      <li>how the voice to text treat the white noise? how the blank image is treated</li>
      <li>in normal ViT , the fixed size image is always required…,   how about reserve the SWIN transformer architecture, change from low level resolution to high resolution</li>
    </ul>
  </li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" checked="checked" />bleu score ✅ 2024-01-12, the bleu score is noted at [[Transformer_learning#3.2 Bleu Score]]</li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" />Pytorch-view的用法</li>
  <li class="task-list-item">在pytorch中view函数的作用为重构张量的维度，相当于numpy中resize（）的功能，但是用法可能不太一样。如下例所示</li>
</ul>

<div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt;&gt; import torch
&gt;&gt;&gt; tt1=torch.tensor([-0.3623, -0.6115,  0.7283,  0.4699,  2.3261,  0.1599])
&gt;&gt;&gt; result=tt1.view(3,2)
&gt;&gt;&gt; result
tensor([[-0.3623, -0.6115],
        [ 0.7283,  0.4699],
        [ 2.3261,  0.1599]])
</code></pre></div></div>

<ol>
  <li>torch.view(参数a，参数b，…)</li>
</ol>

<p>在上面例子中参数a=3和参数b=2决定了将一维的tt1重构成3x2维的张量。</p>

<ol>
  <li>有的时候会出现torch.view(-1)或者torch.view(参数a，-1)这种情况。
    <div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt;&gt; import torch
&gt;&gt;&gt; tt2=torch.tensor([[-0.3623, -0.6115],
...         [ 0.7283,  0.4699],
...         [ 2.3261,  0.1599]])
&gt;&gt;&gt; result=tt2.view(-1)
&gt;&gt;&gt; result
tensor([-0.3623, -0.6115,  0.7283,  0.4699,  2.3261,  0.1599])
</code></pre></div>    </div>
    <p>由上面的案例可以看到，如果是torch.view(-1)，则原张量会变成一维的结构。</p>
    <div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt;&gt; import torch
&gt;&gt;&gt; tt3=torch.tensor([[-0.3623, -0.6115],
...         [ 0.7283,  0.4699],
...         [ 2.3261,  0.1599]])
&gt;&gt;&gt; result=tt3.view(2,-1)
&gt;&gt;&gt; result
tensor([[-0.3623, -0.6115,  0.7283],
     [ 0.4699,  2.3261,  0.1599]])
</code></pre></div>    </div>
  </li>
</ol>

<p>由上面的案例可以看到，如果是torch.view(参数a，-1)，则表示在参数b未知，参数a已知的情况下自动补齐列向量长度，在这个例子中a=2，tt3总共由6个元素，则b=6/2=3。</p>]]></content><author><name>Zhu Tianda</name></author><category term="working" /><category term="AI" /><summary type="html"><![CDATA[#todo #task compare the nougat small model and code with the nougat big model what’s the different between them. 🔼 🛫 2024-01-09 : ✅ 2024-01-21 transformer version change to 4.34.1, then it work (static saving safe is in newer version) #task based work output of above task let’s partially loading the Chinese Bart pre-trained model data 🔼 🛫 2024-01-09 prepare one small set dataset include Chinese data for training 🔼 🛫 2024-01-09 ✅ 2024-01-21 small set dataset — nougat-dataset-test include - ocrpadded, ocrset adding authentication function to android and pc side client. let’s start this after Chinese supporting in server side. adding authentication and security function to server side. let’s start this after Chinese supporting in server side. today’s work 📅 2024-01-11 , ⏫ try to modify the ocr padding method to scale the ocr png to size fit swin-transformer , then padding. I suspect the training error is caused by too small png 🛫 padding. current size is 672(w)x896(h)x8.. arxiv size is 816x1056x24.. something wrong. notice that the orignal code has the resize function to make the small picture to fit the 886*672 size , so using the original un-padding figure (latex ocr dataset image) to feed the current training. but still have the “repetition error” put the original un-padding figure and the padded figure together into the training , it seems that the training have no “repetition error” still unclear why it is so???? this have the repetition error… while using bigger dataset from arXiv orignal data I am think the VIT how to train the all blank image… it is lead to some error , or how it is treated , get some test ??? how about using all back or white image as training data how the voice to text treat the white noise? how the blank image is treated in normal ViT , the fixed size image is always required…, how about reserve the SWIN transformer architecture, change from low level resolution to high resolution bleu score ✅ 2024-01-12, the bleu score is noted at [[Transformer_learning#3.2 Bleu Score]] Pytorch-view的用法 在pytorch中view函数的作用为重构张量的维度，相当于numpy中resize（）的功能，但是用法可能不太一样。如下例所示]]></summary></entry><entry><title type="html">Transformer Network</title><link href="http://0.0.0.0:8855/coding/2023/11/26/Transformer-learning-C5W4A1SubclassV1.html" rel="alternate" type="text/html" title="Transformer Network" /><published>2023-11-26T00:00:00+08:00</published><updated>2023-11-26T00:00:00+08:00</updated><id>http://0.0.0.0:8855/coding/2023/11/26/Transformer-learning-C5W4A1SubclassV1</id><content type="html" xml:base="http://0.0.0.0:8855/coding/2023/11/26/Transformer-learning-C5W4A1SubclassV1.html"><![CDATA[<p>I update this document also refere to</p>
<ol>
  <li>https://www.tensorflow.org/tutorials/text/transformer?hl=zh-cn</li>
  <li>https://nlp.seas.harvard.edu/2018/04/03/attention.html#positional-encoding</li>
</ol>

<h1 id="transformer-network">Transformer Network</h1>

<p>Welcome to Week 4’s assignment, the last assignment of Course 5 of the Deep Learning Specialization! And congratulations on making it to the last assignment of the entire Deep Learning Specialization - you’re almost done!</p>

<p>Ealier in the course, you’ve implemented sequential neural networks such as RNNs, GRUs, and LSTMs. In this notebook you’ll explore the Transformer architecture, a neural network that takes advantage of parallel processing and allows you to substantially speed up the training process.</p>

<p><strong>After this assignment you’ll be able to</strong>:</p>

<ul>
  <li>Create positional encodings to capture sequential relationships in data</li>
  <li>Calculate scaled dot-product self-attention with word embeddings</li>
  <li>Implement masked multi-head attention</li>
  <li>Build and train a Transformer model</li>
</ul>

<p>For the last time, let’s get started!</p>

<h2 id="table-of-contents">Table of Contents</h2>

<ul>
  <li><a href="#0">Packages</a></li>
  <li><a href="#1">1 - Positional Encoding</a>
    <ul>
      <li><a href="#1-1">1.1 - Sine and Cosine Angles</a>
        <ul>
          <li><a href="#ex-1">Exercise 1 - get_angles</a></li>
        </ul>
      </li>
      <li><a href="#1-2">1.2 - Sine and Cosine Positional Encodings</a>
        <ul>
          <li><a href="#ex-2">Exercise 2 - positional_encoding</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#2">2 - Masking</a>
    <ul>
      <li><a href="#2-1">2.1 - Padding Mask</a></li>
      <li><a href="#2-2">2.2 - Look-ahead Mask</a></li>
    </ul>
  </li>
  <li><a href="#3">3 - Self-Attention</a>
    <ul>
      <li><a href="#ex-3">Exercise 3 - scaled_dot_product_attention</a></li>
    </ul>
  </li>
  <li><a href="#4">4 - Encoder</a>
    <ul>
      <li><a href="#4-1">4.1 Encoder Layer</a>
        <ul>
          <li><a href="#ex-4">Exercise 4 - EncoderLayer</a></li>
        </ul>
      </li>
      <li><a href="#4-2">4.2 - Full Encoder</a>
        <ul>
          <li><a href="#ex-5">Exercise 5 - Encoder</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#5">5 - Decoder</a>
    <ul>
      <li><a href="#5-1">5.1 - Decoder Layer</a>
        <ul>
          <li><a href="#ex-6">Exercise 6 - DecoderLayer</a></li>
        </ul>
      </li>
      <li><a href="#5-2">5.2 - Full Decoder</a>
        <ul>
          <li><a href="#ex-7">Exercise 7 - Decoder</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#6">6 - Transformer</a>
    <ul>
      <li><a href="#ex-8">Exercise 8 - Transformer</a></li>
    </ul>
  </li>
  <li><a href="#7">7 - References</a></li>
</ul>

<p><a name="0"></a></p>
<h2 id="packages">Packages</h2>

<p>Run the following cell to load the packages you’ll need.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Embedding</span><span class="p">,</span> <span class="n">MultiHeadAttention</span><span class="p">,</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Input</span><span class="p">,</span> <span class="n">Dropout</span><span class="p">,</span> <span class="n">LayerNormalization</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">DistilBertTokenizerFast</span> <span class="c1">#, TFDistilBertModel
</span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">TFDistilBertForTokenClassification</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm_notebook</span> <span class="k">as</span> <span class="n">tqdm</span>

<span class="kn">import</span> <span class="nn">seaborn</span>
<span class="n">seaborn</span><span class="p">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">context</span><span class="o">=</span><span class="s">"talk"</span><span class="p">)</span>
</code></pre></div></div>

<p><a name="1"></a></p>
<h2 id="1---positional-encoding">1 - Positional Encoding</h2>

<p>In sequence to sequence tasks, the relative order of your data is extremely important to its meaning. When you were training sequential neural networks such as RNNs, you fed your inputs into the network in order. Information about the order of your data was automatically fed into your model.  However, when you train a Transformer network, you feed your data into the model all at once. While this dramatically reduces training time, there is no information about the order of your data. This is where positional encoding is useful - you can specifically encode the positions of your inputs and pass them into the network using these sine and cosine formulas:</p>

<p><img src="/assets/2023-12-03-Transformer-learning-C5W4A1SubclassV1_files/fafd0dfa-961d-416d-8159-678f0d903421.png" alt="image.png" />
\(PE_{(pos, 2i)}= sin\left(\frac{pos}{10000^{\frac{2i}{d}}}\right)
\tag{1}\)</p>

\[PE_{(pos, 2i+1)}= cos\left(\frac{pos}{10000^{\frac{2i}{d}}}\right)
\tag{2}\]

<font size="5" color="red">**it is like FFT, I should check it later!!**</font>
<ul>
  <li>$d$ is the dimension of the word embedding and positional encoding</li>
  <li>$pos$ is the position of the word.</li>
  <li>$i$ refers to each of the different dimensions of the positional encoding.</li>
</ul>

<p>The values of the sine and cosine equations are small enough (between -1 and 1) that when you add the positional encoding to a word embedding, the word embedding is not significantly distorted. The sum of the positional encoding and word embeding is ultimately what is fed into the model. Using a combination of these two equations helps your Transformer network attend to the relative positions of your input data. Note that while in the lectures Andrew uses vertical vectors but in this assignment, all vectors are horizontal. All matrix multiplications should be adjusted accordingly.</p>

<p><a name="1-1"></a></p>
<h3 id="11---sine-and-cosine-angles">1.1 - Sine and Cosine Angles</h3>

<p>Get the possible angles used to compute the positional encodings by calculating the inner term of the sine and cosine equations:</p>

\[\frac{pos}{10000^{\frac{2i}{d}}} \tag{3}\]

<p><a name="ex-1"></a></p>
<h3 id="exercise-1---get_angles">Exercise 1 - get_angles</h3>

<p>Implement the function <code class="language-plaintext highlighter-rouge">get_angles()</code> to calculate the possible angles for the sine and cosine  positional encodings</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># UNQ_C1 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)
# GRADED FUNCTION get_angles
</span><span class="k">def</span> <span class="nf">get_angles</span><span class="p">(</span><span class="n">pos</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">d</span><span class="p">):</span>
    <span class="s">"""
    Get the angles for the positional encoding
    
    Arguments:
        pos -- Column vector containing the positions [[0], [1], ...,[N-1]]
        i --   Row vector containing the dimension span [[0, 1, 2, ..., M-1]]
        d(integer) -- Encoding size
    
    Returns:
        angles -- (pos, d) numpy array 
    """</span>
    <span class="c1"># START CODE HERE
</span>    <span class="n">angles</span> <span class="o">=</span> <span class="n">pos</span><span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">power</span><span class="p">(</span><span class="mi">10000</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">i</span><span class="o">//</span><span class="mi">2</span><span class="p">))</span> <span class="o">/</span> <span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">(</span><span class="n">d</span><span class="p">)))</span>
    <span class="c1"># END CODE HERE
</span>    
    <span class="k">return</span> <span class="n">angles</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># UNIT TEST
</span><span class="k">def</span> <span class="nf">get_angles_test</span><span class="p">(</span><span class="n">target</span><span class="p">):</span>
    <span class="n">position</span> <span class="o">=</span> <span class="mi">4</span>
    <span class="n">d_model</span> <span class="o">=</span> <span class="mi">16</span>
    <span class="n">pos_m</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="n">position</span><span class="p">)[:,</span> <span class="n">np</span><span class="p">.</span><span class="n">newaxis</span><span class="p">]</span>
    <span class="n">dims</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="n">d_model</span><span class="p">)[</span><span class="n">np</span><span class="p">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="p">:]</span>

    <span class="n">result</span> <span class="o">=</span> <span class="n">target</span><span class="p">(</span><span class="n">pos_m</span><span class="p">,</span> <span class="n">dims</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>

    <span class="k">assert</span> <span class="nb">type</span><span class="p">(</span><span class="n">result</span><span class="p">)</span> <span class="o">==</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="s">"You must return a numpy ndarray"</span>
    <span class="k">assert</span> <span class="n">result</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">position</span><span class="p">,</span> <span class="n">d_model</span><span class="p">),</span> <span class="sa">f</span><span class="s">"Wrong shape. We expected: (</span><span class="si">{</span><span class="n">position</span><span class="si">}</span><span class="s">, </span><span class="si">{</span><span class="n">d_model</span><span class="si">}</span><span class="s">)"</span>
    <span class="k">assert</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:])</span> <span class="o">==</span> <span class="mi">0</span>
    <span class="k">assert</span> <span class="n">np</span><span class="p">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">result</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]),</span> <span class="n">position</span> <span class="o">*</span> <span class="p">(</span><span class="n">position</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">even_cols</span> <span class="o">=</span>  <span class="n">result</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span>
    <span class="n">odd_cols</span> <span class="o">=</span> <span class="n">result</span><span class="p">[:,</span>  <span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span>
    <span class="k">assert</span> <span class="n">np</span><span class="p">.</span><span class="nb">all</span><span class="p">(</span><span class="n">even_cols</span> <span class="o">==</span> <span class="n">odd_cols</span><span class="p">),</span> <span class="s">"Submatrices of odd and even columns must be equal"</span>
    <span class="c1"># edge value of the angle (d_model =16)
</span>    <span class="n">limit</span> <span class="o">=</span> <span class="p">(</span><span class="n">position</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="p">.</span><span class="n">power</span><span class="p">(</span><span class="mi">10000</span><span class="p">,</span><span class="mf">14.0</span><span class="o">/</span><span class="mf">16.0</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">np</span><span class="p">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="n">position</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">d_model</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">limit</span> <span class="p">),</span> <span class="sa">f</span><span class="s">"Last value must be </span><span class="si">{</span><span class="n">limit</span><span class="si">}</span><span class="s">"</span>

    <span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\033</span><span class="s">[92mAll tests passed"</span><span class="p">)</span>

<span class="n">get_angles_test</span><span class="p">(</span><span class="n">get_angles</span><span class="p">)</span>

<span class="c1"># Example
</span><span class="n">position</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">d_model</span> <span class="o">=</span> <span class="mi">8</span>
<span class="c1"># add new dimension to column so it will be (4, 1)
</span><span class="n">pos_m</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="n">position</span><span class="p">)[:,</span> <span class="n">np</span><span class="p">.</span><span class="n">newaxis</span><span class="p">]</span>
<span class="c1"># add new dimension to row so it will be (1, 4)
</span><span class="n">dims</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="n">d_model</span><span class="p">)[</span><span class="n">np</span><span class="p">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="p">:]</span>
<span class="n">angles</span><span class="o">=</span> <span class="n">get_angles</span><span class="p">(</span><span class="n">pos_m</span><span class="p">,</span> <span class="n">dims</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[92mAll tests passed
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pos_m</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([[0],
       [1],
       [2],
       [3]])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">dims</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([[0, 1, 2, 3, 4, 5, 6, 7]])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">angles</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([[0.e+00, 0.e+00, 0.e+00, 0.e+00, 0.e+00, 0.e+00, 0.e+00, 0.e+00],
       [1.e+00, 1.e+00, 1.e-01, 1.e-01, 1.e-02, 1.e-02, 1.e-03, 1.e-03],
       [2.e+00, 2.e+00, 2.e-01, 2.e-01, 2.e-02, 2.e-02, 2.e-03, 2.e-03],
       [3.e+00, 3.e+00, 3.e-01, 3.e-01, 3.e-02, 3.e-02, 3.e-03, 3.e-03]])
</code></pre></div></div>

<p><a name="1-2"></a></p>
<h3 id="12---sine-and-cosine-positional-encodings">1.2 - Sine and Cosine Positional Encodings</h3>

<p>Now you can use the angles you computed to calculate the sine and cosine positional encodings.</p>

\[PE_{(pos, 2i)}= sin\left(\frac{pos}{10000^{\frac{2i}{d}}}\right)\]

\[PE_{(pos, 2i+1)}= cos\left(\frac{pos}{10000^{\frac{2i}{d}}}\right)\]

<p><a name="ex-2"></a></p>
<h3 id="exercise-2---positional_encoding">Exercise 2 - positional_encoding</h3>

<p>Implement the function <code class="language-plaintext highlighter-rouge">positional_encoding()</code> to calculate the sine and cosine  positional encodings</p>

<p><strong>Reminder:</strong> Use the sine equation when $i$ is an even number and the cosine equation when $i$ is an odd number.</p>

<h4 id="additional-hints">Additional Hints</h4>
<ul>
  <li>You may find 
<a href="https://numpy.org/doc/stable/reference/arrays.indexing.html">np.newaxis</a> useful depending on the implementation you choose.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># UNQ_C2 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)
# GRADED FUNCTION positional_encoding
</span><span class="k">def</span> <span class="nf">positional_encoding</span><span class="p">(</span><span class="n">positions</span><span class="p">,</span> <span class="n">d</span><span class="p">):</span>
    <span class="s">"""
    Precomputes a matrix with all the positional encodings 
    
    Arguments:
        positions (int) -- Maximum number of positions to be encoded 
        d (int) -- Encoding size 
    
    Returns:
        pos_encoding -- (1, position, d_model) A matrix with the positional encodings
    """</span>
    <span class="c1"># START CODE HERE
</span>    <span class="c1"># initialize a matrix angle_rads of all the angles 
</span>    <span class="n">angle_rads</span> <span class="o">=</span> <span class="n">get_angles</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="n">positions</span><span class="p">)[:,</span> <span class="n">np</span><span class="p">.</span><span class="n">newaxis</span><span class="p">],</span>
                            <span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="n">d</span><span class="p">)[</span> <span class="n">np</span><span class="p">.</span><span class="n">newaxis</span><span class="p">,:],</span>
                            <span class="n">d</span><span class="p">)</span>
  
    <span class="c1"># -&gt; angle_rads has dim (positions,d)
</span>    <span class="c1"># apply sin to even indices in the array; 2i
</span>    <span class="n">angle_rads</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">sin</span><span class="p">(</span><span class="n">angle_rads</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">::</span><span class="mi">2</span><span class="p">])</span>
  
    <span class="c1"># apply cos to odd indices in the array; 2i+1
</span>    <span class="n">angle_rads</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">cos</span><span class="p">(</span><span class="n">angle_rads</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">])</span>
    <span class="c1"># END CODE HERE
</span>    
    <span class="n">pos_encoding</span> <span class="o">=</span> <span class="n">angle_rads</span><span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="p">...]</span>
    
    <span class="k">return</span> <span class="n">tf</span><span class="p">.</span><span class="n">cast</span><span class="p">(</span><span class="n">pos_encoding</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>

</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># UNIT TEST
</span><span class="k">def</span> <span class="nf">positional_encoding_test</span><span class="p">(</span><span class="n">target</span><span class="p">):</span>
    <span class="n">position</span> <span class="o">=</span> <span class="mi">8</span>
    <span class="n">d_model</span> <span class="o">=</span> <span class="mi">16</span>

    <span class="n">pos_encoding</span> <span class="o">=</span> <span class="n">target</span><span class="p">(</span><span class="n">position</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
    <span class="n">sin_part</span> <span class="o">=</span> <span class="n">pos_encoding</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span>
    <span class="n">cos_part</span> <span class="o">=</span> <span class="n">pos_encoding</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span>

    <span class="k">assert</span> <span class="n">tf</span><span class="p">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">pos_encoding</span><span class="p">),</span> <span class="s">"Output is not a tensor"</span>
    <span class="k">assert</span> <span class="n">pos_encoding</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">position</span><span class="p">,</span> <span class="n">d_model</span><span class="p">),</span> <span class="sa">f</span><span class="s">"Wrong shape. We expected: (1, </span><span class="si">{</span><span class="n">position</span><span class="si">}</span><span class="s">, </span><span class="si">{</span><span class="n">d_model</span><span class="si">}</span><span class="s">)"</span>

    <span class="n">ones</span> <span class="o">=</span> <span class="n">sin_part</span> <span class="o">**</span> <span class="mi">2</span>  <span class="o">+</span>  <span class="n">cos_part</span> <span class="o">**</span> <span class="mi">2</span>
    <span class="k">assert</span> <span class="n">np</span><span class="p">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">ones</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">position</span><span class="p">,</span> <span class="n">d_model</span> <span class="o">//</span> <span class="mi">2</span><span class="p">))),</span> <span class="s">"Sum of square pairs must be 1 = sin(a)**2 + cos(a)**2"</span>
    
    <span class="n">angs</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">arctan</span><span class="p">(</span><span class="n">sin_part</span> <span class="o">/</span> <span class="n">cos_part</span><span class="p">)</span>
    <span class="n">angs</span><span class="p">[</span><span class="n">angs</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">]</span> <span class="o">+=</span> <span class="n">np</span><span class="p">.</span><span class="n">pi</span>
    <span class="n">angs</span><span class="p">[</span><span class="n">sin_part</span><span class="p">.</span><span class="n">numpy</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">]</span> <span class="o">+=</span> <span class="n">np</span><span class="p">.</span><span class="n">pi</span>
    <span class="n">angs</span> <span class="o">=</span> <span class="n">angs</span> <span class="o">%</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">pi</span><span class="p">)</span>
    
    <span class="n">pos_m</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="n">position</span><span class="p">)[:,</span> <span class="n">np</span><span class="p">.</span><span class="n">newaxis</span><span class="p">]</span>
    <span class="n">dims</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="n">d_model</span><span class="p">)[</span><span class="n">np</span><span class="p">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="p">:]</span>

    <span class="n">trueAngs</span> <span class="o">=</span> <span class="n">get_angles</span><span class="p">(</span><span class="n">pos_m</span><span class="p">,</span> <span class="n">dims</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)[:,</span> <span class="mi">0</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span> <span class="o">%</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">pi</span><span class="p">)</span>
    
    <span class="k">assert</span> <span class="n">np</span><span class="p">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">angs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">trueAngs</span><span class="p">),</span> <span class="s">"Did you apply sin and cos to even and odd parts respectively?"</span>
 
    <span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\033</span><span class="s">[92mAll tests passed"</span><span class="p">)</span>
    
    
<span class="n">positional_encoding_test</span><span class="p">(</span><span class="n">positional_encoding</span><span class="p">)</span>

</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[92mAll tests passed


2023-05-09 10:37:45.354620: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-09 10:37:45.355316: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
</code></pre></div></div>

<p>another example implementation in torch https://nlp.seas.harvard.edu/2018/04/03/attention.html#positional-encoding</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="n">F</span>
<span class="kn">import</span> <span class="nn">math</span><span class="p">,</span> <span class="n">copy</span><span class="p">,</span> <span class="n">time</span>
<span class="kn">from</span> <span class="nn">torch.autograd</span> <span class="kn">import</span> <span class="n">Variable</span>

<span class="k">class</span> <span class="nc">PositionalEncoding</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="s">"Implement the PE function."</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">max_len</span><span class="o">=</span><span class="mi">5000</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">PositionalEncoding</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="n">dropout</span><span class="p">)</span>
        
        <span class="c1"># Compute the positional encodings once in log space.
</span>        <span class="n">pe</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">max_len</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
        <span class="n">position</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_len</span><span class="p">).</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">div_term</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span>
                             <span class="o">-</span><span class="p">(</span><span class="n">math</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="mf">10000.0</span><span class="p">)</span> <span class="o">/</span> <span class="n">d_model</span><span class="p">))</span>
        <span class="n">pe</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">sin</span><span class="p">(</span><span class="n">position</span> <span class="o">*</span> <span class="n">div_term</span><span class="p">)</span>
        <span class="n">pe</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cos</span><span class="p">(</span><span class="n">position</span> <span class="o">*</span> <span class="n">div_term</span><span class="p">)</span>
        <span class="n">pe</span> <span class="o">=</span> <span class="n">pe</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s">'pe'</span><span class="p">,</span> <span class="n">pe</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">Variable</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">pe</span><span class="p">[:,</span> <span class="p">:</span><span class="n">x</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)],</span> 
                         <span class="n">requires_grad</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</code></pre></div></div>

<p>Nice work calculating the positional encodings! Now you can visualize them.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pos_encoding</span> <span class="o">=</span> <span class="n">positional_encoding</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="mi">512</span><span class="p">)</span>

<span class="k">print</span> <span class="p">(</span><span class="n">pos_encoding</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">pcolormesh</span><span class="p">(</span><span class="n">pos_encoding</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s">'RdBu'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'d'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlim</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">512</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'Position'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">colorbar</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(1, 50, 512)
</code></pre></div></div>

<p><img src="/assets/2023-12-03-Transformer-learning-C5W4A1SubclassV1_files/2023-12-03-Transformer-learning-C5W4A1SubclassV1_17_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#forward acctually just adding the pos_endcoding to x, and adding one dropout which is ingored here
#this is just for corss check the pos_endcoding 
</span><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">x</span> <span class="p">,</span> <span class="n">pos_encoding</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">tf</span><span class="p">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">pos_encoding</span><span class="p">[:,</span> <span class="p">:</span><span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
    <span class="k">return</span> <span class="n">x</span>

<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">position</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">d_model</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">pos_encoding</span> <span class="o">=</span> <span class="n">positional_encoding</span><span class="p">(</span><span class="n">position</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">forward</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">20</span><span class="p">])),</span><span class="n">pos_encoding</span><span class="p">)</span>
<span class="n">tf</span><span class="p">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">20</span><span class="p">]))</span>
<span class="c1">#you will see the different value added
</span><span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">100</span><span class="p">),</span> <span class="n">y</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="mi">4</span><span class="p">:</span><span class="mi">8</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">([</span><span class="s">"dim %d"</span><span class="o">%</span><span class="n">p</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">7</span><span class="p">]])</span>
<span class="bp">None</span>
</code></pre></div></div>

<p><img src="/assets/2023-12-03-Transformer-learning-C5W4A1SubclassV1_files/2023-12-03-Transformer-learning-C5W4A1SubclassV1_18_0.png" alt="png" /></p>

<p>Each row represents a positional encoding - <font size="5" color="red">notice how none of the rows are identical! </font> You have created a unique positional encoding for each of the words.</p>

<p><a name="2"></a></p>
<h2 id="2---masking">2 - Masking</h2>

<p>There are two types of masks that are useful when building your Transformer network: the <em>padding mask</em> and the <em>look-ahead mask</em>. Both help the softmax computation give the appropriate weights to the words in your input sentence.</p>

<p><a name="2-1"></a></p>
<h3 id="21---padding-mask">2.1 - Padding Mask</h3>

<p>Oftentimes your input sequence will exceed the maximum length of a sequence your network can process. Let’s say the maximum length of your model is five, it is fed the following sequences:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[["Do", "you", "know", "when", "Jane", "is", "going", "to", "visit", "Africa"], 
 ["Jane", "visits", "Africa", "in", "September" ],
 ["Exciting", "!"]
]
</code></pre></div></div>

<p>which might get vectorized as:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[[ 71, 121, 4, 56, 99, 2344, 345, 1284, 15],
 [ 56, 1285, 15, 181, 545],
 [ 87, 600]
]
</code></pre></div></div>

<p>When passing sequences into a transformer model, it is important that they are of uniform length. You can achieve this by padding the sequence with zeros, and truncating sentences that exceed the maximum length of your model:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[[ 71, 121, 4, 56, 99],
 [ 2344, 345, 1284, 15, 0],
 [ 56, 1285, 15, 181, 545],
 [ 87, 600, 0, 0, 0],
]
</code></pre></div></div>

<font color="red">Sequences longer than the maximum length of five will be truncated, and zeros will be added to the truncated sequence to achieve uniform length.</font>
<p>Similarly, for sequences shorter than the maximum length, they zeros will also be added for padding. However, these zeros will affect the softmax calculation - this is when a padding mask comes in handy! By multiplying a padding mask by -1e9 and adding it to your sequence, you mask out the zeros by setting them to close to negative infinity. We’ll implement this for you so you can get to the fun of building the Transformer network! 😇 Just make sure you go through the code so you can correctly implement padding when building your model.</p>

<p>After masking, your input should go from <code class="language-plaintext highlighter-rouge">[87, 600, 0, 0, 0]</code> to <code class="language-plaintext highlighter-rouge">[87, 600, -1e9, -1e9, -1e9]</code>, so that when you take the softmax, the zeros don’t affect the score.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">create_padding_mask</span><span class="p">(</span><span class="n">seq</span><span class="p">):</span>
    <span class="s">"""
    Creates a matrix mask for the padding cells
    
    Arguments:
        seq -- (n, m) matrix
    
    Returns:
        mask -- (n, 1, 1, m) binary tensor
    """</span>
    <span class="n">seq</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">cast</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">math</span><span class="p">.</span><span class="n">equal</span><span class="p">(</span><span class="n">seq</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
  
    <span class="c1"># add extra dimensions to add the padding
</span>    <span class="c1"># to the attention logits.
</span>    <span class="k">return</span> <span class="n">seq</span><span class="p">[:,</span> <span class="n">tf</span><span class="p">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="n">tf</span><span class="p">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="p">:]</span> 
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">constant</span><span class="p">([[</span><span class="mf">7.</span><span class="p">,</span> <span class="mf">6.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">]])</span>
<span class="k">print</span><span class="p">(</span><span class="n">create_padding_mask</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tf.Tensor(
[[[[0. 0. 1. 1. 0.]]]


 [[[0. 0. 0. 1. 1.]]]


 [[[1. 1. 1. 0. 0.]]]], shape=(3, 1, 1, 5), dtype=float32)
</code></pre></div></div>

<p>If we multiply this mask by -1e9 and add it to the sample input sequences, the zeros are essentially set to negative infinity. Notice the difference when taking the softmax of the original sequence and the masked sequence:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">activations</span><span class="p">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">activations</span><span class="p">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="n">create_padding_mask</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">*</span> <span class="o">-</span><span class="mf">1.0e9</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tf.Tensor(
[[7.2876638e-01 2.6809818e-01 6.6454895e-04 6.6454895e-04 1.8064313e-03]
 [8.4437370e-02 2.2952457e-01 6.2391245e-01 3.1062772e-02 3.1062772e-02]
 [4.8541026e-03 4.8541026e-03 4.8541026e-03 2.6502505e-01 7.2041273e-01]], shape=(3, 5), dtype=float32)
tf.Tensor(
[[[[7.2973627e-01 2.6845497e-01 0.0000000e+00 0.0000000e+00
    1.8088354e-03]
   [2.4472848e-01 6.6524094e-01 0.0000000e+00 0.0000000e+00
    9.0030573e-02]
   [6.6483542e-03 6.6483542e-03 0.0000000e+00 0.0000000e+00
    9.8670328e-01]]]


 [[[7.3057157e-01 2.6876226e-01 6.6619506e-04 0.0000000e+00
    0.0000000e+00]
   [9.0030566e-02 2.4472845e-01 6.6524088e-01 0.0000000e+00
    0.0000000e+00]
   [3.3333334e-01 3.3333334e-01 3.3333334e-01 0.0000000e+00
    0.0000000e+00]]]


 [[[0.0000000e+00 0.0000000e+00 0.0000000e+00 2.6894143e-01
    7.3105860e-01]
   [0.0000000e+00 0.0000000e+00 0.0000000e+00 5.0000000e-01
    5.0000000e-01]
   [0.0000000e+00 0.0000000e+00 0.0000000e+00 2.6894143e-01
    7.3105860e-01]]]], shape=(3, 1, 3, 5), dtype=float32)
</code></pre></div></div>

<p><a name="2-2"></a></p>
<h3 id="22---look-ahead-mask--it-looks-like-the-mask-m-in-importedimplementing-transformersipynb---no-it-is-not-same-the-m-is-used-in-softmax">2.2 - Look-ahead Mask – it looks like the mask M in “imported/implementing-transformers.ipynb”  – no, it is not same, the M is used in softmax</h3>

<p>The look-ahead mask follows similar intuition. In training, you will have access to the complete correct output of your training example. The look-ahead mask helps your model pretend that it correctly predicted a part of the output and see if, <em>without looking ahead</em>, it can correctly predict the next output.</p>

<p>For example, if the expected correct output is <code class="language-plaintext highlighter-rouge">[1, 2, 3]</code> and you wanted to see if given that the model correctly predicted the first value it could predict the second value, you would mask out the second and third values. So you would input the masked sequence <code class="language-plaintext highlighter-rouge">[1, -1e9, -1e9]</code> and see if it could generate <code class="language-plaintext highlighter-rouge">[1, 2, -1e9]</code>.</p>

<p>Just because you’ve worked so hard, we’ll also implement this mask for you 😇😇. Again, take a close look at the code so you can effictively implement it later.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">create_look_ahead_mask</span><span class="p">(</span><span class="n">size</span><span class="p">):</span>
    <span class="s">"""
    Returns an upper triangular matrix filled with ones
    
    Arguments:
        size -- matrix size
    
    Returns:
        mask -- (size, size) tensor
    """</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="n">band_part</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">ones</span><span class="p">((</span><span class="n">size</span><span class="p">,</span> <span class="n">size</span><span class="p">)),</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">mask</span> 
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">temp</span> <span class="o">=</span> <span class="n">create_look_ahead_mask</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">temp</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tf.Tensor([[0.8312781  0.24044645 0.17191601]], shape=(1, 3), dtype=float32)





&lt;tf.Tensor: shape=(3, 3), dtype=float32, numpy=
array([[1., 0., 0.],
       [1., 1., 0.],
       [1., 1., 1.]], dtype=float32)&gt;
</code></pre></div></div>

<p><a name="3"></a></p>
<h2 id="3---self-attention">3 - Self-Attention</h2>

<p>As the authors of the Transformers paper state, “Attention is All You Need”.</p>

<center><img src="/assets//assets/2023-12-03-Transformer-learning-C5W4A1SubclassV1_files/self-attention.png" alt="Encoder" width="600" /></center>
<caption><center><font color="purple">Figure 1: Self-Attention calculation visualization</font></center></caption>

<p>The use of self-attention paired with traditional convolutional networks allows for the parallization which speeds up training. You will implement <strong>scaled dot product attention</strong> which takes in a query, key, value, and a mask as inputs to returns rich, attention-based vector representations of the words in your sequence. This type of self-attention can be mathematically expressed as:
\(\text { Attention }(Q, K, V)=\operatorname{softmax}\left(\frac{Q K^{T}}{\sqrt{d_{k}}}+{M}\right) V\tag{4}\)</p>

<ul>
  <li>$Q$ is the matrix of queries</li>
  <li>$K$ is the matrix of keys</li>
  <li>$V$ is the matrix of values</li>
  <li>$M$ is the optional mask you choose to apply</li>
  <li>${d_k}$ is the dimension of the keys, which is used to scale everything down so the softmax doesn’t explode</li>
</ul>

<p><a name="ex-3"></a></p>
<h3 id="exercise-3---scaled_dot_product_attention">Exercise 3 - scaled_dot_product_attention</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Implement the function `scaled_dot_product_attention()` to create attention-based representations **Reminder**: The boolean mask parameter can be passed in as `none` or as either padding or look-ahead. Multiply it by -1e9 before applying the softmax. 
</code></pre></div></div>

<p><strong>Additional Hints</strong></p>
<ul>
  <li>You may find <a href="https://www.tensorflow.org/api_docs/python/tf/linalg/matmul">tf.matmul</a> useful for matrix multiplication.</li>
</ul>

<p>Q，K和V是经过卷积后得到的特征，其形状为（batch_size，seq_length，num_features）。</p>

<p>将查询（Q）和键（K）相乘会得到（batch_size，seq_length，seq_length）特征，这大致告诉我们序列中每个元素的重要性，确定我们“注意”哪些元素。 注意数组使用softmax标准化，因此所有权重之和为1。 最后，注意力将通过矩阵乘法应用于值（V）数组。
请注意，MatMul操作在PyTorch中对应为torch.bmm。 这是因为Q，K和V（查询，键和值数组）都是矩阵，每个矩阵的形状均为（batch_size，sequence_length，num_features），矩阵乘法仅在最后两个维度上执行。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># UNQ_C3 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)
# GRADED FUNCTION scaled_dot_product_attention
</span><span class="k">def</span> <span class="nf">scaled_dot_product_attention</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">mask</span><span class="p">):</span>
    <span class="s">"""
    Calculate the attention weights.
      q, k, v must have matching leading dimensions.
      k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.
      The mask has different shapes depending on its type(padding or look ahead) 
      but it must be broadcastable for addition.

    Arguments:
        q -- query shape == (..., seq_len_q, depth)
        k -- key shape == (..., seq_len_k, depth)
        v -- value shape == (..., seq_len_v, depth_v)
        mask: Float tensor with shape broadcastable 
              to (..., seq_len_q, seq_len_k). Defaults to None.

    Returns:
        output -- attention_weights
    """</span>
    <span class="c1"># START CODE HERE
</span>    
    <span class="c1"># Q*K'
</span>    <span class="n">matmul_qk</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">transpose_b</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

    <span class="c1"># scale matmul_qk
</span>    <span class="n">dk</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">cast</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">shape</span><span class="p">(</span><span class="n">k</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">scaled_attention_logits</span> <span class="o">=</span> <span class="n">matmul_qk</span> <span class="o">/</span> <span class="n">tf</span><span class="p">.</span><span class="n">math</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">dk</span><span class="p">)</span>

    <span class="c1"># add the mask to the scaled tensor.
</span>    <span class="k">if</span> <span class="n">mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">scaled_attention_logits</span> <span class="o">+=</span> <span class="p">(</span><span class="n">mask</span> <span class="o">*</span> <span class="o">-</span><span class="mf">1e9</span><span class="p">)</span>

    <span class="c1"># softmax is normalized on the last axis (seq_len_k) so that the scores
</span>    <span class="c1"># add up to 1.
</span>    <span class="n">attention_weights</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">scaled_attention_logits</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># (..., seq_len_q, seq_len_k)
</span>    <span class="c1"># attention_weights * V
</span>    <span class="n">output</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">attention_weights</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>   <span class="c1"># (..., seq_len_q, depth_v)
</span>    
    <span class="c1"># END CODE HERE
</span>
    <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">attention_weights</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># UNIT TEST
</span><span class="k">def</span> <span class="nf">scaled_dot_product_attention_test</span><span class="p">(</span><span class="n">target</span><span class="p">):</span>
    <span class="n">q</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]).</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>  <span class="c1">#accoridng to vector is horizontal, so here means q is 4 feature vector but 
</span>                                                                                 <span class="c1">#3 is the seq_len， so here 3x4 matrix
</span>    <span class="n">k</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span> <span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]).</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span> <span class="c1">#k shape (4,4), still 4 is the seq_len but lenth is also 4
</span>                                                                                               <span class="c1">#q , v should have the same feature number , but it could be different 
</span>                                                                                               <span class="c1">#lenght?? -- it seems not reasonable ?
</span>    <span class="n">v</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]).</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>    <span class="c1">#q lenth is  should be 4, feature bumber is 2
</span>
    <span class="n">attention</span><span class="p">,</span> <span class="n">weights</span> <span class="o">=</span> <span class="n">target</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="bp">None</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">tf</span><span class="p">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">weights</span><span class="p">),</span> <span class="s">"Weights must be a tensor"</span>
    <span class="c1">#so here the weight shape is 3x4, shape should be (q.shape[0], k.shape[0]) instead of  (q.shape[0], k.shape[1]), k is transpose
</span>    <span class="c1">#assert tuple(tf.shape(weights).numpy()) == (q.shape[0], k.shape[1]), f"Wrong shape. We expected ({q.shape[0]}, {k.shape[1]})"
</span>    <span class="k">assert</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">shape</span><span class="p">(</span><span class="n">weights</span><span class="p">).</span><span class="n">numpy</span><span class="p">())</span> <span class="o">==</span> <span class="p">(</span><span class="n">q</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">k</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="sa">f</span><span class="s">"Wrong shape. We expected (</span><span class="si">{</span><span class="n">q</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s">, </span><span class="si">{</span><span class="n">k</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s">)"</span>
    
    <span class="k">assert</span> <span class="n">np</span><span class="p">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="p">[[</span><span class="mf">0.2589478</span><span class="p">,</span>  <span class="mf">0.42693272</span><span class="p">,</span> <span class="mf">0.15705977</span><span class="p">,</span> <span class="mf">0.15705977</span><span class="p">],</span>
                                   <span class="p">[</span><span class="mf">0.2772748</span><span class="p">,</span>  <span class="mf">0.2772748</span><span class="p">,</span>  <span class="mf">0.2772748</span><span class="p">,</span>  <span class="mf">0.16817567</span><span class="p">],</span>
                                   <span class="p">[</span><span class="mf">0.33620113</span><span class="p">,</span> <span class="mf">0.33620113</span><span class="p">,</span> <span class="mf">0.12368149</span><span class="p">,</span> <span class="mf">0.2039163</span> <span class="p">]])</span>

    <span class="k">assert</span> <span class="n">tf</span><span class="p">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">attention</span><span class="p">),</span> <span class="s">"Output must be a tensor"</span>
    <span class="k">assert</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">shape</span><span class="p">(</span><span class="n">attention</span><span class="p">).</span><span class="n">numpy</span><span class="p">())</span> <span class="o">==</span> <span class="p">(</span><span class="n">q</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">v</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="sa">f</span><span class="s">"Wrong shape. We expected (</span><span class="si">{</span><span class="n">q</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s">, </span><span class="si">{</span><span class="n">v</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s">)"</span>
    <span class="k">assert</span> <span class="n">np</span><span class="p">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">attention</span><span class="p">,</span> <span class="p">[[</span><span class="mf">0.74105227</span><span class="p">,</span> <span class="mf">0.15705977</span><span class="p">],</span>
                                   <span class="p">[</span><span class="mf">0.7227253</span><span class="p">,</span>  <span class="mf">0.16817567</span><span class="p">],</span>
                                   <span class="p">[</span><span class="mf">0.6637989</span><span class="p">,</span>  <span class="mf">0.2039163</span> <span class="p">]])</span>

    <span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
    <span class="n">attention</span><span class="p">,</span> <span class="n">weights</span> <span class="o">=</span> <span class="n">target</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>

    <span class="k">assert</span> <span class="n">np</span><span class="p">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="p">[[</span><span class="mf">0.30719590187072754</span><span class="p">,</span> <span class="mf">0.5064803957939148</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.18632373213768005</span><span class="p">],</span>
                                 <span class="p">[</span><span class="mf">0.3836517333984375</span><span class="p">,</span> <span class="mf">0.3836517333984375</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.2326965481042862</span><span class="p">],</span>
                                 <span class="p">[</span><span class="mf">0.3836517333984375</span><span class="p">,</span> <span class="mf">0.3836517333984375</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.2326965481042862</span><span class="p">]]),</span> <span class="s">"Wrong masked weights"</span>
    <span class="k">assert</span> <span class="n">np</span><span class="p">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">attention</span><span class="p">,</span> <span class="p">[[</span><span class="mf">0.6928040981292725</span><span class="p">,</span> <span class="mf">0.18632373213768005</span><span class="p">],</span>
                                   <span class="p">[</span><span class="mf">0.6163482666015625</span><span class="p">,</span> <span class="mf">0.2326965481042862</span><span class="p">],</span> 
                                   <span class="p">[</span><span class="mf">0.6163482666015625</span><span class="p">,</span> <span class="mf">0.2326965481042862</span><span class="p">]]),</span> <span class="s">"Wrong masked attention"</span>
    
    <span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\033</span><span class="s">[92mAll tests passed"</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">attention</span><span class="p">,</span> <span class="n">weights</span> 
    
<span class="n">attention</span><span class="p">,</span> <span class="n">weights</span> <span class="o">=</span> <span class="n">scaled_dot_product_attention_test</span><span class="p">(</span><span class="n">scaled_dot_product_attention</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">attention</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[92mAll tests passed
tf.Tensor(
[[0.6928041  0.18632373]
 [0.61634827 0.23269655]
 [0.61634827 0.23269655]], shape=(3, 2), dtype=float32)
tf.Tensor(
[[0.3071959  0.5064804  0.         0.18632373]
 [0.38365173 0.38365173 0.         0.23269655]
 [0.38365173 0.38365173 0.         0.23269655]], shape=(3, 4), dtype=float32)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">q</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]).</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">k</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span> <span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]).</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">v</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]).</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">k</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">matmul_qk</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">transpose_b</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">matmul_qk</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(4, 4)
tf.Tensor(
[[2. 3. 1. 1.]
 [2. 2. 2. 1.]
 [2. 2. 0. 1.]], shape=(3, 4), dtype=float32)
</code></pre></div></div>

<p>another sample to Obtaining Query, Key and Value matrix</p>

<p><img src="/assets/2023-12-03-Transformer-learning-C5W4A1SubclassV1_files/ce597e22-7e6c-4e60-86f9-1d7af9a71b6b.png" alt="image.png" />!</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#generate the emdedding the word vector for "this is book", each vector have 5 features
</span><span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Shape is :- </span><span class="si">{</span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">5</span><span class="p">).</span><span class="n">shape</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
<span class="n">X</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>
<span class="n">X</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Shape is :- (3, 5)





array([[ 0.47858264, -1.74327212, -0.82029071, -0.21163698,  1.31543753],
       [-0.09012238, -0.48729982,  0.84112528,  1.85078928,  0.32633046],
       [-1.62962921,  0.17127885, -0.49912593,  0.09966805, -0.55323133]])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">weight_of_query</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="n">weight_of_query</span>
<span class="n">Query</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">weight_of_query</span><span class="p">)</span>
<span class="n">Query</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([[-2.28215318, -0.37214572,  0.97116363],
       [-0.04802642,  1.48761478, -0.61758178],
       [-2.79664269, -3.07753598, -0.81546614]])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">weight_of_key</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="n">weight_of_key</span>
<span class="n">Key</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">weight_of_key</span><span class="p">)</span>
<span class="n">Key</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([[-2.03322686,  1.9992987 ,  2.09889272],
       [ 0.1997882 ,  0.12002915, -3.34110812],
       [ 3.23284659, -0.30207486, -0.76657696]])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">weight_of_values</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="n">weight_of_values</span>
<span class="n">Values</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">weight_of_values</span><span class="p">)</span>
<span class="n">Values</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([[-2.60174708, -1.75190164, -1.32735991],
       [-2.93463348,  0.28382245, -1.42966431],
       [ 1.57416533,  3.9202751 , -0.21375642]])
</code></pre></div></div>

<p><strong>so most cases the W_q, W_k, W_v are same shape, so the q, k, v also have the same shape</strong><br />
<img src="/assets/2023-12-03-Transformer-learning-C5W4A1SubclassV1_files/18755036-dc11-421e-917c-7d2aec49f7fb.png" alt="image.png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">dimension</span><span class="o">=</span><span class="mi">5</span>
<span class="n">Scores</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">Query</span><span class="p">,</span><span class="n">Key</span><span class="p">.</span><span class="n">T</span><span class="p">)</span><span class="o">/</span><span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">dimension</span><span class="p">)</span> <span class="c1">#score is the weights
</span><span class="n">Scores</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([[ 2.653977  , -1.6749841 , -3.58213928],
       [ 0.79407112,  0.998346  , -0.0586785 ],
       [-0.97415669,  0.80338804, -3.34799884]])
</code></pre></div></div>

<p>Excellent work! You can now implement self-attention. With that, you can start building the encoder block!</p>

<p><a name="4"></a></p>
<h2 id="4---encoder">4 - Encoder</h2>

<p>The Transformer Encoder layer pairs self-attention and convolutional neural network style of processing to improve the speed of training and passes K and V matrices to the Decoder, which you’ll build later in the assignment. In this section of the assignment, you will implement the Encoder by pairing multi-head attention and a feed forward neural network (Figure 2a).</p>
<center><img src="/assets//assets/2023-12-03-Transformer-learning-C5W4A1SubclassV1_files/encoder_layer.png" alt="Encoder" width="250" /></center>
<caption><center><font color="purple"><b>Figure 2a: Transformer encoder layer</b></font></center></caption>

<ul>
  <li><code class="language-plaintext highlighter-rouge">MultiHeadAttention</code> you can think of as computing the self-attention several times to detect different features.</li>
  <li>Feed forward neural network contains two Dense layers which we’ll implement as the function <code class="language-plaintext highlighter-rouge">FullyConnected</code></li>
</ul>

<p>Your input sentence first passes through a <em>multi-head attention layer</em>, where the encoder looks at other words in the input sentence as it encodes a specific word. The outputs of the multi-head attention layer are then fed to a <em>feed forward neural network</em>. The exact same feed forward network is independently applied to each position.</p>

<ul>
  <li>For the <code class="language-plaintext highlighter-rouge">MultiHeadAttention</code> layer, you will use the <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/MultiHeadAttention">Keras implementation</a>. If you’re curious about how to split the query matrix Q, key matrix K, and value matrix V into different heads, you can look through the implementation.</li>
  <li>You will also use the <a href="https://keras.io/api/models/sequential/">Sequential API</a> with two dense layers to built the feed forward neural network layers.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">FullyConnected</span><span class="p">(</span><span class="n">embedding_dim</span><span class="p">,</span> <span class="n">fully_connected_dim</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">Sequential</span><span class="p">([</span>
        <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">fully_connected_dim</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">),</span>  <span class="c1"># (batch_size, seq_len, dff)
</span>        <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">embedding_dim</span><span class="p">)</span>  <span class="c1"># (batch_size, seq_len, d_model)
</span>    <span class="p">])</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sample_ffn</span> <span class="o">=</span> <span class="n">FullyConnected</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">2048</span><span class="p">)</span>
<span class="n">sample_ffn</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">64</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">512</span><span class="p">))).</span><span class="n">shape</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>TensorShape([64, 50, 512])
</code></pre></div></div>

<p><a name="4-1"></a></p>
<h3 id="41-encoder-layer">4.1 Encoder Layer</h3>

<p>Now you can pair multi-head attention and feed forward neural network together in an encoder layer! You will also use residual connections and layer normalization to help speed up training (Figure 2a).</p>

<p><a name="ex-4"></a></p>
<h3 id="exercise-4---encoderlayer">Exercise 4 - EncoderLayer</h3>

<p>Implement <code class="language-plaintext highlighter-rouge">EncoderLayer()</code> using the <code class="language-plaintext highlighter-rouge">call()</code> method</p>

<p>In this exercise, you will implement one encoder block (Figure 2) using the <code class="language-plaintext highlighter-rouge">call()</code> method. The function should perform the following steps:</p>
<ol>
  <li>You will pass the Q, V, K matrices and a boolean mask to a multi-head attention layer. Remember that to compute <em>self</em>-attention Q, V and K should be the same.</li>
  <li>Next, you will pass the output of the multi-head attention layer to a dropout layer. Don’t forget to use the <code class="language-plaintext highlighter-rouge">training</code> parameter to set the mode of your model.</li>
  <li>Now add a skip connection by adding your original input <code class="language-plaintext highlighter-rouge">x</code> and the output of the dropout layer.</li>
  <li>After adding the skip connection, pass the output through the first layer normalization.</li>
  <li>Finally, repeat steps 1-4 but with the feed forward neural network instead of the multi-head attention layer.</li>
</ol>

<p><strong>Additional Hints</strong>:</p>
<ul>
  <li>The <code class="language-plaintext highlighter-rouge">__init__</code> method creates all the layers that will be accesed by the the <code class="language-plaintext highlighter-rouge">call</code> method. Wherever you want to use a layer defined inside  the <code class="language-plaintext highlighter-rouge">__init__</code>  method you will have to use the syntax <code class="language-plaintext highlighter-rouge">self.[insert layer name]</code>.</li>
  <li>You will find the documentation of <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/MultiHeadAttention">MultiHeadAttention</a> helpful. <em>Note that if query, key and value are the same, then this function performs self-attention.</em></li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># I borrow the another implemenation of the MultiHeadAttention to cross check 
</span><span class="k">def</span> <span class="nf">multihead_attention</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">heads</span><span class="p">,</span> <span class="n">W_KQV</span><span class="p">,</span> <span class="n">W_out</span><span class="p">):</span>
    <span class="n">N</span><span class="p">,</span><span class="n">T</span><span class="p">,</span><span class="n">d</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">shape</span>
    <span class="n">K</span><span class="p">,</span><span class="n">Q</span><span class="p">,</span><span class="n">V</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="o">@</span><span class="n">W_KQV</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">K</span><span class="p">,</span><span class="n">Q</span><span class="p">,</span><span class="n">V</span> <span class="o">=</span> <span class="p">[</span><span class="n">a</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="n">T</span><span class="p">,</span><span class="n">heads</span><span class="p">,</span><span class="n">d</span><span class="o">//</span><span class="n">heads</span><span class="p">).</span><span class="n">swapaxes</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="p">(</span><span class="n">K</span><span class="p">,</span><span class="n">Q</span><span class="p">,</span><span class="n">V</span><span class="p">)]</span>
    
    <span class="n">attn</span> <span class="o">=</span> <span class="n">softmax</span><span class="p">(</span><span class="n">K</span><span class="o">@</span><span class="n">Q</span><span class="p">.</span><span class="n">swapaxes</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">d</span><span class="o">//</span><span class="n">heads</span><span class="p">)</span> <span class="o">+</span> <span class="n">mask</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">attn</span><span class="o">@</span><span class="n">V</span><span class="p">).</span><span class="n">swapaxes</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">).</span><span class="n">reshape</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="n">T</span><span class="p">,</span><span class="n">d</span><span class="p">)</span> <span class="o">@</span> <span class="n">W_out</span><span class="p">,</span> <span class="n">attn</span>
</code></pre></div></div>

<p>多头注意力由四部分组成：</p>

<p>线性层并分拆成多头。
按比缩放的点积注意力。
多头及联。
最后一层线性层。
每个多头注意力块有三个输入：Q（请求）、K（主键）、V（数值）。这些输入经过线性（Dense）层，并分拆成多头。– <font size="4" color="red">先经过dense 层,然后再分拆层多头matrix 喂给多个head ，经过学习后这些dense网络的W_q, W_k, W_v, 其实和前面实现中的W_q, W_k, W_v是相同的作用</font></p>

<p>将上面定义的 scaled_dot_product_attention 函数应用于每个头（进行了广播（broadcasted）以提高效率）。注意力这步必须使用一个恰当的 mask。然后将每个头的注意力输出连接起来（用tf.transpose 和 tf.reshape），并放入最后的 Dense 层。</p>

<p>Q、K、和 V 被拆分到了多个头，而非单个的注意力头，因为多头允许模型共同注意来自不同表示空间的不同位置的信息。在分拆后，每个头部的维度减少，因此总的计算成本与有着全部维度的单个注意力头相同。</p>

<p><img src="/assets/2023-12-03-Transformer-learning-C5W4A1SubclassV1_files/d777e331-2ae4-48d6-8725-1975e945b192.png" alt="image.png" /></p>

<p><img src="/assets/2023-12-03-Transformer-learning-C5W4A1SubclassV1_files/23a76e89-6143-4f1b-86c1-9e5f8a52e641.png" alt="image.png" />
<img src="/assets/2023-12-03-Transformer-learning-C5W4A1SubclassV1_files/a407995b-56d9-4c42-a6d9-f1fc11c53c76.png" alt="image.png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># borrow the clip implemenation of the MultiHeadAttention to cross check 
</span><span class="k">class</span> <span class="nc">MultiheadAttention</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_ctx</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">heads</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">n_ctx</span> <span class="o">=</span> <span class="n">n_ctx</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">width</span> <span class="o">=</span> <span class="n">width</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">heads</span> <span class="o">=</span> <span class="n">heads</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">c_qkv</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">width</span><span class="p">,</span> <span class="n">width</span> <span class="o">*</span> <span class="mi">3</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">c_proj</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">width</span><span class="p">,</span> <span class="n">width</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">attention</span> <span class="o">=</span> <span class="n">QKVMultiheadAttention</span><span class="p">(</span><span class="n">heads</span><span class="p">,</span> <span class="n">n_ctx</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">c_qkv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">attention</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">c_proj</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>


<span class="k">class</span> <span class="nc">MLP</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">width</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">width</span> <span class="o">=</span> <span class="n">width</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">c_fc</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">width</span><span class="p">,</span> <span class="n">width</span> <span class="o">*</span> <span class="mi">4</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">c_proj</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">width</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span> <span class="n">width</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">gelu</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">GELU</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">c_proj</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">gelu</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">c_fc</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>


<span class="k">class</span> <span class="nc">QKVMultiheadAttention</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_heads</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">n_ctx</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">n_heads</span> <span class="o">=</span> <span class="n">n_heads</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">n_ctx</span> <span class="o">=</span> <span class="n">n_ctx</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">qkv</span><span class="p">):</span>
        <span class="c1">#get bachsize , 
</span>        <span class="n">bs</span><span class="p">,</span> <span class="n">n_ctx</span><span class="p">,</span> <span class="n">width</span> <span class="o">=</span> <span class="n">qkv</span><span class="p">.</span><span class="n">shape</span>
        <span class="n">attn_ch</span> <span class="o">=</span> <span class="n">width</span> <span class="o">//</span> <span class="bp">self</span><span class="p">.</span><span class="n">n_heads</span> <span class="o">//</span> <span class="mi">3</span>
        <span class="n">scale</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">math</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">math</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">attn_ch</span><span class="p">))</span>
        <span class="n">qkv</span> <span class="o">=</span> <span class="n">qkv</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="n">n_ctx</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">n_heads</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        
        <span class="c1">### 分拆最后q,k,v维度到 (num_heads, depth).
</span>        <span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="n">th</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="n">qkv</span><span class="p">,</span> <span class="n">attn_ch</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">weight</span> <span class="o">=</span> <span class="n">th</span><span class="p">.</span><span class="n">einsum</span><span class="p">(</span>
            <span class="s">"bthc,bshc-&gt;bhts"</span><span class="p">,</span> <span class="n">q</span> <span class="o">*</span> <span class="n">scale</span><span class="p">,</span> <span class="n">k</span> <span class="o">*</span> <span class="n">scale</span>
        <span class="p">)</span>  <span class="c1"># More stable with f16 than dividing afterwards
</span>        <span class="n">wdtype</span> <span class="o">=</span> <span class="n">weight</span><span class="p">.</span><span class="n">dtype</span>

        <span class="c1">### calucate the softmax attention
</span>        <span class="n">weight</span> <span class="o">=</span> <span class="n">th</span><span class="p">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">weight</span><span class="p">.</span><span class="nb">float</span><span class="p">(),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">).</span><span class="nb">type</span><span class="p">(</span><span class="n">wdtype</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">th</span><span class="p">.</span><span class="n">einsum</span><span class="p">(</span><span class="s">"bhts,bshc-&gt;bthc"</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">v</span><span class="p">).</span><span class="n">reshape</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="n">n_ctx</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># I borrow the another implemenation of the MultiHeadAttention to cross check 
</span><span class="k">class</span> <span class="nc">MultiHeadAttention</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Layer</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MultiHeadAttention</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">num_heads</span> <span class="o">=</span> <span class="n">num_heads</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">d_model</span> <span class="o">=</span> <span class="n">d_model</span>
        <span class="k">assert</span> <span class="n">d_model</span> <span class="o">%</span> <span class="bp">self</span><span class="p">.</span><span class="n">num_heads</span> <span class="o">==</span> <span class="mi">0</span>

        <span class="c1">## numbers heads will collapse the feature depth into heads.. such as feed features parallel to different heads so that improve the efficiency
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">depth</span> <span class="o">=</span> <span class="n">d_model</span> <span class="o">//</span> <span class="bp">self</span><span class="p">.</span><span class="n">num_heads</span> 
        
        <span class="bp">self</span><span class="p">.</span><span class="n">wq</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">wk</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">wv</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">dense</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">split_heads</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
        <span class="s">"""分拆最后一个维度到 (num_heads, depth).
        转置结果使得形状为 (batch_size, num_heads, seq_len, depth)
        """</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">depth</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">tf</span><span class="p">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">perm</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">return_attention_scores</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">shape</span><span class="p">(</span><span class="n">q</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

        <span class="n">q</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">wq</span><span class="p">(</span><span class="n">q</span><span class="p">)</span>  <span class="c1"># (batch_size, seq_len, d_model)
</span>        <span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">wk</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>  <span class="c1"># (batch_size, seq_len, d_model)
</span>        <span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">wv</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>  <span class="c1"># (batch_size, seq_len, d_model)
</span>
        <span class="n">q</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">split_heads</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>  <span class="c1"># (batch_size, num_heads, seq_len_q, depth)
</span>        <span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">split_heads</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>  <span class="c1"># (batch_size, num_heads, seq_len_k, depth)
</span>        <span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">split_heads</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>  <span class="c1"># (batch_size, num_heads, seq_len_v, depth)
</span>
        <span class="c1"># scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)
</span>        <span class="c1"># attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)
</span>        <span class="n">scaled_attention</span><span class="p">,</span> <span class="n">attention_weights</span> <span class="o">=</span> <span class="n">scaled_dot_product_attention</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>
        
        <span class="c1">#reverse the split head procedure 
</span>        <span class="n">scaled_attention</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">scaled_attention</span><span class="p">,</span> <span class="n">perm</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>  <span class="c1"># (batch_size, seq_len_q, num_heads, depth)
</span>    
        <span class="n">concat_attention</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">scaled_attention</span><span class="p">,</span> 
                                      <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">d_model</span><span class="p">))</span>  <span class="c1"># (batch_size, seq_len_q, d_model)
</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">dense</span><span class="p">(</span><span class="n">concat_attention</span><span class="p">)</span>  <span class="c1"># (batch_size, seq_len_q, d_model)
</span>        <span class="k">if</span> <span class="n">return_attention_scores</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">attention_weights</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">output</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">temp_mha</span> <span class="o">=</span> <span class="n">MultiHeadAttention</span><span class="p">(</span><span class="n">d_model</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">num_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">512</span><span class="p">))</span>  <span class="c1"># (batch_size, encoder_sequence, d_model)
</span><span class="n">out</span><span class="p">,</span> <span class="n">attn</span> <span class="o">=</span> <span class="n">temp_mha</span><span class="p">(</span><span class="n">q</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">v</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span><span class="n">return_attention_scores</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">out</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">attn</span><span class="p">.</span><span class="n">shape</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(TensorShape([1, 60, 512]), TensorShape([1, 8, 60, 60]))
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">temp_mha</span><span class="p">.</span><span class="n">num_heads</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>8
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">## if for tf , give the number_heads &gt; key_dim , how the output could be?
</span><span class="n">layer</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">MultiHeadAttention</span><span class="p">(</span><span class="n">num_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">key_dim</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="n">source</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="n">output_tensor</span><span class="p">,</span> <span class="n">weights</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">source</span><span class="p">,</span>
                               <span class="n">return_attention_scores</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">output_tensor</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">weights</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>

</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(None, 8, 4)
(None, 8, 8, 4)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#check the matrix split heads
</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">shape</span><span class="p">(</span><span class="n">y</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">depth</span> <span class="o">=</span> <span class="mi">512</span> <span class="o">//</span> <span class="mi">8</span>  <span class="c1"># numbers heads will collapse the feature depth into heads.. such as feed features parallel to different heads so that improve the efficiency
</span><span class="n">num_heads</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">wq</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">512</span><span class="p">)</span>
<span class="n">q</span> <span class="o">=</span> <span class="n">wq</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="c1">#check split heads
</span><span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">depth</span><span class="p">))</span> <span class="c1"># (batch_size, seq_len_q ,num_heads, depth)
</span><span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">perm</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span> <span class="c1"># (batch_size, num_heads, seq_len_q, depth)
</span><span class="n">x</span><span class="p">.</span><span class="n">shape</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>TensorShape([1, 8, 60, 64])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># UNQ_C4 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)
# GRADED FUNCTION EncoderLayer
</span><span class="k">class</span> <span class="nc">EncoderLayer</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Layer</span><span class="p">):</span>
    <span class="s">"""
    The encoder layer is composed by a multi-head self-attention mechanism,
    followed by a simple, positionwise fully connected feed-forward network. 
    This archirecture includes a residual connection around each of the two 
    sub-layers, followed by layer normalization.
    """</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">fully_connected_dim</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">layernorm_eps</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">EncoderLayer</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">ownMultiHead</span> <span class="o">=</span> <span class="n">ownMultiHead</span>
        
        <span class="k">if</span> <span class="p">(</span><span class="n">ownMultiHead</span><span class="o">==</span><span class="bp">False</span><span class="p">):</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">mha</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">MultiHeadAttention</span><span class="p">(</span><span class="n">num_heads</span><span class="o">=</span><span class="n">num_heads</span><span class="p">,</span>
                                          <span class="n">key_dim</span><span class="o">=</span><span class="n">embedding_dim</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">mha</span> <span class="o">=</span> <span class="n">MultiHeadAttention</span><span class="p">(</span><span class="n">embedding_dim</span><span class="p">,</span><span class="n">num_heads</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="p">.</span><span class="n">ffn</span> <span class="o">=</span> <span class="n">FullyConnected</span><span class="p">(</span><span class="n">embedding_dim</span><span class="o">=</span><span class="n">embedding_dim</span><span class="p">,</span>
                                  <span class="n">fully_connected_dim</span><span class="o">=</span><span class="n">fully_connected_dim</span><span class="p">)</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">layernorm1</span> <span class="o">=</span> <span class="n">LayerNormalization</span><span class="p">(</span><span class="n">epsilon</span><span class="o">=</span><span class="n">layernorm_eps</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">layernorm2</span> <span class="o">=</span> <span class="n">LayerNormalization</span><span class="p">(</span><span class="n">epsilon</span><span class="o">=</span><span class="n">layernorm_eps</span><span class="p">)</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">dropout1</span> <span class="o">=</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_rate</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">dropout2</span> <span class="o">=</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_rate</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="p">,</span> <span class="n">mask</span><span class="p">):</span>
        <span class="s">"""
        Forward pass for the Encoder Layer
        
        Arguments:
            x -- Tensor of shape (batch_size, input_seq_len, embedding_dim)
            training -- Boolean, set to true to activate
                        the training mode for dropout layers
            mask -- Boolean mask to ensure that the padding is not 
                    treated as part of the input
        Returns:
            out2 -- Tensor of shape (batch_size, input_seq_len, embedding_dim)
        """</span>
        <span class="c1"># START CODE HERE
</span>        <span class="c1"># calculate self-attention using mha(~1 line)
</span>        <span class="c1">#-&gt; To compute self-attention Q, V and K should be the same (x)
</span>        <span class="c1">#ztd, namely it should be different q, v and k, but it seems merged with  EmbeddingParamtersMatrix*(Embedding matrix *X)
</span>        <span class="n">self_attn_output</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">mha</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span> <span class="c1"># Self attention (batch_size, input_seq_len, embedding_dim)
</span>        
        <span class="c1"># apply dropout layer to the self-attention output (~1 line)
</span>        <span class="n">self_attn_output</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">dropout1</span><span class="p">(</span><span class="n">self_attn_output</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>
        
        <span class="c1"># apply layer normalization on sum of the input and the attention output to get the  
</span>        <span class="c1"># output of the multi-head attention layer (~1 line)
</span>        <span class="n">mult_attn_out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">layernorm1</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="n">self_attn_output</span><span class="p">)</span>  <span class="c1"># (batch_size, input_seq_len, embedding_dim)
</span>
        <span class="c1"># pass the output of the multi-head attention layer through a ffn (~1 line)
</span>        <span class="n">ffn_output</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">ffn</span><span class="p">(</span><span class="n">mult_attn_out</span><span class="p">)</span>  <span class="c1"># (batch_size, input_seq_len, embedding_dim)
</span>        
        <span class="c1"># apply dropout layer to ffn output (~1 line)
</span>        <span class="n">ffn_output</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">dropout2</span><span class="p">(</span><span class="n">ffn_output</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>
        
        <span class="c1"># apply layer normalization on sum of the output from multi-head attention and ffn output to get the
</span>        <span class="c1"># output of the encoder layer (~1 line)
</span>        <span class="n">encoder_layer_out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">layernorm2</span><span class="p">(</span><span class="n">ffn_output</span> <span class="o">+</span> <span class="n">mult_attn_out</span><span class="p">)</span>  <span class="c1"># (batch_size, input_seq_len, embedding_dim)
</span>        <span class="c1"># END CODE HERE
</span>        
        <span class="k">return</span> <span class="n">encoder_layer_out</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># UNIT TEST
</span><span class="n">ownMultiHead</span><span class="o">=</span><span class="bp">True</span>
<span class="k">def</span> <span class="nf">EncoderLayer_test</span><span class="p">(</span><span class="n">target</span><span class="p">):</span>
    <span class="n">q</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]]).</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">encoder_layer1</span> <span class="o">=</span> <span class="n">EncoderLayer</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>
    <span class="n">tf</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">encoded</span> <span class="o">=</span> <span class="n">encoder_layer1</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="bp">True</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]))</span>
    
    <span class="k">assert</span> <span class="n">tf</span><span class="p">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">encoded</span><span class="p">),</span> <span class="s">"Wrong type. Output must be a tensor"</span>
    <span class="k">assert</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">shape</span><span class="p">(</span><span class="n">encoded</span><span class="p">).</span><span class="n">numpy</span><span class="p">())</span> <span class="o">==</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">q</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">q</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]),</span> <span class="sa">f</span><span class="s">"Wrong shape. We expected ((1, </span><span class="si">{</span><span class="n">q</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s">, </span><span class="si">{</span><span class="n">q</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="si">}</span><span class="s">))"</span>
    <span class="k">print</span><span class="p">(</span><span class="n">encoded</span><span class="p">.</span><span class="n">numpy</span><span class="p">())</span>
    <span class="k">assert</span> <span class="n">np</span><span class="p">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">encoded</span><span class="p">.</span><span class="n">numpy</span><span class="p">(),</span> 
                       <span class="p">[[</span><span class="o">-</span><span class="mf">0.5214877</span> <span class="p">,</span> <span class="o">-</span><span class="mf">1.001476</span>  <span class="p">,</span> <span class="o">-</span><span class="mf">0.12321664</span><span class="p">,</span>  <span class="mf">1.6461804</span> <span class="p">],</span>
                       <span class="p">[</span><span class="o">-</span><span class="mf">1.3114998</span> <span class="p">,</span>  <span class="mf">1.2167752</span> <span class="p">,</span> <span class="o">-</span><span class="mf">0.5830886</span> <span class="p">,</span>  <span class="mf">0.6778133</span> <span class="p">],</span>
                       <span class="p">[</span> <span class="mf">0.25485858</span><span class="p">,</span>  <span class="mf">0.3776546</span> <span class="p">,</span> <span class="o">-</span><span class="mf">1.6564771</span> <span class="p">,</span>  <span class="mf">1.023964</span>  <span class="p">]],),</span> <span class="s">"Wrong values"</span>
    
    <span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\033</span><span class="s">[92mAll tests passed"</span><span class="p">)</span>
    

<span class="n">EncoderLayer_test</span><span class="p">(</span><span class="n">EncoderLayer</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[[[-0.12410855 -1.4025799   0.1106668   1.4160216 ]
  [-1.4312509  -0.02727069  0.06325354  1.3952682 ]
  [-0.0983822  -0.7909938  -0.7737439   1.6631199 ]]]



---------------------------------------------------------------------------

AssertionError                            Traceback (most recent call last)

/var/tmp/ipykernel_27065/4238340319.py in &lt;module&gt;
     18 
     19 
---&gt; 20 EncoderLayer_test(EncoderLayer)


/var/tmp/ipykernel_27065/4238340319.py in EncoderLayer_test(target)
     13                        [[-0.5214877 , -1.001476  , -0.12321664,  1.6461804 ],
     14                        [-1.3114998 ,  1.2167752 , -0.5830886 ,  0.6778133 ],
---&gt; 15                        [ 0.25485858,  0.3776546 , -1.6564771 ,  1.023964  ]],), "Wrong values"
     16 
     17     print("\033[92mAll tests passed")


AssertionError: Wrong values
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sample_encoder_layer</span> <span class="o">=</span> <span class="n">EncoderLayer</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">2048</span><span class="p">)</span> <span class="c1">#embedding_dim, num_heads, fully_connected_dim
</span><span class="n">sample_encoder_layer_output</span> <span class="o">=</span> <span class="n">sample_encoder_layer</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">64</span><span class="p">,</span> <span class="mi">43</span><span class="p">,</span> <span class="mi">512</span><span class="p">)),</span> <span class="bp">False</span><span class="p">,</span> <span class="bp">None</span><span class="p">)</span> <span class="c1">#(batch_size, input_seq_len, embedding_dim)
</span>
<span class="n">sample_encoder_layer_output</span><span class="p">.</span><span class="n">shape</span>  <span class="c1"># (batch_size, input_seq_len, d_model)
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>TensorShape([64, 43, 512])
</code></pre></div></div>

<p>不太明白这个矩阵检查的根据是什么， ingore this error firstly</p>

<p>assert np.allclose(encoded.numpy(), 
                       [[-0.5214877 , -1.001476  , -0.12321664,  1.6461804 ],
                       [-1.3114998 ,  1.2167752 , -0.5830886 ,  0.6778133 ],
                       [ 0.25485858,  0.3776546 , -1.6564771 ,  1.023964  ]],), “Wrong values”</p>

<p><a name="4-2"></a></p>
<h3 id="42---full-encoder">4.2 - Full Encoder</h3>

<p>Awesome job! You have now successfully implemented positional encoding, self-attention, and an encoder layer - give yourself a pat on the back. Now you’re ready to build the full Transformer Encoder (Figure 2b), where you will embedd your input and add the positional encodings you calculated. You will then feed your encoded embeddings to a stack of Encoder layers.</p>

<center><img src="/assets//assets/2023-12-03-Transformer-learning-C5W4A1SubclassV1_files/encoder.png" alt="Encoder" width="330" /></center>
<caption><center><font color="purple">Figure 2b: Transformer Encoder</font></center></caption>

<p><a name="ex-5"></a></p>
<h3 id="exercise-5---encoder">Exercise 5 - Encoder</h3>

<p>Complete the <code class="language-plaintext highlighter-rouge">Encoder()</code> function using the <code class="language-plaintext highlighter-rouge">call()</code> method to embed your input, add positional encoding, and implement multiple encoder layers</p>

<p>In this exercise, you will initialize your Encoder with an Embedding layer, positional encoding, and multiple EncoderLayers. Your <code class="language-plaintext highlighter-rouge">call()</code> method will perform the following steps:</p>
<ol>
  <li>Pass your input through the Embedding layer.</li>
  <li>Scale your embedding by multiplying it by the square root of your embedding dimension. Remember to cast the embedding dimension to data type <code class="language-plaintext highlighter-rouge">tf.float32</code> before computing the square root.</li>
</ol>

<p>** some dicussion about this scal square root of your embedding dimension **
    This is specified in the original Transformer paper, at the end of section 3.4:
    <img src="/assets/2023-12-03-Transformer-learning-C5W4A1SubclassV1_files/7612d8b6-3931-45a4-901e-5765642e5458.png" alt="image.png" /><br />
    <font color="red">Transcription：
    **3.4 Embeddings and Softmax**
    Similarly to other sequence transduction models, we use learned embeddings to convert the input tokens and output tokens to vectors of dimension 𝑑model. We also use the usual learned linear transformation and softmax function to convert the decoder output to predicted next-token probabilities. In our model, we share the same weight matrix between the two embedding layers and the pre-softmax linear transformation, similar to [24]. In the embedding layers, we multiply those weights by $\sqrt{𝑑_model}$</font></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>This aspect is not justified by the authors, either on the paper or anywhere else. It was specifically asked as an issue in the original implementation by Google with no response.      
    
Other implementations of the Transformer have also wondered if this was actually needed (see this, this and this).   
Some hypothesithed arguments (source) are:   
    
    It is for the sharing weight between the decoder embedding and the decoder pre-softmax linear weights.  
    It is not actually needed.  
    It is to make the positional encoding relatively smaller. This means the original meaning in the embedding vector won’t be lost when we add them together.  
    For reference, there are other StackExchange questions discussing this (see this and this).
Thank-you!! I'd also missed that multiply in my (fairseq transformer) code study, and it helps clear up a mystery that I'd noted: the (sinusoidal, non-learned) **positional embeddings are initialized with a range of -1.0 to +1.0, but the word-embeddings are initialized with a mean of 0.0 and s.d. of embedding_dim ** -0.5 (0.044 for 512, 0.03125 for 1024).**

So, on the face of it, the positional embeddings would overwhelm any signal coming from the word embeddings.

But now I can see word embeddings are scaled by math.sqrt(embed_dim) (22.6 for 512, 32 for 1024), it makes sense again.
Following the links in the other answer, it seems it is done this way &lt;font color=red&gt;**because the same embeddings can be used in other parts of the transformer model**, and that has decided the initialization values.&lt;\font&gt;
</code></pre></div></div>

<ol>
  <li>Add the position encoding: self.pos_encoding <code class="language-plaintext highlighter-rouge">[:, :seq_len, :]</code> to your embedding.</li>
  <li>
    <p>Pass the encoded embedding through a dropout layer, remembering to use the <code class="language-plaintext highlighter-rouge">training</code> parameter to set the model training mode.</p>

    <p>https://discuss.pytorch.org/t/why-use-dropout-in-positional-encoding-layer/159923/6    <br />
Dropout is a type of regularization. The final embedding for each token that you use (for the transformer) is a sum of positional and standard embeddings and then they apply dropout to that sum. So dropout is applied to the sum of the standard embedding and the positional embedding, not just the (constant) positional embedding. This sum is then an embedding, a bunch of parameters, and dropout is used to regularize as is usual. 
usually the “embedding” of a word is the embedding that’s used for that token. In this case, <font color="red">**the embedding is the parametric embedding + the constant positional encoding**</font>. When you apply dropout to a neuron, you kill the entire neuron. So if you have a sequence of length 10 and each token has 512 dimensional vectors, you kill on average 60% of the neurons in the 10 by 512 matrix that represents the data. If you only did this to the parametric embeddings and not the positional ones, you would not kill a neuron, you’d leave in its positional information, so it’s not really dropout.</p>
  </li>
  <li>Pass the output of the dropout layer through the stack of encoding layers using a for loop.</li>
</ol>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="mi">1024</span><span class="o">**</span><span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0.03125
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="c1"># UNQ_C5 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)
# GRADED FUNCTION
</span><span class="k">class</span> <span class="nc">Encoder</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Layer</span><span class="p">):</span>
    <span class="s">"""
    The entire Encoder starts by passing the input to an embedding layer 
    and using positional encoding to then pass the output through a stack of
    encoder Layers
        
    """</span>   
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">fully_connected_dim</span><span class="p">,</span> <span class="n">input_vocab_size</span><span class="p">,</span>
               <span class="n">maximum_position_encoding</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">layernorm_eps</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Encoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">embedding_dim</span> <span class="o">=</span> <span class="n">embedding_dim</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">num_layers</span> <span class="o">=</span> <span class="n">num_layers</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">Embedding</span><span class="p">(</span><span class="n">input_vocab_size</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">embedding_dim</span><span class="p">)</span> <span class="c1">#tensorflow Embedding function generate embedding matrix
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">pos_encoding</span> <span class="o">=</span> <span class="n">positional_encoding</span><span class="p">(</span><span class="n">maximum_position_encoding</span><span class="p">,</span>  <span class="c1">#generate the postion encoding matrix
</span>                                                <span class="bp">self</span><span class="p">.</span><span class="n">embedding_dim</span><span class="p">)</span>

        <span class="c1">#init EncoderLayer 
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">enc_layers</span> <span class="o">=</span> <span class="p">[</span><span class="n">EncoderLayer</span><span class="p">(</span><span class="n">embedding_dim</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">embedding_dim</span><span class="p">,</span>
                                        <span class="n">num_heads</span><span class="o">=</span><span class="n">num_heads</span><span class="p">,</span>
                                        <span class="n">fully_connected_dim</span><span class="o">=</span><span class="n">fully_connected_dim</span><span class="p">,</span>
                                        <span class="n">dropout_rate</span><span class="o">=</span><span class="n">dropout_rate</span><span class="p">,</span>
                                        <span class="n">layernorm_eps</span><span class="o">=</span><span class="n">layernorm_eps</span><span class="p">)</span> 
                           <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">num_layers</span><span class="p">)]</span>
    
        <span class="bp">self</span><span class="p">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_rate</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="p">,</span> <span class="n">mask</span><span class="p">):</span>
        <span class="s">"""
        Forward pass for the Encoder
        
        Arguments:
            x -- Tensor of shape (batch_size, input_seq_len)
            training -- Boolean, set to true to activate
                        the training mode for dropout layers
            mask -- Boolean mask to ensure that the padding is not 
                    treated as part of the input
        Returns:
            out2 -- Tensor of shape (batch_size, input_seq_len, embedding_dim)
        """</span>

        <span class="n">seq_len</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
        
        <span class="c1"># START CODE HERE
</span>        <span class="c1"># Pass input through the Embedding layer
</span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># (batch_size, input_seq_len, embedding_dim)
</span>        <span class="c1"># Scale embedding by multiplying it by the square root of the embedding dimension
</span>        <span class="n">x</span> <span class="o">*=</span> <span class="n">tf</span><span class="p">.</span><span class="n">math</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">cast</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">embedding_dim</span><span class="p">,</span><span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">))</span>
        <span class="c1"># Add the position encoding to embedding
</span>        <span class="n">x</span> <span class="o">+=</span> <span class="bp">self</span><span class="p">.</span><span class="n">pos_encoding</span><span class="p">[:,</span> <span class="p">:</span><span class="n">seq_len</span><span class="p">,</span> <span class="p">:]</span>
        <span class="c1"># Pass the encoded embedding through a dropout layer
</span>        <span class="c1"># why we first have one dropout layer ???
</span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>
        <span class="c1"># Pass the output through the stack of encoding layers 
</span>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">num_layers</span><span class="p">):</span>
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">enc_layers</span><span class="p">[</span><span class="n">i</span><span class="p">](</span><span class="n">x</span><span class="p">,</span><span class="n">training</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>
        <span class="c1"># END CODE HERE
</span>        <span class="c1">#Embedding layer also include FFN (feed forward network) +  dropout layer + normalize layer
</span>        <span class="c1">#the output is (batch_size, input_seq_len, embedding_dim) same as input
</span>
        <span class="k">return</span> <span class="n">x</span>  <span class="c1"># (batch_size, input_seq_len, embedding_dim)
</span></code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># UNIT TEST
</span><span class="k">def</span> <span class="nf">Encoder_test</span><span class="p">(</span><span class="n">target</span><span class="p">):</span>
    <span class="n">tf</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
    
    <span class="n">embedding_dim</span><span class="o">=</span><span class="mi">4</span>
    
    <span class="n">encoderq</span> <span class="o">=</span> <span class="n">target</span><span class="p">(</span><span class="n">num_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                      <span class="n">embedding_dim</span><span class="o">=</span><span class="n">embedding_dim</span><span class="p">,</span>
                      <span class="n">num_heads</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                      <span class="n">fully_connected_dim</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
                      <span class="n">input_vocab_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
                      <span class="n">maximum_position_encoding</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
    
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
    
    <span class="n">encoderq_output</span> <span class="o">=</span> <span class="n">encoderq</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">True</span><span class="p">,</span> <span class="bp">None</span><span class="p">)</span>
    
    <span class="k">assert</span> <span class="n">tf</span><span class="p">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">encoderq_output</span><span class="p">),</span> <span class="s">"Wrong type. Output must be a tensor"</span>
    <span class="k">assert</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">shape</span><span class="p">(</span><span class="n">encoderq_output</span><span class="p">).</span><span class="n">numpy</span><span class="p">())</span> <span class="o">==</span> <span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">embedding_dim</span><span class="p">),</span> <span class="sa">f</span><span class="s">"Wrong shape. We expected (</span><span class="si">{</span><span class="n">eshape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s">, </span><span class="si">{</span><span class="n">eshape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s">, </span><span class="si">{</span><span class="n">embedding_dim</span><span class="si">}</span><span class="s">)"</span>
    <span class="k">assert</span> <span class="n">np</span><span class="p">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">encoderq_output</span><span class="p">.</span><span class="n">numpy</span><span class="p">(),</span> 
                       <span class="p">[[[</span><span class="o">-</span><span class="mf">0.40172306</span><span class="p">,</span>  <span class="mf">0.11519244</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.2322885</span><span class="p">,</span>   <span class="mf">1.5188192</span> <span class="p">],</span>
                         <span class="p">[</span> <span class="mf">0.4017268</span><span class="p">,</span>   <span class="mf">0.33922842</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.6836855</span><span class="p">,</span>   <span class="mf">0.9427304</span> <span class="p">],</span>
                         <span class="p">[</span> <span class="mf">0.4685002</span><span class="p">,</span>  <span class="o">-</span><span class="mf">1.6252842</span><span class="p">,</span>   <span class="mf">0.09368491</span><span class="p">,</span>  <span class="mf">1.063099</span>  <span class="p">]],</span>
                        <span class="p">[[</span><span class="o">-</span><span class="mf">0.3489219</span><span class="p">,</span>   <span class="mf">0.31335592</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.3568854</span><span class="p">,</span>   <span class="mf">1.3924513</span> <span class="p">],</span>
                         <span class="p">[</span><span class="o">-</span><span class="mf">0.08761203</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1680029</span><span class="p">,</span>  <span class="o">-</span><span class="mf">1.2742313</span><span class="p">,</span>   <span class="mf">1.5298463</span> <span class="p">],</span>
                         <span class="p">[</span> <span class="mf">0.2627198</span><span class="p">,</span>  <span class="o">-</span><span class="mf">1.6140151</span><span class="p">,</span>   <span class="mf">0.2212624</span> <span class="p">,</span>  <span class="mf">1.130033</span>  <span class="p">]]]),</span> <span class="s">"Wrong values"</span>
    
    <span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\033</span><span class="s">[92mAll tests passed"</span><span class="p">)</span>
    
<span class="n">Encoder_test</span><span class="p">(</span><span class="n">Encoder</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>---------------------------------------------------------------------------

AssertionError                            Traceback (most recent call last)

/var/tmp/ipykernel_27065/2836601725.py in &lt;module&gt;
     28     print("\033[92mAll tests passed")
     29 
---&gt; 30 Encoder_test(Encoder)


/var/tmp/ipykernel_27065/2836601725.py in Encoder_test(target)
     24                         [[-0.3489219,   0.31335592, -1.3568854,   1.3924513 ],
     25                          [-0.08761203, -0.1680029,  -1.2742313,   1.5298463 ],
---&gt; 26                          [ 0.2627198,  -1.6140151,   0.2212624 ,  1.130033  ]]]), "Wrong values"
     27 
     28     print("\033[92mAll tests passed")


AssertionError: Wrong values
</code></pre></div></div>

<p><a name="5"></a></p>
<h2 id="5---decoder">5 - Decoder</h2>

<p>The Decoder layer takes the K and V matrices generated by the Encoder and in computes the second multi-head attention layer with the Q matrix from the output (Figure 3a).</p>

<center><img src="/assets//assets/2023-12-03-Transformer-learning-C5W4A1SubclassV1_files/decoder_layer.png" alt="Encoder" width="250" class="centerImage" /></center>
<caption><center><font color="purple">Figure 3a: Transformer Decoder layer</font></center></caption>

<p><a name="5-1"></a></p>
<h3 id="51---decoder-layer">5.1 - Decoder Layer</h3>
<p>Again, you’ll pair multi-head attention with a feed forward neural network, but this time you’ll implement two multi-head attention layers. You will also use residual connections and layer normalization to help speed up training (Figure 3a).</p>

<p><a name="ex-6"></a></p>
<h3 id="exercise-6---decoderlayer-include-ffndropoutnormlize-layer">Exercise 6 - DecoderLayer (include FFN+dropout+normlize layer)</h3>

<p>Implement <code class="language-plaintext highlighter-rouge">DecoderLayer()</code> using the <code class="language-plaintext highlighter-rouge">call()</code> method</p>

<ol>
  <li>Block 1 is a multi-head attention layer with a residual connection, dropout layer, and look-ahead mask.</li>
  <li>Block 2 will take into account the output of the Encoder, so the multi-head attention layer will receive K and V from the encoder, and Q from the Block 1. You will then apply a dropout layer, layer normalization and a residual connection, just like you’ve done before.</li>
  <li>Finally, Block 3 is a feed forward neural network with dropout and normalization layers and a residual connection.</li>
</ol>

<p><strong>Additional Hints:</strong></p>
<ul>
  <li>The first two blocks are fairly similar to the EncoderLayer except you will return <code class="language-plaintext highlighter-rouge">attention_scores</code> when computing self-attention</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># UNQ_C6 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)
# GRADED FUNCTION DecoderLayer
</span><span class="k">class</span> <span class="nc">DecoderLayer</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Layer</span><span class="p">):</span>
    <span class="s">"""
    The decoder layer is composed by two multi-head attention blocks, 
    one that takes the new input and uses self-attention, and the other 
    one that combines it with the output of the encoder, followed by a
    fully connected block. 
    """</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">fully_connected_dim</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">layernorm_eps</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">DecoderLayer</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>

        <span class="k">if</span> <span class="p">(</span><span class="n">ownMultiHead</span><span class="o">==</span><span class="bp">False</span><span class="p">):</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">mha1</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">MultiHeadAttention</span><span class="p">(</span><span class="n">num_heads</span><span class="o">=</span><span class="n">num_heads</span><span class="p">,</span>
                                          <span class="n">key_dim</span><span class="o">=</span><span class="n">embedding_dim</span><span class="p">)</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">mha2</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">MultiHeadAttention</span><span class="p">(</span><span class="n">num_heads</span><span class="o">=</span><span class="n">num_heads</span><span class="p">,</span>
                                          <span class="n">key_dim</span><span class="o">=</span><span class="n">embedding_dim</span><span class="p">)</span>            
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">mha1</span> <span class="o">=</span> <span class="n">MultiHeadAttention</span><span class="p">(</span><span class="n">embedding_dim</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">)</span> <span class="c1"># there are own wq1, wk1, wv1 for multihead 1
</span>            <span class="bp">self</span><span class="p">.</span><span class="n">mha2</span> <span class="o">=</span> <span class="n">MultiHeadAttention</span><span class="p">(</span><span class="n">embedding_dim</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">)</span> <span class="c1"># there are own wq2, wk2, wv2 for multihead 2
</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">ffn</span> <span class="o">=</span> <span class="n">FullyConnected</span><span class="p">(</span><span class="n">embedding_dim</span><span class="o">=</span><span class="n">embedding_dim</span><span class="p">,</span>
                                  <span class="n">fully_connected_dim</span><span class="o">=</span><span class="n">fully_connected_dim</span><span class="p">)</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">layernorm1</span> <span class="o">=</span> <span class="n">LayerNormalization</span><span class="p">(</span><span class="n">epsilon</span><span class="o">=</span><span class="n">layernorm_eps</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">layernorm2</span> <span class="o">=</span> <span class="n">LayerNormalization</span><span class="p">(</span><span class="n">epsilon</span><span class="o">=</span><span class="n">layernorm_eps</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">layernorm3</span> <span class="o">=</span> <span class="n">LayerNormalization</span><span class="p">(</span><span class="n">epsilon</span><span class="o">=</span><span class="n">layernorm_eps</span><span class="p">)</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">dropout1</span> <span class="o">=</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_rate</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">dropout2</span> <span class="o">=</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_rate</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">dropout3</span> <span class="o">=</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_rate</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">enc_output</span><span class="p">,</span> <span class="n">training</span><span class="p">,</span> <span class="n">look_ahead_mask</span><span class="p">,</span> <span class="n">padding_mask</span><span class="p">):</span>
        <span class="s">"""
        Forward pass for the Decoder Layer
        
        Arguments:
            x -- Tensor of shape (batch_size, target_seq_len, embedding_dim)
            enc_output --  Tensor of shape(batch_size, input_seq_len, embedding_dim)
            training -- Boolean, set to true to activate
                        the training mode for dropout layers
            look_ahead_mask -- Boolean mask for the target_input
            padding_mask -- Boolean mask for the second multihead attention layer
        Returns:
            out3 -- Tensor of shape (batch_size, target_seq_len, embedding_dim)
            attn_weights_block1 -- Tensor of shape(batch_size, num_heads, target_seq_len, input_seq_len)
            attn_weights_block2 -- Tensor of shape(batch_size, num_heads, target_seq_len, input_seq_len)
        """</span>
        
        <span class="c1"># START CODE HERE
</span>        <span class="c1"># enc_output.shape == (batch_size, input_seq_len, embedding_dim)
</span>        
        <span class="c1"># BLOCK 1
</span>        <span class="c1"># calculate self-attention and return attention scores as attn_weights_block1 (~1 line)
</span>        <span class="c1"># decode first mh use x as input + look_ahead_mask
</span>        <span class="n">attn1</span><span class="p">,</span> <span class="n">attn_weights_block1</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">mha1</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span><span class="n">look_ahead_mask</span><span class="p">,</span> <span class="n">return_attention_scores</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>  <span class="c1"># (batch_size, target_seq_len, d_model)
</span>        
        <span class="c1"># apply dropout layer on the attention output (~1 line)
</span>        <span class="n">attn1</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">dropout1</span><span class="p">(</span><span class="n">attn1</span><span class="p">,</span> <span class="n">training</span> <span class="o">=</span> <span class="n">training</span><span class="p">)</span>
        
        <span class="c1"># apply layer normalization to the sum of the attention output and the input (~1 line)
</span>        <span class="n">out1</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">layernorm1</span><span class="p">(</span><span class="n">attn1</span> <span class="o">+</span> <span class="n">x</span><span class="p">)</span>

        <span class="c1"># BLOCK 2
</span>        <span class="c1"># calculate self-attention using the Q from the first block and K and V from the encoder output.  so , K V is same from the output??
</span>        <span class="c1"># MultiHeadAttention's call takes input (Query, Value, Key, attention_mask, return_attention_scores, training)
</span>        <span class="c1"># Return attention scores as attn_weights_block2 (~1 line)
</span>        <span class="n">attn2</span><span class="p">,</span> <span class="n">attn_weights_block2</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">mha2</span><span class="p">(</span> <span class="n">out1</span><span class="p">,</span><span class="n">enc_output</span><span class="p">,</span> <span class="n">enc_output</span><span class="p">,</span> <span class="n">padding_mask</span><span class="p">,</span> <span class="n">return_attention_scores</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>  <span class="c1"># (batch_size, target_seq_len, d_model)
</span>        
        <span class="c1"># apply dropout layer on the attention output (~1 line)
</span>        <span class="n">attn2</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">dropout2</span><span class="p">(</span><span class="n">attn2</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>
        
        <span class="c1"># apply layer normalization to the sum of the attention output and the output of the first block (~1 line)
</span>        <span class="n">out2</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">layernorm2</span><span class="p">(</span><span class="n">attn2</span> <span class="o">+</span> <span class="n">out1</span><span class="p">)</span>  <span class="c1"># (batch_size, target_seq_len, embedding_dim)
</span>        
        <span class="c1">#BLOCK 3
</span>        <span class="c1"># pass the output of the second block through a ffn
</span>        <span class="n">ffn_output</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">ffn</span><span class="p">(</span><span class="n">out2</span><span class="p">)</span> <span class="c1"># (batch_size, target_seq_len, embedding_dim)
</span>        
        <span class="c1"># apply a dropout layer to the ffn output
</span>        <span class="n">ffn_output</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">dropout3</span><span class="p">(</span><span class="n">ffn_output</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>
        
        <span class="c1"># apply layer normalization to the sum of the ffn output and the output of the second block
</span>        <span class="n">out3</span> <span class="o">=</span>  <span class="bp">self</span><span class="p">.</span><span class="n">layernorm3</span><span class="p">(</span><span class="n">ffn_output</span> <span class="o">+</span> <span class="n">out2</span><span class="p">)</span> <span class="c1"># (batch_size, target_seq_len, embedding_dim)
</span>        <span class="c1"># END CODE HERE
</span>
        <span class="k">return</span> <span class="n">out3</span><span class="p">,</span> <span class="n">attn_weights_block1</span><span class="p">,</span> <span class="n">attn_weights_block2</span>
    
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># UNIT TEST
</span><span class="n">ownMultiHead</span><span class="o">=</span><span class="bp">True</span>
<span class="k">def</span> <span class="nf">DecoderLayer_test</span><span class="p">(</span><span class="n">target</span><span class="p">):</span>
    
    <span class="n">num_heads</span><span class="o">=</span><span class="mi">2</span>  <span class="c1"># change to smaller number than embedding_dim
</span>    <span class="n">tf</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
    
    <span class="n">decoderLayerq</span> <span class="o">=</span> <span class="n">target</span><span class="p">(</span>
        <span class="n">embedding_dim</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> 
        <span class="n">num_heads</span><span class="o">=</span><span class="n">num_heads</span><span class="p">,</span>
        <span class="n">fully_connected_dim</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> 
        <span class="n">dropout_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> 
        <span class="n">layernorm_eps</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">)</span>
    
    <span class="n">encoderq_output</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">constant</span><span class="p">([[[</span><span class="o">-</span><span class="mf">0.40172306</span><span class="p">,</span>  <span class="mf">0.11519244</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.2322885</span><span class="p">,</span>   <span class="mf">1.5188192</span> <span class="p">],</span>
                                   <span class="p">[</span> <span class="mf">0.4017268</span><span class="p">,</span>   <span class="mf">0.33922842</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.6836855</span><span class="p">,</span>   <span class="mf">0.9427304</span> <span class="p">],</span>
                                   <span class="p">[</span> <span class="mf">0.4685002</span><span class="p">,</span>  <span class="o">-</span><span class="mf">1.6252842</span><span class="p">,</span>   <span class="mf">0.09368491</span><span class="p">,</span>  <span class="mf">1.063099</span>  <span class="p">]]])</span>
    
    <span class="n">q</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]]).</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
    
    <span class="n">look_ahead_mask</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">constant</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
                       <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
                       <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]])</span>
    
    <span class="n">padding_mask</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="n">out</span><span class="p">,</span> <span class="n">attn_w_b1</span><span class="p">,</span> <span class="n">attn_w_b2</span> <span class="o">=</span> <span class="n">decoderLayerq</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">encoderq_output</span><span class="p">,</span> <span class="bp">True</span><span class="p">,</span> <span class="n">look_ahead_mask</span><span class="p">,</span> <span class="n">padding_mask</span><span class="p">)</span>
    
    <span class="k">assert</span> <span class="n">tf</span><span class="p">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">attn_w_b1</span><span class="p">),</span> <span class="s">"Wrong type for attn_w_b1. Output must be a tensor"</span>
    <span class="k">assert</span> <span class="n">tf</span><span class="p">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">attn_w_b2</span><span class="p">),</span> <span class="s">"Wrong type for attn_w_b2. Output must be a tensor"</span>
    <span class="k">assert</span> <span class="n">tf</span><span class="p">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">out</span><span class="p">),</span> <span class="s">"Wrong type for out. Output must be a tensor"</span>
    
    <span class="n">shape1</span> <span class="o">=</span> <span class="p">(</span><span class="n">q</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">q</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">q</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">assert</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">shape</span><span class="p">(</span><span class="n">attn_w_b1</span><span class="p">).</span><span class="n">numpy</span><span class="p">())</span> <span class="o">==</span> <span class="n">shape1</span><span class="p">,</span> <span class="sa">f</span><span class="s">"Wrong shape. We expected </span><span class="si">{</span><span class="n">shape1</span><span class="si">}</span><span class="s">"</span>
    <span class="k">assert</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">shape</span><span class="p">(</span><span class="n">attn_w_b2</span><span class="p">).</span><span class="n">numpy</span><span class="p">())</span> <span class="o">==</span> <span class="n">shape1</span><span class="p">,</span> <span class="sa">f</span><span class="s">"Wrong shape. We expected </span><span class="si">{</span><span class="n">shape1</span><span class="si">}</span><span class="s">"</span>
    <span class="k">assert</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">shape</span><span class="p">(</span><span class="n">out</span><span class="p">).</span><span class="n">numpy</span><span class="p">())</span> <span class="o">==</span> <span class="n">q</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="sa">f</span><span class="s">"Wrong shape. We expected </span><span class="si">{</span><span class="n">q</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="s">"</span>

    <span class="k">assert</span> <span class="n">np</span><span class="p">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">attn_w_b1</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.5271505</span><span class="p">,</span>  <span class="mf">0.47284946</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span> <span class="n">atol</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">),</span> <span class="s">"Wrong values in attn_w_b1. Check the call to self.mha1"</span>
    <span class="k">assert</span> <span class="n">np</span><span class="p">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">attn_w_b2</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.33365652</span><span class="p">,</span> <span class="mf">0.32598493</span><span class="p">,</span> <span class="mf">0.34035856</span><span class="p">]),</span>  <span class="s">"Wrong values in attn_w_b2. Check the call to self.mha2"</span>
    <span class="k">assert</span> <span class="n">np</span><span class="p">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.04726627</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.6235218</span><span class="p">,</span> <span class="mf">1.0327158</span><span class="p">,</span> <span class="mf">0.54353976</span><span class="p">]),</span> <span class="s">"Wrong values in out"</span>
    

    <span class="c1"># Now let's try a example with padding mask
</span>    <span class="n">padding_mask</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
    <span class="n">out</span><span class="p">,</span> <span class="n">attn_w_b1</span><span class="p">,</span> <span class="n">attn_w_b2</span> <span class="o">=</span> <span class="n">decoderLayerq</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">encoderq_output</span><span class="p">,</span> <span class="bp">True</span><span class="p">,</span> <span class="n">look_ahead_mask</span><span class="p">,</span> <span class="n">padding_mask</span><span class="p">)</span>

    <span class="k">assert</span> <span class="n">np</span><span class="p">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mf">0.34323323</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.4689083</span><span class="p">,</span> <span class="mf">1.1092525</span><span class="p">,</span> <span class="mf">0.7028891</span><span class="p">]),</span> <span class="s">"Wrong values in out when we mask the last word. Are you passing the padding_mask to the inner functions?"</span>

    <span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\033</span><span class="s">[92mAll tests passed"</span><span class="p">)</span>
    
<span class="n">DecoderLayer_test</span><span class="p">(</span><span class="n">DecoderLayer</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>---------------------------------------------------------------------------

AssertionError                            Traceback (most recent call last)

/var/tmp/ipykernel_27065/3323492748.py in &lt;module&gt;
     48     print("\033[92mAll tests passed")
     49 
---&gt; 50 DecoderLayer_test(DecoderLayer)


/var/tmp/ipykernel_27065/3323492748.py in DecoderLayer_test(target)
     35     assert tuple(tf.shape(out).numpy()) == q.shape, f"Wrong shape. We expected {q.shape}"
     36 
---&gt; 37     assert np.allclose(attn_w_b1[0, 0, 1], [0.5271505,  0.47284946, 0.], atol=1e-2), "Wrong values in attn_w_b1. Check the call to self.mha1"
     38     assert np.allclose(attn_w_b2[0, 0, 1], [0.33365652, 0.32598493, 0.34035856]),  "Wrong values in attn_w_b2. Check the call to self.mha2"
     39     assert np.allclose(out[0, 0], [0.04726627, -1.6235218, 1.0327158, 0.54353976]), "Wrong values in out"


AssertionError: Wrong values in attn_w_b1. Check the call to self.mha1
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sample_encoder_layer_output</span><span class="p">.</span><span class="n">shape</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>TensorShape([64, 43, 512])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sample_decoder_layer</span> <span class="o">=</span> <span class="n">DecoderLayer</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">2048</span><span class="p">)</span>
<span class="n">sample_decoder_layer_output</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">sample_decoder_layer</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">64</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">512</span><span class="p">)),</span> <span class="n">sample_encoder_layer_output</span><span class="p">,</span> 
    <span class="bp">False</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">)</span>

<span class="n">sample_decoder_layer_output</span><span class="p">.</span><span class="n">shape</span>  <span class="c1"># (batch_size, target_seq_len, d_model)
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>TensorShape([64, 50, 512])
</code></pre></div></div>

<p><a name="5-2"></a></p>
<h3 id="52---full-decoder">5.2 - Full Decoder</h3>
<p>You’re almost there! Time to use your Decoder layer to build a full Transformer Decoder (Figure 3b). You will embedd your output and add positional encodings. You will then feed your encoded embeddings to a stack of Decoder layers.</p>

<p><img src="/assets/2023-12-03-Transformer-learning-C5W4A1SubclassV1_files/4733f7c9-6d0c-4872-a73e-d0b4e937639d.png" alt="image.png" /></p>
<center><img src="/assets//assets/2023-12-03-Transformer-learning-C5W4A1SubclassV1_files/decoder.png" alt="Encoder" width="300" /></center>
<caption><center><font color="purple">Figure 3b: Transformer Decoder&lt;/b&gt;</font></center></caption>

<p><a name="ex-7"></a></p>
<h3 id="exercise-7---decoder">Exercise 7 - Decoder</h3>

<p>Implement <code class="language-plaintext highlighter-rouge">Decoder()</code> using the <code class="language-plaintext highlighter-rouge">call()</code> method to embed your output, add positional encoding, and implement multiple decoder layers</p>

<p>In this exercise, you will initialize your Decoder with an Embedding layer, positional encoding, and multiple DecoderLayers. Your <code class="language-plaintext highlighter-rouge">call()</code> method will perform the following steps:</p>
<ol>
  <li>Pass your generated output through the Embedding layer.</li>
  <li>Scale your embedding by multiplying it by the square root of your embedding dimension. Remember to cast the embedding dimension to data type <code class="language-plaintext highlighter-rouge">tf.float32</code> before computing the square root.</li>
  <li>Add the position encoding: self.pos_encoding <code class="language-plaintext highlighter-rouge">[:, :seq_len, :]</code> to your embedding.</li>
  <li>Pass the encoded embedding through a dropout layer, remembering to use the <code class="language-plaintext highlighter-rouge">training</code> parameter to set the model training mode.</li>
  <li>Pass the output of the dropout layer through the stack of Decoding layers using a for loop.</li>
</ol>

<p>解码器包括：</p>

<ul>
  <li>输出嵌入（Output Embedding）</li>
  <li>位置编码（Positional Encoding）</li>
  <li>N 个解码器层（decoder layers）
目标（target）经过一个嵌入后，该嵌入和位置编码相加。该加法结果是解码器层的输入。解码器的输出是最后的线性层的输入。</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># UNQ_C7 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)
# GRADED FUNCTION Decoder
</span><span class="k">class</span> <span class="nc">Decoder</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Layer</span><span class="p">):</span>
    <span class="s">"""
    The entire Encoder is starts by passing the target input to an embedding layer 
    and using positional encoding to then pass the output through a stack of
    decoder Layers
        
    """</span> 
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">fully_connected_dim</span><span class="p">,</span> <span class="n">target_vocab_size</span><span class="p">,</span>
               <span class="n">maximum_position_encoding</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">layernorm_eps</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Decoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">embedding_dim</span> <span class="o">=</span> <span class="n">embedding_dim</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">num_layers</span> <span class="o">=</span> <span class="n">num_layers</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">Embedding</span><span class="p">(</span><span class="n">target_vocab_size</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">embedding_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">pos_encoding</span> <span class="o">=</span> <span class="n">positional_encoding</span><span class="p">(</span><span class="n">maximum_position_encoding</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">embedding_dim</span><span class="p">)</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">dec_layers</span> <span class="o">=</span> <span class="p">[</span><span class="n">DecoderLayer</span><span class="p">(</span><span class="n">embedding_dim</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">embedding_dim</span><span class="p">,</span>
                                        <span class="n">num_heads</span><span class="o">=</span><span class="n">num_heads</span><span class="p">,</span>
                                        <span class="n">fully_connected_dim</span><span class="o">=</span><span class="n">fully_connected_dim</span><span class="p">,</span>
                                        <span class="n">dropout_rate</span><span class="o">=</span><span class="n">dropout_rate</span><span class="p">,</span>
                                        <span class="n">layernorm_eps</span><span class="o">=</span><span class="n">layernorm_eps</span><span class="p">)</span> 
                           <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">num_layers</span><span class="p">)]</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_rate</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">enc_output</span><span class="p">,</span> <span class="n">training</span><span class="p">,</span> 
           <span class="n">look_ahead_mask</span><span class="p">,</span> <span class="n">padding_mask</span><span class="p">):</span>
        <span class="s">"""
        Forward  pass for the Decoder
        
        Arguments:
            x -- Tensor of shape (batch_size, target_seq_len, embedding_dim)
            enc_output --  Tensor of shape(batch_size, input_seq_len, embedding_dim)
            training -- Boolean, set to true to activate
                        the training mode for dropout layers
            look_ahead_mask -- Boolean mask for the target_input
            padding_mask -- Boolean mask for the second multihead attention layer
        Returns:
            x -- Tensor of shape (batch_size, target_seq_len, embedding_dim)
            attention_weights - Dictionary of tensors containing all the attention weights
                                each of shape Tensor of shape (batch_size, num_heads, target_seq_len, input_seq_len)
        """</span>

        <span class="n">seq_len</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">attention_weights</span> <span class="o">=</span> <span class="p">{}</span>
        
        <span class="c1"># START CODE HERE
</span>        <span class="c1"># create word embeddings 
</span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># (batch_size, target_seq_len, embedding_dim)
</span>        
        <span class="c1"># scale embeddings by multiplying by the square root of their dimension
</span>        <span class="n">x</span> <span class="o">*=</span> <span class="n">tf</span><span class="p">.</span><span class="n">math</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">cast</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">embedding_dim</span><span class="p">,</span> <span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">))</span>
        
        <span class="c1"># calculate positional encodings and add to word embedding
</span>        <span class="n">x</span> <span class="o">+=</span> <span class="bp">self</span><span class="p">.</span><span class="n">pos_encoding</span><span class="p">[:,</span> <span class="p">:</span><span class="n">seq_len</span><span class="p">,</span> <span class="p">:]</span>
        
        <span class="c1"># apply a dropout layer to x
</span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>

        <span class="c1"># use a for loop to pass x through a stack of decoder layers and update attention_weights (~4 lines total)
</span>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">num_layers</span><span class="p">):</span>
            <span class="c1"># pass x and the encoder output through a stack of decoder layers and save the attention weights
</span>            <span class="c1"># of block 1 and 2 (~1 line)
</span>            <span class="c1">#the layer(i) mh2's output will be the layer(i+1)'s input x
</span>            <span class="n">x</span><span class="p">,</span> <span class="n">block1</span><span class="p">,</span> <span class="n">block2</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">dec_layers</span><span class="p">[</span><span class="n">i</span><span class="p">](</span><span class="n">x</span><span class="p">,</span> <span class="n">enc_output</span><span class="p">,</span> <span class="n">training</span><span class="p">,</span> <span class="n">look_ahead_mask</span><span class="p">,</span> <span class="n">padding_mask</span><span class="p">)</span>

            <span class="c1">#update/store attention_weights dictionary with the attention weights of block 1 and block 2
</span>            <span class="n">attention_weights</span><span class="p">[</span><span class="s">'decoder_layer{}_block1_self_att'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span> <span class="o">=</span> <span class="n">block1</span>
            <span class="n">attention_weights</span><span class="p">[</span><span class="s">'decoder_layer{}_block2_decenc_att'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span> <span class="o">=</span> <span class="n">block2</span>
        <span class="c1"># END CODE HERE
</span>        
        <span class="c1"># x.shape == (batch_size, target_seq_len, embedding_dim)
</span>        <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">attention_weights</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># UNIT TEST
</span><span class="k">def</span> <span class="nf">Decoder_test</span><span class="p">(</span><span class="n">target</span><span class="p">):</span>
    
    <span class="n">tf</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
        
    <span class="n">num_layers</span><span class="o">=</span><span class="mi">7</span>
    <span class="n">embedding_dim</span><span class="o">=</span><span class="mi">4</span> 
    <span class="n">num_heads</span><span class="o">=</span><span class="mi">2</span>
    <span class="n">fully_connected_dim</span><span class="o">=</span><span class="mi">8</span>
    <span class="n">target_vocab_size</span><span class="o">=</span><span class="mi">33</span>
    <span class="n">maximum_position_encoding</span><span class="o">=</span><span class="mi">6</span>
    
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>

    
    <span class="n">encoderq_output</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">constant</span><span class="p">([[[</span><span class="o">-</span><span class="mf">0.40172306</span><span class="p">,</span>  <span class="mf">0.11519244</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.2322885</span><span class="p">,</span>   <span class="mf">1.5188192</span> <span class="p">],</span>
                         <span class="p">[</span> <span class="mf">0.4017268</span><span class="p">,</span>   <span class="mf">0.33922842</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.6836855</span><span class="p">,</span>   <span class="mf">0.9427304</span> <span class="p">],</span>
                         <span class="p">[</span> <span class="mf">0.4685002</span><span class="p">,</span>  <span class="o">-</span><span class="mf">1.6252842</span><span class="p">,</span>   <span class="mf">0.09368491</span><span class="p">,</span>  <span class="mf">1.063099</span>  <span class="p">]],</span>
                        <span class="p">[[</span><span class="o">-</span><span class="mf">0.3489219</span><span class="p">,</span>   <span class="mf">0.31335592</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.3568854</span><span class="p">,</span>   <span class="mf">1.3924513</span> <span class="p">],</span>
                         <span class="p">[</span><span class="o">-</span><span class="mf">0.08761203</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1680029</span><span class="p">,</span>  <span class="o">-</span><span class="mf">1.2742313</span><span class="p">,</span>   <span class="mf">1.5298463</span> <span class="p">],</span>
                         <span class="p">[</span> <span class="mf">0.2627198</span><span class="p">,</span>  <span class="o">-</span><span class="mf">1.6140151</span><span class="p">,</span>   <span class="mf">0.2212624</span> <span class="p">,</span>  <span class="mf">1.130033</span>  <span class="p">]]])</span>
    
    <span class="n">look_ahead_mask</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">constant</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
                       <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
                       <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]])</span>
    
    <span class="n">decoderk</span> <span class="o">=</span> <span class="n">Decoder</span><span class="p">(</span><span class="n">num_layers</span><span class="p">,</span>
                    <span class="n">embedding_dim</span><span class="p">,</span> 
                    <span class="n">num_heads</span><span class="p">,</span> 
                    <span class="n">fully_connected_dim</span><span class="p">,</span>
                    <span class="n">target_vocab_size</span><span class="p">,</span>
                    <span class="n">maximum_position_encoding</span><span class="p">)</span>
    <span class="n">outd</span><span class="p">,</span> <span class="n">att_weights</span> <span class="o">=</span> <span class="n">decoderk</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">encoderq_output</span><span class="p">,</span> <span class="bp">False</span><span class="p">,</span> <span class="n">look_ahead_mask</span><span class="p">,</span> <span class="bp">None</span><span class="p">)</span>
    
    <span class="k">assert</span> <span class="n">tf</span><span class="p">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">outd</span><span class="p">),</span> <span class="s">"Wrong type for outd. It must be a dict"</span>
    <span class="k">assert</span> <span class="n">np</span><span class="p">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">shape</span><span class="p">(</span><span class="n">outd</span><span class="p">),</span> <span class="n">tf</span><span class="p">.</span><span class="n">shape</span><span class="p">(</span><span class="n">encoderq_output</span><span class="p">)),</span> <span class="sa">f</span><span class="s">"Wrong shape. We expected </span><span class="si">{</span> <span class="n">tf</span><span class="p">.</span><span class="n">shape</span><span class="p">(</span><span class="n">encoderq_output</span><span class="p">)</span><span class="si">}</span><span class="s">"</span>
    <span class="k">print</span><span class="p">(</span><span class="n">outd</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="k">assert</span> <span class="n">np</span><span class="p">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">outd</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mf">0.2715261</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5606001</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.861783</span><span class="p">,</span> <span class="mf">1.69390933</span><span class="p">]),</span> <span class="s">"Wrong values in outd"</span>
    
    <span class="n">keys</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">att_weights</span><span class="p">.</span><span class="n">keys</span><span class="p">())</span>
    <span class="k">assert</span> <span class="nb">type</span><span class="p">(</span><span class="n">att_weights</span><span class="p">)</span> <span class="o">==</span> <span class="nb">dict</span><span class="p">,</span> <span class="s">"Wrong type for att_weights[0]. Output must be a tensor"</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">keys</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">num_layers</span><span class="p">,</span> <span class="sa">f</span><span class="s">"Wrong length for attention weights. It must be 2 x num_layers = </span><span class="si">{</span><span class="mi">2</span><span class="o">*</span><span class="n">num_layers</span><span class="si">}</span><span class="s">"</span>
    <span class="k">assert</span> <span class="n">tf</span><span class="p">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">att_weights</span><span class="p">[</span><span class="n">keys</span><span class="p">[</span><span class="mi">0</span><span class="p">]]),</span> <span class="sa">f</span><span class="s">"Wrong type for att_weights[</span><span class="si">{</span><span class="n">keys</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s">]. Output must be a tensor"</span>
    <span class="n">shape1</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">assert</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">shape</span><span class="p">(</span><span class="n">att_weights</span><span class="p">[</span><span class="n">keys</span><span class="p">[</span><span class="mi">1</span><span class="p">]]).</span><span class="n">numpy</span><span class="p">())</span> <span class="o">==</span> <span class="n">shape1</span><span class="p">,</span> <span class="sa">f</span><span class="s">"Wrong shape. We expected </span><span class="si">{</span><span class="n">shape1</span><span class="si">}</span><span class="s">"</span> 
    <span class="k">assert</span> <span class="n">np</span><span class="p">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">att_weights</span><span class="p">[</span><span class="n">keys</span><span class="p">[</span><span class="mi">0</span><span class="p">]][</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.52145624</span><span class="p">,</span> <span class="mf">0.47854376</span><span class="p">,</span> <span class="mf">0.</span><span class="p">]),</span> <span class="sa">f</span><span class="s">"Wrong values in att_weights[</span><span class="si">{</span><span class="n">keys</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s">]"</span>
    
    <span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\033</span><span class="s">[92mAll tests passed"</span><span class="p">)</span>
    
<span class="n">Decoder_test</span><span class="p">(</span><span class="n">Decoder</span><span class="p">)</span>
</code></pre></div></div>

<p><a name="6"></a></p>
<h2 id="6---transformer">6 - Transformer</h2>

<p>Phew! This has been quite the assignment, and now you’ve made it to your last exercise of the Deep Learning Specialization. Congratulations! You’ve done all the hard work, now it’s time to put it all together.</p>

<center><img src="/assets//assets/2023-12-03-Transformer-learning-C5W4A1SubclassV1_files/transformer.png" alt="Transformer" width="550" /></center>
<caption><center><font color="purple">Figure 4: Transformer</font></center></caption>

<p>The flow of data through the Transformer Architecture is as follows:</p>
<ul>
  <li>First your input passes through an Encoder, which is just repeated Encoder layers that you implemented:
    <ul>
      <li>embedding and positional encoding of your input</li>
      <li>multi-head attention on your input</li>
      <li>feed forward neural network to help detect features</li>
    </ul>
  </li>
  <li>Then the predicted output passes through a Decoder, consisting of the decoder layers that you implemented:
    <ul>
      <li>embedding and positional encoding of the output</li>
      <li>multi-head attention on your generated output</li>
      <li>multi-head attention with the Q from the first multi-head attention layer and the K and V from the Encoder</li>
      <li><strong>the decode input:tar is the target stenece? —  the encodeing input’s shifted right???</strong></li>
      <li>a feed forward neural network to help detect features</li>
    </ul>
  </li>
  <li>Finally, after the Nth Decoder layer, two dense layers and a softmax are applied to generate prediction for the next output in your sequence.</li>
</ul>

<p><a name="ex-8"></a></p>
<h3 id="exercise-8---transformer">Exercise 8 - Transformer</h3>

<p>Implement <code class="language-plaintext highlighter-rouge">Transformer()</code> using the <code class="language-plaintext highlighter-rouge">call()</code> method</p>
<ol>
  <li>Pass the input through the Encoder with the appropiate mask.</li>
  <li>Pass the encoder output and the target through the Decoder with the appropiate mask.</li>
  <li>Apply a linear transformation and a softmax to get a prediction.</li>
</ol>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># UNQ_C8 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)
# GRADED FUNCTION Transformer
# max_positional_encoding_target is used for decoder maximum_position_encoding
# max_positional_encoding_input is used for encoder maximum_position_encoding
# tar as the decoder X
</span><span class="k">class</span> <span class="nc">Transformer</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">Model</span><span class="p">):</span>
    <span class="s">"""
    Complete transformer with an Encoder and a Decoder
    """</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">fully_connected_dim</span><span class="p">,</span> <span class="n">input_vocab_size</span><span class="p">,</span> 
               <span class="n">target_vocab_size</span><span class="p">,</span> <span class="n">max_positional_encoding_input</span><span class="p">,</span>
               <span class="n">max_positional_encoding_target</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">layernorm_eps</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Transformer</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">Encoder</span><span class="p">(</span><span class="n">num_layers</span><span class="o">=</span><span class="n">num_layers</span><span class="p">,</span>
                               <span class="n">embedding_dim</span><span class="o">=</span><span class="n">embedding_dim</span><span class="p">,</span>
                               <span class="n">num_heads</span><span class="o">=</span><span class="n">num_heads</span><span class="p">,</span>
                               <span class="n">fully_connected_dim</span><span class="o">=</span><span class="n">fully_connected_dim</span><span class="p">,</span>
                               <span class="n">input_vocab_size</span><span class="o">=</span><span class="n">input_vocab_size</span><span class="p">,</span>
                               <span class="n">maximum_position_encoding</span><span class="o">=</span><span class="n">max_positional_encoding_input</span><span class="p">,</span>
                               <span class="n">dropout_rate</span><span class="o">=</span><span class="n">dropout_rate</span><span class="p">,</span>
                               <span class="n">layernorm_eps</span><span class="o">=</span><span class="n">layernorm_eps</span><span class="p">)</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">Decoder</span><span class="p">(</span><span class="n">num_layers</span><span class="o">=</span><span class="n">num_layers</span><span class="p">,</span> 
                               <span class="n">embedding_dim</span><span class="o">=</span><span class="n">embedding_dim</span><span class="p">,</span>
                               <span class="n">num_heads</span><span class="o">=</span><span class="n">num_heads</span><span class="p">,</span>
                               <span class="n">fully_connected_dim</span><span class="o">=</span><span class="n">fully_connected_dim</span><span class="p">,</span>
                               <span class="n">target_vocab_size</span><span class="o">=</span><span class="n">target_vocab_size</span><span class="p">,</span> 
                               <span class="n">maximum_position_encoding</span><span class="o">=</span><span class="n">max_positional_encoding_target</span><span class="p">,</span>
                               <span class="n">dropout_rate</span><span class="o">=</span><span class="n">dropout_rate</span><span class="p">,</span>
                               <span class="n">layernorm_eps</span><span class="o">=</span><span class="n">layernorm_eps</span><span class="p">)</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">final_layer</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">target_vocab_size</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'softmax'</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inp</span><span class="p">,</span> <span class="n">tar</span><span class="p">,</span> <span class="n">training</span><span class="p">,</span> <span class="n">enc_padding_mask</span><span class="p">,</span> <span class="n">look_ahead_mask</span><span class="p">,</span> <span class="n">dec_padding_mask</span><span class="p">):</span>
        <span class="s">"""
        Forward pass for the entire Transformer
        Arguments:
            inp -- Tensor of shape (batch_size, input_seq_len, fully_connected_dim)
            tar -- Tensor of shape (batch_size, target_seq_len, fully_connected_dim)
            training -- Boolean, set to true to activate
                        the training mode for dropout layers
            enc_padding_mask -- Boolean mask to ensure that the padding is not 
                    treated as part of the input
            look_ahead_mask -- Boolean mask for the target_input
            padding_mask -- Boolean mask for the second multihead attention layer
        Returns:
            final_output -- Describe me
            attention_weights - Dictionary of tensors containing all the attention weights for the decoder
                                each of shape Tensor of shape (batch_size, num_heads, target_seq_len, input_seq_len)
        
        """</span>
        <span class="c1"># START CODE HERE
</span>        <span class="c1"># call self.encoder with the appropriate arguments to get the encoder output
</span>        <span class="n">enc_output</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span><span class="n">training</span><span class="p">,</span><span class="n">enc_padding_mask</span><span class="p">)</span> <span class="c1"># (batch_size, inp_seq_len, fully_connected_dim)
</span>        
        <span class="c1"># call self.decoder with the appropriate arguments to get the decoder output
</span>        <span class="c1"># dec_output.shape == (batch_size, tar_seq_len, fully_connected_dim)
</span>        <span class="c1"># so the tar is the target stenece? ---  the encodeing input's shifted right???
</span>        <span class="n">dec_output</span><span class="p">,</span> <span class="n">attention_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">tar</span><span class="p">,</span> <span class="n">enc_output</span><span class="p">,</span> <span class="n">training</span><span class="p">,</span> <span class="n">look_ahead_mask</span><span class="p">,</span> <span class="n">dec_padding_mask</span><span class="p">)</span>
        
        <span class="c1"># pass decoder output through a linear layer and softmax (~2 lines)
</span>        <span class="n">final_output</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">final_layer</span><span class="p">(</span><span class="n">dec_output</span><span class="p">)</span>  <span class="c1"># (batch_size, tar_seq_len, target_vocab_size)
</span>        <span class="c1"># START CODE HERE
</span>
        <span class="k">return</span> <span class="n">final_output</span><span class="p">,</span> <span class="n">attention_weights</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># UNIT TEST
</span><span class="n">ownMultiHead</span><span class="o">=</span><span class="bp">False</span>
<span class="k">def</span> <span class="nf">Transformer_test</span><span class="p">(</span><span class="n">target</span><span class="p">):</span>
    
    <span class="n">tf</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>


    <span class="n">num_layers</span> <span class="o">=</span> <span class="mi">6</span>
    <span class="n">embedding_dim</span> <span class="o">=</span> <span class="mi">4</span>
    <span class="n">num_heads</span> <span class="o">=</span> <span class="mi">4</span>
    <span class="n">fully_connected_dim</span> <span class="o">=</span> <span class="mi">8</span>
    <span class="n">input_vocab_size</span> <span class="o">=</span> <span class="mi">30</span>
    <span class="n">target_vocab_size</span> <span class="o">=</span> <span class="mi">35</span>
    <span class="n">max_positional_encoding_input</span> <span class="o">=</span> <span class="mi">5</span>
    <span class="n">max_positional_encoding_target</span> <span class="o">=</span> <span class="mi">6</span>

    <span class="n">trans</span> <span class="o">=</span> <span class="n">Transformer</span><span class="p">(</span><span class="n">num_layers</span><span class="p">,</span> 
                        <span class="n">embedding_dim</span><span class="p">,</span> 
                        <span class="n">num_heads</span><span class="p">,</span> 
                        <span class="n">fully_connected_dim</span><span class="p">,</span> 
                        <span class="n">input_vocab_size</span><span class="p">,</span> 
                        <span class="n">target_vocab_size</span><span class="p">,</span> 
                        <span class="n">max_positional_encoding_input</span><span class="p">,</span>
                        <span class="n">max_positional_encoding_target</span><span class="p">)</span>
    <span class="c1"># 0 is the padding value
</span>    <span class="n">sentence_lang_a</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
    <span class="n">sentence_lang_b</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>

    <span class="n">enc_padding_mask</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
    <span class="n">dec_padding_mask</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>

    <span class="n">look_ahead_mask</span> <span class="o">=</span> <span class="n">create_look_ahead_mask</span><span class="p">(</span><span class="n">sentence_lang_a</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

    <span class="n">translation</span><span class="p">,</span> <span class="n">weights</span> <span class="o">=</span> <span class="n">trans</span><span class="p">(</span>
        <span class="n">sentence_lang_a</span><span class="p">,</span>
        <span class="n">sentence_lang_b</span><span class="p">,</span>
        <span class="bp">True</span><span class="p">,</span>
        <span class="n">enc_padding_mask</span><span class="p">,</span>
        <span class="n">look_ahead_mask</span><span class="p">,</span>
        <span class="n">dec_padding_mask</span>
    <span class="p">)</span>
    
    
    <span class="k">assert</span> <span class="n">tf</span><span class="p">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">translation</span><span class="p">),</span> <span class="s">"Wrong type for translation. Output must be a tensor"</span>
    <span class="n">shape1</span> <span class="o">=</span> <span class="p">(</span><span class="n">sentence_lang_a</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">max_positional_encoding_input</span><span class="p">,</span> <span class="n">target_vocab_size</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">shape</span><span class="p">(</span><span class="n">translation</span><span class="p">).</span><span class="n">numpy</span><span class="p">())</span> <span class="o">==</span> <span class="n">shape1</span><span class="p">,</span> <span class="sa">f</span><span class="s">"Wrong shape. We expected </span><span class="si">{</span><span class="n">shape1</span><span class="si">}</span><span class="s">"</span>
        
    <span class="k">print</span><span class="p">(</span><span class="n">translation</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">:</span><span class="mi">8</span><span class="p">])</span>
    <span class="k">assert</span> <span class="n">np</span><span class="p">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">translation</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">:</span><span class="mi">8</span><span class="p">],</span>
                       <span class="p">[[</span><span class="mf">0.02616475</span><span class="p">,</span> <span class="mf">0.02074359</span><span class="p">,</span> <span class="mf">0.01675757</span><span class="p">,</span> 
                         <span class="mf">0.025527</span><span class="p">,</span> <span class="mf">0.04473696</span><span class="p">,</span> <span class="mf">0.02171909</span><span class="p">,</span> 
                         <span class="mf">0.01542725</span><span class="p">,</span> <span class="mf">0.03658631</span><span class="p">]]),</span> <span class="s">"Wrong values in outd"</span>
    
    <span class="n">keys</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">weights</span><span class="p">.</span><span class="n">keys</span><span class="p">())</span>
    <span class="k">assert</span> <span class="nb">type</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span> <span class="o">==</span> <span class="nb">dict</span><span class="p">,</span> <span class="s">"Wrong type for weights. It must be a dict"</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">keys</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">num_layers</span><span class="p">,</span> <span class="sa">f</span><span class="s">"Wrong length for attention weights. It must be 2 x num_layers = </span><span class="si">{</span><span class="mi">2</span><span class="o">*</span><span class="n">num_layers</span><span class="si">}</span><span class="s">"</span>
    <span class="k">assert</span> <span class="n">tf</span><span class="p">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">weights</span><span class="p">[</span><span class="n">keys</span><span class="p">[</span><span class="mi">0</span><span class="p">]]),</span> <span class="sa">f</span><span class="s">"Wrong type for att_weights[</span><span class="si">{</span><span class="n">keys</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s">]. Output must be a tensor"</span>

    <span class="n">shape1</span> <span class="o">=</span> <span class="p">(</span><span class="n">sentence_lang_a</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">sentence_lang_a</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">sentence_lang_a</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">assert</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">shape</span><span class="p">(</span><span class="n">weights</span><span class="p">[</span><span class="n">keys</span><span class="p">[</span><span class="mi">1</span><span class="p">]]).</span><span class="n">numpy</span><span class="p">())</span> <span class="o">==</span> <span class="n">shape1</span><span class="p">,</span> <span class="sa">f</span><span class="s">"Wrong shape. We expected </span><span class="si">{</span><span class="n">shape1</span><span class="si">}</span><span class="s">"</span> 
    <span class="k">assert</span> <span class="n">np</span><span class="p">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">weights</span><span class="p">[</span><span class="n">keys</span><span class="p">[</span><span class="mi">0</span><span class="p">]][</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.4992985</span><span class="p">,</span> <span class="mf">0.5007015</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">]),</span> <span class="sa">f</span><span class="s">"Wrong values in weights[</span><span class="si">{</span><span class="n">keys</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s">]"</span>
    
    <span class="k">print</span><span class="p">(</span><span class="n">translation</span><span class="p">)</span>
    
    <span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\033</span><span class="s">[92mAll tests passed"</span><span class="p">)</span>

    
<span class="n">Transformer_test</span><span class="p">(</span><span class="n">Transformer</span><span class="p">)</span>

</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tf.Tensor(
[0.02616475 0.02074359 0.01675757 0.025527   0.04473695 0.02171909
 0.01542725 0.0365863 ], shape=(8,), dtype=float32)
tf.Tensor(
[[[0.02616475 0.02074359 0.01675757 0.025527   0.04473695 0.02171909
   0.01542725 0.0365863  0.02433536 0.02948791 0.01698964 0.02147779
   0.05749574 0.02669398 0.01277918 0.03276358 0.0253941  0.01698772
   0.02758246 0.02529753 0.04394253 0.06258808 0.03667333 0.03009711
   0.05011231 0.01414333 0.01601289 0.01800467 0.02506283 0.01607273
   0.06204056 0.02099288 0.03005534 0.03070701 0.01854689]
  [0.02490053 0.017258   0.01794803 0.02998916 0.05038005 0.01997477
   0.01526351 0.03385608 0.03138068 0.02608407 0.01852771 0.01744511
   0.05923333 0.03287778 0.01450072 0.02815487 0.02676623 0.01684978
   0.02482791 0.02307897 0.04122656 0.05552058 0.03742857 0.03390088
   0.04666695 0.01667501 0.01400229 0.01981527 0.02202851 0.01818
   0.05918451 0.02173372 0.03040997 0.03337187 0.02055808]
  [0.01867789 0.01225462 0.02509719 0.04180384 0.06244645 0.02000666
   0.01934388 0.03032456 0.05771376 0.02616111 0.01742368 0.01100331
   0.05456048 0.04248188 0.02078063 0.02245298 0.03337655 0.02052129
   0.0239658  0.02193134 0.04068131 0.03323278 0.04556258 0.03676546
   0.04394966 0.01574801 0.01223158 0.02734469 0.01154951 0.02240609
   0.03563077 0.02169302 0.02025472 0.02886864 0.02175329]
  [0.02305287 0.01215192 0.02248081 0.0418811  0.05324595 0.016529
   0.01626855 0.02452858 0.05319852 0.01741914 0.02720063 0.01175192
   0.04887011 0.05262585 0.02324445 0.01787254 0.02867536 0.01768711
   0.01800392 0.01797924 0.02830286 0.03332606 0.0324963  0.04277937
   0.03038614 0.0323176  0.01166379 0.02618811 0.01842924 0.02784598
   0.04346567 0.02524558 0.03285819 0.0404315  0.02959607]
  [0.01859851 0.01163484 0.02560123 0.04363471 0.06270956 0.01928385
   0.01924486 0.02882556 0.06161031 0.02436098 0.01855855 0.01041807
   0.05321557 0.04556077 0.0220504  0.02093103 0.03341144 0.02041205
   0.02265851 0.02099104 0.03823084 0.03121315 0.04416506 0.03813418
   0.04104865 0.01757099 0.01183266 0.0281889  0.0114538  0.02377767
   0.03464996 0.02217591 0.02084129 0.03000083 0.02300425]]], shape=(1, 5, 35), dtype=float32)
[92mAll tests passed
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># UNIT TEST
</span><span class="n">ownMultiHead</span><span class="o">=</span><span class="bp">True</span>
<span class="k">def</span> <span class="nf">Transformer_test</span><span class="p">(</span><span class="n">target</span><span class="p">):</span>
    
    <span class="n">tf</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>


    <span class="n">num_layers</span> <span class="o">=</span> <span class="mi">6</span>
    <span class="n">embedding_dim</span> <span class="o">=</span> <span class="mi">4</span>
    <span class="n">num_heads</span> <span class="o">=</span> <span class="mi">4</span>
    <span class="n">fully_connected_dim</span> <span class="o">=</span> <span class="mi">8</span>
    <span class="n">input_vocab_size</span> <span class="o">=</span> <span class="mi">30</span>
    <span class="n">target_vocab_size</span> <span class="o">=</span> <span class="mi">35</span>
    <span class="n">max_positional_encoding_input</span> <span class="o">=</span> <span class="mi">5</span>
    <span class="n">max_positional_encoding_target</span> <span class="o">=</span> <span class="mi">6</span>

    <span class="n">trans</span> <span class="o">=</span> <span class="n">Transformer</span><span class="p">(</span><span class="n">num_layers</span><span class="p">,</span> 
                        <span class="n">embedding_dim</span><span class="p">,</span> 
                        <span class="n">num_heads</span><span class="p">,</span> 
                        <span class="n">fully_connected_dim</span><span class="p">,</span> 
                        <span class="n">input_vocab_size</span><span class="p">,</span> 
                        <span class="n">target_vocab_size</span><span class="p">,</span> 
                        <span class="n">max_positional_encoding_input</span><span class="p">,</span>
                        <span class="n">max_positional_encoding_target</span><span class="p">)</span>
    <span class="c1"># 0 is the padding value
</span>    <span class="n">sentence_lang_a</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
    <span class="n">sentence_lang_b</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>

    <span class="n">enc_padding_mask</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
    <span class="n">dec_padding_mask</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>

    <span class="n">look_ahead_mask</span> <span class="o">=</span> <span class="n">create_look_ahead_mask</span><span class="p">(</span><span class="n">sentence_lang_a</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

    <span class="n">translation</span><span class="p">,</span> <span class="n">weights</span> <span class="o">=</span> <span class="n">trans</span><span class="p">(</span>
        <span class="n">sentence_lang_a</span><span class="p">,</span>
        <span class="n">sentence_lang_b</span><span class="p">,</span>
        <span class="bp">True</span><span class="p">,</span>
        <span class="n">enc_padding_mask</span><span class="p">,</span>
        <span class="n">look_ahead_mask</span><span class="p">,</span>
        <span class="n">dec_padding_mask</span>
    <span class="p">)</span>
    
    
    <span class="k">assert</span> <span class="n">tf</span><span class="p">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">translation</span><span class="p">),</span> <span class="s">"Wrong type for translation. Output must be a tensor"</span>
    <span class="n">shape1</span> <span class="o">=</span> <span class="p">(</span><span class="n">sentence_lang_a</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">max_positional_encoding_input</span><span class="p">,</span> <span class="n">target_vocab_size</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">shape</span><span class="p">(</span><span class="n">translation</span><span class="p">).</span><span class="n">numpy</span><span class="p">())</span> <span class="o">==</span> <span class="n">shape1</span><span class="p">,</span> <span class="sa">f</span><span class="s">"Wrong shape. We expected </span><span class="si">{</span><span class="n">shape1</span><span class="si">}</span><span class="s">"</span>
        
    <span class="k">print</span><span class="p">(</span><span class="n">translation</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">:</span><span class="mi">8</span><span class="p">])</span>
    
    <span class="n">keys</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">weights</span><span class="p">.</span><span class="n">keys</span><span class="p">())</span>
    <span class="k">assert</span> <span class="nb">type</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span> <span class="o">==</span> <span class="nb">dict</span><span class="p">,</span> <span class="s">"Wrong type for weights. It must be a dict"</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">keys</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">num_layers</span><span class="p">,</span> <span class="sa">f</span><span class="s">"Wrong length for attention weights. It must be 2 x num_layers = </span><span class="si">{</span><span class="mi">2</span><span class="o">*</span><span class="n">num_layers</span><span class="si">}</span><span class="s">"</span>
    <span class="k">assert</span> <span class="n">tf</span><span class="p">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">weights</span><span class="p">[</span><span class="n">keys</span><span class="p">[</span><span class="mi">0</span><span class="p">]]),</span> <span class="sa">f</span><span class="s">"Wrong type for att_weights[</span><span class="si">{</span><span class="n">keys</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s">]. Output must be a tensor"</span>

    <span class="n">shape1</span> <span class="o">=</span> <span class="p">(</span><span class="n">sentence_lang_a</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">sentence_lang_a</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">sentence_lang_a</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">assert</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">shape</span><span class="p">(</span><span class="n">weights</span><span class="p">[</span><span class="n">keys</span><span class="p">[</span><span class="mi">1</span><span class="p">]]).</span><span class="n">numpy</span><span class="p">())</span> <span class="o">==</span> <span class="n">shape1</span><span class="p">,</span> <span class="sa">f</span><span class="s">"Wrong shape. We expected </span><span class="si">{</span><span class="n">shape1</span><span class="si">}</span><span class="s">"</span> 
    <span class="c1">#assert np.allclose(weights[keys[0]][0, 0, 1], [0.4992985, 0.5007015, 0., 0., 0.]), f"Wrong values in weights[{keys[0]}]"
</span>    
    <span class="k">print</span><span class="p">(</span><span class="n">translation</span><span class="p">)</span>
    
    <span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\033</span><span class="s">[92mAll tests passed"</span><span class="p">)</span>
<span class="n">Transformer_test</span><span class="p">(</span><span class="n">Transformer</span><span class="p">)</span>    
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tf.Tensor(
[0.0138899  0.03013041 0.0194122  0.02183245 0.0163418  0.03393482
 0.05421878 0.04387819], shape=(8,), dtype=float32)
tf.Tensor(
[[[0.0138899  0.03013041 0.0194122  0.02183245 0.0163418  0.03393482
   0.05421878 0.04387819 0.0329827  0.01397073 0.03924095 0.01440488
   0.03002763 0.0154879  0.0176722  0.01628551 0.01585947 0.01415133
   0.03792994 0.02771122 0.02725577 0.02476936 0.04830182 0.07570544
   0.02002317 0.02237192 0.02127243 0.02123942 0.01698944 0.02112064
   0.043529   0.03428836 0.04166754 0.04055457 0.03154815]
  [0.01227451 0.02959899 0.0166487  0.02353616 0.01820176 0.03310344
   0.05079214 0.05486127 0.03501931 0.01502464 0.03344036 0.01418775
   0.03232233 0.01766093 0.01824826 0.01715104 0.01604581 0.01408619
   0.04389434 0.02434369 0.03227949 0.02387203 0.03963812 0.07077137
   0.01703417 0.01782698 0.02154371 0.02032982 0.01434441 0.02211295
   0.05294901 0.03850862 0.03668781 0.04071193 0.03094796]
  [0.01763018 0.03471405 0.01863351 0.02474838 0.02410761 0.03263579
   0.03585017 0.06357922 0.0360616  0.02341402 0.02914601 0.01382798
   0.03207213 0.02026083 0.02584696 0.01884262 0.01772998 0.01937712
   0.04135303 0.02141738 0.04634167 0.02295651 0.02191478 0.03458349
   0.01216602 0.01243537 0.03257969 0.0191417  0.01196113 0.02268301
   0.06083624 0.05173917 0.02795435 0.0412199  0.03023846]
  [0.01262886 0.02906489 0.01768985 0.02290371 0.01714453 0.03321528
   0.05317392 0.04823885 0.03380431 0.01412825 0.03580388 0.01471408
   0.03130832 0.01684265 0.01749932 0.01695023 0.01611957 0.01388939
   0.04119689 0.02608779 0.02872973 0.02446639 0.04545375 0.07689973
   0.01928073 0.02068552 0.02047833 0.02108692 0.01605351 0.02187557
   0.04714353 0.03499512 0.03939003 0.03994213 0.03111436]
  [0.01367486 0.02952728 0.01929193 0.02200459 0.01632005 0.03364716
   0.0543959  0.04299618 0.03275498 0.01379251 0.03886067 0.01478795
   0.03005839 0.01573534 0.01740936 0.01650989 0.01605004 0.01407218
   0.03796678 0.02783582 0.02657028 0.02490305 0.04947045 0.07766728
   0.02074305 0.02304619 0.0206537  0.02151686 0.01744339 0.02133087
   0.04263789 0.03324496 0.04177879 0.03989565 0.03140577]]], shape=(1, 5, 35), dtype=float32)
[92mAll tests passed
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ownMultiHead</span><span class="o">=</span><span class="bp">True</span>
<span class="n">sample_transformer</span> <span class="o">=</span> <span class="n">Transformer</span><span class="p">(</span>
    <span class="n">num_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">num_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">fully_connected_dim</span><span class="o">=</span><span class="mi">2048</span><span class="p">,</span> 
    <span class="n">input_vocab_size</span><span class="o">=</span><span class="mi">8500</span><span class="p">,</span> <span class="n">target_vocab_size</span><span class="o">=</span><span class="mi">8000</span><span class="p">,</span> 
    <span class="n">max_positional_encoding_input</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> 
    <span class="n">max_positional_encoding_target</span><span class="o">=</span><span class="mi">6000</span><span class="p">)</span>

<span class="n">temp_input</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">64</span><span class="p">,</span> <span class="mi">62</span><span class="p">))</span>
<span class="n">temp_target</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">64</span><span class="p">,</span> <span class="mi">26</span><span class="p">))</span>

<span class="n">fn_out</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">sample_transformer</span><span class="p">(</span><span class="n">temp_input</span><span class="p">,</span> <span class="n">temp_target</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> 
                               <span class="n">enc_padding_mask</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> 
                               <span class="n">look_ahead_mask</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
                               <span class="n">dec_padding_mask</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>

<span class="n">fn_out</span><span class="p">.</span><span class="n">shape</span>  <span class="c1"># (batch_size, tar_seq_len, target_vocab_size)
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>TensorShape([64, 26, 8000])
</code></pre></div></div>

<p>配置超参数（hyperparameters）
为了让本示例小且相对较快，已经减小了num_layers、 d_model 和 dff 的值。</p>

<p>Transformer 的基础模型使用的数值为：num_layers=6，d_model = 512，dff = 2048。关于所有其他版本的 Transformer，请查阅论文。</p>

<p>Note：通过改变以下数值，您可以获得在许多任务上达到最先进水平的模型。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">tensorflow_datasets</span> <span class="k">as</span> <span class="n">tfds</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="n">examples</span><span class="p">,</span> <span class="n">metadata</span> <span class="o">=</span> <span class="n">tfds</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="s">'ted_hrlr_translate/pt_to_en'</span><span class="p">,</span> <span class="n">with_info</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                               <span class="n">as_supervised</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">train_examples</span><span class="p">,</span> <span class="n">val_examples</span> <span class="o">=</span> <span class="n">examples</span><span class="p">[</span><span class="s">'train'</span><span class="p">],</span> <span class="n">examples</span><span class="p">[</span><span class="s">'validation'</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[1mDownloading and preparing dataset ted_hrlr_translate (124.94 MiB) to /home/jupyter/tensorflow_datasets/ted_hrlr_translate/pt_to_en/0.0.1...[0m


Dl Completed...: 0 url [00:00, ? url/s]
Dl Size...: 0 MiB [00:00, ? MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:00&lt;?, ? url/s]
Dl Size...: 0 MiB [00:00, ? MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:00&lt;?, ? url/s]
Dl Size...:   0%|          | 0/124 [00:00&lt;?, ? MiB/s][A

Extraction completed...: 0 file [00:00, ? file/s][A[A
Dl Completed...:   0%|          | 0/1 [00:00&lt;?, ? url/s]iB/s][A
Dl Size...:   1%|          | 1/124 [00:00&lt;01:27,  1.41 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:00&lt;?, ? url/s]
Dl Size...:   2%|▏         | 2/124 [00:00&lt;01:26,  1.41 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:00&lt;?, ? url/s]
Dl Size...:   2%|▏         | 3/124 [00:00&lt;01:25,  1.41 MiB/s][A

Extraction completed...: 0 file [00:00, ? file/s][A[A
Dl Completed...:   0%|          | 0/1 [00:00&lt;?, ? url/s]iB/s][A
Dl Size...:   3%|▎         | 4/124 [00:00&lt;00:20,  5.82 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:00&lt;?, ? url/s]
Dl Size...:   4%|▍         | 5/124 [00:00&lt;00:20,  5.82 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:00&lt;?, ? url/s]
Dl Size...:   5%|▍         | 6/124 [00:00&lt;00:20,  5.82 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:00&lt;?, ? url/s]
Dl Size...:   6%|▌         | 7/124 [00:00&lt;00:20,  5.82 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:00&lt;?, ? url/s]
Dl Size...:   6%|▋         | 8/124 [00:00&lt;00:19,  5.82 MiB/s][A

Extraction completed...: 0 file [00:00, ? file/s][A[A
Dl Completed...:   0%|          | 0/1 [00:00&lt;?, ? url/s]iB/s][A
Dl Size...:   7%|▋         | 9/124 [00:00&lt;00:08, 13.05 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]
Dl Size...:   8%|▊         | 10/124 [00:01&lt;00:08, 13.05 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]
Dl Size...:   9%|▉         | 11/124 [00:01&lt;00:08, 13.05 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]
Dl Size...:  10%|▉         | 12/124 [00:01&lt;00:08, 13.05 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]
Dl Size...:  10%|█         | 13/124 [00:01&lt;00:08, 13.05 MiB/s][A

Extraction completed...: 0 file [00:01, ? file/s][A[A
Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]MiB/s][A
Dl Size...:  11%|█▏        | 14/124 [00:01&lt;00:05, 19.04 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]
Dl Size...:  12%|█▏        | 15/124 [00:01&lt;00:05, 19.04 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]
Dl Size...:  13%|█▎        | 16/124 [00:01&lt;00:05, 19.04 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]
Dl Size...:  14%|█▎        | 17/124 [00:01&lt;00:05, 19.04 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]
Dl Size...:  15%|█▍        | 18/124 [00:01&lt;00:05, 19.04 MiB/s][A

Extraction completed...: 0 file [00:01, ? file/s][A[A
Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]MiB/s][A
Dl Size...:  15%|█▌        | 19/124 [00:01&lt;00:04, 24.24 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]
Dl Size...:  16%|█▌        | 20/124 [00:01&lt;00:04, 24.24 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]
Dl Size...:  17%|█▋        | 21/124 [00:01&lt;00:04, 24.24 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]
Dl Size...:  18%|█▊        | 22/124 [00:01&lt;00:04, 24.24 MiB/s][A

Extraction completed...: 0 file [00:01, ? file/s][A[A
Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]MiB/s][A
Dl Size...:  19%|█▊        | 23/124 [00:01&lt;00:03, 27.63 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]
Dl Size...:  19%|█▉        | 24/124 [00:01&lt;00:03, 27.63 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]
Dl Size...:  20%|██        | 25/124 [00:01&lt;00:03, 27.63 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]
Dl Size...:  21%|██        | 26/124 [00:01&lt;00:03, 27.63 MiB/s][A

Extraction completed...: 0 file [00:01, ? file/s][A[A
Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]MiB/s][A
Dl Size...:  22%|██▏       | 27/124 [00:01&lt;00:03, 30.56 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]
Dl Size...:  23%|██▎       | 28/124 [00:01&lt;00:03, 30.56 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]
Dl Size...:  23%|██▎       | 29/124 [00:01&lt;00:03, 30.56 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]
Dl Size...:  24%|██▍       | 30/124 [00:01&lt;00:03, 30.56 MiB/s][A

Extraction completed...: 0 file [00:01, ? file/s][A[A
Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]MiB/s][A
Dl Size...:  25%|██▌       | 31/124 [00:01&lt;00:02, 32.46 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]
Dl Size...:  26%|██▌       | 32/124 [00:01&lt;00:02, 32.46 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]
Dl Size...:  27%|██▋       | 33/124 [00:01&lt;00:02, 32.46 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]
Dl Size...:  27%|██▋       | 34/124 [00:01&lt;00:02, 32.46 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]
Dl Size...:  28%|██▊       | 35/124 [00:01&lt;00:02, 32.46 MiB/s][A

Extraction completed...: 0 file [00:01, ? file/s][A[A
Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]MiB/s][A
Dl Size...:  29%|██▉       | 36/124 [00:01&lt;00:02, 35.21 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]
Dl Size...:  30%|██▉       | 37/124 [00:01&lt;00:02, 35.21 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]
Dl Size...:  31%|███       | 38/124 [00:01&lt;00:02, 35.21 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]
Dl Size...:  31%|███▏      | 39/124 [00:01&lt;00:02, 35.21 MiB/s][A

Extraction completed...: 0 file [00:01, ? file/s][A[A
Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]MiB/s][A
Dl Size...:  32%|███▏      | 40/124 [00:01&lt;00:02, 35.71 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]
Dl Size...:  33%|███▎      | 41/124 [00:01&lt;00:02, 35.71 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]
Dl Size...:  34%|███▍      | 42/124 [00:01&lt;00:02, 35.71 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]
Dl Size...:  35%|███▍      | 43/124 [00:01&lt;00:02, 35.71 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]
Dl Size...:  35%|███▌      | 44/124 [00:01&lt;00:02, 35.71 MiB/s][A

Extraction completed...: 0 file [00:01, ? file/s][A[A
Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]MiB/s][A
Dl Size...:  36%|███▋      | 45/124 [00:01&lt;00:02, 37.55 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]
Dl Size...:  37%|███▋      | 46/124 [00:01&lt;00:02, 37.55 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]
Dl Size...:  38%|███▊      | 47/124 [00:01&lt;00:02, 37.55 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]
Dl Size...:  39%|███▊      | 48/124 [00:01&lt;00:02, 37.55 MiB/s][A

Extraction completed...: 0 file [00:01, ? file/s][A[A
Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]MiB/s][A
Dl Size...:  40%|███▉      | 49/124 [00:02&lt;00:02, 37.24 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]
Dl Size...:  40%|████      | 50/124 [00:02&lt;00:01, 37.24 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]
Dl Size...:  41%|████      | 51/124 [00:02&lt;00:01, 37.24 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]
Dl Size...:  42%|████▏     | 52/124 [00:02&lt;00:01, 37.24 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]
Dl Size...:  43%|████▎     | 53/124 [00:02&lt;00:01, 37.24 MiB/s][A

Extraction completed...: 0 file [00:02, ? file/s][A[A
Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]MiB/s][A
Dl Size...:  44%|████▎     | 54/124 [00:02&lt;00:01, 39.37 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]
Dl Size...:  44%|████▍     | 55/124 [00:02&lt;00:01, 39.37 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]
Dl Size...:  45%|████▌     | 56/124 [00:02&lt;00:01, 39.37 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]
Dl Size...:  46%|████▌     | 57/124 [00:02&lt;00:01, 39.37 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]
Dl Size...:  47%|████▋     | 58/124 [00:02&lt;00:01, 39.37 MiB/s][A

Extraction completed...: 0 file [00:02, ? file/s][A[A
Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]MiB/s][A
Dl Size...:  48%|████▊     | 59/124 [00:02&lt;00:01, 38.63 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]
Dl Size...:  48%|████▊     | 60/124 [00:02&lt;00:01, 38.63 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]
Dl Size...:  49%|████▉     | 61/124 [00:02&lt;00:01, 38.63 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]
Dl Size...:  50%|█████     | 62/124 [00:02&lt;00:01, 38.63 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]
Dl Size...:  51%|█████     | 63/124 [00:02&lt;00:01, 38.63 MiB/s][A

Extraction completed...: 0 file [00:02, ? file/s][A[A
Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]MiB/s][A
Dl Size...:  52%|█████▏    | 64/124 [00:02&lt;00:01, 38.13 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]
Dl Size...:  52%|█████▏    | 65/124 [00:02&lt;00:01, 38.13 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]
Dl Size...:  53%|█████▎    | 66/124 [00:02&lt;00:01, 38.13 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]
Dl Size...:  54%|█████▍    | 67/124 [00:02&lt;00:01, 38.13 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]
Dl Size...:  55%|█████▍    | 68/124 [00:02&lt;00:01, 38.13 MiB/s][A

Extraction completed...: 0 file [00:02, ? file/s][A[A
Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]MiB/s][A
Dl Size...:  56%|█████▌    | 69/124 [00:02&lt;00:01, 39.58 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]
Dl Size...:  56%|█████▋    | 70/124 [00:02&lt;00:01, 39.58 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]
Dl Size...:  57%|█████▋    | 71/124 [00:02&lt;00:01, 39.58 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]
Dl Size...:  58%|█████▊    | 72/124 [00:02&lt;00:01, 39.58 MiB/s][A

Extraction completed...: 0 file [00:02, ? file/s][A[A
Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]MiB/s][A
Dl Size...:  59%|█████▉    | 73/124 [00:02&lt;00:01, 38.34 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]
Dl Size...:  60%|█████▉    | 74/124 [00:02&lt;00:01, 38.34 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]
Dl Size...:  60%|██████    | 75/124 [00:02&lt;00:01, 38.34 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]
Dl Size...:  61%|██████▏   | 76/124 [00:02&lt;00:01, 38.34 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]
Dl Size...:  62%|██████▏   | 77/124 [00:02&lt;00:01, 38.34 MiB/s][A

Extraction completed...: 0 file [00:02, ? file/s][A[A
Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]MiB/s][A
Dl Size...:  63%|██████▎   | 78/124 [00:02&lt;00:01, 39.90 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]
Dl Size...:  64%|██████▎   | 79/124 [00:02&lt;00:01, 39.90 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]
Dl Size...:  65%|██████▍   | 80/124 [00:02&lt;00:01, 39.90 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]
Dl Size...:  65%|██████▌   | 81/124 [00:02&lt;00:01, 39.90 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]
Dl Size...:  66%|██████▌   | 82/124 [00:02&lt;00:01, 39.90 MiB/s][A

Extraction completed...: 0 file [00:02, ? file/s][A[A
Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]MiB/s][A
Dl Size...:  67%|██████▋   | 83/124 [00:02&lt;00:01, 39.35 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]
Dl Size...:  68%|██████▊   | 84/124 [00:02&lt;00:01, 39.35 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]
Dl Size...:  69%|██████▊   | 85/124 [00:02&lt;00:00, 39.35 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]
Dl Size...:  69%|██████▉   | 86/124 [00:02&lt;00:00, 39.35 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]
Dl Size...:  70%|███████   | 87/124 [00:02&lt;00:00, 39.35 MiB/s][A

Extraction completed...: 0 file [00:02, ? file/s][A[A
Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s]MiB/s][A
Dl Size...:  71%|███████   | 88/124 [00:03&lt;00:00, 38.82 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s]
Dl Size...:  72%|███████▏  | 89/124 [00:03&lt;00:00, 38.82 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s]
Dl Size...:  73%|███████▎  | 90/124 [00:03&lt;00:00, 38.82 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s]
Dl Size...:  73%|███████▎  | 91/124 [00:03&lt;00:00, 38.82 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s]
Dl Size...:  74%|███████▍  | 92/124 [00:03&lt;00:00, 38.82 MiB/s][A

Extraction completed...: 0 file [00:03, ? file/s][A[A
Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s]MiB/s][A
Dl Size...:  75%|███████▌  | 93/124 [00:03&lt;00:00, 40.16 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s]
Dl Size...:  76%|███████▌  | 94/124 [00:03&lt;00:00, 40.16 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s]
Dl Size...:  77%|███████▋  | 95/124 [00:03&lt;00:00, 40.16 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s]
Dl Size...:  77%|███████▋  | 96/124 [00:03&lt;00:00, 40.16 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s]
Dl Size...:  78%|███████▊  | 97/124 [00:03&lt;00:00, 40.16 MiB/s][A

Extraction completed...: 0 file [00:03, ? file/s][A[A
Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s]MiB/s][A
Dl Size...:  79%|███████▉  | 98/124 [00:03&lt;00:00, 39.51 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s]
Dl Size...:  80%|███████▉  | 99/124 [00:03&lt;00:00, 39.51 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s]
Dl Size...:  81%|████████  | 100/124 [00:03&lt;00:00, 39.51 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s]
Dl Size...:  81%|████████▏ | 101/124 [00:03&lt;00:00, 39.51 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s]
Dl Size...:  82%|████████▏ | 102/124 [00:03&lt;00:00, 39.51 MiB/s][A

Extraction completed...: 0 file [00:03, ? file/s][A[A
Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s] MiB/s][A
Dl Size...:  83%|████████▎ | 103/124 [00:03&lt;00:00, 40.34 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s]
Dl Size...:  84%|████████▍ | 104/124 [00:03&lt;00:00, 40.34 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s]
Dl Size...:  85%|████████▍ | 105/124 [00:03&lt;00:00, 40.34 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s]
Dl Size...:  85%|████████▌ | 106/124 [00:03&lt;00:00, 40.34 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s]
Dl Size...:  86%|████████▋ | 107/124 [00:03&lt;00:00, 40.34 MiB/s][A

Extraction completed...: 0 file [00:03, ? file/s][A[A
Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s] MiB/s][A
Dl Size...:  87%|████████▋ | 108/124 [00:03&lt;00:00, 39.83 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s]
Dl Size...:  88%|████████▊ | 109/124 [00:03&lt;00:00, 39.83 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s]
Dl Size...:  89%|████████▊ | 110/124 [00:03&lt;00:00, 39.83 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s]
Dl Size...:  90%|████████▉ | 111/124 [00:03&lt;00:00, 39.83 MiB/s][A

Extraction completed...: 0 file [00:03, ? file/s][A[A
Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s] MiB/s][A
Dl Size...:  90%|█████████ | 112/124 [00:03&lt;00:00, 39.72 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s]
Dl Size...:  91%|█████████ | 113/124 [00:03&lt;00:00, 39.72 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s]
Dl Size...:  92%|█████████▏| 114/124 [00:03&lt;00:00, 39.72 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s]
Dl Size...:  93%|█████████▎| 115/124 [00:03&lt;00:00, 39.72 MiB/s][A

Extraction completed...: 0 file [00:03, ? file/s][A[A
Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s] MiB/s][A
Dl Size...:  94%|█████████▎| 116/124 [00:03&lt;00:00, 38.85 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s]
Dl Size...:  94%|█████████▍| 117/124 [00:03&lt;00:00, 38.85 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s]
Dl Size...:  95%|█████████▌| 118/124 [00:03&lt;00:00, 38.85 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s]
Dl Size...:  96%|█████████▌| 119/124 [00:03&lt;00:00, 38.85 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s]
Dl Size...:  97%|█████████▋| 120/124 [00:03&lt;00:00, 38.85 MiB/s][A

Extraction completed...: 0 file [00:03, ? file/s][A[A
Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s] MiB/s][A
Dl Size...:  98%|█████████▊| 121/124 [00:03&lt;00:00, 39.96 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s]
Dl Size...:  98%|█████████▊| 122/124 [00:03&lt;00:00, 39.96 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s]
Dl Size...:  99%|█████████▉| 123/124 [00:03&lt;00:00, 39.96 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s]
Dl Size...: 100%|██████████| 124/124 [00:03&lt;00:00, 39.96 MiB/s][A

Dl Completed...: 100%|██████████| 1/1 [00:03&lt;00:00,  3.93s/ url]
Dl Size...: 100%|██████████| 124/124 [00:03&lt;00:00, 39.96 MiB/s][A

Dl Completed...: 100%|██████████| 1/1 [00:03&lt;00:00,  3.93s/ url]
Dl Size...: 100%|██████████| 124/124 [00:03&lt;00:00, 39.96 MiB/s][A

Extraction completed...:   0%|          | 0/1 [00:03&lt;?, ? file/s][A[A

Dl Completed...: 100%|██████████| 1/1 [00:08&lt;00:00,  3.93s/ url]7s/ file][A[A
Dl Size...: 100%|██████████| 124/124 [00:08&lt;00:00, 39.96 MiB/s][A

Extraction completed...: 100%|██████████| 1/1 [00:08&lt;00:00,  8.09s/ file][A[A
Dl Size...: 100%|██████████| 124/124 [00:08&lt;00:00, 15.33 MiB/s]
Dl Completed...: 100%|██████████| 1/1 [00:08&lt;00:00,  8.09s/ url]







Shuffling...:   0%|          | 0/1 [00:00&lt;?, ? shard/s]

WARNING:tensorflow:From /opt/conda/envs/tf/lib/python3.7/site-packages/tensorflow_datasets/core/file_format_adapter.py:209: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.
Instructions for updating:
Use eager execution and: 
`tf.data.TFRecordDataset(path)`


WARNING:tensorflow:From /opt/conda/envs/tf/lib/python3.7/site-packages/tensorflow_datasets/core/file_format_adapter.py:209: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.
Instructions for updating:
Use eager execution and: 
`tf.data.TFRecordDataset(path)`

Reading...: 0 examples [00:00, ? examples/s][A
                                            [A
Writing...:   0%|          | 0/51785 [00:00&lt;?, ? examples/s][A
Shuffling...:   0%|          | 0/1 [00:00&lt;?, ? shard/s]        
Reading...: 0 examples [00:00, ? examples/s][A
                                            [A
Writing...:   0%|          | 0/1193 [00:00&lt;?, ? examples/s][A
Shuffling...:   0%|          | 0/1 [00:00&lt;?, ? shard/s]    [A
Reading...: 0 examples [00:00, ? examples/s][A
                                            [A
Writing...:   0%|          | 0/1803 [00:00&lt;?, ? examples/s][A
                                                           [A

[1mDataset ted_hrlr_translate downloaded and prepared to /home/jupyter/tensorflow_datasets/ted_hrlr_translate/pt_to_en/0.0.1. Subsequent calls will reuse this data.[0m


WARNING:absl:Warning: Setting shuffle_files=True because split=TRAIN and shuffle_files=None. This behavior will be deprecated on 2019-08-06, at which point shuffle_files=False will be the default for all splits.
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">tokenizer_en</span> <span class="o">=</span> <span class="n">tfds</span><span class="p">.</span><span class="n">features</span><span class="p">.</span><span class="n">text</span><span class="p">.</span><span class="n">SubwordTextEncoder</span><span class="p">.</span><span class="n">build_from_corpus</span><span class="p">(</span>
    <span class="p">(</span><span class="n">en</span><span class="p">.</span><span class="n">numpy</span><span class="p">()</span> <span class="k">for</span> <span class="n">pt</span><span class="p">,</span> <span class="n">en</span> <span class="ow">in</span> <span class="n">train_examples</span><span class="p">),</span> <span class="n">target_vocab_size</span><span class="o">=</span><span class="mi">2</span><span class="o">**</span><span class="mi">13</span><span class="p">)</span>

<span class="n">tokenizer_pt</span> <span class="o">=</span> <span class="n">tfds</span><span class="p">.</span><span class="n">features</span><span class="p">.</span><span class="n">text</span><span class="p">.</span><span class="n">SubwordTextEncoder</span><span class="p">.</span><span class="n">build_from_corpus</span><span class="p">(</span>
    <span class="p">(</span><span class="n">pt</span><span class="p">.</span><span class="n">numpy</span><span class="p">()</span> <span class="k">for</span> <span class="n">pt</span><span class="p">,</span> <span class="n">en</span> <span class="ow">in</span> <span class="n">train_examples</span><span class="p">),</span> <span class="n">target_vocab_size</span><span class="o">=</span><span class="mi">2</span><span class="o">**</span><span class="mi">13</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>2023-05-09 11:56:13.233103: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sample_string</span> <span class="o">=</span> <span class="s">'Transformer is awesome.'</span>

<span class="n">tokenized_string</span> <span class="o">=</span> <span class="n">tokenizer_en</span><span class="p">.</span><span class="n">encode</span><span class="p">(</span><span class="n">sample_string</span><span class="p">)</span>
<span class="k">print</span> <span class="p">(</span><span class="s">'Tokenized string is {}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">tokenized_string</span><span class="p">))</span>

<span class="n">original_string</span> <span class="o">=</span> <span class="n">tokenizer_en</span><span class="p">.</span><span class="n">decode</span><span class="p">(</span><span class="n">tokenized_string</span><span class="p">)</span>
<span class="k">print</span> <span class="p">(</span><span class="s">'The original string: {}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">original_string</span><span class="p">))</span>

<span class="k">assert</span> <span class="n">original_string</span> <span class="o">==</span> <span class="n">sample_string</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Tokenized string is [7915, 1248, 7946, 7194, 13, 2799, 7877]
The original string: Transformer is awesome.
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">ts</span> <span class="ow">in</span> <span class="n">tokenized_string</span><span class="p">:</span>
    <span class="k">print</span> <span class="p">(</span><span class="s">'{} ----&gt; {}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">ts</span><span class="p">,</span> <span class="n">tokenizer_en</span><span class="p">.</span><span class="n">decode</span><span class="p">([</span><span class="n">ts</span><span class="p">])))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>7915 ----&gt; T
1248 ----&gt; ran
7946 ----&gt; s
7194 ----&gt; former 
13 ----&gt; is 
2799 ----&gt; awesome
7877 ----&gt; .
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">BUFFER_SIZE</span> <span class="o">=</span> <span class="mi">20000</span>
<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">64</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="n">lang1</span><span class="p">,</span> <span class="n">lang2</span><span class="p">):</span>
    <span class="n">lang1</span> <span class="o">=</span> <span class="p">[</span><span class="n">tokenizer_pt</span><span class="p">.</span><span class="n">vocab_size</span><span class="p">]</span> <span class="o">+</span> <span class="n">tokenizer_pt</span><span class="p">.</span><span class="n">encode</span><span class="p">(</span>
      <span class="n">lang1</span><span class="p">.</span><span class="n">numpy</span><span class="p">())</span> <span class="o">+</span> <span class="p">[</span><span class="n">tokenizer_pt</span><span class="p">.</span><span class="n">vocab_size</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>

    <span class="n">lang2</span> <span class="o">=</span> <span class="p">[</span><span class="n">tokenizer_en</span><span class="p">.</span><span class="n">vocab_size</span><span class="p">]</span> <span class="o">+</span> <span class="n">tokenizer_en</span><span class="p">.</span><span class="n">encode</span><span class="p">(</span>
      <span class="n">lang2</span><span class="p">.</span><span class="n">numpy</span><span class="p">())</span> <span class="o">+</span> <span class="p">[</span><span class="n">tokenizer_en</span><span class="p">.</span><span class="n">vocab_size</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">lang1</span><span class="p">,</span> <span class="n">lang2</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">MAX_LENGTH</span> <span class="o">=</span> <span class="mi">40</span>
<span class="k">def</span> <span class="nf">filter_max_length</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="n">MAX_LENGTH</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tf</span><span class="p">.</span><span class="n">logical_and</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">max_length</span><span class="p">,</span>
                        <span class="n">tf</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">max_length</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">tf_encode</span><span class="p">(</span><span class="n">pt</span><span class="p">,</span> <span class="n">en</span><span class="p">):</span>
    <span class="n">result_pt</span><span class="p">,</span> <span class="n">result_en</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">py_function</span><span class="p">(</span><span class="n">encode</span><span class="p">,</span> <span class="p">[</span><span class="n">pt</span><span class="p">,</span> <span class="n">en</span><span class="p">],</span> <span class="p">[</span><span class="n">tf</span><span class="p">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">tf</span><span class="p">.</span><span class="n">int64</span><span class="p">])</span>
    <span class="n">result_pt</span><span class="p">.</span><span class="n">set_shape</span><span class="p">([</span><span class="bp">None</span><span class="p">])</span>
    <span class="n">result_en</span><span class="p">.</span><span class="n">set_shape</span><span class="p">([</span><span class="bp">None</span><span class="p">])</span>
    
    <span class="k">return</span> <span class="n">result_pt</span><span class="p">,</span> <span class="n">result_en</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">train_examples</span><span class="p">.</span><span class="nb">map</span><span class="p">(</span><span class="n">tf_encode</span><span class="p">)</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="p">.</span><span class="nb">filter</span><span class="p">(</span><span class="n">filter_max_length</span><span class="p">)</span>
<span class="c1"># 将数据集缓存到内存中以加快读取速度。
</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="p">.</span><span class="n">cache</span><span class="p">()</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="p">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">BUFFER_SIZE</span><span class="p">).</span><span class="n">padded_batch</span><span class="p">(</span><span class="n">BATCH_SIZE</span><span class="p">)</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="p">.</span><span class="n">prefetch</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">experimental</span><span class="p">.</span><span class="n">AUTOTUNE</span><span class="p">)</span>


<span class="n">val_dataset</span> <span class="o">=</span> <span class="n">val_examples</span><span class="p">.</span><span class="nb">map</span><span class="p">(</span><span class="n">tf_encode</span><span class="p">)</span>
<span class="n">val_dataset</span> <span class="o">=</span> <span class="n">val_dataset</span><span class="p">.</span><span class="nb">filter</span><span class="p">(</span><span class="n">filter_max_length</span><span class="p">).</span><span class="n">padded_batch</span><span class="p">(</span><span class="n">BATCH_SIZE</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pt_batch</span><span class="p">,</span> <span class="n">en_batch</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">val_dataset</span><span class="p">))</span>
<span class="n">pt_batch</span><span class="p">,</span> <span class="n">en_batch</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(&lt;tf.Tensor: shape=(64, 40), dtype=int64, numpy=
 array([[8214, 1259,    5, ...,    0,    0,    0],
        [8214,  299,   13, ...,    0,    0,    0],
        [8214,   59,    8, ...,    0,    0,    0],
        ...,
        [8214,   95,    3, ...,    0,    0,    0],
        [8214, 5157,    1, ...,    0,    0,    0],
        [8214, 4479, 7990, ...,    0,    0,    0]])&gt;,
 &lt;tf.Tensor: shape=(64, 40), dtype=int64, numpy=
 array([[8087,   18,   12, ...,    0,    0,    0],
        [8087,  634,   30, ...,    0,    0,    0],
        [8087,   16,   13, ...,    0,    0,    0],
        ...,
        [8087,   12,   20, ...,    0,    0,    0],
        [8087,   17, 4981, ...,    0,    0,    0],
        [8087,   12, 5453, ...,    0,    0,    0]])&gt;)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">num_layers</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">d_model</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">dff</span> <span class="o">=</span> <span class="mi">512</span>
<span class="n">num_heads</span> <span class="o">=</span> <span class="mi">8</span>

<span class="n">input_vocab_size</span> <span class="o">=</span> <span class="n">tokenizer_pt</span><span class="p">.</span><span class="n">vocab_size</span> <span class="o">+</span> <span class="mi">2</span>
<span class="n">target_vocab_size</span> <span class="o">=</span> <span class="n">tokenizer_en</span><span class="p">.</span><span class="n">vocab_size</span> <span class="o">+</span> <span class="mi">2</span>
<span class="n">dropout_rate</span> <span class="o">=</span> <span class="mf">0.1</span>
</code></pre></div></div>

<p>优化器（Optimizer）
根据论文中的公式，将 Adam 优化器与自定义的学习速率调度程序（scheduler）配合使用。</p>

\[\Large{lrate = d_{model}^{-0.5} * min(step{\_}num^{-0.5}, step{\_}num * warmup{\_}steps^{-1.5})}\]

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">CustomSchedule</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">optimizers</span><span class="p">.</span><span class="n">schedules</span><span class="p">.</span><span class="n">LearningRateSchedule</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">warmup_steps</span><span class="o">=</span><span class="mi">4000</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">CustomSchedule</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">d_model</span> <span class="o">=</span> <span class="n">d_model</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">d_model</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">cast</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">d_model</span><span class="p">,</span> <span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">warmup_steps</span> <span class="o">=</span> <span class="n">warmup_steps</span>

    <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">step</span><span class="p">):</span>
        <span class="n">arg1</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">math</span><span class="p">.</span><span class="n">rsqrt</span><span class="p">(</span><span class="n">step</span><span class="p">)</span>
        <span class="n">arg2</span> <span class="o">=</span> <span class="n">step</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">warmup_steps</span> <span class="o">**</span> <span class="o">-</span><span class="mf">1.5</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">tf</span><span class="p">.</span><span class="n">math</span><span class="p">.</span><span class="n">rsqrt</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">d_model</span><span class="p">)</span> <span class="o">*</span> <span class="n">tf</span><span class="p">.</span><span class="n">math</span><span class="p">.</span><span class="n">minimum</span><span class="p">(</span><span class="n">arg1</span><span class="p">,</span> <span class="n">arg2</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">CustomSchedule</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">optimizers</span><span class="p">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="p">,</span> <span class="n">beta_1</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">beta_2</span><span class="o">=</span><span class="mf">0.98</span><span class="p">,</span> 
                                     <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-9</span><span class="p">)</span>
<span class="n">temp_learning_rate_schedule</span> <span class="o">=</span> <span class="n">CustomSchedule</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">temp_learning_rate_schedule</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="nb">range</span><span class="p">(</span><span class="mi">40000</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">)))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"Learning Rate"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"Train Step"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Text(0.5, 0, 'Train Step')
</code></pre></div></div>

<p><img src="/assets/2023-12-03-Transformer-learning-C5W4A1SubclassV1_files/2023-12-03-Transformer-learning-C5W4A1SubclassV1_89_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">loss_object</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">losses</span><span class="p">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">(</span>
    <span class="n">from_logits</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s">'none'</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">loss_function</span><span class="p">(</span><span class="n">real</span><span class="p">,</span> <span class="n">pred</span><span class="p">):</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">math</span><span class="p">.</span><span class="n">logical_not</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">math</span><span class="p">.</span><span class="n">equal</span><span class="p">(</span><span class="n">real</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
    <span class="n">loss_</span> <span class="o">=</span> <span class="n">loss_object</span><span class="p">(</span><span class="n">real</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">cast</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">loss_</span><span class="p">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">loss_</span> <span class="o">*=</span> <span class="n">mask</span>
    <span class="k">return</span> <span class="n">tf</span><span class="p">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">loss_</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_loss</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">metrics</span><span class="p">.</span><span class="n">Mean</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s">'train_loss'</span><span class="p">)</span>
<span class="n">train_accuracy</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">metrics</span><span class="p">.</span><span class="n">SparseCategoricalAccuracy</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="s">'train_accuracy'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">transformer</span> <span class="o">=</span> <span class="n">Transformer</span><span class="p">(</span><span class="n">num_layers</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">dff</span><span class="p">,</span>
                          <span class="n">input_vocab_size</span><span class="p">,</span> <span class="n">target_vocab_size</span><span class="p">,</span> 
                          <span class="n">max_positional_encoding_input</span><span class="o">=</span><span class="n">input_vocab_size</span><span class="p">,</span> 
                          <span class="n">max_positional_encoding_target</span><span class="o">=</span><span class="n">target_vocab_size</span><span class="p">,</span>
                          <span class="n">dropout_rate</span><span class="o">=</span><span class="n">dropout_rate</span><span class="p">)</span>
    
<span class="k">def</span> <span class="nf">create_masks</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">tar</span><span class="p">):</span>
    <span class="c1"># 编码器填充遮挡
</span>    <span class="n">enc_padding_mask</span> <span class="o">=</span> <span class="n">create_padding_mask</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span>
    <span class="c1"># 在解码器的第二个注意力模块使用。
</span>    <span class="c1"># 该填充遮挡用于遮挡编码器的输出。
</span>    <span class="n">dec_padding_mask</span> <span class="o">=</span> <span class="n">create_padding_mask</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span>

    <span class="c1"># 在解码器的第一个注意力模块使用。
</span>    <span class="c1"># 用于填充（pad）和遮挡（mask）解码器获取到的输入的后续标记（future tokens）。
</span>    <span class="n">look_ahead_mask</span> <span class="o">=</span> <span class="n">create_look_ahead_mask</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">shape</span><span class="p">(</span><span class="n">tar</span><span class="p">)[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">dec_target_padding_mask</span> <span class="o">=</span> <span class="n">create_padding_mask</span><span class="p">(</span><span class="n">tar</span><span class="p">)</span>
    <span class="n">combined_mask</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">dec_target_padding_mask</span><span class="p">,</span> <span class="n">look_ahead_mask</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">enc_padding_mask</span><span class="p">,</span> <span class="n">combined_mask</span><span class="p">,</span> <span class="n">dec_padding_mask</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">checkpoint_path</span> <span class="o">=</span> <span class="s">"./checkpoints/train"</span>

<span class="n">ckpt</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">train</span><span class="p">.</span><span class="n">Checkpoint</span><span class="p">(</span><span class="n">transformer</span><span class="o">=</span><span class="n">transformer</span><span class="p">,</span>
                           <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">)</span>

<span class="n">ckpt_manager</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">train</span><span class="p">.</span><span class="n">CheckpointManager</span><span class="p">(</span><span class="n">ckpt</span><span class="p">,</span> <span class="n">checkpoint_path</span><span class="p">,</span> <span class="n">max_to_keep</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="c1"># 如果检查点存在，则恢复最新的检查点。
</span><span class="k">if</span> <span class="n">ckpt_manager</span><span class="p">.</span><span class="n">latest_checkpoint</span><span class="p">:</span>
    <span class="n">ckpt</span><span class="p">.</span><span class="n">restore</span><span class="p">(</span><span class="n">ckpt_manager</span><span class="p">.</span><span class="n">latest_checkpoint</span><span class="p">)</span>
    <span class="k">print</span> <span class="p">(</span><span class="s">'Latest checkpoint restored!!'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">20</span>
<span class="c1"># 该 @tf.function 将追踪-编译 train_step 到 TF 图中，以便更快地
# 执行。该函数专用于参数张量的精确形状。为了避免由于可变序列长度或可变
# 批次大小（最后一批次较小）导致的再追踪，使用 input_signature 指定
# 更多的通用形状。
</span>
<span class="n">train_step_signature</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">tf</span><span class="p">.</span><span class="n">TensorSpec</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">int64</span><span class="p">),</span>
    <span class="n">tf</span><span class="p">.</span><span class="n">TensorSpec</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">int64</span><span class="p">),</span>
<span class="p">]</span>

<span class="o">@</span><span class="n">tf</span><span class="p">.</span><span class="n">function</span><span class="p">(</span><span class="n">input_signature</span><span class="o">=</span><span class="n">train_step_signature</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">train_step</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">tar</span><span class="p">):</span>
    <span class="n">tar_inp</span> <span class="o">=</span> <span class="n">tar</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">tar_real</span> <span class="o">=</span> <span class="n">tar</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span>

    <span class="n">enc_padding_mask</span><span class="p">,</span> <span class="n">combined_mask</span><span class="p">,</span> <span class="n">dec_padding_mask</span> <span class="o">=</span> <span class="n">create_masks</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">tar_inp</span><span class="p">)</span>
    
    <span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
        <span class="n">predictions</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">transformer</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">tar_inp</span><span class="p">,</span> 
                                     <span class="bp">True</span><span class="p">,</span> 
                                     <span class="n">enc_padding_mask</span><span class="p">,</span> 
                                     <span class="n">combined_mask</span><span class="p">,</span> 
                                     <span class="n">dec_padding_mask</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">tar_real</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>
        
        <span class="n">gradients</span> <span class="o">=</span> <span class="n">tape</span><span class="p">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">transformer</span><span class="p">.</span><span class="n">trainable_variables</span><span class="p">)</span>    
        <span class="n">optimizer</span><span class="p">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">gradients</span><span class="p">,</span> <span class="n">transformer</span><span class="p">.</span><span class="n">trainable_variables</span><span class="p">))</span>
        
        <span class="n">train_loss</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
        <span class="n">train_accuracy</span><span class="p">(</span><span class="n">tar_real</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>
    <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">train_loss</span><span class="p">.</span><span class="n">reset_states</span><span class="p">()</span>
    <span class="n">train_accuracy</span><span class="p">.</span><span class="n">reset_states</span><span class="p">()</span>

    <span class="c1"># inp -&gt; portuguese, tar -&gt; english
</span>    <span class="k">for</span> <span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">tar</span><span class="p">))</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">):</span>
        <span class="n">train_step</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">tar</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">batch</span> <span class="o">%</span> <span class="mi">50</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">print</span> <span class="p">(</span><span class="s">'Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span>
                <span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">train_loss</span><span class="p">.</span><span class="n">result</span><span class="p">(),</span> <span class="n">train_accuracy</span><span class="p">.</span><span class="n">result</span><span class="p">()))</span>
    
    <span class="k">if</span> <span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">5</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">ckpt_save_path</span> <span class="o">=</span> <span class="n">ckpt_manager</span><span class="p">.</span><span class="n">save</span><span class="p">()</span>
        <span class="k">print</span> <span class="p">(</span><span class="s">'Saving checkpoint for epoch {} at {}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span>
                                                         <span class="n">ckpt_save_path</span><span class="p">))</span>
    <span class="k">print</span> <span class="p">(</span><span class="s">'Epoch {} Loss {:.4f} Accuracy {:.4f}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> 
                                            <span class="n">train_loss</span><span class="p">.</span><span class="n">result</span><span class="p">(),</span> 
                                            <span class="n">train_accuracy</span><span class="p">.</span><span class="n">result</span><span class="p">()))</span>
    <span class="k">print</span> <span class="p">(</span><span class="s">'Time taken for 1 epoch: {} secs</span><span class="se">\n</span><span class="s">'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">time</span><span class="p">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>2023-05-09 12:09:35.813744: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:175] Filling up shuffle buffer (this may take a while): 13805 of 20000
2023-05-09 12:09:40.167687: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:228] Shuffle buffer filled.
/opt/conda/envs/tf/lib/python3.7/site-packages/keras/backend.py:4907: UserWarning: "`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?"
  '"`sparse_categorical_crossentropy` received `from_logits=True`, but '


Epoch 1 Batch 0 Loss 4.4735 Accuracy 0.0000
Epoch 1 Batch 50 Loss 4.2140 Accuracy 0.0030
Epoch 1 Batch 100 Loss 4.1867 Accuracy 0.0151
Epoch 1 Batch 150 Loss 4.1394 Accuracy 0.0195
Epoch 1 Batch 200 Loss 4.0686 Accuracy 0.0261
Epoch 1 Batch 250 Loss 3.9926 Accuracy 0.0342
Epoch 1 Batch 300 Loss 3.9032 Accuracy 0.0396
Epoch 1 Batch 350 Loss 3.8193 Accuracy 0.0438
Epoch 1 Batch 400 Loss 3.7331 Accuracy 0.0472
Epoch 1 Batch 450 Loss 3.6467 Accuracy 0.0520
Epoch 1 Batch 500 Loss 3.5620 Accuracy 0.0580
Epoch 1 Batch 550 Loss 3.4791 Accuracy 0.0647
Epoch 1 Batch 600 Loss 3.3928 Accuracy 0.0722
Epoch 1 Batch 650 Loss 3.3050 Accuracy 0.0804
Epoch 1 Batch 700 Loss 3.2147 Accuracy 0.0884
Epoch 1 Loss 3.2126 Accuracy 0.0887
Time taken for 1 epoch: 931.3518960475922 secs

Epoch 2 Batch 0 Loss 2.1738 Accuracy 0.2027
Epoch 2 Batch 50 Loss 1.8804 Accuracy 0.2144
Epoch 2 Batch 100 Loss 1.8061 Accuracy 0.2266
Epoch 2 Batch 150 Loss 1.7319 Accuracy 0.2366
Epoch 2 Batch 200 Loss 1.6622 Accuracy 0.2467
Epoch 2 Batch 250 Loss 1.6010 Accuracy 0.2561
Epoch 2 Batch 300 Loss 1.5416 Accuracy 0.2644
Epoch 2 Batch 350 Loss 1.4910 Accuracy 0.2720
Epoch 2 Batch 400 Loss 1.4425 Accuracy 0.2788
Epoch 2 Batch 450 Loss 1.3931 Accuracy 0.2846
Epoch 2 Batch 500 Loss 1.3492 Accuracy 0.2897
Epoch 2 Batch 550 Loss 1.3049 Accuracy 0.2945
Epoch 2 Batch 600 Loss 1.2646 Accuracy 0.2993
Epoch 2 Batch 650 Loss 1.2268 Accuracy 0.3045
Epoch 2 Batch 700 Loss 1.1889 Accuracy 0.3088
Epoch 2 Loss 1.1872 Accuracy 0.3089
Time taken for 1 epoch: 878.3964555263519 secs

Epoch 3 Batch 0 Loss 0.7012 Accuracy 0.3709
Epoch 3 Batch 50 Loss 0.6513 Accuracy 0.3779
Epoch 3 Batch 100 Loss 0.6306 Accuracy 0.3825
Epoch 3 Batch 150 Loss 0.6076 Accuracy 0.3854
Epoch 3 Batch 200 Loss 0.5862 Accuracy 0.3889
Epoch 3 Batch 250 Loss 0.5626 Accuracy 0.3923
Epoch 3 Batch 300 Loss 0.5408 Accuracy 0.3962
Epoch 3 Batch 350 Loss 0.5193 Accuracy 0.3995
Epoch 3 Batch 400 Loss 0.4992 Accuracy 0.4032
Epoch 3 Batch 450 Loss 0.4803 Accuracy 0.4065
Epoch 3 Batch 500 Loss 0.4607 Accuracy 0.4088
Epoch 3 Batch 550 Loss 0.4430 Accuracy 0.4120
Epoch 3 Batch 600 Loss 0.4256 Accuracy 0.4150
Epoch 3 Batch 650 Loss 0.4084 Accuracy 0.4172
Epoch 3 Batch 700 Loss 0.3918 Accuracy 0.4201
Epoch 3 Loss 0.3911 Accuracy 0.4201
Time taken for 1 epoch: 878.9100172519684 secs

Epoch 4 Batch 0 Loss 0.1494 Accuracy 0.4347
Epoch 4 Batch 50 Loss 0.1458 Accuracy 0.4610
Epoch 4 Batch 100 Loss 0.1356 Accuracy 0.4609
Epoch 4 Batch 150 Loss 0.1269 Accuracy 0.4615
Epoch 4 Batch 200 Loss 0.1185 Accuracy 0.4626
Epoch 4 Batch 250 Loss 0.1106 Accuracy 0.4639
Epoch 4 Batch 300 Loss 0.1035 Accuracy 0.4654
Epoch 4 Batch 350 Loss 0.0966 Accuracy 0.4653
Epoch 4 Batch 400 Loss 0.0901 Accuracy 0.4656
Epoch 4 Batch 450 Loss 0.0843 Accuracy 0.4658
Epoch 4 Batch 500 Loss 0.0791 Accuracy 0.4667
Epoch 4 Batch 550 Loss 0.0743 Accuracy 0.4667
Epoch 4 Batch 600 Loss 0.0698 Accuracy 0.4671
Epoch 4 Batch 650 Loss 0.0659 Accuracy 0.4673
Epoch 4 Batch 700 Loss 0.0623 Accuracy 0.4676
Epoch 4 Loss 0.0622 Accuracy 0.4675
Time taken for 1 epoch: 876.3038239479065 secs

Epoch 5 Batch 0 Loss 0.0117 Accuracy 0.4605
Epoch 5 Batch 50 Loss 0.0130 Accuracy 0.4672
Epoch 5 Batch 100 Loss 0.0126 Accuracy 0.4679
Epoch 5 Batch 150 Loss 0.0121 Accuracy 0.4712
Epoch 5 Batch 200 Loss 0.0114 Accuracy 0.4714
Epoch 5 Batch 250 Loss 0.0108 Accuracy 0.4705
Epoch 5 Batch 300 Loss 0.0102 Accuracy 0.4697
Epoch 5 Batch 350 Loss 0.0097 Accuracy 0.4688
Epoch 5 Batch 400 Loss 0.0095 Accuracy 0.4699
Epoch 5 Batch 450 Loss 0.0093 Accuracy 0.4699
Epoch 5 Batch 500 Loss 0.0092 Accuracy 0.4711
Epoch 5 Batch 550 Loss 0.0089 Accuracy 0.4713
Epoch 5 Batch 600 Loss 0.0087 Accuracy 0.4709
Epoch 5 Batch 650 Loss 0.0085 Accuracy 0.4710
Epoch 5 Batch 700 Loss 0.0082 Accuracy 0.4712
Saving checkpoint for epoch 5 at ./checkpoints/train/ckpt-1
Epoch 5 Loss 0.0082 Accuracy 0.4712
Time taken for 1 epoch: 878.6954836845398 secs

Epoch 6 Batch 0 Loss 0.0059 Accuracy 0.4674
Epoch 6 Batch 50 Loss 0.0077 Accuracy 0.4734
Epoch 6 Batch 100 Loss 0.0066 Accuracy 0.4704
Epoch 6 Batch 150 Loss 0.0062 Accuracy 0.4702
Epoch 6 Batch 200 Loss 0.0064 Accuracy 0.4696
Epoch 6 Batch 250 Loss 0.0062 Accuracy 0.4698
Epoch 6 Batch 300 Loss 0.0061 Accuracy 0.4709
Epoch 6 Batch 350 Loss 0.0060 Accuracy 0.4704
Epoch 6 Batch 400 Loss 0.0059 Accuracy 0.4702
Epoch 6 Batch 450 Loss 0.0059 Accuracy 0.4703
Epoch 6 Batch 500 Loss 0.0059 Accuracy 0.4706
Epoch 6 Batch 550 Loss 0.0058 Accuracy 0.4706
Epoch 6 Batch 600 Loss 0.0057 Accuracy 0.4709
Epoch 6 Batch 650 Loss 0.0055 Accuracy 0.4711
Epoch 6 Batch 700 Loss 0.0055 Accuracy 0.4710
Epoch 6 Loss 0.0056 Accuracy 0.4709
Time taken for 1 epoch: 877.8011014461517 secs

Epoch 7 Batch 0 Loss 0.0037 Accuracy 0.4639
Epoch 7 Batch 50 Loss 0.0053 Accuracy 0.4670
Epoch 7 Batch 100 Loss 0.0048 Accuracy 0.4698
Epoch 7 Batch 150 Loss 0.0049 Accuracy 0.4722
Epoch 7 Batch 200 Loss 0.0048 Accuracy 0.4723
Epoch 7 Batch 250 Loss 0.0048 Accuracy 0.4707
Epoch 7 Batch 300 Loss 0.0046 Accuracy 0.4708
Epoch 7 Batch 350 Loss 0.0046 Accuracy 0.4704
Epoch 7 Batch 400 Loss 0.0047 Accuracy 0.4694
Epoch 7 Batch 450 Loss 0.0046 Accuracy 0.4699
Epoch 7 Batch 500 Loss 0.0045 Accuracy 0.4704
Epoch 7 Batch 550 Loss 0.0045 Accuracy 0.4705
Epoch 7 Batch 600 Loss 0.0044 Accuracy 0.4704
Epoch 7 Batch 650 Loss 0.0044 Accuracy 0.4703
Epoch 7 Batch 700 Loss 0.0044 Accuracy 0.4707
Epoch 7 Loss 0.0044 Accuracy 0.4707
Time taken for 1 epoch: 877.6704905033112 secs

Epoch 8 Batch 0 Loss 0.0043 Accuracy 0.4354
Epoch 8 Batch 50 Loss 0.0041 Accuracy 0.4712
Epoch 8 Batch 100 Loss 0.0040 Accuracy 0.4708
Epoch 8 Batch 150 Loss 0.0037 Accuracy 0.4711
Epoch 8 Batch 200 Loss 0.0035 Accuracy 0.4703
Epoch 8 Batch 250 Loss 0.0034 Accuracy 0.4696
Epoch 8 Batch 300 Loss 0.0033 Accuracy 0.4704
Epoch 8 Batch 350 Loss 0.0032 Accuracy 0.4705
Epoch 8 Batch 400 Loss 0.0033 Accuracy 0.4708
Epoch 8 Batch 450 Loss 0.0033 Accuracy 0.4707
Epoch 8 Batch 500 Loss 0.0033 Accuracy 0.4708
Epoch 8 Batch 550 Loss 0.0033 Accuracy 0.4714
Epoch 8 Batch 600 Loss 0.0033 Accuracy 0.4717
Epoch 8 Batch 650 Loss 0.0033 Accuracy 0.4720
Epoch 8 Batch 700 Loss 0.0033 Accuracy 0.4717
Epoch 8 Loss 0.0033 Accuracy 0.4717
Time taken for 1 epoch: 871.3958556652069 secs

Epoch 9 Batch 0 Loss 0.0122 Accuracy 0.4700
Epoch 9 Batch 50 Loss 0.0029 Accuracy 0.4676
Epoch 9 Batch 100 Loss 0.0030 Accuracy 0.4734
Epoch 9 Batch 150 Loss 0.0030 Accuracy 0.4718
Epoch 9 Batch 200 Loss 0.0029 Accuracy 0.4721
Epoch 9 Batch 250 Loss 0.0028 Accuracy 0.4713
Epoch 9 Batch 300 Loss 0.0028 Accuracy 0.4717
Epoch 9 Batch 350 Loss 0.0028 Accuracy 0.4704
Epoch 9 Batch 400 Loss 0.0028 Accuracy 0.4703
Epoch 9 Batch 450 Loss 0.0028 Accuracy 0.4701
Epoch 9 Batch 500 Loss 0.0028 Accuracy 0.4710
Epoch 9 Batch 550 Loss 0.0028 Accuracy 0.4709
Epoch 9 Batch 600 Loss 0.0028 Accuracy 0.4704
Epoch 9 Batch 650 Loss 0.0028 Accuracy 0.4704
Epoch 9 Batch 700 Loss 0.0028 Accuracy 0.4706
Epoch 9 Loss 0.0028 Accuracy 0.4707
Time taken for 1 epoch: 877.2159721851349 secs

Epoch 10 Batch 0 Loss 0.0082 Accuracy 0.4655
Epoch 10 Batch 50 Loss 0.0024 Accuracy 0.4676
Epoch 10 Batch 100 Loss 0.0026 Accuracy 0.4686
Epoch 10 Batch 150 Loss 0.0025 Accuracy 0.4703
Epoch 10 Batch 200 Loss 0.0026 Accuracy 0.4698
Epoch 10 Batch 250 Loss 0.0027 Accuracy 0.4690
Epoch 10 Batch 300 Loss 0.0027 Accuracy 0.4687
Epoch 10 Batch 350 Loss 0.0027 Accuracy 0.4704
Epoch 10 Batch 400 Loss 0.0028 Accuracy 0.4704
Epoch 10 Batch 450 Loss 0.0027 Accuracy 0.4700
Epoch 10 Batch 500 Loss 0.0027 Accuracy 0.4707
Epoch 10 Batch 550 Loss 0.0027 Accuracy 0.4705
Epoch 10 Batch 600 Loss 0.0026 Accuracy 0.4704
Epoch 10 Batch 650 Loss 0.0026 Accuracy 0.4707
Epoch 10 Batch 700 Loss 0.0026 Accuracy 0.4708
Saving checkpoint for epoch 10 at ./checkpoints/train/ckpt-2
Epoch 10 Loss 0.0026 Accuracy 0.4709
Time taken for 1 epoch: 879.2923848628998 secs

Epoch 11 Batch 0 Loss 0.0007 Accuracy 0.4331
Epoch 11 Batch 50 Loss 0.0025 Accuracy 0.4653
Epoch 11 Batch 100 Loss 0.0024 Accuracy 0.4699
Epoch 11 Batch 150 Loss 0.0024 Accuracy 0.4715
Epoch 11 Batch 200 Loss 0.0022 Accuracy 0.4713
Epoch 11 Batch 250 Loss 0.0023 Accuracy 0.4725
Epoch 11 Batch 300 Loss 0.0023 Accuracy 0.4724
Epoch 11 Batch 350 Loss 0.0023 Accuracy 0.4721
Epoch 11 Batch 400 Loss 0.0022 Accuracy 0.4718
Epoch 11 Batch 450 Loss 0.0022 Accuracy 0.4718
Epoch 11 Batch 500 Loss 0.0022 Accuracy 0.4719
Epoch 11 Batch 550 Loss 0.0021 Accuracy 0.4719
Epoch 11 Batch 600 Loss 0.0021 Accuracy 0.4715
Epoch 11 Batch 650 Loss 0.0021 Accuracy 0.4710
Epoch 11 Batch 700 Loss 0.0022 Accuracy 0.4711
Epoch 11 Loss 0.0022 Accuracy 0.4711
Time taken for 1 epoch: 878.5343689918518 secs

Epoch 12 Batch 0 Loss 0.0007 Accuracy 0.4329
Epoch 12 Batch 50 Loss 0.0025 Accuracy 0.4751
Epoch 12 Batch 100 Loss 0.0027 Accuracy 0.4730
Epoch 12 Batch 150 Loss 0.0025 Accuracy 0.4719
Epoch 12 Batch 200 Loss 0.0023 Accuracy 0.4706
Epoch 12 Batch 250 Loss 0.0022 Accuracy 0.4717
Epoch 12 Batch 300 Loss 0.0023 Accuracy 0.4711
Epoch 12 Batch 350 Loss 0.0023 Accuracy 0.4705
Epoch 12 Batch 400 Loss 0.0022 Accuracy 0.4713
Epoch 12 Batch 450 Loss 0.0022 Accuracy 0.4710
Epoch 12 Batch 500 Loss 0.0022 Accuracy 0.4708
Epoch 12 Batch 550 Loss 0.0022 Accuracy 0.4709
Epoch 12 Batch 600 Loss 0.0022 Accuracy 0.4708
Epoch 12 Batch 650 Loss 0.0021 Accuracy 0.4704
Epoch 12 Batch 700 Loss 0.0022 Accuracy 0.4703
Epoch 12 Loss 0.0022 Accuracy 0.4703
Time taken for 1 epoch: 876.938019990921 secs

Epoch 13 Batch 0 Loss 0.0006 Accuracy 0.4633
Epoch 13 Batch 50 Loss 0.0013 Accuracy 0.4619
Epoch 13 Batch 200 Loss 0.0016 Accuracy 0.4688
Epoch 13 Batch 250 Loss 0.0017 Accuracy 0.4707
Epoch 13 Batch 300 Loss 0.0018 Accuracy 0.4710
Epoch 13 Batch 350 Loss 0.0017 Accuracy 0.4714
Epoch 13 Batch 400 Loss 0.0018 Accuracy 0.4710
Epoch 13 Batch 450 Loss 0.0017 Accuracy 0.4712
Epoch 13 Batch 500 Loss 0.0017 Accuracy 0.4714
Epoch 13 Batch 550 Loss 0.0017 Accuracy 0.4716
Epoch 13 Batch 600 Loss 0.0018 Accuracy 0.4713
Epoch 13 Batch 650 Loss 0.0017 Accuracy 0.4712
Epoch 13 Batch 700 Loss 0.0017 Accuracy 0.4712
Epoch 13 Loss 0.0017 Accuracy 0.4712
Time taken for 1 epoch: 859.017169713974 secs

Epoch 14 Batch 0 Loss 0.0024 Accuracy 0.4848
Epoch 14 Batch 50 Loss 0.0016 Accuracy 0.4745
Epoch 14 Batch 100 Loss 0.0014 Accuracy 0.4715
Epoch 14 Batch 150 Loss 0.0016 Accuracy 0.4719
Epoch 14 Batch 200 Loss 0.0017 Accuracy 0.4732
Epoch 14 Batch 250 Loss 0.0017 Accuracy 0.4718
Epoch 14 Batch 300 Loss 0.0018 Accuracy 0.4714
Epoch 14 Batch 350 Loss 0.0017 Accuracy 0.4710
Epoch 14 Batch 400 Loss 0.0018 Accuracy 0.4711
Epoch 14 Batch 450 Loss 0.0017 Accuracy 0.4701
Epoch 14 Batch 500 Loss 0.0018 Accuracy 0.4709
Epoch 14 Batch 550 Loss 0.0018 Accuracy 0.4711
Epoch 14 Batch 600 Loss 0.0018 Accuracy 0.4713
Epoch 14 Batch 650 Loss 0.0018 Accuracy 0.4717
Epoch 14 Batch 700 Loss 0.0018 Accuracy 0.4716
Epoch 14 Loss 0.0018 Accuracy 0.4716
Time taken for 1 epoch: 857.9521288871765 secs

Epoch 15 Batch 0 Loss 0.0056 Accuracy 0.4800
Epoch 15 Batch 50 Loss 0.0022 Accuracy 0.4709
Epoch 15 Batch 100 Loss 0.0019 Accuracy 0.4722
Epoch 15 Batch 150 Loss 0.0018 Accuracy 0.4707
Epoch 15 Batch 200 Loss 0.0018 Accuracy 0.4706
Epoch 15 Batch 250 Loss 0.0018 Accuracy 0.4715
Epoch 15 Batch 300 Loss 0.0017 Accuracy 0.4703
Epoch 15 Batch 350 Loss 0.0017 Accuracy 0.4699
Epoch 15 Batch 400 Loss 0.0017 Accuracy 0.4700
Epoch 15 Batch 450 Loss 0.0017 Accuracy 0.4707
Epoch 15 Batch 500 Loss 0.0017 Accuracy 0.4711
Epoch 15 Batch 550 Loss 0.0017 Accuracy 0.4699
Epoch 15 Batch 600 Loss 0.0016 Accuracy 0.4702
Epoch 15 Batch 650 Loss 0.0016 Accuracy 0.4706
Epoch 15 Batch 700 Loss 0.0016 Accuracy 0.4708
Saving checkpoint for epoch 15 at ./checkpoints/train/ckpt-3
Epoch 15 Loss 0.0016 Accuracy 0.4707
Time taken for 1 epoch: 854.1302998065948 secs

Epoch 16 Batch 0 Loss 0.0003 Accuracy 0.4543
Epoch 16 Batch 50 Loss 0.0015 Accuracy 0.4704
Epoch 16 Batch 100 Loss 0.0013 Accuracy 0.4686
Epoch 16 Batch 150 Loss 0.0013 Accuracy 0.4687
Epoch 16 Batch 200 Loss 0.0014 Accuracy 0.4682
Epoch 16 Batch 250 Loss 0.0014 Accuracy 0.4698
Epoch 16 Batch 300 Loss 0.0014 Accuracy 0.4697
Epoch 16 Batch 350 Loss 0.0015 Accuracy 0.4707
Epoch 16 Batch 400 Loss 0.0015 Accuracy 0.4715
Epoch 16 Batch 450 Loss 0.0016 Accuracy 0.4712
Epoch 16 Batch 500 Loss 0.0016 Accuracy 0.4716
Epoch 16 Batch 550 Loss 0.0016 Accuracy 0.4715
Epoch 16 Batch 600 Loss 0.0016 Accuracy 0.4721
Epoch 16 Batch 650 Loss 0.0016 Accuracy 0.4717
Epoch 16 Batch 700 Loss 0.0015 Accuracy 0.4714
Epoch 16 Loss 0.0015 Accuracy 0.4714
Time taken for 1 epoch: 851.0064783096313 secs

Epoch 17 Batch 0 Loss 0.0003 Accuracy 0.4688
Epoch 17 Batch 50 Loss 0.0011 Accuracy 0.4727
Epoch 17 Batch 100 Loss 0.0014 Accuracy 0.4711
Epoch 17 Batch 150 Loss 0.0017 Accuracy 0.4718
Epoch 17 Batch 200 Loss 0.0017 Accuracy 0.4718
Epoch 17 Batch 250 Loss 0.0016 Accuracy 0.4724
Epoch 17 Batch 300 Loss 0.0016 Accuracy 0.4720
Epoch 17 Batch 350 Loss 0.0016 Accuracy 0.4707
Epoch 17 Batch 400 Loss 0.0015 Accuracy 0.4709
Epoch 17 Batch 450 Loss 0.0015 Accuracy 0.4717
Epoch 17 Batch 500 Loss 0.0014 Accuracy 0.4711
Epoch 17 Batch 550 Loss 0.0014 Accuracy 0.4714
Epoch 17 Batch 600 Loss 0.0014 Accuracy 0.4717
Epoch 17 Batch 650 Loss 0.0014 Accuracy 0.4723
Epoch 17 Batch 700 Loss 0.0014 Accuracy 0.4714
Epoch 17 Loss 0.0014 Accuracy 0.4715
Time taken for 1 epoch: 853.1788289546967 secs

Epoch 18 Batch 0 Loss 0.0006 Accuracy 0.4642
Epoch 18 Batch 50 Loss 0.0013 Accuracy 0.4678
Epoch 18 Batch 100 Loss 0.0012 Accuracy 0.4722
Epoch 18 Batch 150 Loss 0.0011 Accuracy 0.4726
Epoch 18 Batch 200 Loss 0.0010 Accuracy 0.4732
Epoch 18 Batch 250 Loss 0.0012 Accuracy 0.4719
Epoch 18 Batch 300 Loss 0.0012 Accuracy 0.4713
Epoch 18 Batch 350 Loss 0.0012 Accuracy 0.4721
Epoch 18 Batch 400 Loss 0.0012 Accuracy 0.4721
Epoch 18 Batch 450 Loss 0.0012 Accuracy 0.4715
Epoch 18 Batch 500 Loss 0.0012 Accuracy 0.4710
Epoch 18 Batch 550 Loss 0.0012 Accuracy 0.4704
Epoch 18 Batch 600 Loss 0.0013 Accuracy 0.4706
Epoch 18 Batch 650 Loss 0.0013 Accuracy 0.4710
Epoch 18 Batch 700 Loss 0.0013 Accuracy 0.4709
Epoch 18 Loss 0.0013 Accuracy 0.4710
Time taken for 1 epoch: 857.0118782520294 secs

Epoch 19 Batch 0 Loss 0.0002 Accuracy 0.4570
Epoch 19 Batch 50 Loss 0.0011 Accuracy 0.4778
Epoch 19 Batch 100 Loss 0.0016 Accuracy 0.4747
Epoch 19 Batch 150 Loss 0.0016 Accuracy 0.4735
Epoch 19 Batch 200 Loss 0.0016 Accuracy 0.4714
Epoch 19 Batch 250 Loss 0.0015 Accuracy 0.4710
Epoch 19 Batch 300 Loss 0.0015 Accuracy 0.4713
Epoch 19 Batch 350 Loss 0.0015 Accuracy 0.4711
Epoch 19 Batch 400 Loss 0.0015 Accuracy 0.4705
Epoch 19 Batch 450 Loss 0.0015 Accuracy 0.4702
Epoch 19 Batch 500 Loss 0.0014 Accuracy 0.4699
Epoch 19 Batch 550 Loss 0.0014 Accuracy 0.4699
Epoch 19 Batch 600 Loss 0.0014 Accuracy 0.4703
Epoch 19 Batch 650 Loss 0.0014 Accuracy 0.4708
Epoch 19 Batch 700 Loss 0.0014 Accuracy 0.4712
Epoch 19 Loss 0.0014 Accuracy 0.4712
Time taken for 1 epoch: 856.3480639457703 secs

Epoch 20 Batch 0 Loss 0.0008 Accuracy 0.4688
Epoch 20 Batch 50 Loss 0.0017 Accuracy 0.4751
Epoch 20 Batch 100 Loss 0.0011 Accuracy 0.4722
Epoch 20 Batch 150 Loss 0.0011 Accuracy 0.4716
Epoch 20 Batch 200 Loss 0.0012 Accuracy 0.4714
Epoch 20 Batch 250 Loss 0.0011 Accuracy 0.4724
Epoch 20 Batch 300 Loss 0.0011 Accuracy 0.4720
Epoch 20 Batch 350 Loss 0.0012 Accuracy 0.4723
Epoch 20 Batch 400 Loss 0.0012 Accuracy 0.4724
Epoch 20 Batch 450 Loss 0.0012 Accuracy 0.4718
Epoch 20 Batch 500 Loss 0.0012 Accuracy 0.4716
Epoch 20 Batch 550 Loss 0.0012 Accuracy 0.4711
Epoch 20 Batch 600 Loss 0.0012 Accuracy 0.4712
Epoch 20 Batch 650 Loss 0.0013 Accuracy 0.4712
Epoch 20 Batch 700 Loss 0.0013 Accuracy 0.4709
Saving checkpoint for epoch 20 at ./checkpoints/train/ckpt-4
Epoch 20 Loss 0.0013 Accuracy 0.4709
Time taken for 1 epoch: 858.4996719360352 secs
</code></pre></div></div>

<h2 id="conclusion">Conclusion</h2>

<p>You’ve come to the end of the graded portion of the assignment. By now, you’ve:</p>

<ul>
  <li>Create positional encodings to capture sequential relationships in data</li>
  <li>Calculate scaled dot-product self-attention with word embeddings</li>
  <li>Implement masked multi-head attention</li>
  <li>Build and train a Transformer model</li>
</ul>

<p><b>What you should remember</b>:</p>

<ul>
  <li>The combination of self-attention and convolutional network layers allows of parallization of training and <em>faster training</em>.</li>
  <li>Self-attention is calculated using the generated query Q, key K, and value V matrices.</li>
  <li>Adding positional encoding to word embeddings is an effective way of include sequence information in self-attention calculations.</li>
  <li>Multi-head attention can help detect multiple features in your sentence.</li>
  <li>Masking stops the model from ‘looking ahead’ during training, or weighting zeroes too much when processing cropped sentences.</li>
</ul>

<p>Now that you have completed the Transformer assignment, make sure you check out the ungraded labs to apply the Transformer model to practical use cases such as Name Entity Recogntion (NER) and Question Answering (QA).</p>

<h1 id="congratulations-on-finishing-the-deep-learning-specialization-">Congratulations on finishing the Deep Learning Specialization!!!!!! 🎉</h1>

<p>This was the last graded assignment of the specialization. It is now time to celebrate all your hard work and dedication!</p>

<p><a name="7"></a></p>
<h2 id="7---references">7 - References</h2>

<p>The Transformer algorithm was due to Vaswani et al. (2017).</p>

<ul>
  <li>Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin (2017). <a href="https://arxiv.org/abs/1706.03762">Attention Is All You Need</a></li>
</ul>

<p><strong>Training</strong>
This section describes the training regime for our models.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Batch</span><span class="p">:</span>
    <span class="s">"Object for holding a batch of data with mask during training."</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">trg</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">src</span> <span class="o">=</span> <span class="n">src</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">src_mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">src</span> <span class="o">!=</span> <span class="n">pad</span><span class="p">).</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">trg</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">trg</span> <span class="o">=</span> <span class="n">trg</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">trg_y</span> <span class="o">=</span> <span class="n">trg</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">trg_mask</span> <span class="o">=</span> \
                <span class="bp">self</span><span class="p">.</span><span class="n">make_std_mask</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">trg</span><span class="p">,</span> <span class="n">pad</span><span class="p">)</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">ntokens</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">trg_y</span> <span class="o">!=</span> <span class="n">pad</span><span class="p">).</span><span class="n">data</span><span class="p">.</span><span class="nb">sum</span><span class="p">()</span>
    
    <span class="o">@</span><span class="nb">staticmethod</span>
    <span class="k">def</span> <span class="nf">make_std_mask</span><span class="p">(</span><span class="n">tgt</span><span class="p">,</span> <span class="n">pad</span><span class="p">):</span>
        <span class="s">"Create a mask to hide padding and future words."</span>
        <span class="n">tgt_mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">tgt</span> <span class="o">!=</span> <span class="n">pad</span><span class="p">).</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">tgt_mask</span> <span class="o">=</span> <span class="n">tgt_mask</span> <span class="o">&amp;</span> <span class="n">Variable</span><span class="p">(</span>
            <span class="n">subsequent_mask</span><span class="p">(</span><span class="n">tgt</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)).</span><span class="n">type_as</span><span class="p">(</span><span class="n">tgt_mask</span><span class="p">.</span><span class="n">data</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">tgt_mask</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">run_epoch</span><span class="p">(</span><span class="n">data_iter</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">loss_compute</span><span class="p">):</span>
    <span class="s">"Standard Training and Logging Function"</span>
    <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">total_tokens</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">total_loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">data_iter</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">forward</span><span class="p">(</span><span class="n">batch</span><span class="p">.</span><span class="n">src</span><span class="p">,</span> <span class="n">batch</span><span class="p">.</span><span class="n">trg</span><span class="p">,</span> 
                            <span class="n">batch</span><span class="p">.</span><span class="n">src_mask</span><span class="p">,</span> <span class="n">batch</span><span class="p">.</span><span class="n">trg_mask</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_compute</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">batch</span><span class="p">.</span><span class="n">trg_y</span><span class="p">,</span> <span class="n">batch</span><span class="p">.</span><span class="n">ntokens</span><span class="p">)</span>
        <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span>
        <span class="n">total_tokens</span> <span class="o">+=</span> <span class="n">batch</span><span class="p">.</span><span class="n">ntokens</span>
        <span class="n">tokens</span> <span class="o">+=</span> <span class="n">batch</span><span class="p">.</span><span class="n">ntokens</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">50</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">elapsed</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span>
            <span class="k">print</span><span class="p">(</span><span class="s">"Epoch Step: %d Loss: %f Tokens per Sec: %f"</span> <span class="o">%</span>
                    <span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">loss</span> <span class="o">/</span> <span class="n">batch</span><span class="p">.</span><span class="n">ntokens</span><span class="p">,</span> <span class="n">tokens</span> <span class="o">/</span> <span class="n">elapsed</span><span class="p">))</span>
            <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="n">time</span><span class="p">()</span>
            <span class="n">tokens</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">return</span> <span class="n">total_loss</span> <span class="o">/</span> <span class="n">total_tokens</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">global</span> <span class="n">max_src_in_batch</span><span class="p">,</span> <span class="n">max_tgt_in_batch</span>
<span class="k">def</span> <span class="nf">batch_size_fn</span><span class="p">(</span><span class="n">new</span><span class="p">,</span> <span class="n">count</span><span class="p">,</span> <span class="n">sofar</span><span class="p">):</span>
    <span class="s">"Keep augmenting batch and calculate total number of tokens + padding."</span>
    <span class="k">global</span> <span class="n">max_src_in_batch</span><span class="p">,</span> <span class="n">max_tgt_in_batch</span>
    <span class="k">if</span> <span class="n">count</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">max_src_in_batch</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">max_tgt_in_batch</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">max_src_in_batch</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">max_src_in_batch</span><span class="p">,</span>  <span class="nb">len</span><span class="p">(</span><span class="n">new</span><span class="p">.</span><span class="n">src</span><span class="p">))</span>
    <span class="n">max_tgt_in_batch</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">max_tgt_in_batch</span><span class="p">,</span>  <span class="nb">len</span><span class="p">(</span><span class="n">new</span><span class="p">.</span><span class="n">trg</span><span class="p">)</span> <span class="o">+</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">src_elements</span> <span class="o">=</span> <span class="n">count</span> <span class="o">*</span> <span class="n">max_src_in_batch</span>
    <span class="n">tgt_elements</span> <span class="o">=</span> <span class="n">count</span> <span class="o">*</span> <span class="n">max_tgt_in_batch</span>
    <span class="k">return</span> <span class="nb">max</span><span class="p">(</span><span class="n">src_elements</span><span class="p">,</span> <span class="n">tgt_elements</span><span class="p">)</span>
</code></pre></div></div>]]></content><author><name>Zhu Tianda</name></author><category term="coding" /><category term="AI" /><summary type="html"><![CDATA[I update this document also refere to https://www.tensorflow.org/tutorials/text/transformer?hl=zh-cn https://nlp.seas.harvard.edu/2018/04/03/attention.html#positional-encoding]]></summary></entry><entry><title type="html">transformer implementation</title><link href="http://0.0.0.0:8855/coding/2023/11/02/transformer-implementation.html" rel="alternate" type="text/html" title="transformer implementation" /><published>2023-11-02T00:00:00+08:00</published><updated>2023-11-02T00:00:00+08:00</updated><id>http://0.0.0.0:8855/coding/2023/11/02/transformer-implementation</id><content type="html" xml:base="http://0.0.0.0:8855/coding/2023/11/02/transformer-implementation.html"><![CDATA[<!DOCTYPE html>

<html lang="en">
<head><meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>transformer_implementation</title><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<style type="text/css">
    pre { line-height: 125%; }
td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
.highlight .hll { background-color: var(--jp-cell-editor-active-background) }
.highlight { background: var(--jp-cell-editor-background); color: var(--jp-mirror-editor-variable-color) }
.highlight .c { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment */
.highlight .err { color: var(--jp-mirror-editor-error-color) } /* Error */
.highlight .k { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword */
.highlight .o { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator */
.highlight .p { color: var(--jp-mirror-editor-punctuation-color) } /* Punctuation */
.highlight .ch { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Multiline */
.highlight .cp { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Preproc */
.highlight .cpf { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Single */
.highlight .cs { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Special */
.highlight .kc { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Pseudo */
.highlight .kr { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Type */
.highlight .m { color: var(--jp-mirror-editor-number-color) } /* Literal.Number */
.highlight .s { color: var(--jp-mirror-editor-string-color) } /* Literal.String */
.highlight .ow { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator.Word */
.highlight .pm { color: var(--jp-mirror-editor-punctuation-color) } /* Punctuation.Marker */
.highlight .w { color: var(--jp-mirror-editor-variable-color) } /* Text.Whitespace */
.highlight .mb { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Bin */
.highlight .mf { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Float */
.highlight .mh { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Hex */
.highlight .mi { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer */
.highlight .mo { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Oct */
.highlight .sa { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Affix */
.highlight .sb { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Backtick */
.highlight .sc { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Char */
.highlight .dl { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Delimiter */
.highlight .sd { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Doc */
.highlight .s2 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Double */
.highlight .se { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Escape */
.highlight .sh { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Heredoc */
.highlight .si { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Interpol */
.highlight .sx { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Other */
.highlight .sr { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Regex */
.highlight .s1 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Single */
.highlight .ss { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Symbol */
.highlight .il { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer.Long */
  </style>
<style type="text/css">
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*
 * Mozilla scrollbar styling
 */

/* use standard opaque scrollbars for most nodes */
[data-jp-theme-scrollbars='true'] {
  scrollbar-color: rgb(var(--jp-scrollbar-thumb-color))
    var(--jp-scrollbar-background-color);
}

/* for code nodes, use a transparent style of scrollbar. These selectors
 * will match lower in the tree, and so will override the above */
[data-jp-theme-scrollbars='true'] .CodeMirror-hscrollbar,
[data-jp-theme-scrollbars='true'] .CodeMirror-vscrollbar {
  scrollbar-color: rgba(var(--jp-scrollbar-thumb-color), 0.5) transparent;
}

/* tiny scrollbar */

.jp-scrollbar-tiny {
  scrollbar-color: rgba(var(--jp-scrollbar-thumb-color), 0.5) transparent;
  scrollbar-width: thin;
}

/* tiny scrollbar */

.jp-scrollbar-tiny::-webkit-scrollbar,
.jp-scrollbar-tiny::-webkit-scrollbar-corner {
  background-color: transparent;
  height: 4px;
  width: 4px;
}

.jp-scrollbar-tiny::-webkit-scrollbar-thumb {
  background: rgba(var(--jp-scrollbar-thumb-color), 0.5);
}

.jp-scrollbar-tiny::-webkit-scrollbar-track:horizontal {
  border-left: 0 solid transparent;
  border-right: 0 solid transparent;
}

.jp-scrollbar-tiny::-webkit-scrollbar-track:vertical {
  border-top: 0 solid transparent;
  border-bottom: 0 solid transparent;
}

/*
 * Lumino
 */

.lm-ScrollBar[data-orientation='horizontal'] {
  min-height: 16px;
  max-height: 16px;
  min-width: 45px;
  border-top: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='vertical'] {
  min-width: 16px;
  max-width: 16px;
  min-height: 45px;
  border-left: 1px solid #a0a0a0;
}

.lm-ScrollBar-button {
  background-color: #f0f0f0;
  background-position: center center;
  min-height: 15px;
  max-height: 15px;
  min-width: 15px;
  max-width: 15px;
}

.lm-ScrollBar-button:hover {
  background-color: #dadada;
}

.lm-ScrollBar-button.lm-mod-active {
  background-color: #cdcdcd;
}

.lm-ScrollBar-track {
  background: #f0f0f0;
}

.lm-ScrollBar-thumb {
  background: #cdcdcd;
}

.lm-ScrollBar-thumb:hover {
  background: #bababa;
}

.lm-ScrollBar-thumb.lm-mod-active {
  background: #a0a0a0;
}

.lm-ScrollBar[data-orientation='horizontal'] .lm-ScrollBar-thumb {
  height: 100%;
  min-width: 15px;
  border-left: 1px solid #a0a0a0;
  border-right: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='vertical'] .lm-ScrollBar-thumb {
  width: 100%;
  min-height: 15px;
  border-top: 1px solid #a0a0a0;
  border-bottom: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='horizontal']
  .lm-ScrollBar-button[data-action='decrement'] {
  background-image: var(--jp-icon-caret-left);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='horizontal']
  .lm-ScrollBar-button[data-action='increment'] {
  background-image: var(--jp-icon-caret-right);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='vertical']
  .lm-ScrollBar-button[data-action='decrement'] {
  background-image: var(--jp-icon-caret-up);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='vertical']
  .lm-ScrollBar-button[data-action='increment'] {
  background-image: var(--jp-icon-caret-down);
  background-size: 17px;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-Widget {
  box-sizing: border-box;
  position: relative;
  overflow: hidden;
}

.lm-Widget.lm-mod-hidden {
  display: none !important;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.lm-AccordionPanel[data-orientation='horizontal'] > .lm-AccordionPanel-title {
  /* Title is rotated for horizontal accordion panel using CSS */
  display: block;
  transform-origin: top left;
  transform: rotate(-90deg) translate(-100%);
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-CommandPalette {
  display: flex;
  flex-direction: column;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-CommandPalette-search {
  flex: 0 0 auto;
}

.lm-CommandPalette-content {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  min-height: 0;
  overflow: auto;
  list-style-type: none;
}

.lm-CommandPalette-header {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.lm-CommandPalette-item {
  display: flex;
  flex-direction: row;
}

.lm-CommandPalette-itemIcon {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemContent {
  flex: 1 1 auto;
  overflow: hidden;
}

.lm-CommandPalette-itemShortcut {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemLabel {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.lm-close-icon {
  border: 1px solid transparent;
  background-color: transparent;
  position: absolute;
  z-index: 1;
  right: 3%;
  top: 0;
  bottom: 0;
  margin: auto;
  padding: 7px 0;
  display: none;
  vertical-align: middle;
  outline: 0;
  cursor: pointer;
}
.lm-close-icon:after {
  content: 'X';
  display: block;
  width: 15px;
  height: 15px;
  text-align: center;
  color: #000;
  font-weight: normal;
  font-size: 12px;
  cursor: pointer;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-DockPanel {
  z-index: 0;
}

.lm-DockPanel-widget {
  z-index: 0;
}

.lm-DockPanel-tabBar {
  z-index: 1;
}

.lm-DockPanel-handle {
  z-index: 2;
}

.lm-DockPanel-handle.lm-mod-hidden {
  display: none !important;
}

.lm-DockPanel-handle:after {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  content: '';
}

.lm-DockPanel-handle[data-orientation='horizontal'] {
  cursor: ew-resize;
}

.lm-DockPanel-handle[data-orientation='vertical'] {
  cursor: ns-resize;
}

.lm-DockPanel-handle[data-orientation='horizontal']:after {
  left: 50%;
  min-width: 8px;
  transform: translateX(-50%);
}

.lm-DockPanel-handle[data-orientation='vertical']:after {
  top: 50%;
  min-height: 8px;
  transform: translateY(-50%);
}

.lm-DockPanel-overlay {
  z-index: 3;
  box-sizing: border-box;
  pointer-events: none;
}

.lm-DockPanel-overlay.lm-mod-hidden {
  display: none !important;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-Menu {
  z-index: 10000;
  position: absolute;
  white-space: nowrap;
  overflow-x: hidden;
  overflow-y: auto;
  outline: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-Menu-content {
  margin: 0;
  padding: 0;
  display: table;
  list-style-type: none;
}

.lm-Menu-item {
  display: table-row;
}

.lm-Menu-item.lm-mod-hidden,
.lm-Menu-item.lm-mod-collapsed {
  display: none !important;
}

.lm-Menu-itemIcon,
.lm-Menu-itemSubmenuIcon {
  display: table-cell;
  text-align: center;
}

.lm-Menu-itemLabel {
  display: table-cell;
  text-align: left;
}

.lm-Menu-itemShortcut {
  display: table-cell;
  text-align: right;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-MenuBar {
  outline: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-MenuBar-content {
  margin: 0;
  padding: 0;
  display: flex;
  flex-direction: row;
  list-style-type: none;
}

.lm-MenuBar-item {
  box-sizing: border-box;
}

.lm-MenuBar-itemIcon,
.lm-MenuBar-itemLabel {
  display: inline-block;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-ScrollBar {
  display: flex;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-ScrollBar[data-orientation='horizontal'] {
  flex-direction: row;
}

.lm-ScrollBar[data-orientation='vertical'] {
  flex-direction: column;
}

.lm-ScrollBar-button {
  box-sizing: border-box;
  flex: 0 0 auto;
}

.lm-ScrollBar-track {
  box-sizing: border-box;
  position: relative;
  overflow: hidden;
  flex: 1 1 auto;
}

.lm-ScrollBar-thumb {
  box-sizing: border-box;
  position: absolute;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-SplitPanel-child {
  z-index: 0;
}

.lm-SplitPanel-handle {
  z-index: 1;
}

.lm-SplitPanel-handle.lm-mod-hidden {
  display: none !important;
}

.lm-SplitPanel-handle:after {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  content: '';
}

.lm-SplitPanel[data-orientation='horizontal'] > .lm-SplitPanel-handle {
  cursor: ew-resize;
}

.lm-SplitPanel[data-orientation='vertical'] > .lm-SplitPanel-handle {
  cursor: ns-resize;
}

.lm-SplitPanel[data-orientation='horizontal'] > .lm-SplitPanel-handle:after {
  left: 50%;
  min-width: 8px;
  transform: translateX(-50%);
}

.lm-SplitPanel[data-orientation='vertical'] > .lm-SplitPanel-handle:after {
  top: 50%;
  min-height: 8px;
  transform: translateY(-50%);
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-TabBar {
  display: flex;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-TabBar[data-orientation='horizontal'] {
  flex-direction: row;
  align-items: flex-end;
}

.lm-TabBar[data-orientation='vertical'] {
  flex-direction: column;
  align-items: flex-end;
}

.lm-TabBar-content {
  margin: 0;
  padding: 0;
  display: flex;
  flex: 1 1 auto;
  list-style-type: none;
}

.lm-TabBar[data-orientation='horizontal'] > .lm-TabBar-content {
  flex-direction: row;
}

.lm-TabBar[data-orientation='vertical'] > .lm-TabBar-content {
  flex-direction: column;
}

.lm-TabBar-tab {
  display: flex;
  flex-direction: row;
  box-sizing: border-box;
  overflow: hidden;
  touch-action: none; /* Disable native Drag/Drop */
}

.lm-TabBar-tabIcon,
.lm-TabBar-tabCloseIcon {
  flex: 0 0 auto;
}

.lm-TabBar-tabLabel {
  flex: 1 1 auto;
  overflow: hidden;
  white-space: nowrap;
}

.lm-TabBar-tabInput {
  user-select: all;
  width: 100%;
  box-sizing: border-box;
}

.lm-TabBar-tab.lm-mod-hidden {
  display: none !important;
}

.lm-TabBar-addButton.lm-mod-hidden {
  display: none !important;
}

.lm-TabBar.lm-mod-dragging .lm-TabBar-tab {
  position: relative;
}

.lm-TabBar.lm-mod-dragging[data-orientation='horizontal'] .lm-TabBar-tab {
  left: 0;
  transition: left 150ms ease;
}

.lm-TabBar.lm-mod-dragging[data-orientation='vertical'] .lm-TabBar-tab {
  top: 0;
  transition: top 150ms ease;
}

.lm-TabBar.lm-mod-dragging .lm-TabBar-tab.lm-mod-dragging {
  transition: none;
}

.lm-TabBar-tabLabel .lm-TabBar-tabInput {
  user-select: all;
  width: 100%;
  box-sizing: border-box;
  background: inherit;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-TabPanel-tabBar {
  z-index: 1;
}

.lm-TabPanel-stackedPanel {
  z-index: 0;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Collapse {
  display: flex;
  flex-direction: column;
  align-items: stretch;
}

.jp-Collapse-header {
  padding: 1px 12px;
  background-color: var(--jp-layout-color1);
  border-bottom: solid var(--jp-border-width) var(--jp-border-color2);
  color: var(--jp-ui-font-color1);
  cursor: pointer;
  display: flex;
  align-items: center;
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  text-transform: uppercase;
  user-select: none;
}

.jp-Collapser-icon {
  height: 16px;
}

.jp-Collapse-header-collapsed .jp-Collapser-icon {
  transform: rotate(-90deg);
  margin: auto 0;
}

.jp-Collapser-title {
  line-height: 25px;
}

.jp-Collapse-contents {
  padding: 0 12px;
  background-color: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  overflow: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensureUiComponents() in @jupyterlab/buildutils */

/**
 * (DEPRECATED) Support for consuming icons as CSS background images
 */

/* Icons urls */

:root {
  --jp-icon-add-above: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGcgY2xpcC1wYXRoPSJ1cmwoI2NsaXAwXzEzN18xOTQ5MikiPgo8cGF0aCBjbGFzcz0ianAtaWNvbjMiIGQ9Ik00Ljc1IDQuOTMwNjZINi42MjVWNi44MDU2NkM2LjYyNSA3LjAxMTkxIDYuNzkzNzUgNy4xODA2NiA3IDcuMTgwNjZDNy4yMDYyNSA3LjE4MDY2IDcuMzc1IDcuMDExOTEgNy4zNzUgNi44MDU2NlY0LjkzMDY2SDkuMjVDOS40NTYyNSA0LjkzMDY2IDkuNjI1IDQuNzYxOTEgOS42MjUgNC41NTU2NkM5LjYyNSA0LjM0OTQxIDkuNDU2MjUgNC4xODA2NiA5LjI1IDQuMTgwNjZINy4zNzVWMi4zMDU2NkM3LjM3NSAyLjA5OTQxIDcuMjA2MjUgMS45MzA2NiA3IDEuOTMwNjZDNi43OTM3NSAxLjkzMDY2IDYuNjI1IDIuMDk5NDEgNi42MjUgMi4zMDU2NlY0LjE4MDY2SDQuNzVDNC41NDM3NSA0LjE4MDY2IDQuMzc1IDQuMzQ5NDEgNC4zNzUgNC41NTU2NkM0LjM3NSA0Ljc2MTkxIDQuNTQzNzUgNC45MzA2NiA0Ljc1IDQuOTMwNjZaIiBmaWxsPSIjNjE2MTYxIiBzdHJva2U9IiM2MTYxNjEiIHN0cm9rZS13aWR0aD0iMC43Ii8+CjwvZz4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiIGNsaXAtcnVsZT0iZXZlbm9kZCIgZD0iTTExLjUgOS41VjExLjVMMi41IDExLjVWOS41TDExLjUgOS41Wk0xMiA4QzEyLjU1MjMgOCAxMyA4LjQ0NzcyIDEzIDlWMTJDMTMgMTIuNTUyMyAxMi41NTIzIDEzIDEyIDEzTDIgMTNDMS40NDc3MiAxMyAxIDEyLjU1MjMgMSAxMlY5QzEgOC40NDc3MiAxLjQ0NzcxIDggMiA4TDEyIDhaIiBmaWxsPSIjNjE2MTYxIi8+CjxkZWZzPgo8Y2xpcFBhdGggaWQ9ImNsaXAwXzEzN18xOTQ5MiI+CjxyZWN0IGNsYXNzPSJqcC1pY29uMyIgd2lkdGg9IjYiIGhlaWdodD0iNiIgZmlsbD0id2hpdGUiIHRyYW5zZm9ybT0ibWF0cml4KC0xIDAgMCAxIDEwIDEuNTU1NjYpIi8+CjwvY2xpcFBhdGg+CjwvZGVmcz4KPC9zdmc+Cg==);
  --jp-icon-add-below: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGcgY2xpcC1wYXRoPSJ1cmwoI2NsaXAwXzEzN18xOTQ5OCkiPgo8cGF0aCBjbGFzcz0ianAtaWNvbjMiIGQ9Ik05LjI1IDEwLjA2OTNMNy4zNzUgMTAuMDY5M0w3LjM3NSA4LjE5NDM0QzcuMzc1IDcuOTg4MDkgNy4yMDYyNSA3LjgxOTM0IDcgNy44MTkzNEM2Ljc5Mzc1IDcuODE5MzQgNi42MjUgNy45ODgwOSA2LjYyNSA4LjE5NDM0TDYuNjI1IDEwLjA2OTNMNC43NSAxMC4wNjkzQzQuNTQzNzUgMTAuMDY5MyA0LjM3NSAxMC4yMzgxIDQuMzc1IDEwLjQ0NDNDNC4zNzUgMTAuNjUwNiA0LjU0Mzc1IDEwLjgxOTMgNC43NSAxMC44MTkzTDYuNjI1IDEwLjgxOTNMNi42MjUgMTIuNjk0M0M2LjYyNSAxMi45MDA2IDYuNzkzNzUgMTMuMDY5MyA3IDEzLjA2OTNDNy4yMDYyNSAxMy4wNjkzIDcuMzc1IDEyLjkwMDYgNy4zNzUgMTIuNjk0M0w3LjM3NSAxMC44MTkzTDkuMjUgMTAuODE5M0M5LjQ1NjI1IDEwLjgxOTMgOS42MjUgMTAuNjUwNiA5LjYyNSAxMC40NDQzQzkuNjI1IDEwLjIzODEgOS40NTYyNSAxMC4wNjkzIDkuMjUgMTAuMDY5M1oiIGZpbGw9IiM2MTYxNjEiIHN0cm9rZT0iIzYxNjE2MSIgc3Ryb2tlLXdpZHRoPSIwLjciLz4KPC9nPgo8cGF0aCBjbGFzcz0ianAtaWNvbjMiIGZpbGwtcnVsZT0iZXZlbm9kZCIgY2xpcC1ydWxlPSJldmVub2RkIiBkPSJNMi41IDUuNUwyLjUgMy41TDExLjUgMy41TDExLjUgNS41TDIuNSA1LjVaTTIgN0MxLjQ0NzcyIDcgMSA2LjU1MjI4IDEgNkwxIDNDMSAyLjQ0NzcyIDEuNDQ3NzIgMiAyIDJMMTIgMkMxMi41NTIzIDIgMTMgMi40NDc3MiAxMyAzTDEzIDZDMTMgNi41NTIyOSAxMi41NTIzIDcgMTIgN0wyIDdaIiBmaWxsPSIjNjE2MTYxIi8+CjxkZWZzPgo8Y2xpcFBhdGggaWQ9ImNsaXAwXzEzN18xOTQ5OCI+CjxyZWN0IGNsYXNzPSJqcC1pY29uMyIgd2lkdGg9IjYiIGhlaWdodD0iNiIgZmlsbD0id2hpdGUiIHRyYW5zZm9ybT0ibWF0cml4KDEgMS43NDg0NmUtMDcgMS43NDg0NmUtMDcgLTEgNCAxMy40NDQzKSIvPgo8L2NsaXBQYXRoPgo8L2RlZnM+Cjwvc3ZnPgo=);
  --jp-icon-add: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE5IDEzaC02djZoLTJ2LTZINXYtMmg2VjVoMnY2aDZ2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-bell: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE2IDE2IiB2ZXJzaW9uPSIxLjEiPgogICA8cGF0aCBjbGFzcz0ianAtaWNvbjIganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMzMzMzMzIgogICAgICBkPSJtOCAwLjI5Yy0xLjQgMC0yLjcgMC43My0zLjYgMS44LTEuMiAxLjUtMS40IDMuNC0xLjUgNS4yLTAuMTggMi4yLTAuNDQgNC0yLjMgNS4zbDAuMjggMS4zaDVjMC4wMjYgMC42NiAwLjMyIDEuMSAwLjcxIDEuNSAwLjg0IDAuNjEgMiAwLjYxIDIuOCAwIDAuNTItMC40IDAuNi0xIDAuNzEtMS41aDVsMC4yOC0xLjNjLTEuOS0wLjk3LTIuMi0zLjMtMi4zLTUuMy0wLjEzLTEuOC0wLjI2LTMuNy0xLjUtNS4yLTAuODUtMS0yLjItMS44LTMuNi0xLjh6bTAgMS40YzAuODggMCAxLjkgMC41NSAyLjUgMS4zIDAuODggMS4xIDEuMSAyLjcgMS4yIDQuNCAwLjEzIDEuNyAwLjIzIDMuNiAxLjMgNS4yaC0xMGMxLjEtMS42IDEuMi0zLjQgMS4zLTUuMiAwLjEzLTEuNyAwLjMtMy4zIDEuMi00LjQgMC41OS0wLjcyIDEuNi0xLjMgMi41LTEuM3ptLTAuNzQgMTJoMS41Yy0wLjAwMTUgMC4yOCAwLjAxNSAwLjc5LTAuNzQgMC43OS0wLjczIDAuMDAxNi0wLjcyLTAuNTMtMC43NC0wLjc5eiIgLz4KPC9zdmc+Cg==);
  --jp-icon-bug-dot: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjQiIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiPgogICAgICAgIDxwYXRoIGZpbGwtcnVsZT0iZXZlbm9kZCIgY2xpcC1ydWxlPSJldmVub2RkIiBkPSJNMTcuMTkgOEgyMFYxMEgxNy45MUMxNy45NiAxMC4zMyAxOCAxMC42NiAxOCAxMVYxMkgyMFYxNEgxOC41SDE4VjE0LjAyNzVDMTUuNzUgMTQuMjc2MiAxNCAxNi4xODM3IDE0IDE4LjVDMTQgMTkuMjA4IDE0LjE2MzUgMTkuODc3OSAxNC40NTQ5IDIwLjQ3MzlDMTMuNzA2MyAyMC44MTE3IDEyLjg3NTcgMjEgMTIgMjFDOS43OCAyMSA3Ljg1IDE5Ljc5IDYuODEgMThINFYxNkg2LjA5QzYuMDQgMTUuNjcgNiAxNS4zNCA2IDE1VjE0SDRWMTJINlYxMUM2IDEwLjY2IDYuMDQgMTAuMzMgNi4wOSAxMEg0VjhINi44MUM3LjI2IDcuMjIgNy44OCA2LjU1IDguNjIgNi4wNEw3IDQuNDFMOC40MSAzTDEwLjU5IDUuMTdDMTEuMDQgNS4wNiAxMS41MSA1IDEyIDVDMTIuNDkgNSAxMi45NiA1LjA2IDEzLjQyIDUuMTdMMTUuNTkgM0wxNyA0LjQxTDE1LjM3IDYuMDRDMTYuMTIgNi41NSAxNi43NCA3LjIyIDE3LjE5IDhaTTEwIDE2SDE0VjE0SDEwVjE2Wk0xMCAxMkgxNFYxMEgxMFYxMloiIGZpbGw9IiM2MTYxNjEiLz4KICAgICAgICA8cGF0aCBkPSJNMjIgMTguNUMyMiAyMC40MzMgMjAuNDMzIDIyIDE4LjUgMjJDMTYuNTY3IDIyIDE1IDIwLjQzMyAxNSAxOC41QzE1IDE2LjU2NyAxNi41NjcgMTUgMTguNSAxNUMyMC40MzMgMTUgMjIgMTYuNTY3IDIyIDE4LjVaIiBmaWxsPSIjNjE2MTYxIi8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-bug: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0yMCA4aC0yLjgxYy0uNDUtLjc4LTEuMDctMS40NS0xLjgyLTEuOTZMMTcgNC40MSAxNS41OSAzbC0yLjE3IDIuMTdDMTIuOTYgNS4wNiAxMi40OSA1IDEyIDVjLS40OSAwLS45Ni4wNi0xLjQxLjE3TDguNDEgMyA3IDQuNDFsMS42MiAxLjYzQzcuODggNi41NSA3LjI2IDcuMjIgNi44MSA4SDR2MmgyLjA5Yy0uMDUuMzMtLjA5LjY2LS4wOSAxdjFINHYyaDJ2MWMwIC4zNC4wNC42Ny4wOSAxSDR2MmgyLjgxYzEuMDQgMS43OSAyLjk3IDMgNS4xOSAzczQuMTUtMS4yMSA1LjE5LTNIMjB2LTJoLTIuMDljLjA1LS4zMy4wOS0uNjYuMDktMXYtMWgydi0yaC0ydi0xYzAtLjM0LS4wNC0uNjctLjA5LTFIMjBWOHptLTYgOGgtNHYtMmg0djJ6bTAtNGgtNHYtMmg0djJ6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-build: url(data:image/svg+xml;base64,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);
  --jp-icon-caret-down-empty-thin: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwb2x5Z29uIGNsYXNzPSJzdDEiIHBvaW50cz0iOS45LDEzLjYgMy42LDcuNCA0LjQsNi42IDkuOSwxMi4yIDE1LjQsNi43IDE2LjEsNy40ICIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-caret-down-empty: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik01LjIsNS45TDksOS43bDMuOC0zLjhsMS4yLDEuMmwtNC45LDVsLTQuOS01TDUuMiw1Ljl6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-caret-down: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik01LjIsNy41TDksMTEuMmwzLjgtMy44SDUuMnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-caret-left: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwYXRoIGQ9Ik0xMC44LDEyLjhMNy4xLDlsMy44LTMuOGwwLDcuNkgxMC44eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-caret-right: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik03LjIsNS4yTDEwLjksOWwtMy44LDMuOFY1LjJINy4yeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-caret-up-empty-thin: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwb2x5Z29uIGNsYXNzPSJzdDEiIHBvaW50cz0iMTUuNCwxMy4zIDkuOSw3LjcgNC40LDEzLjIgMy42LDEyLjUgOS45LDYuMyAxNi4xLDEyLjYgIi8+Cgk8L2c+Cjwvc3ZnPgo=);
  --jp-icon-caret-up: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwYXRoIGQ9Ik01LjIsMTAuNUw5LDYuOGwzLjgsMy44SDUuMnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-case-sensitive: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KICA8ZyBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiM0MTQxNDEiPgogICAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiAgPC9nPgogIDxnIGNsYXNzPSJqcC1pY29uLWFjY2VudDIiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTcuNiw4aDAuOWwzLjUsOGgtMS4xTDEwLDE0SDZsLTAuOSwySDRMNy42LDh6IE04LDkuMUw2LjQsMTNoMy4yTDgsOS4xeiIvPgogICAgPHBhdGggZD0iTTE2LjYsOS44Yy0wLjIsMC4xLTAuNCwwLjEtMC43LDAuMWMtMC4yLDAtMC40LTAuMS0wLjYtMC4yYy0wLjEtMC4xLTAuMi0wLjQtMC4yLTAuNyBjLTAuMywwLjMtMC42LDAuNS0wLjksMC43Yy0wLjMsMC4xLTAuNywwLjItMS4xLDAuMmMtMC4zLDAtMC41LDAtMC43LTAuMWMtMC4yLTAuMS0wLjQtMC4yLTAuNi0wLjNjLTAuMi0wLjEtMC4zLTAuMy0wLjQtMC41IGMtMC4xLTAuMi0wLjEtMC40LTAuMS0wLjdjMC0wLjMsMC4xLTAuNiwwLjItMC44YzAuMS0wLjIsMC4zLTAuNCwwLjQtMC41QzEyLDcsMTIuMiw2LjksMTIuNSw2LjhjMC4yLTAuMSwwLjUtMC4xLDAuNy0wLjIgYzAuMy0wLjEsMC41LTAuMSwwLjctMC4xYzAuMiwwLDAuNC0wLjEsMC42LTAuMWMwLjIsMCwwLjMtMC4xLDAuNC0wLjJjMC4xLTAuMSwwLjItMC4yLDAuMi0wLjRjMC0xLTEuMS0xLTEuMy0xIGMtMC40LDAtMS40LDAtMS40LDEuMmgtMC45YzAtMC40LDAuMS0wLjcsMC4yLTFjMC4xLTAuMiwwLjMtMC40LDAuNS0wLjZjMC4yLTAuMiwwLjUtMC4zLDAuOC0wLjNDMTMuMyw0LDEzLjYsNCwxMy45LDQgYzAuMywwLDAuNSwwLDAuOCwwLjFjMC4zLDAsMC41LDAuMSwwLjcsMC4yYzAuMiwwLjEsMC40LDAuMywwLjUsMC41QzE2LDUsMTYsNS4yLDE2LDUuNnYyLjljMCwwLjIsMCwwLjQsMCwwLjUgYzAsMC4xLDAuMSwwLjIsMC4zLDAuMmMwLjEsMCwwLjIsMCwwLjMsMFY5Ljh6IE0xNS4yLDYuOWMtMS4yLDAuNi0zLjEsMC4yLTMuMSwxLjRjMCwxLjQsMy4xLDEsMy4xLTAuNVY2Ljl6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-check: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik05IDE2LjE3TDQuODMgMTJsLTEuNDIgMS40MUw5IDE5IDIxIDdsLTEuNDEtMS40MXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-circle-empty: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyIDJDNi40NyAyIDIgNi40NyAyIDEyczQuNDcgMTAgMTAgMTAgMTAtNC40NyAxMC0xMFMxNy41MyAyIDEyIDJ6bTAgMThjLTQuNDEgMC04LTMuNTktOC04czMuNTktOCA4LTggOCAzLjU5IDggOC0zLjU5IDgtOCA4eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-circle: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPGNpcmNsZSBjeD0iOSIgY3k9IjkiIHI9IjgiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-clear: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8bWFzayBpZD0iZG9udXRIb2xlIj4KICAgIDxyZWN0IHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgZmlsbD0id2hpdGUiIC8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSI4IiBmaWxsPSJibGFjayIvPgogIDwvbWFzaz4KCiAgPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxyZWN0IGhlaWdodD0iMTgiIHdpZHRoPSIyIiB4PSIxMSIgeT0iMyIgdHJhbnNmb3JtPSJyb3RhdGUoMzE1LCAxMiwgMTIpIi8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIxMCIgbWFzaz0idXJsKCNkb251dEhvbGUpIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-close: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1ub25lIGpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIGpwLWljb24zLWhvdmVyIiBmaWxsPSJub25lIj4KICAgIDxjaXJjbGUgY3g9IjEyIiBjeT0iMTIiIHI9IjExIi8+CiAgPC9nPgoKICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIGpwLWljb24tYWNjZW50Mi1ob3ZlciIgZmlsbD0iIzYxNjE2MSI+CiAgICA8cGF0aCBkPSJNMTkgNi40MUwxNy41OSA1IDEyIDEwLjU5IDYuNDEgNSA1IDYuNDEgMTAuNTkgMTIgNSAxNy41OSA2LjQxIDE5IDEyIDEzLjQxIDE3LjU5IDE5IDE5IDE3LjU5IDEzLjQxIDEyeiIvPgogIDwvZz4KCiAgPGcgY2xhc3M9ImpwLWljb24tbm9uZSBqcC1pY29uLWJ1c3kiIGZpbGw9Im5vbmUiPgogICAgPGNpcmNsZSBjeD0iMTIiIGN5PSIxMiIgcj0iNyIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-code-check: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBzaGFwZS1yZW5kZXJpbmc9Imdlb21ldHJpY1ByZWNpc2lvbiI+CiAgICA8cGF0aCBkPSJNNi41OSwzLjQxTDIsOEw2LjU5LDEyLjZMOCwxMS4xOEw0LjgyLDhMOCw0LjgyTDYuNTksMy40MU0xMi40MSwzLjQxTDExLDQuODJMMTQuMTgsOEwxMSwxMS4xOEwxMi40MSwxMi42TDE3LDhMMTIuNDEsMy40MU0yMS41OSwxMS41OUwxMy41LDE5LjY4TDkuODMsMTZMOC40MiwxNy40MUwxMy41LDIyLjVMMjMsMTNMMjEuNTksMTEuNTlaIiAvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-code: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjIiIGhlaWdodD0iMjIiIHZpZXdCb3g9IjAgMCAyOCAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTExLjQgMTguNkw2LjggMTRMMTEuNCA5LjRMMTAgOEw0IDE0TDEwIDIwTDExLjQgMTguNlpNMTYuNiAxOC42TDIxLjIgMTRMMTYuNiA5LjRMMTggOEwyNCAxNEwxOCAyMEwxNi42IDE4LjZWMTguNloiLz4KCTwvZz4KPC9zdmc+Cg==);
  --jp-icon-collapse-all: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTggMmMxIDAgMTEgMCAxMiAwczIgMSAyIDJjMCAxIDAgMTEgMCAxMnMwIDItMiAyQzIwIDE0IDIwIDQgMjAgNFMxMCA0IDYgNGMwLTIgMS0yIDItMnoiIC8+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTE4IDhjMC0xLTEtMi0yLTJTNSA2IDQgNnMtMiAxLTIgMmMwIDEgMCAxMSAwIDEyczEgMiAyIDJjMSAwIDExIDAgMTIgMHMyLTEgMi0yYzAtMSAwLTExIDAtMTJ6bS0yIDB2MTJINFY4eiIgLz4KICAgICAgICA8cGF0aCBkPSJNNiAxM3YyaDh2LTJ6IiAvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-console: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwMCAyMDAiPgogIDxnIGNsYXNzPSJqcC1jb25zb2xlLWljb24tYmFja2dyb3VuZC1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiMwMjg4RDEiPgogICAgPHBhdGggZD0iTTIwIDE5LjhoMTYwdjE1OS45SDIweiIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtY29uc29sZS1pY29uLWNvbG9yIGpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIiBmaWxsPSIjZmZmIj4KICAgIDxwYXRoIGQ9Ik0xMDUgMTI3LjNoNDB2MTIuOGgtNDB6TTUxLjEgNzdMNzQgOTkuOWwtMjMuMyAyMy4zIDEwLjUgMTAuNSAyMy4zLTIzLjNMOTUgOTkuOSA4NC41IDg5LjQgNjEuNiA2Ni41eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-copy: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTExLjksMUgzLjJDMi40LDEsMS43LDEuNywxLjcsMi41djEwLjJoMS41VjIuNWg4LjdWMXogTTE0LjEsMy45aC04Yy0wLjgsMC0xLjUsMC43LTEuNSwxLjV2MTAuMmMwLDAuOCwwLjcsMS41LDEuNSwxLjVoOCBjMC44LDAsMS41LTAuNywxLjUtMS41VjUuNEMxNS41LDQuNiwxNC45LDMuOSwxNC4xLDMuOXogTTE0LjEsMTUuNWgtOFY1LjRoOFYxNS41eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-copyright: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGVuYWJsZS1iYWNrZ3JvdW5kPSJuZXcgMCAwIDI0IDI0IiBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCI+CiAgPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0xMS44OCw5LjE0YzEuMjgsMC4wNiwxLjYxLDEuMTUsMS42MywxLjY2aDEuNzljLTAuMDgtMS45OC0xLjQ5LTMuMTktMy40NS0zLjE5QzkuNjQsNy42MSw4LDksOCwxMi4xNCBjMCwxLjk0LDAuOTMsNC4yNCwzLjg0LDQuMjRjMi4yMiwwLDMuNDEtMS42NSwzLjQ0LTIuOTVoLTEuNzljLTAuMDMsMC41OS0wLjQ1LDEuMzgtMS42MywxLjQ0QzEwLjU1LDE0LjgzLDEwLDEzLjgxLDEwLDEyLjE0IEMxMCw5LjI1LDExLjI4LDkuMTYsMTEuODgsOS4xNHogTTEyLDJDNi40OCwyLDIsNi40OCwyLDEyczQuNDgsMTAsMTAsMTBzMTAtNC40OCwxMC0xMFMxNy41MiwyLDEyLDJ6IE0xMiwyMGMtNC40MSwwLTgtMy41OS04LTggczMuNTktOCw4LThzOCwzLjU5LDgsOFMxNi40MSwyMCwxMiwyMHoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-cut: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkuNjQgNy42NGMuMjMtLjUuMzYtMS4wNS4zNi0xLjY0IDAtMi4yMS0xLjc5LTQtNC00UzIgMy43OSAyIDZzMS43OSA0IDQgNGMuNTkgMCAxLjE0LS4xMyAxLjY0LS4zNkwxMCAxMmwtMi4zNiAyLjM2QzcuMTQgMTQuMTMgNi41OSAxNCA2IDE0Yy0yLjIxIDAtNCAxLjc5LTQgNHMxLjc5IDQgNCA0IDQtMS43OSA0LTRjMC0uNTktLjEzLTEuMTQtLjM2LTEuNjRMMTIgMTRsNyA3aDN2LTFMOS42NCA3LjY0ek02IDhjLTEuMSAwLTItLjg5LTItMnMuOS0yIDItMiAyIC44OSAyIDItLjkgMi0yIDJ6bTAgMTJjLTEuMSAwLTItLjg5LTItMnMuOS0yIDItMiAyIC44OSAyIDItLjkgMi0yIDJ6bTYtNy41Yy0uMjggMC0uNS0uMjItLjUtLjVzLjIyLS41LjUtLjUuNS4yMi41LjUtLjIyLjUtLjUuNXpNMTkgM2wtNiA2IDIgMiA3LTdWM3oiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-delete: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2cHgiIGhlaWdodD0iMTZweCI+CiAgICA8cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIiAvPgogICAgPHBhdGggY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjI2MjYyIiBkPSJNNiAxOWMwIDEuMS45IDIgMiAyaDhjMS4xIDAgMi0uOSAyLTJWN0g2djEyek0xOSA0aC0zLjVsLTEtMWgtNWwtMSAxSDV2MmgxNFY0eiIgLz4KPC9zdmc+Cg==);
  --jp-icon-download: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE5IDloLTRWM0g5djZINWw3IDcgNy03ek01IDE4djJoMTR2LTJINXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-duplicate: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiIGNsaXAtcnVsZT0iZXZlbm9kZCIgZD0iTTIuNzk5OTggMC44NzVIOC44OTU4MkM5LjIwMDYxIDAuODc1IDkuNDQ5OTggMS4xMzkxNCA5LjQ0OTk4IDEuNDYxOThDOS40NDk5OCAxLjc4NDgyIDkuMjAwNjEgMi4wNDg5NiA4Ljg5NTgyIDIuMDQ4OTZIMy4zNTQxNUMzLjA0OTM2IDIuMDQ4OTYgMi43OTk5OCAyLjMxMzEgMi43OTk5OCAyLjYzNTk0VjkuNjc5NjlDMi43OTk5OCAxMC4wMDI1IDIuNTUwNjEgMTAuMjY2NyAyLjI0NTgyIDEwLjI2NjdDMS45NDEwMyAxMC4yNjY3IDEuNjkxNjUgMTAuMDAyNSAxLjY5MTY1IDkuNjc5NjlWMi4wNDg5NkMxLjY5MTY1IDEuNDAzMjggMi4xOTA0IDAuODc1IDIuNzk5OTggMC44NzVaTTUuMzY2NjUgMTEuOVY0LjU1SDExLjA4MzNWMTEuOUg1LjM2NjY1Wk00LjE0MTY1IDQuMTQxNjdDNC4xNDE2NSAzLjY5MDYzIDQuNTA3MjggMy4zMjUgNC45NTgzMiAzLjMyNUgxMS40OTE3QzExLjk0MjcgMy4zMjUgMTIuMzA4MyAzLjY5MDYzIDEyLjMwODMgNC4xNDE2N1YxMi4zMDgzQzEyLjMwODMgMTIuNzU5NCAxMS45NDI3IDEzLjEyNSAxMS40OTE3IDEzLjEyNUg0Ljk1ODMyQzQuNTA3MjggMTMuMTI1IDQuMTQxNjUgMTIuNzU5NCA0LjE0MTY1IDEyLjMwODNWNC4xNDE2N1oiIGZpbGw9IiM2MTYxNjEiLz4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBkPSJNOS40MzU3NCA4LjI2NTA3SDguMzY0MzFWOS4zMzY1QzguMzY0MzEgOS40NTQzNSA4LjI2Nzg4IDkuNTUwNzggOC4xNTAwMiA5LjU1MDc4QzguMDMyMTcgOS41NTA3OCA3LjkzNTc0IDkuNDU0MzUgNy45MzU3NCA5LjMzNjVWOC4yNjUwN0g2Ljg2NDMxQzYuNzQ2NDUgOC4yNjUwNyA2LjY1MDAyIDguMTY4NjQgNi42NTAwMiA4LjA1MDc4QzYuNjUwMDIgNy45MzI5MiA2Ljc0NjQ1IDcuODM2NSA2Ljg2NDMxIDcuODM2NUg3LjkzNTc0VjYuNzY1MDdDNy45MzU3NCA2LjY0NzIxIDguMDMyMTcgNi41NTA3OCA4LjE1MDAyIDYuNTUwNzhDOC4yNjc4OCA2LjU1MDc4IDguMzY0MzEgNi42NDcyMSA4LjM2NDMxIDYuNzY1MDdWNy44MzY1SDkuNDM1NzRDOS41NTM2IDcuODM2NSA5LjY1MDAyIDcuOTMyOTIgOS42NTAwMiA4LjA1MDc4QzkuNjUwMDIgOC4xNjg2NCA5LjU1MzYgOC4yNjUwNyA5LjQzNTc0IDguMjY1MDdaIiBmaWxsPSIjNjE2MTYxIiBzdHJva2U9IiM2MTYxNjEiIHN0cm9rZS13aWR0aD0iMC41Ii8+Cjwvc3ZnPgo=);
  --jp-icon-edit: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTMgMTcuMjVWMjFoMy43NUwxNy44MSA5Ljk0bC0zLjc1LTMuNzVMMyAxNy4yNXpNMjAuNzEgNy4wNGMuMzktLjM5LjM5LTEuMDIgMC0xLjQxbC0yLjM0LTIuMzRjLS4zOS0uMzktMS4wMi0uMzktMS40MSAwbC0xLjgzIDEuODMgMy43NSAzLjc1IDEuODMtMS44M3oiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-ellipses: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPGNpcmNsZSBjeD0iNSIgY3k9IjEyIiByPSIyIi8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIyIi8+CiAgICA8Y2lyY2xlIGN4PSIxOSIgY3k9IjEyIiByPSIyIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-error: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj48Y2lyY2xlIGN4PSIxMiIgY3k9IjE5IiByPSIyIi8+PHBhdGggZD0iTTEwIDNoNHYxMmgtNHoiLz48L2c+CjxwYXRoIGZpbGw9Im5vbmUiIGQ9Ik0wIDBoMjR2MjRIMHoiLz4KPC9zdmc+Cg==);
  --jp-icon-expand-all: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTggMmMxIDAgMTEgMCAxMiAwczIgMSAyIDJjMCAxIDAgMTEgMCAxMnMwIDItMiAyQzIwIDE0IDIwIDQgMjAgNFMxMCA0IDYgNGMwLTIgMS0yIDItMnoiIC8+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTE4IDhjMC0xLTEtMi0yLTJTNSA2IDQgNnMtMiAxLTIgMmMwIDEgMCAxMSAwIDEyczEgMiAyIDJjMSAwIDExIDAgMTIgMHMyLTEgMi0yYzAtMSAwLTExIDAtMTJ6bS0yIDB2MTJINFY4eiIgLz4KICAgICAgICA8cGF0aCBkPSJNMTEgMTBIOXYzSDZ2MmgzdjNoMnYtM2gzdi0yaC0zeiIgLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-extension: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwLjUgMTFIMTlWN2MwLTEuMS0uOS0yLTItMmgtNFYzLjVDMTMgMi4xMiAxMS44OCAxIDEwLjUgMVM4IDIuMTIgOCAzLjVWNUg0Yy0xLjEgMC0xLjk5LjktMS45OSAydjMuOEgzLjVjMS40OSAwIDIuNyAxLjIxIDIuNyAyLjdzLTEuMjEgMi43LTIuNyAyLjdIMlYyMGMwIDEuMS45IDIgMiAyaDMuOHYtMS41YzAtMS40OSAxLjIxLTIuNyAyLjctMi43IDEuNDkgMCAyLjcgMS4yMSAyLjcgMi43VjIySDE3YzEuMSAwIDItLjkgMi0ydi00aDEuNWMxLjM4IDAgMi41LTEuMTIgMi41LTIuNVMyMS44OCAxMSAyMC41IDExeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-fast-forward: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTQgMThsOC41LTZMNCA2djEyem05LTEydjEybDguNS02TDEzIDZ6Ii8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-file-upload: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkgMTZoNnYtNmg0bC03LTctNyA3aDR6bS00IDJoMTR2Mkg1eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-file: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkuMyA4LjJsLTUuNS01LjVjLS4zLS4zLS43LS41LTEuMi0uNUgzLjljLS44LjEtMS42LjktMS42IDEuOHYxNC4xYzAgLjkuNyAxLjYgMS42IDEuNmgxNC4yYy45IDAgMS42LS43IDEuNi0xLjZWOS40Yy4xLS41LS4xLS45LS40LTEuMnptLTUuOC0zLjNsMy40IDMuNmgtMy40VjQuOXptMy45IDEyLjdINC43Yy0uMSAwLS4yIDAtLjItLjJWNC43YzAtLjIuMS0uMy4yLS4zaDcuMnY0LjRzMCAuOC4zIDEuMWMuMy4zIDEuMS4zIDEuMS4zaDQuM3Y3LjJzLS4xLjItLjIuMnoiLz4KPC9zdmc+Cg==);
  --jp-icon-filter-dot: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTE0LDEyVjE5Ljg4QzE0LjA0LDIwLjE4IDEzLjk0LDIwLjUgMTMuNzEsMjAuNzFDMTMuMzIsMjEuMSAxMi42OSwyMS4xIDEyLjMsMjAuNzFMMTAuMjksMTguN0MxMC4wNiwxOC40NyA5Ljk2LDE4LjE2IDEwLDE3Ljg3VjEySDkuOTdMNC4yMSw0LjYyQzMuODcsNC4xOSAzLjk1LDMuNTYgNC4zOCwzLjIyQzQuNTcsMy4wOCA0Ljc4LDMgNSwzVjNIMTlWM0MxOS4yMiwzIDE5LjQzLDMuMDggMTkuNjIsMy4yMkMyMC4wNSwzLjU2IDIwLjEzLDQuMTkgMTkuNzksNC42MkwxNC4wMywxMkgxNFoiIC8+CiAgPC9nPgogIDxnIGNsYXNzPSJqcC1pY29uLWRvdCIgZmlsbD0iI0ZGRiI+CiAgICA8Y2lyY2xlIGN4PSIxOCIgY3k9IjE3IiByPSIzIj48L2NpcmNsZT4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-filter-list: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEwIDE4aDR2LTJoLTR2MnpNMyA2djJoMThWNkgzem0zIDdoMTJ2LTJINnYyeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-filter: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTE0LDEyVjE5Ljg4QzE0LjA0LDIwLjE4IDEzLjk0LDIwLjUgMTMuNzEsMjAuNzFDMTMuMzIsMjEuMSAxMi42OSwyMS4xIDEyLjMsMjAuNzFMMTAuMjksMTguN0MxMC4wNiwxOC40NyA5Ljk2LDE4LjE2IDEwLDE3Ljg3VjEySDkuOTdMNC4yMSw0LjYyQzMuODcsNC4xOSAzLjk1LDMuNTYgNC4zOCwzLjIyQzQuNTcsMy4wOCA0Ljc4LDMgNSwzVjNIMTlWM0MxOS4yMiwzIDE5LjQzLDMuMDggMTkuNjIsMy4yMkMyMC4wNSwzLjU2IDIwLjEzLDQuMTkgMTkuNzksNC42MkwxNC4wMywxMkgxNFoiIC8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-folder-favorite: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjRweCIgdmlld0JveD0iMCAwIDI0IDI0IiB3aWR0aD0iMjRweCIgZmlsbD0iIzAwMDAwMCI+CiAgPHBhdGggZD0iTTAgMGgyNHYyNEgwVjB6IiBmaWxsPSJub25lIi8+PHBhdGggY2xhc3M9ImpwLWljb24zIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzYxNjE2MSIgZD0iTTIwIDZoLThsLTItMkg0Yy0xLjEgMC0yIC45LTIgMnYxMmMwIDEuMS45IDIgMiAyaDE2YzEuMSAwIDItLjkgMi0yVjhjMC0xLjEtLjktMi0yLTJ6bS0yLjA2IDExTDE1IDE1LjI4IDEyLjA2IDE3bC43OC0zLjMzLTIuNTktMi4yNCAzLjQxLS4yOUwxNSA4bDEuMzQgMy4xNCAzLjQxLjI5LTIuNTkgMi4yNC43OCAzLjMzeiIvPgo8L3N2Zz4K);
  --jp-icon-folder: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTAgNEg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMThjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY4YzAtMS4xLS45LTItMi0yaC04bC0yLTJ6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-home: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjRweCIgdmlld0JveD0iMCAwIDI0IDI0IiB3aWR0aD0iMjRweCIgZmlsbD0iIzAwMDAwMCI+CiAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPjxwYXRoIGNsYXNzPSJqcC1pY29uMyBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xMCAyMHYtNmg0djZoNXYtOGgzTDEyIDMgMiAxMmgzdjh6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-html5: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDUxMiA1MTIiPgogIDxwYXRoIGNsYXNzPSJqcC1pY29uMCBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiMwMDAiIGQ9Ik0xMDguNCAwaDIzdjIyLjhoMjEuMlYwaDIzdjY5aC0yM1Y0NmgtMjF2MjNoLTIzLjJNMjA2IDIzaC0yMC4zVjBoNjMuN3YyM0gyMjl2NDZoLTIzbTUzLjUtNjloMjQuMWwxNC44IDI0LjNMMzEzLjIgMGgyNC4xdjY5aC0yM1YzNC44bC0xNi4xIDI0LjgtMTYuMS0yNC44VjY5aC0yMi42bTg5LjItNjloMjN2NDYuMmgzMi42VjY5aC01NS42Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI2U0NGQyNiIgZD0iTTEwNy42IDQ3MWwtMzMtMzcwLjRoMzYyLjhsLTMzIDM3MC4yTDI1NS43IDUxMiIvPgogIDxwYXRoIGNsYXNzPSJqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNmMTY1MjkiIGQ9Ik0yNTYgNDgwLjVWMTMxaDE0OC4zTDM3NiA0NDciLz4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNlYmViZWIiIGQ9Ik0xNDIgMTc2LjNoMTE0djQ1LjRoLTY0LjJsNC4yIDQ2LjVoNjB2NDUuM0gxNTQuNG0yIDIyLjhIMjAybDMuMiAzNi4zIDUwLjggMTMuNnY0Ny40bC05My4yLTI2Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIiBmaWxsPSIjZmZmIiBkPSJNMzY5LjYgMTc2LjNIMjU1Ljh2NDUuNGgxMDkuNm0tNC4xIDQ2LjVIMjU1Ljh2NDUuNGg1NmwtNS4zIDU5LTUwLjcgMTMuNnY0Ny4ybDkzLTI1LjgiLz4KPC9zdmc+Cg==);
  --jp-icon-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1icmFuZDQganAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNGRkYiIGQ9Ik0yLjIgMi4yaDE3LjV2MTcuNUgyLjJ6Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzNGNTFCNSIgZD0iTTIuMiAyLjJ2MTcuNWgxNy41bC4xLTE3LjVIMi4yem0xMi4xIDIuMmMxLjIgMCAyLjIgMSAyLjIgMi4ycy0xIDIuMi0yLjIgMi4yLTIuMi0xLTIuMi0yLjIgMS0yLjIgMi4yLTIuMnpNNC40IDE3LjZsMy4zLTguOCAzLjMgNi42IDIuMi0zLjIgNC40IDUuNEg0LjR6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-info: url(data:image/svg+xml;base64,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);
  --jp-icon-inspector: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaW5zcGVjdG9yLWljb24tY29sb3IganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMjAgNEg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMThjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY2YzAtMS4xLS45LTItMi0yem0tNSAxNEg0di00aDExdjR6bTAtNUg0VjloMTF2NHptNSA1aC00VjloNHY5eiIvPgo8L3N2Zz4K);
  --jp-icon-json: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtanNvbi1pY29uLWNvbG9yIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI0Y5QTgyNSI+CiAgICA8cGF0aCBkPSJNMjAuMiAxMS44Yy0xLjYgMC0xLjcuNS0xLjcgMSAwIC40LjEuOS4xIDEuMy4xLjUuMS45LjEgMS4zIDAgMS43LTEuNCAyLjMtMy41IDIuM2gtLjl2LTEuOWguNWMxLjEgMCAxLjQgMCAxLjQtLjggMC0uMyAwLS42LS4xLTEgMC0uNC0uMS0uOC0uMS0xLjIgMC0xLjMgMC0xLjggMS4zLTItMS4zLS4yLTEuMy0uNy0xLjMtMiAwLS40LjEtLjguMS0xLjIuMS0uNC4xLS43LjEtMSAwLS44LS40LS43LTEuNC0uOGgtLjVWNC4xaC45YzIuMiAwIDMuNS43IDMuNSAyLjMgMCAuNC0uMS45LS4xIDEuMy0uMS41LS4xLjktLjEgMS4zIDAgLjUuMiAxIDEuNyAxdjEuOHpNMS44IDEwLjFjMS42IDAgMS43LS41IDEuNy0xIDAtLjQtLjEtLjktLjEtMS4zLS4xLS41LS4xLS45LS4xLTEuMyAwLTEuNiAxLjQtMi4zIDMuNS0yLjNoLjl2MS45aC0uNWMtMSAwLTEuNCAwLTEuNC44IDAgLjMgMCAuNi4xIDEgMCAuMi4xLjYuMSAxIDAgMS4zIDAgMS44LTEuMyAyQzYgMTEuMiA2IDExLjcgNiAxM2MwIC40LS4xLjgtLjEgMS4yLS4xLjMtLjEuNy0uMSAxIDAgLjguMy44IDEuNC44aC41djEuOWgtLjljLTIuMSAwLTMuNS0uNi0zLjUtMi4zIDAtLjQuMS0uOS4xLTEuMy4xLS41LjEtLjkuMS0xLjMgMC0uNS0uMi0xLTEuNy0xdi0xLjl6Ii8+CiAgICA8Y2lyY2xlIGN4PSIxMSIgY3k9IjEzLjgiIHI9IjIuMSIvPgogICAgPGNpcmNsZSBjeD0iMTEiIGN5PSI4LjIiIHI9IjIuMSIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-julia: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDMyNSAzMDAiPgogIDxnIGNsYXNzPSJqcC1icmFuZDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjY2IzYzMzIj4KICAgIDxwYXRoIGQ9Ik0gMTUwLjg5ODQzOCAyMjUgQyAxNTAuODk4NDM4IDI2Ni40MjE4NzUgMTE3LjMyMDMxMiAzMDAgNzUuODk4NDM4IDMwMCBDIDM0LjQ3NjU2MiAzMDAgMC44OTg0MzggMjY2LjQyMTg3NSAwLjg5ODQzOCAyMjUgQyAwLjg5ODQzOCAxODMuNTc4MTI1IDM0LjQ3NjU2MiAxNTAgNzUuODk4NDM4IDE1MCBDIDExNy4zMjAzMTIgMTUwIDE1MC44OTg0MzggMTgzLjU3ODEyNSAxNTAuODk4NDM4IDIyNSIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzM4OTgyNiI+CiAgICA8cGF0aCBkPSJNIDIzNy41IDc1IEMgMjM3LjUgMTE2LjQyMTg3NSAyMDMuOTIxODc1IDE1MCAxNjIuNSAxNTAgQyAxMjEuMDc4MTI1IDE1MCA4Ny41IDExNi40MjE4NzUgODcuNSA3NSBDIDg3LjUgMzMuNTc4MTI1IDEyMS4wNzgxMjUgMCAxNjIuNSAwIEMgMjAzLjkyMTg3NSAwIDIzNy41IDMzLjU3ODEyNSAyMzcuNSA3NSIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzk1NThiMiI+CiAgICA8cGF0aCBkPSJNIDMyNC4xMDE1NjIgMjI1IEMgMzI0LjEwMTU2MiAyNjYuNDIxODc1IDI5MC41MjM0MzggMzAwIDI0OS4xMDE1NjIgMzAwIEMgMjA3LjY3OTY4OCAzMDAgMTc0LjEwMTU2MiAyNjYuNDIxODc1IDE3NC4xMDE1NjIgMjI1IEMgMTc0LjEwMTU2MiAxODMuNTc4MTI1IDIwNy42Nzk2ODggMTUwIDI0OS4xMDE1NjIgMTUwIEMgMjkwLjUyMzQzOCAxNTAgMzI0LjEwMTU2MiAxODMuNTc4MTI1IDMyNC4xMDE1NjIgMjI1Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-jupyter-favicon: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTUyIiBoZWlnaHQ9IjE2NSIgdmlld0JveD0iMCAwIDE1MiAxNjUiIHZlcnNpb249IjEuMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgPGcgY2xhc3M9ImpwLWp1cHl0ZXItaWNvbi1jb2xvciIgZmlsbD0iI0YzNzcyNiI+CiAgICA8cGF0aCB0cmFuc2Zvcm09InRyYW5zbGF0ZSgwLjA3ODk0NywgMTEwLjU4MjkyNykiIGQ9Ik03NS45NDIyODQyLDI5LjU4MDQ1NjEgQzQzLjMwMjM5NDcsMjkuNTgwNDU2MSAxNC43OTY3ODMyLDE3LjY1MzQ2MzQgMCwwIEM1LjUxMDgzMjExLDE1Ljg0MDY4MjkgMTUuNzgxNTM4OSwyOS41NjY3NzMyIDI5LjM5MDQ5NDcsMzkuMjc4NDE3MSBDNDIuOTk5Nyw0OC45ODk4NTM3IDU5LjI3MzcsNTQuMjA2NzgwNSA3NS45NjA1Nzg5LDU0LjIwNjc4MDUgQzkyLjY0NzQ1NzksNTQuMjA2NzgwNSAxMDguOTIxNDU4LDQ4Ljk4OTg1MzcgMTIyLjUzMDY2MywzOS4yNzg0MTcxIEMxMzYuMTM5NDUzLDI5LjU2Njc3MzIgMTQ2LjQxMDI4NCwxNS44NDA2ODI5IDE1MS45MjExNTgsMCBDMTM3LjA4Nzg2OCwxNy42NTM0NjM0IDEwOC41ODI1ODksMjkuNTgwNDU2MSA3NS45NDIyODQyLDI5LjU4MDQ1NjEgTDc1Ljk0MjI4NDIsMjkuNTgwNDU2MSBaIiAvPgogICAgPHBhdGggdHJhbnNmb3JtPSJ0cmFuc2xhdGUoMC4wMzczNjgsIDAuNzA0ODc4KSIgZD0iTTc1Ljk3ODQ1NzksMjQuNjI2NDA3MyBDMTA4LjYxODc2MywyNC42MjY0MDczIDEzNy4xMjQ0NTgsMzYuNTUzNDQxNSAxNTEuOTIxMTU4LDU0LjIwNjc4MDUgQzE0Ni40MTAyODQsMzguMzY2MjIyIDEzNi4xMzk0NTMsMjQuNjQwMTMxNyAxMjIuNTMwNjYzLDE0LjkyODQ4NzggQzEwOC45MjE0NTgsNS4yMTY4NDM5IDkyLjY0NzQ1NzksMCA3NS45NjA1Nzg5LDAgQzU5LjI3MzcsMCA0Mi45OTk3LDUuMjE2ODQzOSAyOS4zOTA0OTQ3LDE0LjkyODQ4NzggQzE1Ljc4MTUzODksMjQuNjQwMTMxNyA1LjUxMDgzMjExLDM4LjM2NjIyMiAwLDU0LjIwNjc4MDUgQzE0LjgzMzA4MTYsMzYuNTg5OTI5MyA0My4zMzg1Njg0LDI0LjYyNjQwNzMgNzUuOTc4NDU3OSwyNC42MjY0MDczIEw3NS45Nzg0NTc5LDI0LjYyNjQwNzMgWiIgLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-jupyter: url(data:image/svg+xml;base64,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);
  --jp-icon-jupyterlab-wordmark: url(data:image/svg+xml;base64,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);
  --jp-icon-kernel: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgZmlsbD0iIzYxNjE2MSIgZD0iTTE1IDlIOXY2aDZWOXptLTIgNGgtMnYtMmgydjJ6bTgtMlY5aC0yVjdjMC0xLjEtLjktMi0yLTJoLTJWM2gtMnYyaC0yVjNIOXYySDdjLTEuMSAwLTIgLjktMiAydjJIM3YyaDJ2MkgzdjJoMnYyYzAgMS4xLjkgMiAyIDJoMnYyaDJ2LTJoMnYyaDJ2LTJoMmMxLjEgMCAyLS45IDItMnYtMmgydi0yaC0ydi0yaDJ6bS00IDZIN1Y3aDEwdjEweiIvPgo8L3N2Zz4K);
  --jp-icon-keyboard: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMjAgNUg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMTdjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY3YzAtMS4xLS45LTItMi0yem0tOSAzaDJ2MmgtMlY4em0wIDNoMnYyaC0ydi0yek04IDhoMnYySDhWOHptMCAzaDJ2Mkg4di0yem0tMSAySDV2LTJoMnYyem0wLTNINVY4aDJ2MnptOSA3SDh2LTJoOHYyem0wLTRoLTJ2LTJoMnYyem0wLTNoLTJWOGgydjJ6bTMgM2gtMnYtMmgydjJ6bTAtM2gtMlY4aDJ2MnoiLz4KPC9zdmc+Cg==);
  --jp-icon-launch: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMzIgMzIiIHdpZHRoPSIzMiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0yNiwyOEg2YTIuMDAyNywyLjAwMjcsMCwwLDEtMi0yVjZBMi4wMDI3LDIuMDAyNywwLDAsMSw2LDRIMTZWNkg2VjI2SDI2VjE2aDJWMjZBMi4wMDI3LDIuMDAyNywwLDAsMSwyNiwyOFoiLz4KICAgIDxwb2x5Z29uIHBvaW50cz0iMjAgMiAyMCA0IDI2LjU4NiA0IDE4IDEyLjU4NiAxOS40MTQgMTQgMjggNS40MTQgMjggMTIgMzAgMTIgMzAgMiAyMCAyIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-launcher: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkgMTlINVY1aDdWM0g1YTIgMiAwIDAwLTIgMnYxNGEyIDIgMCAwMDIgMmgxNGMxLjEgMCAyLS45IDItMnYtN2gtMnY3ek0xNCAzdjJoMy41OWwtOS44MyA5LjgzIDEuNDEgMS40MUwxOSA2LjQxVjEwaDJWM2gtN3oiLz4KPC9zdmc+Cg==);
  --jp-icon-line-form: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGZpbGw9IndoaXRlIiBkPSJNNS44OCA0LjEyTDEzLjc2IDEybC03Ljg4IDcuODhMOCAyMmwxMC0xMEw4IDJ6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-link: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTMuOSAxMmMwLTEuNzEgMS4zOS0zLjEgMy4xLTMuMWg0VjdIN2MtMi43NiAwLTUgMi4yNC01IDVzMi4yNCA1IDUgNWg0di0xLjlIN2MtMS43MSAwLTMuMS0xLjM5LTMuMS0zLjF6TTggMTNoOHYtMkg4djJ6bTktNmgtNHYxLjloNGMxLjcxIDAgMy4xIDEuMzkgMy4xIDMuMXMtMS4zOSAzLjEtMy4xIDMuMWgtNFYxN2g0YzIuNzYgMCA1LTIuMjQgNS01cy0yLjI0LTUtNS01eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-list: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xOSA1djE0SDVWNWgxNG0xLjEtMkgzLjljLS41IDAtLjkuNC0uOS45djE2LjJjMCAuNC40LjkuOS45aDE2LjJjLjQgMCAuOS0uNS45LS45VjMuOWMwLS41LS41LS45LS45LS45ek0xMSA3aDZ2MmgtNlY3em0wIDRoNnYyaC02di0yem0wIDRoNnYyaC02ek03IDdoMnYySDd6bTAgNGgydjJIN3ptMCA0aDJ2Mkg3eiIvPgo8L3N2Zz4K);
  --jp-icon-markdown: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjN0IxRkEyIiBkPSJNNSAxNC45aDEybC02LjEgNnptOS40LTYuOGMwLTEuMy0uMS0yLjktLjEtNC41LS40IDEuNC0uOSAyLjktMS4zIDQuM2wtMS4zIDQuM2gtMkw4LjUgNy45Yy0uNC0xLjMtLjctMi45LTEtNC4zLS4xIDEuNi0uMSAzLjItLjIgNC42TDcgMTIuNEg0LjhsLjctMTFoMy4zTDEwIDVjLjQgMS4yLjcgMi43IDEgMy45LjMtMS4yLjctMi42IDEtMy45bDEuMi0zLjdoMy4zbC42IDExaC0yLjRsLS4zLTQuMnoiLz4KPC9zdmc+Cg==);
  --jp-icon-move-down: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBkPSJNMTIuNDcxIDcuNTI4OTlDMTIuNzYzMiA3LjIzNjg0IDEyLjc2MzIgNi43NjMxNiAxMi40NzEgNi40NzEwMVY2LjQ3MTAxQzEyLjE3OSA2LjE3OTA1IDExLjcwNTcgNi4xNzg4NCAxMS40MTM1IDYuNDcwNTRMNy43NSAxMC4xMjc1VjEuNzVDNy43NSAxLjMzNTc5IDcuNDE0MjEgMSA3IDFWMUM2LjU4NTc5IDEgNi4yNSAxLjMzNTc5IDYuMjUgMS43NVYxMC4xMjc1TDIuNTk3MjYgNi40NjgyMkMyLjMwMzM4IDYuMTczODEgMS44MjY0MSA2LjE3MzU5IDEuNTMyMjYgNi40Njc3NFY2LjQ2Nzc0QzEuMjM4MyA2Ljc2MTcgMS4yMzgzIDcuMjM4MyAxLjUzMjI2IDcuNTMyMjZMNi4yOTI4OSAxMi4yOTI5QzYuNjgzNDIgMTIuNjgzNCA3LjMxNjU4IDEyLjY4MzQgNy43MDcxMSAxMi4yOTI5TDEyLjQ3MSA3LjUyODk5WiIgZmlsbD0iIzYxNjE2MSIvPgo8L3N2Zz4K);
  --jp-icon-move-up: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBkPSJNMS41Mjg5OSA2LjQ3MTAxQzEuMjM2ODQgNi43NjMxNiAxLjIzNjg0IDcuMjM2ODQgMS41Mjg5OSA3LjUyODk5VjcuNTI4OTlDMS44MjA5NSA3LjgyMDk1IDIuMjk0MjYgNy44MjExNiAyLjU4NjQ5IDcuNTI5NDZMNi4yNSAzLjg3MjVWMTIuMjVDNi4yNSAxMi42NjQyIDYuNTg1NzkgMTMgNyAxM1YxM0M3LjQxNDIxIDEzIDcuNzUgMTIuNjY0MiA3Ljc1IDEyLjI1VjMuODcyNUwxMS40MDI3IDcuNTMxNzhDMTEuNjk2NiA3LjgyNjE5IDEyLjE3MzYgNy44MjY0MSAxMi40Njc3IDcuNTMyMjZWNy41MzIyNkMxMi43NjE3IDcuMjM4MyAxMi43NjE3IDYuNzYxNyAxMi40Njc3IDYuNDY3NzRMNy43MDcxMSAxLjcwNzExQzcuMzE2NTggMS4zMTY1OCA2LjY4MzQyIDEuMzE2NTggNi4yOTI4OSAxLjcwNzExTDEuNTI4OTkgNi40NzEwMVoiIGZpbGw9IiM2MTYxNjEiLz4KPC9zdmc+Cg==);
  --jp-icon-new-folder: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwIDZoLThsLTItMkg0Yy0xLjExIDAtMS45OS44OS0xLjk5IDJMMiAxOGMwIDEuMTEuODkgMiAyIDJoMTZjMS4xMSAwIDItLjg5IDItMlY4YzAtMS4xMS0uODktMi0yLTJ6bS0xIDhoLTN2M2gtMnYtM2gtM3YtMmgzVjloMnYzaDN2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-not-trusted: url(data:image/svg+xml;base64,PHN2ZyBmaWxsPSJub25lIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI1IDI1Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDMgMykiIGQ9Ik0xLjg2MDk0IDExLjQ0MDlDMC44MjY0NDggOC43NzAyNyAwLjg2Mzc3OSA2LjA1NzY0IDEuMjQ5MDcgNC4xOTkzMkMyLjQ4MjA2IDMuOTMzNDcgNC4wODA2OCAzLjQwMzQ3IDUuNjAxMDIgMi44NDQ5QzcuMjM1NDkgMi4yNDQ0IDguODU2NjYgMS41ODE1IDkuOTg3NiAxLjA5NTM5QzExLjA1OTcgMS41ODM0MSAxMi42MDk0IDIuMjQ0NCAxNC4yMTggMi44NDMzOUMxNS43NTAzIDMuNDEzOTQgMTcuMzk5NSAzLjk1MjU4IDE4Ljc1MzkgNC4yMTM4NUMxOS4xMzY0IDYuMDcxNzcgMTkuMTcwOSA4Ljc3NzIyIDE4LjEzOSAxMS40NDA5QzE3LjAzMDMgMTQuMzAzMiAxNC42NjY4IDE3LjE4NDQgOS45OTk5OSAxOC45MzU0QzUuMzMzMTkgMTcuMTg0NCAyLjk2OTY4IDE0LjMwMzIgMS44NjA5NCAxMS40NDA5WiIvPgogICAgPHBhdGggY2xhc3M9ImpwLWljb24yIiBzdHJva2U9IiMzMzMzMzMiIHN0cm9rZS13aWR0aD0iMiIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoOS4zMTU5MiA5LjMyMDMxKSIgZD0iTTcuMzY4NDIgMEwwIDcuMzY0NzkiLz4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDkuMzE1OTIgMTYuNjgzNikgc2NhbGUoMSAtMSkiIGQ9Ik03LjM2ODQyIDBMMCA3LjM2NDc5Ii8+Cjwvc3ZnPgo=);
  --jp-icon-notebook: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtbm90ZWJvb2staWNvbi1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNFRjZDMDAiPgogICAgPHBhdGggZD0iTTE4LjcgMy4zdjE1LjRIMy4zVjMuM2gxNS40bTEuNS0xLjVIMS44djE4LjNoMTguM2wuMS0xOC4zeiIvPgogICAgPHBhdGggZD0iTTE2LjUgMTYuNWwtNS40LTQuMy01LjYgNC4zdi0xMWgxMXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-numbering: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjIiIGhlaWdodD0iMjIiIHZpZXdCb3g9IjAgMCAyOCAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTQgMTlINlYxOS41SDVWMjAuNUg2VjIxSDRWMjJIN1YxOEg0VjE5Wk01IDEwSDZWNkg0VjdINVYxMFpNNCAxM0g1LjhMNCAxNS4xVjE2SDdWMTVINS4yTDcgMTIuOVYxMkg0VjEzWk05IDdWOUgyM1Y3SDlaTTkgMjFIMjNWMTlIOVYyMVpNOSAxNUgyM1YxM0g5VjE1WiIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-offline-bolt: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyIDIuMDJjLTUuNTEgMC05Ljk4IDQuNDctOS45OCA5Ljk4czQuNDcgOS45OCA5Ljk4IDkuOTggOS45OC00LjQ3IDkuOTgtOS45OFMxNy41MSAyLjAyIDEyIDIuMDJ6TTExLjQ4IDIwdi02LjI2SDhMMTMgNHY2LjI2aDMuMzVMMTEuNDggMjB6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-palette: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE4IDEzVjIwSDRWNkg5LjAyQzkuMDcgNS4yOSA5LjI0IDQuNjIgOS41IDRINEMyLjkgNCAyIDQuOSAyIDZWMjBDMiAyMS4xIDIuOSAyMiA0IDIySDE4QzE5LjEgMjIgMjAgMjEuMSAyMCAyMFYxNUwxOCAxM1pNMTkuMyA4Ljg5QzE5Ljc0IDguMTkgMjAgNy4zOCAyMCA2LjVDMjAgNC4wMSAxNy45OSAyIDE1LjUgMkMxMy4wMSAyIDExIDQuMDEgMTEgNi41QzExIDguOTkgMTMuMDEgMTEgMTUuNDkgMTFDMTYuMzcgMTEgMTcuMTkgMTAuNzQgMTcuODggMTAuM0wyMSAxMy40MkwyMi40MiAxMkwxOS4zIDguODlaTTE1LjUgOUMxNC4xMiA5IDEzIDcuODggMTMgNi41QzEzIDUuMTIgMTQuMTIgNCAxNS41IDRDMTYuODggNCAxOCA1LjEyIDE4IDYuNUMxOCA3Ljg4IDE2Ljg4IDkgMTUuNSA5WiIvPgogICAgPHBhdGggZmlsbC1ydWxlPSJldmVub2RkIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik00IDZIOS4wMTg5NEM5LjAwNjM5IDYuMTY1MDIgOSA2LjMzMTc2IDkgNi41QzkgOC44MTU3NyAxMC4yMTEgMTAuODQ4NyAxMi4wMzQzIDEySDlWMTRIMTZWMTIuOTgxMUMxNi41NzAzIDEyLjkzNzcgMTcuMTIgMTIuODIwNyAxNy42Mzk2IDEyLjYzOTZMMTggMTNWMjBINFY2Wk04IDhINlYxMEg4VjhaTTYgMTJIOFYxNEg2VjEyWk04IDE2SDZWMThIOFYxNlpNOSAxNkgxNlYxOEg5VjE2WiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-paste: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTE5IDJoLTQuMThDMTQuNC44NCAxMy4zIDAgMTIgMGMtMS4zIDAtMi40Ljg0LTIuODIgMkg1Yy0xLjEgMC0yIC45LTIgMnYxNmMwIDEuMS45IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjRjMC0xLjEtLjktMi0yLTJ6bS03IDBjLjU1IDAgMSAuNDUgMSAxcy0uNDUgMS0xIDEtMS0uNDUtMS0xIC40NS0xIDEtMXptNyAxOEg1VjRoMnYzaDEwVjRoMnYxNnoiLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-pdf: url(data:image/svg+xml;base64,PHN2ZwogICB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyMiAyMiIgd2lkdGg9IjE2Ij4KICAgIDxwYXRoIHRyYW5zZm9ybT0icm90YXRlKDQ1KSIgY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI0ZGMkEyQSIKICAgICAgIGQ9Im0gMjIuMzQ0MzY5LC0zLjAxNjM2NDIgaCA1LjYzODYwNCB2IDEuNTc5MjQzMyBoIC0zLjU0OTIyNyB2IDEuNTA4NjkyOTkgaCAzLjMzNzU3NiBWIDEuNjUwODE1NCBoIC0zLjMzNzU3NiB2IDMuNDM1MjYxMyBoIC0yLjA4OTM3NyB6IG0gLTcuMTM2NDQ0LDEuNTc5MjQzMyB2IDQuOTQzOTU0MyBoIDAuNzQ4OTIgcSAxLjI4MDc2MSwwIDEuOTUzNzAzLC0wLjYzNDk1MzUgMC42NzgzNjksLTAuNjM0OTUzNSAwLjY3ODM2OSwtMS44NDUxNjQxIDAsLTEuMjA0NzgzNTUgLTAuNjcyOTQyLC0xLjgzNDMxMDExIC0wLjY3Mjk0MiwtMC42Mjk1MjY1OSAtMS45NTkxMywtMC42Mjk1MjY1OSB6IG0gLTIuMDg5Mzc3LC0xLjU3OTI0MzMgaCAyLjIwMzM0MyBxIDEuODQ1MTY0LDAgMi43NDYwMzksMC4yNjU5MjA3IDAuOTA2MzAxLDAuMjYwNDkzNyAxLjU1MjEwOCwwLjg5MDAyMDMgMC41Njk4MywwLjU0ODEyMjMgMC44NDY2MDUsMS4yNjQ0ODAwNiAwLjI3Njc3NCwwLjcxNjM1NzgxIDAuMjc2Nzc0LDEuNjIyNjU4OTQgMCwwLjkxNzE1NTEgLTAuMjc2Nzc0LDEuNjM4OTM5OSAtMC4yNzY3NzUsMC43MTYzNTc4IC0wLjg0NjYwNSwxLjI2NDQ4IC0wLjY1MTIzNCwwLjYyOTUyNjYgLTEuNTYyOTYyLDAuODk1NDQ3MyAtMC45MTE3MjgsMC4yNjA0OTM3IC0yLjczNTE4NSwwLjI2MDQ5MzcgaCAtMi4yMDMzNDMgeiBtIC04LjE0NTg1NjUsMCBoIDMuNDY3ODIzIHEgMS41NDY2ODE2LDAgMi4zNzE1Nzg1LDAuNjg5MjIzIDAuODMwMzI0LDAuNjgzNzk2MSAwLjgzMDMyNCwxLjk1MzcwMzE0IDAsMS4yNzUzMzM5NyAtMC44MzAzMjQsMS45NjQ1NTcwNiBRIDkuOTg3MTk2MSwyLjI3NDkxNSA4LjQ0MDUxNDUsMi4yNzQ5MTUgSCA3LjA2MjA2ODQgViA1LjA4NjA3NjcgSCA0Ljk3MjY5MTUgWiBtIDIuMDg5Mzc2OSwxLjUxNDExOTkgdiAyLjI2MzAzOTQzIGggMS4xNTU5NDEgcSAwLjYwNzgxODgsMCAwLjkzODg2MjksLTAuMjkzMDU1NDcgMC4zMzEwNDQxLC0wLjI5ODQ4MjQxIDAuMzMxMDQ0MSwtMC44NDExNzc3MiAwLC0wLjU0MjY5NTMxIC0wLjMzMTA0NDEsLTAuODM1NzUwNzQgLTAuMzMxMDQ0MSwtMC4yOTMwNTU1IC0wLjkzODg2MjksLTAuMjkzMDU1NSB6IgovPgo8L3N2Zz4K);
  --jp-icon-python: url(data:image/svg+xml;base64,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);
  --jp-icon-r-kernel: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMjE5NkYzIiBkPSJNNC40IDIuNWMxLjItLjEgMi45LS4zIDQuOS0uMyAyLjUgMCA0LjEuNCA1LjIgMS4zIDEgLjcgMS41IDEuOSAxLjUgMy41IDAgMi0xLjQgMy41LTIuOSA0LjEgMS4yLjQgMS43IDEuNiAyLjIgMyAuNiAxLjkgMSAzLjkgMS4zIDQuNmgtMy44Yy0uMy0uNC0uOC0xLjctMS4yLTMuN3MtMS4yLTIuNi0yLjYtMi42aC0uOXY2LjRINC40VjIuNXptMy43IDYuOWgxLjRjMS45IDAgMi45LS45IDIuOS0yLjNzLTEtMi4zLTIuOC0yLjNjLS43IDAtMS4zIDAtMS42LjJ2NC41aC4xdi0uMXoiLz4KPC9zdmc+Cg==);
  --jp-icon-react: url(data:image/svg+xml;base64,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);
  --jp-icon-redo: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgICA8cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIi8+PHBhdGggZD0iTTE4LjQgMTAuNkMxNi41NSA4Ljk5IDE0LjE1IDggMTEuNSA4Yy00LjY1IDAtOC41OCAzLjAzLTkuOTYgNy4yMkwzLjkgMTZjMS4wNS0zLjE5IDQuMDUtNS41IDcuNi01LjUgMS45NSAwIDMuNzMuNzIgNS4xMiAxLjg4TDEzIDE2aDlWN2wtMy42IDMuNnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-refresh: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTkgMTMuNWMtMi40OSAwLTQuNS0yLjAxLTQuNS00LjVTNi41MSA0LjUgOSA0LjVjMS4yNCAwIDIuMzYuNTIgMy4xNyAxLjMzTDEwIDhoNVYzbC0xLjc2IDEuNzZDMTIuMTUgMy42OCAxMC42NiAzIDkgMyA1LjY5IDMgMy4wMSA1LjY5IDMuMDEgOVM1LjY5IDE1IDkgMTVjMi45NyAwIDUuNDMtMi4xNiA1LjktNWgtMS41MmMtLjQ2IDItMi4yNCAzLjUtNC4zOCAzLjV6Ii8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-regex: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KICA8ZyBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiM0MTQxNDEiPgogICAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiAgPC9nPgoKICA8ZyBjbGFzcz0ianAtaWNvbi1hY2NlbnQyIiBmaWxsPSIjRkZGIj4KICAgIDxjaXJjbGUgY2xhc3M9InN0MiIgY3g9IjUuNSIgY3k9IjE0LjUiIHI9IjEuNSIvPgogICAgPHJlY3QgeD0iMTIiIHk9IjQiIGNsYXNzPSJzdDIiIHdpZHRoPSIxIiBoZWlnaHQ9IjgiLz4KICAgIDxyZWN0IHg9IjguNSIgeT0iNy41IiB0cmFuc2Zvcm09Im1hdHJpeCgwLjg2NiAtMC41IDAuNSAwLjg2NiAtMi4zMjU1IDcuMzIxOSkiIGNsYXNzPSJzdDIiIHdpZHRoPSI4IiBoZWlnaHQ9IjEiLz4KICAgIDxyZWN0IHg9IjEyIiB5PSI0IiB0cmFuc2Zvcm09Im1hdHJpeCgwLjUgLTAuODY2IDAuODY2IDAuNSAtMC42Nzc5IDE0LjgyNTIpIiBjbGFzcz0ic3QyIiB3aWR0aD0iMSIgaGVpZ2h0PSI4Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-run: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTggNXYxNGwxMS03eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-running: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDUxMiA1MTIiPgogIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICA8cGF0aCBkPSJNMjU2IDhDMTE5IDggOCAxMTkgOCAyNTZzMTExIDI0OCAyNDggMjQ4IDI0OC0xMTEgMjQ4LTI0OFMzOTMgOCAyNTYgOHptOTYgMzI4YzAgOC44LTcuMiAxNi0xNiAxNkgxNzZjLTguOCAwLTE2LTcuMi0xNi0xNlYxNzZjMC04LjggNy4yLTE2IDE2LTE2aDE2MGM4LjggMCAxNiA3LjIgMTYgMTZ2MTYweiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-save: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTE3IDNINWMtMS4xMSAwLTIgLjktMiAydjE0YzAgMS4xLjg5IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjdsLTQtNHptLTUgMTZjLTEuNjYgMC0zLTEuMzQtMy0zczEuMzQtMyAzLTMgMyAxLjM0IDMgMy0xLjM0IDMtMyAzem0zLTEwSDVWNWgxMHY0eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-search: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjEsMTAuOWgtMC43bC0wLjItMC4yYzAuOC0wLjksMS4zLTIuMiwxLjMtMy41YzAtMy0yLjQtNS40LTUuNC01LjRTMS44LDQuMiwxLjgsNy4xczIuNCw1LjQsNS40LDUuNCBjMS4zLDAsMi41LTAuNSwzLjUtMS4zbDAuMiwwLjJ2MC43bDQuMSw0LjFsMS4yLTEuMkwxMi4xLDEwLjl6IE03LjEsMTAuOWMtMi4xLDAtMy43LTEuNy0zLjctMy43czEuNy0zLjcsMy43LTMuN3MzLjcsMS43LDMuNywzLjcgUzkuMiwxMC45LDcuMSwxMC45eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-settings: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkuNDMgMTIuOThjLjA0LS4zMi4wNy0uNjQuMDctLjk4cy0uMDMtLjY2LS4wNy0uOThsMi4xMS0xLjY1Yy4xOS0uMTUuMjQtLjQyLjEyLS42NGwtMi0zLjQ2Yy0uMTItLjIyLS4zOS0uMy0uNjEtLjIybC0yLjQ5IDFjLS41Mi0uNC0xLjA4LS43My0xLjY5LS45OGwtLjM4LTIuNjVBLjQ4OC40ODggMCAwMDE0IDJoLTRjLS4yNSAwLS40Ni4xOC0uNDkuNDJsLS4zOCAyLjY1Yy0uNjEuMjUtMS4xNy41OS0xLjY5Ljk4bC0yLjQ5LTFjLS4yMy0uMDktLjQ5IDAtLjYxLjIybC0yIDMuNDZjLS4xMy4yMi0uMDcuNDkuMTIuNjRsMi4xMSAxLjY1Yy0uMDQuMzItLjA3LjY1LS4wNy45OHMuMDMuNjYuMDcuOThsLTIuMTEgMS42NWMtLjE5LjE1LS4yNC40Mi0uMTIuNjRsMiAzLjQ2Yy4xMi4yMi4zOS4zLjYxLjIybDIuNDktMWMuNTIuNCAxLjA4LjczIDEuNjkuOThsLjM4IDIuNjVjLjAzLjI0LjI0LjQyLjQ5LjQyaDRjLjI1IDAgLjQ2LS4xOC40OS0uNDJsLjM4LTIuNjVjLjYxLS4yNSAxLjE3LS41OSAxLjY5LS45OGwyLjQ5IDFjLjIzLjA5LjQ5IDAgLjYxLS4yMmwyLTMuNDZjLjEyLS4yMi4wNy0uNDktLjEyLS42NGwtMi4xMS0xLjY1ek0xMiAxNS41Yy0xLjkzIDAtMy41LTEuNTctMy41LTMuNXMxLjU3LTMuNSAzLjUtMy41IDMuNSAxLjU3IDMuNSAzLjUtMS41NyAzLjUtMy41IDMuNXoiLz4KPC9zdmc+Cg==);
  --jp-icon-share: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIHZpZXdCb3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTSAxOCAyIEMgMTYuMzU0OTkgMiAxNSAzLjM1NDk5MDQgMTUgNSBDIDE1IDUuMTkwOTUyOSAxNS4wMjE3OTEgNS4zNzcxMjI0IDE1LjA1NjY0MSA1LjU1ODU5MzggTCA3LjkyMTg3NSA5LjcyMDcwMzEgQyA3LjM5ODUzOTkgOS4yNzc4NTM5IDYuNzMyMDc3MSA5IDYgOSBDIDQuMzU0OTkwNCA5IDMgMTAuMzU0OTkgMyAxMiBDIDMgMTMuNjQ1MDEgNC4zNTQ5OTA0IDE1IDYgMTUgQyA2LjczMjA3NzEgMTUgNy4zOTg1Mzk5IDE0LjcyMjE0NiA3LjkyMTg3NSAxNC4yNzkyOTcgTCAxNS4wNTY2NDEgMTguNDM5NDUzIEMgMTUuMDIxNTU1IDE4LjYyMTUxNCAxNSAxOC44MDgzODYgMTUgMTkgQyAxNSAyMC42NDUwMSAxNi4zNTQ5OSAyMiAxOCAyMiBDIDE5LjY0NTAxIDIyIDIxIDIwLjY0NTAxIDIxIDE5IEMgMjEgMTcuMzU0OTkgMTkuNjQ1MDEgMTYgMTggMTYgQyAxNy4yNjc0OCAxNiAxNi42MDE1OTMgMTYuMjc5MzI4IDE2LjA3ODEyNSAxNi43MjI2NTYgTCA4Ljk0MzM1OTQgMTIuNTU4NTk0IEMgOC45NzgyMDk1IDEyLjM3NzEyMiA5IDEyLjE5MDk1MyA5IDEyIEMgOSAxMS44MDkwNDcgOC45NzgyMDk1IDExLjYyMjg3OCA4Ljk0MzM1OTQgMTEuNDQxNDA2IEwgMTYuMDc4MTI1IDcuMjc5Mjk2OSBDIDE2LjYwMTQ2IDcuNzIyMTQ2MSAxNy4yNjc5MjMgOCAxOCA4IEMgMTkuNjQ1MDEgOCAyMSA2LjY0NTAwOTYgMjEgNSBDIDIxIDMuMzU0OTkwNCAxOS42NDUwMSAyIDE4IDIgeiBNIDE4IDQgQyAxOC41NjQxMjkgNCAxOSA0LjQzNTg3MDYgMTkgNSBDIDE5IDUuNTY0MTI5NCAxOC41NjQxMjkgNiAxOCA2IEMgMTcuNDM1ODcxIDYgMTcgNS41NjQxMjk0IDE3IDUgQyAxNyA0LjQzNTg3MDYgMTcuNDM1ODcxIDQgMTggNCB6IE0gNiAxMSBDIDYuNTY0MTI5NCAxMSA3IDExLjQzNTg3MSA3IDEyIEMgNyAxMi41NjQxMjkgNi41NjQxMjk0IDEzIDYgMTMgQyA1LjQzNTg3MDYgMTMgNSAxMi41NjQxMjkgNSAxMiBDIDUgMTEuNDM1ODcxIDUuNDM1ODcwNiAxMSA2IDExIHogTSAxOCAxOCBDIDE4LjU2NDEyOSAxOCAxOSAxOC40MzU4NzEgMTkgMTkgQyAxOSAxOS41NjQxMjkgMTguNTY0MTI5IDIwIDE4IDIwIEMgMTcuNDM1ODcxIDIwIDE3IDE5LjU2NDEyOSAxNyAxOSBDIDE3IDE4LjQzNTg3MSAxNy40MzU4NzEgMTggMTggMTggeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-spreadsheet: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDEganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNENBRjUwIiBkPSJNMi4yIDIuMnYxNy42aDE3LjZWMi4ySDIuMnptMTUuNCA3LjdoLTUuNVY0LjRoNS41djUuNXpNOS45IDQuNHY1LjVINC40VjQuNGg1LjV6bS01LjUgNy43aDUuNXY1LjVINC40di01LjV6bTcuNyA1LjV2LTUuNWg1LjV2NS41aC01LjV6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-stop: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik02IDZoMTJ2MTJINnoiLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-tab: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIxIDNIM2MtMS4xIDAtMiAuOS0yIDJ2MTRjMCAxLjEuOSAyIDIgMmgxOGMxLjEgMCAyLS45IDItMlY1YzAtMS4xLS45LTItMi0yem0wIDE2SDNWNWgxMHY0aDh2MTB6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-table-rows: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik0yMSw4SDNWNGgxOFY4eiBNMjEsMTBIM3Y0aDE4VjEweiBNMjEsMTZIM3Y0aDE4VjE2eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-tag: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjgiIGhlaWdodD0iMjgiIHZpZXdCb3g9IjAgMCA0MyAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTI4LjgzMzIgMTIuMzM0TDMyLjk5OTggMTYuNTAwN0wzNy4xNjY1IDEyLjMzNEgyOC44MzMyWiIvPgoJCTxwYXRoIGQ9Ik0xNi4yMDk1IDIxLjYxMDRDMTUuNjg3MyAyMi4xMjk5IDE0Ljg0NDMgMjIuMTI5OSAxNC4zMjQ4IDIxLjYxMDRMNi45ODI5IDE0LjcyNDVDNi41NzI0IDE0LjMzOTQgNi4wODMxMyAxMy42MDk4IDYuMDQ3ODYgMTMuMDQ4MkM1Ljk1MzQ3IDExLjUyODggNi4wMjAwMiA4LjYxOTQ0IDYuMDY2MjEgNy4wNzY5NUM2LjA4MjgxIDYuNTE0NzcgNi41NTU0OCA2LjA0MzQ3IDcuMTE4MDQgNi4wMzA1NUM5LjA4ODYzIDUuOTg0NzMgMTMuMjYzOCA1LjkzNTc5IDEzLjY1MTggNi4zMjQyNUwyMS43MzY5IDEzLjYzOUMyMi4yNTYgMTQuMTU4NSAyMS43ODUxIDE1LjQ3MjQgMjEuMjYyIDE1Ljk5NDZMMTYuMjA5NSAyMS42MTA0Wk05Ljc3NTg1IDguMjY1QzkuMzM1NTEgNy44MjU2NiA4LjYyMzUxIDcuODI1NjYgOC4xODI4IDguMjY1QzcuNzQzNDYgOC43MDU3MSA3Ljc0MzQ2IDkuNDE3MzMgOC4xODI4IDkuODU2NjdDOC42MjM4MiAxMC4yOTY0IDkuMzM1ODIgMTAuMjk2NCA5Ljc3NTg1IDkuODU2NjdDMTAuMjE1NiA5LjQxNzMzIDEwLjIxNTYgOC43MDUzMyA5Ljc3NTg1IDguMjY1WiIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-terminal: url(data:image/svg+xml;base64,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);
  --jp-icon-text-editor: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtdGV4dC1lZGl0b3ItaWNvbi1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xNSAxNUgzdjJoMTJ2LTJ6bTAtOEgzdjJoMTJWN3pNMyAxM2gxOHYtMkgzdjJ6bTAgOGgxOHYtMkgzdjJ6TTMgM3YyaDE4VjNIM3oiLz4KPC9zdmc+Cg==);
  --jp-icon-toc: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik03LDVIMjFWN0g3VjVNNywxM1YxMUgyMVYxM0g3TTQsNC41QTEuNSwxLjUgMCAwLDEgNS41LDZBMS41LDEuNSAwIDAsMSA0LDcuNUExLjUsMS41IDAgMCwxIDIuNSw2QTEuNSwxLjUgMCAwLDEgNCw0LjVNNCwxMC41QTEuNSwxLjUgMCAwLDEgNS41LDEyQTEuNSwxLjUgMCAwLDEgNCwxMy41QTEuNSwxLjUgMCAwLDEgMi41LDEyQTEuNSwxLjUgMCAwLDEgNCwxMC41TTcsMTlWMTdIMjFWMTlIN000LDE2LjVBMS41LDEuNSAwIDAsMSA1LjUsMThBMS41LDEuNSAwIDAsMSA0LDE5LjVBMS41LDEuNSAwIDAsMSAyLjUsMThBMS41LDEuNSAwIDAsMSA0LDE2LjVaIiAvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-tree-view: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik0yMiAxMVYzaC03djNIOVYzSDJ2OGg3VjhoMnYxMGg0djNoN3YtOGgtN3YzaC0yVjhoMnYzeiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-trusted: url(data:image/svg+xml;base64,PHN2ZyBmaWxsPSJub25lIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI1Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDIgMykiIGQ9Ik0xLjg2MDk0IDExLjQ0MDlDMC44MjY0NDggOC43NzAyNyAwLjg2Mzc3OSA2LjA1NzY0IDEuMjQ5MDcgNC4xOTkzMkMyLjQ4MjA2IDMuOTMzNDcgNC4wODA2OCAzLjQwMzQ3IDUuNjAxMDIgMi44NDQ5QzcuMjM1NDkgMi4yNDQ0IDguODU2NjYgMS41ODE1IDkuOTg3NiAxLjA5NTM5QzExLjA1OTcgMS41ODM0MSAxMi42MDk0IDIuMjQ0NCAxNC4yMTggMi44NDMzOUMxNS43NTAzIDMuNDEzOTQgMTcuMzk5NSAzLjk1MjU4IDE4Ljc1MzkgNC4yMTM4NUMxOS4xMzY0IDYuMDcxNzcgMTkuMTcwOSA4Ljc3NzIyIDE4LjEzOSAxMS40NDA5QzE3LjAzMDMgMTQuMzAzMiAxNC42NjY4IDE3LjE4NDQgOS45OTk5OSAxOC45MzU0QzUuMzMzMiAxNy4xODQ0IDIuOTY5NjggMTQuMzAzMiAxLjg2MDk0IDExLjQ0MDlaIi8+CiAgICA8cGF0aCBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiMzMzMzMzMiIHN0cm9rZT0iIzMzMzMzMyIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoOCA5Ljg2NzE5KSIgZD0iTTIuODYwMTUgNC44NjUzNUwwLjcyNjU0OSAyLjk5OTU5TDAgMy42MzA0NUwyLjg2MDE1IDYuMTMxNTdMOCAwLjYzMDg3Mkw3LjI3ODU3IDBMMi44NjAxNSA0Ljg2NTM1WiIvPgo8L3N2Zz4K);
  --jp-icon-undo: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjUgOGMtMi42NSAwLTUuMDUuOTktNi45IDIuNkwyIDd2OWg5bC0zLjYyLTMuNjJjMS4zOS0xLjE2IDMuMTYtMS44OCA1LjEyLTEuODggMy41NCAwIDYuNTUgMi4zMSA3LjYgNS41bDIuMzctLjc4QzIxLjA4IDExLjAzIDE3LjE1IDggMTIuNSA4eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-user: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIHZpZXdCb3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE2IDdhNCA0IDAgMTEtOCAwIDQgNCAwIDAxOCAwek0xMiAxNGE3IDcgMCAwMC03IDdoMTRhNyA3IDAgMDAtNy03eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-users: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjQiIGhlaWdodD0iMjQiIHZlcnNpb249IjEuMSIgdmlld0JveD0iMCAwIDM2IDI0IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPgogPGcgY2xhc3M9ImpwLWljb24zIiB0cmFuc2Zvcm09Im1hdHJpeCgxLjczMjcgMCAwIDEuNzMyNyAtMy42MjgyIC4wOTk1NzcpIiBmaWxsPSIjNjE2MTYxIj4KICA8cGF0aCB0cmFuc2Zvcm09Im1hdHJpeCgxLjUsMCwwLDEuNSwwLC02KSIgZD0ibTEyLjE4NiA3LjUwOThjLTEuMDUzNSAwLTEuOTc1NyAwLjU2NjUtMi40Nzg1IDEuNDEwMiAwLjc1MDYxIDAuMzEyNzcgMS4zOTc0IDAuODI2NDggMS44NzMgMS40NzI3aDMuNDg2M2MwLTEuNTkyLTEuMjg4OS0yLjg4MjgtMi44ODA5LTIuODgyOHoiLz4KICA8cGF0aCBkPSJtMjAuNDY1IDIuMzg5NWEyLjE4ODUgMi4xODg1IDAgMCAxLTIuMTg4NCAyLjE4ODUgMi4xODg1IDIuMTg4NSAwIDAgMS0yLjE4ODUtMi4xODg1IDIuMTg4NSAyLjE4ODUgMCAwIDEgMi4xODg1LTIuMTg4NSAyLjE4ODUgMi4xODg1IDAgMCAxIDIuMTg4NCAyLjE4ODV6Ii8+CiAgPHBhdGggdHJhbnNmb3JtPSJtYXRyaXgoMS41LDAsMCwxLjUsMCwtNikiIGQ9Im0zLjU4OTggOC40MjE5Yy0xLjExMjYgMC0yLjAxMzcgMC45MDExMS0yLjAxMzcgMi4wMTM3aDIuODE0NWMwLjI2Nzk3LTAuMzczMDkgMC41OTA3LTAuNzA0MzUgMC45NTg5OC0wLjk3ODUyLTAuMzQ0MzMtMC42MTY4OC0xLjAwMzEtMS4wMzUyLTEuNzU5OC0xLjAzNTJ6Ii8+CiAgPHBhdGggZD0ibTYuOTE1NCA0LjYyM2ExLjUyOTQgMS41Mjk0IDAgMCAxLTEuNTI5NCAxLjUyOTQgMS41Mjk0IDEuNTI5NCAwIDAgMS0xLjUyOTQtMS41Mjk0IDEuNTI5NCAxLjUyOTQgMCAwIDEgMS41Mjk0LTEuNTI5NCAxLjUyOTQgMS41Mjk0IDAgMCAxIDEuNTI5NCAxLjUyOTR6Ii8+CiAgPHBhdGggZD0ibTYuMTM1IDEzLjUzNWMwLTMuMjM5MiAyLjYyNTktNS44NjUgNS44NjUtNS44NjUgMy4yMzkyIDAgNS44NjUgMi42MjU5IDUuODY1IDUuODY1eiIvPgogIDxjaXJjbGUgY3g9IjEyIiBjeT0iMy43Njg1IiByPSIyLjk2ODUiLz4KIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-vega: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbjEganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMjEyMTIxIj4KICAgIDxwYXRoIGQ9Ik0xMC42IDUuNGwyLjItMy4ySDIuMnY3LjNsNC02LjZ6Ii8+CiAgICA8cGF0aCBkPSJNMTUuOCAyLjJsLTQuNCA2LjZMNyA2LjNsLTQuOCA4djUuNWgxNy42VjIuMmgtNHptLTcgMTUuNEg1LjV2LTQuNGgzLjN2NC40em00LjQgMEg5LjhWOS44aDMuNHY3Ljh6bTQuNCAwaC0zLjRWNi41aDMuNHYxMS4xeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-word: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KIDxnIGNsYXNzPSJqcC1pY29uMiIgZmlsbD0iIzQxNDE0MSI+CiAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiA8L2c+CiA8ZyBjbGFzcz0ianAtaWNvbi1hY2NlbnQyIiB0cmFuc2Zvcm09InRyYW5zbGF0ZSguNDMgLjA0MDEpIiBmaWxsPSIjZmZmIj4KICA8cGF0aCBkPSJtNC4xNCA4Ljc2cTAuMDY4Mi0xLjg5IDIuNDItMS44OSAxLjE2IDAgMS42OCAwLjQyIDAuNTY3IDAuNDEgMC41NjcgMS4xNnYzLjQ3cTAgMC40NjIgMC41MTQgMC40NjIgMC4xMDMgMCAwLjItMC4wMjMxdjAuNzE0cS0wLjM5OSAwLjEwMy0wLjY1MSAwLjEwMy0wLjQ1MiAwLTAuNjkzLTAuMjItMC4yMzEtMC4yLTAuMjg0LTAuNjYyLTAuOTU2IDAuODcyLTIgMC44NzItMC45MDMgMC0xLjQ3LTAuNDcyLTAuNTI1LTAuNDcyLTAuNTI1LTEuMjYgMC0wLjI2MiAwLjA0NTItMC40NzIgMC4wNTY3LTAuMjIgMC4xMTYtMC4zNzggMC4wNjgyLTAuMTY4IDAuMjMxLTAuMzA0IDAuMTU4LTAuMTQ3IDAuMjYyLTAuMjQyIDAuMTE2LTAuMDkxNCAwLjM2OC0wLjE2OCAwLjI2Mi0wLjA5MTQgMC4zOTktMC4xMjYgMC4xMzYtMC4wNDUyIDAuNDcyLTAuMTAzIDAuMzM2LTAuMDU3OCAwLjUwNC0wLjA3OTggMC4xNTgtMC4wMjMxIDAuNTY3LTAuMDc5OCAwLjU1Ni0wLjA2ODIgMC43NzctMC4yMjEgMC4yMi0wLjE1MiAwLjIyLTAuNDQxdi0wLjI1MnEwLTAuNDMtMC4zNTctMC42NjItMC4zMzYtMC4yMzEtMC45NzYtMC4yMzEtMC42NjIgMC0wLjk5OCAwLjI2Mi0wLjMzNiAwLjI1Mi0wLjM5OSAwLjc5OHptMS44OSAzLjY4cTAuNzg4IDAgMS4yNi0wLjQxIDAuNTA0LTAuNDIgMC41MDQtMC45MDN2LTEuMDVxLTAuMjg0IDAuMTM2LTAuODYxIDAuMjMxLTAuNTY3IDAuMDkxNC0wLjk4NyAwLjE1OC0wLjQyIDAuMDY4Mi0wLjc2NiAwLjMyNi0wLjMzNiAwLjI1Mi0wLjMzNiAwLjcwNHQwLjMwNCAwLjcwNCAwLjg2MSAwLjI1MnoiIHN0cm9rZS13aWR0aD0iMS4wNSIvPgogIDxwYXRoIGQ9Im0xMCA0LjU2aDAuOTQ1djMuMTVxMC42NTEtMC45NzYgMS44OS0wLjk3NiAxLjE2IDAgMS44OSAwLjg0IDAuNjgyIDAuODQgMC42ODIgMi4zMSAwIDEuNDctMC43MDQgMi40Mi0wLjcwNCAwLjg4Mi0xLjg5IDAuODgyLTEuMjYgMC0xLjg5LTEuMDJ2MC43NjZoLTAuODV6bTIuNjIgMy4wNHEtMC43NDYgMC0xLjE2IDAuNjQtMC40NTIgMC42My0wLjQ1MiAxLjY4IDAgMS4wNSAwLjQ1MiAxLjY4dDEuMTYgMC42M3EwLjc3NyAwIDEuMjYtMC42MyAwLjQ5NC0wLjY0IDAuNDk0LTEuNjggMC0xLjA1LTAuNDcyLTEuNjgtMC40NjItMC42NC0xLjI2LTAuNjR6IiBzdHJva2Utd2lkdGg9IjEuMDUiLz4KICA8cGF0aCBkPSJtMi43MyAxNS44IDEzLjYgMC4wMDgxYzAuMDA2OSAwIDAtMi42IDAtMi42IDAtMC4wMDc4LTEuMTUgMC0xLjE1IDAtMC4wMDY5IDAtMC4wMDgzIDEuNS0wLjAwODMgMS41LTJlLTMgLTAuMDAxNC0xMS4zLTAuMDAxNC0xMS4zLTAuMDAxNGwtMC4wMDU5Mi0xLjVjMC0wLjAwNzgtMS4xNyAwLjAwMTMtMS4xNyAwLjAwMTN6IiBzdHJva2Utd2lkdGg9Ii45NzUiLz4KIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-yaml: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1jb250cmFzdDIganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjRDgxQjYwIj4KICAgIDxwYXRoIGQ9Ik03LjIgMTguNnYtNS40TDMgNS42aDMuM2wxLjQgMy4xYy4zLjkuNiAxLjYgMSAyLjUuMy0uOC42LTEuNiAxLTIuNWwxLjQtMy4xaDMuNGwtNC40IDcuNnY1LjVsLTIuOS0uMXoiLz4KICAgIDxjaXJjbGUgY2xhc3M9InN0MCIgY3g9IjE3LjYiIGN5PSIxNi41IiByPSIyLjEiLz4KICAgIDxjaXJjbGUgY2xhc3M9InN0MCIgY3g9IjE3LjYiIGN5PSIxMSIgcj0iMi4xIi8+CiAgPC9nPgo8L3N2Zz4K);
}

/* Icon CSS class declarations */

.jp-AddAboveIcon {
  background-image: var(--jp-icon-add-above);
}

.jp-AddBelowIcon {
  background-image: var(--jp-icon-add-below);
}

.jp-AddIcon {
  background-image: var(--jp-icon-add);
}

.jp-BellIcon {
  background-image: var(--jp-icon-bell);
}

.jp-BugDotIcon {
  background-image: var(--jp-icon-bug-dot);
}

.jp-BugIcon {
  background-image: var(--jp-icon-bug);
}

.jp-BuildIcon {
  background-image: var(--jp-icon-build);
}

.jp-CaretDownEmptyIcon {
  background-image: var(--jp-icon-caret-down-empty);
}

.jp-CaretDownEmptyThinIcon {
  background-image: var(--jp-icon-caret-down-empty-thin);
}

.jp-CaretDownIcon {
  background-image: var(--jp-icon-caret-down);
}

.jp-CaretLeftIcon {
  background-image: var(--jp-icon-caret-left);
}

.jp-CaretRightIcon {
  background-image: var(--jp-icon-caret-right);
}

.jp-CaretUpEmptyThinIcon {
  background-image: var(--jp-icon-caret-up-empty-thin);
}

.jp-CaretUpIcon {
  background-image: var(--jp-icon-caret-up);
}

.jp-CaseSensitiveIcon {
  background-image: var(--jp-icon-case-sensitive);
}

.jp-CheckIcon {
  background-image: var(--jp-icon-check);
}

.jp-CircleEmptyIcon {
  background-image: var(--jp-icon-circle-empty);
}

.jp-CircleIcon {
  background-image: var(--jp-icon-circle);
}

.jp-ClearIcon {
  background-image: var(--jp-icon-clear);
}

.jp-CloseIcon {
  background-image: var(--jp-icon-close);
}

.jp-CodeCheckIcon {
  background-image: var(--jp-icon-code-check);
}

.jp-CodeIcon {
  background-image: var(--jp-icon-code);
}

.jp-CollapseAllIcon {
  background-image: var(--jp-icon-collapse-all);
}

.jp-ConsoleIcon {
  background-image: var(--jp-icon-console);
}

.jp-CopyIcon {
  background-image: var(--jp-icon-copy);
}

.jp-CopyrightIcon {
  background-image: var(--jp-icon-copyright);
}

.jp-CutIcon {
  background-image: var(--jp-icon-cut);
}

.jp-DeleteIcon {
  background-image: var(--jp-icon-delete);
}

.jp-DownloadIcon {
  background-image: var(--jp-icon-download);
}

.jp-DuplicateIcon {
  background-image: var(--jp-icon-duplicate);
}

.jp-EditIcon {
  background-image: var(--jp-icon-edit);
}

.jp-EllipsesIcon {
  background-image: var(--jp-icon-ellipses);
}

.jp-ErrorIcon {
  background-image: var(--jp-icon-error);
}

.jp-ExpandAllIcon {
  background-image: var(--jp-icon-expand-all);
}

.jp-ExtensionIcon {
  background-image: var(--jp-icon-extension);
}

.jp-FastForwardIcon {
  background-image: var(--jp-icon-fast-forward);
}

.jp-FileIcon {
  background-image: var(--jp-icon-file);
}

.jp-FileUploadIcon {
  background-image: var(--jp-icon-file-upload);
}

.jp-FilterDotIcon {
  background-image: var(--jp-icon-filter-dot);
}

.jp-FilterIcon {
  background-image: var(--jp-icon-filter);
}

.jp-FilterListIcon {
  background-image: var(--jp-icon-filter-list);
}

.jp-FolderFavoriteIcon {
  background-image: var(--jp-icon-folder-favorite);
}

.jp-FolderIcon {
  background-image: var(--jp-icon-folder);
}

.jp-HomeIcon {
  background-image: var(--jp-icon-home);
}

.jp-Html5Icon {
  background-image: var(--jp-icon-html5);
}

.jp-ImageIcon {
  background-image: var(--jp-icon-image);
}

.jp-InfoIcon {
  background-image: var(--jp-icon-info);
}

.jp-InspectorIcon {
  background-image: var(--jp-icon-inspector);
}

.jp-JsonIcon {
  background-image: var(--jp-icon-json);
}

.jp-JuliaIcon {
  background-image: var(--jp-icon-julia);
}

.jp-JupyterFaviconIcon {
  background-image: var(--jp-icon-jupyter-favicon);
}

.jp-JupyterIcon {
  background-image: var(--jp-icon-jupyter);
}

.jp-JupyterlabWordmarkIcon {
  background-image: var(--jp-icon-jupyterlab-wordmark);
}

.jp-KernelIcon {
  background-image: var(--jp-icon-kernel);
}

.jp-KeyboardIcon {
  background-image: var(--jp-icon-keyboard);
}

.jp-LaunchIcon {
  background-image: var(--jp-icon-launch);
}

.jp-LauncherIcon {
  background-image: var(--jp-icon-launcher);
}

.jp-LineFormIcon {
  background-image: var(--jp-icon-line-form);
}

.jp-LinkIcon {
  background-image: var(--jp-icon-link);
}

.jp-ListIcon {
  background-image: var(--jp-icon-list);
}

.jp-MarkdownIcon {
  background-image: var(--jp-icon-markdown);
}

.jp-MoveDownIcon {
  background-image: var(--jp-icon-move-down);
}

.jp-MoveUpIcon {
  background-image: var(--jp-icon-move-up);
}

.jp-NewFolderIcon {
  background-image: var(--jp-icon-new-folder);
}

.jp-NotTrustedIcon {
  background-image: var(--jp-icon-not-trusted);
}

.jp-NotebookIcon {
  background-image: var(--jp-icon-notebook);
}

.jp-NumberingIcon {
  background-image: var(--jp-icon-numbering);
}

.jp-OfflineBoltIcon {
  background-image: var(--jp-icon-offline-bolt);
}

.jp-PaletteIcon {
  background-image: var(--jp-icon-palette);
}

.jp-PasteIcon {
  background-image: var(--jp-icon-paste);
}

.jp-PdfIcon {
  background-image: var(--jp-icon-pdf);
}

.jp-PythonIcon {
  background-image: var(--jp-icon-python);
}

.jp-RKernelIcon {
  background-image: var(--jp-icon-r-kernel);
}

.jp-ReactIcon {
  background-image: var(--jp-icon-react);
}

.jp-RedoIcon {
  background-image: var(--jp-icon-redo);
}

.jp-RefreshIcon {
  background-image: var(--jp-icon-refresh);
}

.jp-RegexIcon {
  background-image: var(--jp-icon-regex);
}

.jp-RunIcon {
  background-image: var(--jp-icon-run);
}

.jp-RunningIcon {
  background-image: var(--jp-icon-running);
}

.jp-SaveIcon {
  background-image: var(--jp-icon-save);
}

.jp-SearchIcon {
  background-image: var(--jp-icon-search);
}

.jp-SettingsIcon {
  background-image: var(--jp-icon-settings);
}

.jp-ShareIcon {
  background-image: var(--jp-icon-share);
}

.jp-SpreadsheetIcon {
  background-image: var(--jp-icon-spreadsheet);
}

.jp-StopIcon {
  background-image: var(--jp-icon-stop);
}

.jp-TabIcon {
  background-image: var(--jp-icon-tab);
}

.jp-TableRowsIcon {
  background-image: var(--jp-icon-table-rows);
}

.jp-TagIcon {
  background-image: var(--jp-icon-tag);
}

.jp-TerminalIcon {
  background-image: var(--jp-icon-terminal);
}

.jp-TextEditorIcon {
  background-image: var(--jp-icon-text-editor);
}

.jp-TocIcon {
  background-image: var(--jp-icon-toc);
}

.jp-TreeViewIcon {
  background-image: var(--jp-icon-tree-view);
}

.jp-TrustedIcon {
  background-image: var(--jp-icon-trusted);
}

.jp-UndoIcon {
  background-image: var(--jp-icon-undo);
}

.jp-UserIcon {
  background-image: var(--jp-icon-user);
}

.jp-UsersIcon {
  background-image: var(--jp-icon-users);
}

.jp-VegaIcon {
  background-image: var(--jp-icon-vega);
}

.jp-WordIcon {
  background-image: var(--jp-icon-word);
}

.jp-YamlIcon {
  background-image: var(--jp-icon-yaml);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * (DEPRECATED) Support for consuming icons as CSS background images
 */

.jp-Icon,
.jp-MaterialIcon {
  background-position: center;
  background-repeat: no-repeat;
  background-size: 16px;
  min-width: 16px;
  min-height: 16px;
}

.jp-Icon-cover {
  background-position: center;
  background-repeat: no-repeat;
  background-size: cover;
}

/**
 * (DEPRECATED) Support for specific CSS icon sizes
 */

.jp-Icon-16 {
  background-size: 16px;
  min-width: 16px;
  min-height: 16px;
}

.jp-Icon-18 {
  background-size: 18px;
  min-width: 18px;
  min-height: 18px;
}

.jp-Icon-20 {
  background-size: 20px;
  min-width: 20px;
  min-height: 20px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.lm-TabBar .lm-TabBar-addButton {
  align-items: center;
  display: flex;
  padding: 4px;
  padding-bottom: 5px;
  margin-right: 1px;
  background-color: var(--jp-layout-color2);
}

.lm-TabBar .lm-TabBar-addButton:hover {
  background-color: var(--jp-layout-color1);
}

.lm-DockPanel-tabBar .lm-TabBar-tab {
  width: var(--jp-private-horizontal-tab-width);
}

.lm-DockPanel-tabBar .lm-TabBar-content {
  flex: unset;
}

.lm-DockPanel-tabBar[data-orientation='horizontal'] {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * Support for icons as inline SVG HTMLElements
 */

/* recolor the primary elements of an icon */
.jp-icon0[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon1[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon2[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon3[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon4[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon0[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon1[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon2[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon3[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon4[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/* recolor the accent elements of an icon */
.jp-icon-accent0[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-accent1[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-accent2[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-accent3[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-accent4[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-accent0[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-accent1[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-accent2[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-accent3[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-accent4[stroke] {
  stroke: var(--jp-layout-color4);
}

/* set the color of an icon to transparent */
.jp-icon-none[fill] {
  fill: none;
}

.jp-icon-none[stroke] {
  stroke: none;
}

/* brand icon colors. Same for light and dark */
.jp-icon-brand0[fill] {
  fill: var(--jp-brand-color0);
}

.jp-icon-brand1[fill] {
  fill: var(--jp-brand-color1);
}

.jp-icon-brand2[fill] {
  fill: var(--jp-brand-color2);
}

.jp-icon-brand3[fill] {
  fill: var(--jp-brand-color3);
}

.jp-icon-brand4[fill] {
  fill: var(--jp-brand-color4);
}

.jp-icon-brand0[stroke] {
  stroke: var(--jp-brand-color0);
}

.jp-icon-brand1[stroke] {
  stroke: var(--jp-brand-color1);
}

.jp-icon-brand2[stroke] {
  stroke: var(--jp-brand-color2);
}

.jp-icon-brand3[stroke] {
  stroke: var(--jp-brand-color3);
}

.jp-icon-brand4[stroke] {
  stroke: var(--jp-brand-color4);
}

/* warn icon colors. Same for light and dark */
.jp-icon-warn0[fill] {
  fill: var(--jp-warn-color0);
}

.jp-icon-warn1[fill] {
  fill: var(--jp-warn-color1);
}

.jp-icon-warn2[fill] {
  fill: var(--jp-warn-color2);
}

.jp-icon-warn3[fill] {
  fill: var(--jp-warn-color3);
}

.jp-icon-warn0[stroke] {
  stroke: var(--jp-warn-color0);
}

.jp-icon-warn1[stroke] {
  stroke: var(--jp-warn-color1);
}

.jp-icon-warn2[stroke] {
  stroke: var(--jp-warn-color2);
}

.jp-icon-warn3[stroke] {
  stroke: var(--jp-warn-color3);
}

/* icon colors that contrast well with each other and most backgrounds */
.jp-icon-contrast0[fill] {
  fill: var(--jp-icon-contrast-color0);
}

.jp-icon-contrast1[fill] {
  fill: var(--jp-icon-contrast-color1);
}

.jp-icon-contrast2[fill] {
  fill: var(--jp-icon-contrast-color2);
}

.jp-icon-contrast3[fill] {
  fill: var(--jp-icon-contrast-color3);
}

.jp-icon-contrast0[stroke] {
  stroke: var(--jp-icon-contrast-color0);
}

.jp-icon-contrast1[stroke] {
  stroke: var(--jp-icon-contrast-color1);
}

.jp-icon-contrast2[stroke] {
  stroke: var(--jp-icon-contrast-color2);
}

.jp-icon-contrast3[stroke] {
  stroke: var(--jp-icon-contrast-color3);
}

.jp-icon-dot[fill] {
  fill: var(--jp-warn-color0);
}

.jp-jupyter-icon-color[fill] {
  fill: var(--jp-jupyter-icon-color, var(--jp-warn-color0));
}

.jp-notebook-icon-color[fill] {
  fill: var(--jp-notebook-icon-color, var(--jp-warn-color0));
}

.jp-json-icon-color[fill] {
  fill: var(--jp-json-icon-color, var(--jp-warn-color1));
}

.jp-console-icon-color[fill] {
  fill: var(--jp-console-icon-color, white);
}

.jp-console-icon-background-color[fill] {
  fill: var(--jp-console-icon-background-color, var(--jp-brand-color1));
}

.jp-terminal-icon-color[fill] {
  fill: var(--jp-terminal-icon-color, var(--jp-layout-color2));
}

.jp-terminal-icon-background-color[fill] {
  fill: var(
    --jp-terminal-icon-background-color,
    var(--jp-inverse-layout-color2)
  );
}

.jp-text-editor-icon-color[fill] {
  fill: var(--jp-text-editor-icon-color, var(--jp-inverse-layout-color3));
}

.jp-inspector-icon-color[fill] {
  fill: var(--jp-inspector-icon-color, var(--jp-inverse-layout-color3));
}

/* CSS for icons in selected filebrowser listing items */
.jp-DirListing-item.jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}

.jp-DirListing-item.jp-mod-selected .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}

/* stylelint-disable selector-max-class, selector-max-compound-selectors */

/**
* TODO: come up with non css-hack solution for showing the busy icon on top
*  of the close icon
* CSS for complex behavior of close icon of tabs in the main area tabbar
*/
.lm-DockPanel-tabBar
  .lm-TabBar-tab.lm-mod-closable.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon3[fill] {
  fill: none;
}

.lm-DockPanel-tabBar
  .lm-TabBar-tab.lm-mod-closable.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon-busy[fill] {
  fill: var(--jp-inverse-layout-color3);
}

/* stylelint-enable selector-max-class, selector-max-compound-selectors */

/* CSS for icons in status bar */
#jp-main-statusbar .jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}

#jp-main-statusbar .jp-mod-selected .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}

/* special handling for splash icon CSS. While the theme CSS reloads during
   splash, the splash icon can loose theming. To prevent that, we set a
   default for its color variable */
:root {
  --jp-warn-color0: var(--md-orange-700);
}

/* not sure what to do with this one, used in filebrowser listing */
.jp-DragIcon {
  margin-right: 4px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * Support for alt colors for icons as inline SVG HTMLElements
 */

/* alt recolor the primary elements of an icon */
.jp-icon-alt .jp-icon0[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-alt .jp-icon1[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-alt .jp-icon2[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-alt .jp-icon3[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-alt .jp-icon4[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-alt .jp-icon0[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-alt .jp-icon1[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-alt .jp-icon2[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-alt .jp-icon3[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-alt .jp-icon4[stroke] {
  stroke: var(--jp-layout-color4);
}

/* alt recolor the accent elements of an icon */
.jp-icon-alt .jp-icon-accent0[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon-alt .jp-icon-accent1[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon-alt .jp-icon-accent2[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon-alt .jp-icon-accent3[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon-alt .jp-icon-accent4[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-alt .jp-icon-accent0[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon-alt .jp-icon-accent1[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon-alt .jp-icon-accent2[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon-alt .jp-icon-accent3[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon-alt .jp-icon-accent4[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-icon-hoverShow:not(:hover) .jp-icon-hoverShow-content {
  display: none !important;
}

/**
 * Support for hover colors for icons as inline SVG HTMLElements
 */

/**
 * regular colors
 */

/* recolor the primary elements of an icon */
.jp-icon-hover :hover .jp-icon0-hover[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon-hover :hover .jp-icon1-hover[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon-hover :hover .jp-icon2-hover[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon-hover :hover .jp-icon3-hover[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon-hover :hover .jp-icon4-hover[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-hover :hover .jp-icon0-hover[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon-hover :hover .jp-icon1-hover[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon-hover :hover .jp-icon2-hover[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon-hover :hover .jp-icon3-hover[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon-hover :hover .jp-icon4-hover[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/* recolor the accent elements of an icon */
.jp-icon-hover :hover .jp-icon-accent0-hover[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-hover :hover .jp-icon-accent1-hover[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-hover :hover .jp-icon-accent2-hover[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-hover :hover .jp-icon-accent3-hover[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-hover :hover .jp-icon-accent4-hover[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-hover :hover .jp-icon-accent0-hover[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-hover :hover .jp-icon-accent1-hover[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-hover :hover .jp-icon-accent2-hover[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-hover :hover .jp-icon-accent3-hover[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-hover :hover .jp-icon-accent4-hover[stroke] {
  stroke: var(--jp-layout-color4);
}

/* set the color of an icon to transparent */
.jp-icon-hover :hover .jp-icon-none-hover[fill] {
  fill: none;
}

.jp-icon-hover :hover .jp-icon-none-hover[stroke] {
  stroke: none;
}

/**
 * inverse colors
 */

/* inverse recolor the primary elements of an icon */
.jp-icon-hover.jp-icon-alt :hover .jp-icon0-hover[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon1-hover[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon2-hover[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon3-hover[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon4-hover[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon0-hover[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon1-hover[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon2-hover[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon3-hover[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon4-hover[stroke] {
  stroke: var(--jp-layout-color4);
}

/* inverse recolor the accent elements of an icon */
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent0-hover[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent1-hover[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent2-hover[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent3-hover[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent4-hover[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent0-hover[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent1-hover[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent2-hover[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent3-hover[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent4-hover[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-IFrame {
  width: 100%;
  height: 100%;
}

.jp-IFrame > iframe {
  border: none;
}

/*
When drag events occur, `lm-mod-override-cursor` is added to the body.
Because iframes steal all cursor events, the following two rules are necessary
to suppress pointer events while resize drags are occurring. There may be a
better solution to this problem.
*/
body.lm-mod-override-cursor .jp-IFrame {
  position: relative;
}

body.lm-mod-override-cursor .jp-IFrame::before {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-HoverBox {
  position: fixed;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-FormGroup-content fieldset {
  border: none;
  padding: 0;
  min-width: 0;
  width: 100%;
}

/* stylelint-disable selector-max-type */

.jp-FormGroup-content fieldset .jp-inputFieldWrapper input,
.jp-FormGroup-content fieldset .jp-inputFieldWrapper select,
.jp-FormGroup-content fieldset .jp-inputFieldWrapper textarea {
  font-size: var(--jp-content-font-size2);
  border-color: var(--jp-input-border-color);
  border-style: solid;
  border-radius: var(--jp-border-radius);
  border-width: 1px;
  padding: 6px 8px;
  background: none;
  color: var(--jp-ui-font-color0);
  height: inherit;
}

.jp-FormGroup-content fieldset input[type='checkbox'] {
  position: relative;
  top: 2px;
  margin-left: 0;
}

.jp-FormGroup-content button.jp-mod-styled {
  cursor: pointer;
}

.jp-FormGroup-content .checkbox label {
  cursor: pointer;
  font-size: var(--jp-content-font-size1);
}

.jp-FormGroup-content .jp-root > fieldset > legend {
  display: none;
}

.jp-FormGroup-content .jp-root > fieldset > p {
  display: none;
}

/** copy of `input.jp-mod-styled:focus` style */
.jp-FormGroup-content fieldset input:focus,
.jp-FormGroup-content fieldset select:focus {
  -moz-outline-radius: unset;
  outline: var(--jp-border-width) solid var(--md-blue-500);
  outline-offset: -1px;
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-FormGroup-content fieldset input:hover:not(:focus),
.jp-FormGroup-content fieldset select:hover:not(:focus) {
  background-color: var(--jp-border-color2);
}

/* stylelint-enable selector-max-type */

.jp-FormGroup-content .checkbox .field-description {
  /* Disable default description field for checkbox:
   because other widgets do not have description fields,
   we add descriptions to each widget on the field level.
  */
  display: none;
}

.jp-FormGroup-content #root__description {
  display: none;
}

.jp-FormGroup-content .jp-modifiedIndicator {
  width: 5px;
  background-color: var(--jp-brand-color2);
  margin-top: 0;
  margin-left: calc(var(--jp-private-settingeditor-modifier-indent) * -1);
  flex-shrink: 0;
}

.jp-FormGroup-content .jp-modifiedIndicator.jp-errorIndicator {
  background-color: var(--jp-error-color0);
  margin-right: 0.5em;
}

/* RJSF ARRAY style */

.jp-arrayFieldWrapper legend {
  font-size: var(--jp-content-font-size2);
  color: var(--jp-ui-font-color0);
  flex-basis: 100%;
  padding: 4px 0;
  font-weight: var(--jp-content-heading-font-weight);
  border-bottom: 1px solid var(--jp-border-color2);
}

.jp-arrayFieldWrapper .field-description {
  padding: 4px 0;
  white-space: pre-wrap;
}

.jp-arrayFieldWrapper .array-item {
  width: 100%;
  border: 1px solid var(--jp-border-color2);
  border-radius: 4px;
  margin: 4px;
}

.jp-ArrayOperations {
  display: flex;
  margin-left: 8px;
}

.jp-ArrayOperationsButton {
  margin: 2px;
}

.jp-ArrayOperationsButton .jp-icon3[fill] {
  fill: var(--jp-ui-font-color0);
}

button.jp-ArrayOperationsButton.jp-mod-styled:disabled {
  cursor: not-allowed;
  opacity: 0.5;
}

/* RJSF form validation error */

.jp-FormGroup-content .validationErrors {
  color: var(--jp-error-color0);
}

/* Hide panel level error as duplicated the field level error */
.jp-FormGroup-content .panel.errors {
  display: none;
}

/* RJSF normal content (settings-editor) */

.jp-FormGroup-contentNormal {
  display: flex;
  align-items: center;
  flex-wrap: wrap;
}

.jp-FormGroup-contentNormal .jp-FormGroup-contentItem {
  margin-left: 7px;
  color: var(--jp-ui-font-color0);
}

.jp-FormGroup-contentNormal .jp-FormGroup-description {
  flex-basis: 100%;
  padding: 4px 7px;
}

.jp-FormGroup-contentNormal .jp-FormGroup-default {
  flex-basis: 100%;
  padding: 4px 7px;
}

.jp-FormGroup-contentNormal .jp-FormGroup-fieldLabel {
  font-size: var(--jp-content-font-size1);
  font-weight: normal;
  min-width: 120px;
}

.jp-FormGroup-contentNormal fieldset:not(:first-child) {
  margin-left: 7px;
}

.jp-FormGroup-contentNormal .field-array-of-string .array-item {
  /* Display `jp-ArrayOperations` buttons side-by-side with content except
    for small screens where flex-wrap will place them one below the other.
  */
  display: flex;
  align-items: center;
  flex-wrap: wrap;
}

.jp-FormGroup-contentNormal .jp-objectFieldWrapper .form-group {
  padding: 2px 8px 2px var(--jp-private-settingeditor-modifier-indent);
  margin-top: 2px;
}

/* RJSF compact content (metadata-form) */

.jp-FormGroup-content.jp-FormGroup-contentCompact {
  width: 100%;
}

.jp-FormGroup-contentCompact .form-group {
  display: flex;
  padding: 0.5em 0.2em 0.5em 0;
}

.jp-FormGroup-contentCompact
  .jp-FormGroup-compactTitle
  .jp-FormGroup-description {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color2);
}

.jp-FormGroup-contentCompact .jp-FormGroup-fieldLabel {
  padding-bottom: 0.3em;
}

.jp-FormGroup-contentCompact .jp-inputFieldWrapper .form-control {
  width: 100%;
  box-sizing: border-box;
}

.jp-FormGroup-contentCompact .jp-arrayFieldWrapper .jp-FormGroup-compactTitle {
  padding-bottom: 7px;
}

.jp-FormGroup-contentCompact
  .jp-objectFieldWrapper
  .jp-objectFieldWrapper
  .form-group {
  padding: 2px 8px 2px var(--jp-private-settingeditor-modifier-indent);
  margin-top: 2px;
}

.jp-FormGroup-contentCompact ul.error-detail {
  margin-block-start: 0.5em;
  margin-block-end: 0.5em;
  padding-inline-start: 1em;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-SidePanel {
  display: flex;
  flex-direction: column;
  min-width: var(--jp-sidebar-min-width);
  overflow-y: auto;
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);
  font-size: var(--jp-ui-font-size1);
}

.jp-SidePanel-header {
  flex: 0 0 auto;
  display: flex;
  border-bottom: var(--jp-border-width) solid var(--jp-border-color2);
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  letter-spacing: 1px;
  margin: 0;
  padding: 2px;
  text-transform: uppercase;
}

.jp-SidePanel-toolbar {
  flex: 0 0 auto;
}

.jp-SidePanel-content {
  flex: 1 1 auto;
}

.jp-SidePanel-toolbar,
.jp-AccordionPanel-toolbar {
  height: var(--jp-private-toolbar-height);
}

.jp-SidePanel-toolbar.jp-Toolbar-micro {
  display: none;
}

.lm-AccordionPanel .jp-AccordionPanel-title {
  box-sizing: border-box;
  line-height: 25px;
  margin: 0;
  display: flex;
  align-items: center;
  background: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  font-size: var(--jp-ui-font-size0);
}

.jp-AccordionPanel-title {
  cursor: pointer;
  user-select: none;
  -moz-user-select: none;
  -webkit-user-select: none;
  text-transform: uppercase;
}

.lm-AccordionPanel[data-orientation='horizontal'] > .jp-AccordionPanel-title {
  /* Title is rotated for horizontal accordion panel using CSS */
  display: block;
  transform-origin: top left;
  transform: rotate(-90deg) translate(-100%);
}

.jp-AccordionPanel-title .lm-AccordionPanel-titleLabel {
  user-select: none;
  text-overflow: ellipsis;
  white-space: nowrap;
  overflow: hidden;
}

.jp-AccordionPanel-title .lm-AccordionPanel-titleCollapser {
  transform: rotate(-90deg);
  margin: auto 0;
  height: 16px;
}

.jp-AccordionPanel-title.lm-mod-expanded .lm-AccordionPanel-titleCollapser {
  transform: rotate(0deg);
}

.lm-AccordionPanel .jp-AccordionPanel-toolbar {
  background: none;
  box-shadow: none;
  border: none;
  margin-left: auto;
}

.lm-AccordionPanel .lm-SplitPanel-handle:hover {
  background: var(--jp-layout-color3);
}

.jp-text-truncated {
  overflow: hidden;
  text-overflow: ellipsis;
  white-space: nowrap;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Spinner {
  position: absolute;
  display: flex;
  justify-content: center;
  align-items: center;
  z-index: 10;
  left: 0;
  top: 0;
  width: 100%;
  height: 100%;
  background: var(--jp-layout-color0);
  outline: none;
}

.jp-SpinnerContent {
  font-size: 10px;
  margin: 50px auto;
  text-indent: -9999em;
  width: 3em;
  height: 3em;
  border-radius: 50%;
  background: var(--jp-brand-color3);
  background: linear-gradient(
    to right,
    #f37626 10%,
    rgba(255, 255, 255, 0) 42%
  );
  position: relative;
  animation: load3 1s infinite linear, fadeIn 1s;
}

.jp-SpinnerContent::before {
  width: 50%;
  height: 50%;
  background: #f37626;
  border-radius: 100% 0 0;
  position: absolute;
  top: 0;
  left: 0;
  content: '';
}

.jp-SpinnerContent::after {
  background: var(--jp-layout-color0);
  width: 75%;
  height: 75%;
  border-radius: 50%;
  content: '';
  margin: auto;
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  right: 0;
}

@keyframes fadeIn {
  0% {
    opacity: 0;
  }

  100% {
    opacity: 1;
  }
}

@keyframes load3 {
  0% {
    transform: rotate(0deg);
  }

  100% {
    transform: rotate(360deg);
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

button.jp-mod-styled {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  border: none;
  box-sizing: border-box;
  text-align: center;
  line-height: 32px;
  height: 32px;
  padding: 0 12px;
  letter-spacing: 0.8px;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

input.jp-mod-styled {
  background: var(--jp-input-background);
  height: 28px;
  box-sizing: border-box;
  border: var(--jp-border-width) solid var(--jp-border-color1);
  padding-left: 7px;
  padding-right: 7px;
  font-size: var(--jp-ui-font-size2);
  color: var(--jp-ui-font-color0);
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

input[type='checkbox'].jp-mod-styled {
  appearance: checkbox;
  -webkit-appearance: checkbox;
  -moz-appearance: checkbox;
  height: auto;
}

input.jp-mod-styled:focus {
  border: var(--jp-border-width) solid var(--md-blue-500);
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-select-wrapper {
  display: flex;
  position: relative;
  flex-direction: column;
  padding: 1px;
  background-color: var(--jp-layout-color1);
  box-sizing: border-box;
  margin-bottom: 12px;
}

.jp-select-wrapper:not(.multiple) {
  height: 28px;
}

.jp-select-wrapper.jp-mod-focused select.jp-mod-styled {
  border: var(--jp-border-width) solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
  background-color: var(--jp-input-active-background);
}

select.jp-mod-styled:hover {
  cursor: pointer;
  color: var(--jp-ui-font-color0);
  background-color: var(--jp-input-hover-background);
  box-shadow: inset 0 0 1px rgba(0, 0, 0, 0.5);
}

select.jp-mod-styled {
  flex: 1 1 auto;
  width: 100%;
  font-size: var(--jp-ui-font-size2);
  background: var(--jp-input-background);
  color: var(--jp-ui-font-color0);
  padding: 0 25px 0 8px;
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  border-radius: 0;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

select.jp-mod-styled:not([multiple]) {
  height: 32px;
}

select.jp-mod-styled[multiple] {
  max-height: 200px;
  overflow-y: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-switch {
  display: flex;
  align-items: center;
  padding-left: 4px;
  padding-right: 4px;
  font-size: var(--jp-ui-font-size1);
  background-color: transparent;
  color: var(--jp-ui-font-color1);
  border: none;
  height: 20px;
}

.jp-switch:hover {
  background-color: var(--jp-layout-color2);
}

.jp-switch-label {
  margin-right: 5px;
  font-family: var(--jp-ui-font-family);
}

.jp-switch-track {
  cursor: pointer;
  background-color: var(--jp-switch-color, var(--jp-border-color1));
  -webkit-transition: 0.4s;
  transition: 0.4s;
  border-radius: 34px;
  height: 16px;
  width: 35px;
  position: relative;
}

.jp-switch-track::before {
  content: '';
  position: absolute;
  height: 10px;
  width: 10px;
  margin: 3px;
  left: 0;
  background-color: var(--jp-ui-inverse-font-color1);
  -webkit-transition: 0.4s;
  transition: 0.4s;
  border-radius: 50%;
}

.jp-switch[aria-checked='true'] .jp-switch-track {
  background-color: var(--jp-switch-true-position-color, var(--jp-warn-color0));
}

.jp-switch[aria-checked='true'] .jp-switch-track::before {
  /* track width (35) - margins (3 + 3) - thumb width (10) */
  left: 19px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

:root {
  --jp-private-toolbar-height: calc(
    28px + var(--jp-border-width)
  ); /* leave 28px for content */
}

.jp-Toolbar {
  color: var(--jp-ui-font-color1);
  flex: 0 0 auto;
  display: flex;
  flex-direction: row;
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  background: var(--jp-toolbar-background);
  min-height: var(--jp-toolbar-micro-height);
  padding: 2px;
  z-index: 8;
  overflow-x: hidden;
}

/* Toolbar items */

.jp-Toolbar > .jp-Toolbar-item.jp-Toolbar-spacer {
  flex-grow: 1;
  flex-shrink: 1;
}

.jp-Toolbar-item.jp-Toolbar-kernelStatus {
  display: inline-block;
  width: 32px;
  background-repeat: no-repeat;
  background-position: center;
  background-size: 16px;
}

.jp-Toolbar > .jp-Toolbar-item {
  flex: 0 0 auto;
  display: flex;
  padding-left: 1px;
  padding-right: 1px;
  font-size: var(--jp-ui-font-size1);
  line-height: var(--jp-private-toolbar-height);
  height: 100%;
}

/* Toolbar buttons */

/* This is the div we use to wrap the react component into a Widget */
div.jp-ToolbarButton {
  color: transparent;
  border: none;
  box-sizing: border-box;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
  padding: 0;
  margin: 0;
}

button.jp-ToolbarButtonComponent {
  background: var(--jp-layout-color1);
  border: none;
  box-sizing: border-box;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
  padding: 0 6px;
  margin: 0;
  height: 24px;
  border-radius: var(--jp-border-radius);
  display: flex;
  align-items: center;
  text-align: center;
  font-size: 14px;
  min-width: unset;
  min-height: unset;
}

button.jp-ToolbarButtonComponent:disabled {
  opacity: 0.4;
}

button.jp-ToolbarButtonComponent > span {
  padding: 0;
  flex: 0 0 auto;
}

button.jp-ToolbarButtonComponent .jp-ToolbarButtonComponent-label {
  font-size: var(--jp-ui-font-size1);
  line-height: 100%;
  padding-left: 2px;
  color: var(--jp-ui-font-color1);
  font-family: var(--jp-ui-font-family);
}

#jp-main-dock-panel[data-mode='single-document']
  .jp-MainAreaWidget
  > .jp-Toolbar.jp-Toolbar-micro {
  padding: 0;
  min-height: 0;
}

#jp-main-dock-panel[data-mode='single-document']
  .jp-MainAreaWidget
  > .jp-Toolbar {
  border: none;
  box-shadow: none;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-WindowedPanel-outer {
  position: relative;
  overflow-y: auto;
}

.jp-WindowedPanel-inner {
  position: relative;
}

.jp-WindowedPanel-window {
  position: absolute;
  left: 0;
  right: 0;
  overflow: visible;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* Sibling imports */

body {
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
}

/* Disable native link decoration styles everywhere outside of dialog boxes */
a {
  text-decoration: unset;
  color: unset;
}

a:hover {
  text-decoration: unset;
  color: unset;
}

/* Accessibility for links inside dialog box text */
.jp-Dialog-content a {
  text-decoration: revert;
  color: var(--jp-content-link-color);
}

.jp-Dialog-content a:hover {
  text-decoration: revert;
}

/* Styles for ui-components */
.jp-Button {
  color: var(--jp-ui-font-color2);
  border-radius: var(--jp-border-radius);
  padding: 0 12px;
  font-size: var(--jp-ui-font-size1);

  /* Copy from blueprint 3 */
  display: inline-flex;
  flex-direction: row;
  border: none;
  cursor: pointer;
  align-items: center;
  justify-content: center;
  text-align: left;
  vertical-align: middle;
  min-height: 30px;
  min-width: 30px;
}

.jp-Button:disabled {
  cursor: not-allowed;
}

.jp-Button:empty {
  padding: 0 !important;
}

.jp-Button.jp-mod-small {
  min-height: 24px;
  min-width: 24px;
  font-size: 12px;
  padding: 0 7px;
}

/* Use our own theme for hover styles */
.jp-Button.jp-mod-minimal:hover {
  background-color: var(--jp-layout-color2);
}

.jp-Button.jp-mod-minimal {
  background: none;
}

.jp-InputGroup {
  display: block;
  position: relative;
}

.jp-InputGroup input {
  box-sizing: border-box;
  border: none;
  border-radius: 0;
  background-color: transparent;
  color: var(--jp-ui-font-color0);
  box-shadow: inset 0 0 0 var(--jp-border-width) var(--jp-input-border-color);
  padding-bottom: 0;
  padding-top: 0;
  padding-left: 10px;
  padding-right: 28px;
  position: relative;
  width: 100%;
  -webkit-appearance: none;
  -moz-appearance: none;
  appearance: none;
  font-size: 14px;
  font-weight: 400;
  height: 30px;
  line-height: 30px;
  outline: none;
  vertical-align: middle;
}

.jp-InputGroup input:focus {
  box-shadow: inset 0 0 0 var(--jp-border-width)
      var(--jp-input-active-box-shadow-color),
    inset 0 0 0 3px var(--jp-input-active-box-shadow-color);
}

.jp-InputGroup input:disabled {
  cursor: not-allowed;
  resize: block;
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color2);
}

.jp-InputGroup input:disabled ~ span {
  cursor: not-allowed;
  color: var(--jp-ui-font-color2);
}

.jp-InputGroup input::placeholder,
input::placeholder {
  color: var(--jp-ui-font-color2);
}

.jp-InputGroupAction {
  position: absolute;
  bottom: 1px;
  right: 0;
  padding: 6px;
}

.jp-HTMLSelect.jp-DefaultStyle select {
  background-color: initial;
  border: none;
  border-radius: 0;
  box-shadow: none;
  color: var(--jp-ui-font-color0);
  display: block;
  font-size: var(--jp-ui-font-size1);
  font-family: var(--jp-ui-font-family);
  height: 24px;
  line-height: 14px;
  padding: 0 25px 0 10px;
  text-align: left;
  -moz-appearance: none;
  -webkit-appearance: none;
}

.jp-HTMLSelect.jp-DefaultStyle select:disabled {
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color2);
  cursor: not-allowed;
  resize: block;
}

.jp-HTMLSelect.jp-DefaultStyle select:disabled ~ span {
  cursor: not-allowed;
}

/* Use our own theme for hover and option styles */
/* stylelint-disable-next-line selector-max-type */
.jp-HTMLSelect.jp-DefaultStyle select:hover,
.jp-HTMLSelect.jp-DefaultStyle select > option {
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color0);
}

select {
  box-sizing: border-box;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-StatusBar-Widget {
  display: flex;
  align-items: center;
  background: var(--jp-layout-color2);
  min-height: var(--jp-statusbar-height);
  justify-content: space-between;
  padding: 0 10px;
}

.jp-StatusBar-Left {
  display: flex;
  align-items: center;
  flex-direction: row;
}

.jp-StatusBar-Middle {
  display: flex;
  align-items: center;
}

.jp-StatusBar-Right {
  display: flex;
  align-items: center;
  flex-direction: row-reverse;
}

.jp-StatusBar-Item {
  max-height: var(--jp-statusbar-height);
  margin: 0 2px;
  height: var(--jp-statusbar-height);
  white-space: nowrap;
  text-overflow: ellipsis;
  color: var(--jp-ui-font-color1);
  padding: 0 6px;
}

.jp-mod-highlighted:hover {
  background-color: var(--jp-layout-color3);
}

.jp-mod-clicked {
  background-color: var(--jp-brand-color1);
}

.jp-mod-clicked:hover {
  background-color: var(--jp-brand-color0);
}

.jp-mod-clicked .jp-StatusBar-TextItem {
  color: var(--jp-ui-inverse-font-color1);
}

.jp-StatusBar-HoverItem {
  box-shadow: '0px 4px 4px rgba(0, 0, 0, 0.25)';
}

.jp-StatusBar-TextItem {
  font-size: var(--jp-ui-font-size1);
  font-family: var(--jp-ui-font-family);
  line-height: 24px;
  color: var(--jp-ui-font-color1);
}

.jp-StatusBar-GroupItem {
  display: flex;
  align-items: center;
  flex-direction: row;
}

.jp-Statusbar-ProgressCircle svg {
  display: block;
  margin: 0 auto;
  width: 16px;
  height: 24px;
  align-self: normal;
}

.jp-Statusbar-ProgressCircle path {
  fill: var(--jp-inverse-layout-color3);
}

.jp-Statusbar-ProgressBar-progress-bar {
  height: 10px;
  width: 100px;
  border: solid 0.25px var(--jp-brand-color2);
  border-radius: 3px;
  overflow: hidden;
  align-self: center;
}

.jp-Statusbar-ProgressBar-progress-bar > div {
  background-color: var(--jp-brand-color2);
  background-image: linear-gradient(
    -45deg,
    rgba(255, 255, 255, 0.2) 25%,
    transparent 25%,
    transparent 50%,
    rgba(255, 255, 255, 0.2) 50%,
    rgba(255, 255, 255, 0.2) 75%,
    transparent 75%,
    transparent
  );
  background-size: 40px 40px;
  float: left;
  width: 0%;
  height: 100%;
  font-size: 12px;
  line-height: 14px;
  color: #fff;
  text-align: center;
  animation: jp-Statusbar-ExecutionTime-progress-bar 2s linear infinite;
}

.jp-Statusbar-ProgressBar-progress-bar p {
  color: var(--jp-ui-font-color1);
  font-family: var(--jp-ui-font-family);
  font-size: var(--jp-ui-font-size1);
  line-height: 10px;
  width: 100px;
}

@keyframes jp-Statusbar-ExecutionTime-progress-bar {
  0% {
    background-position: 0 0;
  }

  100% {
    background-position: 40px 40px;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-commandpalette-search-height: 28px;
}

/*-----------------------------------------------------------------------------
| Overall styles
|----------------------------------------------------------------------------*/

.lm-CommandPalette {
  padding-bottom: 0;
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);

  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
}

/*-----------------------------------------------------------------------------
| Modal variant
|----------------------------------------------------------------------------*/

.jp-ModalCommandPalette {
  position: absolute;
  z-index: 10000;
  top: 38px;
  left: 30%;
  margin: 0;
  padding: 4px;
  width: 40%;
  box-shadow: var(--jp-elevation-z4);
  border-radius: 4px;
  background: var(--jp-layout-color0);
}

.jp-ModalCommandPalette .lm-CommandPalette {
  max-height: 40vh;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-close-icon::after {
  display: none;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-CommandPalette-header {
  display: none;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-CommandPalette-item {
  margin-left: 4px;
  margin-right: 4px;
}

.jp-ModalCommandPalette
  .lm-CommandPalette
  .lm-CommandPalette-item.lm-mod-disabled {
  display: none;
}

/*-----------------------------------------------------------------------------
| Search
|----------------------------------------------------------------------------*/

.lm-CommandPalette-search {
  padding: 4px;
  background-color: var(--jp-layout-color1);
  z-index: 2;
}

.lm-CommandPalette-wrapper {
  overflow: overlay;
  padding: 0 9px;
  background-color: var(--jp-input-active-background);
  height: 30px;
  box-shadow: inset 0 0 0 var(--jp-border-width) var(--jp-input-border-color);
}

.lm-CommandPalette.lm-mod-focused .lm-CommandPalette-wrapper {
  box-shadow: inset 0 0 0 1px var(--jp-input-active-box-shadow-color),
    inset 0 0 0 3px var(--jp-input-active-box-shadow-color);
}

.jp-SearchIconGroup {
  color: white;
  background-color: var(--jp-brand-color1);
  position: absolute;
  top: 4px;
  right: 4px;
  padding: 5px 5px 1px;
}

.jp-SearchIconGroup svg {
  height: 20px;
  width: 20px;
}

.jp-SearchIconGroup .jp-icon3[fill] {
  fill: var(--jp-layout-color0);
}

.lm-CommandPalette-input {
  background: transparent;
  width: calc(100% - 18px);
  float: left;
  border: none;
  outline: none;
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  line-height: var(--jp-private-commandpalette-search-height);
}

.lm-CommandPalette-input::-webkit-input-placeholder,
.lm-CommandPalette-input::-moz-placeholder,
.lm-CommandPalette-input:-ms-input-placeholder {
  color: var(--jp-ui-font-color2);
  font-size: var(--jp-ui-font-size1);
}

/*-----------------------------------------------------------------------------
| Results
|----------------------------------------------------------------------------*/

.lm-CommandPalette-header:first-child {
  margin-top: 0;
}

.lm-CommandPalette-header {
  border-bottom: solid var(--jp-border-width) var(--jp-border-color2);
  color: var(--jp-ui-font-color1);
  cursor: pointer;
  display: flex;
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  letter-spacing: 1px;
  margin-top: 8px;
  padding: 8px 0 8px 12px;
  text-transform: uppercase;
}

.lm-CommandPalette-header.lm-mod-active {
  background: var(--jp-layout-color2);
}

.lm-CommandPalette-header > mark {
  background-color: transparent;
  font-weight: bold;
  color: var(--jp-ui-font-color1);
}

.lm-CommandPalette-item {
  padding: 4px 12px 4px 4px;
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  font-weight: 400;
  display: flex;
}

.lm-CommandPalette-item.lm-mod-disabled {
  color: var(--jp-ui-font-color2);
}

.lm-CommandPalette-item.lm-mod-active {
  color: var(--jp-ui-inverse-font-color1);
  background: var(--jp-brand-color1);
}

.lm-CommandPalette-item.lm-mod-active .lm-CommandPalette-itemLabel > mark {
  color: var(--jp-ui-inverse-font-color0);
}

.lm-CommandPalette-item.lm-mod-active .jp-icon-selectable[fill] {
  fill: var(--jp-layout-color0);
}

.lm-CommandPalette-item.lm-mod-active:hover:not(.lm-mod-disabled) {
  color: var(--jp-ui-inverse-font-color1);
  background: var(--jp-brand-color1);
}

.lm-CommandPalette-item:hover:not(.lm-mod-active):not(.lm-mod-disabled) {
  background: var(--jp-layout-color2);
}

.lm-CommandPalette-itemContent {
  overflow: hidden;
}

.lm-CommandPalette-itemLabel > mark {
  color: var(--jp-ui-font-color0);
  background-color: transparent;
  font-weight: bold;
}

.lm-CommandPalette-item.lm-mod-disabled mark {
  color: var(--jp-ui-font-color2);
}

.lm-CommandPalette-item .lm-CommandPalette-itemIcon {
  margin: 0 4px 0 0;
  position: relative;
  width: 16px;
  top: 2px;
  flex: 0 0 auto;
}

.lm-CommandPalette-item.lm-mod-disabled .lm-CommandPalette-itemIcon {
  opacity: 0.6;
}

.lm-CommandPalette-item .lm-CommandPalette-itemShortcut {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemCaption {
  display: none;
}

.lm-CommandPalette-content {
  background-color: var(--jp-layout-color1);
}

.lm-CommandPalette-content:empty::after {
  content: 'No results';
  margin: auto;
  margin-top: 20px;
  width: 100px;
  display: block;
  font-size: var(--jp-ui-font-size2);
  font-family: var(--jp-ui-font-family);
  font-weight: lighter;
}

.lm-CommandPalette-emptyMessage {
  text-align: center;
  margin-top: 24px;
  line-height: 1.32;
  padding: 0 8px;
  color: var(--jp-content-font-color3);
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Dialog {
  position: absolute;
  z-index: 10000;
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  top: 0;
  left: 0;
  margin: 0;
  padding: 0;
  width: 100%;
  height: 100%;
  background: var(--jp-dialog-background);
}

.jp-Dialog-content {
  display: flex;
  flex-direction: column;
  margin-left: auto;
  margin-right: auto;
  background: var(--jp-layout-color1);
  padding: 24px 24px 12px;
  min-width: 300px;
  min-height: 150px;
  max-width: 1000px;
  max-height: 500px;
  box-sizing: border-box;
  box-shadow: var(--jp-elevation-z20);
  word-wrap: break-word;
  border-radius: var(--jp-border-radius);

  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color1);
  resize: both;
}

.jp-Dialog-content.jp-Dialog-content-small {
  max-width: 500px;
}

.jp-Dialog-button {
  overflow: visible;
}

button.jp-Dialog-button:focus {
  outline: 1px solid var(--jp-brand-color1);
  outline-offset: 4px;
  -moz-outline-radius: 0;
}

button.jp-Dialog-button:focus::-moz-focus-inner {
  border: 0;
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-accept:focus,
button.jp-Dialog-button.jp-mod-styled.jp-mod-warn:focus,
button.jp-Dialog-button.jp-mod-styled.jp-mod-reject:focus {
  outline-offset: 4px;
  -moz-outline-radius: 0;
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-accept:focus {
  outline: 1px solid var(--jp-accept-color-normal, var(--jp-brand-color1));
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-warn:focus {
  outline: 1px solid var(--jp-warn-color-normal, var(--jp-error-color1));
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-reject:focus {
  outline: 1px solid var(--jp-reject-color-normal, var(--md-grey-600));
}

button.jp-Dialog-close-button {
  padding: 0;
  height: 100%;
  min-width: unset;
  min-height: unset;
}

.jp-Dialog-header {
  display: flex;
  justify-content: space-between;
  flex: 0 0 auto;
  padding-bottom: 12px;
  font-size: var(--jp-ui-font-size3);
  font-weight: 400;
  color: var(--jp-ui-font-color1);
}

.jp-Dialog-body {
  display: flex;
  flex-direction: column;
  flex: 1 1 auto;
  font-size: var(--jp-ui-font-size1);
  background: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  overflow: auto;
}

.jp-Dialog-footer {
  display: flex;
  flex-direction: row;
  justify-content: flex-end;
  align-items: center;
  flex: 0 0 auto;
  margin-left: -12px;
  margin-right: -12px;
  padding: 12px;
}

.jp-Dialog-checkbox {
  padding-right: 5px;
}

.jp-Dialog-checkbox > input:focus-visible {
  outline: 1px solid var(--jp-input-active-border-color);
  outline-offset: 1px;
}

.jp-Dialog-spacer {
  flex: 1 1 auto;
}

.jp-Dialog-title {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.jp-Dialog-body > .jp-select-wrapper {
  width: 100%;
}

.jp-Dialog-body > button {
  padding: 0 16px;
}

.jp-Dialog-body > label {
  line-height: 1.4;
  color: var(--jp-ui-font-color0);
}

.jp-Dialog-button.jp-mod-styled:not(:last-child) {
  margin-right: 12px;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-Input-Boolean-Dialog {
  flex-direction: row-reverse;
  align-items: end;
  width: 100%;
}

.jp-Input-Boolean-Dialog > label {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-MainAreaWidget > :focus {
  outline: none;
}

.jp-MainAreaWidget .jp-MainAreaWidget-error {
  padding: 6px;
}

.jp-MainAreaWidget .jp-MainAreaWidget-error > pre {
  width: auto;
  padding: 10px;
  background: var(--jp-error-color3);
  border: var(--jp-border-width) solid var(--jp-error-color1);
  border-radius: var(--jp-border-radius);
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  white-space: pre-wrap;
  word-wrap: break-word;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/**
 * google-material-color v1.2.6
 * https://github.com/danlevan/google-material-color
 */
:root {
  --md-red-50: #ffebee;
  --md-red-100: #ffcdd2;
  --md-red-200: #ef9a9a;
  --md-red-300: #e57373;
  --md-red-400: #ef5350;
  --md-red-500: #f44336;
  --md-red-600: #e53935;
  --md-red-700: #d32f2f;
  --md-red-800: #c62828;
  --md-red-900: #b71c1c;
  --md-red-A100: #ff8a80;
  --md-red-A200: #ff5252;
  --md-red-A400: #ff1744;
  --md-red-A700: #d50000;
  --md-pink-50: #fce4ec;
  --md-pink-100: #f8bbd0;
  --md-pink-200: #f48fb1;
  --md-pink-300: #f06292;
  --md-pink-400: #ec407a;
  --md-pink-500: #e91e63;
  --md-pink-600: #d81b60;
  --md-pink-700: #c2185b;
  --md-pink-800: #ad1457;
  --md-pink-900: #880e4f;
  --md-pink-A100: #ff80ab;
  --md-pink-A200: #ff4081;
  --md-pink-A400: #f50057;
  --md-pink-A700: #c51162;
  --md-purple-50: #f3e5f5;
  --md-purple-100: #e1bee7;
  --md-purple-200: #ce93d8;
  --md-purple-300: #ba68c8;
  --md-purple-400: #ab47bc;
  --md-purple-500: #9c27b0;
  --md-purple-600: #8e24aa;
  --md-purple-700: #7b1fa2;
  --md-purple-800: #6a1b9a;
  --md-purple-900: #4a148c;
  --md-purple-A100: #ea80fc;
  --md-purple-A200: #e040fb;
  --md-purple-A400: #d500f9;
  --md-purple-A700: #a0f;
  --md-deep-purple-50: #ede7f6;
  --md-deep-purple-100: #d1c4e9;
  --md-deep-purple-200: #b39ddb;
  --md-deep-purple-300: #9575cd;
  --md-deep-purple-400: #7e57c2;
  --md-deep-purple-500: #673ab7;
  --md-deep-purple-600: #5e35b1;
  --md-deep-purple-700: #512da8;
  --md-deep-purple-800: #4527a0;
  --md-deep-purple-900: #311b92;
  --md-deep-purple-A100: #b388ff;
  --md-deep-purple-A200: #7c4dff;
  --md-deep-purple-A400: #651fff;
  --md-deep-purple-A700: #6200ea;
  --md-indigo-50: #e8eaf6;
  --md-indigo-100: #c5cae9;
  --md-indigo-200: #9fa8da;
  --md-indigo-300: #7986cb;
  --md-indigo-400: #5c6bc0;
  --md-indigo-500: #3f51b5;
  --md-indigo-600: #3949ab;
  --md-indigo-700: #303f9f;
  --md-indigo-800: #283593;
  --md-indigo-900: #1a237e;
  --md-indigo-A100: #8c9eff;
  --md-indigo-A200: #536dfe;
  --md-indigo-A400: #3d5afe;
  --md-indigo-A700: #304ffe;
  --md-blue-50: #e3f2fd;
  --md-blue-100: #bbdefb;
  --md-blue-200: #90caf9;
  --md-blue-300: #64b5f6;
  --md-blue-400: #42a5f5;
  --md-blue-500: #2196f3;
  --md-blue-600: #1e88e5;
  --md-blue-700: #1976d2;
  --md-blue-800: #1565c0;
  --md-blue-900: #0d47a1;
  --md-blue-A100: #82b1ff;
  --md-blue-A200: #448aff;
  --md-blue-A400: #2979ff;
  --md-blue-A700: #2962ff;
  --md-light-blue-50: #e1f5fe;
  --md-light-blue-100: #b3e5fc;
  --md-light-blue-200: #81d4fa;
  --md-light-blue-300: #4fc3f7;
  --md-light-blue-400: #29b6f6;
  --md-light-blue-500: #03a9f4;
  --md-light-blue-600: #039be5;
  --md-light-blue-700: #0288d1;
  --md-light-blue-800: #0277bd;
  --md-light-blue-900: #01579b;
  --md-light-blue-A100: #80d8ff;
  --md-light-blue-A200: #40c4ff;
  --md-light-blue-A400: #00b0ff;
  --md-light-blue-A700: #0091ea;
  --md-cyan-50: #e0f7fa;
  --md-cyan-100: #b2ebf2;
  --md-cyan-200: #80deea;
  --md-cyan-300: #4dd0e1;
  --md-cyan-400: #26c6da;
  --md-cyan-500: #00bcd4;
  --md-cyan-600: #00acc1;
  --md-cyan-700: #0097a7;
  --md-cyan-800: #00838f;
  --md-cyan-900: #006064;
  --md-cyan-A100: #84ffff;
  --md-cyan-A200: #18ffff;
  --md-cyan-A400: #00e5ff;
  --md-cyan-A700: #00b8d4;
  --md-teal-50: #e0f2f1;
  --md-teal-100: #b2dfdb;
  --md-teal-200: #80cbc4;
  --md-teal-300: #4db6ac;
  --md-teal-400: #26a69a;
  --md-teal-500: #009688;
  --md-teal-600: #00897b;
  --md-teal-700: #00796b;
  --md-teal-800: #00695c;
  --md-teal-900: #004d40;
  --md-teal-A100: #a7ffeb;
  --md-teal-A200: #64ffda;
  --md-teal-A400: #1de9b6;
  --md-teal-A700: #00bfa5;
  --md-green-50: #e8f5e9;
  --md-green-100: #c8e6c9;
  --md-green-200: #a5d6a7;
  --md-green-300: #81c784;
  --md-green-400: #66bb6a;
  --md-green-500: #4caf50;
  --md-green-600: #43a047;
  --md-green-700: #388e3c;
  --md-green-800: #2e7d32;
  --md-green-900: #1b5e20;
  --md-green-A100: #b9f6ca;
  --md-green-A200: #69f0ae;
  --md-green-A400: #00e676;
  --md-green-A700: #00c853;
  --md-light-green-50: #f1f8e9;
  --md-light-green-100: #dcedc8;
  --md-light-green-200: #c5e1a5;
  --md-light-green-300: #aed581;
  --md-light-green-400: #9ccc65;
  --md-light-green-500: #8bc34a;
  --md-light-green-600: #7cb342;
  --md-light-green-700: #689f38;
  --md-light-green-800: #558b2f;
  --md-light-green-900: #33691e;
  --md-light-green-A100: #ccff90;
  --md-light-green-A200: #b2ff59;
  --md-light-green-A400: #76ff03;
  --md-light-green-A700: #64dd17;
  --md-lime-50: #f9fbe7;
  --md-lime-100: #f0f4c3;
  --md-lime-200: #e6ee9c;
  --md-lime-300: #dce775;
  --md-lime-400: #d4e157;
  --md-lime-500: #cddc39;
  --md-lime-600: #c0ca33;
  --md-lime-700: #afb42b;
  --md-lime-800: #9e9d24;
  --md-lime-900: #827717;
  --md-lime-A100: #f4ff81;
  --md-lime-A200: #eeff41;
  --md-lime-A400: #c6ff00;
  --md-lime-A700: #aeea00;
  --md-yellow-50: #fffde7;
  --md-yellow-100: #fff9c4;
  --md-yellow-200: #fff59d;
  --md-yellow-300: #fff176;
  --md-yellow-400: #ffee58;
  --md-yellow-500: #ffeb3b;
  --md-yellow-600: #fdd835;
  --md-yellow-700: #fbc02d;
  --md-yellow-800: #f9a825;
  --md-yellow-900: #f57f17;
  --md-yellow-A100: #ffff8d;
  --md-yellow-A200: #ff0;
  --md-yellow-A400: #ffea00;
  --md-yellow-A700: #ffd600;
  --md-amber-50: #fff8e1;
  --md-amber-100: #ffecb3;
  --md-amber-200: #ffe082;
  --md-amber-300: #ffd54f;
  --md-amber-400: #ffca28;
  --md-amber-500: #ffc107;
  --md-amber-600: #ffb300;
  --md-amber-700: #ffa000;
  --md-amber-800: #ff8f00;
  --md-amber-900: #ff6f00;
  --md-amber-A100: #ffe57f;
  --md-amber-A200: #ffd740;
  --md-amber-A400: #ffc400;
  --md-amber-A700: #ffab00;
  --md-orange-50: #fff3e0;
  --md-orange-100: #ffe0b2;
  --md-orange-200: #ffcc80;
  --md-orange-300: #ffb74d;
  --md-orange-400: #ffa726;
  --md-orange-500: #ff9800;
  --md-orange-600: #fb8c00;
  --md-orange-700: #f57c00;
  --md-orange-800: #ef6c00;
  --md-orange-900: #e65100;
  --md-orange-A100: #ffd180;
  --md-orange-A200: #ffab40;
  --md-orange-A400: #ff9100;
  --md-orange-A700: #ff6d00;
  --md-deep-orange-50: #fbe9e7;
  --md-deep-orange-100: #ffccbc;
  --md-deep-orange-200: #ffab91;
  --md-deep-orange-300: #ff8a65;
  --md-deep-orange-400: #ff7043;
  --md-deep-orange-500: #ff5722;
  --md-deep-orange-600: #f4511e;
  --md-deep-orange-700: #e64a19;
  --md-deep-orange-800: #d84315;
  --md-deep-orange-900: #bf360c;
  --md-deep-orange-A100: #ff9e80;
  --md-deep-orange-A200: #ff6e40;
  --md-deep-orange-A400: #ff3d00;
  --md-deep-orange-A700: #dd2c00;
  --md-brown-50: #efebe9;
  --md-brown-100: #d7ccc8;
  --md-brown-200: #bcaaa4;
  --md-brown-300: #a1887f;
  --md-brown-400: #8d6e63;
  --md-brown-500: #795548;
  --md-brown-600: #6d4c41;
  --md-brown-700: #5d4037;
  --md-brown-800: #4e342e;
  --md-brown-900: #3e2723;
  --md-grey-50: #fafafa;
  --md-grey-100: #f5f5f5;
  --md-grey-200: #eee;
  --md-grey-300: #e0e0e0;
  --md-grey-400: #bdbdbd;
  --md-grey-500: #9e9e9e;
  --md-grey-600: #757575;
  --md-grey-700: #616161;
  --md-grey-800: #424242;
  --md-grey-900: #212121;
  --md-blue-grey-50: #eceff1;
  --md-blue-grey-100: #cfd8dc;
  --md-blue-grey-200: #b0bec5;
  --md-blue-grey-300: #90a4ae;
  --md-blue-grey-400: #78909c;
  --md-blue-grey-500: #607d8b;
  --md-blue-grey-600: #546e7a;
  --md-blue-grey-700: #455a64;
  --md-blue-grey-800: #37474f;
  --md-blue-grey-900: #263238;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| RenderedText
|----------------------------------------------------------------------------*/

:root {
  /* This is the padding value to fill the gaps between lines containing spans with background color. */
  --jp-private-code-span-padding: calc(
    (var(--jp-code-line-height) - 1) * var(--jp-code-font-size) / 2
  );
}

.jp-RenderedText {
  text-align: left;
  padding-left: var(--jp-code-padding);
  line-height: var(--jp-code-line-height);
  font-family: var(--jp-code-font-family);
}

.jp-RenderedText pre,
.jp-RenderedJavaScript pre,
.jp-RenderedHTMLCommon pre {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-code-font-size);
  border: none;
  margin: 0;
  padding: 0;
}

.jp-RenderedText pre a:link {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

.jp-RenderedText pre a:hover {
  text-decoration: underline;
  color: var(--jp-content-link-color);
}

.jp-RenderedText pre a:visited {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

/* console foregrounds and backgrounds */
.jp-RenderedText pre .ansi-black-fg {
  color: #3e424d;
}

.jp-RenderedText pre .ansi-red-fg {
  color: #e75c58;
}

.jp-RenderedText pre .ansi-green-fg {
  color: #00a250;
}

.jp-RenderedText pre .ansi-yellow-fg {
  color: #ddb62b;
}

.jp-RenderedText pre .ansi-blue-fg {
  color: #208ffb;
}

.jp-RenderedText pre .ansi-magenta-fg {
  color: #d160c4;
}

.jp-RenderedText pre .ansi-cyan-fg {
  color: #60c6c8;
}

.jp-RenderedText pre .ansi-white-fg {
  color: #c5c1b4;
}

.jp-RenderedText pre .ansi-black-bg {
  background-color: #3e424d;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-red-bg {
  background-color: #e75c58;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-green-bg {
  background-color: #00a250;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-yellow-bg {
  background-color: #ddb62b;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-blue-bg {
  background-color: #208ffb;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-magenta-bg {
  background-color: #d160c4;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-cyan-bg {
  background-color: #60c6c8;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-white-bg {
  background-color: #c5c1b4;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-black-intense-fg {
  color: #282c36;
}

.jp-RenderedText pre .ansi-red-intense-fg {
  color: #b22b31;
}

.jp-RenderedText pre .ansi-green-intense-fg {
  color: #007427;
}

.jp-RenderedText pre .ansi-yellow-intense-fg {
  color: #b27d12;
}

.jp-RenderedText pre .ansi-blue-intense-fg {
  color: #0065ca;
}

.jp-RenderedText pre .ansi-magenta-intense-fg {
  color: #a03196;
}

.jp-RenderedText pre .ansi-cyan-intense-fg {
  color: #258f8f;
}

.jp-RenderedText pre .ansi-white-intense-fg {
  color: #a1a6b2;
}

.jp-RenderedText pre .ansi-black-intense-bg {
  background-color: #282c36;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-red-intense-bg {
  background-color: #b22b31;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-green-intense-bg {
  background-color: #007427;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-yellow-intense-bg {
  background-color: #b27d12;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-blue-intense-bg {
  background-color: #0065ca;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-magenta-intense-bg {
  background-color: #a03196;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-cyan-intense-bg {
  background-color: #258f8f;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-white-intense-bg {
  background-color: #a1a6b2;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-default-inverse-fg {
  color: var(--jp-ui-inverse-font-color0);
}

.jp-RenderedText pre .ansi-default-inverse-bg {
  background-color: var(--jp-inverse-layout-color0);
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-bold {
  font-weight: bold;
}

.jp-RenderedText pre .ansi-underline {
  text-decoration: underline;
}

.jp-RenderedText[data-mime-type='application/vnd.jupyter.stderr'] {
  background: var(--jp-rendermime-error-background);
  padding-top: var(--jp-code-padding);
}

/*-----------------------------------------------------------------------------
| RenderedLatex
|----------------------------------------------------------------------------*/

.jp-RenderedLatex {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-content-font-size1);
  line-height: var(--jp-content-line-height);
}

/* Left-justify outputs.*/
.jp-OutputArea-output.jp-RenderedLatex {
  padding: var(--jp-code-padding);
  text-align: left;
}

/*-----------------------------------------------------------------------------
| RenderedHTML
|----------------------------------------------------------------------------*/

.jp-RenderedHTMLCommon {
  color: var(--jp-content-font-color1);
  font-family: var(--jp-content-font-family);
  font-size: var(--jp-content-font-size1);
  line-height: var(--jp-content-line-height);

  /* Give a bit more R padding on Markdown text to keep line lengths reasonable */
  padding-right: 20px;
}

.jp-RenderedHTMLCommon em {
  font-style: italic;
}

.jp-RenderedHTMLCommon strong {
  font-weight: bold;
}

.jp-RenderedHTMLCommon u {
  text-decoration: underline;
}

.jp-RenderedHTMLCommon a:link {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

.jp-RenderedHTMLCommon a:hover {
  text-decoration: underline;
  color: var(--jp-content-link-color);
}

.jp-RenderedHTMLCommon a:visited {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

/* Headings */

.jp-RenderedHTMLCommon h1,
.jp-RenderedHTMLCommon h2,
.jp-RenderedHTMLCommon h3,
.jp-RenderedHTMLCommon h4,
.jp-RenderedHTMLCommon h5,
.jp-RenderedHTMLCommon h6 {
  line-height: var(--jp-content-heading-line-height);
  font-weight: var(--jp-content-heading-font-weight);
  font-style: normal;
  margin: var(--jp-content-heading-margin-top) 0
    var(--jp-content-heading-margin-bottom) 0;
}

.jp-RenderedHTMLCommon h1:first-child,
.jp-RenderedHTMLCommon h2:first-child,
.jp-RenderedHTMLCommon h3:first-child,
.jp-RenderedHTMLCommon h4:first-child,
.jp-RenderedHTMLCommon h5:first-child,
.jp-RenderedHTMLCommon h6:first-child {
  margin-top: calc(0.5 * var(--jp-content-heading-margin-top));
}

.jp-RenderedHTMLCommon h1:last-child,
.jp-RenderedHTMLCommon h2:last-child,
.jp-RenderedHTMLCommon h3:last-child,
.jp-RenderedHTMLCommon h4:last-child,
.jp-RenderedHTMLCommon h5:last-child,
.jp-RenderedHTMLCommon h6:last-child {
  margin-bottom: calc(0.5 * var(--jp-content-heading-margin-bottom));
}

.jp-RenderedHTMLCommon h1 {
  font-size: var(--jp-content-font-size5);
}

.jp-RenderedHTMLCommon h2 {
  font-size: var(--jp-content-font-size4);
}

.jp-RenderedHTMLCommon h3 {
  font-size: var(--jp-content-font-size3);
}

.jp-RenderedHTMLCommon h4 {
  font-size: var(--jp-content-font-size2);
}

.jp-RenderedHTMLCommon h5 {
  font-size: var(--jp-content-font-size1);
}

.jp-RenderedHTMLCommon h6 {
  font-size: var(--jp-content-font-size0);
}

/* Lists */

/* stylelint-disable selector-max-type, selector-max-compound-selectors */

.jp-RenderedHTMLCommon ul:not(.list-inline),
.jp-RenderedHTMLCommon ol:not(.list-inline) {
  padding-left: 2em;
}

.jp-RenderedHTMLCommon ul {
  list-style: disc;
}

.jp-RenderedHTMLCommon ul ul {
  list-style: square;
}

.jp-RenderedHTMLCommon ul ul ul {
  list-style: circle;
}

.jp-RenderedHTMLCommon ol {
  list-style: decimal;
}

.jp-RenderedHTMLCommon ol ol {
  list-style: upper-alpha;
}

.jp-RenderedHTMLCommon ol ol ol {
  list-style: lower-alpha;
}

.jp-RenderedHTMLCommon ol ol ol ol {
  list-style: lower-roman;
}

.jp-RenderedHTMLCommon ol ol ol ol ol {
  list-style: decimal;
}

.jp-RenderedHTMLCommon ol,
.jp-RenderedHTMLCommon ul {
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon ul ul,
.jp-RenderedHTMLCommon ul ol,
.jp-RenderedHTMLCommon ol ul,
.jp-RenderedHTMLCommon ol ol {
  margin-bottom: 0;
}

/* stylelint-enable selector-max-type, selector-max-compound-selectors */

.jp-RenderedHTMLCommon hr {
  color: var(--jp-border-color2);
  background-color: var(--jp-border-color1);
  margin-top: 1em;
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon > pre {
  margin: 1.5em 2em;
}

.jp-RenderedHTMLCommon pre,
.jp-RenderedHTMLCommon code {
  border: 0;
  background-color: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
  font-family: var(--jp-code-font-family);
  font-size: inherit;
  line-height: var(--jp-code-line-height);
  padding: 0;
  white-space: pre-wrap;
}

.jp-RenderedHTMLCommon :not(pre) > code {
  background-color: var(--jp-layout-color2);
  padding: 1px 5px;
}

/* Tables */

.jp-RenderedHTMLCommon table {
  border-collapse: collapse;
  border-spacing: 0;
  border: none;
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  table-layout: fixed;
  margin-left: auto;
  margin-bottom: 1em;
  margin-right: auto;
}

.jp-RenderedHTMLCommon thead {
  border-bottom: var(--jp-border-width) solid var(--jp-border-color1);
  vertical-align: bottom;
}

.jp-RenderedHTMLCommon td,
.jp-RenderedHTMLCommon th,
.jp-RenderedHTMLCommon tr {
  vertical-align: middle;
  padding: 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}

.jp-RenderedMarkdown.jp-RenderedHTMLCommon td,
.jp-RenderedMarkdown.jp-RenderedHTMLCommon th {
  max-width: none;
}

:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon td,
:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon th,
:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon tr {
  text-align: right;
}

.jp-RenderedHTMLCommon th {
  font-weight: bold;
}

.jp-RenderedHTMLCommon tbody tr:nth-child(odd) {
  background: var(--jp-layout-color0);
}

.jp-RenderedHTMLCommon tbody tr:nth-child(even) {
  background: var(--jp-rendermime-table-row-background);
}

.jp-RenderedHTMLCommon tbody tr:hover {
  background: var(--jp-rendermime-table-row-hover-background);
}

.jp-RenderedHTMLCommon p {
  text-align: left;
  margin: 0;
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon img {
  -moz-force-broken-image-icon: 1;
}

/* Restrict to direct children as other images could be nested in other content. */
.jp-RenderedHTMLCommon > img {
  display: block;
  margin-left: 0;
  margin-right: 0;
  margin-bottom: 1em;
}

/* Change color behind transparent images if they need it... */
[data-jp-theme-light='false'] .jp-RenderedImage img.jp-needs-light-background {
  background-color: var(--jp-inverse-layout-color1);
}

[data-jp-theme-light='true'] .jp-RenderedImage img.jp-needs-dark-background {
  background-color: var(--jp-inverse-layout-color1);
}

.jp-RenderedHTMLCommon img,
.jp-RenderedImage img,
.jp-RenderedHTMLCommon svg,
.jp-RenderedSVG svg {
  max-width: 100%;
  height: auto;
}

.jp-RenderedHTMLCommon img.jp-mod-unconfined,
.jp-RenderedImage img.jp-mod-unconfined,
.jp-RenderedHTMLCommon svg.jp-mod-unconfined,
.jp-RenderedSVG svg.jp-mod-unconfined {
  max-width: none;
}

.jp-RenderedHTMLCommon .alert {
  padding: var(--jp-notebook-padding);
  border: var(--jp-border-width) solid transparent;
  border-radius: var(--jp-border-radius);
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon .alert-info {
  color: var(--jp-info-color0);
  background-color: var(--jp-info-color3);
  border-color: var(--jp-info-color2);
}

.jp-RenderedHTMLCommon .alert-info hr {
  border-color: var(--jp-info-color3);
}

.jp-RenderedHTMLCommon .alert-info > p:last-child,
.jp-RenderedHTMLCommon .alert-info > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-warning {
  color: var(--jp-warn-color0);
  background-color: var(--jp-warn-color3);
  border-color: var(--jp-warn-color2);
}

.jp-RenderedHTMLCommon .alert-warning hr {
  border-color: var(--jp-warn-color3);
}

.jp-RenderedHTMLCommon .alert-warning > p:last-child,
.jp-RenderedHTMLCommon .alert-warning > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-success {
  color: var(--jp-success-color0);
  background-color: var(--jp-success-color3);
  border-color: var(--jp-success-color2);
}

.jp-RenderedHTMLCommon .alert-success hr {
  border-color: var(--jp-success-color3);
}

.jp-RenderedHTMLCommon .alert-success > p:last-child,
.jp-RenderedHTMLCommon .alert-success > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-danger {
  color: var(--jp-error-color0);
  background-color: var(--jp-error-color3);
  border-color: var(--jp-error-color2);
}

.jp-RenderedHTMLCommon .alert-danger hr {
  border-color: var(--jp-error-color3);
}

.jp-RenderedHTMLCommon .alert-danger > p:last-child,
.jp-RenderedHTMLCommon .alert-danger > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon blockquote {
  margin: 1em 2em;
  padding: 0 1em;
  border-left: 5px solid var(--jp-border-color2);
}

a.jp-InternalAnchorLink {
  visibility: hidden;
  margin-left: 8px;
  color: var(--md-blue-800);
}

h1:hover .jp-InternalAnchorLink,
h2:hover .jp-InternalAnchorLink,
h3:hover .jp-InternalAnchorLink,
h4:hover .jp-InternalAnchorLink,
h5:hover .jp-InternalAnchorLink,
h6:hover .jp-InternalAnchorLink {
  visibility: visible;
}

.jp-RenderedHTMLCommon kbd {
  background-color: var(--jp-rendermime-table-row-background);
  border: 1px solid var(--jp-border-color0);
  border-bottom-color: var(--jp-border-color2);
  border-radius: 3px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
  display: inline-block;
  font-size: var(--jp-ui-font-size0);
  line-height: 1em;
  padding: 0.2em 0.5em;
}

/* Most direct children of .jp-RenderedHTMLCommon have a margin-bottom of 1.0.
 * At the bottom of cells this is a bit too much as there is also spacing
 * between cells. Going all the way to 0 gets too tight between markdown and
 * code cells.
 */
.jp-RenderedHTMLCommon > *:last-child {
  margin-bottom: 0.5em;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-cursor-backdrop {
  position: fixed;
  width: 200px;
  height: 200px;
  margin-top: -100px;
  margin-left: -100px;
  will-change: transform;
  z-index: 100;
}

.lm-mod-drag-image {
  will-change: transform;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-lineFormSearch {
  padding: 4px 12px;
  background-color: var(--jp-layout-color2);
  box-shadow: var(--jp-toolbar-box-shadow);
  z-index: 2;
  font-size: var(--jp-ui-font-size1);
}

.jp-lineFormCaption {
  font-size: var(--jp-ui-font-size0);
  line-height: var(--jp-ui-font-size1);
  margin-top: 4px;
  color: var(--jp-ui-font-color0);
}

.jp-baseLineForm {
  border: none;
  border-radius: 0;
  position: absolute;
  background-size: 16px;
  background-repeat: no-repeat;
  background-position: center;
  outline: none;
}

.jp-lineFormButtonContainer {
  top: 4px;
  right: 8px;
  height: 24px;
  padding: 0 12px;
  width: 12px;
}

.jp-lineFormButtonIcon {
  top: 0;
  right: 0;
  background-color: var(--jp-brand-color1);
  height: 100%;
  width: 100%;
  box-sizing: border-box;
  padding: 4px 6px;
}

.jp-lineFormButton {
  top: 0;
  right: 0;
  background-color: transparent;
  height: 100%;
  width: 100%;
  box-sizing: border-box;
}

.jp-lineFormWrapper {
  overflow: hidden;
  padding: 0 8px;
  border: 1px solid var(--jp-border-color0);
  background-color: var(--jp-input-active-background);
  height: 22px;
}

.jp-lineFormWrapperFocusWithin {
  border: var(--jp-border-width) solid var(--md-blue-500);
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-lineFormInput {
  background: transparent;
  width: 200px;
  height: 100%;
  border: none;
  outline: none;
  color: var(--jp-ui-font-color0);
  line-height: 28px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-JSONEditor {
  display: flex;
  flex-direction: column;
  width: 100%;
}

.jp-JSONEditor-host {
  flex: 1 1 auto;
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  border-radius: 0;
  background: var(--jp-layout-color0);
  min-height: 50px;
  padding: 1px;
}

.jp-JSONEditor.jp-mod-error .jp-JSONEditor-host {
  border-color: red;
  outline-color: red;
}

.jp-JSONEditor-header {
  display: flex;
  flex: 1 0 auto;
  padding: 0 0 0 12px;
}

.jp-JSONEditor-header label {
  flex: 0 0 auto;
}

.jp-JSONEditor-commitButton {
  height: 16px;
  width: 16px;
  background-size: 18px;
  background-repeat: no-repeat;
  background-position: center;
}

.jp-JSONEditor-host.jp-mod-focused {
  background-color: var(--jp-input-active-background);
  border: 1px solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
}

.jp-Editor.jp-mod-dropTarget {
  border: var(--jp-border-width) solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/
.jp-DocumentSearch-input {
  border: none;
  outline: none;
  color: var(--jp-ui-font-color0);
  font-size: var(--jp-ui-font-size1);
  background-color: var(--jp-layout-color0);
  font-family: var(--jp-ui-font-family);
  padding: 2px 1px;
  resize: none;
}

.jp-DocumentSearch-overlay {
  position: absolute;
  background-color: var(--jp-toolbar-background);
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  border-left: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  top: 0;
  right: 0;
  z-index: 7;
  min-width: 405px;
  padding: 2px;
  font-size: var(--jp-ui-font-size1);

  --jp-private-document-search-button-height: 20px;
}

.jp-DocumentSearch-overlay button {
  background-color: var(--jp-toolbar-background);
  outline: 0;
}

.jp-DocumentSearch-overlay button:hover {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-overlay button:active {
  background-color: var(--jp-layout-color3);
}

.jp-DocumentSearch-overlay-row {
  display: flex;
  align-items: center;
  margin-bottom: 2px;
}

.jp-DocumentSearch-button-content {
  display: inline-block;
  cursor: pointer;
  box-sizing: border-box;
  width: 100%;
  height: 100%;
}

.jp-DocumentSearch-button-content svg {
  width: 100%;
  height: 100%;
}

.jp-DocumentSearch-input-wrapper {
  border: var(--jp-border-width) solid var(--jp-border-color0);
  display: flex;
  background-color: var(--jp-layout-color0);
  margin: 2px;
}

.jp-DocumentSearch-input-wrapper:focus-within {
  border-color: var(--jp-cell-editor-active-border-color);
}

.jp-DocumentSearch-toggle-wrapper,
.jp-DocumentSearch-button-wrapper {
  all: initial;
  overflow: hidden;
  display: inline-block;
  border: none;
  box-sizing: border-box;
}

.jp-DocumentSearch-toggle-wrapper {
  width: 14px;
  height: 14px;
}

.jp-DocumentSearch-button-wrapper {
  width: var(--jp-private-document-search-button-height);
  height: var(--jp-private-document-search-button-height);
}

.jp-DocumentSearch-toggle-wrapper:focus,
.jp-DocumentSearch-button-wrapper:focus {
  outline: var(--jp-border-width) solid
    var(--jp-cell-editor-active-border-color);
  outline-offset: -1px;
}

.jp-DocumentSearch-toggle-wrapper,
.jp-DocumentSearch-button-wrapper,
.jp-DocumentSearch-button-content:focus {
  outline: none;
}

.jp-DocumentSearch-toggle-placeholder {
  width: 5px;
}

.jp-DocumentSearch-input-button::before {
  display: block;
  padding-top: 100%;
}

.jp-DocumentSearch-input-button-off {
  opacity: var(--jp-search-toggle-off-opacity);
}

.jp-DocumentSearch-input-button-off:hover {
  opacity: var(--jp-search-toggle-hover-opacity);
}

.jp-DocumentSearch-input-button-on {
  opacity: var(--jp-search-toggle-on-opacity);
}

.jp-DocumentSearch-index-counter {
  padding-left: 10px;
  padding-right: 10px;
  user-select: none;
  min-width: 35px;
  display: inline-block;
}

.jp-DocumentSearch-up-down-wrapper {
  display: inline-block;
  padding-right: 2px;
  margin-left: auto;
  white-space: nowrap;
}

.jp-DocumentSearch-spacer {
  margin-left: auto;
}

.jp-DocumentSearch-up-down-wrapper button {
  outline: 0;
  border: none;
  width: var(--jp-private-document-search-button-height);
  height: var(--jp-private-document-search-button-height);
  vertical-align: middle;
  margin: 1px 5px 2px;
}

.jp-DocumentSearch-up-down-button:hover {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-up-down-button:active {
  background-color: var(--jp-layout-color3);
}

.jp-DocumentSearch-filter-button {
  border-radius: var(--jp-border-radius);
}

.jp-DocumentSearch-filter-button:hover {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-filter-button-enabled {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-filter-button-enabled:hover {
  background-color: var(--jp-layout-color3);
}

.jp-DocumentSearch-search-options {
  padding: 0 8px;
  margin-left: 3px;
  width: 100%;
  display: grid;
  justify-content: start;
  grid-template-columns: 1fr 1fr;
  align-items: center;
  justify-items: stretch;
}

.jp-DocumentSearch-search-filter-disabled {
  color: var(--jp-ui-font-color2);
}

.jp-DocumentSearch-search-filter {
  display: flex;
  align-items: center;
  user-select: none;
}

.jp-DocumentSearch-regex-error {
  color: var(--jp-error-color0);
}

.jp-DocumentSearch-replace-button-wrapper {
  overflow: hidden;
  display: inline-block;
  box-sizing: border-box;
  border: var(--jp-border-width) solid var(--jp-border-color0);
  margin: auto 2px;
  padding: 1px 4px;
  height: calc(var(--jp-private-document-search-button-height) + 2px);
}

.jp-DocumentSearch-replace-button-wrapper:focus {
  border: var(--jp-border-width) solid var(--jp-cell-editor-active-border-color);
}

.jp-DocumentSearch-replace-button {
  display: inline-block;
  text-align: center;
  cursor: pointer;
  box-sizing: border-box;
  color: var(--jp-ui-font-color1);

  /* height - 2 * (padding of wrapper) */
  line-height: calc(var(--jp-private-document-search-button-height) - 2px);
  width: 100%;
  height: 100%;
}

.jp-DocumentSearch-replace-button:focus {
  outline: none;
}

.jp-DocumentSearch-replace-wrapper-class {
  margin-left: 14px;
  display: flex;
}

.jp-DocumentSearch-replace-toggle {
  border: none;
  background-color: var(--jp-toolbar-background);
  border-radius: var(--jp-border-radius);
}

.jp-DocumentSearch-replace-toggle:hover {
  background-color: var(--jp-layout-color2);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.cm-editor {
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  font-family: var(--jp-code-font-family);
  border: 0;
  border-radius: 0;
  height: auto;

  /* Changed to auto to autogrow */
}

.cm-editor pre {
  padding: 0 var(--jp-code-padding);
}

.jp-CodeMirrorEditor[data-type='inline'] .cm-dialog {
  background-color: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
}

.jp-CodeMirrorEditor {
  cursor: text;
}

/* When zoomed out 67% and 33% on a screen of 1440 width x 900 height */
@media screen and (min-width: 2138px) and (max-width: 4319px) {
  .jp-CodeMirrorEditor[data-type='inline'] .cm-cursor {
    border-left: var(--jp-code-cursor-width1) solid
      var(--jp-editor-cursor-color);
  }
}

/* When zoomed out less than 33% */
@media screen and (min-width: 4320px) {
  .jp-CodeMirrorEditor[data-type='inline'] .cm-cursor {
    border-left: var(--jp-code-cursor-width2) solid
      var(--jp-editor-cursor-color);
  }
}

.cm-editor.jp-mod-readOnly .cm-cursor {
  display: none;
}

.jp-CollaboratorCursor {
  border-left: 5px solid transparent;
  border-right: 5px solid transparent;
  border-top: none;
  border-bottom: 3px solid;
  background-clip: content-box;
  margin-left: -5px;
  margin-right: -5px;
}

.cm-searching,
.cm-searching span {
  /* `.cm-searching span`: we need to override syntax highlighting */
  background-color: var(--jp-search-unselected-match-background-color);
  color: var(--jp-search-unselected-match-color);
}

.cm-searching::selection,
.cm-searching span::selection {
  background-color: var(--jp-search-unselected-match-background-color);
  color: var(--jp-search-unselected-match-color);
}

.jp-current-match > .cm-searching,
.jp-current-match > .cm-searching span,
.cm-searching > .jp-current-match,
.cm-searching > .jp-current-match span {
  background-color: var(--jp-search-selected-match-background-color);
  color: var(--jp-search-selected-match-color);
}

.jp-current-match > .cm-searching::selection,
.cm-searching > .jp-current-match::selection,
.jp-current-match > .cm-searching span::selection {
  background-color: var(--jp-search-selected-match-background-color);
  color: var(--jp-search-selected-match-color);
}

.cm-trailingspace {
  background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAFCAYAAAB4ka1VAAAAsElEQVQIHQGlAFr/AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA7+r3zKmT0/+pk9P/7+r3zAAAAAAAAAAABAAAAAAAAAAA6OPzM+/q9wAAAAAA6OPzMwAAAAAAAAAAAgAAAAAAAAAAGR8NiRQaCgAZIA0AGR8NiQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQyoYJ/SY80UAAAAASUVORK5CYII=);
  background-position: center left;
  background-repeat: repeat-x;
}

.jp-CollaboratorCursor-hover {
  position: absolute;
  z-index: 1;
  transform: translateX(-50%);
  color: white;
  border-radius: 3px;
  padding-left: 4px;
  padding-right: 4px;
  padding-top: 1px;
  padding-bottom: 1px;
  text-align: center;
  font-size: var(--jp-ui-font-size1);
  white-space: nowrap;
}

.jp-CodeMirror-ruler {
  border-left: 1px dashed var(--jp-border-color2);
}

/* Styles for shared cursors (remote cursor locations and selected ranges) */
.jp-CodeMirrorEditor .cm-ySelectionCaret {
  position: relative;
  border-left: 1px solid black;
  margin-left: -1px;
  margin-right: -1px;
  box-sizing: border-box;
}

.jp-CodeMirrorEditor .cm-ySelectionCaret > .cm-ySelectionInfo {
  white-space: nowrap;
  position: absolute;
  top: -1.15em;
  padding-bottom: 0.05em;
  left: -1px;
  font-size: 0.95em;
  font-family: var(--jp-ui-font-family);
  font-weight: bold;
  line-height: normal;
  user-select: none;
  color: white;
  padding-left: 2px;
  padding-right: 2px;
  z-index: 101;
  transition: opacity 0.3s ease-in-out;
}

.jp-CodeMirrorEditor .cm-ySelectionInfo {
  transition-delay: 0.7s;
  opacity: 0;
}

.jp-CodeMirrorEditor .cm-ySelectionCaret:hover > .cm-ySelectionInfo {
  opacity: 1;
  transition-delay: 0s;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-MimeDocument {
  outline: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-filebrowser-button-height: 28px;
  --jp-private-filebrowser-button-width: 48px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-FileBrowser .jp-SidePanel-content {
  display: flex;
  flex-direction: column;
}

.jp-FileBrowser-toolbar.jp-Toolbar {
  flex-wrap: wrap;
  row-gap: 12px;
  border-bottom: none;
  height: auto;
  margin: 8px 12px 0;
  box-shadow: none;
  padding: 0;
  justify-content: flex-start;
}

.jp-FileBrowser-Panel {
  flex: 1 1 auto;
  display: flex;
  flex-direction: column;
}

.jp-BreadCrumbs {
  flex: 0 0 auto;
  margin: 8px 12px;
}

.jp-BreadCrumbs-item {
  margin: 0 2px;
  padding: 0 2px;
  border-radius: var(--jp-border-radius);
  cursor: pointer;
}

.jp-BreadCrumbs-item:hover {
  background-color: var(--jp-layout-color2);
}

.jp-BreadCrumbs-item:first-child {
  margin-left: 0;
}

.jp-BreadCrumbs-item.jp-mod-dropTarget {
  background-color: var(--jp-brand-color2);
  opacity: 0.7;
}

/*-----------------------------------------------------------------------------
| Buttons
|----------------------------------------------------------------------------*/

.jp-FileBrowser-toolbar > .jp-Toolbar-item {
  flex: 0 0 auto;
  padding-left: 0;
  padding-right: 2px;
  align-items: center;
  height: unset;
}

.jp-FileBrowser-toolbar > .jp-Toolbar-item .jp-ToolbarButtonComponent {
  width: 40px;
}

/*-----------------------------------------------------------------------------
| Other styles
|----------------------------------------------------------------------------*/

.jp-FileDialog.jp-mod-conflict input {
  color: var(--jp-error-color1);
}

.jp-FileDialog .jp-new-name-title {
  margin-top: 12px;
}

.jp-LastModified-hidden {
  display: none;
}

.jp-FileSize-hidden {
  display: none;
}

.jp-FileBrowser .lm-AccordionPanel > h3:first-child {
  display: none;
}

/*-----------------------------------------------------------------------------
| DirListing
|----------------------------------------------------------------------------*/

.jp-DirListing {
  flex: 1 1 auto;
  display: flex;
  flex-direction: column;
  outline: 0;
}

.jp-DirListing-header {
  flex: 0 0 auto;
  display: flex;
  flex-direction: row;
  align-items: center;
  overflow: hidden;
  border-top: var(--jp-border-width) solid var(--jp-border-color2);
  border-bottom: var(--jp-border-width) solid var(--jp-border-color1);
  box-shadow: var(--jp-toolbar-box-shadow);
  z-index: 2;
}

.jp-DirListing-headerItem {
  padding: 4px 12px 2px;
  font-weight: 500;
}

.jp-DirListing-headerItem:hover {
  background: var(--jp-layout-color2);
}

.jp-DirListing-headerItem.jp-id-name {
  flex: 1 0 84px;
}

.jp-DirListing-headerItem.jp-id-modified {
  flex: 0 0 112px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
}

.jp-DirListing-headerItem.jp-id-filesize {
  flex: 0 0 75px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
}

.jp-id-narrow {
  display: none;
  flex: 0 0 5px;
  padding: 4px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
  color: var(--jp-border-color2);
}

.jp-DirListing-narrow .jp-id-narrow {
  display: block;
}

.jp-DirListing-narrow .jp-id-modified,
.jp-DirListing-narrow .jp-DirListing-itemModified {
  display: none;
}

.jp-DirListing-headerItem.jp-mod-selected {
  font-weight: 600;
}

/* increase specificity to override bundled default */
.jp-DirListing-content {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  list-style-type: none;
  overflow: auto;
  background-color: var(--jp-layout-color1);
}

.jp-DirListing-content mark {
  color: var(--jp-ui-font-color0);
  background-color: transparent;
  font-weight: bold;
}

.jp-DirListing-content .jp-DirListing-item.jp-mod-selected mark {
  color: var(--jp-ui-inverse-font-color0);
}

/* Style the directory listing content when a user drops a file to upload */
.jp-DirListing.jp-mod-native-drop .jp-DirListing-content {
  outline: 5px dashed rgba(128, 128, 128, 0.5);
  outline-offset: -10px;
  cursor: copy;
}

.jp-DirListing-item {
  display: flex;
  flex-direction: row;
  align-items: center;
  padding: 4px 12px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-DirListing-checkboxWrapper {
  /* Increases hit area of checkbox. */
  padding: 4px;
}

.jp-DirListing-header
  .jp-DirListing-checkboxWrapper
  + .jp-DirListing-headerItem {
  padding-left: 4px;
}

.jp-DirListing-content .jp-DirListing-checkboxWrapper {
  position: relative;
  left: -4px;
  margin: -4px 0 -4px -8px;
}

.jp-DirListing-checkboxWrapper.jp-mod-visible {
  visibility: visible;
}

/* For devices that support hovering, hide checkboxes until hovered, selected...
*/
@media (hover: hover) {
  .jp-DirListing-checkboxWrapper {
    visibility: hidden;
  }

  .jp-DirListing-item:hover .jp-DirListing-checkboxWrapper,
  .jp-DirListing-item.jp-mod-selected .jp-DirListing-checkboxWrapper {
    visibility: visible;
  }
}

.jp-DirListing-item[data-is-dot] {
  opacity: 75%;
}

.jp-DirListing-item.jp-mod-selected {
  color: var(--jp-ui-inverse-font-color1);
  background: var(--jp-brand-color1);
}

.jp-DirListing-item.jp-mod-dropTarget {
  background: var(--jp-brand-color3);
}

.jp-DirListing-item:hover:not(.jp-mod-selected) {
  background: var(--jp-layout-color2);
}

.jp-DirListing-itemIcon {
  flex: 0 0 20px;
  margin-right: 4px;
}

.jp-DirListing-itemText {
  flex: 1 0 64px;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  user-select: none;
}

.jp-DirListing-itemText:focus {
  outline-width: 2px;
  outline-color: var(--jp-inverse-layout-color1);
  outline-style: solid;
  outline-offset: 1px;
}

.jp-DirListing-item.jp-mod-selected .jp-DirListing-itemText:focus {
  outline-color: var(--jp-layout-color1);
}

.jp-DirListing-itemModified {
  flex: 0 0 125px;
  text-align: right;
}

.jp-DirListing-itemFileSize {
  flex: 0 0 90px;
  text-align: right;
}

.jp-DirListing-editor {
  flex: 1 0 64px;
  outline: none;
  border: none;
  color: var(--jp-ui-font-color1);
  background-color: var(--jp-layout-color1);
}

.jp-DirListing-item.jp-mod-running .jp-DirListing-itemIcon::before {
  color: var(--jp-success-color1);
  content: '\25CF';
  font-size: 8px;
  position: absolute;
  left: -8px;
}

.jp-DirListing-item.jp-mod-running.jp-mod-selected
  .jp-DirListing-itemIcon::before {
  color: var(--jp-ui-inverse-font-color1);
}

.jp-DirListing-item.lm-mod-drag-image,
.jp-DirListing-item.jp-mod-selected.lm-mod-drag-image {
  font-size: var(--jp-ui-font-size1);
  padding-left: 4px;
  margin-left: 4px;
  width: 160px;
  background-color: var(--jp-ui-inverse-font-color2);
  box-shadow: var(--jp-elevation-z2);
  border-radius: 0;
  color: var(--jp-ui-font-color1);
  transform: translateX(-40%) translateY(-58%);
}

.jp-Document {
  min-width: 120px;
  min-height: 120px;
  outline: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Main OutputArea
| OutputArea has a list of Outputs
|----------------------------------------------------------------------------*/

.jp-OutputArea {
  overflow-y: auto;
}

.jp-OutputArea-child {
  display: table;
  table-layout: fixed;
  width: 100%;
  overflow: hidden;
}

.jp-OutputPrompt {
  width: var(--jp-cell-prompt-width);
  color: var(--jp-cell-outprompt-font-color);
  font-family: var(--jp-cell-prompt-font-family);
  padding: var(--jp-code-padding);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
  opacity: var(--jp-cell-prompt-opacity);

  /* Right align prompt text, don't wrap to handle large prompt numbers */
  text-align: right;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;

  /* Disable text selection */
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-OutputArea-prompt {
  display: table-cell;
  vertical-align: top;
}

.jp-OutputArea-output {
  display: table-cell;
  width: 100%;
  height: auto;
  overflow: auto;
  user-select: text;
  -moz-user-select: text;
  -webkit-user-select: text;
  -ms-user-select: text;
}

.jp-OutputArea .jp-RenderedText {
  padding-left: 1ch;
}

/**
 * Prompt overlay.
 */

.jp-OutputArea-promptOverlay {
  position: absolute;
  top: 0;
  width: var(--jp-cell-prompt-width);
  height: 100%;
  opacity: 0.5;
}

.jp-OutputArea-promptOverlay:hover {
  background: var(--jp-layout-color2);
  box-shadow: inset 0 0 1px var(--jp-inverse-layout-color0);
  cursor: zoom-out;
}

.jp-mod-outputsScrolled .jp-OutputArea-promptOverlay:hover {
  cursor: zoom-in;
}

/**
 * Isolated output.
 */
.jp-OutputArea-output.jp-mod-isolated {
  width: 100%;
  display: block;
}

/*
When drag events occur, `lm-mod-override-cursor` is added to the body.
Because iframes steal all cursor events, the following two rules are necessary
to suppress pointer events while resize drags are occurring. There may be a
better solution to this problem.
*/
body.lm-mod-override-cursor .jp-OutputArea-output.jp-mod-isolated {
  position: relative;
}

body.lm-mod-override-cursor .jp-OutputArea-output.jp-mod-isolated::before {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: transparent;
}

/* pre */

.jp-OutputArea-output pre {
  border: none;
  margin: 0;
  padding: 0;
  overflow-x: auto;
  overflow-y: auto;
  word-break: break-all;
  word-wrap: break-word;
  white-space: pre-wrap;
}

/* tables */

.jp-OutputArea-output.jp-RenderedHTMLCommon table {
  margin-left: 0;
  margin-right: 0;
}

/* description lists */

.jp-OutputArea-output dl,
.jp-OutputArea-output dt,
.jp-OutputArea-output dd {
  display: block;
}

.jp-OutputArea-output dl {
  width: 100%;
  overflow: hidden;
  padding: 0;
  margin: 0;
}

.jp-OutputArea-output dt {
  font-weight: bold;
  float: left;
  width: 20%;
  padding: 0;
  margin: 0;
}

.jp-OutputArea-output dd {
  float: left;
  width: 80%;
  padding: 0;
  margin: 0;
}

.jp-TrimmedOutputs pre {
  background: var(--jp-layout-color3);
  font-size: calc(var(--jp-code-font-size) * 1.4);
  text-align: center;
  text-transform: uppercase;
}

/* Hide the gutter in case of
 *  - nested output areas (e.g. in the case of output widgets)
 *  - mirrored output areas
 */
.jp-OutputArea .jp-OutputArea .jp-OutputArea-prompt {
  display: none;
}

/* Hide empty lines in the output area, for instance due to cleared widgets */
.jp-OutputArea-prompt:empty {
  padding: 0;
  border: 0;
}

/*-----------------------------------------------------------------------------
| executeResult is added to any Output-result for the display of the object
| returned by a cell
|----------------------------------------------------------------------------*/

.jp-OutputArea-output.jp-OutputArea-executeResult {
  margin-left: 0;
  width: 100%;
}

/* Text output with the Out[] prompt needs a top padding to match the
 * alignment of the Out[] prompt itself.
 */
.jp-OutputArea-executeResult .jp-RenderedText.jp-OutputArea-output {
  padding-top: var(--jp-code-padding);
  border-top: var(--jp-border-width) solid transparent;
}

/*-----------------------------------------------------------------------------
| The Stdin output
|----------------------------------------------------------------------------*/

.jp-Stdin-prompt {
  color: var(--jp-content-font-color0);
  padding-right: var(--jp-code-padding);
  vertical-align: baseline;
  flex: 0 0 auto;
}

.jp-Stdin-input {
  font-family: var(--jp-code-font-family);
  font-size: inherit;
  color: inherit;
  background-color: inherit;
  width: 42%;
  min-width: 200px;

  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;

  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0 0.25em;
  margin: 0 0.25em;
  flex: 0 0 70%;
}

.jp-Stdin-input::placeholder {
  opacity: 0;
}

.jp-Stdin-input:focus {
  box-shadow: none;
}

.jp-Stdin-input:focus::placeholder {
  opacity: 1;
}

/*-----------------------------------------------------------------------------
| Output Area View
|----------------------------------------------------------------------------*/

.jp-LinkedOutputView .jp-OutputArea {
  height: 100%;
  display: block;
}

.jp-LinkedOutputView .jp-OutputArea-output:only-child {
  height: 100%;
}

/*-----------------------------------------------------------------------------
| Printing
|----------------------------------------------------------------------------*/

@media print {
  .jp-OutputArea-child {
    break-inside: avoid-page;
  }
}

/*-----------------------------------------------------------------------------
| Mobile
|----------------------------------------------------------------------------*/
@media only screen and (max-width: 760px) {
  .jp-OutputPrompt {
    display: table-row;
    text-align: left;
  }

  .jp-OutputArea-child .jp-OutputArea-output {
    display: table-row;
    margin-left: var(--jp-notebook-padding);
  }
}

/* Trimmed outputs warning */
.jp-TrimmedOutputs > a {
  margin: 10px;
  text-decoration: none;
  cursor: pointer;
}

.jp-TrimmedOutputs > a:hover {
  text-decoration: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Table of Contents
|----------------------------------------------------------------------------*/

:root {
  --jp-private-toc-active-width: 4px;
}

.jp-TableOfContents {
  display: flex;
  flex-direction: column;
  background: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  height: 100%;
}

.jp-TableOfContents-placeholder {
  text-align: center;
}

.jp-TableOfContents-placeholderContent {
  color: var(--jp-content-font-color2);
  padding: 8px;
}

.jp-TableOfContents-placeholderContent > h3 {
  margin-bottom: var(--jp-content-heading-margin-bottom);
}

.jp-TableOfContents .jp-SidePanel-content {
  overflow-y: auto;
}

.jp-TableOfContents-tree {
  margin: 4px;
}

.jp-TableOfContents ol {
  list-style-type: none;
}

/* stylelint-disable-next-line selector-max-type */
.jp-TableOfContents li > ol {
  /* Align left border with triangle icon center */
  padding-left: 11px;
}

.jp-TableOfContents-content {
  /* left margin for the active heading indicator */
  margin: 0 0 0 var(--jp-private-toc-active-width);
  padding: 0;
  background-color: var(--jp-layout-color1);
}

.jp-tocItem {
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-tocItem-heading {
  display: flex;
  cursor: pointer;
}

.jp-tocItem-heading:hover {
  background-color: var(--jp-layout-color2);
}

.jp-tocItem-content {
  display: block;
  padding: 4px 0;
  white-space: nowrap;
  text-overflow: ellipsis;
  overflow-x: hidden;
}

.jp-tocItem-collapser {
  height: 20px;
  margin: 2px 2px 0;
  padding: 0;
  background: none;
  border: none;
  cursor: pointer;
}

.jp-tocItem-collapser:hover {
  background-color: var(--jp-layout-color3);
}

/* Active heading indicator */

.jp-tocItem-heading::before {
  content: ' ';
  background: transparent;
  width: var(--jp-private-toc-active-width);
  height: 24px;
  position: absolute;
  left: 0;
  border-radius: var(--jp-border-radius);
}

.jp-tocItem-heading.jp-tocItem-active::before {
  background-color: var(--jp-brand-color1);
}

.jp-tocItem-heading:hover.jp-tocItem-active::before {
  background: var(--jp-brand-color0);
  opacity: 1;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Collapser {
  flex: 0 0 var(--jp-cell-collapser-width);
  padding: 0;
  margin: 0;
  border: none;
  outline: none;
  background: transparent;
  border-radius: var(--jp-border-radius);
  opacity: 1;
}

.jp-Collapser-child {
  display: block;
  width: 100%;
  box-sizing: border-box;

  /* height: 100% doesn't work because the height of its parent is computed from content */
  position: absolute;
  top: 0;
  bottom: 0;
}

/*-----------------------------------------------------------------------------
| Printing
|----------------------------------------------------------------------------*/

/*
Hiding collapsers in print mode.

Note: input and output wrappers have "display: block" propery in print mode.
*/

@media print {
  .jp-Collapser {
    display: none;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Header/Footer
|----------------------------------------------------------------------------*/

/* Hidden by zero height by default */
.jp-CellHeader,
.jp-CellFooter {
  height: 0;
  width: 100%;
  padding: 0;
  margin: 0;
  border: none;
  outline: none;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Input
|----------------------------------------------------------------------------*/

/* All input areas */
.jp-InputArea {
  display: table;
  table-layout: fixed;
  width: 100%;
  overflow: hidden;
}

.jp-InputArea-editor {
  display: table-cell;
  overflow: hidden;
  vertical-align: top;

  /* This is the non-active, default styling */
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  border-radius: 0;
  background: var(--jp-cell-editor-background);
}

.jp-InputPrompt {
  display: table-cell;
  vertical-align: top;
  width: var(--jp-cell-prompt-width);
  color: var(--jp-cell-inprompt-font-color);
  font-family: var(--jp-cell-prompt-font-family);
  padding: var(--jp-code-padding);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  opacity: var(--jp-cell-prompt-opacity);
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;

  /* Right align prompt text, don't wrap to handle large prompt numbers */
  text-align: right;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;

  /* Disable text selection */
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

/*-----------------------------------------------------------------------------
| Mobile
|----------------------------------------------------------------------------*/
@media only screen and (max-width: 760px) {
  .jp-InputArea-editor {
    display: table-row;
    margin-left: var(--jp-notebook-padding);
  }

  .jp-InputPrompt {
    display: table-row;
    text-align: left;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Placeholder
|----------------------------------------------------------------------------*/

.jp-Placeholder {
  display: table;
  table-layout: fixed;
  width: 100%;
}

.jp-Placeholder-prompt {
  display: table-cell;
  box-sizing: border-box;
}

.jp-Placeholder-content {
  display: table-cell;
  padding: 4px 6px;
  border: 1px solid transparent;
  border-radius: 0;
  background: none;
  box-sizing: border-box;
  cursor: pointer;
}

.jp-Placeholder-contentContainer {
  display: flex;
}

.jp-Placeholder-content:hover,
.jp-InputPlaceholder > .jp-Placeholder-content:hover {
  border-color: var(--jp-layout-color3);
}

.jp-Placeholder-content .jp-MoreHorizIcon {
  width: 32px;
  height: 16px;
  border: 1px solid transparent;
  border-radius: var(--jp-border-radius);
}

.jp-Placeholder-content .jp-MoreHorizIcon:hover {
  border: 1px solid var(--jp-border-color1);
  box-shadow: 0 0 2px 0 rgba(0, 0, 0, 0.25);
  background-color: var(--jp-layout-color0);
}

.jp-PlaceholderText {
  white-space: nowrap;
  overflow-x: hidden;
  color: var(--jp-inverse-layout-color3);
  font-family: var(--jp-code-font-family);
}

.jp-InputPlaceholder > .jp-Placeholder-content {
  border-color: var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Private CSS variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-cell-scrolling-output-offset: 5px;
}

/*-----------------------------------------------------------------------------
| Cell
|----------------------------------------------------------------------------*/

.jp-Cell {
  padding: var(--jp-cell-padding);
  margin: 0;
  border: none;
  outline: none;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Common input/output
|----------------------------------------------------------------------------*/

.jp-Cell-inputWrapper,
.jp-Cell-outputWrapper {
  display: flex;
  flex-direction: row;
  padding: 0;
  margin: 0;

  /* Added to reveal the box-shadow on the input and output collapsers. */
  overflow: visible;
}

/* Only input/output areas inside cells */
.jp-Cell-inputArea,
.jp-Cell-outputArea {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Collapser
|----------------------------------------------------------------------------*/

/* Make the output collapser disappear when there is not output, but do so
 * in a manner that leaves it in the layout and preserves its width.
 */
.jp-Cell.jp-mod-noOutputs .jp-Cell-outputCollapser {
  border: none !important;
  background: transparent !important;
}

.jp-Cell:not(.jp-mod-noOutputs) .jp-Cell-outputCollapser {
  min-height: var(--jp-cell-collapser-min-height);
}

/*-----------------------------------------------------------------------------
| Output
|----------------------------------------------------------------------------*/

/* Put a space between input and output when there IS output */
.jp-Cell:not(.jp-mod-noOutputs) .jp-Cell-outputWrapper {
  margin-top: 5px;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea {
  overflow-y: auto;
  max-height: 24em;
  margin-left: var(--jp-private-cell-scrolling-output-offset);
  resize: vertical;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea[style*='height'] {
  max-height: unset;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea::after {
  content: ' ';
  box-shadow: inset 0 0 6px 2px rgb(0 0 0 / 30%);
  width: 100%;
  height: 100%;
  position: sticky;
  bottom: 0;
  top: 0;
  margin-top: -50%;
  float: left;
  display: block;
  pointer-events: none;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-child {
  padding-top: 6px;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-prompt {
  width: calc(
    var(--jp-cell-prompt-width) - var(--jp-private-cell-scrolling-output-offset)
  );
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-promptOverlay {
  left: calc(-1 * var(--jp-private-cell-scrolling-output-offset));
}

/*-----------------------------------------------------------------------------
| CodeCell
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| MarkdownCell
|----------------------------------------------------------------------------*/

.jp-MarkdownOutput {
  display: table-cell;
  width: 100%;
  margin-top: 0;
  margin-bottom: 0;
  padding-left: var(--jp-code-padding);
}

.jp-MarkdownOutput.jp-RenderedHTMLCommon {
  overflow: auto;
}

/* collapseHeadingButton (show always if hiddenCellsButton is _not_ shown) */
.jp-collapseHeadingButton {
  display: flex;
  min-height: var(--jp-cell-collapser-min-height);
  font-size: var(--jp-code-font-size);
  position: absolute;
  background-color: transparent;
  background-size: 25px;
  background-repeat: no-repeat;
  background-position-x: center;
  background-position-y: top;
  background-image: var(--jp-icon-caret-down);
  right: 0;
  top: 0;
  bottom: 0;
}

.jp-collapseHeadingButton.jp-mod-collapsed {
  background-image: var(--jp-icon-caret-right);
}

/*
 set the container font size to match that of content
 so that the nested collapse buttons have the right size
*/
.jp-MarkdownCell .jp-InputPrompt {
  font-size: var(--jp-content-font-size1);
}

/*
  Align collapseHeadingButton with cell top header
  The font sizes are identical to the ones in packages/rendermime/style/base.css
*/
.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='1'] {
  font-size: var(--jp-content-font-size5);
  background-position-y: calc(0.3 * var(--jp-content-font-size5));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='2'] {
  font-size: var(--jp-content-font-size4);
  background-position-y: calc(0.3 * var(--jp-content-font-size4));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='3'] {
  font-size: var(--jp-content-font-size3);
  background-position-y: calc(0.3 * var(--jp-content-font-size3));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='4'] {
  font-size: var(--jp-content-font-size2);
  background-position-y: calc(0.3 * var(--jp-content-font-size2));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='5'] {
  font-size: var(--jp-content-font-size1);
  background-position-y: top;
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='6'] {
  font-size: var(--jp-content-font-size0);
  background-position-y: top;
}

/* collapseHeadingButton (show only on (hover,active) if hiddenCellsButton is shown) */
.jp-Notebook.jp-mod-showHiddenCellsButton .jp-collapseHeadingButton {
  display: none;
}

.jp-Notebook.jp-mod-showHiddenCellsButton
  :is(.jp-MarkdownCell:hover, .jp-mod-active)
  .jp-collapseHeadingButton {
  display: flex;
}

/* showHiddenCellsButton (only show if jp-mod-showHiddenCellsButton is set, which
is a consequence of the showHiddenCellsButton option in Notebook Settings)*/
.jp-Notebook.jp-mod-showHiddenCellsButton .jp-showHiddenCellsButton {
  margin-left: calc(var(--jp-cell-prompt-width) + 2 * var(--jp-code-padding));
  margin-top: var(--jp-code-padding);
  border: 1px solid var(--jp-border-color2);
  background-color: var(--jp-border-color3) !important;
  color: var(--jp-content-font-color0) !important;
  display: flex;
}

.jp-Notebook.jp-mod-showHiddenCellsButton .jp-showHiddenCellsButton:hover {
  background-color: var(--jp-border-color2) !important;
}

.jp-showHiddenCellsButton {
  display: none;
}

/*-----------------------------------------------------------------------------
| Printing
|----------------------------------------------------------------------------*/

/*
Using block instead of flex to allow the use of the break-inside CSS property for
cell outputs.
*/

@media print {
  .jp-Cell-inputWrapper,
  .jp-Cell-outputWrapper {
    display: block;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-notebook-toolbar-padding: 2px 5px 2px 2px;
}

/*-----------------------------------------------------------------------------

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-NotebookPanel-toolbar {
  padding: var(--jp-notebook-toolbar-padding);

  /* disable paint containment from lumino 2.0 default strict CSS containment */
  contain: style size !important;
}

.jp-Toolbar-item.jp-Notebook-toolbarCellType .jp-select-wrapper.jp-mod-focused {
  border: none;
  box-shadow: none;
}

.jp-Notebook-toolbarCellTypeDropdown select {
  height: 24px;
  font-size: var(--jp-ui-font-size1);
  line-height: 14px;
  border-radius: 0;
  display: block;
}

.jp-Notebook-toolbarCellTypeDropdown span {
  top: 5px !important;
}

.jp-Toolbar-responsive-popup {
  position: absolute;
  height: fit-content;
  display: flex;
  flex-direction: row;
  flex-wrap: wrap;
  justify-content: flex-end;
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  background: var(--jp-toolbar-background);
  min-height: var(--jp-toolbar-micro-height);
  padding: var(--jp-notebook-toolbar-padding);
  z-index: 1;
  right: 0;
  top: 0;
}

.jp-Toolbar > .jp-Toolbar-responsive-opener {
  margin-left: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-Notebook-ExecutionIndicator {
  position: relative;
  display: inline-block;
  height: 100%;
  z-index: 9997;
}

.jp-Notebook-ExecutionIndicator-tooltip {
  visibility: hidden;
  height: auto;
  width: max-content;
  width: -moz-max-content;
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color1);
  text-align: justify;
  border-radius: 6px;
  padding: 0 5px;
  position: fixed;
  display: table;
}

.jp-Notebook-ExecutionIndicator-tooltip.up {
  transform: translateX(-50%) translateY(-100%) translateY(-32px);
}

.jp-Notebook-ExecutionIndicator-tooltip.down {
  transform: translateX(calc(-100% + 16px)) translateY(5px);
}

.jp-Notebook-ExecutionIndicator-tooltip.hidden {
  display: none;
}

.jp-Notebook-ExecutionIndicator:hover .jp-Notebook-ExecutionIndicator-tooltip {
  visibility: visible;
}

.jp-Notebook-ExecutionIndicator span {
  font-size: var(--jp-ui-font-size1);
  font-family: var(--jp-ui-font-family);
  color: var(--jp-ui-font-color1);
  line-height: 24px;
  display: block;
}

.jp-Notebook-ExecutionIndicator-progress-bar {
  display: flex;
  justify-content: center;
  height: 100%;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*
 * Execution indicator
 */
.jp-tocItem-content::after {
  content: '';

  /* Must be identical to form a circle */
  width: 12px;
  height: 12px;
  background: none;
  border: none;
  position: absolute;
  right: 0;
}

.jp-tocItem-content[data-running='0']::after {
  border-radius: 50%;
  border: var(--jp-border-width) solid var(--jp-inverse-layout-color3);
  background: none;
}

.jp-tocItem-content[data-running='1']::after {
  border-radius: 50%;
  border: var(--jp-border-width) solid var(--jp-inverse-layout-color3);
  background-color: var(--jp-inverse-layout-color3);
}

.jp-tocItem-content[data-running='0'],
.jp-tocItem-content[data-running='1'] {
  margin-right: 12px;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-Notebook-footer {
  height: 27px;
  margin-left: calc(
    var(--jp-cell-prompt-width) + var(--jp-cell-collapser-width) +
      var(--jp-cell-padding)
  );
  width: calc(
    100% -
      (
        var(--jp-cell-prompt-width) + var(--jp-cell-collapser-width) +
          var(--jp-cell-padding) + var(--jp-cell-padding)
      )
  );
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  color: var(--jp-ui-font-color3);
  margin-top: 6px;
  background: none;
  cursor: pointer;
}

.jp-Notebook-footer:focus {
  border-color: var(--jp-cell-editor-active-border-color);
}

/* For devices that support hovering, hide footer until hover */
@media (hover: hover) {
  .jp-Notebook-footer {
    opacity: 0;
  }

  .jp-Notebook-footer:focus,
  .jp-Notebook-footer:hover {
    opacity: 1;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Imports
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| CSS variables
|----------------------------------------------------------------------------*/

:root {
  --jp-side-by-side-output-size: 1fr;
  --jp-side-by-side-resized-cell: var(--jp-side-by-side-output-size);
  --jp-private-notebook-dragImage-width: 304px;
  --jp-private-notebook-dragImage-height: 36px;
  --jp-private-notebook-selected-color: var(--md-blue-400);
  --jp-private-notebook-active-color: var(--md-green-400);
}

/*-----------------------------------------------------------------------------
| Notebook
|----------------------------------------------------------------------------*/

/* stylelint-disable selector-max-class */

.jp-NotebookPanel {
  display: block;
  height: 100%;
}

.jp-NotebookPanel.jp-Document {
  min-width: 240px;
  min-height: 120px;
}

.jp-Notebook {
  padding: var(--jp-notebook-padding);
  outline: none;
  overflow: auto;
  background: var(--jp-layout-color0);
}

.jp-Notebook.jp-mod-scrollPastEnd::after {
  display: block;
  content: '';
  min-height: var(--jp-notebook-scroll-padding);
}

.jp-MainAreaWidget-ContainStrict .jp-Notebook * {
  contain: strict;
}

.jp-Notebook .jp-Cell {
  overflow: visible;
}

.jp-Notebook .jp-Cell .jp-InputPrompt {
  cursor: move;
}

/*-----------------------------------------------------------------------------
| Notebook state related styling
|
| The notebook and cells each have states, here are the possibilities:
|
| - Notebook
|   - Command
|   - Edit
| - Cell
|   - None
|   - Active (only one can be active)
|   - Selected (the cells actions are applied to)
|   - Multiselected (when multiple selected, the cursor)
|   - No outputs
|----------------------------------------------------------------------------*/

/* Command or edit modes */

.jp-Notebook .jp-Cell:not(.jp-mod-active) .jp-InputPrompt {
  opacity: var(--jp-cell-prompt-not-active-opacity);
  color: var(--jp-cell-prompt-not-active-font-color);
}

.jp-Notebook .jp-Cell:not(.jp-mod-active) .jp-OutputPrompt {
  opacity: var(--jp-cell-prompt-not-active-opacity);
  color: var(--jp-cell-prompt-not-active-font-color);
}

/* cell is active */
.jp-Notebook .jp-Cell.jp-mod-active .jp-Collapser {
  background: var(--jp-brand-color1);
}

/* cell is dirty */
.jp-Notebook .jp-Cell.jp-mod-dirty .jp-InputPrompt {
  color: var(--jp-warn-color1);
}

.jp-Notebook .jp-Cell.jp-mod-dirty .jp-InputPrompt::before {
  color: var(--jp-warn-color1);
  content: '•';
}

.jp-Notebook .jp-Cell.jp-mod-active.jp-mod-dirty .jp-Collapser {
  background: var(--jp-warn-color1);
}

/* collapser is hovered */
.jp-Notebook .jp-Cell .jp-Collapser:hover {
  box-shadow: var(--jp-elevation-z2);
  background: var(--jp-brand-color1);
  opacity: var(--jp-cell-collapser-not-active-hover-opacity);
}

/* cell is active and collapser is hovered */
.jp-Notebook .jp-Cell.jp-mod-active .jp-Collapser:hover {
  background: var(--jp-brand-color0);
  opacity: 1;
}

/* Command mode */

.jp-Notebook.jp-mod-commandMode .jp-Cell.jp-mod-selected {
  background: var(--jp-notebook-multiselected-color);
}

.jp-Notebook.jp-mod-commandMode
  .jp-Cell.jp-mod-active.jp-mod-selected:not(.jp-mod-multiSelected) {
  background: transparent;
}

/* Edit mode */

.jp-Notebook.jp-mod-editMode .jp-Cell.jp-mod-active .jp-InputArea-editor {
  border: var(--jp-border-width) solid var(--jp-cell-editor-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
  background-color: var(--jp-cell-editor-active-background);
}

/*-----------------------------------------------------------------------------
| Notebook drag and drop
|----------------------------------------------------------------------------*/

.jp-Notebook-cell.jp-mod-dropSource {
  opacity: 0.5;
}

.jp-Notebook-cell.jp-mod-dropTarget,
.jp-Notebook.jp-mod-commandMode
  .jp-Notebook-cell.jp-mod-active.jp-mod-selected.jp-mod-dropTarget {
  border-top-color: var(--jp-private-notebook-selected-color);
  border-top-style: solid;
  border-top-width: 2px;
}

.jp-dragImage {
  display: block;
  flex-direction: row;
  width: var(--jp-private-notebook-dragImage-width);
  height: var(--jp-private-notebook-dragImage-height);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background);
  overflow: visible;
}

.jp-dragImage-singlePrompt {
  box-shadow: 2px 2px 4px 0 rgba(0, 0, 0, 0.12);
}

.jp-dragImage .jp-dragImage-content {
  flex: 1 1 auto;
  z-index: 2;
  font-size: var(--jp-code-font-size);
  font-family: var(--jp-code-font-family);
  line-height: var(--jp-code-line-height);
  padding: var(--jp-code-padding);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background-color);
  color: var(--jp-content-font-color3);
  text-align: left;
  margin: 4px 4px 4px 0;
}

.jp-dragImage .jp-dragImage-prompt {
  flex: 0 0 auto;
  min-width: 36px;
  color: var(--jp-cell-inprompt-font-color);
  padding: var(--jp-code-padding);
  padding-left: 12px;
  font-family: var(--jp-cell-prompt-font-family);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  line-height: 1.9;
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
}

.jp-dragImage-multipleBack {
  z-index: -1;
  position: absolute;
  height: 32px;
  width: 300px;
  top: 8px;
  left: 8px;
  background: var(--jp-layout-color2);
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  box-shadow: 2px 2px 4px 0 rgba(0, 0, 0, 0.12);
}

/*-----------------------------------------------------------------------------
| Cell toolbar
|----------------------------------------------------------------------------*/

.jp-NotebookTools {
  display: block;
  min-width: var(--jp-sidebar-min-width);
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);

  /* This is needed so that all font sizing of children done in ems is
    * relative to this base size */
  font-size: var(--jp-ui-font-size1);
  overflow: auto;
}

.jp-ActiveCellTool {
  padding: 12px 0;
  display: flex;
}

.jp-ActiveCellTool-Content {
  flex: 1 1 auto;
}

.jp-ActiveCellTool .jp-ActiveCellTool-CellContent {
  background: var(--jp-cell-editor-background);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  border-radius: 0;
  min-height: 29px;
}

.jp-ActiveCellTool .jp-InputPrompt {
  min-width: calc(var(--jp-cell-prompt-width) * 0.75);
}

.jp-ActiveCellTool-CellContent > pre {
  padding: 5px 4px;
  margin: 0;
  white-space: normal;
}

.jp-MetadataEditorTool {
  flex-direction: column;
  padding: 12px 0;
}

.jp-RankedPanel > :not(:first-child) {
  margin-top: 12px;
}

.jp-KeySelector select.jp-mod-styled {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  border: var(--jp-border-width) solid var(--jp-border-color1);
}

.jp-KeySelector label,
.jp-MetadataEditorTool label,
.jp-NumberSetter label {
  line-height: 1.4;
}

.jp-NotebookTools .jp-select-wrapper {
  margin-top: 4px;
  margin-bottom: 0;
}

.jp-NumberSetter input {
  width: 100%;
  margin-top: 4px;
}

.jp-NotebookTools .jp-Collapse {
  margin-top: 16px;
}

/*-----------------------------------------------------------------------------
| Presentation Mode (.jp-mod-presentationMode)
|----------------------------------------------------------------------------*/

.jp-mod-presentationMode .jp-Notebook {
  --jp-content-font-size1: var(--jp-content-presentation-font-size1);
  --jp-code-font-size: var(--jp-code-presentation-font-size);
}

.jp-mod-presentationMode .jp-Notebook .jp-Cell .jp-InputPrompt,
.jp-mod-presentationMode .jp-Notebook .jp-Cell .jp-OutputPrompt {
  flex: 0 0 110px;
}

/*-----------------------------------------------------------------------------
| Side-by-side Mode (.jp-mod-sideBySide)
|----------------------------------------------------------------------------*/
.jp-mod-sideBySide.jp-Notebook .jp-Notebook-cell {
  margin-top: 3em;
  margin-bottom: 3em;
  margin-left: 5%;
  margin-right: 5%;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell {
  display: grid;
  grid-template-columns: minmax(0, 1fr) min-content minmax(
      0,
      var(--jp-side-by-side-output-size)
    );
  grid-template-rows: auto minmax(0, 1fr) auto;
  grid-template-areas:
    'header header header'
    'input handle output'
    'footer footer footer';
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell.jp-mod-resizedCell {
  grid-template-columns: minmax(0, 1fr) min-content minmax(
      0,
      var(--jp-side-by-side-resized-cell)
    );
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellHeader {
  grid-area: header;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-Cell-inputWrapper {
  grid-area: input;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-Cell-outputWrapper {
  /* overwrite the default margin (no vertical separation needed in side by side move */
  margin-top: 0;
  grid-area: output;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellFooter {
  grid-area: footer;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellResizeHandle {
  grid-area: handle;
  user-select: none;
  display: block;
  height: 100%;
  cursor: ew-resize;
  padding: 0 var(--jp-cell-padding);
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellResizeHandle::after {
  content: '';
  display: block;
  background: var(--jp-border-color2);
  height: 100%;
  width: 5px;
}

.jp-mod-sideBySide.jp-Notebook
  .jp-CodeCell.jp-mod-resizedCell
  .jp-CellResizeHandle::after {
  background: var(--jp-border-color0);
}

.jp-CellResizeHandle {
  display: none;
}

/*-----------------------------------------------------------------------------
| Placeholder
|----------------------------------------------------------------------------*/

.jp-Cell-Placeholder {
  padding-left: 55px;
}

.jp-Cell-Placeholder-wrapper {
  background: #fff;
  border: 1px solid;
  border-color: #e5e6e9 #dfe0e4 #d0d1d5;
  border-radius: 4px;
  -webkit-border-radius: 4px;
  margin: 10px 15px;
}

.jp-Cell-Placeholder-wrapper-inner {
  padding: 15px;
  position: relative;
}

.jp-Cell-Placeholder-wrapper-body {
  background-repeat: repeat;
  background-size: 50% auto;
}

.jp-Cell-Placeholder-wrapper-body div {
  background: #f6f7f8;
  background-image: -webkit-linear-gradient(
    left,
    #f6f7f8 0%,
    #edeef1 20%,
    #f6f7f8 40%,
    #f6f7f8 100%
  );
  background-repeat: no-repeat;
  background-size: 800px 104px;
  height: 104px;
  position: absolute;
  right: 15px;
  left: 15px;
  top: 15px;
}

div.jp-Cell-Placeholder-h1 {
  top: 20px;
  height: 20px;
  left: 15px;
  width: 150px;
}

div.jp-Cell-Placeholder-h2 {
  left: 15px;
  top: 50px;
  height: 10px;
  width: 100px;
}

div.jp-Cell-Placeholder-content-1,
div.jp-Cell-Placeholder-content-2,
div.jp-Cell-Placeholder-content-3 {
  left: 15px;
  right: 15px;
  height: 10px;
}

div.jp-Cell-Placeholder-content-1 {
  top: 100px;
}

div.jp-Cell-Placeholder-content-2 {
  top: 120px;
}

div.jp-Cell-Placeholder-content-3 {
  top: 140px;
}

</style>
<style type="text/css">
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*
The following CSS variables define the main, public API for styling JupyterLab.
These variables should be used by all plugins wherever possible. In other
words, plugins should not define custom colors, sizes, etc unless absolutely
necessary. This enables users to change the visual theme of JupyterLab
by changing these variables.

Many variables appear in an ordered sequence (0,1,2,3). These sequences
are designed to work well together, so for example, `--jp-border-color1` should
be used with `--jp-layout-color1`. The numbers have the following meanings:

* 0: super-primary, reserved for special emphasis
* 1: primary, most important under normal situations
* 2: secondary, next most important under normal situations
* 3: tertiary, next most important under normal situations

Throughout JupyterLab, we are mostly following principles from Google's
Material Design when selecting colors. We are not, however, following
all of MD as it is not optimized for dense, information rich UIs.
*/

:root {
  /* Elevation
   *
   * We style box-shadows using Material Design's idea of elevation. These particular numbers are taken from here:
   *
   * https://github.com/material-components/material-components-web
   * https://material-components-web.appspot.com/elevation.html
   */

  --jp-shadow-base-lightness: 0;
  --jp-shadow-umbra-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.2
  );
  --jp-shadow-penumbra-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.14
  );
  --jp-shadow-ambient-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.12
  );
  --jp-elevation-z0: none;
  --jp-elevation-z1: 0 2px 1px -1px var(--jp-shadow-umbra-color),
    0 1px 1px 0 var(--jp-shadow-penumbra-color),
    0 1px 3px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z2: 0 3px 1px -2px var(--jp-shadow-umbra-color),
    0 2px 2px 0 var(--jp-shadow-penumbra-color),
    0 1px 5px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z4: 0 2px 4px -1px var(--jp-shadow-umbra-color),
    0 4px 5px 0 var(--jp-shadow-penumbra-color),
    0 1px 10px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z6: 0 3px 5px -1px var(--jp-shadow-umbra-color),
    0 6px 10px 0 var(--jp-shadow-penumbra-color),
    0 1px 18px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z8: 0 5px 5px -3px var(--jp-shadow-umbra-color),
    0 8px 10px 1px var(--jp-shadow-penumbra-color),
    0 3px 14px 2px var(--jp-shadow-ambient-color);
  --jp-elevation-z12: 0 7px 8px -4px var(--jp-shadow-umbra-color),
    0 12px 17px 2px var(--jp-shadow-penumbra-color),
    0 5px 22px 4px var(--jp-shadow-ambient-color);
  --jp-elevation-z16: 0 8px 10px -5px var(--jp-shadow-umbra-color),
    0 16px 24px 2px var(--jp-shadow-penumbra-color),
    0 6px 30px 5px var(--jp-shadow-ambient-color);
  --jp-elevation-z20: 0 10px 13px -6px var(--jp-shadow-umbra-color),
    0 20px 31px 3px var(--jp-shadow-penumbra-color),
    0 8px 38px 7px var(--jp-shadow-ambient-color);
  --jp-elevation-z24: 0 11px 15px -7px var(--jp-shadow-umbra-color),
    0 24px 38px 3px var(--jp-shadow-penumbra-color),
    0 9px 46px 8px var(--jp-shadow-ambient-color);

  /* Borders
   *
   * The following variables, specify the visual styling of borders in JupyterLab.
   */

  --jp-border-width: 1px;
  --jp-border-color0: var(--md-grey-400);
  --jp-border-color1: var(--md-grey-400);
  --jp-border-color2: var(--md-grey-300);
  --jp-border-color3: var(--md-grey-200);
  --jp-inverse-border-color: var(--md-grey-600);
  --jp-border-radius: 2px;

  /* UI Fonts
   *
   * The UI font CSS variables are used for the typography all of the JupyterLab
   * user interface elements that are not directly user generated content.
   *
   * The font sizing here is done assuming that the body font size of --jp-ui-font-size1
   * is applied to a parent element. When children elements, such as headings, are sized
   * in em all things will be computed relative to that body size.
   */

  --jp-ui-font-scale-factor: 1.2;
  --jp-ui-font-size0: 0.83333em;
  --jp-ui-font-size1: 13px; /* Base font size */
  --jp-ui-font-size2: 1.2em;
  --jp-ui-font-size3: 1.44em;
  --jp-ui-font-family: system-ui, -apple-system, blinkmacsystemfont, 'Segoe UI',
    helvetica, arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji',
    'Segoe UI Symbol';

  /*
   * Use these font colors against the corresponding main layout colors.
   * In a light theme, these go from dark to light.
   */

  /* Defaults use Material Design specification */
  --jp-ui-font-color0: rgba(0, 0, 0, 1);
  --jp-ui-font-color1: rgba(0, 0, 0, 0.87);
  --jp-ui-font-color2: rgba(0, 0, 0, 0.54);
  --jp-ui-font-color3: rgba(0, 0, 0, 0.38);

  /*
   * Use these against the brand/accent/warn/error colors.
   * These will typically go from light to darker, in both a dark and light theme.
   */

  --jp-ui-inverse-font-color0: rgba(255, 255, 255, 1);
  --jp-ui-inverse-font-color1: rgba(255, 255, 255, 1);
  --jp-ui-inverse-font-color2: rgba(255, 255, 255, 0.7);
  --jp-ui-inverse-font-color3: rgba(255, 255, 255, 0.5);

  /* Content Fonts
   *
   * Content font variables are used for typography of user generated content.
   *
   * The font sizing here is done assuming that the body font size of --jp-content-font-size1
   * is applied to a parent element. When children elements, such as headings, are sized
   * in em all things will be computed relative to that body size.
   */

  --jp-content-line-height: 1.6;
  --jp-content-font-scale-factor: 1.2;
  --jp-content-font-size0: 0.83333em;
  --jp-content-font-size1: 14px; /* Base font size */
  --jp-content-font-size2: 1.2em;
  --jp-content-font-size3: 1.44em;
  --jp-content-font-size4: 1.728em;
  --jp-content-font-size5: 2.0736em;

  /* This gives a magnification of about 125% in presentation mode over normal. */
  --jp-content-presentation-font-size1: 17px;
  --jp-content-heading-line-height: 1;
  --jp-content-heading-margin-top: 1.2em;
  --jp-content-heading-margin-bottom: 0.8em;
  --jp-content-heading-font-weight: 500;

  /* Defaults use Material Design specification */
  --jp-content-font-color0: rgba(0, 0, 0, 1);
  --jp-content-font-color1: rgba(0, 0, 0, 0.87);
  --jp-content-font-color2: rgba(0, 0, 0, 0.54);
  --jp-content-font-color3: rgba(0, 0, 0, 0.38);
  --jp-content-link-color: var(--md-blue-900);
  --jp-content-font-family: system-ui, -apple-system, blinkmacsystemfont,
    'Segoe UI', helvetica, arial, sans-serif, 'Apple Color Emoji',
    'Segoe UI Emoji', 'Segoe UI Symbol';

  /*
   * Code Fonts
   *
   * Code font variables are used for typography of code and other monospaces content.
   */

  --jp-code-font-size: 13px;
  --jp-code-line-height: 1.3077; /* 17px for 13px base */
  --jp-code-padding: 5px; /* 5px for 13px base, codemirror highlighting needs integer px value */
  --jp-code-font-family-default: menlo, consolas, 'DejaVu Sans Mono', monospace;
  --jp-code-font-family: var(--jp-code-font-family-default);

  /* This gives a magnification of about 125% in presentation mode over normal. */
  --jp-code-presentation-font-size: 16px;

  /* may need to tweak cursor width if you change font size */
  --jp-code-cursor-width0: 1.4px;
  --jp-code-cursor-width1: 2px;
  --jp-code-cursor-width2: 4px;

  /* Layout
   *
   * The following are the main layout colors use in JupyterLab. In a light
   * theme these would go from light to dark.
   */

  --jp-layout-color0: white;
  --jp-layout-color1: white;
  --jp-layout-color2: var(--md-grey-200);
  --jp-layout-color3: var(--md-grey-400);
  --jp-layout-color4: var(--md-grey-600);

  /* Inverse Layout
   *
   * The following are the inverse layout colors use in JupyterLab. In a light
   * theme these would go from dark to light.
   */

  --jp-inverse-layout-color0: #111;
  --jp-inverse-layout-color1: var(--md-grey-900);
  --jp-inverse-layout-color2: var(--md-grey-800);
  --jp-inverse-layout-color3: var(--md-grey-700);
  --jp-inverse-layout-color4: var(--md-grey-600);

  /* Brand/accent */

  --jp-brand-color0: var(--md-blue-900);
  --jp-brand-color1: var(--md-blue-700);
  --jp-brand-color2: var(--md-blue-300);
  --jp-brand-color3: var(--md-blue-100);
  --jp-brand-color4: var(--md-blue-50);
  --jp-accent-color0: var(--md-green-900);
  --jp-accent-color1: var(--md-green-700);
  --jp-accent-color2: var(--md-green-300);
  --jp-accent-color3: var(--md-green-100);

  /* State colors (warn, error, success, info) */

  --jp-warn-color0: var(--md-orange-900);
  --jp-warn-color1: var(--md-orange-700);
  --jp-warn-color2: var(--md-orange-300);
  --jp-warn-color3: var(--md-orange-100);
  --jp-error-color0: var(--md-red-900);
  --jp-error-color1: var(--md-red-700);
  --jp-error-color2: var(--md-red-300);
  --jp-error-color3: var(--md-red-100);
  --jp-success-color0: var(--md-green-900);
  --jp-success-color1: var(--md-green-700);
  --jp-success-color2: var(--md-green-300);
  --jp-success-color3: var(--md-green-100);
  --jp-info-color0: var(--md-cyan-900);
  --jp-info-color1: var(--md-cyan-700);
  --jp-info-color2: var(--md-cyan-300);
  --jp-info-color3: var(--md-cyan-100);

  /* Cell specific styles */

  --jp-cell-padding: 5px;
  --jp-cell-collapser-width: 8px;
  --jp-cell-collapser-min-height: 20px;
  --jp-cell-collapser-not-active-hover-opacity: 0.6;
  --jp-cell-editor-background: var(--md-grey-100);
  --jp-cell-editor-border-color: var(--md-grey-300);
  --jp-cell-editor-box-shadow: inset 0 0 2px var(--md-blue-300);
  --jp-cell-editor-active-background: var(--jp-layout-color0);
  --jp-cell-editor-active-border-color: var(--jp-brand-color1);
  --jp-cell-prompt-width: 64px;
  --jp-cell-prompt-font-family: var(--jp-code-font-family-default);
  --jp-cell-prompt-letter-spacing: 0;
  --jp-cell-prompt-opacity: 1;
  --jp-cell-prompt-not-active-opacity: 0.5;
  --jp-cell-prompt-not-active-font-color: var(--md-grey-700);

  /* A custom blend of MD grey and blue 600
   * See https://meyerweb.com/eric/tools/color-blend/#546E7A:1E88E5:5:hex */
  --jp-cell-inprompt-font-color: #307fc1;

  /* A custom blend of MD grey and orange 600
   * https://meyerweb.com/eric/tools/color-blend/#546E7A:F4511E:5:hex */
  --jp-cell-outprompt-font-color: #bf5b3d;

  /* Notebook specific styles */

  --jp-notebook-padding: 10px;
  --jp-notebook-select-background: var(--jp-layout-color1);
  --jp-notebook-multiselected-color: var(--md-blue-50);

  /* The scroll padding is calculated to fill enough space at the bottom of the
  notebook to show one single-line cell (with appropriate padding) at the top
  when the notebook is scrolled all the way to the bottom. We also subtract one
  pixel so that no scrollbar appears if we have just one single-line cell in the
  notebook. This padding is to enable a 'scroll past end' feature in a notebook.
  */
  --jp-notebook-scroll-padding: calc(
    100% - var(--jp-code-font-size) * var(--jp-code-line-height) -
      var(--jp-code-padding) - var(--jp-cell-padding) - 1px
  );

  /* Rendermime styles */

  --jp-rendermime-error-background: #fdd;
  --jp-rendermime-table-row-background: var(--md-grey-100);
  --jp-rendermime-table-row-hover-background: var(--md-light-blue-50);

  /* Dialog specific styles */

  --jp-dialog-background: rgba(0, 0, 0, 0.25);

  /* Console specific styles */

  --jp-console-padding: 10px;

  /* Toolbar specific styles */

  --jp-toolbar-border-color: var(--jp-border-color1);
  --jp-toolbar-micro-height: 8px;
  --jp-toolbar-background: var(--jp-layout-color1);
  --jp-toolbar-box-shadow: 0 0 2px 0 rgba(0, 0, 0, 0.24);
  --jp-toolbar-header-margin: 4px 4px 0 4px;
  --jp-toolbar-active-background: var(--md-grey-300);

  /* Statusbar specific styles */

  --jp-statusbar-height: 24px;

  /* Input field styles */

  --jp-input-box-shadow: inset 0 0 2px var(--md-blue-300);
  --jp-input-active-background: var(--jp-layout-color1);
  --jp-input-hover-background: var(--jp-layout-color1);
  --jp-input-background: var(--md-grey-100);
  --jp-input-border-color: var(--jp-inverse-border-color);
  --jp-input-active-border-color: var(--jp-brand-color1);
  --jp-input-active-box-shadow-color: rgba(19, 124, 189, 0.3);

  /* General editor styles */

  --jp-editor-selected-background: #d9d9d9;
  --jp-editor-selected-focused-background: #d7d4f0;
  --jp-editor-cursor-color: var(--jp-ui-font-color0);

  /* Code mirror specific styles */

  --jp-mirror-editor-keyword-color: #008000;
  --jp-mirror-editor-atom-color: #88f;
  --jp-mirror-editor-number-color: #080;
  --jp-mirror-editor-def-color: #00f;
  --jp-mirror-editor-variable-color: var(--md-grey-900);
  --jp-mirror-editor-variable-2-color: rgb(0, 54, 109);
  --jp-mirror-editor-variable-3-color: #085;
  --jp-mirror-editor-punctuation-color: #05a;
  --jp-mirror-editor-property-color: #05a;
  --jp-mirror-editor-operator-color: #a2f;
  --jp-mirror-editor-comment-color: #408080;
  --jp-mirror-editor-string-color: #ba2121;
  --jp-mirror-editor-string-2-color: #708;
  --jp-mirror-editor-meta-color: #a2f;
  --jp-mirror-editor-qualifier-color: #555;
  --jp-mirror-editor-builtin-color: #008000;
  --jp-mirror-editor-bracket-color: #997;
  --jp-mirror-editor-tag-color: #170;
  --jp-mirror-editor-attribute-color: #00c;
  --jp-mirror-editor-header-color: blue;
  --jp-mirror-editor-quote-color: #090;
  --jp-mirror-editor-link-color: #00c;
  --jp-mirror-editor-error-color: #f00;
  --jp-mirror-editor-hr-color: #999;

  /*
    RTC user specific colors.
    These colors are used for the cursor, username in the editor,
    and the icon of the user.
  */

  --jp-collaborator-color1: #ffad8e;
  --jp-collaborator-color2: #dac83d;
  --jp-collaborator-color3: #72dd76;
  --jp-collaborator-color4: #00e4d0;
  --jp-collaborator-color5: #45d4ff;
  --jp-collaborator-color6: #e2b1ff;
  --jp-collaborator-color7: #ff9de6;

  /* Vega extension styles */

  --jp-vega-background: white;

  /* Sidebar-related styles */

  --jp-sidebar-min-width: 250px;

  /* Search-related styles */

  --jp-search-toggle-off-opacity: 0.5;
  --jp-search-toggle-hover-opacity: 0.8;
  --jp-search-toggle-on-opacity: 1;
  --jp-search-selected-match-background-color: rgb(245, 200, 0);
  --jp-search-selected-match-color: black;
  --jp-search-unselected-match-background-color: var(
    --jp-inverse-layout-color0
  );
  --jp-search-unselected-match-color: var(--jp-ui-inverse-font-color0);

  /* Icon colors that work well with light or dark backgrounds */
  --jp-icon-contrast-color0: var(--md-purple-600);
  --jp-icon-contrast-color1: var(--md-green-600);
  --jp-icon-contrast-color2: var(--md-pink-600);
  --jp-icon-contrast-color3: var(--md-blue-600);

  /* Button colors */
  --jp-accept-color-normal: var(--md-blue-700);
  --jp-accept-color-hover: var(--md-blue-800);
  --jp-accept-color-active: var(--md-blue-900);
  --jp-warn-color-normal: var(--md-red-700);
  --jp-warn-color-hover: var(--md-red-800);
  --jp-warn-color-active: var(--md-red-900);
  --jp-reject-color-normal: var(--md-grey-600);
  --jp-reject-color-hover: var(--md-grey-700);
  --jp-reject-color-active: var(--md-grey-800);

  /* File or activity icons and switch semantic variables */
  --jp-jupyter-icon-color: #f37626;
  --jp-notebook-icon-color: #f37626;
  --jp-json-icon-color: var(--md-orange-700);
  --jp-console-icon-background-color: var(--md-blue-700);
  --jp-console-icon-color: white;
  --jp-terminal-icon-background-color: var(--md-grey-800);
  --jp-terminal-icon-color: var(--md-grey-200);
  --jp-text-editor-icon-color: var(--md-grey-700);
  --jp-inspector-icon-color: var(--md-grey-700);
  --jp-switch-color: var(--md-grey-400);
  --jp-switch-true-position-color: var(--md-orange-900);
}
</style>
<style type="text/css">
/* Force rendering true colors when outputing to pdf */
* {
  -webkit-print-color-adjust: exact;
}

/* Misc */
a.anchor-link {
  display: none;
}

/* Input area styling */
.jp-InputArea {
  overflow: hidden;
}

.jp-InputArea-editor {
  overflow: hidden;
}

.cm-editor.cm-s-jupyter .highlight pre {
/* weird, but --jp-code-padding defined to be 5px but 4px horizontal padding is hardcoded for pre.cm-line */
  padding: var(--jp-code-padding) 4px;
  margin: 0;

  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
  color: inherit;

}

.jp-OutputArea-output pre {
  line-height: inherit;
  font-family: inherit;
}

.jp-RenderedText pre {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-code-font-size);
}

/* Hiding the collapser by default */
.jp-Collapser {
  display: none;
}

@page {
    margin: 0.5in; /* Margin for each printed piece of paper */
}

@media print {
  .jp-Cell-inputWrapper,
  .jp-Cell-outputWrapper {
    display: block;
  }
}
</style>
<!-- Load mathjax -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML-full,Safe"> </script>
<!-- MathJax configuration -->
<script type="text/x-mathjax-config">
    init_mathjax = function() {
        if (window.MathJax) {
        // MathJax loaded
            MathJax.Hub.Config({
                TeX: {
                    equationNumbers: {
                    autoNumber: "AMS",
                    useLabelIds: true
                    }
                },
                tex2jax: {
                    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                    processEscapes: true,
                    processEnvironments: true
                },
                displayAlign: 'center',
                CommonHTML: {
                    linebreaks: {
                    automatic: true
                    }
                }
            });

            MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
        }
    }
    init_mathjax();
    </script>
<!-- End of mathjax configuration --><script type="module">
  document.addEventListener("DOMContentLoaded", async () => {
    const diagrams = document.querySelectorAll(".jp-Mermaid > pre.mermaid");
    // do not load mermaidjs if not needed
    if (!diagrams.length) {
      return;
    }
    const mermaid = (await import("https://cdnjs.cloudflare.com/ajax/libs/mermaid/10.7.0/mermaid.esm.min.mjs")).default;
    const parser = new DOMParser();

    mermaid.initialize({
      maxTextSize: 100000,
      maxEdges: 100000,
      startOnLoad: false,
      fontFamily: window
        .getComputedStyle(document.body)
        .getPropertyValue("--jp-ui-font-family"),
      theme: document.querySelector("body[data-jp-theme-light='true']")
        ? "default"
        : "dark",
    });

    let _nextMermaidId = 0;

    function makeMermaidImage(svg) {
      const img = document.createElement("img");
      const doc = parser.parseFromString(svg, "image/svg+xml");
      const svgEl = doc.querySelector("svg");
      const { maxWidth } = svgEl?.style || {};
      const firstTitle = doc.querySelector("title");
      const firstDesc = doc.querySelector("desc");

      img.setAttribute("src", `data:image/svg+xml,${encodeURIComponent(svg)}`);
      if (maxWidth) {
        img.width = parseInt(maxWidth);
      }
      if (firstTitle) {
        img.setAttribute("alt", firstTitle.textContent);
      }
      if (firstDesc) {
        const caption = document.createElement("figcaption");
        caption.className = "sr-only";
        caption.textContent = firstDesc.textContent;
        return [img, caption];
      }
      return [img];
    }

    async function makeMermaidError(text) {
      let errorMessage = "";
      try {
        await mermaid.parse(text);
      } catch (err) {
        errorMessage = `${err}`;
      }

      const result = document.createElement("details");
      result.className = 'jp-RenderedMermaid-Details';
      const summary = document.createElement("summary");
      summary.className = 'jp-RenderedMermaid-Summary';
      const pre = document.createElement("pre");
      const code = document.createElement("code");
      code.innerText = text;
      pre.appendChild(code);
      summary.appendChild(pre);
      result.appendChild(summary);

      const warning = document.createElement("pre");
      warning.innerText = errorMessage;
      result.appendChild(warning);
      return [result];
    }

    async function renderOneMarmaid(src) {
      const id = `jp-mermaid-${_nextMermaidId++}`;
      const parent = src.parentNode;
      let raw = src.textContent.trim();
      const el = document.createElement("div");
      el.style.visibility = "hidden";
      document.body.appendChild(el);
      let results = null;
      let output = null;
      try {
        let { svg } = await mermaid.render(id, raw, el);
        svg = cleanMermaidSvg(svg);
        results = makeMermaidImage(svg);
        output = document.createElement("figure");
        results.map(output.appendChild, output);
      } catch (err) {
        parent.classList.add("jp-mod-warning");
        results = await makeMermaidError(raw);
        output = results[0];
      } finally {
        el.remove();
      }
      parent.classList.add("jp-RenderedMermaid");
      parent.appendChild(output);
    }


    /**
     * Post-process to ensure mermaid diagrams contain only valid SVG and XHTML.
     */
    function cleanMermaidSvg(svg) {
      return svg.replace(RE_VOID_ELEMENT, replaceVoidElement);
    }


    /**
     * A regular expression for all void elements, which may include attributes and
     * a slash.
     *
     * @see https://developer.mozilla.org/en-US/docs/Glossary/Void_element
     *
     * Of these, only `<br>` is generated by Mermaid in place of `\n`,
     * but _any_ "malformed" tag will break the SVG rendering entirely.
     */
    const RE_VOID_ELEMENT =
      /<\s*(area|base|br|col|embed|hr|img|input|link|meta|param|source|track|wbr)\s*([^>]*?)\s*>/gi;

    /**
     * Ensure a void element is closed with a slash, preserving any attributes.
     */
    function replaceVoidElement(match, tag, rest) {
      rest = rest.trim();
      if (!rest.endsWith('/')) {
        rest = `${rest} /`;
      }
      return `<${tag} ${rest}>`;
    }

    void Promise.all([...diagrams].map(renderOneMarmaid));
  });
</script>
<style>
  .jp-Mermaid:not(.jp-RenderedMermaid) {
    display: none;
  }

  .jp-RenderedMermaid {
    overflow: auto;
    display: flex;
  }

  .jp-RenderedMermaid.jp-mod-warning {
    width: auto;
    padding: 0.5em;
    margin-top: 0.5em;
    border: var(--jp-border-width) solid var(--jp-warn-color2);
    border-radius: var(--jp-border-radius);
    color: var(--jp-ui-font-color1);
    font-size: var(--jp-ui-font-size1);
    white-space: pre-wrap;
    word-wrap: break-word;
  }

  .jp-RenderedMermaid figure {
    margin: 0;
    overflow: auto;
    max-width: 100%;
  }

  .jp-RenderedMermaid img {
    max-width: 100%;
  }

  .jp-RenderedMermaid-Details > pre {
    margin-top: 1em;
  }

  .jp-RenderedMermaid-Summary {
    color: var(--jp-warn-color2);
  }

  .jp-RenderedMermaid:not(.jp-mod-warning) pre {
    display: none;
  }

  .jp-RenderedMermaid-Summary > pre {
    display: inline-block;
    white-space: normal;
  }
</style>
<!-- End of mermaid configuration --></head>
<body class="jp-Notebook" data-jp-theme-light="true" data-jp-theme-name="JupyterLab Light">
<main>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=3d9f4abf">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="Implementing-Transformers">Implementing Transformers<a class="anchor-link" href="#Implementing-Transformers">¶</a></h1><p>This notebook will walk you through the internals of implementing self attention and transformer networks.  As with recurrent networks (and unlike convolutions), there is actually relatively little that is fundamentally new in their implementation, as it all largely involves an application of existing primitives you will have already implemented in your autodiff framework.  However, there is indeed one aspect of an efficient implementation that requires a slight generalization of an item we have discussed already: a <em>batch</em> version of matrix multiplication.  This is required for both the minibatch version of attention as well as the common "multihead" version.  We will also briefly discuss some approaches to making Transformers more efficient.</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=e150202b">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Implementing-self-attention">Implementing self-attention<a class="anchor-link" href="#Implementing-self-attention">¶</a></h2><p>Let's begin with a simple implementation of self-attention.  This essentially just implements the basic equation</p>
<p>\begin{equation}
Y = \mathrm{softmax}\left(\frac{KQ^T}{\sqrt{d}}\right)V
\end{equation}</p>
<p>By convention, however, it's typical to implement self attention in terms of the actual inputs $X$ rather than the $K$, $Q$, and $V$ values themselves (i.e., instead of having the linear layer separately).  It's also common to have an output weight as well (even though this could in theory be folded into the $W_{KQV}$ terms), which applies an additional linear layer to the output of the the entire operation.  I.e., the full operation is given by
\begin{equation}
Y = \left(\mathrm{softmax}\left(\frac{X W_K W_Q^T X^T}{\sqrt{d}}\right)X W_V \right) W_o.
\end{equation}
It's possible to also incorporate bias terms into each of these projections, though we won't bother with this, as it is less common for everything but the output weight, and then just largely adds complexity.</p>
<p>Let's see what this implementation looks like.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=a35fb17d">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [5]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=67a9d7ab">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [2]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">softmax</span><span class="p">(</span><span class="n">Z</span><span class="p">):</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">Z</span> <span class="o">-</span> <span class="n">Z</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">Z</span> <span class="o">/</span> <span class="n">Z</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    
<span class="k">def</span> <span class="nf">self_attention</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">W_KQV</span><span class="p">,</span> <span class="n">W_out</span><span class="p">):</span>
    <span class="n">K</span><span class="p">,</span><span class="n">Q</span><span class="p">,</span><span class="n">V</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="nd">@W_KQV</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">attn</span> <span class="o">=</span> <span class="n">softmax</span><span class="p">(</span><span class="n">K</span><span class="nd">@Q</span><span class="o">.</span><span class="n">swapaxes</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="o">+</span> <span class="n">mask</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">attn</span><span class="nd">@V@W_out</span><span class="p">,</span> <span class="n">attn</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=cbe332ed">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>We can compare this to PyTorch's self-attention implementation, the <code>nn.MultiheadAttention</code> layer (we'll cover what we mean by "multi-head" shortly).  Note that by default (mainly just to be similar to the RNN implementation and other sequence models, the <code>nn.MultiheadAttention</code> layer <em>also</em> by default takes inputs in $(T,N,d)$ form (i.e, the batch dimension second.  But unlike for RNNs, this ordering doesn't make much sense for self-attention and Transformers: we will be computing the operation "in parallel" over all times points, instead of as a sequential model like for RNNs.  So we'll use the <code>batch_first=True</code> flag to make this a more natural dimension ordering for the inputs.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=3cc24289">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [3]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">T</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">M</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">triu</span><span class="p">(</span><span class="o">-</span><span class="nb">float</span><span class="p">(</span><span class="s2">"inf"</span><span class="p">)</span><span class="o">*</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">T</span><span class="p">,</span><span class="n">T</span><span class="p">),</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[3]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>tensor([[0., -inf, -inf, -inf, -inf],
        [0., 0., -inf, -inf, -inf],
        [0., 0., 0., -inf, -inf],
        [0., 0., 0., 0., -inf],
        [0., 0., 0., 0., 0.]])</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=30733bf4">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [52]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">T</span><span class="p">,</span> <span class="n">d</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">64</span>
<span class="n">attn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MultiheadAttention</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">M</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">triu</span><span class="p">(</span><span class="o">-</span><span class="nb">float</span><span class="p">(</span><span class="s2">"inf"</span><span class="p">)</span><span class="o">*</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">T</span><span class="p">,</span><span class="n">T</span><span class="p">),</span><span class="mi">1</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">T</span><span class="p">,</span><span class="n">d</span><span class="p">)</span>
<span class="n">Y_</span><span class="p">,</span> <span class="n">A_</span> <span class="o">=</span> <span class="n">attn</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">X</span><span class="p">,</span><span class="n">X</span><span class="p">,</span> <span class="n">attn_mask</span><span class="o">=</span><span class="n">M</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=2779de31">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [13]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">Y</span><span class="p">,</span> <span class="n">A</span> <span class="o">=</span> <span class="n">self_attention</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">M</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> 
                      <span class="n">attn</span><span class="o">.</span><span class="n">in_proj_weight</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">T</span><span class="p">,</span>
                      <span class="n">attn</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=f28d3c52">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [14]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">A</span> <span class="o">-</span> <span class="n">A_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">Y</span> <span class="o">-</span> <span class="n">Y_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>1.8741974e-07
1.3277154e-06
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=e22a711c">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Minibatching-with-batch-matrix-multiply">Minibatching with batch matrix multiply<a class="anchor-link" href="#Minibatching-with-batch-matrix-multiply">¶</a></h2><p>Once we move from single example to minibatches, there is one additional subtlety that comes into play for self-attenion.  Recall that for <em>each</em> sample in the minibatch, we will have to compute a matrix product, e.g., the $KQ^T$ term.  If we need to process examples in a minibatch, we will need to perform this matrix multiplication correspondingly for each sample.  This is an operation known as a batch matrix multiply.</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=05a54cdb">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>It may seem as though nothing is new here.  True, for an MLP it was possible to perform the entire batch equation as a single matrix multiplication, but didn't we similarly need to batch matrix multiplications for convolutional networks (after the im2col function)?  Or for RNNs?</p>
<p>The answer is actually that no, previous to this we haven't needed the true batch matrix multiplication fuctionality.  The situations we had before involved the multiplication of a "batched" tensor by a <em>single</em> weight matrix.  I.e., in a ConvNet, we had something like
\begin{equation}
y = \mathrm{im2col}(x) W
\end{equation}
or in the batched setting
\begin{equation}
y^{(i)} = \mathrm{im2col}\left(x^{(i)}\right) W.
\end{equation}</p>
<p>But this operation can be accomplished with "normal" matrix multiplication by just stacking the multiple samples into the matrix on the left
\begin{equation}
\begin{bmatrix}
y^{(1)} \\ y^{(2)} \\ \vdots \\ y^{(N)}
\end{bmatrix}
= 
\begin{bmatrix}
\mathrm{im2col}\left(x^{(1)}\right) \\
\mathrm{im2col}\left(x^{(2)}\right) \\
\vdots \\
\mathrm{im2col}\left(x^{(N)}\right) \\
\end{bmatrix}
W.
\end{equation}
This operation is just a normal matrix multiplication, so can be implemented e.g., using your framework so far, where matrix multiplication always operates on 2 dimensional NDArrays.</p>
<p>Fortunately, numpy's <code>@</code> operator <em>already</em> performs batch matrix multiplication for the case of multiple arrays of (the same) dimension more than 2.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=f3a70fa6">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [40]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># illustration of batch matmul</span>
<span class="n">B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span>
<span class="n">C</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="p">(</span><span class="n">B</span><span class="nd">@C</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[40]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(10, 3, 5, 3)</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=c28c527a">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>Let's see how this works with our self attention layer.  In fact, because of the judicious usage of <code>axis=-1</code> and similar terms, our layer works <em>exactly</em> the same as it did before.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=fa24a2cf">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [53]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">N</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">M</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">triu</span><span class="p">(</span><span class="o">-</span><span class="nb">float</span><span class="p">(</span><span class="s2">"inf"</span><span class="p">)</span><span class="o">*</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">T</span><span class="p">,</span><span class="n">T</span><span class="p">),</span><span class="mi">1</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="n">T</span><span class="p">,</span><span class="n">d</span><span class="p">)</span>
<span class="n">Y_</span><span class="p">,</span> <span class="n">A_</span> <span class="o">=</span> <span class="n">attn</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">X</span><span class="p">,</span><span class="n">X</span><span class="p">,</span> <span class="n">attn_mask</span><span class="o">=</span><span class="n">M</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=546135ec">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [55]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">Y</span><span class="p">,</span> <span class="n">A</span> <span class="o">=</span> <span class="n">self_attention</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">M</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span>
                      <span class="n">attn</span><span class="o">.</span><span class="n">in_proj_weight</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> 
                      <span class="n">attn</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=2d96c92e">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [56]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">A</span> <span class="o">-</span> <span class="n">A_</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">Y</span> <span class="o">-</span> <span class="n">Y_</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>5.5253105e-07
3.97839e-06
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=756fc65a">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Multihead-attention">Multihead attention<a class="anchor-link" href="#Multihead-attention">¶</a></h2><p>Practical implementations of attention use what is called <em>multihead</em> attention, which simply means that we run the self-attention mechansism of different subsets of the $K$, $Q$, $V$ terms, then concatenate them together.  Formally, we'll partition these terms as
\begin{equation}
K = \begin{bmatrix} K_1 &amp; K_2 &amp; \cdots &amp; K_{\mathrm{heads}} \end{bmatrix}
\end{equation}
(and similarly for $Q$ and $V$.</p>
<p>Then will form the self attention outputs
\begin{equation}
Y_i = \mathrm{softmax}\left(\frac{K_iQ_i^T}{\sqrt{d/\mathrm{heads}}}\right)V_i
\end{equation}
and then form the final ouput
\begin{equation}
Y = \begin{bmatrix} Y_1 &amp; Y_2 &amp; \cdots &amp; Y_{\mathrm{heads}} \end{bmatrix} W_o.
\end{equation}</p>
<p>The advantage of multi-head attention is that applying a single self-attention layer to a "high dimensional" hidden state (i.e., where $d$ is large) seems to waste a lot of the information contained in the hidden layers.  Recall, for intance, that the terms in the self attention matrix would be proportation to $k_t^T q_s$.  If $k_t$ and $q_s$ are high dimensional, then a lot of "internal structure" could be lost to result in ultimately just one weighting term.  By breaking this up and computing multiple differen attention matrices, each of which weights different dimensions of the $V$ term, we avoid this problem, and practically lead to better performance.  Note however that the "right" tradeoff between the number of heads and $d$ is still rather heuristic in nature.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=1acf3ad0">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [57]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">multihead_attention</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">heads</span><span class="p">,</span> <span class="n">W_KQV</span><span class="p">,</span> <span class="n">W_out</span><span class="p">):</span>
    <span class="n">N</span><span class="p">,</span><span class="n">T</span><span class="p">,</span><span class="n">d</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">K</span><span class="p">,</span><span class="n">Q</span><span class="p">,</span><span class="n">V</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="nd">@W_KQV</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">K</span><span class="p">,</span><span class="n">Q</span><span class="p">,</span><span class="n">V</span> <span class="o">=</span> <span class="p">[</span><span class="n">a</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="n">T</span><span class="p">,</span><span class="n">heads</span><span class="p">,</span><span class="n">d</span><span class="o">//</span><span class="n">heads</span><span class="p">)</span><span class="o">.</span><span class="n">swapaxes</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="p">(</span><span class="n">K</span><span class="p">,</span><span class="n">Q</span><span class="p">,</span><span class="n">V</span><span class="p">)]</span>
    
    <span class="n">attn</span> <span class="o">=</span> <span class="n">softmax</span><span class="p">(</span><span class="n">K</span><span class="nd">@Q</span><span class="o">.</span><span class="n">swapaxes</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">d</span><span class="o">//</span><span class="n">heads</span><span class="p">)</span> <span class="o">+</span> <span class="n">mask</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">attn</span><span class="nd">@V</span><span class="p">)</span><span class="o">.</span><span class="n">swapaxes</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="n">T</span><span class="p">,</span><span class="n">d</span><span class="p">)</span> <span class="o">@</span> <span class="n">W_out</span><span class="p">,</span> <span class="n">attn</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=7c001698">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [58]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">heads</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">attn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MultiheadAttention</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">heads</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">Y_</span><span class="p">,</span> <span class="n">A_</span> <span class="o">=</span> <span class="n">attn</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">X</span><span class="p">,</span><span class="n">X</span><span class="p">,</span> <span class="n">attn_mask</span><span class="o">=</span><span class="n">M</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=846e82b8">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [59]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">Y</span><span class="p">,</span> <span class="n">A</span> <span class="o">=</span> <span class="n">multihead_attention</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">M</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="mi">4</span><span class="p">,</span>
                           <span class="n">attn</span><span class="o">.</span><span class="n">in_proj_weight</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> 
                           <span class="n">attn</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=a8d14502">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [62]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">A_</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[62]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>torch.Size([10, 100, 100])</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=127ae789">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [61]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">A</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[61]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>(10, 4, 100, 100)</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=e1fe95a7">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [60]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">Y</span> <span class="o">-</span> <span class="n">Y_</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="n">A_</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>4.0823516e-06
4.2045417e-07
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=63fe7db8">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Transformer-Block">Transformer Block<a class="anchor-link" href="#Transformer-Block">¶</a></h2><p>Let's finally put all this together into a full transformer block.  Transformers simply amount to a self-attention block, with a residual layers and layer norm operation, followed by a two-layer feedforward network, with another residual layer and layer norm.  We can implement this in a few lines of code.  Note that in "real" implementations, the layer norm terms, etc, would actually have trainable scale/bias terms that add a bit more expressivity to the model.  This version we show will only be the same, for instance, at initialization.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=c8daabf2">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [63]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">layer_norm</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">eps</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">Z</span> <span class="o">-</span> <span class="n">Z</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">Z</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">+</span> <span class="n">eps</span><span class="p">)</span>
    
<span class="k">def</span> <span class="nf">relu</span><span class="p">(</span><span class="n">Z</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">transformer</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">heads</span><span class="p">,</span> <span class="n">W_KQV</span><span class="p">,</span> <span class="n">W_out</span><span class="p">,</span> <span class="n">W_ff1</span><span class="p">,</span> <span class="n">W_ff2</span><span class="p">,</span> <span class="n">eps</span><span class="p">):</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="n">layer_norm</span><span class="p">(</span><span class="n">multihead_attention</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">heads</span><span class="p">,</span> <span class="n">W_KQV</span><span class="p">,</span> <span class="n">W_out</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">X</span><span class="p">,</span> <span class="n">eps</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">layer_norm</span><span class="p">(</span><span class="n">Z</span> <span class="o">+</span> <span class="n">relu</span><span class="p">(</span><span class="n">Z</span><span class="nd">@W_ff1</span><span class="p">)</span><span class="nd">@W_ff2</span><span class="p">,</span> <span class="n">eps</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=9b3c6bd5">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [65]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">trans</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">TransformerEncoderLayer</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">heads</span><span class="p">,</span> <span class="n">dim_feedforward</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">trans</span><span class="o">.</span><span class="n">linear1</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
<span class="n">trans</span><span class="o">.</span><span class="n">linear2</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">zero_</span><span class="p">();</span>
<span class="n">Y_</span> <span class="o">=</span> <span class="n">trans</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">M</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=a47cc0dc">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [66]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">Y</span> <span class="o">=</span> <span class="n">transformer</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">M</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">heads</span><span class="p">,</span>
                <span class="n">trans</span><span class="o">.</span><span class="n">self_attn</span><span class="o">.</span><span class="n">in_proj_weight</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> 
                <span class="n">trans</span><span class="o">.</span><span class="n">self_attn</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">T</span><span class="p">,</span>
                <span class="n">trans</span><span class="o">.</span><span class="n">linear1</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">T</span><span class="p">,</span>
                <span class="n">trans</span><span class="o">.</span><span class="n">linear2</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">T</span><span class="p">,</span>
                <span class="n">trans</span><span class="o">.</span><span class="n">norm1</span><span class="o">.</span><span class="n">eps</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=676dfc0f">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [67]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">Y</span> <span class="o">-</span> <span class="n">Y_</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>2.7750326e-05
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=6e94da64">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="The-question-for-%22efficient-Transformers%22">The question for "efficient Transformers"<a class="anchor-link" href="#The-question-for-%22efficient-Transformers%22">¶</a></h2><p>Since the Transformer was first proposed, there have been endless attempts made to make different "efficient" versions of the operation.  The key drawback of transformers, we have seen, is that they require forming a the $T \times T$ attention matrix and multiplying by $V$ (an $O(T^2d)$ operation)
\begin{equation}
\mathrm{softmax}\left(\frac{KQ^T}{\sqrt{d}}\right)V
\end{equation}
If $T$ is much larger than $d$ (e.g., the sequence is very long, then this operation is quite costly).</p>
<p>There are essentially two approaches to making the approach more efficient: by attempting the represent the attention matrix
\begin{equation}
A = \mathrm{softmax}\left(\frac{KQ^T}{\sqrt{d}}\right)
\end{equation}
either using <em>sparsity</em> or using <em>low rank</em> structure.  In general, of course, this matrix neither sparse nor low rank.  But we could simply dicate, for example, that we will only compute some subset of the attention weights, thereby decreasing the number of inner products we need to perform (this is the basis of the so-called "Sparse Attention" layer: similar approaches have been proposed a number of times, but <a href="https://arxiv.org/abs/1904.10509">this</a> is one such example).  Alternatively, one could try to infer some kind of hard sparsity by e.g., triangle inequalities or other similar instances (because, remember, we are computing what amounts to a similarly metric between the $x$ terms at different times).</p>
<p>Alternatively, we could try to represent $A$ in <em>low rank</em> form instead.  To see why this could be appealing, consider the case where we don't have a softmax operation at all, but instead used the "attention" layer
\begin{equation}
\left(\frac{KQ^T}{\sqrt{d}}\right)V
\end{equation}
In this case, if $T \gg d$, we could instead perform our multiplication in the order $K(Q^T V)$, which would only have complexity $O(Td^2)$, potentially much smaller.  And some papers infact advocate for this very thing, or alternatively try to find a low-rank representation of the actual attention weights, to similar effects.</p>
<p>The thing to keep in mind with all these "efficient" alternatives (and if you have been reading the literation surrounding Transformers, you have likely seen a <em>ton</em> of these), is whether they are actually more efficient, for an equivalent level of performance, once real execution speed in taken into account.  My best understanding of the current situation is that 1) explicit sparse self attention is indeed sometimes useful for models that want very long history, but that 2) most of the "efficient" transformer mechanisms that use low rank structure or inferred sparsity structure don't improve much in practice over traditional attention.</p>
</div>
</div>
</div>
</div>
</main>
</body>
</html>]]></content><author><name>Zhu Tianda</name></author><category term="coding" /><category term="AI" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">GPR</title><link href="http://0.0.0.0:8855/coding/learning/2023/06/02/GPR.html" rel="alternate" type="text/html" title="GPR" /><published>2023-06-02T00:00:00+08:00</published><updated>2023-06-02T00:00:00+08:00</updated><id>http://0.0.0.0:8855/coding/learning/2023/06/02/GPR</id><content type="html" xml:base="http://0.0.0.0:8855/coding/learning/2023/06/02/GPR.html"><![CDATA[<!DOCTYPE html>

<html lang="en">
<head><meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>GPR</title><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<style type="text/css">
    pre { line-height: 125%; }
td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
.highlight .hll { background-color: var(--jp-cell-editor-active-background) }
.highlight { background: var(--jp-cell-editor-background); color: var(--jp-mirror-editor-variable-color) }
.highlight .c { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment */
.highlight .err { color: var(--jp-mirror-editor-error-color) } /* Error */
.highlight .k { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword */
.highlight .o { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator */
.highlight .p { color: var(--jp-mirror-editor-punctuation-color) } /* Punctuation */
.highlight .ch { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Multiline */
.highlight .cp { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Preproc */
.highlight .cpf { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Single */
.highlight .cs { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Special */
.highlight .kc { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Pseudo */
.highlight .kr { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Type */
.highlight .m { color: var(--jp-mirror-editor-number-color) } /* Literal.Number */
.highlight .s { color: var(--jp-mirror-editor-string-color) } /* Literal.String */
.highlight .ow { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator.Word */
.highlight .pm { color: var(--jp-mirror-editor-punctuation-color) } /* Punctuation.Marker */
.highlight .w { color: var(--jp-mirror-editor-variable-color) } /* Text.Whitespace */
.highlight .mb { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Bin */
.highlight .mf { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Float */
.highlight .mh { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Hex */
.highlight .mi { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer */
.highlight .mo { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Oct */
.highlight .sa { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Affix */
.highlight .sb { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Backtick */
.highlight .sc { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Char */
.highlight .dl { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Delimiter */
.highlight .sd { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Doc */
.highlight .s2 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Double */
.highlight .se { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Escape */
.highlight .sh { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Heredoc */
.highlight .si { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Interpol */
.highlight .sx { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Other */
.highlight .sr { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Regex */
.highlight .s1 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Single */
.highlight .ss { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Symbol */
.highlight .il { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer.Long */
  </style>
<style type="text/css">
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*
 * Mozilla scrollbar styling
 */

/* use standard opaque scrollbars for most nodes */
[data-jp-theme-scrollbars='true'] {
  scrollbar-color: rgb(var(--jp-scrollbar-thumb-color))
    var(--jp-scrollbar-background-color);
}

/* for code nodes, use a transparent style of scrollbar. These selectors
 * will match lower in the tree, and so will override the above */
[data-jp-theme-scrollbars='true'] .CodeMirror-hscrollbar,
[data-jp-theme-scrollbars='true'] .CodeMirror-vscrollbar {
  scrollbar-color: rgba(var(--jp-scrollbar-thumb-color), 0.5) transparent;
}

/* tiny scrollbar */

.jp-scrollbar-tiny {
  scrollbar-color: rgba(var(--jp-scrollbar-thumb-color), 0.5) transparent;
  scrollbar-width: thin;
}

/* tiny scrollbar */

.jp-scrollbar-tiny::-webkit-scrollbar,
.jp-scrollbar-tiny::-webkit-scrollbar-corner {
  background-color: transparent;
  height: 4px;
  width: 4px;
}

.jp-scrollbar-tiny::-webkit-scrollbar-thumb {
  background: rgba(var(--jp-scrollbar-thumb-color), 0.5);
}

.jp-scrollbar-tiny::-webkit-scrollbar-track:horizontal {
  border-left: 0 solid transparent;
  border-right: 0 solid transparent;
}

.jp-scrollbar-tiny::-webkit-scrollbar-track:vertical {
  border-top: 0 solid transparent;
  border-bottom: 0 solid transparent;
}

/*
 * Lumino
 */

.lm-ScrollBar[data-orientation='horizontal'] {
  min-height: 16px;
  max-height: 16px;
  min-width: 45px;
  border-top: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='vertical'] {
  min-width: 16px;
  max-width: 16px;
  min-height: 45px;
  border-left: 1px solid #a0a0a0;
}

.lm-ScrollBar-button {
  background-color: #f0f0f0;
  background-position: center center;
  min-height: 15px;
  max-height: 15px;
  min-width: 15px;
  max-width: 15px;
}

.lm-ScrollBar-button:hover {
  background-color: #dadada;
}

.lm-ScrollBar-button.lm-mod-active {
  background-color: #cdcdcd;
}

.lm-ScrollBar-track {
  background: #f0f0f0;
}

.lm-ScrollBar-thumb {
  background: #cdcdcd;
}

.lm-ScrollBar-thumb:hover {
  background: #bababa;
}

.lm-ScrollBar-thumb.lm-mod-active {
  background: #a0a0a0;
}

.lm-ScrollBar[data-orientation='horizontal'] .lm-ScrollBar-thumb {
  height: 100%;
  min-width: 15px;
  border-left: 1px solid #a0a0a0;
  border-right: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='vertical'] .lm-ScrollBar-thumb {
  width: 100%;
  min-height: 15px;
  border-top: 1px solid #a0a0a0;
  border-bottom: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='horizontal']
  .lm-ScrollBar-button[data-action='decrement'] {
  background-image: var(--jp-icon-caret-left);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='horizontal']
  .lm-ScrollBar-button[data-action='increment'] {
  background-image: var(--jp-icon-caret-right);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='vertical']
  .lm-ScrollBar-button[data-action='decrement'] {
  background-image: var(--jp-icon-caret-up);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='vertical']
  .lm-ScrollBar-button[data-action='increment'] {
  background-image: var(--jp-icon-caret-down);
  background-size: 17px;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-Widget {
  box-sizing: border-box;
  position: relative;
  overflow: hidden;
}

.lm-Widget.lm-mod-hidden {
  display: none !important;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.lm-AccordionPanel[data-orientation='horizontal'] > .lm-AccordionPanel-title {
  /* Title is rotated for horizontal accordion panel using CSS */
  display: block;
  transform-origin: top left;
  transform: rotate(-90deg) translate(-100%);
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-CommandPalette {
  display: flex;
  flex-direction: column;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-CommandPalette-search {
  flex: 0 0 auto;
}

.lm-CommandPalette-content {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  min-height: 0;
  overflow: auto;
  list-style-type: none;
}

.lm-CommandPalette-header {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.lm-CommandPalette-item {
  display: flex;
  flex-direction: row;
}

.lm-CommandPalette-itemIcon {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemContent {
  flex: 1 1 auto;
  overflow: hidden;
}

.lm-CommandPalette-itemShortcut {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemLabel {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.lm-close-icon {
  border: 1px solid transparent;
  background-color: transparent;
  position: absolute;
  z-index: 1;
  right: 3%;
  top: 0;
  bottom: 0;
  margin: auto;
  padding: 7px 0;
  display: none;
  vertical-align: middle;
  outline: 0;
  cursor: pointer;
}
.lm-close-icon:after {
  content: 'X';
  display: block;
  width: 15px;
  height: 15px;
  text-align: center;
  color: #000;
  font-weight: normal;
  font-size: 12px;
  cursor: pointer;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-DockPanel {
  z-index: 0;
}

.lm-DockPanel-widget {
  z-index: 0;
}

.lm-DockPanel-tabBar {
  z-index: 1;
}

.lm-DockPanel-handle {
  z-index: 2;
}

.lm-DockPanel-handle.lm-mod-hidden {
  display: none !important;
}

.lm-DockPanel-handle:after {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  content: '';
}

.lm-DockPanel-handle[data-orientation='horizontal'] {
  cursor: ew-resize;
}

.lm-DockPanel-handle[data-orientation='vertical'] {
  cursor: ns-resize;
}

.lm-DockPanel-handle[data-orientation='horizontal']:after {
  left: 50%;
  min-width: 8px;
  transform: translateX(-50%);
}

.lm-DockPanel-handle[data-orientation='vertical']:after {
  top: 50%;
  min-height: 8px;
  transform: translateY(-50%);
}

.lm-DockPanel-overlay {
  z-index: 3;
  box-sizing: border-box;
  pointer-events: none;
}

.lm-DockPanel-overlay.lm-mod-hidden {
  display: none !important;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-Menu {
  z-index: 10000;
  position: absolute;
  white-space: nowrap;
  overflow-x: hidden;
  overflow-y: auto;
  outline: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-Menu-content {
  margin: 0;
  padding: 0;
  display: table;
  list-style-type: none;
}

.lm-Menu-item {
  display: table-row;
}

.lm-Menu-item.lm-mod-hidden,
.lm-Menu-item.lm-mod-collapsed {
  display: none !important;
}

.lm-Menu-itemIcon,
.lm-Menu-itemSubmenuIcon {
  display: table-cell;
  text-align: center;
}

.lm-Menu-itemLabel {
  display: table-cell;
  text-align: left;
}

.lm-Menu-itemShortcut {
  display: table-cell;
  text-align: right;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-MenuBar {
  outline: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-MenuBar-content {
  margin: 0;
  padding: 0;
  display: flex;
  flex-direction: row;
  list-style-type: none;
}

.lm-MenuBar-item {
  box-sizing: border-box;
}

.lm-MenuBar-itemIcon,
.lm-MenuBar-itemLabel {
  display: inline-block;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-ScrollBar {
  display: flex;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-ScrollBar[data-orientation='horizontal'] {
  flex-direction: row;
}

.lm-ScrollBar[data-orientation='vertical'] {
  flex-direction: column;
}

.lm-ScrollBar-button {
  box-sizing: border-box;
  flex: 0 0 auto;
}

.lm-ScrollBar-track {
  box-sizing: border-box;
  position: relative;
  overflow: hidden;
  flex: 1 1 auto;
}

.lm-ScrollBar-thumb {
  box-sizing: border-box;
  position: absolute;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-SplitPanel-child {
  z-index: 0;
}

.lm-SplitPanel-handle {
  z-index: 1;
}

.lm-SplitPanel-handle.lm-mod-hidden {
  display: none !important;
}

.lm-SplitPanel-handle:after {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  content: '';
}

.lm-SplitPanel[data-orientation='horizontal'] > .lm-SplitPanel-handle {
  cursor: ew-resize;
}

.lm-SplitPanel[data-orientation='vertical'] > .lm-SplitPanel-handle {
  cursor: ns-resize;
}

.lm-SplitPanel[data-orientation='horizontal'] > .lm-SplitPanel-handle:after {
  left: 50%;
  min-width: 8px;
  transform: translateX(-50%);
}

.lm-SplitPanel[data-orientation='vertical'] > .lm-SplitPanel-handle:after {
  top: 50%;
  min-height: 8px;
  transform: translateY(-50%);
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-TabBar {
  display: flex;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-TabBar[data-orientation='horizontal'] {
  flex-direction: row;
  align-items: flex-end;
}

.lm-TabBar[data-orientation='vertical'] {
  flex-direction: column;
  align-items: flex-end;
}

.lm-TabBar-content {
  margin: 0;
  padding: 0;
  display: flex;
  flex: 1 1 auto;
  list-style-type: none;
}

.lm-TabBar[data-orientation='horizontal'] > .lm-TabBar-content {
  flex-direction: row;
}

.lm-TabBar[data-orientation='vertical'] > .lm-TabBar-content {
  flex-direction: column;
}

.lm-TabBar-tab {
  display: flex;
  flex-direction: row;
  box-sizing: border-box;
  overflow: hidden;
  touch-action: none; /* Disable native Drag/Drop */
}

.lm-TabBar-tabIcon,
.lm-TabBar-tabCloseIcon {
  flex: 0 0 auto;
}

.lm-TabBar-tabLabel {
  flex: 1 1 auto;
  overflow: hidden;
  white-space: nowrap;
}

.lm-TabBar-tabInput {
  user-select: all;
  width: 100%;
  box-sizing: border-box;
}

.lm-TabBar-tab.lm-mod-hidden {
  display: none !important;
}

.lm-TabBar-addButton.lm-mod-hidden {
  display: none !important;
}

.lm-TabBar.lm-mod-dragging .lm-TabBar-tab {
  position: relative;
}

.lm-TabBar.lm-mod-dragging[data-orientation='horizontal'] .lm-TabBar-tab {
  left: 0;
  transition: left 150ms ease;
}

.lm-TabBar.lm-mod-dragging[data-orientation='vertical'] .lm-TabBar-tab {
  top: 0;
  transition: top 150ms ease;
}

.lm-TabBar.lm-mod-dragging .lm-TabBar-tab.lm-mod-dragging {
  transition: none;
}

.lm-TabBar-tabLabel .lm-TabBar-tabInput {
  user-select: all;
  width: 100%;
  box-sizing: border-box;
  background: inherit;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-TabPanel-tabBar {
  z-index: 1;
}

.lm-TabPanel-stackedPanel {
  z-index: 0;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Collapse {
  display: flex;
  flex-direction: column;
  align-items: stretch;
}

.jp-Collapse-header {
  padding: 1px 12px;
  background-color: var(--jp-layout-color1);
  border-bottom: solid var(--jp-border-width) var(--jp-border-color2);
  color: var(--jp-ui-font-color1);
  cursor: pointer;
  display: flex;
  align-items: center;
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  text-transform: uppercase;
  user-select: none;
}

.jp-Collapser-icon {
  height: 16px;
}

.jp-Collapse-header-collapsed .jp-Collapser-icon {
  transform: rotate(-90deg);
  margin: auto 0;
}

.jp-Collapser-title {
  line-height: 25px;
}

.jp-Collapse-contents {
  padding: 0 12px;
  background-color: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  overflow: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensureUiComponents() in @jupyterlab/buildutils */

/**
 * (DEPRECATED) Support for consuming icons as CSS background images
 */

/* Icons urls */

:root {
  --jp-icon-add-above: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGcgY2xpcC1wYXRoPSJ1cmwoI2NsaXAwXzEzN18xOTQ5MikiPgo8cGF0aCBjbGFzcz0ianAtaWNvbjMiIGQ9Ik00Ljc1IDQuOTMwNjZINi42MjVWNi44MDU2NkM2LjYyNSA3LjAxMTkxIDYuNzkzNzUgNy4xODA2NiA3IDcuMTgwNjZDNy4yMDYyNSA3LjE4MDY2IDcuMzc1IDcuMDExOTEgNy4zNzUgNi44MDU2NlY0LjkzMDY2SDkuMjVDOS40NTYyNSA0LjkzMDY2IDkuNjI1IDQuNzYxOTEgOS42MjUgNC41NTU2NkM5LjYyNSA0LjM0OTQxIDkuNDU2MjUgNC4xODA2NiA5LjI1IDQuMTgwNjZINy4zNzVWMi4zMDU2NkM3LjM3NSAyLjA5OTQxIDcuMjA2MjUgMS45MzA2NiA3IDEuOTMwNjZDNi43OTM3NSAxLjkzMDY2IDYuNjI1IDIuMDk5NDEgNi42MjUgMi4zMDU2NlY0LjE4MDY2SDQuNzVDNC41NDM3NSA0LjE4MDY2IDQuMzc1IDQuMzQ5NDEgNC4zNzUgNC41NTU2NkM0LjM3NSA0Ljc2MTkxIDQuNTQzNzUgNC45MzA2NiA0Ljc1IDQuOTMwNjZaIiBmaWxsPSIjNjE2MTYxIiBzdHJva2U9IiM2MTYxNjEiIHN0cm9rZS13aWR0aD0iMC43Ii8+CjwvZz4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiIGNsaXAtcnVsZT0iZXZlbm9kZCIgZD0iTTExLjUgOS41VjExLjVMMi41IDExLjVWOS41TDExLjUgOS41Wk0xMiA4QzEyLjU1MjMgOCAxMyA4LjQ0NzcyIDEzIDlWMTJDMTMgMTIuNTUyMyAxMi41NTIzIDEzIDEyIDEzTDIgMTNDMS40NDc3MiAxMyAxIDEyLjU1MjMgMSAxMlY5QzEgOC40NDc3MiAxLjQ0NzcxIDggMiA4TDEyIDhaIiBmaWxsPSIjNjE2MTYxIi8+CjxkZWZzPgo8Y2xpcFBhdGggaWQ9ImNsaXAwXzEzN18xOTQ5MiI+CjxyZWN0IGNsYXNzPSJqcC1pY29uMyIgd2lkdGg9IjYiIGhlaWdodD0iNiIgZmlsbD0id2hpdGUiIHRyYW5zZm9ybT0ibWF0cml4KC0xIDAgMCAxIDEwIDEuNTU1NjYpIi8+CjwvY2xpcFBhdGg+CjwvZGVmcz4KPC9zdmc+Cg==);
  --jp-icon-add-below: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGcgY2xpcC1wYXRoPSJ1cmwoI2NsaXAwXzEzN18xOTQ5OCkiPgo8cGF0aCBjbGFzcz0ianAtaWNvbjMiIGQ9Ik05LjI1IDEwLjA2OTNMNy4zNzUgMTAuMDY5M0w3LjM3NSA4LjE5NDM0QzcuMzc1IDcuOTg4MDkgNy4yMDYyNSA3LjgxOTM0IDcgNy44MTkzNEM2Ljc5Mzc1IDcuODE5MzQgNi42MjUgNy45ODgwOSA2LjYyNSA4LjE5NDM0TDYuNjI1IDEwLjA2OTNMNC43NSAxMC4wNjkzQzQuNTQzNzUgMTAuMDY5MyA0LjM3NSAxMC4yMzgxIDQuMzc1IDEwLjQ0NDNDNC4zNzUgMTAuNjUwNiA0LjU0Mzc1IDEwLjgxOTMgNC43NSAxMC44MTkzTDYuNjI1IDEwLjgxOTNMNi42MjUgMTIuNjk0M0M2LjYyNSAxMi45MDA2IDYuNzkzNzUgMTMuMDY5MyA3IDEzLjA2OTNDNy4yMDYyNSAxMy4wNjkzIDcuMzc1IDEyLjkwMDYgNy4zNzUgMTIuNjk0M0w3LjM3NSAxMC44MTkzTDkuMjUgMTAuODE5M0M5LjQ1NjI1IDEwLjgxOTMgOS42MjUgMTAuNjUwNiA5LjYyNSAxMC40NDQzQzkuNjI1IDEwLjIzODEgOS40NTYyNSAxMC4wNjkzIDkuMjUgMTAuMDY5M1oiIGZpbGw9IiM2MTYxNjEiIHN0cm9rZT0iIzYxNjE2MSIgc3Ryb2tlLXdpZHRoPSIwLjciLz4KPC9nPgo8cGF0aCBjbGFzcz0ianAtaWNvbjMiIGZpbGwtcnVsZT0iZXZlbm9kZCIgY2xpcC1ydWxlPSJldmVub2RkIiBkPSJNMi41IDUuNUwyLjUgMy41TDExLjUgMy41TDExLjUgNS41TDIuNSA1LjVaTTIgN0MxLjQ0NzcyIDcgMSA2LjU1MjI4IDEgNkwxIDNDMSAyLjQ0NzcyIDEuNDQ3NzIgMiAyIDJMMTIgMkMxMi41NTIzIDIgMTMgMi40NDc3MiAxMyAzTDEzIDZDMTMgNi41NTIyOSAxMi41NTIzIDcgMTIgN0wyIDdaIiBmaWxsPSIjNjE2MTYxIi8+CjxkZWZzPgo8Y2xpcFBhdGggaWQ9ImNsaXAwXzEzN18xOTQ5OCI+CjxyZWN0IGNsYXNzPSJqcC1pY29uMyIgd2lkdGg9IjYiIGhlaWdodD0iNiIgZmlsbD0id2hpdGUiIHRyYW5zZm9ybT0ibWF0cml4KDEgMS43NDg0NmUtMDcgMS43NDg0NmUtMDcgLTEgNCAxMy40NDQzKSIvPgo8L2NsaXBQYXRoPgo8L2RlZnM+Cjwvc3ZnPgo=);
  --jp-icon-add: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE5IDEzaC02djZoLTJ2LTZINXYtMmg2VjVoMnY2aDZ2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-bell: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE2IDE2IiB2ZXJzaW9uPSIxLjEiPgogICA8cGF0aCBjbGFzcz0ianAtaWNvbjIganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMzMzMzMzIgogICAgICBkPSJtOCAwLjI5Yy0xLjQgMC0yLjcgMC43My0zLjYgMS44LTEuMiAxLjUtMS40IDMuNC0xLjUgNS4yLTAuMTggMi4yLTAuNDQgNC0yLjMgNS4zbDAuMjggMS4zaDVjMC4wMjYgMC42NiAwLjMyIDEuMSAwLjcxIDEuNSAwLjg0IDAuNjEgMiAwLjYxIDIuOCAwIDAuNTItMC40IDAuNi0xIDAuNzEtMS41aDVsMC4yOC0xLjNjLTEuOS0wLjk3LTIuMi0zLjMtMi4zLTUuMy0wLjEzLTEuOC0wLjI2LTMuNy0xLjUtNS4yLTAuODUtMS0yLjItMS44LTMuNi0xLjh6bTAgMS40YzAuODggMCAxLjkgMC41NSAyLjUgMS4zIDAuODggMS4xIDEuMSAyLjcgMS4yIDQuNCAwLjEzIDEuNyAwLjIzIDMuNiAxLjMgNS4yaC0xMGMxLjEtMS42IDEuMi0zLjQgMS4zLTUuMiAwLjEzLTEuNyAwLjMtMy4zIDEuMi00LjQgMC41OS0wLjcyIDEuNi0xLjMgMi41LTEuM3ptLTAuNzQgMTJoMS41Yy0wLjAwMTUgMC4yOCAwLjAxNSAwLjc5LTAuNzQgMC43OS0wLjczIDAuMDAxNi0wLjcyLTAuNTMtMC43NC0wLjc5eiIgLz4KPC9zdmc+Cg==);
  --jp-icon-bug-dot: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjQiIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiPgogICAgICAgIDxwYXRoIGZpbGwtcnVsZT0iZXZlbm9kZCIgY2xpcC1ydWxlPSJldmVub2RkIiBkPSJNMTcuMTkgOEgyMFYxMEgxNy45MUMxNy45NiAxMC4zMyAxOCAxMC42NiAxOCAxMVYxMkgyMFYxNEgxOC41SDE4VjE0LjAyNzVDMTUuNzUgMTQuMjc2MiAxNCAxNi4xODM3IDE0IDE4LjVDMTQgMTkuMjA4IDE0LjE2MzUgMTkuODc3OSAxNC40NTQ5IDIwLjQ3MzlDMTMuNzA2MyAyMC44MTE3IDEyLjg3NTcgMjEgMTIgMjFDOS43OCAyMSA3Ljg1IDE5Ljc5IDYuODEgMThINFYxNkg2LjA5QzYuMDQgMTUuNjcgNiAxNS4zNCA2IDE1VjE0SDRWMTJINlYxMUM2IDEwLjY2IDYuMDQgMTAuMzMgNi4wOSAxMEg0VjhINi44MUM3LjI2IDcuMjIgNy44OCA2LjU1IDguNjIgNi4wNEw3IDQuNDFMOC40MSAzTDEwLjU5IDUuMTdDMTEuMDQgNS4wNiAxMS41MSA1IDEyIDVDMTIuNDkgNSAxMi45NiA1LjA2IDEzLjQyIDUuMTdMMTUuNTkgM0wxNyA0LjQxTDE1LjM3IDYuMDRDMTYuMTIgNi41NSAxNi43NCA3LjIyIDE3LjE5IDhaTTEwIDE2SDE0VjE0SDEwVjE2Wk0xMCAxMkgxNFYxMEgxMFYxMloiIGZpbGw9IiM2MTYxNjEiLz4KICAgICAgICA8cGF0aCBkPSJNMjIgMTguNUMyMiAyMC40MzMgMjAuNDMzIDIyIDE4LjUgMjJDMTYuNTY3IDIyIDE1IDIwLjQzMyAxNSAxOC41QzE1IDE2LjU2NyAxNi41NjcgMTUgMTguNSAxNUMyMC40MzMgMTUgMjIgMTYuNTY3IDIyIDE4LjVaIiBmaWxsPSIjNjE2MTYxIi8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-bug: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0yMCA4aC0yLjgxYy0uNDUtLjc4LTEuMDctMS40NS0xLjgyLTEuOTZMMTcgNC40MSAxNS41OSAzbC0yLjE3IDIuMTdDMTIuOTYgNS4wNiAxMi40OSA1IDEyIDVjLS40OSAwLS45Ni4wNi0xLjQxLjE3TDguNDEgMyA3IDQuNDFsMS42MiAxLjYzQzcuODggNi41NSA3LjI2IDcuMjIgNi44MSA4SDR2MmgyLjA5Yy0uMDUuMzMtLjA5LjY2LS4wOSAxdjFINHYyaDJ2MWMwIC4zNC4wNC42Ny4wOSAxSDR2MmgyLjgxYzEuMDQgMS43OSAyLjk3IDMgNS4xOSAzczQuMTUtMS4yMSA1LjE5LTNIMjB2LTJoLTIuMDljLjA1LS4zMy4wOS0uNjYuMDktMXYtMWgydi0yaC0ydi0xYzAtLjM0LS4wNC0uNjctLjA5LTFIMjBWOHptLTYgOGgtNHYtMmg0djJ6bTAtNGgtNHYtMmg0djJ6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-build: url(data:image/svg+xml;base64,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);
  --jp-icon-caret-down-empty-thin: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwb2x5Z29uIGNsYXNzPSJzdDEiIHBvaW50cz0iOS45LDEzLjYgMy42LDcuNCA0LjQsNi42IDkuOSwxMi4yIDE1LjQsNi43IDE2LjEsNy40ICIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-caret-down-empty: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik01LjIsNS45TDksOS43bDMuOC0zLjhsMS4yLDEuMmwtNC45LDVsLTQuOS01TDUuMiw1Ljl6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-caret-down: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik01LjIsNy41TDksMTEuMmwzLjgtMy44SDUuMnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-caret-left: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwYXRoIGQ9Ik0xMC44LDEyLjhMNy4xLDlsMy44LTMuOGwwLDcuNkgxMC44eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-caret-right: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik03LjIsNS4yTDEwLjksOWwtMy44LDMuOFY1LjJINy4yeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-caret-up-empty-thin: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwb2x5Z29uIGNsYXNzPSJzdDEiIHBvaW50cz0iMTUuNCwxMy4zIDkuOSw3LjcgNC40LDEzLjIgMy42LDEyLjUgOS45LDYuMyAxNi4xLDEyLjYgIi8+Cgk8L2c+Cjwvc3ZnPgo=);
  --jp-icon-caret-up: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwYXRoIGQ9Ik01LjIsMTAuNUw5LDYuOGwzLjgsMy44SDUuMnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-case-sensitive: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KICA8ZyBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiM0MTQxNDEiPgogICAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiAgPC9nPgogIDxnIGNsYXNzPSJqcC1pY29uLWFjY2VudDIiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTcuNiw4aDAuOWwzLjUsOGgtMS4xTDEwLDE0SDZsLTAuOSwySDRMNy42LDh6IE04LDkuMUw2LjQsMTNoMy4yTDgsOS4xeiIvPgogICAgPHBhdGggZD0iTTE2LjYsOS44Yy0wLjIsMC4xLTAuNCwwLjEtMC43LDAuMWMtMC4yLDAtMC40LTAuMS0wLjYtMC4yYy0wLjEtMC4xLTAuMi0wLjQtMC4yLTAuNyBjLTAuMywwLjMtMC42LDAuNS0wLjksMC43Yy0wLjMsMC4xLTAuNywwLjItMS4xLDAuMmMtMC4zLDAtMC41LDAtMC43LTAuMWMtMC4yLTAuMS0wLjQtMC4yLTAuNi0wLjNjLTAuMi0wLjEtMC4zLTAuMy0wLjQtMC41IGMtMC4xLTAuMi0wLjEtMC40LTAuMS0wLjdjMC0wLjMsMC4xLTAuNiwwLjItMC44YzAuMS0wLjIsMC4zLTAuNCwwLjQtMC41QzEyLDcsMTIuMiw2LjksMTIuNSw2LjhjMC4yLTAuMSwwLjUtMC4xLDAuNy0wLjIgYzAuMy0wLjEsMC41LTAuMSwwLjctMC4xYzAuMiwwLDAuNC0wLjEsMC42LTAuMWMwLjIsMCwwLjMtMC4xLDAuNC0wLjJjMC4xLTAuMSwwLjItMC4yLDAuMi0wLjRjMC0xLTEuMS0xLTEuMy0xIGMtMC40LDAtMS40LDAtMS40LDEuMmgtMC45YzAtMC40LDAuMS0wLjcsMC4yLTFjMC4xLTAuMiwwLjMtMC40LDAuNS0wLjZjMC4yLTAuMiwwLjUtMC4zLDAuOC0wLjNDMTMuMyw0LDEzLjYsNCwxMy45LDQgYzAuMywwLDAuNSwwLDAuOCwwLjFjMC4zLDAsMC41LDAuMSwwLjcsMC4yYzAuMiwwLjEsMC40LDAuMywwLjUsMC41QzE2LDUsMTYsNS4yLDE2LDUuNnYyLjljMCwwLjIsMCwwLjQsMCwwLjUgYzAsMC4xLDAuMSwwLjIsMC4zLDAuMmMwLjEsMCwwLjIsMCwwLjMsMFY5Ljh6IE0xNS4yLDYuOWMtMS4yLDAuNi0zLjEsMC4yLTMuMSwxLjRjMCwxLjQsMy4xLDEsMy4xLTAuNVY2Ljl6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-check: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik05IDE2LjE3TDQuODMgMTJsLTEuNDIgMS40MUw5IDE5IDIxIDdsLTEuNDEtMS40MXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-circle-empty: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyIDJDNi40NyAyIDIgNi40NyAyIDEyczQuNDcgMTAgMTAgMTAgMTAtNC40NyAxMC0xMFMxNy41MyAyIDEyIDJ6bTAgMThjLTQuNDEgMC04LTMuNTktOC04czMuNTktOCA4LTggOCAzLjU5IDggOC0zLjU5IDgtOCA4eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-circle: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPGNpcmNsZSBjeD0iOSIgY3k9IjkiIHI9IjgiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-clear: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8bWFzayBpZD0iZG9udXRIb2xlIj4KICAgIDxyZWN0IHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgZmlsbD0id2hpdGUiIC8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSI4IiBmaWxsPSJibGFjayIvPgogIDwvbWFzaz4KCiAgPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxyZWN0IGhlaWdodD0iMTgiIHdpZHRoPSIyIiB4PSIxMSIgeT0iMyIgdHJhbnNmb3JtPSJyb3RhdGUoMzE1LCAxMiwgMTIpIi8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIxMCIgbWFzaz0idXJsKCNkb251dEhvbGUpIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-close: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1ub25lIGpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIGpwLWljb24zLWhvdmVyIiBmaWxsPSJub25lIj4KICAgIDxjaXJjbGUgY3g9IjEyIiBjeT0iMTIiIHI9IjExIi8+CiAgPC9nPgoKICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIGpwLWljb24tYWNjZW50Mi1ob3ZlciIgZmlsbD0iIzYxNjE2MSI+CiAgICA8cGF0aCBkPSJNMTkgNi40MUwxNy41OSA1IDEyIDEwLjU5IDYuNDEgNSA1IDYuNDEgMTAuNTkgMTIgNSAxNy41OSA2LjQxIDE5IDEyIDEzLjQxIDE3LjU5IDE5IDE5IDE3LjU5IDEzLjQxIDEyeiIvPgogIDwvZz4KCiAgPGcgY2xhc3M9ImpwLWljb24tbm9uZSBqcC1pY29uLWJ1c3kiIGZpbGw9Im5vbmUiPgogICAgPGNpcmNsZSBjeD0iMTIiIGN5PSIxMiIgcj0iNyIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-code-check: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBzaGFwZS1yZW5kZXJpbmc9Imdlb21ldHJpY1ByZWNpc2lvbiI+CiAgICA8cGF0aCBkPSJNNi41OSwzLjQxTDIsOEw2LjU5LDEyLjZMOCwxMS4xOEw0LjgyLDhMOCw0LjgyTDYuNTksMy40MU0xMi40MSwzLjQxTDExLDQuODJMMTQuMTgsOEwxMSwxMS4xOEwxMi40MSwxMi42TDE3LDhMMTIuNDEsMy40MU0yMS41OSwxMS41OUwxMy41LDE5LjY4TDkuODMsMTZMOC40MiwxNy40MUwxMy41LDIyLjVMMjMsMTNMMjEuNTksMTEuNTlaIiAvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-code: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjIiIGhlaWdodD0iMjIiIHZpZXdCb3g9IjAgMCAyOCAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTExLjQgMTguNkw2LjggMTRMMTEuNCA5LjRMMTAgOEw0IDE0TDEwIDIwTDExLjQgMTguNlpNMTYuNiAxOC42TDIxLjIgMTRMMTYuNiA5LjRMMTggOEwyNCAxNEwxOCAyMEwxNi42IDE4LjZWMTguNloiLz4KCTwvZz4KPC9zdmc+Cg==);
  --jp-icon-collapse-all: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTggMmMxIDAgMTEgMCAxMiAwczIgMSAyIDJjMCAxIDAgMTEgMCAxMnMwIDItMiAyQzIwIDE0IDIwIDQgMjAgNFMxMCA0IDYgNGMwLTIgMS0yIDItMnoiIC8+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTE4IDhjMC0xLTEtMi0yLTJTNSA2IDQgNnMtMiAxLTIgMmMwIDEgMCAxMSAwIDEyczEgMiAyIDJjMSAwIDExIDAgMTIgMHMyLTEgMi0yYzAtMSAwLTExIDAtMTJ6bS0yIDB2MTJINFY4eiIgLz4KICAgICAgICA8cGF0aCBkPSJNNiAxM3YyaDh2LTJ6IiAvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-console: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwMCAyMDAiPgogIDxnIGNsYXNzPSJqcC1jb25zb2xlLWljb24tYmFja2dyb3VuZC1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiMwMjg4RDEiPgogICAgPHBhdGggZD0iTTIwIDE5LjhoMTYwdjE1OS45SDIweiIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtY29uc29sZS1pY29uLWNvbG9yIGpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIiBmaWxsPSIjZmZmIj4KICAgIDxwYXRoIGQ9Ik0xMDUgMTI3LjNoNDB2MTIuOGgtNDB6TTUxLjEgNzdMNzQgOTkuOWwtMjMuMyAyMy4zIDEwLjUgMTAuNSAyMy4zLTIzLjNMOTUgOTkuOSA4NC41IDg5LjQgNjEuNiA2Ni41eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-copy: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTExLjksMUgzLjJDMi40LDEsMS43LDEuNywxLjcsMi41djEwLjJoMS41VjIuNWg4LjdWMXogTTE0LjEsMy45aC04Yy0wLjgsMC0xLjUsMC43LTEuNSwxLjV2MTAuMmMwLDAuOCwwLjcsMS41LDEuNSwxLjVoOCBjMC44LDAsMS41LTAuNywxLjUtMS41VjUuNEMxNS41LDQuNiwxNC45LDMuOSwxNC4xLDMuOXogTTE0LjEsMTUuNWgtOFY1LjRoOFYxNS41eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-copyright: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGVuYWJsZS1iYWNrZ3JvdW5kPSJuZXcgMCAwIDI0IDI0IiBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCI+CiAgPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0xMS44OCw5LjE0YzEuMjgsMC4wNiwxLjYxLDEuMTUsMS42MywxLjY2aDEuNzljLTAuMDgtMS45OC0xLjQ5LTMuMTktMy40NS0zLjE5QzkuNjQsNy42MSw4LDksOCwxMi4xNCBjMCwxLjk0LDAuOTMsNC4yNCwzLjg0LDQuMjRjMi4yMiwwLDMuNDEtMS42NSwzLjQ0LTIuOTVoLTEuNzljLTAuMDMsMC41OS0wLjQ1LDEuMzgtMS42MywxLjQ0QzEwLjU1LDE0LjgzLDEwLDEzLjgxLDEwLDEyLjE0IEMxMCw5LjI1LDExLjI4LDkuMTYsMTEuODgsOS4xNHogTTEyLDJDNi40OCwyLDIsNi40OCwyLDEyczQuNDgsMTAsMTAsMTBzMTAtNC40OCwxMC0xMFMxNy41MiwyLDEyLDJ6IE0xMiwyMGMtNC40MSwwLTgtMy41OS04LTggczMuNTktOCw4LThzOCwzLjU5LDgsOFMxNi40MSwyMCwxMiwyMHoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-cut: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkuNjQgNy42NGMuMjMtLjUuMzYtMS4wNS4zNi0xLjY0IDAtMi4yMS0xLjc5LTQtNC00UzIgMy43OSAyIDZzMS43OSA0IDQgNGMuNTkgMCAxLjE0LS4xMyAxLjY0LS4zNkwxMCAxMmwtMi4zNiAyLjM2QzcuMTQgMTQuMTMgNi41OSAxNCA2IDE0Yy0yLjIxIDAtNCAxLjc5LTQgNHMxLjc5IDQgNCA0IDQtMS43OSA0LTRjMC0uNTktLjEzLTEuMTQtLjM2LTEuNjRMMTIgMTRsNyA3aDN2LTFMOS42NCA3LjY0ek02IDhjLTEuMSAwLTItLjg5LTItMnMuOS0yIDItMiAyIC44OSAyIDItLjkgMi0yIDJ6bTAgMTJjLTEuMSAwLTItLjg5LTItMnMuOS0yIDItMiAyIC44OSAyIDItLjkgMi0yIDJ6bTYtNy41Yy0uMjggMC0uNS0uMjItLjUtLjVzLjIyLS41LjUtLjUuNS4yMi41LjUtLjIyLjUtLjUuNXpNMTkgM2wtNiA2IDIgMiA3LTdWM3oiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-delete: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2cHgiIGhlaWdodD0iMTZweCI+CiAgICA8cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIiAvPgogICAgPHBhdGggY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjI2MjYyIiBkPSJNNiAxOWMwIDEuMS45IDIgMiAyaDhjMS4xIDAgMi0uOSAyLTJWN0g2djEyek0xOSA0aC0zLjVsLTEtMWgtNWwtMSAxSDV2MmgxNFY0eiIgLz4KPC9zdmc+Cg==);
  --jp-icon-download: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE5IDloLTRWM0g5djZINWw3IDcgNy03ek01IDE4djJoMTR2LTJINXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-duplicate: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiIGNsaXAtcnVsZT0iZXZlbm9kZCIgZD0iTTIuNzk5OTggMC44NzVIOC44OTU4MkM5LjIwMDYxIDAuODc1IDkuNDQ5OTggMS4xMzkxNCA5LjQ0OTk4IDEuNDYxOThDOS40NDk5OCAxLjc4NDgyIDkuMjAwNjEgMi4wNDg5NiA4Ljg5NTgyIDIuMDQ4OTZIMy4zNTQxNUMzLjA0OTM2IDIuMDQ4OTYgMi43OTk5OCAyLjMxMzEgMi43OTk5OCAyLjYzNTk0VjkuNjc5NjlDMi43OTk5OCAxMC4wMDI1IDIuNTUwNjEgMTAuMjY2NyAyLjI0NTgyIDEwLjI2NjdDMS45NDEwMyAxMC4yNjY3IDEuNjkxNjUgMTAuMDAyNSAxLjY5MTY1IDkuNjc5NjlWMi4wNDg5NkMxLjY5MTY1IDEuNDAzMjggMi4xOTA0IDAuODc1IDIuNzk5OTggMC44NzVaTTUuMzY2NjUgMTEuOVY0LjU1SDExLjA4MzNWMTEuOUg1LjM2NjY1Wk00LjE0MTY1IDQuMTQxNjdDNC4xNDE2NSAzLjY5MDYzIDQuNTA3MjggMy4zMjUgNC45NTgzMiAzLjMyNUgxMS40OTE3QzExLjk0MjcgMy4zMjUgMTIuMzA4MyAzLjY5MDYzIDEyLjMwODMgNC4xNDE2N1YxMi4zMDgzQzEyLjMwODMgMTIuNzU5NCAxMS45NDI3IDEzLjEyNSAxMS40OTE3IDEzLjEyNUg0Ljk1ODMyQzQuNTA3MjggMTMuMTI1IDQuMTQxNjUgMTIuNzU5NCA0LjE0MTY1IDEyLjMwODNWNC4xNDE2N1oiIGZpbGw9IiM2MTYxNjEiLz4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBkPSJNOS40MzU3NCA4LjI2NTA3SDguMzY0MzFWOS4zMzY1QzguMzY0MzEgOS40NTQzNSA4LjI2Nzg4IDkuNTUwNzggOC4xNTAwMiA5LjU1MDc4QzguMDMyMTcgOS41NTA3OCA3LjkzNTc0IDkuNDU0MzUgNy45MzU3NCA5LjMzNjVWOC4yNjUwN0g2Ljg2NDMxQzYuNzQ2NDUgOC4yNjUwNyA2LjY1MDAyIDguMTY4NjQgNi42NTAwMiA4LjA1MDc4QzYuNjUwMDIgNy45MzI5MiA2Ljc0NjQ1IDcuODM2NSA2Ljg2NDMxIDcuODM2NUg3LjkzNTc0VjYuNzY1MDdDNy45MzU3NCA2LjY0NzIxIDguMDMyMTcgNi41NTA3OCA4LjE1MDAyIDYuNTUwNzhDOC4yNjc4OCA2LjU1MDc4IDguMzY0MzEgNi42NDcyMSA4LjM2NDMxIDYuNzY1MDdWNy44MzY1SDkuNDM1NzRDOS41NTM2IDcuODM2NSA5LjY1MDAyIDcuOTMyOTIgOS42NTAwMiA4LjA1MDc4QzkuNjUwMDIgOC4xNjg2NCA5LjU1MzYgOC4yNjUwNyA5LjQzNTc0IDguMjY1MDdaIiBmaWxsPSIjNjE2MTYxIiBzdHJva2U9IiM2MTYxNjEiIHN0cm9rZS13aWR0aD0iMC41Ii8+Cjwvc3ZnPgo=);
  --jp-icon-edit: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTMgMTcuMjVWMjFoMy43NUwxNy44MSA5Ljk0bC0zLjc1LTMuNzVMMyAxNy4yNXpNMjAuNzEgNy4wNGMuMzktLjM5LjM5LTEuMDIgMC0xLjQxbC0yLjM0LTIuMzRjLS4zOS0uMzktMS4wMi0uMzktMS40MSAwbC0xLjgzIDEuODMgMy43NSAzLjc1IDEuODMtMS44M3oiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-ellipses: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPGNpcmNsZSBjeD0iNSIgY3k9IjEyIiByPSIyIi8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIyIi8+CiAgICA8Y2lyY2xlIGN4PSIxOSIgY3k9IjEyIiByPSIyIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-error: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj48Y2lyY2xlIGN4PSIxMiIgY3k9IjE5IiByPSIyIi8+PHBhdGggZD0iTTEwIDNoNHYxMmgtNHoiLz48L2c+CjxwYXRoIGZpbGw9Im5vbmUiIGQ9Ik0wIDBoMjR2MjRIMHoiLz4KPC9zdmc+Cg==);
  --jp-icon-expand-all: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTggMmMxIDAgMTEgMCAxMiAwczIgMSAyIDJjMCAxIDAgMTEgMCAxMnMwIDItMiAyQzIwIDE0IDIwIDQgMjAgNFMxMCA0IDYgNGMwLTIgMS0yIDItMnoiIC8+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTE4IDhjMC0xLTEtMi0yLTJTNSA2IDQgNnMtMiAxLTIgMmMwIDEgMCAxMSAwIDEyczEgMiAyIDJjMSAwIDExIDAgMTIgMHMyLTEgMi0yYzAtMSAwLTExIDAtMTJ6bS0yIDB2MTJINFY4eiIgLz4KICAgICAgICA8cGF0aCBkPSJNMTEgMTBIOXYzSDZ2MmgzdjNoMnYtM2gzdi0yaC0zeiIgLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-extension: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwLjUgMTFIMTlWN2MwLTEuMS0uOS0yLTItMmgtNFYzLjVDMTMgMi4xMiAxMS44OCAxIDEwLjUgMVM4IDIuMTIgOCAzLjVWNUg0Yy0xLjEgMC0xLjk5LjktMS45OSAydjMuOEgzLjVjMS40OSAwIDIuNyAxLjIxIDIuNyAyLjdzLTEuMjEgMi43LTIuNyAyLjdIMlYyMGMwIDEuMS45IDIgMiAyaDMuOHYtMS41YzAtMS40OSAxLjIxLTIuNyAyLjctMi43IDEuNDkgMCAyLjcgMS4yMSAyLjcgMi43VjIySDE3YzEuMSAwIDItLjkgMi0ydi00aDEuNWMxLjM4IDAgMi41LTEuMTIgMi41LTIuNVMyMS44OCAxMSAyMC41IDExeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-fast-forward: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTQgMThsOC41LTZMNCA2djEyem05LTEydjEybDguNS02TDEzIDZ6Ii8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-file-upload: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkgMTZoNnYtNmg0bC03LTctNyA3aDR6bS00IDJoMTR2Mkg1eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-file: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkuMyA4LjJsLTUuNS01LjVjLS4zLS4zLS43LS41LTEuMi0uNUgzLjljLS44LjEtMS42LjktMS42IDEuOHYxNC4xYzAgLjkuNyAxLjYgMS42IDEuNmgxNC4yYy45IDAgMS42LS43IDEuNi0xLjZWOS40Yy4xLS41LS4xLS45LS40LTEuMnptLTUuOC0zLjNsMy40IDMuNmgtMy40VjQuOXptMy45IDEyLjdINC43Yy0uMSAwLS4yIDAtLjItLjJWNC43YzAtLjIuMS0uMy4yLS4zaDcuMnY0LjRzMCAuOC4zIDEuMWMuMy4zIDEuMS4zIDEuMS4zaDQuM3Y3LjJzLS4xLjItLjIuMnoiLz4KPC9zdmc+Cg==);
  --jp-icon-filter-dot: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTE0LDEyVjE5Ljg4QzE0LjA0LDIwLjE4IDEzLjk0LDIwLjUgMTMuNzEsMjAuNzFDMTMuMzIsMjEuMSAxMi42OSwyMS4xIDEyLjMsMjAuNzFMMTAuMjksMTguN0MxMC4wNiwxOC40NyA5Ljk2LDE4LjE2IDEwLDE3Ljg3VjEySDkuOTdMNC4yMSw0LjYyQzMuODcsNC4xOSAzLjk1LDMuNTYgNC4zOCwzLjIyQzQuNTcsMy4wOCA0Ljc4LDMgNSwzVjNIMTlWM0MxOS4yMiwzIDE5LjQzLDMuMDggMTkuNjIsMy4yMkMyMC4wNSwzLjU2IDIwLjEzLDQuMTkgMTkuNzksNC42MkwxNC4wMywxMkgxNFoiIC8+CiAgPC9nPgogIDxnIGNsYXNzPSJqcC1pY29uLWRvdCIgZmlsbD0iI0ZGRiI+CiAgICA8Y2lyY2xlIGN4PSIxOCIgY3k9IjE3IiByPSIzIj48L2NpcmNsZT4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-filter-list: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEwIDE4aDR2LTJoLTR2MnpNMyA2djJoMThWNkgzem0zIDdoMTJ2LTJINnYyeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-filter: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTE0LDEyVjE5Ljg4QzE0LjA0LDIwLjE4IDEzLjk0LDIwLjUgMTMuNzEsMjAuNzFDMTMuMzIsMjEuMSAxMi42OSwyMS4xIDEyLjMsMjAuNzFMMTAuMjksMTguN0MxMC4wNiwxOC40NyA5Ljk2LDE4LjE2IDEwLDE3Ljg3VjEySDkuOTdMNC4yMSw0LjYyQzMuODcsNC4xOSAzLjk1LDMuNTYgNC4zOCwzLjIyQzQuNTcsMy4wOCA0Ljc4LDMgNSwzVjNIMTlWM0MxOS4yMiwzIDE5LjQzLDMuMDggMTkuNjIsMy4yMkMyMC4wNSwzLjU2IDIwLjEzLDQuMTkgMTkuNzksNC42MkwxNC4wMywxMkgxNFoiIC8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-folder-favorite: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjRweCIgdmlld0JveD0iMCAwIDI0IDI0IiB3aWR0aD0iMjRweCIgZmlsbD0iIzAwMDAwMCI+CiAgPHBhdGggZD0iTTAgMGgyNHYyNEgwVjB6IiBmaWxsPSJub25lIi8+PHBhdGggY2xhc3M9ImpwLWljb24zIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzYxNjE2MSIgZD0iTTIwIDZoLThsLTItMkg0Yy0xLjEgMC0yIC45LTIgMnYxMmMwIDEuMS45IDIgMiAyaDE2YzEuMSAwIDItLjkgMi0yVjhjMC0xLjEtLjktMi0yLTJ6bS0yLjA2IDExTDE1IDE1LjI4IDEyLjA2IDE3bC43OC0zLjMzLTIuNTktMi4yNCAzLjQxLS4yOUwxNSA4bDEuMzQgMy4xNCAzLjQxLjI5LTIuNTkgMi4yNC43OCAzLjMzeiIvPgo8L3N2Zz4K);
  --jp-icon-folder: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTAgNEg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMThjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY4YzAtMS4xLS45LTItMi0yaC04bC0yLTJ6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-home: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjRweCIgdmlld0JveD0iMCAwIDI0IDI0IiB3aWR0aD0iMjRweCIgZmlsbD0iIzAwMDAwMCI+CiAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPjxwYXRoIGNsYXNzPSJqcC1pY29uMyBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xMCAyMHYtNmg0djZoNXYtOGgzTDEyIDMgMiAxMmgzdjh6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-html5: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDUxMiA1MTIiPgogIDxwYXRoIGNsYXNzPSJqcC1pY29uMCBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiMwMDAiIGQ9Ik0xMDguNCAwaDIzdjIyLjhoMjEuMlYwaDIzdjY5aC0yM1Y0NmgtMjF2MjNoLTIzLjJNMjA2IDIzaC0yMC4zVjBoNjMuN3YyM0gyMjl2NDZoLTIzbTUzLjUtNjloMjQuMWwxNC44IDI0LjNMMzEzLjIgMGgyNC4xdjY5aC0yM1YzNC44bC0xNi4xIDI0LjgtMTYuMS0yNC44VjY5aC0yMi42bTg5LjItNjloMjN2NDYuMmgzMi42VjY5aC01NS42Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI2U0NGQyNiIgZD0iTTEwNy42IDQ3MWwtMzMtMzcwLjRoMzYyLjhsLTMzIDM3MC4yTDI1NS43IDUxMiIvPgogIDxwYXRoIGNsYXNzPSJqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNmMTY1MjkiIGQ9Ik0yNTYgNDgwLjVWMTMxaDE0OC4zTDM3NiA0NDciLz4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNlYmViZWIiIGQ9Ik0xNDIgMTc2LjNoMTE0djQ1LjRoLTY0LjJsNC4yIDQ2LjVoNjB2NDUuM0gxNTQuNG0yIDIyLjhIMjAybDMuMiAzNi4zIDUwLjggMTMuNnY0Ny40bC05My4yLTI2Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIiBmaWxsPSIjZmZmIiBkPSJNMzY5LjYgMTc2LjNIMjU1Ljh2NDUuNGgxMDkuNm0tNC4xIDQ2LjVIMjU1Ljh2NDUuNGg1NmwtNS4zIDU5LTUwLjcgMTMuNnY0Ny4ybDkzLTI1LjgiLz4KPC9zdmc+Cg==);
  --jp-icon-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1icmFuZDQganAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNGRkYiIGQ9Ik0yLjIgMi4yaDE3LjV2MTcuNUgyLjJ6Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzNGNTFCNSIgZD0iTTIuMiAyLjJ2MTcuNWgxNy41bC4xLTE3LjVIMi4yem0xMi4xIDIuMmMxLjIgMCAyLjIgMSAyLjIgMi4ycy0xIDIuMi0yLjIgMi4yLTIuMi0xLTIuMi0yLjIgMS0yLjIgMi4yLTIuMnpNNC40IDE3LjZsMy4zLTguOCAzLjMgNi42IDIuMi0zLjIgNC40IDUuNEg0LjR6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-info: url(data:image/svg+xml;base64,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);
  --jp-icon-inspector: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaW5zcGVjdG9yLWljb24tY29sb3IganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMjAgNEg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMThjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY2YzAtMS4xLS45LTItMi0yem0tNSAxNEg0di00aDExdjR6bTAtNUg0VjloMTF2NHptNSA1aC00VjloNHY5eiIvPgo8L3N2Zz4K);
  --jp-icon-json: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtanNvbi1pY29uLWNvbG9yIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI0Y5QTgyNSI+CiAgICA8cGF0aCBkPSJNMjAuMiAxMS44Yy0xLjYgMC0xLjcuNS0xLjcgMSAwIC40LjEuOS4xIDEuMy4xLjUuMS45LjEgMS4zIDAgMS43LTEuNCAyLjMtMy41IDIuM2gtLjl2LTEuOWguNWMxLjEgMCAxLjQgMCAxLjQtLjggMC0uMyAwLS42LS4xLTEgMC0uNC0uMS0uOC0uMS0xLjIgMC0xLjMgMC0xLjggMS4zLTItMS4zLS4yLTEuMy0uNy0xLjMtMiAwLS40LjEtLjguMS0xLjIuMS0uNC4xLS43LjEtMSAwLS44LS40LS43LTEuNC0uOGgtLjVWNC4xaC45YzIuMiAwIDMuNS43IDMuNSAyLjMgMCAuNC0uMS45LS4xIDEuMy0uMS41LS4xLjktLjEgMS4zIDAgLjUuMiAxIDEuNyAxdjEuOHpNMS44IDEwLjFjMS42IDAgMS43LS41IDEuNy0xIDAtLjQtLjEtLjktLjEtMS4zLS4xLS41LS4xLS45LS4xLTEuMyAwLTEuNiAxLjQtMi4zIDMuNS0yLjNoLjl2MS45aC0uNWMtMSAwLTEuNCAwLTEuNC44IDAgLjMgMCAuNi4xIDEgMCAuMi4xLjYuMSAxIDAgMS4zIDAgMS44LTEuMyAyQzYgMTEuMiA2IDExLjcgNiAxM2MwIC40LS4xLjgtLjEgMS4yLS4xLjMtLjEuNy0uMSAxIDAgLjguMy44IDEuNC44aC41djEuOWgtLjljLTIuMSAwLTMuNS0uNi0zLjUtMi4zIDAtLjQuMS0uOS4xLTEuMy4xLS41LjEtLjkuMS0xLjMgMC0uNS0uMi0xLTEuNy0xdi0xLjl6Ii8+CiAgICA8Y2lyY2xlIGN4PSIxMSIgY3k9IjEzLjgiIHI9IjIuMSIvPgogICAgPGNpcmNsZSBjeD0iMTEiIGN5PSI4LjIiIHI9IjIuMSIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-julia: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDMyNSAzMDAiPgogIDxnIGNsYXNzPSJqcC1icmFuZDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjY2IzYzMzIj4KICAgIDxwYXRoIGQ9Ik0gMTUwLjg5ODQzOCAyMjUgQyAxNTAuODk4NDM4IDI2Ni40MjE4NzUgMTE3LjMyMDMxMiAzMDAgNzUuODk4NDM4IDMwMCBDIDM0LjQ3NjU2MiAzMDAgMC44OTg0MzggMjY2LjQyMTg3NSAwLjg5ODQzOCAyMjUgQyAwLjg5ODQzOCAxODMuNTc4MTI1IDM0LjQ3NjU2MiAxNTAgNzUuODk4NDM4IDE1MCBDIDExNy4zMjAzMTIgMTUwIDE1MC44OTg0MzggMTgzLjU3ODEyNSAxNTAuODk4NDM4IDIyNSIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzM4OTgyNiI+CiAgICA8cGF0aCBkPSJNIDIzNy41IDc1IEMgMjM3LjUgMTE2LjQyMTg3NSAyMDMuOTIxODc1IDE1MCAxNjIuNSAxNTAgQyAxMjEuMDc4MTI1IDE1MCA4Ny41IDExNi40MjE4NzUgODcuNSA3NSBDIDg3LjUgMzMuNTc4MTI1IDEyMS4wNzgxMjUgMCAxNjIuNSAwIEMgMjAzLjkyMTg3NSAwIDIzNy41IDMzLjU3ODEyNSAyMzcuNSA3NSIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzk1NThiMiI+CiAgICA8cGF0aCBkPSJNIDMyNC4xMDE1NjIgMjI1IEMgMzI0LjEwMTU2MiAyNjYuNDIxODc1IDI5MC41MjM0MzggMzAwIDI0OS4xMDE1NjIgMzAwIEMgMjA3LjY3OTY4OCAzMDAgMTc0LjEwMTU2MiAyNjYuNDIxODc1IDE3NC4xMDE1NjIgMjI1IEMgMTc0LjEwMTU2MiAxODMuNTc4MTI1IDIwNy42Nzk2ODggMTUwIDI0OS4xMDE1NjIgMTUwIEMgMjkwLjUyMzQzOCAxNTAgMzI0LjEwMTU2MiAxODMuNTc4MTI1IDMyNC4xMDE1NjIgMjI1Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-jupyter-favicon: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTUyIiBoZWlnaHQ9IjE2NSIgdmlld0JveD0iMCAwIDE1MiAxNjUiIHZlcnNpb249IjEuMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgPGcgY2xhc3M9ImpwLWp1cHl0ZXItaWNvbi1jb2xvciIgZmlsbD0iI0YzNzcyNiI+CiAgICA8cGF0aCB0cmFuc2Zvcm09InRyYW5zbGF0ZSgwLjA3ODk0NywgMTEwLjU4MjkyNykiIGQ9Ik03NS45NDIyODQyLDI5LjU4MDQ1NjEgQzQzLjMwMjM5NDcsMjkuNTgwNDU2MSAxNC43OTY3ODMyLDE3LjY1MzQ2MzQgMCwwIEM1LjUxMDgzMjExLDE1Ljg0MDY4MjkgMTUuNzgxNTM4OSwyOS41NjY3NzMyIDI5LjM5MDQ5NDcsMzkuMjc4NDE3MSBDNDIuOTk5Nyw0OC45ODk4NTM3IDU5LjI3MzcsNTQuMjA2NzgwNSA3NS45NjA1Nzg5LDU0LjIwNjc4MDUgQzkyLjY0NzQ1NzksNTQuMjA2NzgwNSAxMDguOTIxNDU4LDQ4Ljk4OTg1MzcgMTIyLjUzMDY2MywzOS4yNzg0MTcxIEMxMzYuMTM5NDUzLDI5LjU2Njc3MzIgMTQ2LjQxMDI4NCwxNS44NDA2ODI5IDE1MS45MjExNTgsMCBDMTM3LjA4Nzg2OCwxNy42NTM0NjM0IDEwOC41ODI1ODksMjkuNTgwNDU2MSA3NS45NDIyODQyLDI5LjU4MDQ1NjEgTDc1Ljk0MjI4NDIsMjkuNTgwNDU2MSBaIiAvPgogICAgPHBhdGggdHJhbnNmb3JtPSJ0cmFuc2xhdGUoMC4wMzczNjgsIDAuNzA0ODc4KSIgZD0iTTc1Ljk3ODQ1NzksMjQuNjI2NDA3MyBDMTA4LjYxODc2MywyNC42MjY0MDczIDEzNy4xMjQ0NTgsMzYuNTUzNDQxNSAxNTEuOTIxMTU4LDU0LjIwNjc4MDUgQzE0Ni40MTAyODQsMzguMzY2MjIyIDEzNi4xMzk0NTMsMjQuNjQwMTMxNyAxMjIuNTMwNjYzLDE0LjkyODQ4NzggQzEwOC45MjE0NTgsNS4yMTY4NDM5IDkyLjY0NzQ1NzksMCA3NS45NjA1Nzg5LDAgQzU5LjI3MzcsMCA0Mi45OTk3LDUuMjE2ODQzOSAyOS4zOTA0OTQ3LDE0LjkyODQ4NzggQzE1Ljc4MTUzODksMjQuNjQwMTMxNyA1LjUxMDgzMjExLDM4LjM2NjIyMiAwLDU0LjIwNjc4MDUgQzE0LjgzMzA4MTYsMzYuNTg5OTI5MyA0My4zMzg1Njg0LDI0LjYyNjQwNzMgNzUuOTc4NDU3OSwyNC42MjY0MDczIEw3NS45Nzg0NTc5LDI0LjYyNjQwNzMgWiIgLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-jupyter: url(data:image/svg+xml;base64,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);
  --jp-icon-jupyterlab-wordmark: url(data:image/svg+xml;base64,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);
  --jp-icon-kernel: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgZmlsbD0iIzYxNjE2MSIgZD0iTTE1IDlIOXY2aDZWOXptLTIgNGgtMnYtMmgydjJ6bTgtMlY5aC0yVjdjMC0xLjEtLjktMi0yLTJoLTJWM2gtMnYyaC0yVjNIOXYySDdjLTEuMSAwLTIgLjktMiAydjJIM3YyaDJ2MkgzdjJoMnYyYzAgMS4xLjkgMiAyIDJoMnYyaDJ2LTJoMnYyaDJ2LTJoMmMxLjEgMCAyLS45IDItMnYtMmgydi0yaC0ydi0yaDJ6bS00IDZIN1Y3aDEwdjEweiIvPgo8L3N2Zz4K);
  --jp-icon-keyboard: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMjAgNUg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMTdjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY3YzAtMS4xLS45LTItMi0yem0tOSAzaDJ2MmgtMlY4em0wIDNoMnYyaC0ydi0yek04IDhoMnYySDhWOHptMCAzaDJ2Mkg4di0yem0tMSAySDV2LTJoMnYyem0wLTNINVY4aDJ2MnptOSA3SDh2LTJoOHYyem0wLTRoLTJ2LTJoMnYyem0wLTNoLTJWOGgydjJ6bTMgM2gtMnYtMmgydjJ6bTAtM2gtMlY4aDJ2MnoiLz4KPC9zdmc+Cg==);
  --jp-icon-launch: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMzIgMzIiIHdpZHRoPSIzMiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0yNiwyOEg2YTIuMDAyNywyLjAwMjcsMCwwLDEtMi0yVjZBMi4wMDI3LDIuMDAyNywwLDAsMSw2LDRIMTZWNkg2VjI2SDI2VjE2aDJWMjZBMi4wMDI3LDIuMDAyNywwLDAsMSwyNiwyOFoiLz4KICAgIDxwb2x5Z29uIHBvaW50cz0iMjAgMiAyMCA0IDI2LjU4NiA0IDE4IDEyLjU4NiAxOS40MTQgMTQgMjggNS40MTQgMjggMTIgMzAgMTIgMzAgMiAyMCAyIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-launcher: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkgMTlINVY1aDdWM0g1YTIgMiAwIDAwLTIgMnYxNGEyIDIgMCAwMDIgMmgxNGMxLjEgMCAyLS45IDItMnYtN2gtMnY3ek0xNCAzdjJoMy41OWwtOS44MyA5LjgzIDEuNDEgMS40MUwxOSA2LjQxVjEwaDJWM2gtN3oiLz4KPC9zdmc+Cg==);
  --jp-icon-line-form: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGZpbGw9IndoaXRlIiBkPSJNNS44OCA0LjEyTDEzLjc2IDEybC03Ljg4IDcuODhMOCAyMmwxMC0xMEw4IDJ6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-link: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTMuOSAxMmMwLTEuNzEgMS4zOS0zLjEgMy4xLTMuMWg0VjdIN2MtMi43NiAwLTUgMi4yNC01IDVzMi4yNCA1IDUgNWg0di0xLjlIN2MtMS43MSAwLTMuMS0xLjM5LTMuMS0zLjF6TTggMTNoOHYtMkg4djJ6bTktNmgtNHYxLjloNGMxLjcxIDAgMy4xIDEuMzkgMy4xIDMuMXMtMS4zOSAzLjEtMy4xIDMuMWgtNFYxN2g0YzIuNzYgMCA1LTIuMjQgNS01cy0yLjI0LTUtNS01eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-list: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xOSA1djE0SDVWNWgxNG0xLjEtMkgzLjljLS41IDAtLjkuNC0uOS45djE2LjJjMCAuNC40LjkuOS45aDE2LjJjLjQgMCAuOS0uNS45LS45VjMuOWMwLS41LS41LS45LS45LS45ek0xMSA3aDZ2MmgtNlY3em0wIDRoNnYyaC02di0yem0wIDRoNnYyaC02ek03IDdoMnYySDd6bTAgNGgydjJIN3ptMCA0aDJ2Mkg3eiIvPgo8L3N2Zz4K);
  --jp-icon-markdown: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjN0IxRkEyIiBkPSJNNSAxNC45aDEybC02LjEgNnptOS40LTYuOGMwLTEuMy0uMS0yLjktLjEtNC41LS40IDEuNC0uOSAyLjktMS4zIDQuM2wtMS4zIDQuM2gtMkw4LjUgNy45Yy0uNC0xLjMtLjctMi45LTEtNC4zLS4xIDEuNi0uMSAzLjItLjIgNC42TDcgMTIuNEg0LjhsLjctMTFoMy4zTDEwIDVjLjQgMS4yLjcgMi43IDEgMy45LjMtMS4yLjctMi42IDEtMy45bDEuMi0zLjdoMy4zbC42IDExaC0yLjRsLS4zLTQuMnoiLz4KPC9zdmc+Cg==);
  --jp-icon-move-down: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBkPSJNMTIuNDcxIDcuNTI4OTlDMTIuNzYzMiA3LjIzNjg0IDEyLjc2MzIgNi43NjMxNiAxMi40NzEgNi40NzEwMVY2LjQ3MTAxQzEyLjE3OSA2LjE3OTA1IDExLjcwNTcgNi4xNzg4NCAxMS40MTM1IDYuNDcwNTRMNy43NSAxMC4xMjc1VjEuNzVDNy43NSAxLjMzNTc5IDcuNDE0MjEgMSA3IDFWMUM2LjU4NTc5IDEgNi4yNSAxLjMzNTc5IDYuMjUgMS43NVYxMC4xMjc1TDIuNTk3MjYgNi40NjgyMkMyLjMwMzM4IDYuMTczODEgMS44MjY0MSA2LjE3MzU5IDEuNTMyMjYgNi40Njc3NFY2LjQ2Nzc0QzEuMjM4MyA2Ljc2MTcgMS4yMzgzIDcuMjM4MyAxLjUzMjI2IDcuNTMyMjZMNi4yOTI4OSAxMi4yOTI5QzYuNjgzNDIgMTIuNjgzNCA3LjMxNjU4IDEyLjY4MzQgNy43MDcxMSAxMi4yOTI5TDEyLjQ3MSA3LjUyODk5WiIgZmlsbD0iIzYxNjE2MSIvPgo8L3N2Zz4K);
  --jp-icon-move-up: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBkPSJNMS41Mjg5OSA2LjQ3MTAxQzEuMjM2ODQgNi43NjMxNiAxLjIzNjg0IDcuMjM2ODQgMS41Mjg5OSA3LjUyODk5VjcuNTI4OTlDMS44MjA5NSA3LjgyMDk1IDIuMjk0MjYgNy44MjExNiAyLjU4NjQ5IDcuNTI5NDZMNi4yNSAzLjg3MjVWMTIuMjVDNi4yNSAxMi42NjQyIDYuNTg1NzkgMTMgNyAxM1YxM0M3LjQxNDIxIDEzIDcuNzUgMTIuNjY0MiA3Ljc1IDEyLjI1VjMuODcyNUwxMS40MDI3IDcuNTMxNzhDMTEuNjk2NiA3LjgyNjE5IDEyLjE3MzYgNy44MjY0MSAxMi40Njc3IDcuNTMyMjZWNy41MzIyNkMxMi43NjE3IDcuMjM4MyAxMi43NjE3IDYuNzYxNyAxMi40Njc3IDYuNDY3NzRMNy43MDcxMSAxLjcwNzExQzcuMzE2NTggMS4zMTY1OCA2LjY4MzQyIDEuMzE2NTggNi4yOTI4OSAxLjcwNzExTDEuNTI4OTkgNi40NzEwMVoiIGZpbGw9IiM2MTYxNjEiLz4KPC9zdmc+Cg==);
  --jp-icon-new-folder: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwIDZoLThsLTItMkg0Yy0xLjExIDAtMS45OS44OS0xLjk5IDJMMiAxOGMwIDEuMTEuODkgMiAyIDJoMTZjMS4xMSAwIDItLjg5IDItMlY4YzAtMS4xMS0uODktMi0yLTJ6bS0xIDhoLTN2M2gtMnYtM2gtM3YtMmgzVjloMnYzaDN2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-not-trusted: url(data:image/svg+xml;base64,PHN2ZyBmaWxsPSJub25lIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI1IDI1Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDMgMykiIGQ9Ik0xLjg2MDk0IDExLjQ0MDlDMC44MjY0NDggOC43NzAyNyAwLjg2Mzc3OSA2LjA1NzY0IDEuMjQ5MDcgNC4xOTkzMkMyLjQ4MjA2IDMuOTMzNDcgNC4wODA2OCAzLjQwMzQ3IDUuNjAxMDIgMi44NDQ5QzcuMjM1NDkgMi4yNDQ0IDguODU2NjYgMS41ODE1IDkuOTg3NiAxLjA5NTM5QzExLjA1OTcgMS41ODM0MSAxMi42MDk0IDIuMjQ0NCAxNC4yMTggMi44NDMzOUMxNS43NTAzIDMuNDEzOTQgMTcuMzk5NSAzLjk1MjU4IDE4Ljc1MzkgNC4yMTM4NUMxOS4xMzY0IDYuMDcxNzcgMTkuMTcwOSA4Ljc3NzIyIDE4LjEzOSAxMS40NDA5QzE3LjAzMDMgMTQuMzAzMiAxNC42NjY4IDE3LjE4NDQgOS45OTk5OSAxOC45MzU0QzUuMzMzMTkgMTcuMTg0NCAyLjk2OTY4IDE0LjMwMzIgMS44NjA5NCAxMS40NDA5WiIvPgogICAgPHBhdGggY2xhc3M9ImpwLWljb24yIiBzdHJva2U9IiMzMzMzMzMiIHN0cm9rZS13aWR0aD0iMiIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoOS4zMTU5MiA5LjMyMDMxKSIgZD0iTTcuMzY4NDIgMEwwIDcuMzY0NzkiLz4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDkuMzE1OTIgMTYuNjgzNikgc2NhbGUoMSAtMSkiIGQ9Ik03LjM2ODQyIDBMMCA3LjM2NDc5Ii8+Cjwvc3ZnPgo=);
  --jp-icon-notebook: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtbm90ZWJvb2staWNvbi1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNFRjZDMDAiPgogICAgPHBhdGggZD0iTTE4LjcgMy4zdjE1LjRIMy4zVjMuM2gxNS40bTEuNS0xLjVIMS44djE4LjNoMTguM2wuMS0xOC4zeiIvPgogICAgPHBhdGggZD0iTTE2LjUgMTYuNWwtNS40LTQuMy01LjYgNC4zdi0xMWgxMXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-numbering: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjIiIGhlaWdodD0iMjIiIHZpZXdCb3g9IjAgMCAyOCAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTQgMTlINlYxOS41SDVWMjAuNUg2VjIxSDRWMjJIN1YxOEg0VjE5Wk01IDEwSDZWNkg0VjdINVYxMFpNNCAxM0g1LjhMNCAxNS4xVjE2SDdWMTVINS4yTDcgMTIuOVYxMkg0VjEzWk05IDdWOUgyM1Y3SDlaTTkgMjFIMjNWMTlIOVYyMVpNOSAxNUgyM1YxM0g5VjE1WiIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-offline-bolt: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyIDIuMDJjLTUuNTEgMC05Ljk4IDQuNDctOS45OCA5Ljk4czQuNDcgOS45OCA5Ljk4IDkuOTggOS45OC00LjQ3IDkuOTgtOS45OFMxNy41MSAyLjAyIDEyIDIuMDJ6TTExLjQ4IDIwdi02LjI2SDhMMTMgNHY2LjI2aDMuMzVMMTEuNDggMjB6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-palette: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE4IDEzVjIwSDRWNkg5LjAyQzkuMDcgNS4yOSA5LjI0IDQuNjIgOS41IDRINEMyLjkgNCAyIDQuOSAyIDZWMjBDMiAyMS4xIDIuOSAyMiA0IDIySDE4QzE5LjEgMjIgMjAgMjEuMSAyMCAyMFYxNUwxOCAxM1pNMTkuMyA4Ljg5QzE5Ljc0IDguMTkgMjAgNy4zOCAyMCA2LjVDMjAgNC4wMSAxNy45OSAyIDE1LjUgMkMxMy4wMSAyIDExIDQuMDEgMTEgNi41QzExIDguOTkgMTMuMDEgMTEgMTUuNDkgMTFDMTYuMzcgMTEgMTcuMTkgMTAuNzQgMTcuODggMTAuM0wyMSAxMy40MkwyMi40MiAxMkwxOS4zIDguODlaTTE1LjUgOUMxNC4xMiA5IDEzIDcuODggMTMgNi41QzEzIDUuMTIgMTQuMTIgNCAxNS41IDRDMTYuODggNCAxOCA1LjEyIDE4IDYuNUMxOCA3Ljg4IDE2Ljg4IDkgMTUuNSA5WiIvPgogICAgPHBhdGggZmlsbC1ydWxlPSJldmVub2RkIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik00IDZIOS4wMTg5NEM5LjAwNjM5IDYuMTY1MDIgOSA2LjMzMTc2IDkgNi41QzkgOC44MTU3NyAxMC4yMTEgMTAuODQ4NyAxMi4wMzQzIDEySDlWMTRIMTZWMTIuOTgxMUMxNi41NzAzIDEyLjkzNzcgMTcuMTIgMTIuODIwNyAxNy42Mzk2IDEyLjYzOTZMMTggMTNWMjBINFY2Wk04IDhINlYxMEg4VjhaTTYgMTJIOFYxNEg2VjEyWk04IDE2SDZWMThIOFYxNlpNOSAxNkgxNlYxOEg5VjE2WiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-paste: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTE5IDJoLTQuMThDMTQuNC44NCAxMy4zIDAgMTIgMGMtMS4zIDAtMi40Ljg0LTIuODIgMkg1Yy0xLjEgMC0yIC45LTIgMnYxNmMwIDEuMS45IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjRjMC0xLjEtLjktMi0yLTJ6bS03IDBjLjU1IDAgMSAuNDUgMSAxcy0uNDUgMS0xIDEtMS0uNDUtMS0xIC40NS0xIDEtMXptNyAxOEg1VjRoMnYzaDEwVjRoMnYxNnoiLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-pdf: url(data:image/svg+xml;base64,PHN2ZwogICB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyMiAyMiIgd2lkdGg9IjE2Ij4KICAgIDxwYXRoIHRyYW5zZm9ybT0icm90YXRlKDQ1KSIgY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI0ZGMkEyQSIKICAgICAgIGQ9Im0gMjIuMzQ0MzY5LC0zLjAxNjM2NDIgaCA1LjYzODYwNCB2IDEuNTc5MjQzMyBoIC0zLjU0OTIyNyB2IDEuNTA4NjkyOTkgaCAzLjMzNzU3NiBWIDEuNjUwODE1NCBoIC0zLjMzNzU3NiB2IDMuNDM1MjYxMyBoIC0yLjA4OTM3NyB6IG0gLTcuMTM2NDQ0LDEuNTc5MjQzMyB2IDQuOTQzOTU0MyBoIDAuNzQ4OTIgcSAxLjI4MDc2MSwwIDEuOTUzNzAzLC0wLjYzNDk1MzUgMC42NzgzNjksLTAuNjM0OTUzNSAwLjY3ODM2OSwtMS44NDUxNjQxIDAsLTEuMjA0NzgzNTUgLTAuNjcyOTQyLC0xLjgzNDMxMDExIC0wLjY3Mjk0MiwtMC42Mjk1MjY1OSAtMS45NTkxMywtMC42Mjk1MjY1OSB6IG0gLTIuMDg5Mzc3LC0xLjU3OTI0MzMgaCAyLjIwMzM0MyBxIDEuODQ1MTY0LDAgMi43NDYwMzksMC4yNjU5MjA3IDAuOTA2MzAxLDAuMjYwNDkzNyAxLjU1MjEwOCwwLjg5MDAyMDMgMC41Njk4MywwLjU0ODEyMjMgMC44NDY2MDUsMS4yNjQ0ODAwNiAwLjI3Njc3NCwwLjcxNjM1NzgxIDAuMjc2Nzc0LDEuNjIyNjU4OTQgMCwwLjkxNzE1NTEgLTAuMjc2Nzc0LDEuNjM4OTM5OSAtMC4yNzY3NzUsMC43MTYzNTc4IC0wLjg0NjYwNSwxLjI2NDQ4IC0wLjY1MTIzNCwwLjYyOTUyNjYgLTEuNTYyOTYyLDAuODk1NDQ3MyAtMC45MTE3MjgsMC4yNjA0OTM3IC0yLjczNTE4NSwwLjI2MDQ5MzcgaCAtMi4yMDMzNDMgeiBtIC04LjE0NTg1NjUsMCBoIDMuNDY3ODIzIHEgMS41NDY2ODE2LDAgMi4zNzE1Nzg1LDAuNjg5MjIzIDAuODMwMzI0LDAuNjgzNzk2MSAwLjgzMDMyNCwxLjk1MzcwMzE0IDAsMS4yNzUzMzM5NyAtMC44MzAzMjQsMS45NjQ1NTcwNiBRIDkuOTg3MTk2MSwyLjI3NDkxNSA4LjQ0MDUxNDUsMi4yNzQ5MTUgSCA3LjA2MjA2ODQgViA1LjA4NjA3NjcgSCA0Ljk3MjY5MTUgWiBtIDIuMDg5Mzc2OSwxLjUxNDExOTkgdiAyLjI2MzAzOTQzIGggMS4xNTU5NDEgcSAwLjYwNzgxODgsMCAwLjkzODg2MjksLTAuMjkzMDU1NDcgMC4zMzEwNDQxLC0wLjI5ODQ4MjQxIDAuMzMxMDQ0MSwtMC44NDExNzc3MiAwLC0wLjU0MjY5NTMxIC0wLjMzMTA0NDEsLTAuODM1NzUwNzQgLTAuMzMxMDQ0MSwtMC4yOTMwNTU1IC0wLjkzODg2MjksLTAuMjkzMDU1NSB6IgovPgo8L3N2Zz4K);
  --jp-icon-python: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iLTEwIC0xMCAxMzEuMTYxMzYxNjk0MzM1OTQgMTMyLjM4ODk5OTkzODk2NDg0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMzA2OTk4IiBkPSJNIDU0LjkxODc4NSw5LjE5Mjc0MjFlLTQgQyA1MC4zMzUxMzIsMC4wMjIyMTcyNyA0NS45NTc4NDYsMC40MTMxMzY5NyA0Mi4xMDYyODUsMS4wOTQ2NjkzIDMwLjc2MDA2OSwzLjA5OTE3MzEgMjguNzAwMDM2LDcuMjk0NzcxNCAyOC43MDAwMzUsMTUuMDMyMTY5IHYgMTAuMjE4NzUgaCAyNi44MTI1IHYgMy40MDYyNSBoIC0yNi44MTI1IC0xMC4wNjI1IGMgLTcuNzkyNDU5LDAgLTE0LjYxNTc1ODgsNC42ODM3MTcgLTE2Ljc0OTk5OTgsMTMuNTkzNzUgLTIuNDYxODE5OTgsMTAuMjEyOTY2IC0yLjU3MTAxNTA4LDE2LjU4NjAyMyAwLDI3LjI1IDEuOTA1OTI4Myw3LjkzNzg1MiA2LjQ1NzU0MzIsMTMuNTkzNzQ4IDE0LjI0OTk5OTgsMTMuNTkzNzUgaCA5LjIxODc1IHYgLTEyLjI1IGMgMCwtOC44NDk5MDIgNy42NTcxNDQsLTE2LjY1NjI0OCAxNi43NSwtMTYuNjU2MjUgaCAyNi43ODEyNSBjIDcuNDU0OTUxLDAgMTMuNDA2MjUzLC02LjEzODE2NCAxMy40MDYyNSwtMTMuNjI1IHYgLTI1LjUzMTI1IGMgMCwtNy4yNjYzMzg2IC02LjEyOTk4LC0xMi43MjQ3NzcxIC0xMy40MDYyNSwtMTMuOTM3NDk5NyBDIDY0LjI4MTU0OCwwLjMyNzk0Mzk3IDU5LjUwMjQzOCwtMC4wMjAzNzkwMyA1NC45MTg3ODUsOS4xOTI3NDIxZS00IFogbSAtMTQuNSw4LjIxODc1MDEyNTc5IGMgMi43Njk1NDcsMCA1LjAzMTI1LDIuMjk4NjQ1NiA1LjAzMTI1LDUuMTI0OTk5NiAtMmUtNiwyLjgxNjMzNiAtMi4yNjE3MDMsNS4wOTM3NSAtNS4wMzEyNSw1LjA5Mzc1IC0yLjc3OTQ3NiwtMWUtNiAtNS4wMzEyNSwtMi4yNzc0MTUgLTUuMDMxMjUsLTUuMDkzNzUgLTEwZS03LC0yLjgyNjM1MyAyLjI1MTc3NCwtNS4xMjQ5OTk2IDUuMDMxMjUsLTUuMTI0OTk5NiB6Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI2ZmZDQzYiIgZD0ibSA4NS42Mzc1MzUsMjguNjU3MTY5IHYgMTEuOTA2MjUgYyAwLDkuMjMwNzU1IC03LjgyNTg5NSwxNi45OTk5OTkgLTE2Ljc1LDE3IGggLTI2Ljc4MTI1IGMgLTcuMzM1ODMzLDAgLTEzLjQwNjI0OSw2LjI3ODQ4MyAtMTMuNDA2MjUsMTMuNjI1IHYgMjUuNTMxMjQ3IGMgMCw3LjI2NjM0NCA2LjMxODU4OCwxMS41NDAzMjQgMTMuNDA2MjUsMTMuNjI1MDA0IDguNDg3MzMxLDIuNDk1NjEgMTYuNjI2MjM3LDIuOTQ2NjMgMjYuNzgxMjUsMCA2Ljc1MDE1NSwtMS45NTQzOSAxMy40MDYyNTMsLTUuODg3NjEgMTMuNDA2MjUsLTEzLjYyNTAwNCBWIDg2LjUwMDkxOSBoIC0yNi43ODEyNSB2IC0zLjQwNjI1IGggMjYuNzgxMjUgMTMuNDA2MjU0IGMgNy43OTI0NjEsMCAxMC42OTYyNTEsLTUuNDM1NDA4IDEzLjQwNjI0MSwtMTMuNTkzNzUgMi43OTkzMywtOC4zOTg4ODYgMi42ODAyMiwtMTYuNDc1Nzc2IDAsLTI3LjI1IC0xLjkyNTc4LC03Ljc1NzQ0MSAtNS42MDM4NywtMTMuNTkzNzUgLTEzLjQwNjI0MSwtMTMuNTkzNzUgeiBtIC0xNS4wNjI1LDY0LjY1NjI1IGMgMi43Nzk0NzgsM2UtNiA1LjAzMTI1LDIuMjc3NDE3IDUuMDMxMjUsNS4wOTM3NDcgLTJlLTYsMi44MjYzNTQgLTIuMjUxNzc1LDUuMTI1MDA0IC01LjAzMTI1LDUuMTI1MDA0IC0yLjc2OTU1LDAgLTUuMDMxMjUsLTIuMjk4NjUgLTUuMDMxMjUsLTUuMTI1MDA0IDJlLTYsLTIuODE2MzMgMi4yNjE2OTcsLTUuMDkzNzQ3IDUuMDMxMjUsLTUuMDkzNzQ3IHoiLz4KPC9zdmc+Cg==);
  --jp-icon-r-kernel: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMjE5NkYzIiBkPSJNNC40IDIuNWMxLjItLjEgMi45LS4zIDQuOS0uMyAyLjUgMCA0LjEuNCA1LjIgMS4zIDEgLjcgMS41IDEuOSAxLjUgMy41IDAgMi0xLjQgMy41LTIuOSA0LjEgMS4yLjQgMS43IDEuNiAyLjIgMyAuNiAxLjkgMSAzLjkgMS4zIDQuNmgtMy44Yy0uMy0uNC0uOC0xLjctMS4yLTMuN3MtMS4yLTIuNi0yLjYtMi42aC0uOXY2LjRINC40VjIuNXptMy43IDYuOWgxLjRjMS45IDAgMi45LS45IDIuOS0yLjNzLTEtMi4zLTIuOC0yLjNjLS43IDAtMS4zIDAtMS42LjJ2NC41aC4xdi0uMXoiLz4KPC9zdmc+Cg==);
  --jp-icon-react: url(data:image/svg+xml;base64,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);
  --jp-icon-redo: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgICA8cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIi8+PHBhdGggZD0iTTE4LjQgMTAuNkMxNi41NSA4Ljk5IDE0LjE1IDggMTEuNSA4Yy00LjY1IDAtOC41OCAzLjAzLTkuOTYgNy4yMkwzLjkgMTZjMS4wNS0zLjE5IDQuMDUtNS41IDcuNi01LjUgMS45NSAwIDMuNzMuNzIgNS4xMiAxLjg4TDEzIDE2aDlWN2wtMy42IDMuNnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-refresh: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTkgMTMuNWMtMi40OSAwLTQuNS0yLjAxLTQuNS00LjVTNi41MSA0LjUgOSA0LjVjMS4yNCAwIDIuMzYuNTIgMy4xNyAxLjMzTDEwIDhoNVYzbC0xLjc2IDEuNzZDMTIuMTUgMy42OCAxMC42NiAzIDkgMyA1LjY5IDMgMy4wMSA1LjY5IDMuMDEgOVM1LjY5IDE1IDkgMTVjMi45NyAwIDUuNDMtMi4xNiA1LjktNWgtMS41MmMtLjQ2IDItMi4yNCAzLjUtNC4zOCAzLjV6Ii8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-regex: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KICA8ZyBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiM0MTQxNDEiPgogICAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiAgPC9nPgoKICA8ZyBjbGFzcz0ianAtaWNvbi1hY2NlbnQyIiBmaWxsPSIjRkZGIj4KICAgIDxjaXJjbGUgY2xhc3M9InN0MiIgY3g9IjUuNSIgY3k9IjE0LjUiIHI9IjEuNSIvPgogICAgPHJlY3QgeD0iMTIiIHk9IjQiIGNsYXNzPSJzdDIiIHdpZHRoPSIxIiBoZWlnaHQ9IjgiLz4KICAgIDxyZWN0IHg9IjguNSIgeT0iNy41IiB0cmFuc2Zvcm09Im1hdHJpeCgwLjg2NiAtMC41IDAuNSAwLjg2NiAtMi4zMjU1IDcuMzIxOSkiIGNsYXNzPSJzdDIiIHdpZHRoPSI4IiBoZWlnaHQ9IjEiLz4KICAgIDxyZWN0IHg9IjEyIiB5PSI0IiB0cmFuc2Zvcm09Im1hdHJpeCgwLjUgLTAuODY2IDAuODY2IDAuNSAtMC42Nzc5IDE0LjgyNTIpIiBjbGFzcz0ic3QyIiB3aWR0aD0iMSIgaGVpZ2h0PSI4Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-run: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTggNXYxNGwxMS03eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-running: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDUxMiA1MTIiPgogIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICA8cGF0aCBkPSJNMjU2IDhDMTE5IDggOCAxMTkgOCAyNTZzMTExIDI0OCAyNDggMjQ4IDI0OC0xMTEgMjQ4LTI0OFMzOTMgOCAyNTYgOHptOTYgMzI4YzAgOC44LTcuMiAxNi0xNiAxNkgxNzZjLTguOCAwLTE2LTcuMi0xNi0xNlYxNzZjMC04LjggNy4yLTE2IDE2LTE2aDE2MGM4LjggMCAxNiA3LjIgMTYgMTZ2MTYweiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-save: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTE3IDNINWMtMS4xMSAwLTIgLjktMiAydjE0YzAgMS4xLjg5IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjdsLTQtNHptLTUgMTZjLTEuNjYgMC0zLTEuMzQtMy0zczEuMzQtMyAzLTMgMyAxLjM0IDMgMy0xLjM0IDMtMyAzem0zLTEwSDVWNWgxMHY0eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-search: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjEsMTAuOWgtMC43bC0wLjItMC4yYzAuOC0wLjksMS4zLTIuMiwxLjMtMy41YzAtMy0yLjQtNS40LTUuNC01LjRTMS44LDQuMiwxLjgsNy4xczIuNCw1LjQsNS40LDUuNCBjMS4zLDAsMi41LTAuNSwzLjUtMS4zbDAuMiwwLjJ2MC43bDQuMSw0LjFsMS4yLTEuMkwxMi4xLDEwLjl6IE03LjEsMTAuOWMtMi4xLDAtMy43LTEuNy0zLjctMy43czEuNy0zLjcsMy43LTMuN3MzLjcsMS43LDMuNywzLjcgUzkuMiwxMC45LDcuMSwxMC45eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-settings: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkuNDMgMTIuOThjLjA0LS4zMi4wNy0uNjQuMDctLjk4cy0uMDMtLjY2LS4wNy0uOThsMi4xMS0xLjY1Yy4xOS0uMTUuMjQtLjQyLjEyLS42NGwtMi0zLjQ2Yy0uMTItLjIyLS4zOS0uMy0uNjEtLjIybC0yLjQ5IDFjLS41Mi0uNC0xLjA4LS43My0xLjY5LS45OGwtLjM4LTIuNjVBLjQ4OC40ODggMCAwMDE0IDJoLTRjLS4yNSAwLS40Ni4xOC0uNDkuNDJsLS4zOCAyLjY1Yy0uNjEuMjUtMS4xNy41OS0xLjY5Ljk4bC0yLjQ5LTFjLS4yMy0uMDktLjQ5IDAtLjYxLjIybC0yIDMuNDZjLS4xMy4yMi0uMDcuNDkuMTIuNjRsMi4xMSAxLjY1Yy0uMDQuMzItLjA3LjY1LS4wNy45OHMuMDMuNjYuMDcuOThsLTIuMTEgMS42NWMtLjE5LjE1LS4yNC40Mi0uMTIuNjRsMiAzLjQ2Yy4xMi4yMi4zOS4zLjYxLjIybDIuNDktMWMuNTIuNCAxLjA4LjczIDEuNjkuOThsLjM4IDIuNjVjLjAzLjI0LjI0LjQyLjQ5LjQyaDRjLjI1IDAgLjQ2LS4xOC40OS0uNDJsLjM4LTIuNjVjLjYxLS4yNSAxLjE3LS41OSAxLjY5LS45OGwyLjQ5IDFjLjIzLjA5LjQ5IDAgLjYxLS4yMmwyLTMuNDZjLjEyLS4yMi4wNy0uNDktLjEyLS42NGwtMi4xMS0xLjY1ek0xMiAxNS41Yy0xLjkzIDAtMy41LTEuNTctMy41LTMuNXMxLjU3LTMuNSAzLjUtMy41IDMuNSAxLjU3IDMuNSAzLjUtMS41NyAzLjUtMy41IDMuNXoiLz4KPC9zdmc+Cg==);
  --jp-icon-share: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIHZpZXdCb3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTSAxOCAyIEMgMTYuMzU0OTkgMiAxNSAzLjM1NDk5MDQgMTUgNSBDIDE1IDUuMTkwOTUyOSAxNS4wMjE3OTEgNS4zNzcxMjI0IDE1LjA1NjY0MSA1LjU1ODU5MzggTCA3LjkyMTg3NSA5LjcyMDcwMzEgQyA3LjM5ODUzOTkgOS4yNzc4NTM5IDYuNzMyMDc3MSA5IDYgOSBDIDQuMzU0OTkwNCA5IDMgMTAuMzU0OTkgMyAxMiBDIDMgMTMuNjQ1MDEgNC4zNTQ5OTA0IDE1IDYgMTUgQyA2LjczMjA3NzEgMTUgNy4zOTg1Mzk5IDE0LjcyMjE0NiA3LjkyMTg3NSAxNC4yNzkyOTcgTCAxNS4wNTY2NDEgMTguNDM5NDUzIEMgMTUuMDIxNTU1IDE4LjYyMTUxNCAxNSAxOC44MDgzODYgMTUgMTkgQyAxNSAyMC42NDUwMSAxNi4zNTQ5OSAyMiAxOCAyMiBDIDE5LjY0NTAxIDIyIDIxIDIwLjY0NTAxIDIxIDE5IEMgMjEgMTcuMzU0OTkgMTkuNjQ1MDEgMTYgMTggMTYgQyAxNy4yNjc0OCAxNiAxNi42MDE1OTMgMTYuMjc5MzI4IDE2LjA3ODEyNSAxNi43MjI2NTYgTCA4Ljk0MzM1OTQgMTIuNTU4NTk0IEMgOC45NzgyMDk1IDEyLjM3NzEyMiA5IDEyLjE5MDk1MyA5IDEyIEMgOSAxMS44MDkwNDcgOC45NzgyMDk1IDExLjYyMjg3OCA4Ljk0MzM1OTQgMTEuNDQxNDA2IEwgMTYuMDc4MTI1IDcuMjc5Mjk2OSBDIDE2LjYwMTQ2IDcuNzIyMTQ2MSAxNy4yNjc5MjMgOCAxOCA4IEMgMTkuNjQ1MDEgOCAyMSA2LjY0NTAwOTYgMjEgNSBDIDIxIDMuMzU0OTkwNCAxOS42NDUwMSAyIDE4IDIgeiBNIDE4IDQgQyAxOC41NjQxMjkgNCAxOSA0LjQzNTg3MDYgMTkgNSBDIDE5IDUuNTY0MTI5NCAxOC41NjQxMjkgNiAxOCA2IEMgMTcuNDM1ODcxIDYgMTcgNS41NjQxMjk0IDE3IDUgQyAxNyA0LjQzNTg3MDYgMTcuNDM1ODcxIDQgMTggNCB6IE0gNiAxMSBDIDYuNTY0MTI5NCAxMSA3IDExLjQzNTg3MSA3IDEyIEMgNyAxMi41NjQxMjkgNi41NjQxMjk0IDEzIDYgMTMgQyA1LjQzNTg3MDYgMTMgNSAxMi41NjQxMjkgNSAxMiBDIDUgMTEuNDM1ODcxIDUuNDM1ODcwNiAxMSA2IDExIHogTSAxOCAxOCBDIDE4LjU2NDEyOSAxOCAxOSAxOC40MzU4NzEgMTkgMTkgQyAxOSAxOS41NjQxMjkgMTguNTY0MTI5IDIwIDE4IDIwIEMgMTcuNDM1ODcxIDIwIDE3IDE5LjU2NDEyOSAxNyAxOSBDIDE3IDE4LjQzNTg3MSAxNy40MzU4NzEgMTggMTggMTggeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-spreadsheet: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDEganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNENBRjUwIiBkPSJNMi4yIDIuMnYxNy42aDE3LjZWMi4ySDIuMnptMTUuNCA3LjdoLTUuNVY0LjRoNS41djUuNXpNOS45IDQuNHY1LjVINC40VjQuNGg1LjV6bS01LjUgNy43aDUuNXY1LjVINC40di01LjV6bTcuNyA1LjV2LTUuNWg1LjV2NS41aC01LjV6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-stop: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik02IDZoMTJ2MTJINnoiLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-tab: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIxIDNIM2MtMS4xIDAtMiAuOS0yIDJ2MTRjMCAxLjEuOSAyIDIgMmgxOGMxLjEgMCAyLS45IDItMlY1YzAtMS4xLS45LTItMi0yem0wIDE2SDNWNWgxMHY0aDh2MTB6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-table-rows: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik0yMSw4SDNWNGgxOFY4eiBNMjEsMTBIM3Y0aDE4VjEweiBNMjEsMTZIM3Y0aDE4VjE2eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-tag: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjgiIGhlaWdodD0iMjgiIHZpZXdCb3g9IjAgMCA0MyAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTI4LjgzMzIgMTIuMzM0TDMyLjk5OTggMTYuNTAwN0wzNy4xNjY1IDEyLjMzNEgyOC44MzMyWiIvPgoJCTxwYXRoIGQ9Ik0xNi4yMDk1IDIxLjYxMDRDMTUuNjg3MyAyMi4xMjk5IDE0Ljg0NDMgMjIuMTI5OSAxNC4zMjQ4IDIxLjYxMDRMNi45ODI5IDE0LjcyNDVDNi41NzI0IDE0LjMzOTQgNi4wODMxMyAxMy42MDk4IDYuMDQ3ODYgMTMuMDQ4MkM1Ljk1MzQ3IDExLjUyODggNi4wMjAwMiA4LjYxOTQ0IDYuMDY2MjEgNy4wNzY5NUM2LjA4MjgxIDYuNTE0NzcgNi41NTU0OCA2LjA0MzQ3IDcuMTE4MDQgNi4wMzA1NUM5LjA4ODYzIDUuOTg0NzMgMTMuMjYzOCA1LjkzNTc5IDEzLjY1MTggNi4zMjQyNUwyMS43MzY5IDEzLjYzOUMyMi4yNTYgMTQuMTU4NSAyMS43ODUxIDE1LjQ3MjQgMjEuMjYyIDE1Ljk5NDZMMTYuMjA5NSAyMS42MTA0Wk05Ljc3NTg1IDguMjY1QzkuMzM1NTEgNy44MjU2NiA4LjYyMzUxIDcuODI1NjYgOC4xODI4IDguMjY1QzcuNzQzNDYgOC43MDU3MSA3Ljc0MzQ2IDkuNDE3MzMgOC4xODI4IDkuODU2NjdDOC42MjM4MiAxMC4yOTY0IDkuMzM1ODIgMTAuMjk2NCA5Ljc3NTg1IDkuODU2NjdDMTAuMjE1NiA5LjQxNzMzIDEwLjIxNTYgOC43MDUzMyA5Ljc3NTg1IDguMjY1WiIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-terminal: url(data:image/svg+xml;base64,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);
  --jp-icon-text-editor: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtdGV4dC1lZGl0b3ItaWNvbi1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xNSAxNUgzdjJoMTJ2LTJ6bTAtOEgzdjJoMTJWN3pNMyAxM2gxOHYtMkgzdjJ6bTAgOGgxOHYtMkgzdjJ6TTMgM3YyaDE4VjNIM3oiLz4KPC9zdmc+Cg==);
  --jp-icon-toc: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik03LDVIMjFWN0g3VjVNNywxM1YxMUgyMVYxM0g3TTQsNC41QTEuNSwxLjUgMCAwLDEgNS41LDZBMS41LDEuNSAwIDAsMSA0LDcuNUExLjUsMS41IDAgMCwxIDIuNSw2QTEuNSwxLjUgMCAwLDEgNCw0LjVNNCwxMC41QTEuNSwxLjUgMCAwLDEgNS41LDEyQTEuNSwxLjUgMCAwLDEgNCwxMy41QTEuNSwxLjUgMCAwLDEgMi41LDEyQTEuNSwxLjUgMCAwLDEgNCwxMC41TTcsMTlWMTdIMjFWMTlIN000LDE2LjVBMS41LDEuNSAwIDAsMSA1LjUsMThBMS41LDEuNSAwIDAsMSA0LDE5LjVBMS41LDEuNSAwIDAsMSAyLjUsMThBMS41LDEuNSAwIDAsMSA0LDE2LjVaIiAvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-tree-view: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik0yMiAxMVYzaC03djNIOVYzSDJ2OGg3VjhoMnYxMGg0djNoN3YtOGgtN3YzaC0yVjhoMnYzeiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-trusted: url(data:image/svg+xml;base64,PHN2ZyBmaWxsPSJub25lIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI1Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDIgMykiIGQ9Ik0xLjg2MDk0IDExLjQ0MDlDMC44MjY0NDggOC43NzAyNyAwLjg2Mzc3OSA2LjA1NzY0IDEuMjQ5MDcgNC4xOTkzMkMyLjQ4MjA2IDMuOTMzNDcgNC4wODA2OCAzLjQwMzQ3IDUuNjAxMDIgMi44NDQ5QzcuMjM1NDkgMi4yNDQ0IDguODU2NjYgMS41ODE1IDkuOTg3NiAxLjA5NTM5QzExLjA1OTcgMS41ODM0MSAxMi42MDk0IDIuMjQ0NCAxNC4yMTggMi44NDMzOUMxNS43NTAzIDMuNDEzOTQgMTcuMzk5NSAzLjk1MjU4IDE4Ljc1MzkgNC4yMTM4NUMxOS4xMzY0IDYuMDcxNzcgMTkuMTcwOSA4Ljc3NzIyIDE4LjEzOSAxMS40NDA5QzE3LjAzMDMgMTQuMzAzMiAxNC42NjY4IDE3LjE4NDQgOS45OTk5OSAxOC45MzU0QzUuMzMzMiAxNy4xODQ0IDIuOTY5NjggMTQuMzAzMiAxLjg2MDk0IDExLjQ0MDlaIi8+CiAgICA8cGF0aCBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiMzMzMzMzMiIHN0cm9rZT0iIzMzMzMzMyIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoOCA5Ljg2NzE5KSIgZD0iTTIuODYwMTUgNC44NjUzNUwwLjcyNjU0OSAyLjk5OTU5TDAgMy42MzA0NUwyLjg2MDE1IDYuMTMxNTdMOCAwLjYzMDg3Mkw3LjI3ODU3IDBMMi44NjAxNSA0Ljg2NTM1WiIvPgo8L3N2Zz4K);
  --jp-icon-undo: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjUgOGMtMi42NSAwLTUuMDUuOTktNi45IDIuNkwyIDd2OWg5bC0zLjYyLTMuNjJjMS4zOS0xLjE2IDMuMTYtMS44OCA1LjEyLTEuODggMy41NCAwIDYuNTUgMi4zMSA3LjYgNS41bDIuMzctLjc4QzIxLjA4IDExLjAzIDE3LjE1IDggMTIuNSA4eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-user: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIHZpZXdCb3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE2IDdhNCA0IDAgMTEtOCAwIDQgNCAwIDAxOCAwek0xMiAxNGE3IDcgMCAwMC03IDdoMTRhNyA3IDAgMDAtNy03eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-users: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjQiIGhlaWdodD0iMjQiIHZlcnNpb249IjEuMSIgdmlld0JveD0iMCAwIDM2IDI0IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPgogPGcgY2xhc3M9ImpwLWljb24zIiB0cmFuc2Zvcm09Im1hdHJpeCgxLjczMjcgMCAwIDEuNzMyNyAtMy42MjgyIC4wOTk1NzcpIiBmaWxsPSIjNjE2MTYxIj4KICA8cGF0aCB0cmFuc2Zvcm09Im1hdHJpeCgxLjUsMCwwLDEuNSwwLC02KSIgZD0ibTEyLjE4NiA3LjUwOThjLTEuMDUzNSAwLTEuOTc1NyAwLjU2NjUtMi40Nzg1IDEuNDEwMiAwLjc1MDYxIDAuMzEyNzcgMS4zOTc0IDAuODI2NDggMS44NzMgMS40NzI3aDMuNDg2M2MwLTEuNTkyLTEuMjg4OS0yLjg4MjgtMi44ODA5LTIuODgyOHoiLz4KICA8cGF0aCBkPSJtMjAuNDY1IDIuMzg5NWEyLjE4ODUgMi4xODg1IDAgMCAxLTIuMTg4NCAyLjE4ODUgMi4xODg1IDIuMTg4NSAwIDAgMS0yLjE4ODUtMi4xODg1IDIuMTg4NSAyLjE4ODUgMCAwIDEgMi4xODg1LTIuMTg4NSAyLjE4ODUgMi4xODg1IDAgMCAxIDIuMTg4NCAyLjE4ODV6Ii8+CiAgPHBhdGggdHJhbnNmb3JtPSJtYXRyaXgoMS41LDAsMCwxLjUsMCwtNikiIGQ9Im0zLjU4OTggOC40MjE5Yy0xLjExMjYgMC0yLjAxMzcgMC45MDExMS0yLjAxMzcgMi4wMTM3aDIuODE0NWMwLjI2Nzk3LTAuMzczMDkgMC41OTA3LTAuNzA0MzUgMC45NTg5OC0wLjk3ODUyLTAuMzQ0MzMtMC42MTY4OC0xLjAwMzEtMS4wMzUyLTEuNzU5OC0xLjAzNTJ6Ii8+CiAgPHBhdGggZD0ibTYuOTE1NCA0LjYyM2ExLjUyOTQgMS41Mjk0IDAgMCAxLTEuNTI5NCAxLjUyOTQgMS41Mjk0IDEuNTI5NCAwIDAgMS0xLjUyOTQtMS41Mjk0IDEuNTI5NCAxLjUyOTQgMCAwIDEgMS41Mjk0LTEuNTI5NCAxLjUyOTQgMS41Mjk0IDAgMCAxIDEuNTI5NCAxLjUyOTR6Ii8+CiAgPHBhdGggZD0ibTYuMTM1IDEzLjUzNWMwLTMuMjM5MiAyLjYyNTktNS44NjUgNS44NjUtNS44NjUgMy4yMzkyIDAgNS44NjUgMi42MjU5IDUuODY1IDUuODY1eiIvPgogIDxjaXJjbGUgY3g9IjEyIiBjeT0iMy43Njg1IiByPSIyLjk2ODUiLz4KIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-vega: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbjEganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMjEyMTIxIj4KICAgIDxwYXRoIGQ9Ik0xMC42IDUuNGwyLjItMy4ySDIuMnY3LjNsNC02LjZ6Ii8+CiAgICA8cGF0aCBkPSJNMTUuOCAyLjJsLTQuNCA2LjZMNyA2LjNsLTQuOCA4djUuNWgxNy42VjIuMmgtNHptLTcgMTUuNEg1LjV2LTQuNGgzLjN2NC40em00LjQgMEg5LjhWOS44aDMuNHY3Ljh6bTQuNCAwaC0zLjRWNi41aDMuNHYxMS4xeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-word: url(data:image/svg+xml;base64,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);
  --jp-icon-yaml: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1jb250cmFzdDIganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjRDgxQjYwIj4KICAgIDxwYXRoIGQ9Ik03LjIgMTguNnYtNS40TDMgNS42aDMuM2wxLjQgMy4xYy4zLjkuNiAxLjYgMSAyLjUuMy0uOC42LTEuNiAxLTIuNWwxLjQtMy4xaDMuNGwtNC40IDcuNnY1LjVsLTIuOS0uMXoiLz4KICAgIDxjaXJjbGUgY2xhc3M9InN0MCIgY3g9IjE3LjYiIGN5PSIxNi41IiByPSIyLjEiLz4KICAgIDxjaXJjbGUgY2xhc3M9InN0MCIgY3g9IjE3LjYiIGN5PSIxMSIgcj0iMi4xIi8+CiAgPC9nPgo8L3N2Zz4K);
}

/* Icon CSS class declarations */

.jp-AddAboveIcon {
  background-image: var(--jp-icon-add-above);
}

.jp-AddBelowIcon {
  background-image: var(--jp-icon-add-below);
}

.jp-AddIcon {
  background-image: var(--jp-icon-add);
}

.jp-BellIcon {
  background-image: var(--jp-icon-bell);
}

.jp-BugDotIcon {
  background-image: var(--jp-icon-bug-dot);
}

.jp-BugIcon {
  background-image: var(--jp-icon-bug);
}

.jp-BuildIcon {
  background-image: var(--jp-icon-build);
}

.jp-CaretDownEmptyIcon {
  background-image: var(--jp-icon-caret-down-empty);
}

.jp-CaretDownEmptyThinIcon {
  background-image: var(--jp-icon-caret-down-empty-thin);
}

.jp-CaretDownIcon {
  background-image: var(--jp-icon-caret-down);
}

.jp-CaretLeftIcon {
  background-image: var(--jp-icon-caret-left);
}

.jp-CaretRightIcon {
  background-image: var(--jp-icon-caret-right);
}

.jp-CaretUpEmptyThinIcon {
  background-image: var(--jp-icon-caret-up-empty-thin);
}

.jp-CaretUpIcon {
  background-image: var(--jp-icon-caret-up);
}

.jp-CaseSensitiveIcon {
  background-image: var(--jp-icon-case-sensitive);
}

.jp-CheckIcon {
  background-image: var(--jp-icon-check);
}

.jp-CircleEmptyIcon {
  background-image: var(--jp-icon-circle-empty);
}

.jp-CircleIcon {
  background-image: var(--jp-icon-circle);
}

.jp-ClearIcon {
  background-image: var(--jp-icon-clear);
}

.jp-CloseIcon {
  background-image: var(--jp-icon-close);
}

.jp-CodeCheckIcon {
  background-image: var(--jp-icon-code-check);
}

.jp-CodeIcon {
  background-image: var(--jp-icon-code);
}

.jp-CollapseAllIcon {
  background-image: var(--jp-icon-collapse-all);
}

.jp-ConsoleIcon {
  background-image: var(--jp-icon-console);
}

.jp-CopyIcon {
  background-image: var(--jp-icon-copy);
}

.jp-CopyrightIcon {
  background-image: var(--jp-icon-copyright);
}

.jp-CutIcon {
  background-image: var(--jp-icon-cut);
}

.jp-DeleteIcon {
  background-image: var(--jp-icon-delete);
}

.jp-DownloadIcon {
  background-image: var(--jp-icon-download);
}

.jp-DuplicateIcon {
  background-image: var(--jp-icon-duplicate);
}

.jp-EditIcon {
  background-image: var(--jp-icon-edit);
}

.jp-EllipsesIcon {
  background-image: var(--jp-icon-ellipses);
}

.jp-ErrorIcon {
  background-image: var(--jp-icon-error);
}

.jp-ExpandAllIcon {
  background-image: var(--jp-icon-expand-all);
}

.jp-ExtensionIcon {
  background-image: var(--jp-icon-extension);
}

.jp-FastForwardIcon {
  background-image: var(--jp-icon-fast-forward);
}

.jp-FileIcon {
  background-image: var(--jp-icon-file);
}

.jp-FileUploadIcon {
  background-image: var(--jp-icon-file-upload);
}

.jp-FilterDotIcon {
  background-image: var(--jp-icon-filter-dot);
}

.jp-FilterIcon {
  background-image: var(--jp-icon-filter);
}

.jp-FilterListIcon {
  background-image: var(--jp-icon-filter-list);
}

.jp-FolderFavoriteIcon {
  background-image: var(--jp-icon-folder-favorite);
}

.jp-FolderIcon {
  background-image: var(--jp-icon-folder);
}

.jp-HomeIcon {
  background-image: var(--jp-icon-home);
}

.jp-Html5Icon {
  background-image: var(--jp-icon-html5);
}

.jp-ImageIcon {
  background-image: var(--jp-icon-image);
}

.jp-InfoIcon {
  background-image: var(--jp-icon-info);
}

.jp-InspectorIcon {
  background-image: var(--jp-icon-inspector);
}

.jp-JsonIcon {
  background-image: var(--jp-icon-json);
}

.jp-JuliaIcon {
  background-image: var(--jp-icon-julia);
}

.jp-JupyterFaviconIcon {
  background-image: var(--jp-icon-jupyter-favicon);
}

.jp-JupyterIcon {
  background-image: var(--jp-icon-jupyter);
}

.jp-JupyterlabWordmarkIcon {
  background-image: var(--jp-icon-jupyterlab-wordmark);
}

.jp-KernelIcon {
  background-image: var(--jp-icon-kernel);
}

.jp-KeyboardIcon {
  background-image: var(--jp-icon-keyboard);
}

.jp-LaunchIcon {
  background-image: var(--jp-icon-launch);
}

.jp-LauncherIcon {
  background-image: var(--jp-icon-launcher);
}

.jp-LineFormIcon {
  background-image: var(--jp-icon-line-form);
}

.jp-LinkIcon {
  background-image: var(--jp-icon-link);
}

.jp-ListIcon {
  background-image: var(--jp-icon-list);
}

.jp-MarkdownIcon {
  background-image: var(--jp-icon-markdown);
}

.jp-MoveDownIcon {
  background-image: var(--jp-icon-move-down);
}

.jp-MoveUpIcon {
  background-image: var(--jp-icon-move-up);
}

.jp-NewFolderIcon {
  background-image: var(--jp-icon-new-folder);
}

.jp-NotTrustedIcon {
  background-image: var(--jp-icon-not-trusted);
}

.jp-NotebookIcon {
  background-image: var(--jp-icon-notebook);
}

.jp-NumberingIcon {
  background-image: var(--jp-icon-numbering);
}

.jp-OfflineBoltIcon {
  background-image: var(--jp-icon-offline-bolt);
}

.jp-PaletteIcon {
  background-image: var(--jp-icon-palette);
}

.jp-PasteIcon {
  background-image: var(--jp-icon-paste);
}

.jp-PdfIcon {
  background-image: var(--jp-icon-pdf);
}

.jp-PythonIcon {
  background-image: var(--jp-icon-python);
}

.jp-RKernelIcon {
  background-image: var(--jp-icon-r-kernel);
}

.jp-ReactIcon {
  background-image: var(--jp-icon-react);
}

.jp-RedoIcon {
  background-image: var(--jp-icon-redo);
}

.jp-RefreshIcon {
  background-image: var(--jp-icon-refresh);
}

.jp-RegexIcon {
  background-image: var(--jp-icon-regex);
}

.jp-RunIcon {
  background-image: var(--jp-icon-run);
}

.jp-RunningIcon {
  background-image: var(--jp-icon-running);
}

.jp-SaveIcon {
  background-image: var(--jp-icon-save);
}

.jp-SearchIcon {
  background-image: var(--jp-icon-search);
}

.jp-SettingsIcon {
  background-image: var(--jp-icon-settings);
}

.jp-ShareIcon {
  background-image: var(--jp-icon-share);
}

.jp-SpreadsheetIcon {
  background-image: var(--jp-icon-spreadsheet);
}

.jp-StopIcon {
  background-image: var(--jp-icon-stop);
}

.jp-TabIcon {
  background-image: var(--jp-icon-tab);
}

.jp-TableRowsIcon {
  background-image: var(--jp-icon-table-rows);
}

.jp-TagIcon {
  background-image: var(--jp-icon-tag);
}

.jp-TerminalIcon {
  background-image: var(--jp-icon-terminal);
}

.jp-TextEditorIcon {
  background-image: var(--jp-icon-text-editor);
}

.jp-TocIcon {
  background-image: var(--jp-icon-toc);
}

.jp-TreeViewIcon {
  background-image: var(--jp-icon-tree-view);
}

.jp-TrustedIcon {
  background-image: var(--jp-icon-trusted);
}

.jp-UndoIcon {
  background-image: var(--jp-icon-undo);
}

.jp-UserIcon {
  background-image: var(--jp-icon-user);
}

.jp-UsersIcon {
  background-image: var(--jp-icon-users);
}

.jp-VegaIcon {
  background-image: var(--jp-icon-vega);
}

.jp-WordIcon {
  background-image: var(--jp-icon-word);
}

.jp-YamlIcon {
  background-image: var(--jp-icon-yaml);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * (DEPRECATED) Support for consuming icons as CSS background images
 */

.jp-Icon,
.jp-MaterialIcon {
  background-position: center;
  background-repeat: no-repeat;
  background-size: 16px;
  min-width: 16px;
  min-height: 16px;
}

.jp-Icon-cover {
  background-position: center;
  background-repeat: no-repeat;
  background-size: cover;
}

/**
 * (DEPRECATED) Support for specific CSS icon sizes
 */

.jp-Icon-16 {
  background-size: 16px;
  min-width: 16px;
  min-height: 16px;
}

.jp-Icon-18 {
  background-size: 18px;
  min-width: 18px;
  min-height: 18px;
}

.jp-Icon-20 {
  background-size: 20px;
  min-width: 20px;
  min-height: 20px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.lm-TabBar .lm-TabBar-addButton {
  align-items: center;
  display: flex;
  padding: 4px;
  padding-bottom: 5px;
  margin-right: 1px;
  background-color: var(--jp-layout-color2);
}

.lm-TabBar .lm-TabBar-addButton:hover {
  background-color: var(--jp-layout-color1);
}

.lm-DockPanel-tabBar .lm-TabBar-tab {
  width: var(--jp-private-horizontal-tab-width);
}

.lm-DockPanel-tabBar .lm-TabBar-content {
  flex: unset;
}

.lm-DockPanel-tabBar[data-orientation='horizontal'] {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * Support for icons as inline SVG HTMLElements
 */

/* recolor the primary elements of an icon */
.jp-icon0[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon1[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon2[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon3[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon4[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon0[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon1[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon2[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon3[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon4[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/* recolor the accent elements of an icon */
.jp-icon-accent0[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-accent1[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-accent2[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-accent3[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-accent4[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-accent0[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-accent1[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-accent2[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-accent3[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-accent4[stroke] {
  stroke: var(--jp-layout-color4);
}

/* set the color of an icon to transparent */
.jp-icon-none[fill] {
  fill: none;
}

.jp-icon-none[stroke] {
  stroke: none;
}

/* brand icon colors. Same for light and dark */
.jp-icon-brand0[fill] {
  fill: var(--jp-brand-color0);
}

.jp-icon-brand1[fill] {
  fill: var(--jp-brand-color1);
}

.jp-icon-brand2[fill] {
  fill: var(--jp-brand-color2);
}

.jp-icon-brand3[fill] {
  fill: var(--jp-brand-color3);
}

.jp-icon-brand4[fill] {
  fill: var(--jp-brand-color4);
}

.jp-icon-brand0[stroke] {
  stroke: var(--jp-brand-color0);
}

.jp-icon-brand1[stroke] {
  stroke: var(--jp-brand-color1);
}

.jp-icon-brand2[stroke] {
  stroke: var(--jp-brand-color2);
}

.jp-icon-brand3[stroke] {
  stroke: var(--jp-brand-color3);
}

.jp-icon-brand4[stroke] {
  stroke: var(--jp-brand-color4);
}

/* warn icon colors. Same for light and dark */
.jp-icon-warn0[fill] {
  fill: var(--jp-warn-color0);
}

.jp-icon-warn1[fill] {
  fill: var(--jp-warn-color1);
}

.jp-icon-warn2[fill] {
  fill: var(--jp-warn-color2);
}

.jp-icon-warn3[fill] {
  fill: var(--jp-warn-color3);
}

.jp-icon-warn0[stroke] {
  stroke: var(--jp-warn-color0);
}

.jp-icon-warn1[stroke] {
  stroke: var(--jp-warn-color1);
}

.jp-icon-warn2[stroke] {
  stroke: var(--jp-warn-color2);
}

.jp-icon-warn3[stroke] {
  stroke: var(--jp-warn-color3);
}

/* icon colors that contrast well with each other and most backgrounds */
.jp-icon-contrast0[fill] {
  fill: var(--jp-icon-contrast-color0);
}

.jp-icon-contrast1[fill] {
  fill: var(--jp-icon-contrast-color1);
}

.jp-icon-contrast2[fill] {
  fill: var(--jp-icon-contrast-color2);
}

.jp-icon-contrast3[fill] {
  fill: var(--jp-icon-contrast-color3);
}

.jp-icon-contrast0[stroke] {
  stroke: var(--jp-icon-contrast-color0);
}

.jp-icon-contrast1[stroke] {
  stroke: var(--jp-icon-contrast-color1);
}

.jp-icon-contrast2[stroke] {
  stroke: var(--jp-icon-contrast-color2);
}

.jp-icon-contrast3[stroke] {
  stroke: var(--jp-icon-contrast-color3);
}

.jp-icon-dot[fill] {
  fill: var(--jp-warn-color0);
}

.jp-jupyter-icon-color[fill] {
  fill: var(--jp-jupyter-icon-color, var(--jp-warn-color0));
}

.jp-notebook-icon-color[fill] {
  fill: var(--jp-notebook-icon-color, var(--jp-warn-color0));
}

.jp-json-icon-color[fill] {
  fill: var(--jp-json-icon-color, var(--jp-warn-color1));
}

.jp-console-icon-color[fill] {
  fill: var(--jp-console-icon-color, white);
}

.jp-console-icon-background-color[fill] {
  fill: var(--jp-console-icon-background-color, var(--jp-brand-color1));
}

.jp-terminal-icon-color[fill] {
  fill: var(--jp-terminal-icon-color, var(--jp-layout-color2));
}

.jp-terminal-icon-background-color[fill] {
  fill: var(
    --jp-terminal-icon-background-color,
    var(--jp-inverse-layout-color2)
  );
}

.jp-text-editor-icon-color[fill] {
  fill: var(--jp-text-editor-icon-color, var(--jp-inverse-layout-color3));
}

.jp-inspector-icon-color[fill] {
  fill: var(--jp-inspector-icon-color, var(--jp-inverse-layout-color3));
}

/* CSS for icons in selected filebrowser listing items */
.jp-DirListing-item.jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}

.jp-DirListing-item.jp-mod-selected .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}

/* stylelint-disable selector-max-class, selector-max-compound-selectors */

/**
* TODO: come up with non css-hack solution for showing the busy icon on top
*  of the close icon
* CSS for complex behavior of close icon of tabs in the main area tabbar
*/
.lm-DockPanel-tabBar
  .lm-TabBar-tab.lm-mod-closable.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon3[fill] {
  fill: none;
}

.lm-DockPanel-tabBar
  .lm-TabBar-tab.lm-mod-closable.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon-busy[fill] {
  fill: var(--jp-inverse-layout-color3);
}

/* stylelint-enable selector-max-class, selector-max-compound-selectors */

/* CSS for icons in status bar */
#jp-main-statusbar .jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}

#jp-main-statusbar .jp-mod-selected .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}

/* special handling for splash icon CSS. While the theme CSS reloads during
   splash, the splash icon can loose theming. To prevent that, we set a
   default for its color variable */
:root {
  --jp-warn-color0: var(--md-orange-700);
}

/* not sure what to do with this one, used in filebrowser listing */
.jp-DragIcon {
  margin-right: 4px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * Support for alt colors for icons as inline SVG HTMLElements
 */

/* alt recolor the primary elements of an icon */
.jp-icon-alt .jp-icon0[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-alt .jp-icon1[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-alt .jp-icon2[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-alt .jp-icon3[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-alt .jp-icon4[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-alt .jp-icon0[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-alt .jp-icon1[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-alt .jp-icon2[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-alt .jp-icon3[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-alt .jp-icon4[stroke] {
  stroke: var(--jp-layout-color4);
}

/* alt recolor the accent elements of an icon */
.jp-icon-alt .jp-icon-accent0[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon-alt .jp-icon-accent1[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon-alt .jp-icon-accent2[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon-alt .jp-icon-accent3[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon-alt .jp-icon-accent4[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-alt .jp-icon-accent0[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon-alt .jp-icon-accent1[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon-alt .jp-icon-accent2[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon-alt .jp-icon-accent3[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon-alt .jp-icon-accent4[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-icon-hoverShow:not(:hover) .jp-icon-hoverShow-content {
  display: none !important;
}

/**
 * Support for hover colors for icons as inline SVG HTMLElements
 */

/**
 * regular colors
 */

/* recolor the primary elements of an icon */
.jp-icon-hover :hover .jp-icon0-hover[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon-hover :hover .jp-icon1-hover[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon-hover :hover .jp-icon2-hover[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon-hover :hover .jp-icon3-hover[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon-hover :hover .jp-icon4-hover[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-hover :hover .jp-icon0-hover[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon-hover :hover .jp-icon1-hover[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon-hover :hover .jp-icon2-hover[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon-hover :hover .jp-icon3-hover[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon-hover :hover .jp-icon4-hover[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/* recolor the accent elements of an icon */
.jp-icon-hover :hover .jp-icon-accent0-hover[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-hover :hover .jp-icon-accent1-hover[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-hover :hover .jp-icon-accent2-hover[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-hover :hover .jp-icon-accent3-hover[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-hover :hover .jp-icon-accent4-hover[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-hover :hover .jp-icon-accent0-hover[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-hover :hover .jp-icon-accent1-hover[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-hover :hover .jp-icon-accent2-hover[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-hover :hover .jp-icon-accent3-hover[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-hover :hover .jp-icon-accent4-hover[stroke] {
  stroke: var(--jp-layout-color4);
}

/* set the color of an icon to transparent */
.jp-icon-hover :hover .jp-icon-none-hover[fill] {
  fill: none;
}

.jp-icon-hover :hover .jp-icon-none-hover[stroke] {
  stroke: none;
}

/**
 * inverse colors
 */

/* inverse recolor the primary elements of an icon */
.jp-icon-hover.jp-icon-alt :hover .jp-icon0-hover[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon1-hover[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon2-hover[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon3-hover[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon4-hover[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon0-hover[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon1-hover[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon2-hover[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon3-hover[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon4-hover[stroke] {
  stroke: var(--jp-layout-color4);
}

/* inverse recolor the accent elements of an icon */
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent0-hover[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent1-hover[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent2-hover[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent3-hover[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent4-hover[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent0-hover[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent1-hover[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent2-hover[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent3-hover[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent4-hover[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-IFrame {
  width: 100%;
  height: 100%;
}

.jp-IFrame > iframe {
  border: none;
}

/*
When drag events occur, `lm-mod-override-cursor` is added to the body.
Because iframes steal all cursor events, the following two rules are necessary
to suppress pointer events while resize drags are occurring. There may be a
better solution to this problem.
*/
body.lm-mod-override-cursor .jp-IFrame {
  position: relative;
}

body.lm-mod-override-cursor .jp-IFrame::before {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-HoverBox {
  position: fixed;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-FormGroup-content fieldset {
  border: none;
  padding: 0;
  min-width: 0;
  width: 100%;
}

/* stylelint-disable selector-max-type */

.jp-FormGroup-content fieldset .jp-inputFieldWrapper input,
.jp-FormGroup-content fieldset .jp-inputFieldWrapper select,
.jp-FormGroup-content fieldset .jp-inputFieldWrapper textarea {
  font-size: var(--jp-content-font-size2);
  border-color: var(--jp-input-border-color);
  border-style: solid;
  border-radius: var(--jp-border-radius);
  border-width: 1px;
  padding: 6px 8px;
  background: none;
  color: var(--jp-ui-font-color0);
  height: inherit;
}

.jp-FormGroup-content fieldset input[type='checkbox'] {
  position: relative;
  top: 2px;
  margin-left: 0;
}

.jp-FormGroup-content button.jp-mod-styled {
  cursor: pointer;
}

.jp-FormGroup-content .checkbox label {
  cursor: pointer;
  font-size: var(--jp-content-font-size1);
}

.jp-FormGroup-content .jp-root > fieldset > legend {
  display: none;
}

.jp-FormGroup-content .jp-root > fieldset > p {
  display: none;
}

/** copy of `input.jp-mod-styled:focus` style */
.jp-FormGroup-content fieldset input:focus,
.jp-FormGroup-content fieldset select:focus {
  -moz-outline-radius: unset;
  outline: var(--jp-border-width) solid var(--md-blue-500);
  outline-offset: -1px;
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-FormGroup-content fieldset input:hover:not(:focus),
.jp-FormGroup-content fieldset select:hover:not(:focus) {
  background-color: var(--jp-border-color2);
}

/* stylelint-enable selector-max-type */

.jp-FormGroup-content .checkbox .field-description {
  /* Disable default description field for checkbox:
   because other widgets do not have description fields,
   we add descriptions to each widget on the field level.
  */
  display: none;
}

.jp-FormGroup-content #root__description {
  display: none;
}

.jp-FormGroup-content .jp-modifiedIndicator {
  width: 5px;
  background-color: var(--jp-brand-color2);
  margin-top: 0;
  margin-left: calc(var(--jp-private-settingeditor-modifier-indent) * -1);
  flex-shrink: 0;
}

.jp-FormGroup-content .jp-modifiedIndicator.jp-errorIndicator {
  background-color: var(--jp-error-color0);
  margin-right: 0.5em;
}

/* RJSF ARRAY style */

.jp-arrayFieldWrapper legend {
  font-size: var(--jp-content-font-size2);
  color: var(--jp-ui-font-color0);
  flex-basis: 100%;
  padding: 4px 0;
  font-weight: var(--jp-content-heading-font-weight);
  border-bottom: 1px solid var(--jp-border-color2);
}

.jp-arrayFieldWrapper .field-description {
  padding: 4px 0;
  white-space: pre-wrap;
}

.jp-arrayFieldWrapper .array-item {
  width: 100%;
  border: 1px solid var(--jp-border-color2);
  border-radius: 4px;
  margin: 4px;
}

.jp-ArrayOperations {
  display: flex;
  margin-left: 8px;
}

.jp-ArrayOperationsButton {
  margin: 2px;
}

.jp-ArrayOperationsButton .jp-icon3[fill] {
  fill: var(--jp-ui-font-color0);
}

button.jp-ArrayOperationsButton.jp-mod-styled:disabled {
  cursor: not-allowed;
  opacity: 0.5;
}

/* RJSF form validation error */

.jp-FormGroup-content .validationErrors {
  color: var(--jp-error-color0);
}

/* Hide panel level error as duplicated the field level error */
.jp-FormGroup-content .panel.errors {
  display: none;
}

/* RJSF normal content (settings-editor) */

.jp-FormGroup-contentNormal {
  display: flex;
  align-items: center;
  flex-wrap: wrap;
}

.jp-FormGroup-contentNormal .jp-FormGroup-contentItem {
  margin-left: 7px;
  color: var(--jp-ui-font-color0);
}

.jp-FormGroup-contentNormal .jp-FormGroup-description {
  flex-basis: 100%;
  padding: 4px 7px;
}

.jp-FormGroup-contentNormal .jp-FormGroup-default {
  flex-basis: 100%;
  padding: 4px 7px;
}

.jp-FormGroup-contentNormal .jp-FormGroup-fieldLabel {
  font-size: var(--jp-content-font-size1);
  font-weight: normal;
  min-width: 120px;
}

.jp-FormGroup-contentNormal fieldset:not(:first-child) {
  margin-left: 7px;
}

.jp-FormGroup-contentNormal .field-array-of-string .array-item {
  /* Display `jp-ArrayOperations` buttons side-by-side with content except
    for small screens where flex-wrap will place them one below the other.
  */
  display: flex;
  align-items: center;
  flex-wrap: wrap;
}

.jp-FormGroup-contentNormal .jp-objectFieldWrapper .form-group {
  padding: 2px 8px 2px var(--jp-private-settingeditor-modifier-indent);
  margin-top: 2px;
}

/* RJSF compact content (metadata-form) */

.jp-FormGroup-content.jp-FormGroup-contentCompact {
  width: 100%;
}

.jp-FormGroup-contentCompact .form-group {
  display: flex;
  padding: 0.5em 0.2em 0.5em 0;
}

.jp-FormGroup-contentCompact
  .jp-FormGroup-compactTitle
  .jp-FormGroup-description {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color2);
}

.jp-FormGroup-contentCompact .jp-FormGroup-fieldLabel {
  padding-bottom: 0.3em;
}

.jp-FormGroup-contentCompact .jp-inputFieldWrapper .form-control {
  width: 100%;
  box-sizing: border-box;
}

.jp-FormGroup-contentCompact .jp-arrayFieldWrapper .jp-FormGroup-compactTitle {
  padding-bottom: 7px;
}

.jp-FormGroup-contentCompact
  .jp-objectFieldWrapper
  .jp-objectFieldWrapper
  .form-group {
  padding: 2px 8px 2px var(--jp-private-settingeditor-modifier-indent);
  margin-top: 2px;
}

.jp-FormGroup-contentCompact ul.error-detail {
  margin-block-start: 0.5em;
  margin-block-end: 0.5em;
  padding-inline-start: 1em;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-SidePanel {
  display: flex;
  flex-direction: column;
  min-width: var(--jp-sidebar-min-width);
  overflow-y: auto;
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);
  font-size: var(--jp-ui-font-size1);
}

.jp-SidePanel-header {
  flex: 0 0 auto;
  display: flex;
  border-bottom: var(--jp-border-width) solid var(--jp-border-color2);
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  letter-spacing: 1px;
  margin: 0;
  padding: 2px;
  text-transform: uppercase;
}

.jp-SidePanel-toolbar {
  flex: 0 0 auto;
}

.jp-SidePanel-content {
  flex: 1 1 auto;
}

.jp-SidePanel-toolbar,
.jp-AccordionPanel-toolbar {
  height: var(--jp-private-toolbar-height);
}

.jp-SidePanel-toolbar.jp-Toolbar-micro {
  display: none;
}

.lm-AccordionPanel .jp-AccordionPanel-title {
  box-sizing: border-box;
  line-height: 25px;
  margin: 0;
  display: flex;
  align-items: center;
  background: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  font-size: var(--jp-ui-font-size0);
}

.jp-AccordionPanel-title {
  cursor: pointer;
  user-select: none;
  -moz-user-select: none;
  -webkit-user-select: none;
  text-transform: uppercase;
}

.lm-AccordionPanel[data-orientation='horizontal'] > .jp-AccordionPanel-title {
  /* Title is rotated for horizontal accordion panel using CSS */
  display: block;
  transform-origin: top left;
  transform: rotate(-90deg) translate(-100%);
}

.jp-AccordionPanel-title .lm-AccordionPanel-titleLabel {
  user-select: none;
  text-overflow: ellipsis;
  white-space: nowrap;
  overflow: hidden;
}

.jp-AccordionPanel-title .lm-AccordionPanel-titleCollapser {
  transform: rotate(-90deg);
  margin: auto 0;
  height: 16px;
}

.jp-AccordionPanel-title.lm-mod-expanded .lm-AccordionPanel-titleCollapser {
  transform: rotate(0deg);
}

.lm-AccordionPanel .jp-AccordionPanel-toolbar {
  background: none;
  box-shadow: none;
  border: none;
  margin-left: auto;
}

.lm-AccordionPanel .lm-SplitPanel-handle:hover {
  background: var(--jp-layout-color3);
}

.jp-text-truncated {
  overflow: hidden;
  text-overflow: ellipsis;
  white-space: nowrap;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Spinner {
  position: absolute;
  display: flex;
  justify-content: center;
  align-items: center;
  z-index: 10;
  left: 0;
  top: 0;
  width: 100%;
  height: 100%;
  background: var(--jp-layout-color0);
  outline: none;
}

.jp-SpinnerContent {
  font-size: 10px;
  margin: 50px auto;
  text-indent: -9999em;
  width: 3em;
  height: 3em;
  border-radius: 50%;
  background: var(--jp-brand-color3);
  background: linear-gradient(
    to right,
    #f37626 10%,
    rgba(255, 255, 255, 0) 42%
  );
  position: relative;
  animation: load3 1s infinite linear, fadeIn 1s;
}

.jp-SpinnerContent::before {
  width: 50%;
  height: 50%;
  background: #f37626;
  border-radius: 100% 0 0;
  position: absolute;
  top: 0;
  left: 0;
  content: '';
}

.jp-SpinnerContent::after {
  background: var(--jp-layout-color0);
  width: 75%;
  height: 75%;
  border-radius: 50%;
  content: '';
  margin: auto;
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  right: 0;
}

@keyframes fadeIn {
  0% {
    opacity: 0;
  }

  100% {
    opacity: 1;
  }
}

@keyframes load3 {
  0% {
    transform: rotate(0deg);
  }

  100% {
    transform: rotate(360deg);
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

button.jp-mod-styled {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  border: none;
  box-sizing: border-box;
  text-align: center;
  line-height: 32px;
  height: 32px;
  padding: 0 12px;
  letter-spacing: 0.8px;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

input.jp-mod-styled {
  background: var(--jp-input-background);
  height: 28px;
  box-sizing: border-box;
  border: var(--jp-border-width) solid var(--jp-border-color1);
  padding-left: 7px;
  padding-right: 7px;
  font-size: var(--jp-ui-font-size2);
  color: var(--jp-ui-font-color0);
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

input[type='checkbox'].jp-mod-styled {
  appearance: checkbox;
  -webkit-appearance: checkbox;
  -moz-appearance: checkbox;
  height: auto;
}

input.jp-mod-styled:focus {
  border: var(--jp-border-width) solid var(--md-blue-500);
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-select-wrapper {
  display: flex;
  position: relative;
  flex-direction: column;
  padding: 1px;
  background-color: var(--jp-layout-color1);
  box-sizing: border-box;
  margin-bottom: 12px;
}

.jp-select-wrapper:not(.multiple) {
  height: 28px;
}

.jp-select-wrapper.jp-mod-focused select.jp-mod-styled {
  border: var(--jp-border-width) solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
  background-color: var(--jp-input-active-background);
}

select.jp-mod-styled:hover {
  cursor: pointer;
  color: var(--jp-ui-font-color0);
  background-color: var(--jp-input-hover-background);
  box-shadow: inset 0 0 1px rgba(0, 0, 0, 0.5);
}

select.jp-mod-styled {
  flex: 1 1 auto;
  width: 100%;
  font-size: var(--jp-ui-font-size2);
  background: var(--jp-input-background);
  color: var(--jp-ui-font-color0);
  padding: 0 25px 0 8px;
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  border-radius: 0;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

select.jp-mod-styled:not([multiple]) {
  height: 32px;
}

select.jp-mod-styled[multiple] {
  max-height: 200px;
  overflow-y: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-switch {
  display: flex;
  align-items: center;
  padding-left: 4px;
  padding-right: 4px;
  font-size: var(--jp-ui-font-size1);
  background-color: transparent;
  color: var(--jp-ui-font-color1);
  border: none;
  height: 20px;
}

.jp-switch:hover {
  background-color: var(--jp-layout-color2);
}

.jp-switch-label {
  margin-right: 5px;
  font-family: var(--jp-ui-font-family);
}

.jp-switch-track {
  cursor: pointer;
  background-color: var(--jp-switch-color, var(--jp-border-color1));
  -webkit-transition: 0.4s;
  transition: 0.4s;
  border-radius: 34px;
  height: 16px;
  width: 35px;
  position: relative;
}

.jp-switch-track::before {
  content: '';
  position: absolute;
  height: 10px;
  width: 10px;
  margin: 3px;
  left: 0;
  background-color: var(--jp-ui-inverse-font-color1);
  -webkit-transition: 0.4s;
  transition: 0.4s;
  border-radius: 50%;
}

.jp-switch[aria-checked='true'] .jp-switch-track {
  background-color: var(--jp-switch-true-position-color, var(--jp-warn-color0));
}

.jp-switch[aria-checked='true'] .jp-switch-track::before {
  /* track width (35) - margins (3 + 3) - thumb width (10) */
  left: 19px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

:root {
  --jp-private-toolbar-height: calc(
    28px + var(--jp-border-width)
  ); /* leave 28px for content */
}

.jp-Toolbar {
  color: var(--jp-ui-font-color1);
  flex: 0 0 auto;
  display: flex;
  flex-direction: row;
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  background: var(--jp-toolbar-background);
  min-height: var(--jp-toolbar-micro-height);
  padding: 2px;
  z-index: 8;
  overflow-x: hidden;
}

/* Toolbar items */

.jp-Toolbar > .jp-Toolbar-item.jp-Toolbar-spacer {
  flex-grow: 1;
  flex-shrink: 1;
}

.jp-Toolbar-item.jp-Toolbar-kernelStatus {
  display: inline-block;
  width: 32px;
  background-repeat: no-repeat;
  background-position: center;
  background-size: 16px;
}

.jp-Toolbar > .jp-Toolbar-item {
  flex: 0 0 auto;
  display: flex;
  padding-left: 1px;
  padding-right: 1px;
  font-size: var(--jp-ui-font-size1);
  line-height: var(--jp-private-toolbar-height);
  height: 100%;
}

/* Toolbar buttons */

/* This is the div we use to wrap the react component into a Widget */
div.jp-ToolbarButton {
  color: transparent;
  border: none;
  box-sizing: border-box;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
  padding: 0;
  margin: 0;
}

button.jp-ToolbarButtonComponent {
  background: var(--jp-layout-color1);
  border: none;
  box-sizing: border-box;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
  padding: 0 6px;
  margin: 0;
  height: 24px;
  border-radius: var(--jp-border-radius);
  display: flex;
  align-items: center;
  text-align: center;
  font-size: 14px;
  min-width: unset;
  min-height: unset;
}

button.jp-ToolbarButtonComponent:disabled {
  opacity: 0.4;
}

button.jp-ToolbarButtonComponent > span {
  padding: 0;
  flex: 0 0 auto;
}

button.jp-ToolbarButtonComponent .jp-ToolbarButtonComponent-label {
  font-size: var(--jp-ui-font-size1);
  line-height: 100%;
  padding-left: 2px;
  color: var(--jp-ui-font-color1);
  font-family: var(--jp-ui-font-family);
}

#jp-main-dock-panel[data-mode='single-document']
  .jp-MainAreaWidget
  > .jp-Toolbar.jp-Toolbar-micro {
  padding: 0;
  min-height: 0;
}

#jp-main-dock-panel[data-mode='single-document']
  .jp-MainAreaWidget
  > .jp-Toolbar {
  border: none;
  box-shadow: none;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-WindowedPanel-outer {
  position: relative;
  overflow-y: auto;
}

.jp-WindowedPanel-inner {
  position: relative;
}

.jp-WindowedPanel-window {
  position: absolute;
  left: 0;
  right: 0;
  overflow: visible;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* Sibling imports */

body {
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
}

/* Disable native link decoration styles everywhere outside of dialog boxes */
a {
  text-decoration: unset;
  color: unset;
}

a:hover {
  text-decoration: unset;
  color: unset;
}

/* Accessibility for links inside dialog box text */
.jp-Dialog-content a {
  text-decoration: revert;
  color: var(--jp-content-link-color);
}

.jp-Dialog-content a:hover {
  text-decoration: revert;
}

/* Styles for ui-components */
.jp-Button {
  color: var(--jp-ui-font-color2);
  border-radius: var(--jp-border-radius);
  padding: 0 12px;
  font-size: var(--jp-ui-font-size1);

  /* Copy from blueprint 3 */
  display: inline-flex;
  flex-direction: row;
  border: none;
  cursor: pointer;
  align-items: center;
  justify-content: center;
  text-align: left;
  vertical-align: middle;
  min-height: 30px;
  min-width: 30px;
}

.jp-Button:disabled {
  cursor: not-allowed;
}

.jp-Button:empty {
  padding: 0 !important;
}

.jp-Button.jp-mod-small {
  min-height: 24px;
  min-width: 24px;
  font-size: 12px;
  padding: 0 7px;
}

/* Use our own theme for hover styles */
.jp-Button.jp-mod-minimal:hover {
  background-color: var(--jp-layout-color2);
}

.jp-Button.jp-mod-minimal {
  background: none;
}

.jp-InputGroup {
  display: block;
  position: relative;
}

.jp-InputGroup input {
  box-sizing: border-box;
  border: none;
  border-radius: 0;
  background-color: transparent;
  color: var(--jp-ui-font-color0);
  box-shadow: inset 0 0 0 var(--jp-border-width) var(--jp-input-border-color);
  padding-bottom: 0;
  padding-top: 0;
  padding-left: 10px;
  padding-right: 28px;
  position: relative;
  width: 100%;
  -webkit-appearance: none;
  -moz-appearance: none;
  appearance: none;
  font-size: 14px;
  font-weight: 400;
  height: 30px;
  line-height: 30px;
  outline: none;
  vertical-align: middle;
}

.jp-InputGroup input:focus {
  box-shadow: inset 0 0 0 var(--jp-border-width)
      var(--jp-input-active-box-shadow-color),
    inset 0 0 0 3px var(--jp-input-active-box-shadow-color);
}

.jp-InputGroup input:disabled {
  cursor: not-allowed;
  resize: block;
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color2);
}

.jp-InputGroup input:disabled ~ span {
  cursor: not-allowed;
  color: var(--jp-ui-font-color2);
}

.jp-InputGroup input::placeholder,
input::placeholder {
  color: var(--jp-ui-font-color2);
}

.jp-InputGroupAction {
  position: absolute;
  bottom: 1px;
  right: 0;
  padding: 6px;
}

.jp-HTMLSelect.jp-DefaultStyle select {
  background-color: initial;
  border: none;
  border-radius: 0;
  box-shadow: none;
  color: var(--jp-ui-font-color0);
  display: block;
  font-size: var(--jp-ui-font-size1);
  font-family: var(--jp-ui-font-family);
  height: 24px;
  line-height: 14px;
  padding: 0 25px 0 10px;
  text-align: left;
  -moz-appearance: none;
  -webkit-appearance: none;
}

.jp-HTMLSelect.jp-DefaultStyle select:disabled {
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color2);
  cursor: not-allowed;
  resize: block;
}

.jp-HTMLSelect.jp-DefaultStyle select:disabled ~ span {
  cursor: not-allowed;
}

/* Use our own theme for hover and option styles */
/* stylelint-disable-next-line selector-max-type */
.jp-HTMLSelect.jp-DefaultStyle select:hover,
.jp-HTMLSelect.jp-DefaultStyle select > option {
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color0);
}

select {
  box-sizing: border-box;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-StatusBar-Widget {
  display: flex;
  align-items: center;
  background: var(--jp-layout-color2);
  min-height: var(--jp-statusbar-height);
  justify-content: space-between;
  padding: 0 10px;
}

.jp-StatusBar-Left {
  display: flex;
  align-items: center;
  flex-direction: row;
}

.jp-StatusBar-Middle {
  display: flex;
  align-items: center;
}

.jp-StatusBar-Right {
  display: flex;
  align-items: center;
  flex-direction: row-reverse;
}

.jp-StatusBar-Item {
  max-height: var(--jp-statusbar-height);
  margin: 0 2px;
  height: var(--jp-statusbar-height);
  white-space: nowrap;
  text-overflow: ellipsis;
  color: var(--jp-ui-font-color1);
  padding: 0 6px;
}

.jp-mod-highlighted:hover {
  background-color: var(--jp-layout-color3);
}

.jp-mod-clicked {
  background-color: var(--jp-brand-color1);
}

.jp-mod-clicked:hover {
  background-color: var(--jp-brand-color0);
}

.jp-mod-clicked .jp-StatusBar-TextItem {
  color: var(--jp-ui-inverse-font-color1);
}

.jp-StatusBar-HoverItem {
  box-shadow: '0px 4px 4px rgba(0, 0, 0, 0.25)';
}

.jp-StatusBar-TextItem {
  font-size: var(--jp-ui-font-size1);
  font-family: var(--jp-ui-font-family);
  line-height: 24px;
  color: var(--jp-ui-font-color1);
}

.jp-StatusBar-GroupItem {
  display: flex;
  align-items: center;
  flex-direction: row;
}

.jp-Statusbar-ProgressCircle svg {
  display: block;
  margin: 0 auto;
  width: 16px;
  height: 24px;
  align-self: normal;
}

.jp-Statusbar-ProgressCircle path {
  fill: var(--jp-inverse-layout-color3);
}

.jp-Statusbar-ProgressBar-progress-bar {
  height: 10px;
  width: 100px;
  border: solid 0.25px var(--jp-brand-color2);
  border-radius: 3px;
  overflow: hidden;
  align-self: center;
}

.jp-Statusbar-ProgressBar-progress-bar > div {
  background-color: var(--jp-brand-color2);
  background-image: linear-gradient(
    -45deg,
    rgba(255, 255, 255, 0.2) 25%,
    transparent 25%,
    transparent 50%,
    rgba(255, 255, 255, 0.2) 50%,
    rgba(255, 255, 255, 0.2) 75%,
    transparent 75%,
    transparent
  );
  background-size: 40px 40px;
  float: left;
  width: 0%;
  height: 100%;
  font-size: 12px;
  line-height: 14px;
  color: #fff;
  text-align: center;
  animation: jp-Statusbar-ExecutionTime-progress-bar 2s linear infinite;
}

.jp-Statusbar-ProgressBar-progress-bar p {
  color: var(--jp-ui-font-color1);
  font-family: var(--jp-ui-font-family);
  font-size: var(--jp-ui-font-size1);
  line-height: 10px;
  width: 100px;
}

@keyframes jp-Statusbar-ExecutionTime-progress-bar {
  0% {
    background-position: 0 0;
  }

  100% {
    background-position: 40px 40px;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-commandpalette-search-height: 28px;
}

/*-----------------------------------------------------------------------------
| Overall styles
|----------------------------------------------------------------------------*/

.lm-CommandPalette {
  padding-bottom: 0;
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);

  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
}

/*-----------------------------------------------------------------------------
| Modal variant
|----------------------------------------------------------------------------*/

.jp-ModalCommandPalette {
  position: absolute;
  z-index: 10000;
  top: 38px;
  left: 30%;
  margin: 0;
  padding: 4px;
  width: 40%;
  box-shadow: var(--jp-elevation-z4);
  border-radius: 4px;
  background: var(--jp-layout-color0);
}

.jp-ModalCommandPalette .lm-CommandPalette {
  max-height: 40vh;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-close-icon::after {
  display: none;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-CommandPalette-header {
  display: none;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-CommandPalette-item {
  margin-left: 4px;
  margin-right: 4px;
}

.jp-ModalCommandPalette
  .lm-CommandPalette
  .lm-CommandPalette-item.lm-mod-disabled {
  display: none;
}

/*-----------------------------------------------------------------------------
| Search
|----------------------------------------------------------------------------*/

.lm-CommandPalette-search {
  padding: 4px;
  background-color: var(--jp-layout-color1);
  z-index: 2;
}

.lm-CommandPalette-wrapper {
  overflow: overlay;
  padding: 0 9px;
  background-color: var(--jp-input-active-background);
  height: 30px;
  box-shadow: inset 0 0 0 var(--jp-border-width) var(--jp-input-border-color);
}

.lm-CommandPalette.lm-mod-focused .lm-CommandPalette-wrapper {
  box-shadow: inset 0 0 0 1px var(--jp-input-active-box-shadow-color),
    inset 0 0 0 3px var(--jp-input-active-box-shadow-color);
}

.jp-SearchIconGroup {
  color: white;
  background-color: var(--jp-brand-color1);
  position: absolute;
  top: 4px;
  right: 4px;
  padding: 5px 5px 1px;
}

.jp-SearchIconGroup svg {
  height: 20px;
  width: 20px;
}

.jp-SearchIconGroup .jp-icon3[fill] {
  fill: var(--jp-layout-color0);
}

.lm-CommandPalette-input {
  background: transparent;
  width: calc(100% - 18px);
  float: left;
  border: none;
  outline: none;
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  line-height: var(--jp-private-commandpalette-search-height);
}

.lm-CommandPalette-input::-webkit-input-placeholder,
.lm-CommandPalette-input::-moz-placeholder,
.lm-CommandPalette-input:-ms-input-placeholder {
  color: var(--jp-ui-font-color2);
  font-size: var(--jp-ui-font-size1);
}

/*-----------------------------------------------------------------------------
| Results
|----------------------------------------------------------------------------*/

.lm-CommandPalette-header:first-child {
  margin-top: 0;
}

.lm-CommandPalette-header {
  border-bottom: solid var(--jp-border-width) var(--jp-border-color2);
  color: var(--jp-ui-font-color1);
  cursor: pointer;
  display: flex;
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  letter-spacing: 1px;
  margin-top: 8px;
  padding: 8px 0 8px 12px;
  text-transform: uppercase;
}

.lm-CommandPalette-header.lm-mod-active {
  background: var(--jp-layout-color2);
}

.lm-CommandPalette-header > mark {
  background-color: transparent;
  font-weight: bold;
  color: var(--jp-ui-font-color1);
}

.lm-CommandPalette-item {
  padding: 4px 12px 4px 4px;
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  font-weight: 400;
  display: flex;
}

.lm-CommandPalette-item.lm-mod-disabled {
  color: var(--jp-ui-font-color2);
}

.lm-CommandPalette-item.lm-mod-active {
  color: var(--jp-ui-inverse-font-color1);
  background: var(--jp-brand-color1);
}

.lm-CommandPalette-item.lm-mod-active .lm-CommandPalette-itemLabel > mark {
  color: var(--jp-ui-inverse-font-color0);
}

.lm-CommandPalette-item.lm-mod-active .jp-icon-selectable[fill] {
  fill: var(--jp-layout-color0);
}

.lm-CommandPalette-item.lm-mod-active:hover:not(.lm-mod-disabled) {
  color: var(--jp-ui-inverse-font-color1);
  background: var(--jp-brand-color1);
}

.lm-CommandPalette-item:hover:not(.lm-mod-active):not(.lm-mod-disabled) {
  background: var(--jp-layout-color2);
}

.lm-CommandPalette-itemContent {
  overflow: hidden;
}

.lm-CommandPalette-itemLabel > mark {
  color: var(--jp-ui-font-color0);
  background-color: transparent;
  font-weight: bold;
}

.lm-CommandPalette-item.lm-mod-disabled mark {
  color: var(--jp-ui-font-color2);
}

.lm-CommandPalette-item .lm-CommandPalette-itemIcon {
  margin: 0 4px 0 0;
  position: relative;
  width: 16px;
  top: 2px;
  flex: 0 0 auto;
}

.lm-CommandPalette-item.lm-mod-disabled .lm-CommandPalette-itemIcon {
  opacity: 0.6;
}

.lm-CommandPalette-item .lm-CommandPalette-itemShortcut {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemCaption {
  display: none;
}

.lm-CommandPalette-content {
  background-color: var(--jp-layout-color1);
}

.lm-CommandPalette-content:empty::after {
  content: 'No results';
  margin: auto;
  margin-top: 20px;
  width: 100px;
  display: block;
  font-size: var(--jp-ui-font-size2);
  font-family: var(--jp-ui-font-family);
  font-weight: lighter;
}

.lm-CommandPalette-emptyMessage {
  text-align: center;
  margin-top: 24px;
  line-height: 1.32;
  padding: 0 8px;
  color: var(--jp-content-font-color3);
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Dialog {
  position: absolute;
  z-index: 10000;
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  top: 0;
  left: 0;
  margin: 0;
  padding: 0;
  width: 100%;
  height: 100%;
  background: var(--jp-dialog-background);
}

.jp-Dialog-content {
  display: flex;
  flex-direction: column;
  margin-left: auto;
  margin-right: auto;
  background: var(--jp-layout-color1);
  padding: 24px 24px 12px;
  min-width: 300px;
  min-height: 150px;
  max-width: 1000px;
  max-height: 500px;
  box-sizing: border-box;
  box-shadow: var(--jp-elevation-z20);
  word-wrap: break-word;
  border-radius: var(--jp-border-radius);

  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color1);
  resize: both;
}

.jp-Dialog-content.jp-Dialog-content-small {
  max-width: 500px;
}

.jp-Dialog-button {
  overflow: visible;
}

button.jp-Dialog-button:focus {
  outline: 1px solid var(--jp-brand-color1);
  outline-offset: 4px;
  -moz-outline-radius: 0;
}

button.jp-Dialog-button:focus::-moz-focus-inner {
  border: 0;
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-accept:focus,
button.jp-Dialog-button.jp-mod-styled.jp-mod-warn:focus,
button.jp-Dialog-button.jp-mod-styled.jp-mod-reject:focus {
  outline-offset: 4px;
  -moz-outline-radius: 0;
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-accept:focus {
  outline: 1px solid var(--jp-accept-color-normal, var(--jp-brand-color1));
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-warn:focus {
  outline: 1px solid var(--jp-warn-color-normal, var(--jp-error-color1));
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-reject:focus {
  outline: 1px solid var(--jp-reject-color-normal, var(--md-grey-600));
}

button.jp-Dialog-close-button {
  padding: 0;
  height: 100%;
  min-width: unset;
  min-height: unset;
}

.jp-Dialog-header {
  display: flex;
  justify-content: space-between;
  flex: 0 0 auto;
  padding-bottom: 12px;
  font-size: var(--jp-ui-font-size3);
  font-weight: 400;
  color: var(--jp-ui-font-color1);
}

.jp-Dialog-body {
  display: flex;
  flex-direction: column;
  flex: 1 1 auto;
  font-size: var(--jp-ui-font-size1);
  background: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  overflow: auto;
}

.jp-Dialog-footer {
  display: flex;
  flex-direction: row;
  justify-content: flex-end;
  align-items: center;
  flex: 0 0 auto;
  margin-left: -12px;
  margin-right: -12px;
  padding: 12px;
}

.jp-Dialog-checkbox {
  padding-right: 5px;
}

.jp-Dialog-checkbox > input:focus-visible {
  outline: 1px solid var(--jp-input-active-border-color);
  outline-offset: 1px;
}

.jp-Dialog-spacer {
  flex: 1 1 auto;
}

.jp-Dialog-title {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.jp-Dialog-body > .jp-select-wrapper {
  width: 100%;
}

.jp-Dialog-body > button {
  padding: 0 16px;
}

.jp-Dialog-body > label {
  line-height: 1.4;
  color: var(--jp-ui-font-color0);
}

.jp-Dialog-button.jp-mod-styled:not(:last-child) {
  margin-right: 12px;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-Input-Boolean-Dialog {
  flex-direction: row-reverse;
  align-items: end;
  width: 100%;
}

.jp-Input-Boolean-Dialog > label {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-MainAreaWidget > :focus {
  outline: none;
}

.jp-MainAreaWidget .jp-MainAreaWidget-error {
  padding: 6px;
}

.jp-MainAreaWidget .jp-MainAreaWidget-error > pre {
  width: auto;
  padding: 10px;
  background: var(--jp-error-color3);
  border: var(--jp-border-width) solid var(--jp-error-color1);
  border-radius: var(--jp-border-radius);
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  white-space: pre-wrap;
  word-wrap: break-word;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/**
 * google-material-color v1.2.6
 * https://github.com/danlevan/google-material-color
 */
:root {
  --md-red-50: #ffebee;
  --md-red-100: #ffcdd2;
  --md-red-200: #ef9a9a;
  --md-red-300: #e57373;
  --md-red-400: #ef5350;
  --md-red-500: #f44336;
  --md-red-600: #e53935;
  --md-red-700: #d32f2f;
  --md-red-800: #c62828;
  --md-red-900: #b71c1c;
  --md-red-A100: #ff8a80;
  --md-red-A200: #ff5252;
  --md-red-A400: #ff1744;
  --md-red-A700: #d50000;
  --md-pink-50: #fce4ec;
  --md-pink-100: #f8bbd0;
  --md-pink-200: #f48fb1;
  --md-pink-300: #f06292;
  --md-pink-400: #ec407a;
  --md-pink-500: #e91e63;
  --md-pink-600: #d81b60;
  --md-pink-700: #c2185b;
  --md-pink-800: #ad1457;
  --md-pink-900: #880e4f;
  --md-pink-A100: #ff80ab;
  --md-pink-A200: #ff4081;
  --md-pink-A400: #f50057;
  --md-pink-A700: #c51162;
  --md-purple-50: #f3e5f5;
  --md-purple-100: #e1bee7;
  --md-purple-200: #ce93d8;
  --md-purple-300: #ba68c8;
  --md-purple-400: #ab47bc;
  --md-purple-500: #9c27b0;
  --md-purple-600: #8e24aa;
  --md-purple-700: #7b1fa2;
  --md-purple-800: #6a1b9a;
  --md-purple-900: #4a148c;
  --md-purple-A100: #ea80fc;
  --md-purple-A200: #e040fb;
  --md-purple-A400: #d500f9;
  --md-purple-A700: #a0f;
  --md-deep-purple-50: #ede7f6;
  --md-deep-purple-100: #d1c4e9;
  --md-deep-purple-200: #b39ddb;
  --md-deep-purple-300: #9575cd;
  --md-deep-purple-400: #7e57c2;
  --md-deep-purple-500: #673ab7;
  --md-deep-purple-600: #5e35b1;
  --md-deep-purple-700: #512da8;
  --md-deep-purple-800: #4527a0;
  --md-deep-purple-900: #311b92;
  --md-deep-purple-A100: #b388ff;
  --md-deep-purple-A200: #7c4dff;
  --md-deep-purple-A400: #651fff;
  --md-deep-purple-A700: #6200ea;
  --md-indigo-50: #e8eaf6;
  --md-indigo-100: #c5cae9;
  --md-indigo-200: #9fa8da;
  --md-indigo-300: #7986cb;
  --md-indigo-400: #5c6bc0;
  --md-indigo-500: #3f51b5;
  --md-indigo-600: #3949ab;
  --md-indigo-700: #303f9f;
  --md-indigo-800: #283593;
  --md-indigo-900: #1a237e;
  --md-indigo-A100: #8c9eff;
  --md-indigo-A200: #536dfe;
  --md-indigo-A400: #3d5afe;
  --md-indigo-A700: #304ffe;
  --md-blue-50: #e3f2fd;
  --md-blue-100: #bbdefb;
  --md-blue-200: #90caf9;
  --md-blue-300: #64b5f6;
  --md-blue-400: #42a5f5;
  --md-blue-500: #2196f3;
  --md-blue-600: #1e88e5;
  --md-blue-700: #1976d2;
  --md-blue-800: #1565c0;
  --md-blue-900: #0d47a1;
  --md-blue-A100: #82b1ff;
  --md-blue-A200: #448aff;
  --md-blue-A400: #2979ff;
  --md-blue-A700: #2962ff;
  --md-light-blue-50: #e1f5fe;
  --md-light-blue-100: #b3e5fc;
  --md-light-blue-200: #81d4fa;
  --md-light-blue-300: #4fc3f7;
  --md-light-blue-400: #29b6f6;
  --md-light-blue-500: #03a9f4;
  --md-light-blue-600: #039be5;
  --md-light-blue-700: #0288d1;
  --md-light-blue-800: #0277bd;
  --md-light-blue-900: #01579b;
  --md-light-blue-A100: #80d8ff;
  --md-light-blue-A200: #40c4ff;
  --md-light-blue-A400: #00b0ff;
  --md-light-blue-A700: #0091ea;
  --md-cyan-50: #e0f7fa;
  --md-cyan-100: #b2ebf2;
  --md-cyan-200: #80deea;
  --md-cyan-300: #4dd0e1;
  --md-cyan-400: #26c6da;
  --md-cyan-500: #00bcd4;
  --md-cyan-600: #00acc1;
  --md-cyan-700: #0097a7;
  --md-cyan-800: #00838f;
  --md-cyan-900: #006064;
  --md-cyan-A100: #84ffff;
  --md-cyan-A200: #18ffff;
  --md-cyan-A400: #00e5ff;
  --md-cyan-A700: #00b8d4;
  --md-teal-50: #e0f2f1;
  --md-teal-100: #b2dfdb;
  --md-teal-200: #80cbc4;
  --md-teal-300: #4db6ac;
  --md-teal-400: #26a69a;
  --md-teal-500: #009688;
  --md-teal-600: #00897b;
  --md-teal-700: #00796b;
  --md-teal-800: #00695c;
  --md-teal-900: #004d40;
  --md-teal-A100: #a7ffeb;
  --md-teal-A200: #64ffda;
  --md-teal-A400: #1de9b6;
  --md-teal-A700: #00bfa5;
  --md-green-50: #e8f5e9;
  --md-green-100: #c8e6c9;
  --md-green-200: #a5d6a7;
  --md-green-300: #81c784;
  --md-green-400: #66bb6a;
  --md-green-500: #4caf50;
  --md-green-600: #43a047;
  --md-green-700: #388e3c;
  --md-green-800: #2e7d32;
  --md-green-900: #1b5e20;
  --md-green-A100: #b9f6ca;
  --md-green-A200: #69f0ae;
  --md-green-A400: #00e676;
  --md-green-A700: #00c853;
  --md-light-green-50: #f1f8e9;
  --md-light-green-100: #dcedc8;
  --md-light-green-200: #c5e1a5;
  --md-light-green-300: #aed581;
  --md-light-green-400: #9ccc65;
  --md-light-green-500: #8bc34a;
  --md-light-green-600: #7cb342;
  --md-light-green-700: #689f38;
  --md-light-green-800: #558b2f;
  --md-light-green-900: #33691e;
  --md-light-green-A100: #ccff90;
  --md-light-green-A200: #b2ff59;
  --md-light-green-A400: #76ff03;
  --md-light-green-A700: #64dd17;
  --md-lime-50: #f9fbe7;
  --md-lime-100: #f0f4c3;
  --md-lime-200: #e6ee9c;
  --md-lime-300: #dce775;
  --md-lime-400: #d4e157;
  --md-lime-500: #cddc39;
  --md-lime-600: #c0ca33;
  --md-lime-700: #afb42b;
  --md-lime-800: #9e9d24;
  --md-lime-900: #827717;
  --md-lime-A100: #f4ff81;
  --md-lime-A200: #eeff41;
  --md-lime-A400: #c6ff00;
  --md-lime-A700: #aeea00;
  --md-yellow-50: #fffde7;
  --md-yellow-100: #fff9c4;
  --md-yellow-200: #fff59d;
  --md-yellow-300: #fff176;
  --md-yellow-400: #ffee58;
  --md-yellow-500: #ffeb3b;
  --md-yellow-600: #fdd835;
  --md-yellow-700: #fbc02d;
  --md-yellow-800: #f9a825;
  --md-yellow-900: #f57f17;
  --md-yellow-A100: #ffff8d;
  --md-yellow-A200: #ff0;
  --md-yellow-A400: #ffea00;
  --md-yellow-A700: #ffd600;
  --md-amber-50: #fff8e1;
  --md-amber-100: #ffecb3;
  --md-amber-200: #ffe082;
  --md-amber-300: #ffd54f;
  --md-amber-400: #ffca28;
  --md-amber-500: #ffc107;
  --md-amber-600: #ffb300;
  --md-amber-700: #ffa000;
  --md-amber-800: #ff8f00;
  --md-amber-900: #ff6f00;
  --md-amber-A100: #ffe57f;
  --md-amber-A200: #ffd740;
  --md-amber-A400: #ffc400;
  --md-amber-A700: #ffab00;
  --md-orange-50: #fff3e0;
  --md-orange-100: #ffe0b2;
  --md-orange-200: #ffcc80;
  --md-orange-300: #ffb74d;
  --md-orange-400: #ffa726;
  --md-orange-500: #ff9800;
  --md-orange-600: #fb8c00;
  --md-orange-700: #f57c00;
  --md-orange-800: #ef6c00;
  --md-orange-900: #e65100;
  --md-orange-A100: #ffd180;
  --md-orange-A200: #ffab40;
  --md-orange-A400: #ff9100;
  --md-orange-A700: #ff6d00;
  --md-deep-orange-50: #fbe9e7;
  --md-deep-orange-100: #ffccbc;
  --md-deep-orange-200: #ffab91;
  --md-deep-orange-300: #ff8a65;
  --md-deep-orange-400: #ff7043;
  --md-deep-orange-500: #ff5722;
  --md-deep-orange-600: #f4511e;
  --md-deep-orange-700: #e64a19;
  --md-deep-orange-800: #d84315;
  --md-deep-orange-900: #bf360c;
  --md-deep-orange-A100: #ff9e80;
  --md-deep-orange-A200: #ff6e40;
  --md-deep-orange-A400: #ff3d00;
  --md-deep-orange-A700: #dd2c00;
  --md-brown-50: #efebe9;
  --md-brown-100: #d7ccc8;
  --md-brown-200: #bcaaa4;
  --md-brown-300: #a1887f;
  --md-brown-400: #8d6e63;
  --md-brown-500: #795548;
  --md-brown-600: #6d4c41;
  --md-brown-700: #5d4037;
  --md-brown-800: #4e342e;
  --md-brown-900: #3e2723;
  --md-grey-50: #fafafa;
  --md-grey-100: #f5f5f5;
  --md-grey-200: #eee;
  --md-grey-300: #e0e0e0;
  --md-grey-400: #bdbdbd;
  --md-grey-500: #9e9e9e;
  --md-grey-600: #757575;
  --md-grey-700: #616161;
  --md-grey-800: #424242;
  --md-grey-900: #212121;
  --md-blue-grey-50: #eceff1;
  --md-blue-grey-100: #cfd8dc;
  --md-blue-grey-200: #b0bec5;
  --md-blue-grey-300: #90a4ae;
  --md-blue-grey-400: #78909c;
  --md-blue-grey-500: #607d8b;
  --md-blue-grey-600: #546e7a;
  --md-blue-grey-700: #455a64;
  --md-blue-grey-800: #37474f;
  --md-blue-grey-900: #263238;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| RenderedText
|----------------------------------------------------------------------------*/

:root {
  /* This is the padding value to fill the gaps between lines containing spans with background color. */
  --jp-private-code-span-padding: calc(
    (var(--jp-code-line-height) - 1) * var(--jp-code-font-size) / 2
  );
}

.jp-RenderedText {
  text-align: left;
  padding-left: var(--jp-code-padding);
  line-height: var(--jp-code-line-height);
  font-family: var(--jp-code-font-family);
}

.jp-RenderedText pre,
.jp-RenderedJavaScript pre,
.jp-RenderedHTMLCommon pre {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-code-font-size);
  border: none;
  margin: 0;
  padding: 0;
}

.jp-RenderedText pre a:link {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

.jp-RenderedText pre a:hover {
  text-decoration: underline;
  color: var(--jp-content-link-color);
}

.jp-RenderedText pre a:visited {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

/* console foregrounds and backgrounds */
.jp-RenderedText pre .ansi-black-fg {
  color: #3e424d;
}

.jp-RenderedText pre .ansi-red-fg {
  color: #e75c58;
}

.jp-RenderedText pre .ansi-green-fg {
  color: #00a250;
}

.jp-RenderedText pre .ansi-yellow-fg {
  color: #ddb62b;
}

.jp-RenderedText pre .ansi-blue-fg {
  color: #208ffb;
}

.jp-RenderedText pre .ansi-magenta-fg {
  color: #d160c4;
}

.jp-RenderedText pre .ansi-cyan-fg {
  color: #60c6c8;
}

.jp-RenderedText pre .ansi-white-fg {
  color: #c5c1b4;
}

.jp-RenderedText pre .ansi-black-bg {
  background-color: #3e424d;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-red-bg {
  background-color: #e75c58;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-green-bg {
  background-color: #00a250;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-yellow-bg {
  background-color: #ddb62b;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-blue-bg {
  background-color: #208ffb;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-magenta-bg {
  background-color: #d160c4;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-cyan-bg {
  background-color: #60c6c8;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-white-bg {
  background-color: #c5c1b4;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-black-intense-fg {
  color: #282c36;
}

.jp-RenderedText pre .ansi-red-intense-fg {
  color: #b22b31;
}

.jp-RenderedText pre .ansi-green-intense-fg {
  color: #007427;
}

.jp-RenderedText pre .ansi-yellow-intense-fg {
  color: #b27d12;
}

.jp-RenderedText pre .ansi-blue-intense-fg {
  color: #0065ca;
}

.jp-RenderedText pre .ansi-magenta-intense-fg {
  color: #a03196;
}

.jp-RenderedText pre .ansi-cyan-intense-fg {
  color: #258f8f;
}

.jp-RenderedText pre .ansi-white-intense-fg {
  color: #a1a6b2;
}

.jp-RenderedText pre .ansi-black-intense-bg {
  background-color: #282c36;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-red-intense-bg {
  background-color: #b22b31;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-green-intense-bg {
  background-color: #007427;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-yellow-intense-bg {
  background-color: #b27d12;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-blue-intense-bg {
  background-color: #0065ca;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-magenta-intense-bg {
  background-color: #a03196;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-cyan-intense-bg {
  background-color: #258f8f;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-white-intense-bg {
  background-color: #a1a6b2;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-default-inverse-fg {
  color: var(--jp-ui-inverse-font-color0);
}

.jp-RenderedText pre .ansi-default-inverse-bg {
  background-color: var(--jp-inverse-layout-color0);
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-bold {
  font-weight: bold;
}

.jp-RenderedText pre .ansi-underline {
  text-decoration: underline;
}

.jp-RenderedText[data-mime-type='application/vnd.jupyter.stderr'] {
  background: var(--jp-rendermime-error-background);
  padding-top: var(--jp-code-padding);
}

/*-----------------------------------------------------------------------------
| RenderedLatex
|----------------------------------------------------------------------------*/

.jp-RenderedLatex {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-content-font-size1);
  line-height: var(--jp-content-line-height);
}

/* Left-justify outputs.*/
.jp-OutputArea-output.jp-RenderedLatex {
  padding: var(--jp-code-padding);
  text-align: left;
}

/*-----------------------------------------------------------------------------
| RenderedHTML
|----------------------------------------------------------------------------*/

.jp-RenderedHTMLCommon {
  color: var(--jp-content-font-color1);
  font-family: var(--jp-content-font-family);
  font-size: var(--jp-content-font-size1);
  line-height: var(--jp-content-line-height);

  /* Give a bit more R padding on Markdown text to keep line lengths reasonable */
  padding-right: 20px;
}

.jp-RenderedHTMLCommon em {
  font-style: italic;
}

.jp-RenderedHTMLCommon strong {
  font-weight: bold;
}

.jp-RenderedHTMLCommon u {
  text-decoration: underline;
}

.jp-RenderedHTMLCommon a:link {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

.jp-RenderedHTMLCommon a:hover {
  text-decoration: underline;
  color: var(--jp-content-link-color);
}

.jp-RenderedHTMLCommon a:visited {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

/* Headings */

.jp-RenderedHTMLCommon h1,
.jp-RenderedHTMLCommon h2,
.jp-RenderedHTMLCommon h3,
.jp-RenderedHTMLCommon h4,
.jp-RenderedHTMLCommon h5,
.jp-RenderedHTMLCommon h6 {
  line-height: var(--jp-content-heading-line-height);
  font-weight: var(--jp-content-heading-font-weight);
  font-style: normal;
  margin: var(--jp-content-heading-margin-top) 0
    var(--jp-content-heading-margin-bottom) 0;
}

.jp-RenderedHTMLCommon h1:first-child,
.jp-RenderedHTMLCommon h2:first-child,
.jp-RenderedHTMLCommon h3:first-child,
.jp-RenderedHTMLCommon h4:first-child,
.jp-RenderedHTMLCommon h5:first-child,
.jp-RenderedHTMLCommon h6:first-child {
  margin-top: calc(0.5 * var(--jp-content-heading-margin-top));
}

.jp-RenderedHTMLCommon h1:last-child,
.jp-RenderedHTMLCommon h2:last-child,
.jp-RenderedHTMLCommon h3:last-child,
.jp-RenderedHTMLCommon h4:last-child,
.jp-RenderedHTMLCommon h5:last-child,
.jp-RenderedHTMLCommon h6:last-child {
  margin-bottom: calc(0.5 * var(--jp-content-heading-margin-bottom));
}

.jp-RenderedHTMLCommon h1 {
  font-size: var(--jp-content-font-size5);
}

.jp-RenderedHTMLCommon h2 {
  font-size: var(--jp-content-font-size4);
}

.jp-RenderedHTMLCommon h3 {
  font-size: var(--jp-content-font-size3);
}

.jp-RenderedHTMLCommon h4 {
  font-size: var(--jp-content-font-size2);
}

.jp-RenderedHTMLCommon h5 {
  font-size: var(--jp-content-font-size1);
}

.jp-RenderedHTMLCommon h6 {
  font-size: var(--jp-content-font-size0);
}

/* Lists */

/* stylelint-disable selector-max-type, selector-max-compound-selectors */

.jp-RenderedHTMLCommon ul:not(.list-inline),
.jp-RenderedHTMLCommon ol:not(.list-inline) {
  padding-left: 2em;
}

.jp-RenderedHTMLCommon ul {
  list-style: disc;
}

.jp-RenderedHTMLCommon ul ul {
  list-style: square;
}

.jp-RenderedHTMLCommon ul ul ul {
  list-style: circle;
}

.jp-RenderedHTMLCommon ol {
  list-style: decimal;
}

.jp-RenderedHTMLCommon ol ol {
  list-style: upper-alpha;
}

.jp-RenderedHTMLCommon ol ol ol {
  list-style: lower-alpha;
}

.jp-RenderedHTMLCommon ol ol ol ol {
  list-style: lower-roman;
}

.jp-RenderedHTMLCommon ol ol ol ol ol {
  list-style: decimal;
}

.jp-RenderedHTMLCommon ol,
.jp-RenderedHTMLCommon ul {
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon ul ul,
.jp-RenderedHTMLCommon ul ol,
.jp-RenderedHTMLCommon ol ul,
.jp-RenderedHTMLCommon ol ol {
  margin-bottom: 0;
}

/* stylelint-enable selector-max-type, selector-max-compound-selectors */

.jp-RenderedHTMLCommon hr {
  color: var(--jp-border-color2);
  background-color: var(--jp-border-color1);
  margin-top: 1em;
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon > pre {
  margin: 1.5em 2em;
}

.jp-RenderedHTMLCommon pre,
.jp-RenderedHTMLCommon code {
  border: 0;
  background-color: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
  font-family: var(--jp-code-font-family);
  font-size: inherit;
  line-height: var(--jp-code-line-height);
  padding: 0;
  white-space: pre-wrap;
}

.jp-RenderedHTMLCommon :not(pre) > code {
  background-color: var(--jp-layout-color2);
  padding: 1px 5px;
}

/* Tables */

.jp-RenderedHTMLCommon table {
  border-collapse: collapse;
  border-spacing: 0;
  border: none;
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  table-layout: fixed;
  margin-left: auto;
  margin-bottom: 1em;
  margin-right: auto;
}

.jp-RenderedHTMLCommon thead {
  border-bottom: var(--jp-border-width) solid var(--jp-border-color1);
  vertical-align: bottom;
}

.jp-RenderedHTMLCommon td,
.jp-RenderedHTMLCommon th,
.jp-RenderedHTMLCommon tr {
  vertical-align: middle;
  padding: 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}

.jp-RenderedMarkdown.jp-RenderedHTMLCommon td,
.jp-RenderedMarkdown.jp-RenderedHTMLCommon th {
  max-width: none;
}

:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon td,
:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon th,
:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon tr {
  text-align: right;
}

.jp-RenderedHTMLCommon th {
  font-weight: bold;
}

.jp-RenderedHTMLCommon tbody tr:nth-child(odd) {
  background: var(--jp-layout-color0);
}

.jp-RenderedHTMLCommon tbody tr:nth-child(even) {
  background: var(--jp-rendermime-table-row-background);
}

.jp-RenderedHTMLCommon tbody tr:hover {
  background: var(--jp-rendermime-table-row-hover-background);
}

.jp-RenderedHTMLCommon p {
  text-align: left;
  margin: 0;
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon img {
  -moz-force-broken-image-icon: 1;
}

/* Restrict to direct children as other images could be nested in other content. */
.jp-RenderedHTMLCommon > img {
  display: block;
  margin-left: 0;
  margin-right: 0;
  margin-bottom: 1em;
}

/* Change color behind transparent images if they need it... */
[data-jp-theme-light='false'] .jp-RenderedImage img.jp-needs-light-background {
  background-color: var(--jp-inverse-layout-color1);
}

[data-jp-theme-light='true'] .jp-RenderedImage img.jp-needs-dark-background {
  background-color: var(--jp-inverse-layout-color1);
}

.jp-RenderedHTMLCommon img,
.jp-RenderedImage img,
.jp-RenderedHTMLCommon svg,
.jp-RenderedSVG svg {
  max-width: 100%;
  height: auto;
}

.jp-RenderedHTMLCommon img.jp-mod-unconfined,
.jp-RenderedImage img.jp-mod-unconfined,
.jp-RenderedHTMLCommon svg.jp-mod-unconfined,
.jp-RenderedSVG svg.jp-mod-unconfined {
  max-width: none;
}

.jp-RenderedHTMLCommon .alert {
  padding: var(--jp-notebook-padding);
  border: var(--jp-border-width) solid transparent;
  border-radius: var(--jp-border-radius);
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon .alert-info {
  color: var(--jp-info-color0);
  background-color: var(--jp-info-color3);
  border-color: var(--jp-info-color2);
}

.jp-RenderedHTMLCommon .alert-info hr {
  border-color: var(--jp-info-color3);
}

.jp-RenderedHTMLCommon .alert-info > p:last-child,
.jp-RenderedHTMLCommon .alert-info > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-warning {
  color: var(--jp-warn-color0);
  background-color: var(--jp-warn-color3);
  border-color: var(--jp-warn-color2);
}

.jp-RenderedHTMLCommon .alert-warning hr {
  border-color: var(--jp-warn-color3);
}

.jp-RenderedHTMLCommon .alert-warning > p:last-child,
.jp-RenderedHTMLCommon .alert-warning > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-success {
  color: var(--jp-success-color0);
  background-color: var(--jp-success-color3);
  border-color: var(--jp-success-color2);
}

.jp-RenderedHTMLCommon .alert-success hr {
  border-color: var(--jp-success-color3);
}

.jp-RenderedHTMLCommon .alert-success > p:last-child,
.jp-RenderedHTMLCommon .alert-success > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-danger {
  color: var(--jp-error-color0);
  background-color: var(--jp-error-color3);
  border-color: var(--jp-error-color2);
}

.jp-RenderedHTMLCommon .alert-danger hr {
  border-color: var(--jp-error-color3);
}

.jp-RenderedHTMLCommon .alert-danger > p:last-child,
.jp-RenderedHTMLCommon .alert-danger > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon blockquote {
  margin: 1em 2em;
  padding: 0 1em;
  border-left: 5px solid var(--jp-border-color2);
}

a.jp-InternalAnchorLink {
  visibility: hidden;
  margin-left: 8px;
  color: var(--md-blue-800);
}

h1:hover .jp-InternalAnchorLink,
h2:hover .jp-InternalAnchorLink,
h3:hover .jp-InternalAnchorLink,
h4:hover .jp-InternalAnchorLink,
h5:hover .jp-InternalAnchorLink,
h6:hover .jp-InternalAnchorLink {
  visibility: visible;
}

.jp-RenderedHTMLCommon kbd {
  background-color: var(--jp-rendermime-table-row-background);
  border: 1px solid var(--jp-border-color0);
  border-bottom-color: var(--jp-border-color2);
  border-radius: 3px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
  display: inline-block;
  font-size: var(--jp-ui-font-size0);
  line-height: 1em;
  padding: 0.2em 0.5em;
}

/* Most direct children of .jp-RenderedHTMLCommon have a margin-bottom of 1.0.
 * At the bottom of cells this is a bit too much as there is also spacing
 * between cells. Going all the way to 0 gets too tight between markdown and
 * code cells.
 */
.jp-RenderedHTMLCommon > *:last-child {
  margin-bottom: 0.5em;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-cursor-backdrop {
  position: fixed;
  width: 200px;
  height: 200px;
  margin-top: -100px;
  margin-left: -100px;
  will-change: transform;
  z-index: 100;
}

.lm-mod-drag-image {
  will-change: transform;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-lineFormSearch {
  padding: 4px 12px;
  background-color: var(--jp-layout-color2);
  box-shadow: var(--jp-toolbar-box-shadow);
  z-index: 2;
  font-size: var(--jp-ui-font-size1);
}

.jp-lineFormCaption {
  font-size: var(--jp-ui-font-size0);
  line-height: var(--jp-ui-font-size1);
  margin-top: 4px;
  color: var(--jp-ui-font-color0);
}

.jp-baseLineForm {
  border: none;
  border-radius: 0;
  position: absolute;
  background-size: 16px;
  background-repeat: no-repeat;
  background-position: center;
  outline: none;
}

.jp-lineFormButtonContainer {
  top: 4px;
  right: 8px;
  height: 24px;
  padding: 0 12px;
  width: 12px;
}

.jp-lineFormButtonIcon {
  top: 0;
  right: 0;
  background-color: var(--jp-brand-color1);
  height: 100%;
  width: 100%;
  box-sizing: border-box;
  padding: 4px 6px;
}

.jp-lineFormButton {
  top: 0;
  right: 0;
  background-color: transparent;
  height: 100%;
  width: 100%;
  box-sizing: border-box;
}

.jp-lineFormWrapper {
  overflow: hidden;
  padding: 0 8px;
  border: 1px solid var(--jp-border-color0);
  background-color: var(--jp-input-active-background);
  height: 22px;
}

.jp-lineFormWrapperFocusWithin {
  border: var(--jp-border-width) solid var(--md-blue-500);
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-lineFormInput {
  background: transparent;
  width: 200px;
  height: 100%;
  border: none;
  outline: none;
  color: var(--jp-ui-font-color0);
  line-height: 28px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-JSONEditor {
  display: flex;
  flex-direction: column;
  width: 100%;
}

.jp-JSONEditor-host {
  flex: 1 1 auto;
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  border-radius: 0;
  background: var(--jp-layout-color0);
  min-height: 50px;
  padding: 1px;
}

.jp-JSONEditor.jp-mod-error .jp-JSONEditor-host {
  border-color: red;
  outline-color: red;
}

.jp-JSONEditor-header {
  display: flex;
  flex: 1 0 auto;
  padding: 0 0 0 12px;
}

.jp-JSONEditor-header label {
  flex: 0 0 auto;
}

.jp-JSONEditor-commitButton {
  height: 16px;
  width: 16px;
  background-size: 18px;
  background-repeat: no-repeat;
  background-position: center;
}

.jp-JSONEditor-host.jp-mod-focused {
  background-color: var(--jp-input-active-background);
  border: 1px solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
}

.jp-Editor.jp-mod-dropTarget {
  border: var(--jp-border-width) solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/
.jp-DocumentSearch-input {
  border: none;
  outline: none;
  color: var(--jp-ui-font-color0);
  font-size: var(--jp-ui-font-size1);
  background-color: var(--jp-layout-color0);
  font-family: var(--jp-ui-font-family);
  padding: 2px 1px;
  resize: none;
}

.jp-DocumentSearch-overlay {
  position: absolute;
  background-color: var(--jp-toolbar-background);
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  border-left: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  top: 0;
  right: 0;
  z-index: 7;
  min-width: 405px;
  padding: 2px;
  font-size: var(--jp-ui-font-size1);

  --jp-private-document-search-button-height: 20px;
}

.jp-DocumentSearch-overlay button {
  background-color: var(--jp-toolbar-background);
  outline: 0;
}

.jp-DocumentSearch-overlay button:hover {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-overlay button:active {
  background-color: var(--jp-layout-color3);
}

.jp-DocumentSearch-overlay-row {
  display: flex;
  align-items: center;
  margin-bottom: 2px;
}

.jp-DocumentSearch-button-content {
  display: inline-block;
  cursor: pointer;
  box-sizing: border-box;
  width: 100%;
  height: 100%;
}

.jp-DocumentSearch-button-content svg {
  width: 100%;
  height: 100%;
}

.jp-DocumentSearch-input-wrapper {
  border: var(--jp-border-width) solid var(--jp-border-color0);
  display: flex;
  background-color: var(--jp-layout-color0);
  margin: 2px;
}

.jp-DocumentSearch-input-wrapper:focus-within {
  border-color: var(--jp-cell-editor-active-border-color);
}

.jp-DocumentSearch-toggle-wrapper,
.jp-DocumentSearch-button-wrapper {
  all: initial;
  overflow: hidden;
  display: inline-block;
  border: none;
  box-sizing: border-box;
}

.jp-DocumentSearch-toggle-wrapper {
  width: 14px;
  height: 14px;
}

.jp-DocumentSearch-button-wrapper {
  width: var(--jp-private-document-search-button-height);
  height: var(--jp-private-document-search-button-height);
}

.jp-DocumentSearch-toggle-wrapper:focus,
.jp-DocumentSearch-button-wrapper:focus {
  outline: var(--jp-border-width) solid
    var(--jp-cell-editor-active-border-color);
  outline-offset: -1px;
}

.jp-DocumentSearch-toggle-wrapper,
.jp-DocumentSearch-button-wrapper,
.jp-DocumentSearch-button-content:focus {
  outline: none;
}

.jp-DocumentSearch-toggle-placeholder {
  width: 5px;
}

.jp-DocumentSearch-input-button::before {
  display: block;
  padding-top: 100%;
}

.jp-DocumentSearch-input-button-off {
  opacity: var(--jp-search-toggle-off-opacity);
}

.jp-DocumentSearch-input-button-off:hover {
  opacity: var(--jp-search-toggle-hover-opacity);
}

.jp-DocumentSearch-input-button-on {
  opacity: var(--jp-search-toggle-on-opacity);
}

.jp-DocumentSearch-index-counter {
  padding-left: 10px;
  padding-right: 10px;
  user-select: none;
  min-width: 35px;
  display: inline-block;
}

.jp-DocumentSearch-up-down-wrapper {
  display: inline-block;
  padding-right: 2px;
  margin-left: auto;
  white-space: nowrap;
}

.jp-DocumentSearch-spacer {
  margin-left: auto;
}

.jp-DocumentSearch-up-down-wrapper button {
  outline: 0;
  border: none;
  width: var(--jp-private-document-search-button-height);
  height: var(--jp-private-document-search-button-height);
  vertical-align: middle;
  margin: 1px 5px 2px;
}

.jp-DocumentSearch-up-down-button:hover {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-up-down-button:active {
  background-color: var(--jp-layout-color3);
}

.jp-DocumentSearch-filter-button {
  border-radius: var(--jp-border-radius);
}

.jp-DocumentSearch-filter-button:hover {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-filter-button-enabled {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-filter-button-enabled:hover {
  background-color: var(--jp-layout-color3);
}

.jp-DocumentSearch-search-options {
  padding: 0 8px;
  margin-left: 3px;
  width: 100%;
  display: grid;
  justify-content: start;
  grid-template-columns: 1fr 1fr;
  align-items: center;
  justify-items: stretch;
}

.jp-DocumentSearch-search-filter-disabled {
  color: var(--jp-ui-font-color2);
}

.jp-DocumentSearch-search-filter {
  display: flex;
  align-items: center;
  user-select: none;
}

.jp-DocumentSearch-regex-error {
  color: var(--jp-error-color0);
}

.jp-DocumentSearch-replace-button-wrapper {
  overflow: hidden;
  display: inline-block;
  box-sizing: border-box;
  border: var(--jp-border-width) solid var(--jp-border-color0);
  margin: auto 2px;
  padding: 1px 4px;
  height: calc(var(--jp-private-document-search-button-height) + 2px);
}

.jp-DocumentSearch-replace-button-wrapper:focus {
  border: var(--jp-border-width) solid var(--jp-cell-editor-active-border-color);
}

.jp-DocumentSearch-replace-button {
  display: inline-block;
  text-align: center;
  cursor: pointer;
  box-sizing: border-box;
  color: var(--jp-ui-font-color1);

  /* height - 2 * (padding of wrapper) */
  line-height: calc(var(--jp-private-document-search-button-height) - 2px);
  width: 100%;
  height: 100%;
}

.jp-DocumentSearch-replace-button:focus {
  outline: none;
}

.jp-DocumentSearch-replace-wrapper-class {
  margin-left: 14px;
  display: flex;
}

.jp-DocumentSearch-replace-toggle {
  border: none;
  background-color: var(--jp-toolbar-background);
  border-radius: var(--jp-border-radius);
}

.jp-DocumentSearch-replace-toggle:hover {
  background-color: var(--jp-layout-color2);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.cm-editor {
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  font-family: var(--jp-code-font-family);
  border: 0;
  border-radius: 0;
  height: auto;

  /* Changed to auto to autogrow */
}

.cm-editor pre {
  padding: 0 var(--jp-code-padding);
}

.jp-CodeMirrorEditor[data-type='inline'] .cm-dialog {
  background-color: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
}

.jp-CodeMirrorEditor {
  cursor: text;
}

/* When zoomed out 67% and 33% on a screen of 1440 width x 900 height */
@media screen and (min-width: 2138px) and (max-width: 4319px) {
  .jp-CodeMirrorEditor[data-type='inline'] .cm-cursor {
    border-left: var(--jp-code-cursor-width1) solid
      var(--jp-editor-cursor-color);
  }
}

/* When zoomed out less than 33% */
@media screen and (min-width: 4320px) {
  .jp-CodeMirrorEditor[data-type='inline'] .cm-cursor {
    border-left: var(--jp-code-cursor-width2) solid
      var(--jp-editor-cursor-color);
  }
}

.cm-editor.jp-mod-readOnly .cm-cursor {
  display: none;
}

.jp-CollaboratorCursor {
  border-left: 5px solid transparent;
  border-right: 5px solid transparent;
  border-top: none;
  border-bottom: 3px solid;
  background-clip: content-box;
  margin-left: -5px;
  margin-right: -5px;
}

.cm-searching,
.cm-searching span {
  /* `.cm-searching span`: we need to override syntax highlighting */
  background-color: var(--jp-search-unselected-match-background-color);
  color: var(--jp-search-unselected-match-color);
}

.cm-searching::selection,
.cm-searching span::selection {
  background-color: var(--jp-search-unselected-match-background-color);
  color: var(--jp-search-unselected-match-color);
}

.jp-current-match > .cm-searching,
.jp-current-match > .cm-searching span,
.cm-searching > .jp-current-match,
.cm-searching > .jp-current-match span {
  background-color: var(--jp-search-selected-match-background-color);
  color: var(--jp-search-selected-match-color);
}

.jp-current-match > .cm-searching::selection,
.cm-searching > .jp-current-match::selection,
.jp-current-match > .cm-searching span::selection {
  background-color: var(--jp-search-selected-match-background-color);
  color: var(--jp-search-selected-match-color);
}

.cm-trailingspace {
  background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAFCAYAAAB4ka1VAAAAsElEQVQIHQGlAFr/AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA7+r3zKmT0/+pk9P/7+r3zAAAAAAAAAAABAAAAAAAAAAA6OPzM+/q9wAAAAAA6OPzMwAAAAAAAAAAAgAAAAAAAAAAGR8NiRQaCgAZIA0AGR8NiQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQyoYJ/SY80UAAAAASUVORK5CYII=);
  background-position: center left;
  background-repeat: repeat-x;
}

.jp-CollaboratorCursor-hover {
  position: absolute;
  z-index: 1;
  transform: translateX(-50%);
  color: white;
  border-radius: 3px;
  padding-left: 4px;
  padding-right: 4px;
  padding-top: 1px;
  padding-bottom: 1px;
  text-align: center;
  font-size: var(--jp-ui-font-size1);
  white-space: nowrap;
}

.jp-CodeMirror-ruler {
  border-left: 1px dashed var(--jp-border-color2);
}

/* Styles for shared cursors (remote cursor locations and selected ranges) */
.jp-CodeMirrorEditor .cm-ySelectionCaret {
  position: relative;
  border-left: 1px solid black;
  margin-left: -1px;
  margin-right: -1px;
  box-sizing: border-box;
}

.jp-CodeMirrorEditor .cm-ySelectionCaret > .cm-ySelectionInfo {
  white-space: nowrap;
  position: absolute;
  top: -1.15em;
  padding-bottom: 0.05em;
  left: -1px;
  font-size: 0.95em;
  font-family: var(--jp-ui-font-family);
  font-weight: bold;
  line-height: normal;
  user-select: none;
  color: white;
  padding-left: 2px;
  padding-right: 2px;
  z-index: 101;
  transition: opacity 0.3s ease-in-out;
}

.jp-CodeMirrorEditor .cm-ySelectionInfo {
  transition-delay: 0.7s;
  opacity: 0;
}

.jp-CodeMirrorEditor .cm-ySelectionCaret:hover > .cm-ySelectionInfo {
  opacity: 1;
  transition-delay: 0s;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-MimeDocument {
  outline: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-filebrowser-button-height: 28px;
  --jp-private-filebrowser-button-width: 48px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-FileBrowser .jp-SidePanel-content {
  display: flex;
  flex-direction: column;
}

.jp-FileBrowser-toolbar.jp-Toolbar {
  flex-wrap: wrap;
  row-gap: 12px;
  border-bottom: none;
  height: auto;
  margin: 8px 12px 0;
  box-shadow: none;
  padding: 0;
  justify-content: flex-start;
}

.jp-FileBrowser-Panel {
  flex: 1 1 auto;
  display: flex;
  flex-direction: column;
}

.jp-BreadCrumbs {
  flex: 0 0 auto;
  margin: 8px 12px;
}

.jp-BreadCrumbs-item {
  margin: 0 2px;
  padding: 0 2px;
  border-radius: var(--jp-border-radius);
  cursor: pointer;
}

.jp-BreadCrumbs-item:hover {
  background-color: var(--jp-layout-color2);
}

.jp-BreadCrumbs-item:first-child {
  margin-left: 0;
}

.jp-BreadCrumbs-item.jp-mod-dropTarget {
  background-color: var(--jp-brand-color2);
  opacity: 0.7;
}

/*-----------------------------------------------------------------------------
| Buttons
|----------------------------------------------------------------------------*/

.jp-FileBrowser-toolbar > .jp-Toolbar-item {
  flex: 0 0 auto;
  padding-left: 0;
  padding-right: 2px;
  align-items: center;
  height: unset;
}

.jp-FileBrowser-toolbar > .jp-Toolbar-item .jp-ToolbarButtonComponent {
  width: 40px;
}

/*-----------------------------------------------------------------------------
| Other styles
|----------------------------------------------------------------------------*/

.jp-FileDialog.jp-mod-conflict input {
  color: var(--jp-error-color1);
}

.jp-FileDialog .jp-new-name-title {
  margin-top: 12px;
}

.jp-LastModified-hidden {
  display: none;
}

.jp-FileSize-hidden {
  display: none;
}

.jp-FileBrowser .lm-AccordionPanel > h3:first-child {
  display: none;
}

/*-----------------------------------------------------------------------------
| DirListing
|----------------------------------------------------------------------------*/

.jp-DirListing {
  flex: 1 1 auto;
  display: flex;
  flex-direction: column;
  outline: 0;
}

.jp-DirListing-header {
  flex: 0 0 auto;
  display: flex;
  flex-direction: row;
  align-items: center;
  overflow: hidden;
  border-top: var(--jp-border-width) solid var(--jp-border-color2);
  border-bottom: var(--jp-border-width) solid var(--jp-border-color1);
  box-shadow: var(--jp-toolbar-box-shadow);
  z-index: 2;
}

.jp-DirListing-headerItem {
  padding: 4px 12px 2px;
  font-weight: 500;
}

.jp-DirListing-headerItem:hover {
  background: var(--jp-layout-color2);
}

.jp-DirListing-headerItem.jp-id-name {
  flex: 1 0 84px;
}

.jp-DirListing-headerItem.jp-id-modified {
  flex: 0 0 112px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
}

.jp-DirListing-headerItem.jp-id-filesize {
  flex: 0 0 75px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
}

.jp-id-narrow {
  display: none;
  flex: 0 0 5px;
  padding: 4px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
  color: var(--jp-border-color2);
}

.jp-DirListing-narrow .jp-id-narrow {
  display: block;
}

.jp-DirListing-narrow .jp-id-modified,
.jp-DirListing-narrow .jp-DirListing-itemModified {
  display: none;
}

.jp-DirListing-headerItem.jp-mod-selected {
  font-weight: 600;
}

/* increase specificity to override bundled default */
.jp-DirListing-content {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  list-style-type: none;
  overflow: auto;
  background-color: var(--jp-layout-color1);
}

.jp-DirListing-content mark {
  color: var(--jp-ui-font-color0);
  background-color: transparent;
  font-weight: bold;
}

.jp-DirListing-content .jp-DirListing-item.jp-mod-selected mark {
  color: var(--jp-ui-inverse-font-color0);
}

/* Style the directory listing content when a user drops a file to upload */
.jp-DirListing.jp-mod-native-drop .jp-DirListing-content {
  outline: 5px dashed rgba(128, 128, 128, 0.5);
  outline-offset: -10px;
  cursor: copy;
}

.jp-DirListing-item {
  display: flex;
  flex-direction: row;
  align-items: center;
  padding: 4px 12px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-DirListing-checkboxWrapper {
  /* Increases hit area of checkbox. */
  padding: 4px;
}

.jp-DirListing-header
  .jp-DirListing-checkboxWrapper
  + .jp-DirListing-headerItem {
  padding-left: 4px;
}

.jp-DirListing-content .jp-DirListing-checkboxWrapper {
  position: relative;
  left: -4px;
  margin: -4px 0 -4px -8px;
}

.jp-DirListing-checkboxWrapper.jp-mod-visible {
  visibility: visible;
}

/* For devices that support hovering, hide checkboxes until hovered, selected...
*/
@media (hover: hover) {
  .jp-DirListing-checkboxWrapper {
    visibility: hidden;
  }

  .jp-DirListing-item:hover .jp-DirListing-checkboxWrapper,
  .jp-DirListing-item.jp-mod-selected .jp-DirListing-checkboxWrapper {
    visibility: visible;
  }
}

.jp-DirListing-item[data-is-dot] {
  opacity: 75%;
}

.jp-DirListing-item.jp-mod-selected {
  color: var(--jp-ui-inverse-font-color1);
  background: var(--jp-brand-color1);
}

.jp-DirListing-item.jp-mod-dropTarget {
  background: var(--jp-brand-color3);
}

.jp-DirListing-item:hover:not(.jp-mod-selected) {
  background: var(--jp-layout-color2);
}

.jp-DirListing-itemIcon {
  flex: 0 0 20px;
  margin-right: 4px;
}

.jp-DirListing-itemText {
  flex: 1 0 64px;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  user-select: none;
}

.jp-DirListing-itemText:focus {
  outline-width: 2px;
  outline-color: var(--jp-inverse-layout-color1);
  outline-style: solid;
  outline-offset: 1px;
}

.jp-DirListing-item.jp-mod-selected .jp-DirListing-itemText:focus {
  outline-color: var(--jp-layout-color1);
}

.jp-DirListing-itemModified {
  flex: 0 0 125px;
  text-align: right;
}

.jp-DirListing-itemFileSize {
  flex: 0 0 90px;
  text-align: right;
}

.jp-DirListing-editor {
  flex: 1 0 64px;
  outline: none;
  border: none;
  color: var(--jp-ui-font-color1);
  background-color: var(--jp-layout-color1);
}

.jp-DirListing-item.jp-mod-running .jp-DirListing-itemIcon::before {
  color: var(--jp-success-color1);
  content: '\25CF';
  font-size: 8px;
  position: absolute;
  left: -8px;
}

.jp-DirListing-item.jp-mod-running.jp-mod-selected
  .jp-DirListing-itemIcon::before {
  color: var(--jp-ui-inverse-font-color1);
}

.jp-DirListing-item.lm-mod-drag-image,
.jp-DirListing-item.jp-mod-selected.lm-mod-drag-image {
  font-size: var(--jp-ui-font-size1);
  padding-left: 4px;
  margin-left: 4px;
  width: 160px;
  background-color: var(--jp-ui-inverse-font-color2);
  box-shadow: var(--jp-elevation-z2);
  border-radius: 0;
  color: var(--jp-ui-font-color1);
  transform: translateX(-40%) translateY(-58%);
}

.jp-Document {
  min-width: 120px;
  min-height: 120px;
  outline: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Main OutputArea
| OutputArea has a list of Outputs
|----------------------------------------------------------------------------*/

.jp-OutputArea {
  overflow-y: auto;
}

.jp-OutputArea-child {
  display: table;
  table-layout: fixed;
  width: 100%;
  overflow: hidden;
}

.jp-OutputPrompt {
  width: var(--jp-cell-prompt-width);
  color: var(--jp-cell-outprompt-font-color);
  font-family: var(--jp-cell-prompt-font-family);
  padding: var(--jp-code-padding);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
  opacity: var(--jp-cell-prompt-opacity);

  /* Right align prompt text, don't wrap to handle large prompt numbers */
  text-align: right;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;

  /* Disable text selection */
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-OutputArea-prompt {
  display: table-cell;
  vertical-align: top;
}

.jp-OutputArea-output {
  display: table-cell;
  width: 100%;
  height: auto;
  overflow: auto;
  user-select: text;
  -moz-user-select: text;
  -webkit-user-select: text;
  -ms-user-select: text;
}

.jp-OutputArea .jp-RenderedText {
  padding-left: 1ch;
}

/**
 * Prompt overlay.
 */

.jp-OutputArea-promptOverlay {
  position: absolute;
  top: 0;
  width: var(--jp-cell-prompt-width);
  height: 100%;
  opacity: 0.5;
}

.jp-OutputArea-promptOverlay:hover {
  background: var(--jp-layout-color2);
  box-shadow: inset 0 0 1px var(--jp-inverse-layout-color0);
  cursor: zoom-out;
}

.jp-mod-outputsScrolled .jp-OutputArea-promptOverlay:hover {
  cursor: zoom-in;
}

/**
 * Isolated output.
 */
.jp-OutputArea-output.jp-mod-isolated {
  width: 100%;
  display: block;
}

/*
When drag events occur, `lm-mod-override-cursor` is added to the body.
Because iframes steal all cursor events, the following two rules are necessary
to suppress pointer events while resize drags are occurring. There may be a
better solution to this problem.
*/
body.lm-mod-override-cursor .jp-OutputArea-output.jp-mod-isolated {
  position: relative;
}

body.lm-mod-override-cursor .jp-OutputArea-output.jp-mod-isolated::before {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: transparent;
}

/* pre */

.jp-OutputArea-output pre {
  border: none;
  margin: 0;
  padding: 0;
  overflow-x: auto;
  overflow-y: auto;
  word-break: break-all;
  word-wrap: break-word;
  white-space: pre-wrap;
}

/* tables */

.jp-OutputArea-output.jp-RenderedHTMLCommon table {
  margin-left: 0;
  margin-right: 0;
}

/* description lists */

.jp-OutputArea-output dl,
.jp-OutputArea-output dt,
.jp-OutputArea-output dd {
  display: block;
}

.jp-OutputArea-output dl {
  width: 100%;
  overflow: hidden;
  padding: 0;
  margin: 0;
}

.jp-OutputArea-output dt {
  font-weight: bold;
  float: left;
  width: 20%;
  padding: 0;
  margin: 0;
}

.jp-OutputArea-output dd {
  float: left;
  width: 80%;
  padding: 0;
  margin: 0;
}

.jp-TrimmedOutputs pre {
  background: var(--jp-layout-color3);
  font-size: calc(var(--jp-code-font-size) * 1.4);
  text-align: center;
  text-transform: uppercase;
}

/* Hide the gutter in case of
 *  - nested output areas (e.g. in the case of output widgets)
 *  - mirrored output areas
 */
.jp-OutputArea .jp-OutputArea .jp-OutputArea-prompt {
  display: none;
}

/* Hide empty lines in the output area, for instance due to cleared widgets */
.jp-OutputArea-prompt:empty {
  padding: 0;
  border: 0;
}

/*-----------------------------------------------------------------------------
| executeResult is added to any Output-result for the display of the object
| returned by a cell
|----------------------------------------------------------------------------*/

.jp-OutputArea-output.jp-OutputArea-executeResult {
  margin-left: 0;
  width: 100%;
}

/* Text output with the Out[] prompt needs a top padding to match the
 * alignment of the Out[] prompt itself.
 */
.jp-OutputArea-executeResult .jp-RenderedText.jp-OutputArea-output {
  padding-top: var(--jp-code-padding);
  border-top: var(--jp-border-width) solid transparent;
}

/*-----------------------------------------------------------------------------
| The Stdin output
|----------------------------------------------------------------------------*/

.jp-Stdin-prompt {
  color: var(--jp-content-font-color0);
  padding-right: var(--jp-code-padding);
  vertical-align: baseline;
  flex: 0 0 auto;
}

.jp-Stdin-input {
  font-family: var(--jp-code-font-family);
  font-size: inherit;
  color: inherit;
  background-color: inherit;
  width: 42%;
  min-width: 200px;

  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;

  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0 0.25em;
  margin: 0 0.25em;
  flex: 0 0 70%;
}

.jp-Stdin-input::placeholder {
  opacity: 0;
}

.jp-Stdin-input:focus {
  box-shadow: none;
}

.jp-Stdin-input:focus::placeholder {
  opacity: 1;
}

/*-----------------------------------------------------------------------------
| Output Area View
|----------------------------------------------------------------------------*/

.jp-LinkedOutputView .jp-OutputArea {
  height: 100%;
  display: block;
}

.jp-LinkedOutputView .jp-OutputArea-output:only-child {
  height: 100%;
}

/*-----------------------------------------------------------------------------
| Printing
|----------------------------------------------------------------------------*/

@media print {
  .jp-OutputArea-child {
    break-inside: avoid-page;
  }
}

/*-----------------------------------------------------------------------------
| Mobile
|----------------------------------------------------------------------------*/
@media only screen and (max-width: 760px) {
  .jp-OutputPrompt {
    display: table-row;
    text-align: left;
  }

  .jp-OutputArea-child .jp-OutputArea-output {
    display: table-row;
    margin-left: var(--jp-notebook-padding);
  }
}

/* Trimmed outputs warning */
.jp-TrimmedOutputs > a {
  margin: 10px;
  text-decoration: none;
  cursor: pointer;
}

.jp-TrimmedOutputs > a:hover {
  text-decoration: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Table of Contents
|----------------------------------------------------------------------------*/

:root {
  --jp-private-toc-active-width: 4px;
}

.jp-TableOfContents {
  display: flex;
  flex-direction: column;
  background: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  height: 100%;
}

.jp-TableOfContents-placeholder {
  text-align: center;
}

.jp-TableOfContents-placeholderContent {
  color: var(--jp-content-font-color2);
  padding: 8px;
}

.jp-TableOfContents-placeholderContent > h3 {
  margin-bottom: var(--jp-content-heading-margin-bottom);
}

.jp-TableOfContents .jp-SidePanel-content {
  overflow-y: auto;
}

.jp-TableOfContents-tree {
  margin: 4px;
}

.jp-TableOfContents ol {
  list-style-type: none;
}

/* stylelint-disable-next-line selector-max-type */
.jp-TableOfContents li > ol {
  /* Align left border with triangle icon center */
  padding-left: 11px;
}

.jp-TableOfContents-content {
  /* left margin for the active heading indicator */
  margin: 0 0 0 var(--jp-private-toc-active-width);
  padding: 0;
  background-color: var(--jp-layout-color1);
}

.jp-tocItem {
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-tocItem-heading {
  display: flex;
  cursor: pointer;
}

.jp-tocItem-heading:hover {
  background-color: var(--jp-layout-color2);
}

.jp-tocItem-content {
  display: block;
  padding: 4px 0;
  white-space: nowrap;
  text-overflow: ellipsis;
  overflow-x: hidden;
}

.jp-tocItem-collapser {
  height: 20px;
  margin: 2px 2px 0;
  padding: 0;
  background: none;
  border: none;
  cursor: pointer;
}

.jp-tocItem-collapser:hover {
  background-color: var(--jp-layout-color3);
}

/* Active heading indicator */

.jp-tocItem-heading::before {
  content: ' ';
  background: transparent;
  width: var(--jp-private-toc-active-width);
  height: 24px;
  position: absolute;
  left: 0;
  border-radius: var(--jp-border-radius);
}

.jp-tocItem-heading.jp-tocItem-active::before {
  background-color: var(--jp-brand-color1);
}

.jp-tocItem-heading:hover.jp-tocItem-active::before {
  background: var(--jp-brand-color0);
  opacity: 1;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Collapser {
  flex: 0 0 var(--jp-cell-collapser-width);
  padding: 0;
  margin: 0;
  border: none;
  outline: none;
  background: transparent;
  border-radius: var(--jp-border-radius);
  opacity: 1;
}

.jp-Collapser-child {
  display: block;
  width: 100%;
  box-sizing: border-box;

  /* height: 100% doesn't work because the height of its parent is computed from content */
  position: absolute;
  top: 0;
  bottom: 0;
}

/*-----------------------------------------------------------------------------
| Printing
|----------------------------------------------------------------------------*/

/*
Hiding collapsers in print mode.

Note: input and output wrappers have "display: block" propery in print mode.
*/

@media print {
  .jp-Collapser {
    display: none;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Header/Footer
|----------------------------------------------------------------------------*/

/* Hidden by zero height by default */
.jp-CellHeader,
.jp-CellFooter {
  height: 0;
  width: 100%;
  padding: 0;
  margin: 0;
  border: none;
  outline: none;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Input
|----------------------------------------------------------------------------*/

/* All input areas */
.jp-InputArea {
  display: table;
  table-layout: fixed;
  width: 100%;
  overflow: hidden;
}

.jp-InputArea-editor {
  display: table-cell;
  overflow: hidden;
  vertical-align: top;

  /* This is the non-active, default styling */
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  border-radius: 0;
  background: var(--jp-cell-editor-background);
}

.jp-InputPrompt {
  display: table-cell;
  vertical-align: top;
  width: var(--jp-cell-prompt-width);
  color: var(--jp-cell-inprompt-font-color);
  font-family: var(--jp-cell-prompt-font-family);
  padding: var(--jp-code-padding);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  opacity: var(--jp-cell-prompt-opacity);
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;

  /* Right align prompt text, don't wrap to handle large prompt numbers */
  text-align: right;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;

  /* Disable text selection */
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

/*-----------------------------------------------------------------------------
| Mobile
|----------------------------------------------------------------------------*/
@media only screen and (max-width: 760px) {
  .jp-InputArea-editor {
    display: table-row;
    margin-left: var(--jp-notebook-padding);
  }

  .jp-InputPrompt {
    display: table-row;
    text-align: left;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Placeholder
|----------------------------------------------------------------------------*/

.jp-Placeholder {
  display: table;
  table-layout: fixed;
  width: 100%;
}

.jp-Placeholder-prompt {
  display: table-cell;
  box-sizing: border-box;
}

.jp-Placeholder-content {
  display: table-cell;
  padding: 4px 6px;
  border: 1px solid transparent;
  border-radius: 0;
  background: none;
  box-sizing: border-box;
  cursor: pointer;
}

.jp-Placeholder-contentContainer {
  display: flex;
}

.jp-Placeholder-content:hover,
.jp-InputPlaceholder > .jp-Placeholder-content:hover {
  border-color: var(--jp-layout-color3);
}

.jp-Placeholder-content .jp-MoreHorizIcon {
  width: 32px;
  height: 16px;
  border: 1px solid transparent;
  border-radius: var(--jp-border-radius);
}

.jp-Placeholder-content .jp-MoreHorizIcon:hover {
  border: 1px solid var(--jp-border-color1);
  box-shadow: 0 0 2px 0 rgba(0, 0, 0, 0.25);
  background-color: var(--jp-layout-color0);
}

.jp-PlaceholderText {
  white-space: nowrap;
  overflow-x: hidden;
  color: var(--jp-inverse-layout-color3);
  font-family: var(--jp-code-font-family);
}

.jp-InputPlaceholder > .jp-Placeholder-content {
  border-color: var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Private CSS variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-cell-scrolling-output-offset: 5px;
}

/*-----------------------------------------------------------------------------
| Cell
|----------------------------------------------------------------------------*/

.jp-Cell {
  padding: var(--jp-cell-padding);
  margin: 0;
  border: none;
  outline: none;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Common input/output
|----------------------------------------------------------------------------*/

.jp-Cell-inputWrapper,
.jp-Cell-outputWrapper {
  display: flex;
  flex-direction: row;
  padding: 0;
  margin: 0;

  /* Added to reveal the box-shadow on the input and output collapsers. */
  overflow: visible;
}

/* Only input/output areas inside cells */
.jp-Cell-inputArea,
.jp-Cell-outputArea {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Collapser
|----------------------------------------------------------------------------*/

/* Make the output collapser disappear when there is not output, but do so
 * in a manner that leaves it in the layout and preserves its width.
 */
.jp-Cell.jp-mod-noOutputs .jp-Cell-outputCollapser {
  border: none !important;
  background: transparent !important;
}

.jp-Cell:not(.jp-mod-noOutputs) .jp-Cell-outputCollapser {
  min-height: var(--jp-cell-collapser-min-height);
}

/*-----------------------------------------------------------------------------
| Output
|----------------------------------------------------------------------------*/

/* Put a space between input and output when there IS output */
.jp-Cell:not(.jp-mod-noOutputs) .jp-Cell-outputWrapper {
  margin-top: 5px;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea {
  overflow-y: auto;
  max-height: 24em;
  margin-left: var(--jp-private-cell-scrolling-output-offset);
  resize: vertical;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea[style*='height'] {
  max-height: unset;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea::after {
  content: ' ';
  box-shadow: inset 0 0 6px 2px rgb(0 0 0 / 30%);
  width: 100%;
  height: 100%;
  position: sticky;
  bottom: 0;
  top: 0;
  margin-top: -50%;
  float: left;
  display: block;
  pointer-events: none;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-child {
  padding-top: 6px;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-prompt {
  width: calc(
    var(--jp-cell-prompt-width) - var(--jp-private-cell-scrolling-output-offset)
  );
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-promptOverlay {
  left: calc(-1 * var(--jp-private-cell-scrolling-output-offset));
}

/*-----------------------------------------------------------------------------
| CodeCell
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| MarkdownCell
|----------------------------------------------------------------------------*/

.jp-MarkdownOutput {
  display: table-cell;
  width: 100%;
  margin-top: 0;
  margin-bottom: 0;
  padding-left: var(--jp-code-padding);
}

.jp-MarkdownOutput.jp-RenderedHTMLCommon {
  overflow: auto;
}

/* collapseHeadingButton (show always if hiddenCellsButton is _not_ shown) */
.jp-collapseHeadingButton {
  display: flex;
  min-height: var(--jp-cell-collapser-min-height);
  font-size: var(--jp-code-font-size);
  position: absolute;
  background-color: transparent;
  background-size: 25px;
  background-repeat: no-repeat;
  background-position-x: center;
  background-position-y: top;
  background-image: var(--jp-icon-caret-down);
  right: 0;
  top: 0;
  bottom: 0;
}

.jp-collapseHeadingButton.jp-mod-collapsed {
  background-image: var(--jp-icon-caret-right);
}

/*
 set the container font size to match that of content
 so that the nested collapse buttons have the right size
*/
.jp-MarkdownCell .jp-InputPrompt {
  font-size: var(--jp-content-font-size1);
}

/*
  Align collapseHeadingButton with cell top header
  The font sizes are identical to the ones in packages/rendermime/style/base.css
*/
.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='1'] {
  font-size: var(--jp-content-font-size5);
  background-position-y: calc(0.3 * var(--jp-content-font-size5));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='2'] {
  font-size: var(--jp-content-font-size4);
  background-position-y: calc(0.3 * var(--jp-content-font-size4));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='3'] {
  font-size: var(--jp-content-font-size3);
  background-position-y: calc(0.3 * var(--jp-content-font-size3));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='4'] {
  font-size: var(--jp-content-font-size2);
  background-position-y: calc(0.3 * var(--jp-content-font-size2));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='5'] {
  font-size: var(--jp-content-font-size1);
  background-position-y: top;
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='6'] {
  font-size: var(--jp-content-font-size0);
  background-position-y: top;
}

/* collapseHeadingButton (show only on (hover,active) if hiddenCellsButton is shown) */
.jp-Notebook.jp-mod-showHiddenCellsButton .jp-collapseHeadingButton {
  display: none;
}

.jp-Notebook.jp-mod-showHiddenCellsButton
  :is(.jp-MarkdownCell:hover, .jp-mod-active)
  .jp-collapseHeadingButton {
  display: flex;
}

/* showHiddenCellsButton (only show if jp-mod-showHiddenCellsButton is set, which
is a consequence of the showHiddenCellsButton option in Notebook Settings)*/
.jp-Notebook.jp-mod-showHiddenCellsButton .jp-showHiddenCellsButton {
  margin-left: calc(var(--jp-cell-prompt-width) + 2 * var(--jp-code-padding));
  margin-top: var(--jp-code-padding);
  border: 1px solid var(--jp-border-color2);
  background-color: var(--jp-border-color3) !important;
  color: var(--jp-content-font-color0) !important;
  display: flex;
}

.jp-Notebook.jp-mod-showHiddenCellsButton .jp-showHiddenCellsButton:hover {
  background-color: var(--jp-border-color2) !important;
}

.jp-showHiddenCellsButton {
  display: none;
}

/*-----------------------------------------------------------------------------
| Printing
|----------------------------------------------------------------------------*/

/*
Using block instead of flex to allow the use of the break-inside CSS property for
cell outputs.
*/

@media print {
  .jp-Cell-inputWrapper,
  .jp-Cell-outputWrapper {
    display: block;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-notebook-toolbar-padding: 2px 5px 2px 2px;
}

/*-----------------------------------------------------------------------------

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-NotebookPanel-toolbar {
  padding: var(--jp-notebook-toolbar-padding);

  /* disable paint containment from lumino 2.0 default strict CSS containment */
  contain: style size !important;
}

.jp-Toolbar-item.jp-Notebook-toolbarCellType .jp-select-wrapper.jp-mod-focused {
  border: none;
  box-shadow: none;
}

.jp-Notebook-toolbarCellTypeDropdown select {
  height: 24px;
  font-size: var(--jp-ui-font-size1);
  line-height: 14px;
  border-radius: 0;
  display: block;
}

.jp-Notebook-toolbarCellTypeDropdown span {
  top: 5px !important;
}

.jp-Toolbar-responsive-popup {
  position: absolute;
  height: fit-content;
  display: flex;
  flex-direction: row;
  flex-wrap: wrap;
  justify-content: flex-end;
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  background: var(--jp-toolbar-background);
  min-height: var(--jp-toolbar-micro-height);
  padding: var(--jp-notebook-toolbar-padding);
  z-index: 1;
  right: 0;
  top: 0;
}

.jp-Toolbar > .jp-Toolbar-responsive-opener {
  margin-left: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-Notebook-ExecutionIndicator {
  position: relative;
  display: inline-block;
  height: 100%;
  z-index: 9997;
}

.jp-Notebook-ExecutionIndicator-tooltip {
  visibility: hidden;
  height: auto;
  width: max-content;
  width: -moz-max-content;
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color1);
  text-align: justify;
  border-radius: 6px;
  padding: 0 5px;
  position: fixed;
  display: table;
}

.jp-Notebook-ExecutionIndicator-tooltip.up {
  transform: translateX(-50%) translateY(-100%) translateY(-32px);
}

.jp-Notebook-ExecutionIndicator-tooltip.down {
  transform: translateX(calc(-100% + 16px)) translateY(5px);
}

.jp-Notebook-ExecutionIndicator-tooltip.hidden {
  display: none;
}

.jp-Notebook-ExecutionIndicator:hover .jp-Notebook-ExecutionIndicator-tooltip {
  visibility: visible;
}

.jp-Notebook-ExecutionIndicator span {
  font-size: var(--jp-ui-font-size1);
  font-family: var(--jp-ui-font-family);
  color: var(--jp-ui-font-color1);
  line-height: 24px;
  display: block;
}

.jp-Notebook-ExecutionIndicator-progress-bar {
  display: flex;
  justify-content: center;
  height: 100%;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*
 * Execution indicator
 */
.jp-tocItem-content::after {
  content: '';

  /* Must be identical to form a circle */
  width: 12px;
  height: 12px;
  background: none;
  border: none;
  position: absolute;
  right: 0;
}

.jp-tocItem-content[data-running='0']::after {
  border-radius: 50%;
  border: var(--jp-border-width) solid var(--jp-inverse-layout-color3);
  background: none;
}

.jp-tocItem-content[data-running='1']::after {
  border-radius: 50%;
  border: var(--jp-border-width) solid var(--jp-inverse-layout-color3);
  background-color: var(--jp-inverse-layout-color3);
}

.jp-tocItem-content[data-running='0'],
.jp-tocItem-content[data-running='1'] {
  margin-right: 12px;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-Notebook-footer {
  height: 27px;
  margin-left: calc(
    var(--jp-cell-prompt-width) + var(--jp-cell-collapser-width) +
      var(--jp-cell-padding)
  );
  width: calc(
    100% -
      (
        var(--jp-cell-prompt-width) + var(--jp-cell-collapser-width) +
          var(--jp-cell-padding) + var(--jp-cell-padding)
      )
  );
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  color: var(--jp-ui-font-color3);
  margin-top: 6px;
  background: none;
  cursor: pointer;
}

.jp-Notebook-footer:focus {
  border-color: var(--jp-cell-editor-active-border-color);
}

/* For devices that support hovering, hide footer until hover */
@media (hover: hover) {
  .jp-Notebook-footer {
    opacity: 0;
  }

  .jp-Notebook-footer:focus,
  .jp-Notebook-footer:hover {
    opacity: 1;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Imports
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| CSS variables
|----------------------------------------------------------------------------*/

:root {
  --jp-side-by-side-output-size: 1fr;
  --jp-side-by-side-resized-cell: var(--jp-side-by-side-output-size);
  --jp-private-notebook-dragImage-width: 304px;
  --jp-private-notebook-dragImage-height: 36px;
  --jp-private-notebook-selected-color: var(--md-blue-400);
  --jp-private-notebook-active-color: var(--md-green-400);
}

/*-----------------------------------------------------------------------------
| Notebook
|----------------------------------------------------------------------------*/

/* stylelint-disable selector-max-class */

.jp-NotebookPanel {
  display: block;
  height: 100%;
}

.jp-NotebookPanel.jp-Document {
  min-width: 240px;
  min-height: 120px;
}

.jp-Notebook {
  padding: var(--jp-notebook-padding);
  outline: none;
  overflow: auto;
  background: var(--jp-layout-color0);
}

.jp-Notebook.jp-mod-scrollPastEnd::after {
  display: block;
  content: '';
  min-height: var(--jp-notebook-scroll-padding);
}

.jp-MainAreaWidget-ContainStrict .jp-Notebook * {
  contain: strict;
}

.jp-Notebook .jp-Cell {
  overflow: visible;
}

.jp-Notebook .jp-Cell .jp-InputPrompt {
  cursor: move;
}

/*-----------------------------------------------------------------------------
| Notebook state related styling
|
| The notebook and cells each have states, here are the possibilities:
|
| - Notebook
|   - Command
|   - Edit
| - Cell
|   - None
|   - Active (only one can be active)
|   - Selected (the cells actions are applied to)
|   - Multiselected (when multiple selected, the cursor)
|   - No outputs
|----------------------------------------------------------------------------*/

/* Command or edit modes */

.jp-Notebook .jp-Cell:not(.jp-mod-active) .jp-InputPrompt {
  opacity: var(--jp-cell-prompt-not-active-opacity);
  color: var(--jp-cell-prompt-not-active-font-color);
}

.jp-Notebook .jp-Cell:not(.jp-mod-active) .jp-OutputPrompt {
  opacity: var(--jp-cell-prompt-not-active-opacity);
  color: var(--jp-cell-prompt-not-active-font-color);
}

/* cell is active */
.jp-Notebook .jp-Cell.jp-mod-active .jp-Collapser {
  background: var(--jp-brand-color1);
}

/* cell is dirty */
.jp-Notebook .jp-Cell.jp-mod-dirty .jp-InputPrompt {
  color: var(--jp-warn-color1);
}

.jp-Notebook .jp-Cell.jp-mod-dirty .jp-InputPrompt::before {
  color: var(--jp-warn-color1);
  content: '•';
}

.jp-Notebook .jp-Cell.jp-mod-active.jp-mod-dirty .jp-Collapser {
  background: var(--jp-warn-color1);
}

/* collapser is hovered */
.jp-Notebook .jp-Cell .jp-Collapser:hover {
  box-shadow: var(--jp-elevation-z2);
  background: var(--jp-brand-color1);
  opacity: var(--jp-cell-collapser-not-active-hover-opacity);
}

/* cell is active and collapser is hovered */
.jp-Notebook .jp-Cell.jp-mod-active .jp-Collapser:hover {
  background: var(--jp-brand-color0);
  opacity: 1;
}

/* Command mode */

.jp-Notebook.jp-mod-commandMode .jp-Cell.jp-mod-selected {
  background: var(--jp-notebook-multiselected-color);
}

.jp-Notebook.jp-mod-commandMode
  .jp-Cell.jp-mod-active.jp-mod-selected:not(.jp-mod-multiSelected) {
  background: transparent;
}

/* Edit mode */

.jp-Notebook.jp-mod-editMode .jp-Cell.jp-mod-active .jp-InputArea-editor {
  border: var(--jp-border-width) solid var(--jp-cell-editor-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
  background-color: var(--jp-cell-editor-active-background);
}

/*-----------------------------------------------------------------------------
| Notebook drag and drop
|----------------------------------------------------------------------------*/

.jp-Notebook-cell.jp-mod-dropSource {
  opacity: 0.5;
}

.jp-Notebook-cell.jp-mod-dropTarget,
.jp-Notebook.jp-mod-commandMode
  .jp-Notebook-cell.jp-mod-active.jp-mod-selected.jp-mod-dropTarget {
  border-top-color: var(--jp-private-notebook-selected-color);
  border-top-style: solid;
  border-top-width: 2px;
}

.jp-dragImage {
  display: block;
  flex-direction: row;
  width: var(--jp-private-notebook-dragImage-width);
  height: var(--jp-private-notebook-dragImage-height);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background);
  overflow: visible;
}

.jp-dragImage-singlePrompt {
  box-shadow: 2px 2px 4px 0 rgba(0, 0, 0, 0.12);
}

.jp-dragImage .jp-dragImage-content {
  flex: 1 1 auto;
  z-index: 2;
  font-size: var(--jp-code-font-size);
  font-family: var(--jp-code-font-family);
  line-height: var(--jp-code-line-height);
  padding: var(--jp-code-padding);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background-color);
  color: var(--jp-content-font-color3);
  text-align: left;
  margin: 4px 4px 4px 0;
}

.jp-dragImage .jp-dragImage-prompt {
  flex: 0 0 auto;
  min-width: 36px;
  color: var(--jp-cell-inprompt-font-color);
  padding: var(--jp-code-padding);
  padding-left: 12px;
  font-family: var(--jp-cell-prompt-font-family);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  line-height: 1.9;
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
}

.jp-dragImage-multipleBack {
  z-index: -1;
  position: absolute;
  height: 32px;
  width: 300px;
  top: 8px;
  left: 8px;
  background: var(--jp-layout-color2);
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  box-shadow: 2px 2px 4px 0 rgba(0, 0, 0, 0.12);
}

/*-----------------------------------------------------------------------------
| Cell toolbar
|----------------------------------------------------------------------------*/

.jp-NotebookTools {
  display: block;
  min-width: var(--jp-sidebar-min-width);
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);

  /* This is needed so that all font sizing of children done in ems is
    * relative to this base size */
  font-size: var(--jp-ui-font-size1);
  overflow: auto;
}

.jp-ActiveCellTool {
  padding: 12px 0;
  display: flex;
}

.jp-ActiveCellTool-Content {
  flex: 1 1 auto;
}

.jp-ActiveCellTool .jp-ActiveCellTool-CellContent {
  background: var(--jp-cell-editor-background);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  border-radius: 0;
  min-height: 29px;
}

.jp-ActiveCellTool .jp-InputPrompt {
  min-width: calc(var(--jp-cell-prompt-width) * 0.75);
}

.jp-ActiveCellTool-CellContent > pre {
  padding: 5px 4px;
  margin: 0;
  white-space: normal;
}

.jp-MetadataEditorTool {
  flex-direction: column;
  padding: 12px 0;
}

.jp-RankedPanel > :not(:first-child) {
  margin-top: 12px;
}

.jp-KeySelector select.jp-mod-styled {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  border: var(--jp-border-width) solid var(--jp-border-color1);
}

.jp-KeySelector label,
.jp-MetadataEditorTool label,
.jp-NumberSetter label {
  line-height: 1.4;
}

.jp-NotebookTools .jp-select-wrapper {
  margin-top: 4px;
  margin-bottom: 0;
}

.jp-NumberSetter input {
  width: 100%;
  margin-top: 4px;
}

.jp-NotebookTools .jp-Collapse {
  margin-top: 16px;
}

/*-----------------------------------------------------------------------------
| Presentation Mode (.jp-mod-presentationMode)
|----------------------------------------------------------------------------*/

.jp-mod-presentationMode .jp-Notebook {
  --jp-content-font-size1: var(--jp-content-presentation-font-size1);
  --jp-code-font-size: var(--jp-code-presentation-font-size);
}

.jp-mod-presentationMode .jp-Notebook .jp-Cell .jp-InputPrompt,
.jp-mod-presentationMode .jp-Notebook .jp-Cell .jp-OutputPrompt {
  flex: 0 0 110px;
}

/*-----------------------------------------------------------------------------
| Side-by-side Mode (.jp-mod-sideBySide)
|----------------------------------------------------------------------------*/
.jp-mod-sideBySide.jp-Notebook .jp-Notebook-cell {
  margin-top: 3em;
  margin-bottom: 3em;
  margin-left: 5%;
  margin-right: 5%;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell {
  display: grid;
  grid-template-columns: minmax(0, 1fr) min-content minmax(
      0,
      var(--jp-side-by-side-output-size)
    );
  grid-template-rows: auto minmax(0, 1fr) auto;
  grid-template-areas:
    'header header header'
    'input handle output'
    'footer footer footer';
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell.jp-mod-resizedCell {
  grid-template-columns: minmax(0, 1fr) min-content minmax(
      0,
      var(--jp-side-by-side-resized-cell)
    );
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellHeader {
  grid-area: header;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-Cell-inputWrapper {
  grid-area: input;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-Cell-outputWrapper {
  /* overwrite the default margin (no vertical separation needed in side by side move */
  margin-top: 0;
  grid-area: output;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellFooter {
  grid-area: footer;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellResizeHandle {
  grid-area: handle;
  user-select: none;
  display: block;
  height: 100%;
  cursor: ew-resize;
  padding: 0 var(--jp-cell-padding);
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellResizeHandle::after {
  content: '';
  display: block;
  background: var(--jp-border-color2);
  height: 100%;
  width: 5px;
}

.jp-mod-sideBySide.jp-Notebook
  .jp-CodeCell.jp-mod-resizedCell
  .jp-CellResizeHandle::after {
  background: var(--jp-border-color0);
}

.jp-CellResizeHandle {
  display: none;
}

/*-----------------------------------------------------------------------------
| Placeholder
|----------------------------------------------------------------------------*/

.jp-Cell-Placeholder {
  padding-left: 55px;
}

.jp-Cell-Placeholder-wrapper {
  background: #fff;
  border: 1px solid;
  border-color: #e5e6e9 #dfe0e4 #d0d1d5;
  border-radius: 4px;
  -webkit-border-radius: 4px;
  margin: 10px 15px;
}

.jp-Cell-Placeholder-wrapper-inner {
  padding: 15px;
  position: relative;
}

.jp-Cell-Placeholder-wrapper-body {
  background-repeat: repeat;
  background-size: 50% auto;
}

.jp-Cell-Placeholder-wrapper-body div {
  background: #f6f7f8;
  background-image: -webkit-linear-gradient(
    left,
    #f6f7f8 0%,
    #edeef1 20%,
    #f6f7f8 40%,
    #f6f7f8 100%
  );
  background-repeat: no-repeat;
  background-size: 800px 104px;
  height: 104px;
  position: absolute;
  right: 15px;
  left: 15px;
  top: 15px;
}

div.jp-Cell-Placeholder-h1 {
  top: 20px;
  height: 20px;
  left: 15px;
  width: 150px;
}

div.jp-Cell-Placeholder-h2 {
  left: 15px;
  top: 50px;
  height: 10px;
  width: 100px;
}

div.jp-Cell-Placeholder-content-1,
div.jp-Cell-Placeholder-content-2,
div.jp-Cell-Placeholder-content-3 {
  left: 15px;
  right: 15px;
  height: 10px;
}

div.jp-Cell-Placeholder-content-1 {
  top: 100px;
}

div.jp-Cell-Placeholder-content-2 {
  top: 120px;
}

div.jp-Cell-Placeholder-content-3 {
  top: 140px;
}

</style>
<style type="text/css">
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*
The following CSS variables define the main, public API for styling JupyterLab.
These variables should be used by all plugins wherever possible. In other
words, plugins should not define custom colors, sizes, etc unless absolutely
necessary. This enables users to change the visual theme of JupyterLab
by changing these variables.

Many variables appear in an ordered sequence (0,1,2,3). These sequences
are designed to work well together, so for example, `--jp-border-color1` should
be used with `--jp-layout-color1`. The numbers have the following meanings:

* 0: super-primary, reserved for special emphasis
* 1: primary, most important under normal situations
* 2: secondary, next most important under normal situations
* 3: tertiary, next most important under normal situations

Throughout JupyterLab, we are mostly following principles from Google's
Material Design when selecting colors. We are not, however, following
all of MD as it is not optimized for dense, information rich UIs.
*/

:root {
  /* Elevation
   *
   * We style box-shadows using Material Design's idea of elevation. These particular numbers are taken from here:
   *
   * https://github.com/material-components/material-components-web
   * https://material-components-web.appspot.com/elevation.html
   */

  --jp-shadow-base-lightness: 0;
  --jp-shadow-umbra-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.2
  );
  --jp-shadow-penumbra-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.14
  );
  --jp-shadow-ambient-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.12
  );
  --jp-elevation-z0: none;
  --jp-elevation-z1: 0 2px 1px -1px var(--jp-shadow-umbra-color),
    0 1px 1px 0 var(--jp-shadow-penumbra-color),
    0 1px 3px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z2: 0 3px 1px -2px var(--jp-shadow-umbra-color),
    0 2px 2px 0 var(--jp-shadow-penumbra-color),
    0 1px 5px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z4: 0 2px 4px -1px var(--jp-shadow-umbra-color),
    0 4px 5px 0 var(--jp-shadow-penumbra-color),
    0 1px 10px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z6: 0 3px 5px -1px var(--jp-shadow-umbra-color),
    0 6px 10px 0 var(--jp-shadow-penumbra-color),
    0 1px 18px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z8: 0 5px 5px -3px var(--jp-shadow-umbra-color),
    0 8px 10px 1px var(--jp-shadow-penumbra-color),
    0 3px 14px 2px var(--jp-shadow-ambient-color);
  --jp-elevation-z12: 0 7px 8px -4px var(--jp-shadow-umbra-color),
    0 12px 17px 2px var(--jp-shadow-penumbra-color),
    0 5px 22px 4px var(--jp-shadow-ambient-color);
  --jp-elevation-z16: 0 8px 10px -5px var(--jp-shadow-umbra-color),
    0 16px 24px 2px var(--jp-shadow-penumbra-color),
    0 6px 30px 5px var(--jp-shadow-ambient-color);
  --jp-elevation-z20: 0 10px 13px -6px var(--jp-shadow-umbra-color),
    0 20px 31px 3px var(--jp-shadow-penumbra-color),
    0 8px 38px 7px var(--jp-shadow-ambient-color);
  --jp-elevation-z24: 0 11px 15px -7px var(--jp-shadow-umbra-color),
    0 24px 38px 3px var(--jp-shadow-penumbra-color),
    0 9px 46px 8px var(--jp-shadow-ambient-color);

  /* Borders
   *
   * The following variables, specify the visual styling of borders in JupyterLab.
   */

  --jp-border-width: 1px;
  --jp-border-color0: var(--md-grey-400);
  --jp-border-color1: var(--md-grey-400);
  --jp-border-color2: var(--md-grey-300);
  --jp-border-color3: var(--md-grey-200);
  --jp-inverse-border-color: var(--md-grey-600);
  --jp-border-radius: 2px;

  /* UI Fonts
   *
   * The UI font CSS variables are used for the typography all of the JupyterLab
   * user interface elements that are not directly user generated content.
   *
   * The font sizing here is done assuming that the body font size of --jp-ui-font-size1
   * is applied to a parent element. When children elements, such as headings, are sized
   * in em all things will be computed relative to that body size.
   */

  --jp-ui-font-scale-factor: 1.2;
  --jp-ui-font-size0: 0.83333em;
  --jp-ui-font-size1: 13px; /* Base font size */
  --jp-ui-font-size2: 1.2em;
  --jp-ui-font-size3: 1.44em;
  --jp-ui-font-family: system-ui, -apple-system, blinkmacsystemfont, 'Segoe UI',
    helvetica, arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji',
    'Segoe UI Symbol';

  /*
   * Use these font colors against the corresponding main layout colors.
   * In a light theme, these go from dark to light.
   */

  /* Defaults use Material Design specification */
  --jp-ui-font-color0: rgba(0, 0, 0, 1);
  --jp-ui-font-color1: rgba(0, 0, 0, 0.87);
  --jp-ui-font-color2: rgba(0, 0, 0, 0.54);
  --jp-ui-font-color3: rgba(0, 0, 0, 0.38);

  /*
   * Use these against the brand/accent/warn/error colors.
   * These will typically go from light to darker, in both a dark and light theme.
   */

  --jp-ui-inverse-font-color0: rgba(255, 255, 255, 1);
  --jp-ui-inverse-font-color1: rgba(255, 255, 255, 1);
  --jp-ui-inverse-font-color2: rgba(255, 255, 255, 0.7);
  --jp-ui-inverse-font-color3: rgba(255, 255, 255, 0.5);

  /* Content Fonts
   *
   * Content font variables are used for typography of user generated content.
   *
   * The font sizing here is done assuming that the body font size of --jp-content-font-size1
   * is applied to a parent element. When children elements, such as headings, are sized
   * in em all things will be computed relative to that body size.
   */

  --jp-content-line-height: 1.6;
  --jp-content-font-scale-factor: 1.2;
  --jp-content-font-size0: 0.83333em;
  --jp-content-font-size1: 14px; /* Base font size */
  --jp-content-font-size2: 1.2em;
  --jp-content-font-size3: 1.44em;
  --jp-content-font-size4: 1.728em;
  --jp-content-font-size5: 2.0736em;

  /* This gives a magnification of about 125% in presentation mode over normal. */
  --jp-content-presentation-font-size1: 17px;
  --jp-content-heading-line-height: 1;
  --jp-content-heading-margin-top: 1.2em;
  --jp-content-heading-margin-bottom: 0.8em;
  --jp-content-heading-font-weight: 500;

  /* Defaults use Material Design specification */
  --jp-content-font-color0: rgba(0, 0, 0, 1);
  --jp-content-font-color1: rgba(0, 0, 0, 0.87);
  --jp-content-font-color2: rgba(0, 0, 0, 0.54);
  --jp-content-font-color3: rgba(0, 0, 0, 0.38);
  --jp-content-link-color: var(--md-blue-900);
  --jp-content-font-family: system-ui, -apple-system, blinkmacsystemfont,
    'Segoe UI', helvetica, arial, sans-serif, 'Apple Color Emoji',
    'Segoe UI Emoji', 'Segoe UI Symbol';

  /*
   * Code Fonts
   *
   * Code font variables are used for typography of code and other monospaces content.
   */

  --jp-code-font-size: 13px;
  --jp-code-line-height: 1.3077; /* 17px for 13px base */
  --jp-code-padding: 5px; /* 5px for 13px base, codemirror highlighting needs integer px value */
  --jp-code-font-family-default: menlo, consolas, 'DejaVu Sans Mono', monospace;
  --jp-code-font-family: var(--jp-code-font-family-default);

  /* This gives a magnification of about 125% in presentation mode over normal. */
  --jp-code-presentation-font-size: 16px;

  /* may need to tweak cursor width if you change font size */
  --jp-code-cursor-width0: 1.4px;
  --jp-code-cursor-width1: 2px;
  --jp-code-cursor-width2: 4px;

  /* Layout
   *
   * The following are the main layout colors use in JupyterLab. In a light
   * theme these would go from light to dark.
   */

  --jp-layout-color0: white;
  --jp-layout-color1: white;
  --jp-layout-color2: var(--md-grey-200);
  --jp-layout-color3: var(--md-grey-400);
  --jp-layout-color4: var(--md-grey-600);

  /* Inverse Layout
   *
   * The following are the inverse layout colors use in JupyterLab. In a light
   * theme these would go from dark to light.
   */

  --jp-inverse-layout-color0: #111;
  --jp-inverse-layout-color1: var(--md-grey-900);
  --jp-inverse-layout-color2: var(--md-grey-800);
  --jp-inverse-layout-color3: var(--md-grey-700);
  --jp-inverse-layout-color4: var(--md-grey-600);

  /* Brand/accent */

  --jp-brand-color0: var(--md-blue-900);
  --jp-brand-color1: var(--md-blue-700);
  --jp-brand-color2: var(--md-blue-300);
  --jp-brand-color3: var(--md-blue-100);
  --jp-brand-color4: var(--md-blue-50);
  --jp-accent-color0: var(--md-green-900);
  --jp-accent-color1: var(--md-green-700);
  --jp-accent-color2: var(--md-green-300);
  --jp-accent-color3: var(--md-green-100);

  /* State colors (warn, error, success, info) */

  --jp-warn-color0: var(--md-orange-900);
  --jp-warn-color1: var(--md-orange-700);
  --jp-warn-color2: var(--md-orange-300);
  --jp-warn-color3: var(--md-orange-100);
  --jp-error-color0: var(--md-red-900);
  --jp-error-color1: var(--md-red-700);
  --jp-error-color2: var(--md-red-300);
  --jp-error-color3: var(--md-red-100);
  --jp-success-color0: var(--md-green-900);
  --jp-success-color1: var(--md-green-700);
  --jp-success-color2: var(--md-green-300);
  --jp-success-color3: var(--md-green-100);
  --jp-info-color0: var(--md-cyan-900);
  --jp-info-color1: var(--md-cyan-700);
  --jp-info-color2: var(--md-cyan-300);
  --jp-info-color3: var(--md-cyan-100);

  /* Cell specific styles */

  --jp-cell-padding: 5px;
  --jp-cell-collapser-width: 8px;
  --jp-cell-collapser-min-height: 20px;
  --jp-cell-collapser-not-active-hover-opacity: 0.6;
  --jp-cell-editor-background: var(--md-grey-100);
  --jp-cell-editor-border-color: var(--md-grey-300);
  --jp-cell-editor-box-shadow: inset 0 0 2px var(--md-blue-300);
  --jp-cell-editor-active-background: var(--jp-layout-color0);
  --jp-cell-editor-active-border-color: var(--jp-brand-color1);
  --jp-cell-prompt-width: 64px;
  --jp-cell-prompt-font-family: var(--jp-code-font-family-default);
  --jp-cell-prompt-letter-spacing: 0;
  --jp-cell-prompt-opacity: 1;
  --jp-cell-prompt-not-active-opacity: 0.5;
  --jp-cell-prompt-not-active-font-color: var(--md-grey-700);

  /* A custom blend of MD grey and blue 600
   * See https://meyerweb.com/eric/tools/color-blend/#546E7A:1E88E5:5:hex */
  --jp-cell-inprompt-font-color: #307fc1;

  /* A custom blend of MD grey and orange 600
   * https://meyerweb.com/eric/tools/color-blend/#546E7A:F4511E:5:hex */
  --jp-cell-outprompt-font-color: #bf5b3d;

  /* Notebook specific styles */

  --jp-notebook-padding: 10px;
  --jp-notebook-select-background: var(--jp-layout-color1);
  --jp-notebook-multiselected-color: var(--md-blue-50);

  /* The scroll padding is calculated to fill enough space at the bottom of the
  notebook to show one single-line cell (with appropriate padding) at the top
  when the notebook is scrolled all the way to the bottom. We also subtract one
  pixel so that no scrollbar appears if we have just one single-line cell in the
  notebook. This padding is to enable a 'scroll past end' feature in a notebook.
  */
  --jp-notebook-scroll-padding: calc(
    100% - var(--jp-code-font-size) * var(--jp-code-line-height) -
      var(--jp-code-padding) - var(--jp-cell-padding) - 1px
  );

  /* Rendermime styles */

  --jp-rendermime-error-background: #fdd;
  --jp-rendermime-table-row-background: var(--md-grey-100);
  --jp-rendermime-table-row-hover-background: var(--md-light-blue-50);

  /* Dialog specific styles */

  --jp-dialog-background: rgba(0, 0, 0, 0.25);

  /* Console specific styles */

  --jp-console-padding: 10px;

  /* Toolbar specific styles */

  --jp-toolbar-border-color: var(--jp-border-color1);
  --jp-toolbar-micro-height: 8px;
  --jp-toolbar-background: var(--jp-layout-color1);
  --jp-toolbar-box-shadow: 0 0 2px 0 rgba(0, 0, 0, 0.24);
  --jp-toolbar-header-margin: 4px 4px 0 4px;
  --jp-toolbar-active-background: var(--md-grey-300);

  /* Statusbar specific styles */

  --jp-statusbar-height: 24px;

  /* Input field styles */

  --jp-input-box-shadow: inset 0 0 2px var(--md-blue-300);
  --jp-input-active-background: var(--jp-layout-color1);
  --jp-input-hover-background: var(--jp-layout-color1);
  --jp-input-background: var(--md-grey-100);
  --jp-input-border-color: var(--jp-inverse-border-color);
  --jp-input-active-border-color: var(--jp-brand-color1);
  --jp-input-active-box-shadow-color: rgba(19, 124, 189, 0.3);

  /* General editor styles */

  --jp-editor-selected-background: #d9d9d9;
  --jp-editor-selected-focused-background: #d7d4f0;
  --jp-editor-cursor-color: var(--jp-ui-font-color0);

  /* Code mirror specific styles */

  --jp-mirror-editor-keyword-color: #008000;
  --jp-mirror-editor-atom-color: #88f;
  --jp-mirror-editor-number-color: #080;
  --jp-mirror-editor-def-color: #00f;
  --jp-mirror-editor-variable-color: var(--md-grey-900);
  --jp-mirror-editor-variable-2-color: rgb(0, 54, 109);
  --jp-mirror-editor-variable-3-color: #085;
  --jp-mirror-editor-punctuation-color: #05a;
  --jp-mirror-editor-property-color: #05a;
  --jp-mirror-editor-operator-color: #a2f;
  --jp-mirror-editor-comment-color: #408080;
  --jp-mirror-editor-string-color: #ba2121;
  --jp-mirror-editor-string-2-color: #708;
  --jp-mirror-editor-meta-color: #a2f;
  --jp-mirror-editor-qualifier-color: #555;
  --jp-mirror-editor-builtin-color: #008000;
  --jp-mirror-editor-bracket-color: #997;
  --jp-mirror-editor-tag-color: #170;
  --jp-mirror-editor-attribute-color: #00c;
  --jp-mirror-editor-header-color: blue;
  --jp-mirror-editor-quote-color: #090;
  --jp-mirror-editor-link-color: #00c;
  --jp-mirror-editor-error-color: #f00;
  --jp-mirror-editor-hr-color: #999;

  /*
    RTC user specific colors.
    These colors are used for the cursor, username in the editor,
    and the icon of the user.
  */

  --jp-collaborator-color1: #ffad8e;
  --jp-collaborator-color2: #dac83d;
  --jp-collaborator-color3: #72dd76;
  --jp-collaborator-color4: #00e4d0;
  --jp-collaborator-color5: #45d4ff;
  --jp-collaborator-color6: #e2b1ff;
  --jp-collaborator-color7: #ff9de6;

  /* Vega extension styles */

  --jp-vega-background: white;

  /* Sidebar-related styles */

  --jp-sidebar-min-width: 250px;

  /* Search-related styles */

  --jp-search-toggle-off-opacity: 0.5;
  --jp-search-toggle-hover-opacity: 0.8;
  --jp-search-toggle-on-opacity: 1;
  --jp-search-selected-match-background-color: rgb(245, 200, 0);
  --jp-search-selected-match-color: black;
  --jp-search-unselected-match-background-color: var(
    --jp-inverse-layout-color0
  );
  --jp-search-unselected-match-color: var(--jp-ui-inverse-font-color0);

  /* Icon colors that work well with light or dark backgrounds */
  --jp-icon-contrast-color0: var(--md-purple-600);
  --jp-icon-contrast-color1: var(--md-green-600);
  --jp-icon-contrast-color2: var(--md-pink-600);
  --jp-icon-contrast-color3: var(--md-blue-600);

  /* Button colors */
  --jp-accept-color-normal: var(--md-blue-700);
  --jp-accept-color-hover: var(--md-blue-800);
  --jp-accept-color-active: var(--md-blue-900);
  --jp-warn-color-normal: var(--md-red-700);
  --jp-warn-color-hover: var(--md-red-800);
  --jp-warn-color-active: var(--md-red-900);
  --jp-reject-color-normal: var(--md-grey-600);
  --jp-reject-color-hover: var(--md-grey-700);
  --jp-reject-color-active: var(--md-grey-800);

  /* File or activity icons and switch semantic variables */
  --jp-jupyter-icon-color: #f37626;
  --jp-notebook-icon-color: #f37626;
  --jp-json-icon-color: var(--md-orange-700);
  --jp-console-icon-background-color: var(--md-blue-700);
  --jp-console-icon-color: white;
  --jp-terminal-icon-background-color: var(--md-grey-800);
  --jp-terminal-icon-color: var(--md-grey-200);
  --jp-text-editor-icon-color: var(--md-grey-700);
  --jp-inspector-icon-color: var(--md-grey-700);
  --jp-switch-color: var(--md-grey-400);
  --jp-switch-true-position-color: var(--md-orange-900);
}
</style>
<style type="text/css">
/* Force rendering true colors when outputing to pdf */
* {
  -webkit-print-color-adjust: exact;
}

/* Misc */
a.anchor-link {
  display: none;
}

/* Input area styling */
.jp-InputArea {
  overflow: hidden;
}

.jp-InputArea-editor {
  overflow: hidden;
}

.cm-editor.cm-s-jupyter .highlight pre {
/* weird, but --jp-code-padding defined to be 5px but 4px horizontal padding is hardcoded for pre.cm-line */
  padding: var(--jp-code-padding) 4px;
  margin: 0;

  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
  color: inherit;

}

.jp-OutputArea-output pre {
  line-height: inherit;
  font-family: inherit;
}

.jp-RenderedText pre {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-code-font-size);
}

/* Hiding the collapser by default */
.jp-Collapser {
  display: none;
}

@page {
    margin: 0.5in; /* Margin for each printed piece of paper */
}

@media print {
  .jp-Cell-inputWrapper,
  .jp-Cell-outputWrapper {
    display: block;
  }
}
</style>
<!-- Load mathjax -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML-full,Safe"> </script>
<!-- MathJax configuration -->
<script type="text/x-mathjax-config">
    init_mathjax = function() {
        if (window.MathJax) {
        // MathJax loaded
            MathJax.Hub.Config({
                TeX: {
                    equationNumbers: {
                    autoNumber: "AMS",
                    useLabelIds: true
                    }
                },
                tex2jax: {
                    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                    processEscapes: true,
                    processEnvironments: true
                },
                displayAlign: 'center',
                CommonHTML: {
                    linebreaks: {
                    automatic: true
                    }
                }
            });

            MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
        }
    }
    init_mathjax();
    </script>
<!-- End of mathjax configuration --><script type="module">
  document.addEventListener("DOMContentLoaded", async () => {
    const diagrams = document.querySelectorAll(".jp-Mermaid > pre.mermaid");
    // do not load mermaidjs if not needed
    if (!diagrams.length) {
      return;
    }
    const mermaid = (await import("https://cdnjs.cloudflare.com/ajax/libs/mermaid/10.7.0/mermaid.esm.min.mjs")).default;
    const parser = new DOMParser();

    mermaid.initialize({
      maxTextSize: 100000,
      maxEdges: 100000,
      startOnLoad: false,
      fontFamily: window
        .getComputedStyle(document.body)
        .getPropertyValue("--jp-ui-font-family"),
      theme: document.querySelector("body[data-jp-theme-light='true']")
        ? "default"
        : "dark",
    });

    let _nextMermaidId = 0;

    function makeMermaidImage(svg) {
      const img = document.createElement("img");
      const doc = parser.parseFromString(svg, "image/svg+xml");
      const svgEl = doc.querySelector("svg");
      const { maxWidth } = svgEl?.style || {};
      const firstTitle = doc.querySelector("title");
      const firstDesc = doc.querySelector("desc");

      img.setAttribute("src", `data:image/svg+xml,${encodeURIComponent(svg)}`);
      if (maxWidth) {
        img.width = parseInt(maxWidth);
      }
      if (firstTitle) {
        img.setAttribute("alt", firstTitle.textContent);
      }
      if (firstDesc) {
        const caption = document.createElement("figcaption");
        caption.className = "sr-only";
        caption.textContent = firstDesc.textContent;
        return [img, caption];
      }
      return [img];
    }

    async function makeMermaidError(text) {
      let errorMessage = "";
      try {
        await mermaid.parse(text);
      } catch (err) {
        errorMessage = `${err}`;
      }

      const result = document.createElement("details");
      result.className = 'jp-RenderedMermaid-Details';
      const summary = document.createElement("summary");
      summary.className = 'jp-RenderedMermaid-Summary';
      const pre = document.createElement("pre");
      const code = document.createElement("code");
      code.innerText = text;
      pre.appendChild(code);
      summary.appendChild(pre);
      result.appendChild(summary);

      const warning = document.createElement("pre");
      warning.innerText = errorMessage;
      result.appendChild(warning);
      return [result];
    }

    async function renderOneMarmaid(src) {
      const id = `jp-mermaid-${_nextMermaidId++}`;
      const parent = src.parentNode;
      let raw = src.textContent.trim();
      const el = document.createElement("div");
      el.style.visibility = "hidden";
      document.body.appendChild(el);
      let results = null;
      let output = null;
      try {
        let { svg } = await mermaid.render(id, raw, el);
        svg = cleanMermaidSvg(svg);
        results = makeMermaidImage(svg);
        output = document.createElement("figure");
        results.map(output.appendChild, output);
      } catch (err) {
        parent.classList.add("jp-mod-warning");
        results = await makeMermaidError(raw);
        output = results[0];
      } finally {
        el.remove();
      }
      parent.classList.add("jp-RenderedMermaid");
      parent.appendChild(output);
    }


    /**
     * Post-process to ensure mermaid diagrams contain only valid SVG and XHTML.
     */
    function cleanMermaidSvg(svg) {
      return svg.replace(RE_VOID_ELEMENT, replaceVoidElement);
    }


    /**
     * A regular expression for all void elements, which may include attributes and
     * a slash.
     *
     * @see https://developer.mozilla.org/en-US/docs/Glossary/Void_element
     *
     * Of these, only `<br>` is generated by Mermaid in place of `\n`,
     * but _any_ "malformed" tag will break the SVG rendering entirely.
     */
    const RE_VOID_ELEMENT =
      /<\s*(area|base|br|col|embed|hr|img|input|link|meta|param|source|track|wbr)\s*([^>]*?)\s*>/gi;

    /**
     * Ensure a void element is closed with a slash, preserving any attributes.
     */
    function replaceVoidElement(match, tag, rest) {
      rest = rest.trim();
      if (!rest.endsWith('/')) {
        rest = `${rest} /`;
      }
      return `<${tag} ${rest}>`;
    }

    void Promise.all([...diagrams].map(renderOneMarmaid));
  });
</script>
<style>
  .jp-Mermaid:not(.jp-RenderedMermaid) {
    display: none;
  }

  .jp-RenderedMermaid {
    overflow: auto;
    display: flex;
  }

  .jp-RenderedMermaid.jp-mod-warning {
    width: auto;
    padding: 0.5em;
    margin-top: 0.5em;
    border: var(--jp-border-width) solid var(--jp-warn-color2);
    border-radius: var(--jp-border-radius);
    color: var(--jp-ui-font-color1);
    font-size: var(--jp-ui-font-size1);
    white-space: pre-wrap;
    word-wrap: break-word;
  }

  .jp-RenderedMermaid figure {
    margin: 0;
    overflow: auto;
    max-width: 100%;
  }

  .jp-RenderedMermaid img {
    max-width: 100%;
  }

  .jp-RenderedMermaid-Details > pre {
    margin-top: 1em;
  }

  .jp-RenderedMermaid-Summary {
    color: var(--jp-warn-color2);
  }

  .jp-RenderedMermaid:not(.jp-mod-warning) pre {
    display: none;
  }

  .jp-RenderedMermaid-Summary > pre {
    display: inline-block;
    white-space: normal;
  }
</style>
<!-- End of mermaid configuration --></head>
<body class="jp-Notebook" data-jp-theme-light="true" data-jp-theme-name="JupyterLab Light">
<main>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p><a href="https://colab.research.google.com/github/zphilip/zphilip.github.io/blob/main/GPR.ipynb" target="_parent"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg"/></a></p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>GP learning by doing , Refer to
<a href="https://peterroelants.github.io/posts/gaussian-process-kernels/">https://peterroelants.github.io/posts/gaussian-process-kernels/</a>
<a href="https://zhuanlan.zhihu.com/p/31427491">https://zhuanlan.zhihu.com/p/31427491</a></p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="c1"># Imports</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="o">%</span><span class="n">config</span> <span class="n">InlineBackend</span><span class="o">.</span><span class="n">figure_format</span> <span class="o">=</span> <span class="s1">'svg'</span>

<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="s2">"ignore"</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">tensorflow_probability</span> <span class="k">as</span> <span class="nn">tfp</span>

<span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">cm</span>
<span class="kn">from</span> <span class="nn">mpl_toolkits.axes_grid1</span> <span class="kn">import</span> <span class="n">make_axes_locatable</span>
<span class="kn">import</span> <span class="nn">matplotlib.gridspec</span> <span class="k">as</span> <span class="nn">gridspec</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="n">tfb</span> <span class="o">=</span> <span class="n">tfp</span><span class="o">.</span><span class="n">bijectors</span>
<span class="n">tfd</span> <span class="o">=</span> <span class="n">tfp</span><span class="o">.</span><span class="n">distributions</span>
<span class="n">tfk</span> <span class="o">=</span> <span class="n">tfp</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">psd_kernels</span> <span class="c1"># Positive-semidefinite kernels package, 也是对一切合法kernal的定义</span>

<span class="n">sns</span><span class="o">.</span><span class="n">set_style</span><span class="p">(</span><span class="s1">'darkgrid'</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="c1"># Plotting function to be used below</span>

<span class="k">def</span> <span class="nf">plot_kernel</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">Σ</span><span class="p">,</span> <span class="n">description</span><span class="p">,</span> <span class="n">fig</span><span class="p">,</span> <span class="n">subplot_spec</span><span class="p">,</span> <span class="n">xlim</span><span class="p">,</span>
                <span class="n">scatter</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">rotate_x_labels</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Plot kernel matrix and samples."""</span>
    <span class="n">grid_spec</span> <span class="o">=</span> <span class="n">gridspec</span><span class="o">.</span><span class="n">GridSpecFromSubplotSpec</span><span class="p">(</span>
        <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">width_ratios</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="n">height_ratios</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
        <span class="n">wspace</span><span class="o">=</span><span class="mf">0.18</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
        <span class="n">subplot_spec</span><span class="o">=</span><span class="n">subplot_spec</span><span class="p">)</span>
    <span class="n">ax1</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="n">grid_spec</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">ax2</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="n">grid_spec</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="c1"># Plot samples</span>
    <span class="k">if</span> <span class="n">scatter</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="n">ax1</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">[:,</span><span class="n">i</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">[:,</span><span class="n">i</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">'$y$'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">13</span><span class="p">,</span> <span class="n">labelpad</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">'$x$'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">13</span><span class="p">,</span> <span class="n">labelpad</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="n">xlim</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">rotate_x_labels</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">ax1</span><span class="o">.</span><span class="n">get_xticklabels</span><span class="p">():</span>
            <span class="n">l</span><span class="o">.</span><span class="n">set_rotation</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Samples from </span><span class="si">{</span><span class="n">description</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
    <span class="c1"># Plot covariance matrix</span>
    <span class="n">im</span> <span class="o">=</span> <span class="n">ax2</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">Σ</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cm</span><span class="o">.</span><span class="n">YlGnBu</span><span class="p">)</span>
    <span class="n">divider</span> <span class="o">=</span> <span class="n">make_axes_locatable</span><span class="p">(</span><span class="n">ax2</span><span class="p">)</span>
    <span class="n">cax</span> <span class="o">=</span> <span class="n">divider</span><span class="o">.</span><span class="n">append_axes</span><span class="p">(</span><span class="s1">'right'</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="s1">'5%'</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="mf">0.02</span><span class="p">)</span>
    <span class="n">cbar</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax2</span><span class="p">,</span> <span class="n">cax</span><span class="o">=</span><span class="n">cax</span><span class="p">)</span>
    <span class="n">cbar</span><span class="o">.</span><span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">'$K(X,X)$'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Covariance matrix</span><span class="se">\n</span><span class="si">{</span><span class="n">description</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">'X'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">labelpad</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">'X'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">labelpad</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="c1"># Show 5 custom ticks on x an y axis of covariance plot</span>
    <span class="n">nb_ticks</span> <span class="o">=</span> <span class="mi">5</span>
    <span class="n">ticks</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">xlim</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">xlim</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">ticks_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">rint</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span>
        <span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">ticks</span><span class="p">),</span> <span class="n">num</span><span class="o">=</span><span class="nb">min</span><span class="p">(</span><span class="n">nb_ticks</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">ticks</span><span class="p">)))</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
    <span class="n">ticks</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">ticks</span><span class="p">)[</span><span class="n">ticks_idx</span><span class="p">])</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">ticks</span><span class="p">)))</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">ticks</span><span class="p">)))</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">(</span><span class="n">ticks</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">(</span><span class="n">ticks</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">rotate_x_labels</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">ax2</span><span class="o">.</span><span class="n">get_xticklabels</span><span class="p">():</span>
            <span class="n">l</span><span class="o">.</span><span class="n">set_rotation</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
<span class="c1">#</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>Kernel function
A kernel (or covariance function) describes the covariance of the Gaussian process random variables. Together with the mean function the kernel completely defines a Gaussian process.</p>
<p>The kernel function $k(x, x')$ models the covariance between each pair in $x$. The kernel function together with the mean function $m(x)$
define the Gaussian process distribution:
$$y \sim \mathcal{GP}(m(x),k(x,x'))$$</p>
<p>Valid kernels</p>
<p>n order to be a valid kernel function the resulting kernel matrix $\Sigma = k(X, X)$
should <strong>be positive definite</strong> . Which implies that the matrix should be <strong>symmetric</strong> . Being positive definite also means that the kernel matrix is invertible .</p>
<p>The process of defining a new valid kernel from scratch it not always trivial. Typically pre-defined kernels are used to model a variety of processes. In what follows we will visually explore some of these pre-defined kernels</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p><strong>Squared Exponential Kernel (Exponentiated quadratic kernel)</strong>
The exponentiated quadratic kernel (also known as squared exponential kernel, Gaussian kernel or radial basis function kernel) is one of the most popular kernels used in Gaussian process modelling. It can be computed as:
$$k(x_a, x_b) = \sigma^2 \exp \left(-\frac{ \left\Vert x_a - x_b \right\Vert^2}{2\ell^2}\right)$$</p>
<p>With:</p>
<ul>
<li>$\sigma^2$the overall variance (\sigma
is also known as amplitude). it determines the average distance of your function away from its mean. Every kernel has this parameter out in front; it's just a scale factor.</li>
<li>$l$ the lengthscale.determines the length of the 'wiggles' in your function. In general, you won't be able to extrapolate more than ℓ
units away from your data</li>
</ul>
<p>Using the exponentiated quadratic kernel will result in a smooth prior on functions sampled from the Gaussian process.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="c1"># Plot exponentiated quadratic distance</span>

<span class="n">xlim</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">*</span><span class="n">xlim</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">75</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">zero</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.</span><span class="p">]])</span>
<span class="c1"># Make the plots</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mf">5.4</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>

<span class="n">Σ</span> <span class="o">=</span> <span class="n">tfk</span><span class="o">.</span><span class="n">ExponentiatedQuadratic</span><span class="p">(</span><span class="n">amplitude</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">length_scale</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span><span class="o">.</span><span class="n">matrix</span><span class="p">(</span><span class="n">zero</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">Σ</span><span class="p">[</span><span class="mi">0</span><span class="p">,:],</span> <span class="n">label</span><span class="o">=</span><span class="s1">'$</span><span class="se">\\</span><span class="s1">ell = 1$, $</span><span class="se">\\</span><span class="s1">sigma = 1$'</span><span class="p">)</span>
<span class="n">Σ</span> <span class="o">=</span> <span class="n">tfk</span><span class="o">.</span><span class="n">ExponentiatedQuadratic</span><span class="p">(</span><span class="n">amplitude</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">length_scale</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">matrix</span><span class="p">(</span><span class="n">zero</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">Σ</span><span class="p">[</span><span class="mi">0</span><span class="p">,:],</span> <span class="n">label</span><span class="o">=</span><span class="s1">'$</span><span class="se">\\</span><span class="s1">ell = 0.5$, $</span><span class="se">\\</span><span class="s1">sigma = 1$'</span><span class="p">)</span>
<span class="n">Σ</span> <span class="o">=</span>  <span class="n">tfk</span><span class="o">.</span><span class="n">ExponentiatedQuadratic</span><span class="p">(</span><span class="n">amplitude</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">length_scale</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span><span class="o">.</span><span class="n">matrix</span><span class="p">(</span><span class="n">zero</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">Σ</span><span class="p">[</span><span class="mi">0</span><span class="p">,:],</span> <span class="n">label</span><span class="o">=</span><span class="s1">'$</span><span class="se">\\</span><span class="s1">ell = 1$, $</span><span class="se">\\</span><span class="s1">sigma = 0.5$'</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">'$x_a - x_b$'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">'$K(x_a,x_b)$'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">'Exponentiated quadratic distance plot'</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mf">1.1</span><span class="p">])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="o">*</span><span class="n">xlim</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="c1">#</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedSVG jp-OutputArea-output" data-mime-type="image/svg+xml" tabindex="0">
<img alt="No description has been provided for this image" src="data:image/svg+xml;base64,<?xml version="1.0" encoding="utf-8" standalone="no"?>
<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN"
  "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">
<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="379.164906pt" height="190.268031pt" viewBox="0 0 379.164906 190.268031" xmlns="http://www.w3.org/2000/svg" version="1.1">
 <metadata>
  <rdf:RDF xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:cc="http://creativecommons.org/ns#" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#">
   <cc:Work>
    <dc:type rdf:resource="http://purl.org/dc/dcmitype/StillImage"/>
    <dc:date>2023-05-10T02:40:30.693746</dc:date>
    <dc:format>image/svg+xml</dc:format>
    <dc:creator>
     <cc:Agent>
      <dc:title>Matplotlib v3.7.1, https://matplotlib.org/</dc:title>
     </cc:Agent>
    </dc:creator>
   </cc:Work>
  </rdf:RDF>
 </metadata>
 <defs>
  <style type="text/css">*{stroke-linejoin: round; stroke-linecap: butt}</style>
 </defs>
 <g id="figure_1">
  <g id="patch_1">
   <path d="M 0 190.268031 
L 379.164906 190.268031 
L 379.164906 0 
L 0 0 
z
" style="fill: #ffffff"/>
  </g>
  <g id="axes_1">
   <g id="patch_2">
    <path d="M 60.586094 139.953187 
L 338.728094 139.953187 
L 338.728094 26.877188 
L 60.586094 26.877188 
z
" style="fill: #eaeaf2"/>
   </g>
   <g id="matplotlib.axis_1">
    <g id="xtick_1">
     <g id="line2d_1">
      <path d="M 60.586094 139.953187 
L 60.586094 26.877188 
" clip-path="url(#pfe801ce296)" style="fill: none; stroke: #ffffff; stroke-width: 1.5; stroke-linecap: round"/>
     </g>
     <g id="text_1">
      <!-- −4 -->
      <g style="fill: #262626" transform="translate(48.423789 164.990609) scale(0.165 -0.165)">
       <defs>
        <path id="DejaVuSans-2212" d="M 678 2272 
L 4684 2272 
L 4684 1741 
L 678 1741 
L 678 2272 
z
" transform="scale(0.015625)"/>
        <path id="DejaVuSans-34" d="M 2419 4116 
L 825 1625 
L 2419 1625 
L 2419 4116 
z
M 2253 4666 
L 3047 4666 
L 3047 1625 
L 3713 1625 
L 3713 1100 
L 3047 1100 
L 3047 0 
L 2419 0 
L 2419 1100 
L 313 1100 
L 313 1709 
L 2253 4666 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-2212"/>
       <use xlink:href="#DejaVuSans-34" x="83.789062"/>
      </g>
     </g>
    </g>
    <g id="xtick_2">
     <g id="line2d_2">
      <path d="M 130.121594 139.953187 
L 130.121594 26.877188 
" clip-path="url(#pfe801ce296)" style="fill: none; stroke: #ffffff; stroke-width: 1.5; stroke-linecap: round"/>
     </g>
     <g id="text_2">
      <!-- −2 -->
      <g style="fill: #262626" transform="translate(117.959289 164.990609) scale(0.165 -0.165)">
       <defs>
        <path id="DejaVuSans-32" d="M 1228 531 
L 3431 531 
L 3431 0 
L 469 0 
L 469 531 
Q 828 903 1448 1529 
Q 2069 2156 2228 2338 
Q 2531 2678 2651 2914 
Q 2772 3150 2772 3378 
Q 2772 3750 2511 3984 
Q 2250 4219 1831 4219 
Q 1534 4219 1204 4116 
Q 875 4013 500 3803 
L 500 4441 
Q 881 4594 1212 4672 
Q 1544 4750 1819 4750 
Q 2544 4750 2975 4387 
Q 3406 4025 3406 3419 
Q 3406 3131 3298 2873 
Q 3191 2616 2906 2266 
Q 2828 2175 2409 1742 
Q 1991 1309 1228 531 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-2212"/>
       <use xlink:href="#DejaVuSans-32" x="83.789062"/>
      </g>
     </g>
    </g>
    <g id="xtick_3">
     <g id="line2d_3">
      <path d="M 199.657094 139.953187 
L 199.657094 26.877188 
" clip-path="url(#pfe801ce296)" style="fill: none; stroke: #ffffff; stroke-width: 1.5; stroke-linecap: round"/>
     </g>
     <g id="text_3">
      <!-- 0 -->
      <g style="fill: #262626" transform="translate(194.408031 164.990609) scale(0.165 -0.165)">
       <defs>
        <path id="DejaVuSans-30" d="M 2034 4250 
Q 1547 4250 1301 3770 
Q 1056 3291 1056 2328 
Q 1056 1369 1301 889 
Q 1547 409 2034 409 
Q 2525 409 2770 889 
Q 3016 1369 3016 2328 
Q 3016 3291 2770 3770 
Q 2525 4250 2034 4250 
z
M 2034 4750 
Q 2819 4750 3233 4129 
Q 3647 3509 3647 2328 
Q 3647 1150 3233 529 
Q 2819 -91 2034 -91 
Q 1250 -91 836 529 
Q 422 1150 422 2328 
Q 422 3509 836 4129 
Q 1250 4750 2034 4750 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-30"/>
      </g>
     </g>
    </g>
    <g id="xtick_4">
     <g id="line2d_4">
      <path d="M 269.192594 139.953187 
L 269.192594 26.877188 
" clip-path="url(#pfe801ce296)" style="fill: none; stroke: #ffffff; stroke-width: 1.5; stroke-linecap: round"/>
     </g>
     <g id="text_4">
      <!-- 2 -->
      <g style="fill: #262626" transform="translate(263.943531 164.990609) scale(0.165 -0.165)">
       <use xlink:href="#DejaVuSans-32"/>
      </g>
     </g>
    </g>
    <g id="xtick_5">
     <g id="line2d_5">
      <path d="M 338.728094 139.953187 
L 338.728094 26.877188 
" clip-path="url(#pfe801ce296)" style="fill: none; stroke: #ffffff; stroke-width: 1.5; stroke-linecap: round"/>
     </g>
     <g id="text_5">
      <!-- 4 -->
      <g style="fill: #262626" transform="translate(333.479031 164.990609) scale(0.165 -0.165)">
       <use xlink:href="#DejaVuSans-34"/>
      </g>
     </g>
    </g>
    <g id="text_6">
     <!-- $x_a - x_b$ -->
     <g style="fill: #262626" transform="translate(181.287094 180.780375) scale(0.11 -0.11)">
      <defs>
       <path id="DejaVuSans-Oblique-78" d="M 3841 3500 
L 2234 1784 
L 3219 0 
L 2559 0 
L 1819 1388 
L 531 0 
L -166 0 
L 1556 1844 
L 641 3500 
L 1300 3500 
L 1972 2234 
L 3144 3500 
L 3841 3500 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-Oblique-61" d="M 3438 1997 
L 3047 0 
L 2472 0 
L 2578 531 
Q 2325 219 2001 64 
Q 1678 -91 1281 -91 
Q 834 -91 548 182 
Q 263 456 263 884 
Q 263 1497 752 1853 
Q 1241 2209 2100 2209 
L 2900 2209 
L 2931 2363 
Q 2938 2388 2941 2417 
Q 2944 2447 2944 2509 
Q 2944 2788 2717 2942 
Q 2491 3097 2081 3097 
Q 1800 3097 1504 3025 
Q 1209 2953 897 2809 
L 997 3341 
Q 1322 3463 1633 3523 
Q 1944 3584 2234 3584 
Q 2853 3584 3176 3315 
Q 3500 3047 3500 2534 
Q 3500 2431 3484 2292 
Q 3469 2153 3438 1997 
z
M 2816 1759 
L 2241 1759 
Q 1534 1759 1195 1570 
Q 856 1381 856 984 
Q 856 709 1029 553 
Q 1203 397 1509 397 
Q 1978 397 2328 733 
Q 2678 1069 2791 1631 
L 2816 1759 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-Oblique-62" d="M 3169 2138 
Q 3169 2591 2961 2847 
Q 2753 3103 2388 3103 
Q 2122 3103 1889 2973 
Q 1656 2844 1484 2597 
Q 1303 2338 1198 1995 
Q 1094 1653 1094 1313 
Q 1094 881 1298 636 
Q 1503 391 1863 391 
Q 2134 391 2365 517 
Q 2597 644 2772 891 
Q 2950 1147 3059 1487 
Q 3169 1828 3169 2138 
z
M 1381 2969 
Q 1594 3256 1914 3420 
Q 2234 3584 2584 3584 
Q 3122 3584 3439 3221 
Q 3756 2859 3756 2241 
Q 3756 1734 3570 1259 
Q 3384 784 3041 416 
Q 2816 172 2522 40 
Q 2228 -91 1906 -91 
Q 1566 -91 1316 65 
Q 1066 222 909 531 
L 806 0 
L 231 0 
L 1178 4863 
L 1753 4863 
L 1381 2969 
z
" transform="scale(0.015625)"/>
      </defs>
      <use xlink:href="#DejaVuSans-Oblique-78" transform="translate(0 0.3125)"/>
      <use xlink:href="#DejaVuSans-Oblique-61" transform="translate(59.179688 -16.09375) scale(0.7)"/>
      <use xlink:href="#DejaVuSans-2212" transform="translate(124.291992 0.3125)"/>
      <use xlink:href="#DejaVuSans-Oblique-78" transform="translate(227.563477 0.3125)"/>
      <use xlink:href="#DejaVuSans-Oblique-62" transform="translate(286.743164 -16.09375) scale(0.7)"/>
     </g>
    </g>
   </g>
   <g id="matplotlib.axis_2">
    <g id="ytick_1">
     <g id="line2d_6">
      <path d="M 60.586094 139.953187 
L 338.728094 139.953187 
" clip-path="url(#pfe801ce296)" style="fill: none; stroke: #ffffff; stroke-width: 1.5; stroke-linecap: round"/>
     </g>
     <g id="text_7">
      <!-- 0.0 -->
      <g style="fill: #262626" transform="translate(21.845938 146.221898) scale(0.165 -0.165)">
       <defs>
        <path id="DejaVuSans-2e" d="M 684 794 
L 1344 794 
L 1344 0 
L 684 0 
L 684 794 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-30"/>
       <use xlink:href="#DejaVuSans-2e" x="63.623047"/>
       <use xlink:href="#DejaVuSans-30" x="95.410156"/>
      </g>
     </g>
    </g>
    <g id="ytick_2">
     <g id="line2d_7">
      <path d="M 60.586094 88.555006 
L 338.728094 88.555006 
" clip-path="url(#pfe801ce296)" style="fill: none; stroke: #ffffff; stroke-width: 1.5; stroke-linecap: round"/>
     </g>
     <g id="text_8">
      <!-- 0.5 -->
      <g style="fill: #262626" transform="translate(21.845938 94.823717) scale(0.165 -0.165)">
       <defs>
        <path id="DejaVuSans-35" d="M 691 4666 
L 3169 4666 
L 3169 4134 
L 1269 4134 
L 1269 2991 
Q 1406 3038 1543 3061 
Q 1681 3084 1819 3084 
Q 2600 3084 3056 2656 
Q 3513 2228 3513 1497 
Q 3513 744 3044 326 
Q 2575 -91 1722 -91 
Q 1428 -91 1123 -41 
Q 819 9 494 109 
L 494 744 
Q 775 591 1075 516 
Q 1375 441 1709 441 
Q 2250 441 2565 725 
Q 2881 1009 2881 1497 
Q 2881 1984 2565 2268 
Q 2250 2553 1709 2553 
Q 1456 2553 1204 2497 
Q 953 2441 691 2322 
L 691 4666 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-30"/>
       <use xlink:href="#DejaVuSans-2e" x="63.623047"/>
       <use xlink:href="#DejaVuSans-35" x="95.410156"/>
      </g>
     </g>
    </g>
    <g id="ytick_3">
     <g id="line2d_8">
      <path d="M 60.586094 37.156824 
L 338.728094 37.156824 
" clip-path="url(#pfe801ce296)" style="fill: none; stroke: #ffffff; stroke-width: 1.5; stroke-linecap: round"/>
     </g>
     <g id="text_9">
      <!-- 1.0 -->
      <g style="fill: #262626" transform="translate(21.845938 43.425535) scale(0.165 -0.165)">
       <defs>
        <path id="DejaVuSans-31" d="M 794 531 
L 1825 531 
L 1825 4091 
L 703 3866 
L 703 4441 
L 1819 4666 
L 2450 4666 
L 2450 531 
L 3481 531 
L 3481 0 
L 794 0 
L 794 531 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-31"/>
       <use xlink:href="#DejaVuSans-2e" x="63.623047"/>
       <use xlink:href="#DejaVuSans-30" x="95.410156"/>
      </g>
     </g>
    </g>
    <g id="text_10">
     <!-- $K(x_a,x_b)$ -->
     <g style="fill: #262626" transform="translate(15.558281 105.800188) rotate(-90) scale(0.11 -0.11)">
      <defs>
       <path id="DejaVuSans-Oblique-4b" d="M 1081 4666 
L 1716 4666 
L 1331 2700 
L 3781 4666 
L 4622 4666 
L 1850 2438 
L 3878 0 
L 3109 0 
L 1247 2272 
L 806 0 
L 172 0 
L 1081 4666 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-28" d="M 1984 4856 
Q 1566 4138 1362 3434 
Q 1159 2731 1159 2009 
Q 1159 1288 1364 580 
Q 1569 -128 1984 -844 
L 1484 -844 
Q 1016 -109 783 600 
Q 550 1309 550 2009 
Q 550 2706 781 3412 
Q 1013 4119 1484 4856 
L 1984 4856 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-2c" d="M 750 794 
L 1409 794 
L 1409 256 
L 897 -744 
L 494 -744 
L 750 256 
L 750 794 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-29" d="M 513 4856 
L 1013 4856 
Q 1481 4119 1714 3412 
Q 1947 2706 1947 2009 
Q 1947 1309 1714 600 
Q 1481 -109 1013 -844 
L 513 -844 
Q 928 -128 1133 580 
Q 1338 1288 1338 2009 
Q 1338 2731 1133 3434 
Q 928 4138 513 4856 
z
" transform="scale(0.015625)"/>
      </defs>
      <use xlink:href="#DejaVuSans-Oblique-4b" transform="translate(0 0.125)"/>
      <use xlink:href="#DejaVuSans-28" transform="translate(65.576172 0.125)"/>
      <use xlink:href="#DejaVuSans-Oblique-78" transform="translate(104.589844 0.125)"/>
      <use xlink:href="#DejaVuSans-Oblique-61" transform="translate(163.769531 -16.28125) scale(0.7)"/>
      <use xlink:href="#DejaVuSans-2c" transform="translate(209.399414 0.125)"/>
      <use xlink:href="#DejaVuSans-Oblique-78" transform="translate(260.668945 0.125)"/>
      <use xlink:href="#DejaVuSans-Oblique-62" transform="translate(319.848633 -16.28125) scale(0.7)"/>
      <use xlink:href="#DejaVuSans-29" transform="translate(367.016602 0.125)"/>
     </g>
    </g>
   </g>
   <g id="line2d_9">
    <path d="M 60.586094 139.918703 
L 64.344769 139.900357 
L 68.103445 139.87319 
L 71.862121 139.833461 
L 75.620796 139.776084 
L 79.379472 139.694253 
L 83.138148 139.579011 
L 86.896823 139.418762 
L 90.655499 139.198753 
L 94.414175 138.900545 
L 98.172851 138.501529 
L 101.931526 137.974524 
L 105.690202 137.287535 
L 109.448878 136.403748 
L 113.207553 135.281863 
L 116.966229 133.876814 
L 120.724905 132.140991 
L 124.48358 130.025996 
L 128.242256 127.484994 
L 132.000932 124.475537 
L 135.759607 120.962931 
L 139.518283 116.923885 
L 143.276959 112.350262 
L 147.035634 107.252754 
L 150.79431 101.66399 
L 154.552986 95.640995 
L 158.311661 89.26644 
L 162.070337 82.648534 
L 165.829013 75.919346 
L 169.587688 69.231352 
L 173.346364 62.752409 
L 177.10504 56.659108 
L 180.863715 51.129094 
L 184.622391 46.33253 
L 188.381067 42.423493 
L 192.139742 39.531796 
L 195.898418 37.755783 
L 199.657094 37.156824 
L 203.415769 37.755783 
L 207.174445 39.531796 
L 210.933121 42.423493 
L 214.691796 46.33253 
L 218.450472 51.129094 
L 222.209148 56.659108 
L 225.967823 62.752409 
L 229.726499 69.231352 
L 233.485175 75.919346 
L 237.243851 82.648534 
L 241.002526 89.26644 
L 244.761202 95.640995 
L 248.519878 101.66399 
L 252.278553 107.252754 
L 256.037229 112.350262 
L 259.795905 116.923885 
L 263.55458 120.962931 
L 267.313256 124.475537 
L 271.071932 127.484994 
L 274.830607 130.025996 
L 278.589283 132.140991 
L 282.347959 133.876814 
L 286.106634 135.281863 
L 289.86531 136.403748 
L 293.623986 137.287535 
L 297.382661 137.974524 
L 301.141337 138.501529 
L 304.900013 138.900545 
L 308.658688 139.198753 
L 312.417364 139.418762 
L 316.17604 139.579011 
L 319.934715 139.694253 
L 323.693391 139.776084 
L 327.452067 139.833461 
L 331.210742 139.87319 
L 334.969418 139.900357 
L 338.728094 139.918703 
" clip-path="url(#pfe801ce296)" style="fill: none; stroke: #1f77b4; stroke-width: 2.25; stroke-linecap: round"/>
   </g>
   <g id="line2d_10">
    <path d="M 60.586094 139.953187 
L 64.344769 139.953187 
L 68.103445 139.953187 
L 71.862121 139.953187 
L 75.620796 139.953187 
L 79.379472 139.953187 
L 83.138148 139.953187 
L 86.896823 139.953187 
L 90.655499 139.953187 
L 94.414175 139.953186 
L 98.172851 139.953183 
L 101.931526 139.953173 
L 105.690202 139.953141 
L 109.448878 139.953041 
L 113.207553 139.952749 
L 116.966229 139.951932 
L 120.724905 139.949759 
L 124.48358 139.944247 
L 128.242256 139.93094 
L 132.000932 139.900357 
L 135.759607 139.833461 
L 139.518283 139.694253 
L 143.276959 139.418762 
L 147.035634 138.900545 
L 150.79431 137.974524 
L 154.552986 136.403748 
L 158.311661 133.876814 
L 162.070337 130.025996 
L 165.829013 124.475537 
L 169.587688 116.923885 
L 173.346364 107.252754 
L 177.10504 95.640995 
L 180.863715 82.648534 
L 184.622391 69.231352 
L 188.381067 56.659108 
L 192.139742 46.33253 
L 195.898418 39.531796 
L 199.657094 37.156824 
L 203.415769 39.531796 
L 207.174445 46.33253 
L 210.933121 56.659108 
L 214.691796 69.231352 
L 218.450472 82.648534 
L 222.209148 95.640995 
L 225.967823 107.252754 
L 229.726499 116.923885 
L 233.485175 124.475537 
L 237.243851 130.025996 
L 241.002526 133.876814 
L 244.761202 136.403748 
L 248.519878 137.974524 
L 252.278553 138.900545 
L 256.037229 139.418762 
L 259.795905 139.694253 
L 263.55458 139.833461 
L 267.313256 139.900357 
L 271.071932 139.93094 
L 274.830607 139.944247 
L 278.589283 139.949759 
L 282.347959 139.951932 
L 286.106634 139.952749 
L 289.86531 139.953041 
L 293.623986 139.953141 
L 297.382661 139.953173 
L 301.141337 139.953183 
L 304.900013 139.953186 
L 308.658688 139.953187 
L 312.417364 139.953187 
L 316.17604 139.953187 
L 319.934715 139.953187 
L 323.693391 139.953187 
L 327.452067 139.953187 
L 331.210742 139.953187 
L 334.969418 139.953187 
L 338.728094 139.953187 
" clip-path="url(#pfe801ce296)" style="fill: none; stroke: #ff7f0e; stroke-width: 2.25; stroke-linecap: round"/>
   </g>
   <g id="line2d_11">
    <path d="M 60.586094 139.944566 
L 64.344769 139.93998 
L 68.103445 139.933188 
L 71.862121 139.923256 
L 75.620796 139.908912 
L 79.379472 139.888454 
L 83.138148 139.859643 
L 86.896823 139.819581 
L 90.655499 139.764579 
L 94.414175 139.690027 
L 98.172851 139.590273 
L 101.931526 139.458522 
L 105.690202 139.286774 
L 109.448878 139.065828 
L 113.207553 138.785357 
L 116.966229 138.434094 
L 120.724905 138.000138 
L 124.48358 137.47139 
L 128.242256 136.836139 
L 132.000932 136.083775 
L 135.759607 135.205623 
L 139.518283 134.195862 
L 143.276959 133.052458 
L 147.035634 131.778079 
L 150.79431 130.380889 
L 154.552986 128.875139 
L 158.311661 127.281502 
L 162.070337 125.627024 
L 165.829013 123.944727 
L 169.587688 122.27273 
L 173.346364 120.652994 
L 177.10504 119.129669 
L 180.863715 117.747164 
L 184.622391 116.548023 
L 188.381067 115.570764 
L 192.139742 114.847838 
L 195.898418 114.403835 
L 199.657094 114.254097 
L 203.415769 114.403835 
L 207.174445 114.847838 
L 210.933121 115.570764 
L 214.691796 116.548023 
L 218.450472 117.747164 
L 222.209148 119.129669 
L 225.967823 120.652994 
L 229.726499 122.27273 
L 233.485175 123.944727 
L 237.243851 125.627024 
L 241.002526 127.281502 
L 244.761202 128.875139 
L 248.519878 130.380889 
L 252.278553 131.778079 
L 256.037229 133.052458 
L 259.795905 134.195862 
L 263.55458 135.205623 
L 267.313256 136.083775 
L 271.071932 136.836139 
L 274.830607 137.47139 
L 278.589283 138.000138 
L 282.347959 138.434094 
L 286.106634 138.785357 
L 289.86531 139.065828 
L 293.623986 139.286774 
L 297.382661 139.458522 
L 301.141337 139.590273 
L 304.900013 139.690027 
L 308.658688 139.764579 
L 312.417364 139.819581 
L 316.17604 139.859643 
L 319.934715 139.888454 
L 323.693391 139.908912 
L 327.452067 139.923256 
L 331.210742 139.933188 
L 334.969418 139.93998 
L 338.728094 139.944566 
" clip-path="url(#pfe801ce296)" style="fill: none; stroke: #2ca02c; stroke-width: 2.25; stroke-linecap: round"/>
   </g>
   <g id="patch_3">
    <path d="M 60.586094 139.953187 
L 60.586094 26.877187 
" style="fill: none; stroke: #ffffff; stroke-width: 1.875; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="patch_4">
    <path d="M 338.728094 139.953187 
L 338.728094 26.877187 
" style="fill: none; stroke: #ffffff; stroke-width: 1.875; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="patch_5">
    <path d="M 60.586094 139.953187 
L 338.728094 139.953187 
" style="fill: none; stroke: #ffffff; stroke-width: 1.875; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="patch_6">
    <path d="M 60.586094 26.877188 
L 338.728094 26.877188 
" style="fill: none; stroke: #ffffff; stroke-width: 1.875; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="text_11">
    <!-- Exponentiated quadratic distance plot -->
    <g style="fill: #262626" transform="translate(27.349281 20.877188) scale(0.18 -0.18)">
     <defs>
      <path id="DejaVuSans-45" d="M 628 4666 
L 3578 4666 
L 3578 4134 
L 1259 4134 
L 1259 2753 
L 3481 2753 
L 3481 2222 
L 1259 2222 
L 1259 531 
L 3634 531 
L 3634 0 
L 628 0 
L 628 4666 
z
" transform="scale(0.015625)"/>
      <path id="DejaVuSans-78" d="M 3513 3500 
L 2247 1797 
L 3578 0 
L 2900 0 
L 1881 1375 
L 863 0 
L 184 0 
L 1544 1831 
L 300 3500 
L 978 3500 
L 1906 2253 
L 2834 3500 
L 3513 3500 
z
" transform="scale(0.015625)"/>
      <path id="DejaVuSans-70" d="M 1159 525 
L 1159 -1331 
L 581 -1331 
L 581 3500 
L 1159 3500 
L 1159 2969 
Q 1341 3281 1617 3432 
Q 1894 3584 2278 3584 
Q 2916 3584 3314 3078 
Q 3713 2572 3713 1747 
Q 3713 922 3314 415 
Q 2916 -91 2278 -91 
Q 1894 -91 1617 61 
Q 1341 213 1159 525 
z
M 3116 1747 
Q 3116 2381 2855 2742 
Q 2594 3103 2138 3103 
Q 1681 3103 1420 2742 
Q 1159 2381 1159 1747 
Q 1159 1113 1420 752 
Q 1681 391 2138 391 
Q 2594 391 2855 752 
Q 3116 1113 3116 1747 
z
" transform="scale(0.015625)"/>
      <path id="DejaVuSans-6f" d="M 1959 3097 
Q 1497 3097 1228 2736 
Q 959 2375 959 1747 
Q 959 1119 1226 758 
Q 1494 397 1959 397 
Q 2419 397 2687 759 
Q 2956 1122 2956 1747 
Q 2956 2369 2687 2733 
Q 2419 3097 1959 3097 
z
M 1959 3584 
Q 2709 3584 3137 3096 
Q 3566 2609 3566 1747 
Q 3566 888 3137 398 
Q 2709 -91 1959 -91 
Q 1206 -91 779 398 
Q 353 888 353 1747 
Q 353 2609 779 3096 
Q 1206 3584 1959 3584 
z
" transform="scale(0.015625)"/>
      <path id="DejaVuSans-6e" d="M 3513 2113 
L 3513 0 
L 2938 0 
L 2938 2094 
Q 2938 2591 2744 2837 
Q 2550 3084 2163 3084 
Q 1697 3084 1428 2787 
Q 1159 2491 1159 1978 
L 1159 0 
L 581 0 
L 581 3500 
L 1159 3500 
L 1159 2956 
Q 1366 3272 1645 3428 
Q 1925 3584 2291 3584 
Q 2894 3584 3203 3211 
Q 3513 2838 3513 2113 
z
" transform="scale(0.015625)"/>
      <path id="DejaVuSans-65" d="M 3597 1894 
L 3597 1613 
L 953 1613 
Q 991 1019 1311 708 
Q 1631 397 2203 397 
Q 2534 397 2845 478 
Q 3156 559 3463 722 
L 3463 178 
Q 3153 47 2828 -22 
Q 2503 -91 2169 -91 
Q 1331 -91 842 396 
Q 353 884 353 1716 
Q 353 2575 817 3079 
Q 1281 3584 2069 3584 
Q 2775 3584 3186 3129 
Q 3597 2675 3597 1894 
z
M 3022 2063 
Q 3016 2534 2758 2815 
Q 2500 3097 2075 3097 
Q 1594 3097 1305 2825 
Q 1016 2553 972 2059 
L 3022 2063 
z
" transform="scale(0.015625)"/>
      <path id="DejaVuSans-74" d="M 1172 4494 
L 1172 3500 
L 2356 3500 
L 2356 3053 
L 1172 3053 
L 1172 1153 
Q 1172 725 1289 603 
Q 1406 481 1766 481 
L 2356 481 
L 2356 0 
L 1766 0 
Q 1100 0 847 248 
Q 594 497 594 1153 
L 594 3053 
L 172 3053 
L 172 3500 
L 594 3500 
L 594 4494 
L 1172 4494 
z
" transform="scale(0.015625)"/>
      <path id="DejaVuSans-69" d="M 603 3500 
L 1178 3500 
L 1178 0 
L 603 0 
L 603 3500 
z
M 603 4863 
L 1178 4863 
L 1178 4134 
L 603 4134 
L 603 4863 
z
" transform="scale(0.015625)"/>
      <path id="DejaVuSans-61" d="M 2194 1759 
Q 1497 1759 1228 1600 
Q 959 1441 959 1056 
Q 959 750 1161 570 
Q 1363 391 1709 391 
Q 2188 391 2477 730 
Q 2766 1069 2766 1631 
L 2766 1759 
L 2194 1759 
z
M 3341 1997 
L 3341 0 
L 2766 0 
L 2766 531 
Q 2569 213 2275 61 
Q 1981 -91 1556 -91 
Q 1019 -91 701 211 
Q 384 513 384 1019 
Q 384 1609 779 1909 
Q 1175 2209 1959 2209 
L 2766 2209 
L 2766 2266 
Q 2766 2663 2505 2880 
Q 2244 3097 1772 3097 
Q 1472 3097 1187 3025 
Q 903 2953 641 2809 
L 641 3341 
Q 956 3463 1253 3523 
Q 1550 3584 1831 3584 
Q 2591 3584 2966 3190 
Q 3341 2797 3341 1997 
z
" transform="scale(0.015625)"/>
      <path id="DejaVuSans-64" d="M 2906 2969 
L 2906 4863 
L 3481 4863 
L 3481 0 
L 2906 0 
L 2906 525 
Q 2725 213 2448 61 
Q 2172 -91 1784 -91 
Q 1150 -91 751 415 
Q 353 922 353 1747 
Q 353 2572 751 3078 
Q 1150 3584 1784 3584 
Q 2172 3584 2448 3432 
Q 2725 3281 2906 2969 
z
M 947 1747 
Q 947 1113 1208 752 
Q 1469 391 1925 391 
Q 2381 391 2643 752 
Q 2906 1113 2906 1747 
Q 2906 2381 2643 2742 
Q 2381 3103 1925 3103 
Q 1469 3103 1208 2742 
Q 947 2381 947 1747 
z
" transform="scale(0.015625)"/>
      <path id="DejaVuSans-20" transform="scale(0.015625)"/>
      <path id="DejaVuSans-71" d="M 947 1747 
Q 947 1113 1208 752 
Q 1469 391 1925 391 
Q 2381 391 2643 752 
Q 2906 1113 2906 1747 
Q 2906 2381 2643 2742 
Q 2381 3103 1925 3103 
Q 1469 3103 1208 2742 
Q 947 2381 947 1747 
z
M 2906 525 
Q 2725 213 2448 61 
Q 2172 -91 1784 -91 
Q 1150 -91 751 415 
Q 353 922 353 1747 
Q 353 2572 751 3078 
Q 1150 3584 1784 3584 
Q 2172 3584 2448 3432 
Q 2725 3281 2906 2969 
L 2906 3500 
L 3481 3500 
L 3481 -1331 
L 2906 -1331 
L 2906 525 
z
" transform="scale(0.015625)"/>
      <path id="DejaVuSans-75" d="M 544 1381 
L 544 3500 
L 1119 3500 
L 1119 1403 
Q 1119 906 1312 657 
Q 1506 409 1894 409 
Q 2359 409 2629 706 
Q 2900 1003 2900 1516 
L 2900 3500 
L 3475 3500 
L 3475 0 
L 2900 0 
L 2900 538 
Q 2691 219 2414 64 
Q 2138 -91 1772 -91 
Q 1169 -91 856 284 
Q 544 659 544 1381 
z
M 1991 3584 
L 1991 3584 
z
" transform="scale(0.015625)"/>
      <path id="DejaVuSans-72" d="M 2631 2963 
Q 2534 3019 2420 3045 
Q 2306 3072 2169 3072 
Q 1681 3072 1420 2755 
Q 1159 2438 1159 1844 
L 1159 0 
L 581 0 
L 581 3500 
L 1159 3500 
L 1159 2956 
Q 1341 3275 1631 3429 
Q 1922 3584 2338 3584 
Q 2397 3584 2469 3576 
Q 2541 3569 2628 3553 
L 2631 2963 
z
" transform="scale(0.015625)"/>
      <path id="DejaVuSans-63" d="M 3122 3366 
L 3122 2828 
Q 2878 2963 2633 3030 
Q 2388 3097 2138 3097 
Q 1578 3097 1268 2742 
Q 959 2388 959 1747 
Q 959 1106 1268 751 
Q 1578 397 2138 397 
Q 2388 397 2633 464 
Q 2878 531 3122 666 
L 3122 134 
Q 2881 22 2623 -34 
Q 2366 -91 2075 -91 
Q 1284 -91 818 406 
Q 353 903 353 1747 
Q 353 2603 823 3093 
Q 1294 3584 2113 3584 
Q 2378 3584 2631 3529 
Q 2884 3475 3122 3366 
z
" transform="scale(0.015625)"/>
      <path id="DejaVuSans-73" d="M 2834 3397 
L 2834 2853 
Q 2591 2978 2328 3040 
Q 2066 3103 1784 3103 
Q 1356 3103 1142 2972 
Q 928 2841 928 2578 
Q 928 2378 1081 2264 
Q 1234 2150 1697 2047 
L 1894 2003 
Q 2506 1872 2764 1633 
Q 3022 1394 3022 966 
Q 3022 478 2636 193 
Q 2250 -91 1575 -91 
Q 1294 -91 989 -36 
Q 684 19 347 128 
L 347 722 
Q 666 556 975 473 
Q 1284 391 1588 391 
Q 1994 391 2212 530 
Q 2431 669 2431 922 
Q 2431 1156 2273 1281 
Q 2116 1406 1581 1522 
L 1381 1569 
Q 847 1681 609 1914 
Q 372 2147 372 2553 
Q 372 3047 722 3315 
Q 1072 3584 1716 3584 
Q 2034 3584 2315 3537 
Q 2597 3491 2834 3397 
z
" transform="scale(0.015625)"/>
      <path id="DejaVuSans-6c" d="M 603 4863 
L 1178 4863 
L 1178 0 
L 603 0 
L 603 4863 
z
" transform="scale(0.015625)"/>
     </defs>
     <use xlink:href="#DejaVuSans-45"/>
     <use xlink:href="#DejaVuSans-78" x="63.183594"/>
     <use xlink:href="#DejaVuSans-70" x="122.363281"/>
     <use xlink:href="#DejaVuSans-6f" x="185.839844"/>
     <use xlink:href="#DejaVuSans-6e" x="247.021484"/>
     <use xlink:href="#DejaVuSans-65" x="310.400391"/>
     <use xlink:href="#DejaVuSans-6e" x="371.923828"/>
     <use xlink:href="#DejaVuSans-74" x="435.302734"/>
     <use xlink:href="#DejaVuSans-69" x="474.511719"/>
     <use xlink:href="#DejaVuSans-61" x="502.294922"/>
     <use xlink:href="#DejaVuSans-74" x="563.574219"/>
     <use xlink:href="#DejaVuSans-65" x="602.783203"/>
     <use xlink:href="#DejaVuSans-64" x="664.306641"/>
     <use xlink:href="#DejaVuSans-20" x="727.783203"/>
     <use xlink:href="#DejaVuSans-71" x="759.570312"/>
     <use xlink:href="#DejaVuSans-75" x="823.046875"/>
     <use xlink:href="#DejaVuSans-61" x="886.425781"/>
     <use xlink:href="#DejaVuSans-64" x="947.705078"/>
     <use xlink:href="#DejaVuSans-72" x="1011.181641"/>
     <use xlink:href="#DejaVuSans-61" x="1052.294922"/>
     <use xlink:href="#DejaVuSans-74" x="1113.574219"/>
     <use xlink:href="#DejaVuSans-69" x="1152.783203"/>
     <use xlink:href="#DejaVuSans-63" x="1180.566406"/>
     <use xlink:href="#DejaVuSans-20" x="1235.546875"/>
     <use xlink:href="#DejaVuSans-64" x="1267.333984"/>
     <use xlink:href="#DejaVuSans-69" x="1330.810547"/>
     <use xlink:href="#DejaVuSans-73" x="1358.59375"/>
     <use xlink:href="#DejaVuSans-74" x="1410.693359"/>
     <use xlink:href="#DejaVuSans-61" x="1449.902344"/>
     <use xlink:href="#DejaVuSans-6e" x="1511.181641"/>
     <use xlink:href="#DejaVuSans-63" x="1574.560547"/>
     <use xlink:href="#DejaVuSans-65" x="1629.541016"/>
     <use xlink:href="#DejaVuSans-20" x="1691.064453"/>
     <use xlink:href="#DejaVuSans-70" x="1722.851562"/>
     <use xlink:href="#DejaVuSans-6c" x="1786.328125"/>
     <use xlink:href="#DejaVuSans-6f" x="1814.111328"/>
     <use xlink:href="#DejaVuSans-74" x="1875.292969"/>
    </g>
   </g>
   <g id="legend_1">
    <g id="patch_7">
     <path d="M 169.273094 112.733906 
L 327.178094 112.733906 
Q 330.478094 112.733906 330.478094 109.433906 
L 330.478094 38.427188 
Q 330.478094 35.127188 327.178094 35.127188 
L 169.273094 35.127188 
Q 165.973094 35.127188 165.973094 38.427188 
L 165.973094 109.433906 
Q 165.973094 112.733906 169.273094 112.733906 
z
" style="fill: #eaeaf2; opacity: 0.8; stroke: #cccccc; stroke-width: 1.5; stroke-linejoin: miter"/>
    </g>
    <g id="line2d_12">
     <path d="M 172.573094 48.489609 
L 189.073094 48.489609 
L 205.573094 48.489609 
" style="fill: none; stroke: #1f77b4; stroke-width: 2.25; stroke-linecap: round"/>
    </g>
    <g id="text_12">
     <!-- $\ell = 1$, $\sigma = 1$ -->
     <g style="fill: #262626" transform="translate(218.773094 54.264609) scale(0.165 -0.165)">
      <defs>
       <path id="DejaVuSans-Oblique-2113" d="M 950 838 
Q 1078 213 1350 213 
Q 1531 213 1766 572 
L 2181 572 
Q 1994 253 1775 88 
Q 1538 -91 1319 -91 
Q 831 -91 634 344 
L 400 0 
L -88 0 
Q 250 459 500 888 
Q 469 1131 469 1397 
Q 469 1872 566 2347 
Q 931 4131 1256 4497 
Q 1481 4750 1866 4750 
Q 2256 4750 2256 4209 
Q 2253 3966 2197 3675 
Q 1972 2484 950 838 
z
M 947 1656 
Q 1531 2744 1709 3613 
Q 1803 4072 1803 4191 
Q 1803 4406 1725 4406 
Q 1384 4134 1081 2516 
Q 997 2063 947 1656 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-3d" d="M 678 2906 
L 4684 2906 
L 4684 2381 
L 678 2381 
L 678 2906 
z
M 678 1631 
L 4684 1631 
L 4684 1100 
L 678 1100 
L 678 1631 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-Oblique-3c3" d="M 2219 3044 
Q 1744 3044 1422 2700 
Q 1081 2341 969 1747 
Q 844 1119 1044 756 
Q 1241 397 1706 397 
Q 2166 397 2503 759 
Q 2844 1122 2966 1747 
Q 3075 2319 2881 2700 
Q 2700 3044 2219 3044 
z
M 2309 3503 
L 4219 3500 
L 4106 2925 
L 3463 2925 
Q 3706 2438 3575 1747 
Q 3406 888 2884 400 
Q 2359 -91 1609 -91 
Q 856 -91 525 400 
Q 194 888 363 1747 
Q 528 2609 1050 3097 
Q 1484 3503 2309 3503 
z
" transform="scale(0.015625)"/>
      </defs>
      <use xlink:href="#DejaVuSans-Oblique-2113" transform="translate(0 0.78125)"/>
      <use xlink:href="#DejaVuSans-3d" transform="translate(60.791016 0.78125)"/>
      <use xlink:href="#DejaVuSans-31" transform="translate(164.0625 0.78125)"/>
      <use xlink:href="#DejaVuSans-2c" transform="translate(227.685547 0.78125)"/>
      <use xlink:href="#DejaVuSans-20" transform="translate(259.472656 0.78125)"/>
      <use xlink:href="#DejaVuSans-Oblique-3c3" transform="translate(291.259766 0.78125)"/>
      <use xlink:href="#DejaVuSans-3d" transform="translate(374.121094 0.78125)"/>
      <use xlink:href="#DejaVuSans-31" transform="translate(477.392578 0.78125)"/>
     </g>
    </g>
    <g id="line2d_13">
     <path d="M 172.573094 72.708516 
L 189.073094 72.708516 
L 205.573094 72.708516 
" style="fill: none; stroke: #ff7f0e; stroke-width: 2.25; stroke-linecap: round"/>
    </g>
    <g id="text_13">
     <!-- $\ell = 0.5$, $\sigma = 1$ -->
     <g style="fill: #262626" transform="translate(218.773094 78.483516) scale(0.165 -0.165)">
      <use xlink:href="#DejaVuSans-Oblique-2113" transform="translate(0 0.78125)"/>
      <use xlink:href="#DejaVuSans-3d" transform="translate(60.791016 0.78125)"/>
      <use xlink:href="#DejaVuSans-30" transform="translate(164.0625 0.78125)"/>
      <use xlink:href="#DejaVuSans-2e" transform="translate(227.685547 0.78125)"/>
      <use xlink:href="#DejaVuSans-35" transform="translate(259.472656 0.78125)"/>
      <use xlink:href="#DejaVuSans-2c" transform="translate(323.095703 0.78125)"/>
      <use xlink:href="#DejaVuSans-20" transform="translate(354.882812 0.78125)"/>
      <use xlink:href="#DejaVuSans-Oblique-3c3" transform="translate(386.669922 0.78125)"/>
      <use xlink:href="#DejaVuSans-3d" transform="translate(469.53125 0.78125)"/>
      <use xlink:href="#DejaVuSans-31" transform="translate(572.802734 0.78125)"/>
     </g>
    </g>
    <g id="line2d_14">
     <path d="M 172.573094 96.927422 
L 189.073094 96.927422 
L 205.573094 96.927422 
" style="fill: none; stroke: #2ca02c; stroke-width: 2.25; stroke-linecap: round"/>
    </g>
    <g id="text_14">
     <!-- $\ell = 1$, $\sigma = 0.5$ -->
     <g style="fill: #262626" transform="translate(218.773094 102.702422) scale(0.165 -0.165)">
      <use xlink:href="#DejaVuSans-Oblique-2113" transform="translate(0 0.78125)"/>
      <use xlink:href="#DejaVuSans-3d" transform="translate(60.791016 0.78125)"/>
      <use xlink:href="#DejaVuSans-31" transform="translate(164.0625 0.78125)"/>
      <use xlink:href="#DejaVuSans-2c" transform="translate(227.685547 0.78125)"/>
      <use xlink:href="#DejaVuSans-20" transform="translate(259.472656 0.78125)"/>
      <use xlink:href="#DejaVuSans-Oblique-3c3" transform="translate(291.259766 0.78125)"/>
      <use xlink:href="#DejaVuSans-3d" transform="translate(374.121094 0.78125)"/>
      <use xlink:href="#DejaVuSans-30" transform="translate(477.392578 0.78125)"/>
      <use xlink:href="#DejaVuSans-2e" transform="translate(541.015625 0.78125)"/>
      <use xlink:href="#DejaVuSans-35" transform="translate(572.802734 0.78125)"/>
     </g>
    </g>
   </g>
  </g>
 </g>
 <defs>
  <clipPath id="pfe801ce296">
   <rect x="60.586094" y="26.877188" width="278.142" height="113.076"/>
  </clipPath>
 </defs>
</svg>
"/>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>高斯过程，从字面上分解，我们就可以看出他包含两部分</p>
<ul>
<li>高斯，指的是高斯分布</li>
<li>过程，指的是随机过程<center>
<img alt="Encoder" src="https://drive.google.com/uc?export=view&amp;id=1Esepf22Yt32X7KFJCu_T4JJnewPm978c" width="600">
</img></center>
<caption><center><font color="purple"><b>Figure 1</b></font></center></caption>
</li>
</ul>
<p>首先当随机变量是1维的时候，我们称之为一维高斯分布，概率密度函数 $p(x)=N(μ,σ2)$当随机变量的维度上升到有限的 p 维的时候，就称之为高维高斯分布， $p(x)=N(μ,Σp×p)$. 而高斯过程则更进一步，他是一个定义在连续域上的无限多个高斯随机变量所组成的随机过程，换句话说，高斯过程是一个无限维的高斯分布</p>
<p>对于一个连续域 T （假设他是一个时间轴），如果我们在连续域上任选 n 个时刻： t1,t2,t3,...,tn∈T ，使得获得的一个 n 维向量 ${ξ_1,ξ_2,ξ_3,...,ξ_n}$ 都满足其是一个 n 维高斯分布，那么这个 ${ξ_t}$ 就是一个高斯过程</p>
<p>对于一个 p 维的高斯分布而言，决定他的分布是两个参数，一个是 p 维的均值向量 μp ，他反映了 p 维高斯分布中每一维随机变量的期望，另一个就是 p×p 的协方差矩阵 Σp×p ，他反映了高维分布中，每一维自身的方差，以及不同维度之间的协方差</p>
<p>定义在连续域 T 上的高斯过程其实也是一样，他是无限维的高斯分布，他同样需要描述每一个时间点 t 上的均值，但是这个时候就不能用向量了，因为是在连续域上的，维数是无限的，因此就应该定义成一个关于时刻 t 的函数： $m(t)$ 。</p>
<p>协方差矩阵也是同理，无限维的情况下就定义为一个核函数 $k(s,t)$ ，其中 s 和 t 表示任意两个时刻，核函数也称协方差函数。核函数是一个高斯过程的核心，他决定了高斯过程的性质，在研究和实践中，核函数有很多种不同的类型，他们对高斯过程的衡量方法也不尽相同，这里我们介绍和使用最为常见的一个核函数：径向基函数 RBF - Squared Exponential Kernel ，其定义如下
$$k(x_a, x_b) = \sigma^2 \exp \left(-\frac{ \left\Vert x_a - x_b \right\Vert^2}{2\ell^2}\right)$$</p>
<p>这里面的 σ 和 l 是径向基函数的超参数，使我们提前可以设置好的，例如我们可以让 σ=1 ， l=1 ，从这个式子中，我们可以解读出他的思想</p>
<p>和 t 表示高斯过程连续域上的两个不同的时间点， $||s−t||^2$ 是一个二范式，简单点说就是 s 和 t 之间的距离，径向基函数输出的是一个标量，他代表的就是 s 和 t 两个时间点各自所代表的高斯分布之间的协方差值，很明显径向基函数是一个关于s，t距离负相关的函数，两个点距离越大，两个分布之间的协方差值越小，即相关性越小，反之越靠近的两个时间点对应的分布其协方差值就越大。</p>
<p>由此，高斯过程的两个核心要素：均值函数和核函数的定义我们就描述清楚了，按照高斯过程存在性定理，一旦这两个要素确定了，那么整个高斯过程就确定了：
$$ξ_t∼GP(m(t),k(t,s))$$</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">def</span> <span class="nf">gaussian_kernel</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">l</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">sigma_f</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
    <span class="n">m</span><span class="p">,</span> <span class="n">n</span> <span class="o">=</span> <span class="n">x1</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x2</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">dist_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">m</span><span class="p">,</span> <span class="n">n</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
            <span class="n">dist_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">x1</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">x2</span><span class="p">[</span><span class="n">j</span><span class="p">])</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">sigma_f</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span> <span class="mf">0.5</span> <span class="o">/</span> <span class="n">l</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">dist_matrix</span><span class="p">)</span>

<span class="n">train_X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">9</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="c1">#转换为4*1矩阵形式</span>
<span class="nb">print</span><span class="p">(</span><span class="n">gaussian_kernel</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_X</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>[[1.00000000e+00 1.35335283e-01 1.52299797e-08 1.26641655e-14]
 [1.35335283e-01 1.00000000e+00 3.35462628e-04 1.52299797e-08]
 [1.52299797e-08 3.35462628e-04 1.00000000e+00 1.35335283e-01]
 [1.26641655e-14 1.52299797e-08 1.35335283e-01 1.00000000e+00]]
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>Generate the GP:</p>
<ul>
<li>给定mean function和covariance（kernel） function，比如最简单的mean默认为constant，且为0，,kernel = Squared Exponential(SE)。</li>
<li>给定mean function以及kernel中的hyperparameter的初始值，比如，mean是constant，一点为0那就是处处为0了，kernel =SE, 需要给出其中的$\ell,\sigma^2$ (refer to Documentation for GPML Matlab Code)</li>
<li>给定想要产生的样本函数定义域，比如问题图中的范围[0,1]，如果是计算程序的，自然还涉及到取多少个点，比如在给定的[0,1]每隔0.01去一个点总共101个输入点。</li>
<li>有了mean function和kernel以及对应的初始超参数，那么我们就可以计算对应的mean function 的均值向量，记为M， kernel的covariance matrix，记为C。</li>
<li>对C进行SVD分解 $C=\mu sv^{'}$</li>
<li>从标准高斯分布中产生n个点的样本，这里n就是输入点的个数，记为$g_n$</li>
<li>利用$z_{gp}=\mu \sqrt{s}g_n+M$就可以生成一个给定具体mean function和kernel的GP的样本。</li>
</ul>
<p>这个定理（详见<a href="https://arxiv.org/pdf/1605.07906.pdf%EF%BC%89%5B3">https://arxiv.org/pdf/1605.07906.pdf）[3</a>]</p>
<center>
<img alt="Encoder" src="https://drive.google.com/uc?export=view&amp;id=1KgnxkwS6DGJhBE5_WtwycdwvRaD0XYIv" width="600"/>
</center>
<center>
<caption><font color="purple"><b>Figure 2</b></font></caption>
</center>
<p>所以,
$$
E\left(z_{g p}\right)=u \sqrt{s} E\left(g_n\right)+E(M)=M
$$
$$
\operatorname{cov}\left(z_{g p}, z_{g p}^{\prime}\right)=u \sqrt{s} * 1 * \sqrt{s} v^{\prime}=u s v^{\prime}=C
$$
因此就可以说明这就是以上GP的一个样本。</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [238]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="c1"># Plot kernel matrix and samples of exponentiated quadratic</span>

<span class="n">nb_of_samples</span> <span class="o">=</span> <span class="mi">150</span>  <span class="c1"># Number of test points.</span>
<span class="n">nb_of_realizations</span> <span class="o">=</span> <span class="mi">1</span>  <span class="c1"># Number of function realizations</span>
<span class="c1"># Generate input points</span>
<span class="n">xlim</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">*</span><span class="n">xlim</span><span class="p">,</span> <span class="n">nb_of_samples</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># Start plotting</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span> 
<span class="n">gs</span> <span class="o">=</span> <span class="n">gridspec</span><span class="o">.</span><span class="n">GridSpec</span><span class="p">(</span>
    <span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figure</span><span class="o">=</span><span class="n">fig</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.4</span><span class="p">)</span>

<span class="c1"># Plot first</span>
<span class="c1"># 计算coveraince according to the input</span>
<span class="n">Σ</span> <span class="o">=</span> <span class="n">tfk</span><span class="o">.</span><span class="n">ExponentiatedQuadratic</span><span class="p">(</span><span class="n">amplitude</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">length_scale</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span><span class="o">.</span><span class="n">matrix</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span>
    <span class="n">mean</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">nb_of_samples</span><span class="p">),</span> <span class="n">cov</span><span class="o">=</span><span class="n">Σ</span><span class="p">,</span> 
    <span class="n">size</span><span class="o">=</span><span class="n">nb_of_realizations</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
<span class="n">plot_kernel</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">Σ</span><span class="p">,</span> <span class="s1">'$</span><span class="se">\\</span><span class="s1">ell = 1$, $</span><span class="se">\\</span><span class="s1">sigma = 1$'</span><span class="p">,</span> 
    <span class="n">fig</span><span class="p">,</span> <span class="n">gs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">xlim</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedSVG jp-OutputArea-output" data-mime-type="image/svg+xml" tabindex="0">
<img alt="No description has been provided for this image" src="data:image/svg+xml;base64,<?xml version="1.0" encoding="utf-8" standalone="no"?>
<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN"
  "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">
<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="470.937681pt" height="178.830572pt" viewBox="0 0 470.937681 178.830572" xmlns="http://www.w3.org/2000/svg" version="1.1">
 <metadata>
  <rdf:RDF xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:cc="http://creativecommons.org/ns#" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#">
   <cc:Work>
    <dc:type rdf:resource="http://purl.org/dc/dcmitype/StillImage"/>
    <dc:date>2023-05-11T08:10:53.685416</dc:date>
    <dc:format>image/svg+xml</dc:format>
    <dc:creator>
     <cc:Agent>
      <dc:title>Matplotlib v3.7.1, https://matplotlib.org/</dc:title>
     </cc:Agent>
    </dc:creator>
   </cc:Work>
  </rdf:RDF>
 </metadata>
 <defs>
  <style type="text/css">*{stroke-linejoin: round; stroke-linecap: butt}</style>
 </defs>
 <g id="figure_1">
  <g id="patch_1">
   <path d="M 0 178.830572 
L 470.937681 178.830572 
L 470.937681 0 
L 0 0 
z
" style="fill: #ffffff"/>
  </g>
  <g id="axes_1">
   <g id="patch_2">
    <path d="M 41.52375 142.370885 
L 280.422833 142.370885 
L 280.422833 35.7555 
L 41.52375 35.7555 
z
" style="fill: #eaeaf2"/>
   </g>
   <g id="matplotlib.axis_1">
    <g id="xtick_1">
     <g id="line2d_1">
      <path d="M 41.52375 142.370885 
L 41.52375 35.7555 
" clip-path="url(#p9f020a32a5)" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round"/>
     </g>
     <g id="text_1">
      <!-- −4 -->
      <g style="fill: #262626" transform="translate(34.152656 156.969322) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-2212" d="M 678 2272 
L 4684 2272 
L 4684 1741 
L 678 1741 
L 678 2272 
z
" transform="scale(0.015625)"/>
        <path id="DejaVuSans-34" d="M 2419 4116 
L 825 1625 
L 2419 1625 
L 2419 4116 
z
M 2253 4666 
L 3047 4666 
L 3047 1625 
L 3713 1625 
L 3713 1100 
L 3047 1100 
L 3047 0 
L 2419 0 
L 2419 1100 
L 313 1100 
L 313 1709 
L 2253 4666 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-2212"/>
       <use xlink:href="#DejaVuSans-34" x="83.789062"/>
      </g>
     </g>
    </g>
    <g id="xtick_2">
     <g id="line2d_2">
      <path d="M 101.248521 142.370885 
L 101.248521 35.7555 
" clip-path="url(#p9f020a32a5)" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round"/>
     </g>
     <g id="text_2">
      <!-- −2 -->
      <g style="fill: #262626" transform="translate(93.877427 156.969322) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-32" d="M 1228 531 
L 3431 531 
L 3431 0 
L 469 0 
L 469 531 
Q 828 903 1448 1529 
Q 2069 2156 2228 2338 
Q 2531 2678 2651 2914 
Q 2772 3150 2772 3378 
Q 2772 3750 2511 3984 
Q 2250 4219 1831 4219 
Q 1534 4219 1204 4116 
Q 875 4013 500 3803 
L 500 4441 
Q 881 4594 1212 4672 
Q 1544 4750 1819 4750 
Q 2544 4750 2975 4387 
Q 3406 4025 3406 3419 
Q 3406 3131 3298 2873 
Q 3191 2616 2906 2266 
Q 2828 2175 2409 1742 
Q 1991 1309 1228 531 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-2212"/>
       <use xlink:href="#DejaVuSans-32" x="83.789062"/>
      </g>
     </g>
    </g>
    <g id="xtick_3">
     <g id="line2d_3">
      <path d="M 160.973291 142.370885 
L 160.973291 35.7555 
" clip-path="url(#p9f020a32a5)" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round"/>
     </g>
     <g id="text_3">
      <!-- 0 -->
      <g style="fill: #262626" transform="translate(157.792041 156.969322) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-30" d="M 2034 4250 
Q 1547 4250 1301 3770 
Q 1056 3291 1056 2328 
Q 1056 1369 1301 889 
Q 1547 409 2034 409 
Q 2525 409 2770 889 
Q 3016 1369 3016 2328 
Q 3016 3291 2770 3770 
Q 2525 4250 2034 4250 
z
M 2034 4750 
Q 2819 4750 3233 4129 
Q 3647 3509 3647 2328 
Q 3647 1150 3233 529 
Q 2819 -91 2034 -91 
Q 1250 -91 836 529 
Q 422 1150 422 2328 
Q 422 3509 836 4129 
Q 1250 4750 2034 4750 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-30"/>
      </g>
     </g>
    </g>
    <g id="xtick_4">
     <g id="line2d_4">
      <path d="M 220.698062 142.370885 
L 220.698062 35.7555 
" clip-path="url(#p9f020a32a5)" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round"/>
     </g>
     <g id="text_4">
      <!-- 2 -->
      <g style="fill: #262626" transform="translate(217.516812 156.969322) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-32"/>
      </g>
     </g>
    </g>
    <g id="xtick_5">
     <g id="line2d_5">
      <path d="M 280.422833 142.370885 
L 280.422833 35.7555 
" clip-path="url(#p9f020a32a5)" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round"/>
     </g>
     <g id="text_5">
      <!-- 4 -->
      <g style="fill: #262626" transform="translate(277.241583 156.969322) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-34"/>
      </g>
     </g>
    </g>
    <g id="text_6">
     <!-- $x$ -->
     <g style="fill: #262626" transform="translate(157.073291 168.926978) scale(0.13 -0.13)">
      <defs>
       <path id="DejaVuSans-Oblique-78" d="M 3841 3500 
L 2234 1784 
L 3219 0 
L 2559 0 
L 1819 1388 
L 531 0 
L -166 0 
L 1556 1844 
L 641 3500 
L 1300 3500 
L 1972 2234 
L 3144 3500 
L 3841 3500 
z
" transform="scale(0.015625)"/>
      </defs>
      <use xlink:href="#DejaVuSans-Oblique-78" transform="translate(0 0.3125)"/>
     </g>
    </g>
   </g>
   <g id="matplotlib.axis_2">
    <g id="ytick_1">
     <g id="line2d_6">
      <path d="M 41.52375 130.1311 
L 280.422833 130.1311 
" clip-path="url(#p9f020a32a5)" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round"/>
     </g>
     <g id="text_7">
      <!-- −2 -->
      <g style="fill: #262626" transform="translate(19.781563 133.930319) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-2212"/>
       <use xlink:href="#DejaVuSans-32" x="83.789062"/>
      </g>
     </g>
    </g>
    <g id="ytick_2">
     <g id="line2d_7">
      <path d="M 41.52375 105.166903 
L 280.422833 105.166903 
" clip-path="url(#p9f020a32a5)" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round"/>
     </g>
     <g id="text_8">
      <!-- −1 -->
      <g style="fill: #262626" transform="translate(19.781563 108.966121) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-31" d="M 794 531 
L 1825 531 
L 1825 4091 
L 703 3866 
L 703 4441 
L 1819 4666 
L 2450 4666 
L 2450 531 
L 3481 531 
L 3481 0 
L 794 0 
L 794 531 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-2212"/>
       <use xlink:href="#DejaVuSans-31" x="83.789062"/>
      </g>
     </g>
    </g>
    <g id="ytick_3">
     <g id="line2d_8">
      <path d="M 41.52375 80.202705 
L 280.422833 80.202705 
" clip-path="url(#p9f020a32a5)" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round"/>
     </g>
     <g id="text_9">
      <!-- 0 -->
      <g style="fill: #262626" transform="translate(28.16125 84.001924) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-30"/>
      </g>
     </g>
    </g>
    <g id="ytick_4">
     <g id="line2d_9">
      <path d="M 41.52375 55.238508 
L 280.422833 55.238508 
" clip-path="url(#p9f020a32a5)" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round"/>
     </g>
     <g id="text_10">
      <!-- 1 -->
      <g style="fill: #262626" transform="translate(28.16125 59.037726) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-31"/>
      </g>
     </g>
    </g>
    <g id="text_11">
     <!-- $y$ -->
     <g style="fill: #262626" transform="translate(17.051563 92.963192) rotate(-90) scale(0.13 -0.13)">
      <defs>
       <path id="DejaVuSans-Oblique-79" d="M 1588 -325 
Q 1188 -997 936 -1164 
Q 684 -1331 294 -1331 
L -159 -1331 
L -63 -850 
L 269 -850 
Q 509 -850 678 -719 
Q 847 -588 1056 -206 
L 1234 128 
L 459 3500 
L 1069 3500 
L 1650 819 
L 3256 3500 
L 3859 3500 
L 1588 -325 
z
" transform="scale(0.015625)"/>
      </defs>
      <use xlink:href="#DejaVuSans-Oblique-79" transform="translate(0 0.3125)"/>
     </g>
    </g>
   </g>
   <g id="line2d_10">
    <path d="M 41.52375 51.565086 
L 44.730449 51.216064 
L 47.937148 50.347978 
L 51.143847 49.124097 
L 54.350546 47.557566 
L 63.970644 42.622084 
L 65.573993 41.940755 
L 68.780692 40.984238 
L 70.384042 40.65121 
L 73.590741 40.655668 
L 75.19409 40.924441 
L 76.79744 41.349619 
L 78.40079 42.026407 
L 80.004139 42.911583 
L 81.607489 43.97887 
L 83.210838 45.299149 
L 84.814188 46.851567 
L 86.417537 48.607557 
L 89.624236 52.596646 
L 92.830936 57.249953 
L 97.640984 64.734032 
L 102.451033 72.280159 
L 105.657732 76.815487 
L 108.864431 80.669385 
L 110.467781 82.286976 
L 112.07113 83.689792 
L 113.67448 84.780149 
L 115.277829 85.685114 
L 116.881179 86.303234 
L 118.484528 86.669701 
L 120.087878 86.804611 
L 121.691227 86.685223 
L 123.294577 86.392059 
L 124.897926 85.872946 
L 126.501276 85.233401 
L 129.707975 83.628365 
L 136.121373 79.993009 
L 139.328072 78.498828 
L 142.534771 77.497754 
L 144.138121 77.203617 
L 145.741471 77.076871 
L 147.34482 77.134652 
L 148.94817 77.347382 
L 150.551519 77.751432 
L 152.154869 78.307814 
L 153.758218 79.012642 
L 156.964917 80.861415 
L 160.171617 83.155444 
L 163.378316 85.747677 
L 171.395063 92.574082 
L 174.601762 95.018099 
L 177.808462 97.110047 
L 181.015161 98.754314 
L 182.61851 99.392368 
L 184.22186 99.88368 
L 185.825209 100.189066 
L 187.428559 100.377885 
L 189.031908 100.435737 
L 192.238607 100.120646 
L 193.841957 99.755937 
L 197.048656 98.711215 
L 200.255355 97.316039 
L 209.875452 92.532757 
L 211.478802 91.853512 
L 214.685501 90.869656 
L 216.288851 90.539893 
L 217.8922 90.383875 
L 221.098899 90.672609 
L 222.702249 91.083685 
L 224.305598 91.731858 
L 225.908948 92.54179 
L 227.512298 93.616782 
L 229.115647 94.889353 
L 230.718997 96.330003 
L 233.925696 99.838529 
L 237.132395 104.107767 
L 240.339094 108.836067 
L 245.149143 116.435028 
L 249.959191 123.960744 
L 253.16589 128.531943 
L 256.372589 132.298063 
L 257.975939 133.816684 
L 259.579288 135.162214 
L 261.182638 136.20654 
L 262.785988 136.99731 
L 264.389337 137.356249 
L 265.992687 137.524731 
L 267.596036 137.359318 
L 269.199386 136.827231 
L 270.802735 136.049451 
L 272.406085 134.942295 
L 274.009434 133.558979 
L 275.612784 131.848478 
L 278.819483 127.771897 
L 280.422833 125.340166 
L 280.422833 125.340166 
" clip-path="url(#p9f020a32a5)" style="fill: none; stroke: #1f77b4; stroke-opacity: 0.8; stroke-width: 1.5; stroke-linecap: round"/>
   </g>
   <g id="patch_3">
    <path d="M 41.52375 142.370885 
L 41.52375 35.7555 
" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="patch_4">
    <path d="M 280.422833 142.370885 
L 280.422833 35.7555 
" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="patch_5">
    <path d="M 41.52375 142.370885 
L 280.422833 142.370885 
" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="patch_6">
    <path d="M 41.52375 35.7555 
L 280.422833 35.7555 
" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="text_12">
    <!-- Samples from $\ell = 1$, $\sigma = 1$ -->
    <g style="fill: #262626" transform="translate(84.953291 29.7555) scale(0.12 -0.12)">
     <defs>
      <path id="DejaVuSans-53" d="M 3425 4513 
L 3425 3897 
Q 3066 4069 2747 4153 
Q 2428 4238 2131 4238 
Q 1616 4238 1336 4038 
Q 1056 3838 1056 3469 
Q 1056 3159 1242 3001 
Q 1428 2844 1947 2747 
L 2328 2669 
Q 3034 2534 3370 2195 
Q 3706 1856 3706 1288 
Q 3706 609 3251 259 
Q 2797 -91 1919 -91 
Q 1588 -91 1214 -16 
Q 841 59 441 206 
L 441 856 
Q 825 641 1194 531 
Q 1563 422 1919 422 
Q 2459 422 2753 634 
Q 3047 847 3047 1241 
Q 3047 1584 2836 1778 
Q 2625 1972 2144 2069 
L 1759 2144 
Q 1053 2284 737 2584 
Q 422 2884 422 3419 
Q 422 4038 858 4394 
Q 1294 4750 2059 4750 
Q 2388 4750 2728 4690 
Q 3069 4631 3425 4513 
z
" transform="scale(0.015625)"/>
      <path id="DejaVuSans-61" d="M 2194 1759 
Q 1497 1759 1228 1600 
Q 959 1441 959 1056 
Q 959 750 1161 570 
Q 1363 391 1709 391 
Q 2188 391 2477 730 
Q 2766 1069 2766 1631 
L 2766 1759 
L 2194 1759 
z
M 3341 1997 
L 3341 0 
L 2766 0 
L 2766 531 
Q 2569 213 2275 61 
Q 1981 -91 1556 -91 
Q 1019 -91 701 211 
Q 384 513 384 1019 
Q 384 1609 779 1909 
Q 1175 2209 1959 2209 
L 2766 2209 
L 2766 2266 
Q 2766 2663 2505 2880 
Q 2244 3097 1772 3097 
Q 1472 3097 1187 3025 
Q 903 2953 641 2809 
L 641 3341 
Q 956 3463 1253 3523 
Q 1550 3584 1831 3584 
Q 2591 3584 2966 3190 
Q 3341 2797 3341 1997 
z
" transform="scale(0.015625)"/>
      <path id="DejaVuSans-6d" d="M 3328 2828 
Q 3544 3216 3844 3400 
Q 4144 3584 4550 3584 
Q 5097 3584 5394 3201 
Q 5691 2819 5691 2113 
L 5691 0 
L 5113 0 
L 5113 2094 
Q 5113 2597 4934 2840 
Q 4756 3084 4391 3084 
Q 3944 3084 3684 2787 
Q 3425 2491 3425 1978 
L 3425 0 
L 2847 0 
L 2847 2094 
Q 2847 2600 2669 2842 
Q 2491 3084 2119 3084 
Q 1678 3084 1418 2786 
Q 1159 2488 1159 1978 
L 1159 0 
L 581 0 
L 581 3500 
L 1159 3500 
L 1159 2956 
Q 1356 3278 1631 3431 
Q 1906 3584 2284 3584 
Q 2666 3584 2933 3390 
Q 3200 3197 3328 2828 
z
" transform="scale(0.015625)"/>
      <path id="DejaVuSans-70" d="M 1159 525 
L 1159 -1331 
L 581 -1331 
L 581 3500 
L 1159 3500 
L 1159 2969 
Q 1341 3281 1617 3432 
Q 1894 3584 2278 3584 
Q 2916 3584 3314 3078 
Q 3713 2572 3713 1747 
Q 3713 922 3314 415 
Q 2916 -91 2278 -91 
Q 1894 -91 1617 61 
Q 1341 213 1159 525 
z
M 3116 1747 
Q 3116 2381 2855 2742 
Q 2594 3103 2138 3103 
Q 1681 3103 1420 2742 
Q 1159 2381 1159 1747 
Q 1159 1113 1420 752 
Q 1681 391 2138 391 
Q 2594 391 2855 752 
Q 3116 1113 3116 1747 
z
" transform="scale(0.015625)"/>
      <path id="DejaVuSans-6c" d="M 603 4863 
L 1178 4863 
L 1178 0 
L 603 0 
L 603 4863 
z
" transform="scale(0.015625)"/>
      <path id="DejaVuSans-65" d="M 3597 1894 
L 3597 1613 
L 953 1613 
Q 991 1019 1311 708 
Q 1631 397 2203 397 
Q 2534 397 2845 478 
Q 3156 559 3463 722 
L 3463 178 
Q 3153 47 2828 -22 
Q 2503 -91 2169 -91 
Q 1331 -91 842 396 
Q 353 884 353 1716 
Q 353 2575 817 3079 
Q 1281 3584 2069 3584 
Q 2775 3584 3186 3129 
Q 3597 2675 3597 1894 
z
M 3022 2063 
Q 3016 2534 2758 2815 
Q 2500 3097 2075 3097 
Q 1594 3097 1305 2825 
Q 1016 2553 972 2059 
L 3022 2063 
z
" transform="scale(0.015625)"/>
      <path id="DejaVuSans-73" d="M 2834 3397 
L 2834 2853 
Q 2591 2978 2328 3040 
Q 2066 3103 1784 3103 
Q 1356 3103 1142 2972 
Q 928 2841 928 2578 
Q 928 2378 1081 2264 
Q 1234 2150 1697 2047 
L 1894 2003 
Q 2506 1872 2764 1633 
Q 3022 1394 3022 966 
Q 3022 478 2636 193 
Q 2250 -91 1575 -91 
Q 1294 -91 989 -36 
Q 684 19 347 128 
L 347 722 
Q 666 556 975 473 
Q 1284 391 1588 391 
Q 1994 391 2212 530 
Q 2431 669 2431 922 
Q 2431 1156 2273 1281 
Q 2116 1406 1581 1522 
L 1381 1569 
Q 847 1681 609 1914 
Q 372 2147 372 2553 
Q 372 3047 722 3315 
Q 1072 3584 1716 3584 
Q 2034 3584 2315 3537 
Q 2597 3491 2834 3397 
z
" transform="scale(0.015625)"/>
      <path id="DejaVuSans-20" transform="scale(0.015625)"/>
      <path id="DejaVuSans-66" d="M 2375 4863 
L 2375 4384 
L 1825 4384 
Q 1516 4384 1395 4259 
Q 1275 4134 1275 3809 
L 1275 3500 
L 2222 3500 
L 2222 3053 
L 1275 3053 
L 1275 0 
L 697 0 
L 697 3053 
L 147 3053 
L 147 3500 
L 697 3500 
L 697 3744 
Q 697 4328 969 4595 
Q 1241 4863 1831 4863 
L 2375 4863 
z
" transform="scale(0.015625)"/>
      <path id="DejaVuSans-72" d="M 2631 2963 
Q 2534 3019 2420 3045 
Q 2306 3072 2169 3072 
Q 1681 3072 1420 2755 
Q 1159 2438 1159 1844 
L 1159 0 
L 581 0 
L 581 3500 
L 1159 3500 
L 1159 2956 
Q 1341 3275 1631 3429 
Q 1922 3584 2338 3584 
Q 2397 3584 2469 3576 
Q 2541 3569 2628 3553 
L 2631 2963 
z
" transform="scale(0.015625)"/>
      <path id="DejaVuSans-6f" d="M 1959 3097 
Q 1497 3097 1228 2736 
Q 959 2375 959 1747 
Q 959 1119 1226 758 
Q 1494 397 1959 397 
Q 2419 397 2687 759 
Q 2956 1122 2956 1747 
Q 2956 2369 2687 2733 
Q 2419 3097 1959 3097 
z
M 1959 3584 
Q 2709 3584 3137 3096 
Q 3566 2609 3566 1747 
Q 3566 888 3137 398 
Q 2709 -91 1959 -91 
Q 1206 -91 779 398 
Q 353 888 353 1747 
Q 353 2609 779 3096 
Q 1206 3584 1959 3584 
z
" transform="scale(0.015625)"/>
      <path id="DejaVuSans-Oblique-2113" d="M 950 838 
Q 1078 213 1350 213 
Q 1531 213 1766 572 
L 2181 572 
Q 1994 253 1775 88 
Q 1538 -91 1319 -91 
Q 831 -91 634 344 
L 400 0 
L -88 0 
Q 250 459 500 888 
Q 469 1131 469 1397 
Q 469 1872 566 2347 
Q 931 4131 1256 4497 
Q 1481 4750 1866 4750 
Q 2256 4750 2256 4209 
Q 2253 3966 2197 3675 
Q 1972 2484 950 838 
z
M 947 1656 
Q 1531 2744 1709 3613 
Q 1803 4072 1803 4191 
Q 1803 4406 1725 4406 
Q 1384 4134 1081 2516 
Q 997 2063 947 1656 
z
" transform="scale(0.015625)"/>
      <path id="DejaVuSans-3d" d="M 678 2906 
L 4684 2906 
L 4684 2381 
L 678 2381 
L 678 2906 
z
M 678 1631 
L 4684 1631 
L 4684 1100 
L 678 1100 
L 678 1631 
z
" transform="scale(0.015625)"/>
      <path id="DejaVuSans-2c" d="M 750 794 
L 1409 794 
L 1409 256 
L 897 -744 
L 494 -744 
L 750 256 
L 750 794 
z
" transform="scale(0.015625)"/>
      <path id="DejaVuSans-Oblique-3c3" d="M 2219 3044 
Q 1744 3044 1422 2700 
Q 1081 2341 969 1747 
Q 844 1119 1044 756 
Q 1241 397 1706 397 
Q 2166 397 2503 759 
Q 2844 1122 2966 1747 
Q 3075 2319 2881 2700 
Q 2700 3044 2219 3044 
z
M 2309 3503 
L 4219 3500 
L 4106 2925 
L 3463 2925 
Q 3706 2438 3575 1747 
Q 3406 888 2884 400 
Q 2359 -91 1609 -91 
Q 856 -91 525 400 
Q 194 888 363 1747 
Q 528 2609 1050 3097 
Q 1484 3503 2309 3503 
z
" transform="scale(0.015625)"/>
     </defs>
     <use xlink:href="#DejaVuSans-53" transform="translate(0 0.015625)"/>
     <use xlink:href="#DejaVuSans-61" transform="translate(63.476562 0.015625)"/>
     <use xlink:href="#DejaVuSans-6d" transform="translate(124.755859 0.015625)"/>
     <use xlink:href="#DejaVuSans-70" transform="translate(222.167969 0.015625)"/>
     <use xlink:href="#DejaVuSans-6c" transform="translate(285.644531 0.015625)"/>
     <use xlink:href="#DejaVuSans-65" transform="translate(313.427734 0.015625)"/>
     <use xlink:href="#DejaVuSans-73" transform="translate(374.951172 0.015625)"/>
     <use xlink:href="#DejaVuSans-20" transform="translate(427.050781 0.015625)"/>
     <use xlink:href="#DejaVuSans-66" transform="translate(458.837891 0.015625)"/>
     <use xlink:href="#DejaVuSans-72" transform="translate(494.042969 0.015625)"/>
     <use xlink:href="#DejaVuSans-6f" transform="translate(535.15625 0.015625)"/>
     <use xlink:href="#DejaVuSans-6d" transform="translate(596.337891 0.015625)"/>
     <use xlink:href="#DejaVuSans-20" transform="translate(693.75 0.015625)"/>
     <use xlink:href="#DejaVuSans-Oblique-2113" transform="translate(725.537109 0.015625)"/>
     <use xlink:href="#DejaVuSans-3d" transform="translate(786.328125 0.015625)"/>
     <use xlink:href="#DejaVuSans-31" transform="translate(889.599609 0.015625)"/>
     <use xlink:href="#DejaVuSans-2c" transform="translate(953.222656 0.015625)"/>
     <use xlink:href="#DejaVuSans-20" transform="translate(985.009766 0.015625)"/>
     <use xlink:href="#DejaVuSans-Oblique-3c3" transform="translate(1016.796875 0.015625)"/>
     <use xlink:href="#DejaVuSans-3d" transform="translate(1099.658203 0.015625)"/>
     <use xlink:href="#DejaVuSans-31" transform="translate(1202.929688 0.015625)"/>
    </g>
   </g>
  </g>
  <g id="axes_2">
   <g id="patch_7">
    <path d="M 315.705902 142.370885 
L 422.321287 142.370885 
L 422.321287 35.7555 
L 315.705902 35.7555 
z
" style="fill: #eaeaf2"/>
   </g>
   <g clip-path="url(#p69acad6b62)">
    <image xlink:href="data:image/png;base64,
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" id="imaged3c6bd34af" transform="scale(1 -1) translate(0 -106.56)" x="315.705902" y="-35.456681" width="106.56" height="106.56"/>
   </g>
   <g id="matplotlib.axis_3">
    <g id="xtick_6">
     <g id="text_13">
      <!-- -4 -->
      <g style="fill: #262626" transform="translate(311.07495 156.969322) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-2d" d="M 313 2009 
L 1997 2009 
L 1997 1497 
L 313 1497 
L 313 2009 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-2d"/>
       <use xlink:href="#DejaVuSans-34" x="36.083984"/>
      </g>
     </g>
    </g>
    <g id="xtick_7">
     <g id="text_14">
      <!-- -2 -->
      <g style="fill: #262626" transform="translate(337.640245 156.969322) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-2d"/>
       <use xlink:href="#DejaVuSans-32" x="36.083984"/>
      </g>
     </g>
    </g>
    <g id="xtick_8">
     <g id="text_15">
      <!-- 0 -->
      <g style="fill: #262626" transform="translate(366.009447 156.969322) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-30"/>
      </g>
     </g>
    </g>
    <g id="xtick_9">
     <g id="text_16">
      <!-- 2 -->
      <g style="fill: #262626" transform="translate(392.574742 156.969322) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-32"/>
      </g>
     </g>
    </g>
    <g id="xtick_10">
     <g id="text_17">
      <!-- 4 -->
      <g style="fill: #262626" transform="translate(419.140037 156.969322) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-34"/>
      </g>
     </g>
    </g>
    <g id="text_18">
     <!-- X -->
     <g style="fill: #262626" transform="translate(365.588595 166.647447) scale(0.1 -0.1)">
      <defs>
       <path id="DejaVuSans-58" d="M 403 4666 
L 1081 4666 
L 2241 2931 
L 3406 4666 
L 4084 4666 
L 2584 2425 
L 4184 0 
L 3506 0 
L 2194 1984 
L 872 0 
L 191 0 
L 1856 2491 
L 403 4666 
z
" transform="scale(0.015625)"/>
      </defs>
      <use xlink:href="#DejaVuSans-58"/>
     </g>
    </g>
   </g>
   <g id="matplotlib.axis_4">
    <g id="ytick_5">
     <g id="text_19">
      <!-- -4 -->
      <g style="fill: #262626" transform="translate(298.73559 39.908923) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-2d"/>
       <use xlink:href="#DejaVuSans-34" x="36.083984"/>
      </g>
     </g>
    </g>
    <g id="ytick_6">
     <g id="text_20">
      <!-- -2 -->
      <g style="fill: #262626" transform="translate(298.73559 66.474218) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-2d"/>
       <use xlink:href="#DejaVuSans-32" x="36.083984"/>
      </g>
     </g>
    </g>
    <g id="ytick_7">
     <g id="text_21">
      <!-- 0 -->
      <g style="fill: #262626" transform="translate(302.343402 93.039513) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-30"/>
      </g>
     </g>
    </g>
    <g id="ytick_8">
     <g id="text_22">
      <!-- 2 -->
      <g style="fill: #262626" transform="translate(302.343402 119.604808) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-32"/>
      </g>
     </g>
    </g>
    <g id="ytick_9">
     <g id="text_23">
      <!-- 4 -->
      <g style="fill: #262626" transform="translate(302.343402 146.170103) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-34"/>
      </g>
     </g>
    </g>
    <g id="text_24">
     <!-- X -->
     <g style="fill: #262626" transform="translate(296.655902 92.488192) rotate(-90) scale(0.1 -0.1)">
      <use xlink:href="#DejaVuSans-58"/>
     </g>
    </g>
   </g>
   <g id="patch_8">
    <path d="M 315.705902 142.370885 
L 315.705902 35.7555 
" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="patch_9">
    <path d="M 422.321287 142.370885 
L 422.321287 35.7555 
" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="patch_10">
    <path d="M 315.705902 142.370885 
L 422.321287 142.370885 
" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="patch_11">
    <path d="M 315.705902 35.7555 
L 422.321287 35.7555 
" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="text_25">
    <!-- Covariance matrix -->
    <g style="fill: #262626" transform="translate(313.855782 16.318125) scale(0.12 -0.12)">
     <defs>
      <path id="DejaVuSans-43" d="M 4122 4306 
L 4122 3641 
Q 3803 3938 3442 4084 
Q 3081 4231 2675 4231 
Q 1875 4231 1450 3742 
Q 1025 3253 1025 2328 
Q 1025 1406 1450 917 
Q 1875 428 2675 428 
Q 3081 428 3442 575 
Q 3803 722 4122 1019 
L 4122 359 
Q 3791 134 3420 21 
Q 3050 -91 2638 -91 
Q 1578 -91 968 557 
Q 359 1206 359 2328 
Q 359 3453 968 4101 
Q 1578 4750 2638 4750 
Q 3056 4750 3426 4639 
Q 3797 4528 4122 4306 
z
" transform="scale(0.015625)"/>
      <path id="DejaVuSans-76" d="M 191 3500 
L 800 3500 
L 1894 563 
L 2988 3500 
L 3597 3500 
L 2284 0 
L 1503 0 
L 191 3500 
z
" transform="scale(0.015625)"/>
      <path id="DejaVuSans-69" d="M 603 3500 
L 1178 3500 
L 1178 0 
L 603 0 
L 603 3500 
z
M 603 4863 
L 1178 4863 
L 1178 4134 
L 603 4134 
L 603 4863 
z
" transform="scale(0.015625)"/>
      <path id="DejaVuSans-6e" d="M 3513 2113 
L 3513 0 
L 2938 0 
L 2938 2094 
Q 2938 2591 2744 2837 
Q 2550 3084 2163 3084 
Q 1697 3084 1428 2787 
Q 1159 2491 1159 1978 
L 1159 0 
L 581 0 
L 581 3500 
L 1159 3500 
L 1159 2956 
Q 1366 3272 1645 3428 
Q 1925 3584 2291 3584 
Q 2894 3584 3203 3211 
Q 3513 2838 3513 2113 
z
" transform="scale(0.015625)"/>
      <path id="DejaVuSans-63" d="M 3122 3366 
L 3122 2828 
Q 2878 2963 2633 3030 
Q 2388 3097 2138 3097 
Q 1578 3097 1268 2742 
Q 959 2388 959 1747 
Q 959 1106 1268 751 
Q 1578 397 2138 397 
Q 2388 397 2633 464 
Q 2878 531 3122 666 
L 3122 134 
Q 2881 22 2623 -34 
Q 2366 -91 2075 -91 
Q 1284 -91 818 406 
Q 353 903 353 1747 
Q 353 2603 823 3093 
Q 1294 3584 2113 3584 
Q 2378 3584 2631 3529 
Q 2884 3475 3122 3366 
z
" transform="scale(0.015625)"/>
      <path id="DejaVuSans-74" d="M 1172 4494 
L 1172 3500 
L 2356 3500 
L 2356 3053 
L 1172 3053 
L 1172 1153 
Q 1172 725 1289 603 
Q 1406 481 1766 481 
L 2356 481 
L 2356 0 
L 1766 0 
Q 1100 0 847 248 
Q 594 497 594 1153 
L 594 3053 
L 172 3053 
L 172 3500 
L 594 3500 
L 594 4494 
L 1172 4494 
z
" transform="scale(0.015625)"/>
      <path id="DejaVuSans-78" d="M 3513 3500 
L 2247 1797 
L 3578 0 
L 2900 0 
L 1881 1375 
L 863 0 
L 184 0 
L 1544 1831 
L 300 3500 
L 978 3500 
L 1906 2253 
L 2834 3500 
L 3513 3500 
z
" transform="scale(0.015625)"/>
     </defs>
     <use xlink:href="#DejaVuSans-43"/>
     <use xlink:href="#DejaVuSans-6f" x="69.824219"/>
     <use xlink:href="#DejaVuSans-76" x="131.005859"/>
     <use xlink:href="#DejaVuSans-61" x="190.185547"/>
     <use xlink:href="#DejaVuSans-72" x="251.464844"/>
     <use xlink:href="#DejaVuSans-69" x="292.578125"/>
     <use xlink:href="#DejaVuSans-61" x="320.361328"/>
     <use xlink:href="#DejaVuSans-6e" x="381.640625"/>
     <use xlink:href="#DejaVuSans-63" x="445.019531"/>
     <use xlink:href="#DejaVuSans-65" x="500"/>
     <use xlink:href="#DejaVuSans-20" x="561.523438"/>
     <use xlink:href="#DejaVuSans-6d" x="593.310547"/>
     <use xlink:href="#DejaVuSans-61" x="690.722656"/>
     <use xlink:href="#DejaVuSans-74" x="752.001953"/>
     <use xlink:href="#DejaVuSans-72" x="791.210938"/>
     <use xlink:href="#DejaVuSans-69" x="832.324219"/>
     <use xlink:href="#DejaVuSans-78" x="860.107422"/>
    </g>
    <!-- $\ell = 1$, $\sigma = 1$ -->
    <g style="fill: #262626" transform="translate(336.493595 29.7555) scale(0.12 -0.12)">
     <use xlink:href="#DejaVuSans-Oblique-2113" transform="translate(0 0.78125)"/>
     <use xlink:href="#DejaVuSans-3d" transform="translate(60.791016 0.78125)"/>
     <use xlink:href="#DejaVuSans-31" transform="translate(164.0625 0.78125)"/>
     <use xlink:href="#DejaVuSans-2c" transform="translate(227.685547 0.78125)"/>
     <use xlink:href="#DejaVuSans-20" transform="translate(259.472656 0.78125)"/>
     <use xlink:href="#DejaVuSans-Oblique-3c3" transform="translate(291.259766 0.78125)"/>
     <use xlink:href="#DejaVuSans-3d" transform="translate(374.121094 0.78125)"/>
     <use xlink:href="#DejaVuSans-31" transform="translate(477.392578 0.78125)"/>
    </g>
   </g>
  </g>
  <g id="axes_3">
   <g id="patch_12">
    <path d="M 423.761287 142.370885 
L 429.092056 142.370885 
L 429.092056 35.7555 
L 423.761287 35.7555 
z
" style="fill: #eaeaf2"/>
   </g>
   <g id="matplotlib.axis_5"/>
   <g id="matplotlib.axis_6">
    <g id="ytick_10">
     <g id="line2d_11">
      <path d="M 423.761287 142.370885 
L 429.092056 142.370885 
" clip-path="url(#pc0b721b82f)" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round"/>
     </g>
     <g id="line2d_12">
      <defs>
       <path id="m7e79fb9c6c" d="M 0 0 
L 3.5 0 
" style="stroke: #262626; stroke-width: 0.8"/>
      </defs>
      <g>
       <use xlink:href="#m7e79fb9c6c" x="429.092056" y="142.370885" style="fill: #262626; stroke: #262626; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_26">
      <!-- 0.0 -->
      <g style="fill: #262626" transform="translate(436.092056 146.170103) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-2e" d="M 684 794 
L 1344 794 
L 1344 0 
L 684 0 
L 684 794 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-30"/>
       <use xlink:href="#DejaVuSans-2e" x="63.623047"/>
       <use xlink:href="#DejaVuSans-30" x="95.410156"/>
      </g>
     </g>
    </g>
    <g id="ytick_11">
     <g id="line2d_13">
      <path d="M 423.761287 121.047808 
L 429.092056 121.047808 
" clip-path="url(#pc0b721b82f)" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round"/>
     </g>
     <g id="line2d_14">
      <g>
       <use xlink:href="#m7e79fb9c6c" x="429.092056" y="121.047808" style="fill: #262626; stroke: #262626; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_27">
      <!-- 0.2 -->
      <g style="fill: #262626" transform="translate(436.092056 124.847026) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-30"/>
       <use xlink:href="#DejaVuSans-2e" x="63.623047"/>
       <use xlink:href="#DejaVuSans-32" x="95.410156"/>
      </g>
     </g>
    </g>
    <g id="ytick_12">
     <g id="line2d_15">
      <path d="M 423.761287 99.724731 
L 429.092056 99.724731 
" clip-path="url(#pc0b721b82f)" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round"/>
     </g>
     <g id="line2d_16">
      <g>
       <use xlink:href="#m7e79fb9c6c" x="429.092056" y="99.724731" style="fill: #262626; stroke: #262626; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_28">
      <!-- 0.4 -->
      <g style="fill: #262626" transform="translate(436.092056 103.52395) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-30"/>
       <use xlink:href="#DejaVuSans-2e" x="63.623047"/>
       <use xlink:href="#DejaVuSans-34" x="95.410156"/>
      </g>
     </g>
    </g>
    <g id="ytick_13">
     <g id="line2d_17">
      <path d="M 423.761287 78.401654 
L 429.092056 78.401654 
" clip-path="url(#pc0b721b82f)" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round"/>
     </g>
     <g id="line2d_18">
      <g>
       <use xlink:href="#m7e79fb9c6c" x="429.092056" y="78.401654" style="fill: #262626; stroke: #262626; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_29">
      <!-- 0.6 -->
      <g style="fill: #262626" transform="translate(436.092056 82.200873) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-36" d="M 2113 2584 
Q 1688 2584 1439 2293 
Q 1191 2003 1191 1497 
Q 1191 994 1439 701 
Q 1688 409 2113 409 
Q 2538 409 2786 701 
Q 3034 994 3034 1497 
Q 3034 2003 2786 2293 
Q 2538 2584 2113 2584 
z
M 3366 4563 
L 3366 3988 
Q 3128 4100 2886 4159 
Q 2644 4219 2406 4219 
Q 1781 4219 1451 3797 
Q 1122 3375 1075 2522 
Q 1259 2794 1537 2939 
Q 1816 3084 2150 3084 
Q 2853 3084 3261 2657 
Q 3669 2231 3669 1497 
Q 3669 778 3244 343 
Q 2819 -91 2113 -91 
Q 1303 -91 875 529 
Q 447 1150 447 2328 
Q 447 3434 972 4092 
Q 1497 4750 2381 4750 
Q 2619 4750 2861 4703 
Q 3103 4656 3366 4563 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-30"/>
       <use xlink:href="#DejaVuSans-2e" x="63.623047"/>
       <use xlink:href="#DejaVuSans-36" x="95.410156"/>
      </g>
     </g>
    </g>
    <g id="ytick_14">
     <g id="line2d_19">
      <path d="M 423.761287 57.078577 
L 429.092056 57.078577 
" clip-path="url(#pc0b721b82f)" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round"/>
     </g>
     <g id="line2d_20">
      <g>
       <use xlink:href="#m7e79fb9c6c" x="429.092056" y="57.078577" style="fill: #262626; stroke: #262626; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_30">
      <!-- 0.8 -->
      <g style="fill: #262626" transform="translate(436.092056 60.877796) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-38" d="M 2034 2216 
Q 1584 2216 1326 1975 
Q 1069 1734 1069 1313 
Q 1069 891 1326 650 
Q 1584 409 2034 409 
Q 2484 409 2743 651 
Q 3003 894 3003 1313 
Q 3003 1734 2745 1975 
Q 2488 2216 2034 2216 
z
M 1403 2484 
Q 997 2584 770 2862 
Q 544 3141 544 3541 
Q 544 4100 942 4425 
Q 1341 4750 2034 4750 
Q 2731 4750 3128 4425 
Q 3525 4100 3525 3541 
Q 3525 3141 3298 2862 
Q 3072 2584 2669 2484 
Q 3125 2378 3379 2068 
Q 3634 1759 3634 1313 
Q 3634 634 3220 271 
Q 2806 -91 2034 -91 
Q 1263 -91 848 271 
Q 434 634 434 1313 
Q 434 1759 690 2068 
Q 947 2378 1403 2484 
z
M 1172 3481 
Q 1172 3119 1398 2916 
Q 1625 2713 2034 2713 
Q 2441 2713 2670 2916 
Q 2900 3119 2900 3481 
Q 2900 3844 2670 4047 
Q 2441 4250 2034 4250 
Q 1625 4250 1398 4047 
Q 1172 3844 1172 3481 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-30"/>
       <use xlink:href="#DejaVuSans-2e" x="63.623047"/>
       <use xlink:href="#DejaVuSans-38" x="95.410156"/>
      </g>
     </g>
    </g>
    <g id="ytick_15">
     <g id="line2d_21">
      <path d="M 423.761287 35.7555 
L 429.092056 35.7555 
" clip-path="url(#pc0b721b82f)" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round"/>
     </g>
     <g id="line2d_22">
      <g>
       <use xlink:href="#m7e79fb9c6c" x="429.092056" y="35.7555" style="fill: #262626; stroke: #262626; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_31">
      <!-- 1.0 -->
      <g style="fill: #262626" transform="translate(436.092056 39.554719) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-31"/>
       <use xlink:href="#DejaVuSans-2e" x="63.623047"/>
       <use xlink:href="#DejaVuSans-30" x="95.410156"/>
      </g>
     </g>
    </g>
    <g id="text_32">
     <!-- $K(X,X)$ -->
     <g style="fill: #262626" transform="translate(462.073931 102.343192) rotate(-90) scale(0.08 -0.08)">
      <defs>
       <path id="DejaVuSans-Oblique-4b" d="M 1081 4666 
L 1716 4666 
L 1331 2700 
L 3781 4666 
L 4622 4666 
L 1850 2438 
L 3878 0 
L 3109 0 
L 1247 2272 
L 806 0 
L 172 0 
L 1081 4666 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-28" d="M 1984 4856 
Q 1566 4138 1362 3434 
Q 1159 2731 1159 2009 
Q 1159 1288 1364 580 
Q 1569 -128 1984 -844 
L 1484 -844 
Q 1016 -109 783 600 
Q 550 1309 550 2009 
Q 550 2706 781 3412 
Q 1013 4119 1484 4856 
L 1984 4856 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-Oblique-58" d="M 878 4666 
L 1516 4666 
L 2316 2981 
L 3763 4666 
L 4500 4666 
L 2578 2438 
L 3738 0 
L 3103 0 
L 2163 1966 
L 459 0 
L -275 0 
L 1906 2509 
L 878 4666 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-29" d="M 513 4856 
L 1013 4856 
Q 1481 4119 1714 3412 
Q 1947 2706 1947 2009 
Q 1947 1309 1714 600 
Q 1481 -109 1013 -844 
L 513 -844 
Q 928 -128 1133 580 
Q 1338 1288 1338 2009 
Q 1338 2731 1133 3434 
Q 928 4138 513 4856 
z
" transform="scale(0.015625)"/>
      </defs>
      <use xlink:href="#DejaVuSans-Oblique-4b" transform="translate(0 0.125)"/>
      <use xlink:href="#DejaVuSans-28" transform="translate(65.576172 0.125)"/>
      <use xlink:href="#DejaVuSans-Oblique-58" transform="translate(104.589844 0.125)"/>
      <use xlink:href="#DejaVuSans-2c" transform="translate(173.095703 0.125)"/>
      <use xlink:href="#DejaVuSans-Oblique-58" transform="translate(224.365234 0.125)"/>
      <use xlink:href="#DejaVuSans-29" transform="translate(292.871094 0.125)"/>
     </g>
    </g>
   </g>
   <image xlink:href="data:image/png;base64,
iVBORw0KGgoAAAANSUhEUgAAAAcAAACUCAYAAABfoDM+AAABGElEQVR4nMXXUY7DQAgDUEbi/ufrXZpCTzAPiWq1+UW2sWEmyal+dVye7P7capERV2BkB5DVtURac03LhiJIq6Lia8e3pyVya+VzbzayVEQtsvosNXvd0GAFDdHKPiH7lOZAKyvrbh8WaztP0r5F+9zXdrBi2jVy0ETR8d2BA3LQRJHH4b3eBGbb0txvH2wOITxsaL0JtsKL8R80Tcu95YKp2LilsnAeftIUEleYNU3LbqVppK2sGwLvFB+KgfzySDOUkGmJtKa+GEV7cNckvgknTRztPETqlJHW2dIKQ9gPW1Y8bG/C34yMa8Kp/LC32/jc7T4+3pq4MbL4G8Q/nX5AWyoK6dfVWpPd0icTGjRJu+22NM+15hcw2TvZ9lU+zwAAAABJRU5ErkJggg==" id="imagebd1fac773e" transform="scale(1 -1) translate(0 -106.56)" x="424.08" y="-35.28" width="5.04" height="106.56"/>
   <g id="LineCollection_1"/>
   <g id="patch_13">
    <path d="M 423.761287 142.370885 
L 426.426672 142.370885 
L 429.092056 142.370885 
L 429.092056 35.7555 
L 426.426672 35.7555 
L 423.761287 35.7555 
L 423.761287 142.370885 
z
" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
  </g>
 </g>
 <defs>
  <clipPath id="p9f020a32a5">
   <rect x="41.52375" y="35.7555" width="238.899083" height="106.615385"/>
  </clipPath>
  <clipPath id="p69acad6b62">
   <rect x="315.705902" y="35.7555" width="106.615385" height="106.615385"/>
  </clipPath>
  <clipPath id="pc0b721b82f">
   <rect x="423.761287" y="35.7555" width="5.330769" height="106.615385"/>
  </clipPath>
 </defs>
</svg>
"/>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="n">Σ</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[ ]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>array([[1.0000000e+00, 9.9855906e-01, 9.9425161e-01, ..., 2.9727445e-14,
        1.9430919e-14, 1.2664165e-14],
       [9.9855906e-01, 1.0000000e+00, 9.9856001e-01, ..., 4.5349351e-14,
        2.9727502e-14, 1.9430919e-14],
       [9.9425161e-01, 9.9856001e-01, 1.0000000e+00, ..., 6.8981279e-14,
        4.5349351e-14, 2.9727445e-14],
       ...,
       [2.9727445e-14, 4.5349351e-14, 6.8981279e-14, ..., 1.0000000e+00,
        9.9856001e-01, 9.9425161e-01],
       [1.9430919e-14, 2.9727502e-14, 4.5349351e-14, ..., 9.9856001e-01,
        1.0000000e+00, 9.9855906e-01],
       [1.2664165e-14, 1.9430919e-14, 2.9727445e-14, ..., 9.9425161e-01,
        9.9855906e-01, 1.0000000e+00]], dtype=float32)</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>Example code how how to draw example from data, the data x , cacluate the covariacne matrix from kernel, assume we already know the mean value.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [239]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="k">def</span> <span class="nf">kernel</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
 <span class="c1"># Squared Exponential Kernel Function for GP</span>
 <span class="n">square_distance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">a</span><span class="o">-</span><span class="n">b</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
 <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">square_distance</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [240]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="k">def</span> <span class="nf">draw_samples</span><span class="p">(</span><span class="n">mean</span><span class="p">,</span><span class="n">X</span><span class="p">,</span><span class="n">covariance</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
 <span class="c1"># SVD gives better numerical stability than Cholesky Decomp </span>
 <span class="n">num_dimensions</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
 <span class="n">z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">standard_normal</span><span class="p">((</span><span class="n">num_dimensions</span><span class="p">,</span><span class="n">num_samples</span><span class="p">))</span>
 <span class="p">[</span><span class="n">U</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">V</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">covariance</span><span class="p">)</span>
 <span class="n">A</span> <span class="o">=</span> <span class="n">U</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">S</span><span class="p">)</span>
 <span class="n">all_samples</span> <span class="o">=</span> <span class="n">mean</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">z</span><span class="p">)</span>
 <span class="k">return</span> <span class="n">all_samples</span>

<span class="n">all_samples</span> <span class="o">=</span> <span class="n">draw_samples</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="n">X</span><span class="p">,</span><span class="n">Σ</span><span class="p">,</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [241]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">all_samples</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedSVG jp-OutputArea-output" data-mime-type="image/svg+xml" tabindex="0">
<img alt="No description has been provided for this image" src="data:image/svg+xml;base64,<?xml version="1.0" encoding="utf-8" standalone="no"?>
<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN"
  "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">
<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="418.3625pt" height="197.398125pt" viewBox="0 0 418.3625 197.398125" xmlns="http://www.w3.org/2000/svg" version="1.1">
 <metadata>
  <rdf:RDF xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:cc="http://creativecommons.org/ns#" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#">
   <cc:Work>
    <dc:type rdf:resource="http://purl.org/dc/dcmitype/StillImage"/>
    <dc:date>2023-05-11T08:11:05.681194</dc:date>
    <dc:format>image/svg+xml</dc:format>
    <dc:creator>
     <cc:Agent>
      <dc:title>Matplotlib v3.7.1, https://matplotlib.org/</dc:title>
     </cc:Agent>
    </dc:creator>
   </cc:Work>
  </rdf:RDF>
 </metadata>
 <defs>
  <style type="text/css">*{stroke-linejoin: round; stroke-linecap: butt}</style>
 </defs>
 <g id="figure_1">
  <g id="patch_1">
   <path d="M 0 197.398125 
L 418.3625 197.398125 
L 418.3625 0 
L 0 0 
z
" style="fill: #ffffff"/>
  </g>
  <g id="axes_1">
   <g id="patch_2">
    <path d="M 20.5625 173.52 
L 411.1625 173.52 
L 411.1625 7.2 
L 20.5625 7.2 
z
" style="fill: #eaeaf2"/>
   </g>
   <g id="matplotlib.axis_1">
    <g id="xtick_1">
     <g id="line2d_1">
      <path d="M 38.317045 173.52 
L 38.317045 7.2 
" clip-path="url(#pa1c8d505f7)" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round"/>
     </g>
     <g id="text_1">
      <!-- −4 -->
      <g style="fill: #262626" transform="translate(30.945952 188.118438) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-2212" d="M 678 2272 
L 4684 2272 
L 4684 1741 
L 678 1741 
L 678 2272 
z
" transform="scale(0.015625)"/>
        <path id="DejaVuSans-34" d="M 2419 4116 
L 825 1625 
L 2419 1625 
L 2419 4116 
z
M 2253 4666 
L 3047 4666 
L 3047 1625 
L 3713 1625 
L 3713 1100 
L 3047 1100 
L 3047 0 
L 2419 0 
L 2419 1100 
L 313 1100 
L 313 1709 
L 2253 4666 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-2212"/>
       <use xlink:href="#DejaVuSans-34" x="83.789062"/>
      </g>
     </g>
    </g>
    <g id="xtick_2">
     <g id="line2d_2">
      <path d="M 82.703409 173.52 
L 82.703409 7.2 
" clip-path="url(#pa1c8d505f7)" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round"/>
     </g>
     <g id="text_2">
      <!-- −3 -->
      <g style="fill: #262626" transform="translate(75.332315 188.118438) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-33" d="M 2597 2516 
Q 3050 2419 3304 2112 
Q 3559 1806 3559 1356 
Q 3559 666 3084 287 
Q 2609 -91 1734 -91 
Q 1441 -91 1130 -33 
Q 819 25 488 141 
L 488 750 
Q 750 597 1062 519 
Q 1375 441 1716 441 
Q 2309 441 2620 675 
Q 2931 909 2931 1356 
Q 2931 1769 2642 2001 
Q 2353 2234 1838 2234 
L 1294 2234 
L 1294 2753 
L 1863 2753 
Q 2328 2753 2575 2939 
Q 2822 3125 2822 3475 
Q 2822 3834 2567 4026 
Q 2313 4219 1838 4219 
Q 1578 4219 1281 4162 
Q 984 4106 628 3988 
L 628 4550 
Q 988 4650 1302 4700 
Q 1616 4750 1894 4750 
Q 2613 4750 3031 4423 
Q 3450 4097 3450 3541 
Q 3450 3153 3228 2886 
Q 3006 2619 2597 2516 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-2212"/>
       <use xlink:href="#DejaVuSans-33" x="83.789062"/>
      </g>
     </g>
    </g>
    <g id="xtick_3">
     <g id="line2d_3">
      <path d="M 127.089773 173.52 
L 127.089773 7.2 
" clip-path="url(#pa1c8d505f7)" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round"/>
     </g>
     <g id="text_3">
      <!-- −2 -->
      <g style="fill: #262626" transform="translate(119.718679 188.118438) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-32" d="M 1228 531 
L 3431 531 
L 3431 0 
L 469 0 
L 469 531 
Q 828 903 1448 1529 
Q 2069 2156 2228 2338 
Q 2531 2678 2651 2914 
Q 2772 3150 2772 3378 
Q 2772 3750 2511 3984 
Q 2250 4219 1831 4219 
Q 1534 4219 1204 4116 
Q 875 4013 500 3803 
L 500 4441 
Q 881 4594 1212 4672 
Q 1544 4750 1819 4750 
Q 2544 4750 2975 4387 
Q 3406 4025 3406 3419 
Q 3406 3131 3298 2873 
Q 3191 2616 2906 2266 
Q 2828 2175 2409 1742 
Q 1991 1309 1228 531 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-2212"/>
       <use xlink:href="#DejaVuSans-32" x="83.789062"/>
      </g>
     </g>
    </g>
    <g id="xtick_4">
     <g id="line2d_4">
      <path d="M 171.476136 173.52 
L 171.476136 7.2 
" clip-path="url(#pa1c8d505f7)" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round"/>
     </g>
     <g id="text_4">
      <!-- −1 -->
      <g style="fill: #262626" transform="translate(164.105043 188.118438) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-31" d="M 794 531 
L 1825 531 
L 1825 4091 
L 703 3866 
L 703 4441 
L 1819 4666 
L 2450 4666 
L 2450 531 
L 3481 531 
L 3481 0 
L 794 0 
L 794 531 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-2212"/>
       <use xlink:href="#DejaVuSans-31" x="83.789062"/>
      </g>
     </g>
    </g>
    <g id="xtick_5">
     <g id="line2d_5">
      <path d="M 215.8625 173.52 
L 215.8625 7.2 
" clip-path="url(#pa1c8d505f7)" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round"/>
     </g>
     <g id="text_5">
      <!-- 0 -->
      <g style="fill: #262626" transform="translate(212.68125 188.118438) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-30" d="M 2034 4250 
Q 1547 4250 1301 3770 
Q 1056 3291 1056 2328 
Q 1056 1369 1301 889 
Q 1547 409 2034 409 
Q 2525 409 2770 889 
Q 3016 1369 3016 2328 
Q 3016 3291 2770 3770 
Q 2525 4250 2034 4250 
z
M 2034 4750 
Q 2819 4750 3233 4129 
Q 3647 3509 3647 2328 
Q 3647 1150 3233 529 
Q 2819 -91 2034 -91 
Q 1250 -91 836 529 
Q 422 1150 422 2328 
Q 422 3509 836 4129 
Q 1250 4750 2034 4750 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-30"/>
      </g>
     </g>
    </g>
    <g id="xtick_6">
     <g id="line2d_6">
      <path d="M 260.248864 173.52 
L 260.248864 7.2 
" clip-path="url(#pa1c8d505f7)" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round"/>
     </g>
     <g id="text_6">
      <!-- 1 -->
      <g style="fill: #262626" transform="translate(257.067614 188.118438) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-31"/>
      </g>
     </g>
    </g>
    <g id="xtick_7">
     <g id="line2d_7">
      <path d="M 304.635227 173.52 
L 304.635227 7.2 
" clip-path="url(#pa1c8d505f7)" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round"/>
     </g>
     <g id="text_7">
      <!-- 2 -->
      <g style="fill: #262626" transform="translate(301.453977 188.118438) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-32"/>
      </g>
     </g>
    </g>
    <g id="xtick_8">
     <g id="line2d_8">
      <path d="M 349.021591 173.52 
L 349.021591 7.2 
" clip-path="url(#pa1c8d505f7)" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round"/>
     </g>
     <g id="text_8">
      <!-- 3 -->
      <g style="fill: #262626" transform="translate(345.840341 188.118438) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-33"/>
      </g>
     </g>
    </g>
    <g id="xtick_9">
     <g id="line2d_9">
      <path d="M 393.407955 173.52 
L 393.407955 7.2 
" clip-path="url(#pa1c8d505f7)" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round"/>
     </g>
     <g id="text_9">
      <!-- 4 -->
      <g style="fill: #262626" transform="translate(390.226705 188.118438) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-34"/>
      </g>
     </g>
    </g>
   </g>
   <g id="matplotlib.axis_2">
    <g id="ytick_1">
     <g id="line2d_10">
      <path d="M 20.5625 142.336612 
L 411.1625 142.336612 
" clip-path="url(#pa1c8d505f7)" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round"/>
     </g>
     <g id="text_10">
      <!-- 1 -->
      <g style="fill: #262626" transform="translate(7.2 146.135831) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-31"/>
      </g>
     </g>
    </g>
    <g id="ytick_2">
     <g id="line2d_11">
      <path d="M 20.5625 103.636637 
L 411.1625 103.636637 
" clip-path="url(#pa1c8d505f7)" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round"/>
     </g>
     <g id="text_11">
      <!-- 2 -->
      <g style="fill: #262626" transform="translate(7.2 107.435856) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-32"/>
      </g>
     </g>
    </g>
    <g id="ytick_3">
     <g id="line2d_12">
      <path d="M 20.5625 64.936662 
L 411.1625 64.936662 
" clip-path="url(#pa1c8d505f7)" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round"/>
     </g>
     <g id="text_12">
      <!-- 3 -->
      <g style="fill: #262626" transform="translate(7.2 68.735881) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-33"/>
      </g>
     </g>
    </g>
    <g id="ytick_4">
     <g id="line2d_13">
      <path d="M 20.5625 26.236687 
L 411.1625 26.236687 
" clip-path="url(#pa1c8d505f7)" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round"/>
     </g>
     <g id="text_13">
      <!-- 4 -->
      <g style="fill: #262626" transform="translate(7.2 30.035905) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-34"/>
      </g>
     </g>
    </g>
   </g>
   <g id="line2d_14">
    <path d="M 38.317045 122.95767 
L 40.700206 120.410797 
L 43.083366 118.063026 
L 45.466527 115.97851 
L 47.849687 114.127102 
L 50.232848 112.502132 
L 52.616008 111.16521 
L 54.999169 110.22477 
L 57.382329 109.541815 
L 59.76549 109.073327 
L 62.14865 109.092149 
L 64.531811 109.389324 
L 66.914971 109.978991 
L 69.298131 110.781078 
L 71.681292 111.956815 
L 74.064452 113.295258 
L 76.447613 114.921337 
L 78.830773 116.681983 
L 81.213934 118.658893 
L 88.363415 125.232055 
L 97.896057 134.276187 
L 102.662378 138.219325 
L 105.045538 140.05294 
L 109.811859 143.104311 
L 112.19502 144.208783 
L 114.57818 145.164117 
L 116.961341 145.807471 
L 119.344501 146.218228 
L 121.727662 146.290754 
L 124.110822 146.039196 
L 126.493983 145.519565 
L 128.877143 144.621762 
L 131.260304 143.57702 
L 133.643464 142.09952 
L 136.026624 140.387387 
L 138.409785 138.450754 
L 140.792945 136.165578 
L 143.176106 133.718311 
L 147.942427 128.218834 
L 152.708748 122.192934 
L 164.62455 106.783403 
L 167.00771 103.931442 
L 169.390871 101.297625 
L 171.774031 98.8597 
L 174.157192 96.685914 
L 176.540352 94.811653 
L 178.923513 93.235797 
L 181.306673 91.960168 
L 183.689834 91.124513 
L 186.072994 90.650936 
L 188.456155 90.578726 
L 190.839315 90.900079 
L 193.222476 91.571797 
L 195.605636 92.665679 
L 197.988797 94.156894 
L 200.371957 96.000811 
L 202.755117 98.188714 
L 205.138278 100.693832 
L 207.521438 103.434018 
L 209.904599 106.43276 
L 214.67092 113.054752 
L 228.969883 133.67589 
L 231.353043 136.723812 
L 233.736203 139.510245 
L 236.119364 141.966874 
L 238.502524 144.180496 
L 240.885685 146.009369 
L 243.268845 147.44001 
L 245.652006 148.493729 
L 248.035166 149.096937 
L 250.418327 149.342181 
L 252.801487 149.144447 
L 255.184648 148.541129 
L 257.567808 147.489003 
L 259.950969 146.054594 
L 262.334129 144.304947 
L 264.71729 142.213572 
L 267.10045 139.755441 
L 269.48361 137.053844 
L 274.249931 131.018447 
L 281.399413 120.862702 
L 288.548894 110.257893 
L 293.315215 103.579449 
L 298.081536 97.455848 
L 302.847857 91.983317 
L 305.231017 89.609642 
L 307.614178 87.506776 
L 309.997338 85.557897 
L 314.763659 82.477757 
L 317.14682 81.331218 
L 319.52998 80.550883 
L 321.913141 79.951317 
L 324.296301 79.607658 
L 326.679462 79.605451 
L 329.062622 79.766258 
L 331.445782 80.255838 
L 333.828943 80.962693 
L 336.212103 81.950696 
L 338.595264 83.25 
L 340.978424 84.77988 
L 343.361585 86.532078 
L 345.744745 88.576248 
L 348.127906 90.886833 
L 350.511066 93.370989 
L 352.894227 96.150446 
L 355.277387 99.102235 
L 357.660548 102.307004 
L 362.426869 109.281298 
L 364.810029 112.890246 
L 381.492152 139.91412 
L 383.875313 143.377853 
L 388.641634 149.72597 
L 391.024794 152.299373 
L 393.407955 154.701818 
L 393.407955 154.701818 
" clip-path="url(#pa1c8d505f7)" style="fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: round"/>
   </g>
   <g id="line2d_15">
    <path d="M 38.317045 149.492873 
L 40.700206 149.669852 
L 43.083366 149.698395 
L 45.466527 149.566402 
L 47.849687 149.287587 
L 52.616008 148.117242 
L 54.999169 147.387789 
L 64.531811 142.514631 
L 66.914971 141.070279 
L 69.298131 139.771254 
L 74.064452 136.803432 
L 78.830773 134.345013 
L 83.597094 132.239946 
L 85.980255 131.46626 
L 88.363415 130.89024 
L 90.746576 130.433998 
L 93.129736 130.183076 
L 97.896057 130.278651 
L 102.662378 131.291472 
L 105.045538 131.936608 
L 109.811859 133.758457 
L 116.961341 136.975068 
L 126.493983 140.74617 
L 128.877143 141.437399 
L 131.260304 141.947364 
L 133.643464 142.300061 
L 136.026624 142.318926 
L 138.409785 142.162427 
L 140.792945 141.699039 
L 143.176106 140.993806 
L 145.559266 139.892411 
L 147.942427 138.664919 
L 150.325587 137.021407 
L 152.708748 135.10208 
L 155.091908 132.860272 
L 159.858229 127.584043 
L 162.24139 124.520385 
L 164.62455 121.209888 
L 169.390871 113.838542 
L 174.157192 105.741604 
L 178.923513 97.098365 
L 186.072994 83.427156 
L 195.605636 65.02657 
L 200.371957 56.284029 
L 205.138278 48.011938 
L 207.521438 44.078813 
L 209.904599 40.370002 
L 212.287759 36.872017 
L 214.67092 33.577677 
L 217.05408 30.502608 
L 219.437241 27.734425 
L 221.820401 25.170154 
L 224.203562 22.893206 
L 226.586722 20.881058 
L 228.969883 19.163952 
L 231.353043 17.727697 
L 233.736203 16.588726 
L 236.119364 15.714985 
L 238.502524 15.133789 
L 240.885685 14.841305 
L 243.268845 14.76 
L 245.652006 14.920676 
L 248.035166 15.336046 
L 250.418327 16.006244 
L 252.801487 16.869661 
L 255.184648 17.881099 
L 257.567808 19.06416 
L 262.334129 21.89483 
L 267.10045 25.153532 
L 274.249931 30.755846 
L 281.399413 36.776817 
L 290.932055 45.369154 
L 300.464696 54.534085 
L 305.231017 59.327359 
L 312.380499 66.964005 
L 319.52998 74.866793 
L 329.062622 85.83142 
L 331.445782 88.636913 
L 343.361585 101.675167 
L 345.744745 103.967805 
L 348.127906 106.458152 
L 352.894227 110.652981 
L 355.277387 112.66644 
L 360.043708 116.345523 
L 362.426869 117.997793 
L 367.193189 120.825097 
L 371.95951 122.986909 
L 374.342671 123.921544 
L 379.108992 125.367496 
L 383.875313 126.397246 
L 391.024794 127.178217 
L 393.407955 127.241501 
L 393.407955 127.241501 
" clip-path="url(#pa1c8d505f7)" style="fill: none; stroke: #ff7f0e; stroke-width: 1.5; stroke-linecap: round"/>
   </g>
   <g id="line2d_16">
    <path d="M 38.317045 64.032554 
L 40.700206 61.636384 
L 43.083366 58.978805 
L 45.466527 56.511572 
L 47.849687 53.876721 
L 54.999169 46.680403 
L 57.382329 44.523327 
L 59.76549 42.552456 
L 62.14865 40.736292 
L 64.531811 39.155071 
L 66.914971 37.786841 
L 69.298131 36.607977 
L 71.681292 35.764723 
L 74.064452 35.1335 
L 76.447613 34.681178 
L 78.830773 34.449975 
L 81.213934 34.484143 
L 85.980255 35.053574 
L 90.746576 36.158566 
L 95.512897 37.800977 
L 97.896057 38.481472 
L 100.279218 39.46392 
L 109.811859 42.617412 
L 114.57818 43.865244 
L 119.344501 44.812057 
L 126.493983 45.773329 
L 128.877143 46.006474 
L 131.260304 46.113475 
L 136.026624 46.650585 
L 138.409785 46.887846 
L 143.176106 47.672504 
L 147.942427 48.752887 
L 152.708748 50.343991 
L 155.091908 51.353013 
L 157.475069 52.506987 
L 159.858229 53.827672 
L 164.62455 56.837159 
L 169.390871 60.462385 
L 174.157192 64.586884 
L 178.923513 69.11542 
L 186.072994 76.449565 
L 202.755117 94.205141 
L 207.521438 98.852497 
L 209.904599 101.016339 
L 212.287759 103.027149 
L 214.67092 104.862289 
L 217.05408 106.545636 
L 219.437241 107.98098 
L 221.820401 109.179212 
L 224.203562 110.154378 
L 226.586722 110.798301 
L 228.969883 111.205965 
L 231.353043 111.250467 
L 233.736203 110.964572 
L 236.119364 110.360905 
L 238.502524 109.44118 
L 240.885685 108.224015 
L 243.268845 106.664308 
L 245.652006 104.791331 
L 248.035166 102.689765 
L 250.418327 100.324906 
L 255.184648 95.04158 
L 259.950969 89.284421 
L 269.48361 77.742588 
L 271.866771 75.124622 
L 276.633092 70.483498 
L 279.016252 68.53345 
L 281.399413 66.869254 
L 283.782573 65.437441 
L 286.165734 64.244704 
L 288.548894 63.435996 
L 290.932055 62.83258 
L 293.315215 62.521383 
L 295.698376 62.503661 
L 298.081536 62.772328 
L 300.464696 63.19411 
L 305.231017 64.701055 
L 309.997338 66.887811 
L 314.763659 69.414947 
L 329.062622 77.498071 
L 331.445782 78.764139 
L 338.595264 81.97844 
L 340.978424 82.906469 
L 360.043708 89.166598 
L 364.810029 91.201436 
L 369.57635 93.664317 
L 371.95951 95.090615 
L 374.342671 96.772396 
L 379.108992 100.570768 
L 383.875313 105.12101 
L 388.641634 110.317954 
L 393.407955 116.037242 
L 393.407955 116.037242 
" clip-path="url(#pa1c8d505f7)" style="fill: none; stroke: #2ca02c; stroke-width: 1.5; stroke-linecap: round"/>
   </g>
   <g id="line2d_17">
    <path d="M 38.317045 139.267973 
L 40.700206 137.783943 
L 45.466527 135.336571 
L 50.232848 133.453718 
L 52.616008 132.763336 
L 54.999169 132.209693 
L 59.76549 131.652807 
L 64.531811 131.539764 
L 69.298131 131.973432 
L 74.064452 132.865147 
L 81.213934 134.59613 
L 85.980255 136.220925 
L 95.512897 140.174681 
L 100.279218 142.54767 
L 105.045538 144.954505 
L 112.19502 148.665902 
L 119.344501 152.184627 
L 124.110822 154.012092 
L 126.493983 154.804273 
L 131.260304 155.877739 
L 133.643464 156.177967 
L 138.409785 156.213239 
L 140.792945 155.947353 
L 145.559266 155.053677 
L 147.942427 154.287997 
L 152.708748 152.508463 
L 157.475069 150.354149 
L 171.774031 142.8084 
L 188.456155 133.413216 
L 193.222476 130.319259 
L 197.988797 126.782222 
L 202.755117 122.831712 
L 207.521438 118.391309 
L 212.287759 113.54952 
L 219.437241 105.727545 
L 226.586722 97.776016 
L 231.353043 92.852376 
L 236.119364 88.381441 
L 238.502524 86.390808 
L 240.885685 84.610642 
L 243.268845 83.036091 
L 245.652006 81.667806 
L 248.035166 80.542082 
L 250.418327 79.646125 
L 252.801487 79.036078 
L 255.184648 78.572962 
L 257.567808 78.409639 
L 259.950969 78.420294 
L 262.334129 78.678485 
L 264.71729 79.091067 
L 267.10045 79.643386 
L 271.866771 81.314768 
L 276.633092 83.350052 
L 288.548894 88.555633 
L 290.932055 89.448546 
L 293.315215 90.092168 
L 298.081536 91.077928 
L 300.464696 91.318386 
L 302.847857 91.347509 
L 305.231017 91.130606 
L 309.997338 90.314518 
L 312.380499 89.558592 
L 317.14682 87.691555 
L 321.913141 85.293781 
L 331.445782 80.057125 
L 333.828943 78.822402 
L 338.595264 76.711817 
L 340.978424 76.216353 
L 343.361585 75.5153 
L 345.744745 75.235598 
L 348.127906 75.184996 
L 350.511066 75.509043 
L 355.277387 76.783722 
L 357.660548 77.807149 
L 360.043708 79.013167 
L 364.810029 82.152258 
L 369.57635 85.822862 
L 374.342671 89.843384 
L 381.492152 95.417722 
L 386.258473 98.383049 
L 388.641634 99.535591 
L 391.024794 100.39622 
L 393.407955 100.951117 
L 393.407955 100.951117 
" clip-path="url(#pa1c8d505f7)" style="fill: none; stroke: #d62728; stroke-width: 1.5; stroke-linecap: round"/>
   </g>
   <g id="line2d_18">
    <path d="M 38.317045 19.359084 
L 40.700206 19.05288 
L 43.083366 19.43485 
L 45.466527 20.412677 
L 47.849687 22.019477 
L 50.232848 24.251672 
L 52.616008 27.024059 
L 54.999169 30.160401 
L 57.382329 33.771615 
L 62.14865 42.239303 
L 64.531811 46.97191 
L 69.298131 57.174987 
L 76.447613 73.359718 
L 81.213934 84.400067 
L 90.746576 105.275411 
L 95.512897 114.815426 
L 100.279218 123.69881 
L 105.045538 131.630022 
L 109.811859 138.539963 
L 112.19502 141.683586 
L 114.57818 144.626562 
L 119.344501 149.698989 
L 121.727662 151.85844 
L 124.110822 153.856659 
L 126.493983 155.570645 
L 128.877143 156.921159 
L 131.260304 158.092522 
L 133.643464 159.071161 
L 136.026624 159.772371 
L 138.409785 160.191794 
L 140.792945 160.339203 
L 143.176106 160.305476 
L 145.559266 160.075852 
L 147.942427 159.587396 
L 150.325587 158.871872 
L 152.708748 157.941649 
L 155.091908 156.840852 
L 159.858229 154.207868 
L 164.62455 151.002553 
L 169.390871 147.490837 
L 181.306673 138.230266 
L 186.072994 134.686423 
L 190.839315 131.304273 
L 197.988797 126.612287 
L 217.05408 114.866053 
L 224.203562 110.230982 
L 238.502524 100.73992 
L 243.268845 97.80096 
L 245.652006 96.418322 
L 250.418327 93.986058 
L 252.801487 92.892577 
L 255.184648 91.934894 
L 257.567808 91.104927 
L 262.334129 89.854837 
L 264.71729 89.41102 
L 267.10045 89.131493 
L 271.866771 89.053521 
L 276.633092 89.585934 
L 279.016252 90.026186 
L 283.782573 91.504446 
L 286.165734 92.391701 
L 290.932055 94.60665 
L 295.698376 97.317807 
L 300.464696 100.379157 
L 319.52998 113.88631 
L 326.679462 117.963577 
L 329.062622 119.169143 
L 331.445782 120.156771 
L 336.212103 121.736727 
L 338.595264 122.307881 
L 343.361585 122.982342 
L 348.127906 123.139779 
L 352.894227 122.940465 
L 360.043708 122.099035 
L 381.492152 118.659754 
L 393.407955 116.527417 
L 393.407955 116.527417 
" clip-path="url(#pa1c8d505f7)" style="fill: none; stroke: #9467bd; stroke-width: 1.5; stroke-linecap: round"/>
   </g>
   <g id="line2d_19">
    <path d="M 38.317045 26.002019 
L 45.466527 27.4294 
L 47.849687 28.016152 
L 54.999169 30.226339 
L 59.76549 32.398585 
L 62.14865 33.507654 
L 64.531811 34.807174 
L 71.681292 39.474114 
L 74.064452 41.212367 
L 81.213934 46.77487 
L 88.363415 52.079122 
L 90.746576 53.658088 
L 93.129736 55.05953 
L 95.512897 56.275742 
L 100.279218 58.220176 
L 102.662378 58.800367 
L 105.045538 59.103202 
L 107.428699 59.210822 
L 109.811859 59.079519 
L 112.19502 58.659249 
L 114.57818 58.01476 
L 116.961341 57.170852 
L 119.344501 56.150832 
L 124.110822 53.489611 
L 128.877143 50.318748 
L 136.026624 45.164086 
L 140.792945 41.680549 
L 145.559266 38.549047 
L 150.325587 35.901252 
L 152.708748 34.811807 
L 155.091908 33.870594 
L 157.475069 33.133537 
L 159.858229 32.567777 
L 162.24139 32.215652 
L 164.62455 32.082083 
L 167.00771 32.082123 
L 169.390871 32.322992 
L 171.774031 32.765633 
L 174.157192 33.402408 
L 178.923513 35.271228 
L 183.689834 37.796934 
L 186.072994 39.316655 
L 190.839315 42.736894 
L 195.605636 46.534241 
L 202.755117 52.668496 
L 209.904599 59.019045 
L 214.67092 63.095696 
L 219.437241 66.961392 
L 224.203562 70.493289 
L 228.969883 73.697776 
L 233.736203 76.39109 
L 236.119364 77.639024 
L 240.885685 79.665956 
L 243.268845 80.56767 
L 248.035166 81.987545 
L 252.801487 82.992426 
L 257.567808 83.769193 
L 264.71729 84.448055 
L 271.866771 84.862428 
L 279.016252 85.441786 
L 283.782573 86.076088 
L 290.932055 87.577193 
L 295.698376 88.828818 
L 307.614178 93.045232 
L 317.14682 96.396497 
L 321.913141 97.700243 
L 326.679462 98.596856 
L 329.062622 98.916634 
L 331.445782 98.998752 
L 336.212103 98.784054 
L 340.978424 98.06552 
L 343.361585 97.490586 
L 348.127906 95.843585 
L 355.277387 92.560291 
L 362.426869 88.464512 
L 376.725831 79.407899 
L 381.492152 76.34719 
L 383.875313 74.820045 
L 386.258473 73.494244 
L 391.024794 70.634205 
L 393.407955 69.367403 
L 393.407955 69.367403 
" clip-path="url(#pa1c8d505f7)" style="fill: none; stroke: #8c564b; stroke-width: 1.5; stroke-linecap: round"/>
   </g>
   <g id="line2d_20">
    <path d="M 38.317045 132.030192 
L 40.700206 132.205322 
L 50.232848 132.287566 
L 52.616008 132.206876 
L 54.999169 131.987372 
L 57.382329 132.037363 
L 71.681292 131.201753 
L 74.064452 131.197676 
L 76.447613 131.071068 
L 78.830773 131.131214 
L 81.213934 130.986279 
L 90.746576 131.482767 
L 105.045538 132.918251 
L 112.19502 133.340859 
L 116.961341 133.285076 
L 119.344501 133.097818 
L 121.727662 132.787521 
L 124.110822 132.31306 
L 126.493983 131.697303 
L 131.260304 130.039648 
L 133.643464 128.931119 
L 138.409785 126.282123 
L 140.792945 124.76284 
L 145.559266 121.313856 
L 150.325587 117.445167 
L 167.00771 103.349522 
L 169.390871 101.562508 
L 174.157192 98.441117 
L 176.540352 97.210874 
L 181.306673 95.19092 
L 183.689834 94.567644 
L 186.072994 94.122777 
L 188.456155 93.915696 
L 190.839315 93.930674 
L 193.222476 94.166737 
L 195.605636 94.634653 
L 197.988797 95.315854 
L 202.755117 97.212757 
L 205.138278 98.389197 
L 209.904599 101.098632 
L 221.820401 108.587748 
L 226.586722 111.207866 
L 228.969883 112.343657 
L 231.353043 113.326576 
L 233.736203 114.152033 
L 236.119364 114.843123 
L 238.502524 115.322848 
L 240.885685 115.632784 
L 243.268845 115.766034 
L 248.035166 115.592488 
L 250.418327 115.273764 
L 255.184648 114.296266 
L 274.249931 109.236397 
L 276.633092 108.708066 
L 281.399413 108.031749 
L 286.165734 107.573268 
L 293.315215 107.037662 
L 298.081536 106.609575 
L 300.464696 106.381386 
L 302.847857 106.01436 
L 307.614178 104.917499 
L 309.997338 104.189846 
L 312.380499 103.315768 
L 317.14682 101.180694 
L 319.52998 99.846581 
L 324.296301 96.662119 
L 329.062622 93.051119 
L 333.828943 89.222102 
L 343.361585 81.196738 
L 345.744745 79.320522 
L 350.511066 75.850964 
L 352.894227 74.320262 
L 357.660548 71.827413 
L 362.426869 69.846546 
L 367.193189 68.810587 
L 369.57635 68.581574 
L 371.95951 68.196639 
L 379.108992 68.230855 
L 381.492152 68.626438 
L 391.024794 69.319703 
L 393.407955 69.306098 
L 393.407955 69.306098 
" clip-path="url(#pa1c8d505f7)" style="fill: none; stroke: #e377c2; stroke-width: 1.5; stroke-linecap: round"/>
   </g>
   <g id="line2d_21">
    <path d="M 38.317045 141.355779 
L 43.083366 144.988725 
L 47.849687 148.284362 
L 50.232848 149.685313 
L 52.616008 150.916895 
L 54.999169 151.942986 
L 57.382329 152.798582 
L 59.76549 153.333861 
L 62.14865 153.679222 
L 64.531811 153.651633 
L 66.914971 153.452846 
L 69.298131 152.911753 
L 71.681292 152.181512 
L 74.064452 151.188847 
L 76.447613 150.039614 
L 81.213934 147.094571 
L 85.980255 143.747808 
L 88.363415 141.976521 
L 95.512897 137.094442 
L 100.279218 134.410498 
L 102.662378 133.330856 
L 105.045538 132.496683 
L 107.428699 131.800016 
L 109.811859 131.484712 
L 112.19502 131.343453 
L 114.57818 131.474875 
L 116.961341 131.730691 
L 119.344501 132.260787 
L 121.727662 132.982435 
L 126.493983 134.831513 
L 128.877143 135.83458 
L 133.643464 138.112757 
L 138.409785 140.177732 
L 140.792945 141.074663 
L 145.559266 142.387327 
L 147.942427 142.692139 
L 150.325587 142.761926 
L 152.708748 142.706845 
L 155.091908 142.296079 
L 157.475069 141.615713 
L 159.858229 140.58875 
L 162.24139 139.385306 
L 164.62455 137.778122 
L 167.00771 135.942178 
L 169.390871 133.778695 
L 171.774031 131.330256 
L 174.157192 128.661623 
L 176.540352 125.769068 
L 181.306673 119.209657 
L 183.689834 115.665357 
L 188.456155 107.982788 
L 193.222476 99.740368 
L 197.988797 91.189619 
L 209.904599 69.290419 
L 214.67092 60.887304 
L 219.437241 52.92512 
L 224.203562 45.659177 
L 226.586722 42.336637 
L 228.969883 39.24949 
L 231.353043 36.396508 
L 233.736203 33.816106 
L 236.119364 31.508712 
L 238.502524 29.445002 
L 240.885685 27.737034 
L 243.268845 26.291309 
L 245.652006 25.152871 
L 248.035166 24.323384 
L 250.418327 23.829384 
L 252.801487 23.652796 
L 255.184648 23.727027 
L 257.567808 24.108436 
L 259.950969 24.79125 
L 262.334129 25.733276 
L 264.71729 26.927879 
L 267.10045 28.466127 
L 269.48361 30.218489 
L 271.866771 32.172694 
L 274.249931 34.363458 
L 276.633092 36.807572 
L 279.016252 39.446104 
L 283.782573 45.253277 
L 288.548894 51.83732 
L 293.315215 58.91891 
L 295.698376 62.588243 
L 305.231017 78.413745 
L 317.14682 98.35884 
L 321.913141 105.783571 
L 324.296301 109.330458 
L 329.062622 115.744913 
L 331.445782 118.548595 
L 333.828943 121.153013 
L 336.212103 123.474409 
L 340.978424 127.283969 
L 343.361585 128.578506 
L 345.744745 129.701581 
L 348.127906 130.328428 
L 350.511066 130.526357 
L 352.894227 130.573912 
L 355.277387 130.260333 
L 357.660548 129.599167 
L 360.043708 128.50908 
L 362.426869 127.193052 
L 364.810029 125.599548 
L 367.193189 123.801853 
L 369.57635 121.763489 
L 376.725831 114.63425 
L 383.875313 106.586046 
L 393.407955 95.853432 
L 393.407955 95.853432 
" clip-path="url(#pa1c8d505f7)" style="fill: none; stroke: #7f7f7f; stroke-width: 1.5; stroke-linecap: round"/>
   </g>
   <g id="line2d_22">
    <path d="M 38.317045 114.825461 
L 47.849687 107.153652 
L 52.616008 103.251565 
L 57.382329 99.583905 
L 59.76549 97.626814 
L 62.14865 95.948064 
L 71.681292 88.584186 
L 83.597094 79.546572 
L 97.896057 69.166174 
L 102.662378 65.989624 
L 105.045538 64.446133 
L 112.19502 60.505884 
L 114.57818 59.304146 
L 121.727662 56.819159 
L 124.110822 56.226648 
L 126.493983 55.815609 
L 128.877143 55.597914 
L 131.260304 55.599497 
L 133.643464 55.849769 
L 136.026624 56.300404 
L 138.409785 57.070616 
L 140.792945 58.141896 
L 143.176106 59.465614 
L 145.559266 61.080968 
L 147.942427 62.919378 
L 150.325587 65.167877 
L 152.708748 67.674032 
L 155.091908 70.378575 
L 159.858229 76.702293 
L 164.62455 83.876278 
L 169.390871 91.635512 
L 183.689834 115.569005 
L 186.072994 119.216734 
L 188.456155 122.653524 
L 190.839315 125.85701 
L 193.222476 128.800769 
L 195.605636 131.433097 
L 197.988797 133.783775 
L 200.371957 135.802475 
L 202.755117 137.407216 
L 205.138278 138.692055 
L 207.521438 139.650103 
L 209.904599 140.205851 
L 212.287759 140.466079 
L 214.67092 140.336901 
L 217.05408 139.913511 
L 219.437241 139.183695 
L 221.820401 138.151356 
L 224.203562 136.883537 
L 226.586722 135.33892 
L 228.969883 133.595174 
L 233.736203 129.639868 
L 238.502524 125.243414 
L 250.418327 113.964349 
L 255.184648 109.932209 
L 257.567808 108.09262 
L 262.334129 104.900973 
L 264.71729 103.50873 
L 269.48361 101.1939 
L 271.866771 100.260115 
L 274.249931 99.475836 
L 279.016252 98.344222 
L 281.399413 97.900979 
L 286.165734 97.34737 
L 290.932055 97.043441 
L 295.698376 96.986277 
L 300.464696 97.05763 
L 302.847857 97.176899 
L 309.997338 97.961152 
L 314.763659 99.01015 
L 317.14682 99.69532 
L 319.52998 100.540454 
L 321.913141 101.515587 
L 326.679462 103.949136 
L 331.445782 107.044524 
L 333.828943 108.839696 
L 338.595264 112.74471 
L 350.511066 123.419842 
L 352.894227 125.324198 
L 357.660548 128.699427 
L 360.043708 129.908029 
L 362.426869 130.914682 
L 364.810029 131.573395 
L 367.193189 131.851345 
L 369.57635 131.709433 
L 371.95951 131.253782 
L 374.342671 130.365045 
L 376.725831 129.042592 
L 379.108992 127.344098 
L 381.492152 125.279847 
L 383.875313 122.809216 
L 388.641634 116.843287 
L 391.024794 113.578392 
L 393.407955 110.011682 
L 393.407955 110.011682 
" clip-path="url(#pa1c8d505f7)" style="fill: none; stroke: #bcbd22; stroke-width: 1.5; stroke-linecap: round"/>
   </g>
   <g id="line2d_23">
    <path d="M 38.317045 123.729345 
L 40.700206 126.818834 
L 52.616008 143.362302 
L 59.76549 152.528148 
L 62.14865 155.258433 
L 66.914971 159.961607 
L 69.298131 161.892441 
L 71.681292 163.494708 
L 74.064452 164.622937 
L 76.447613 165.47964 
L 78.830773 165.96 
L 81.213934 165.925222 
L 83.597094 165.553679 
L 85.980255 164.61656 
L 88.363415 163.49655 
L 90.746576 161.820079 
L 95.512897 157.487907 
L 97.896057 154.66206 
L 100.279218 151.649997 
L 102.662378 148.288977 
L 105.045538 144.703391 
L 109.811859 136.779451 
L 114.57818 128.168012 
L 121.727662 114.386036 
L 131.260304 95.4034 
L 136.026624 86.280089 
L 140.792945 77.55883 
L 145.559266 69.553003 
L 147.942427 65.897012 
L 150.325587 62.546486 
L 152.708748 59.485803 
L 155.091908 56.733177 
L 157.475069 54.365995 
L 159.858229 52.317551 
L 162.24139 50.704155 
L 164.62455 49.490084 
L 167.00771 48.652362 
L 169.390871 48.22533 
L 171.774031 48.228551 
L 174.157192 48.646076 
L 176.540352 49.38471 
L 178.923513 50.524616 
L 181.306673 51.988095 
L 183.689834 53.689446 
L 188.456155 57.775003 
L 193.222476 62.511634 
L 200.371957 69.665559 
L 202.755117 71.865192 
L 205.138278 73.90294 
L 207.521438 75.684518 
L 209.904599 77.202104 
L 212.287759 78.434469 
L 214.67092 79.387632 
L 217.05408 79.969647 
L 219.437241 80.168806 
L 221.820401 79.984465 
L 224.203562 79.467338 
L 226.586722 78.515113 
L 228.969883 77.283094 
L 231.353043 75.68893 
L 233.736203 73.773191 
L 236.119364 71.571624 
L 238.502524 69.122307 
L 240.885685 66.469593 
L 245.652006 60.705216 
L 257.567808 45.728261 
L 262.334129 40.505954 
L 264.71729 38.19341 
L 267.10045 36.200713 
L 269.48361 34.440244 
L 271.866771 33.023733 
L 274.249931 31.959197 
L 276.633092 31.218404 
L 279.016252 30.82298 
L 281.399413 30.756813 
L 283.782573 31.183635 
L 286.165734 31.901147 
L 288.548894 33.049809 
L 290.932055 34.515828 
L 293.315215 36.346302 
L 295.698376 38.448678 
L 298.081536 40.828414 
L 300.464696 43.54006 
L 302.847857 46.507635 
L 305.231017 49.672325 
L 307.614178 53.026485 
L 312.380499 60.213183 
L 319.52998 71.924729 
L 329.062622 87.697816 
L 333.828943 95.229681 
L 338.595264 102.308682 
L 340.978424 105.642399 
L 343.361585 108.708054 
L 348.127906 114.334649 
L 350.511066 116.802079 
L 352.894227 119.070221 
L 355.277387 120.951207 
L 357.660548 122.53777 
L 360.043708 123.861187 
L 362.426869 124.858611 
L 364.810029 125.464 
L 367.193189 125.6472 
L 369.57635 125.681541 
L 371.95951 125.228951 
L 374.342671 124.397187 
L 376.725831 123.173009 
L 379.108992 121.641606 
L 381.492152 119.739757 
L 383.875313 117.443883 
L 386.258473 114.841916 
L 388.641634 111.969993 
L 391.024794 108.768758 
L 393.407955 105.248082 
L 393.407955 105.248082 
" clip-path="url(#pa1c8d505f7)" style="fill: none; stroke: #17becf; stroke-width: 1.5; stroke-linecap: round"/>
   </g>
   <g id="patch_3">
    <path d="M 20.5625 173.52 
L 20.5625 7.2 
" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="patch_4">
    <path d="M 411.1625 173.52 
L 411.1625 7.2 
" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="patch_5">
    <path d="M 20.5625 173.52 
L 411.1625 173.52 
" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="patch_6">
    <path d="M 20.5625 7.2 
L 411.1625 7.2 
" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
  </g>
 </g>
 <defs>
  <clipPath id="pa1c8d505f7">
   <rect x="20.5625" y="7.2" width="390.6" height="166.32"/>
  </clipPath>
 </defs>
</svg>
"/>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p><strong>Here we only sample the random varibale from the prior, so you will see each sample will have the 0 mean and defined variance</strong></p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>Example 1, Noise data</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [242]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="k">def</span> <span class="nf">kernel</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">l2</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
  <span class="n">sqdist</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> \
  	             <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mf">.5</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">l2</span><span class="p">)</span> <span class="o">*</span> <span class="n">sqdist</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">kernel_advance</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="p">,</span> <span class="n">l</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">sigma_f</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">''' Isotropic squared exponential kernel. Computes a covariance matrix from points in X1 and X2. Args: X1: Array of m points (m x d). X2: Array of n points (n x d). Returns: Covariance matrix (m x n). '''</span>
    <span class="n">sqdist</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">X1</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">X2</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">sigma_f</span><span class="o">**</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mf">0.5</span> <span class="o">/</span> <span class="n">l</span><span class="o">**</span><span class="mi">2</span> <span class="o">*</span> <span class="n">sqdist</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [246]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="k">def</span> <span class="nf">generate_noisy_points</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">noise_variance</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">):</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">777</span><span class="p">)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mf">3.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">noise_variance</span><span class="o">**</span><span class="mf">0.5</span>
    <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span>

<span class="kn">import</span> <span class="nn">matplotlib.pylab</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">noise_var</span> <span class="o">=</span> <span class="mf">1e-6</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">generate_noisy_points</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="n">noise_variance</span><span class="o">=</span><span class="n">noise_var</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="s1">'x'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">Xtest</span><span class="p">,</span> <span class="n">ytest</span> <span class="o">=</span> <span class="n">generate_noisy_points</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span><span class="n">noise_variance</span><span class="o">=</span><span class="n">noise_var</span><span class="p">)</span>
<span class="n">Xtest</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">n_samples</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">Xtest</span><span class="p">)</span>
<span class="n">K_ss</span> <span class="o">=</span> <span class="n">kernel</span><span class="p">(</span><span class="n">Xtest</span><span class="p">,</span><span class="n">Xtest</span><span class="p">)</span>
<span class="c1">#L_ss = np.linalg.cholesky(K_ss)    #it could not be solved if becuase the K_ss is not positive matrix</span>
<span class="n">L_ss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cholesky</span><span class="p">(</span><span class="n">K_ss</span> <span class="o">+</span> <span class="mf">1e-6</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">n</span><span class="p">))</span> <span class="c1"># has to add some small noise value</span>
<span class="n">f_prior</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">L_ss</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">)))</span>  <span class="c1">#draw samples</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">Xtest</span><span class="p">,</span> <span class="n">f_prior</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedSVG jp-OutputArea-output" data-mime-type="image/svg+xml" tabindex="0">
<img alt="No description has been provided for this image" src="data:image/svg+xml;base64,<?xml version="1.0" encoding="utf-8" standalone="no"?>
<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN"
  "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">
<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="409.165312pt" height="297.190125pt" viewBox="0 0 409.165312 297.190125" xmlns="http://www.w3.org/2000/svg" version="1.1">
 <metadata>
  <rdf:RDF xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:cc="http://creativecommons.org/ns#" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#">
   <cc:Work>
    <dc:type rdf:resource="http://purl.org/dc/dcmitype/StillImage"/>
    <dc:date>2023-05-11T08:16:53.464621</dc:date>
    <dc:format>image/svg+xml</dc:format>
    <dc:creator>
     <cc:Agent>
      <dc:title>Matplotlib v3.7.1, https://matplotlib.org/</dc:title>
     </cc:Agent>
    </dc:creator>
   </cc:Work>
  </rdf:RDF>
 </metadata>
 <defs>
  <style type="text/css">*{stroke-linejoin: round; stroke-linecap: butt}</style>
 </defs>
 <g id="figure_1">
  <g id="patch_1">
   <path d="M 0 297.190125 
L 409.165312 297.190125 
L 409.165312 0 
L 0 0 
z
" style="fill: #ffffff"/>
  </g>
  <g id="axes_1">
   <g id="patch_2">
    <path d="M 44.845313 273.312 
L 401.965312 273.312 
L 401.965312 7.2 
L 44.845313 7.2 
z
" style="fill: #eaeaf2"/>
   </g>
   <g id="matplotlib.axis_1">
    <g id="xtick_1">
     <g id="line2d_1">
      <path d="M 100.349985 273.312 
L 100.349985 7.2 
" clip-path="url(#p309b19a4dc)" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round"/>
     </g>
     <g id="text_1">
      <!-- −2 -->
      <g style="fill: #262626" transform="translate(92.978892 287.910437) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-2212" d="M 678 2272 
L 4684 2272 
L 4684 1741 
L 678 1741 
L 678 2272 
z
" transform="scale(0.015625)"/>
        <path id="DejaVuSans-32" d="M 1228 531 
L 3431 531 
L 3431 0 
L 469 0 
L 469 531 
Q 828 903 1448 1529 
Q 2069 2156 2228 2338 
Q 2531 2678 2651 2914 
Q 2772 3150 2772 3378 
Q 2772 3750 2511 3984 
Q 2250 4219 1831 4219 
Q 1534 4219 1204 4116 
Q 875 4013 500 3803 
L 500 4441 
Q 881 4594 1212 4672 
Q 1544 4750 1819 4750 
Q 2544 4750 2975 4387 
Q 3406 4025 3406 3419 
Q 3406 3131 3298 2873 
Q 3191 2616 2906 2266 
Q 2828 2175 2409 1742 
Q 1991 1309 1228 531 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-2212"/>
       <use xlink:href="#DejaVuSans-32" x="83.789062"/>
      </g>
     </g>
    </g>
    <g id="xtick_2">
     <g id="line2d_2">
      <path d="M 162.906695 273.312 
L 162.906695 7.2 
" clip-path="url(#p309b19a4dc)" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round"/>
     </g>
     <g id="text_2">
      <!-- −1 -->
      <g style="fill: #262626" transform="translate(155.535601 287.910437) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-31" d="M 794 531 
L 1825 531 
L 1825 4091 
L 703 3866 
L 703 4441 
L 1819 4666 
L 2450 4666 
L 2450 531 
L 3481 531 
L 3481 0 
L 794 0 
L 794 531 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-2212"/>
       <use xlink:href="#DejaVuSans-31" x="83.789062"/>
      </g>
     </g>
    </g>
    <g id="xtick_3">
     <g id="line2d_3">
      <path d="M 225.463404 273.312 
L 225.463404 7.2 
" clip-path="url(#p309b19a4dc)" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round"/>
     </g>
     <g id="text_3">
      <!-- 0 -->
      <g style="fill: #262626" transform="translate(222.282154 287.910437) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-30" d="M 2034 4250 
Q 1547 4250 1301 3770 
Q 1056 3291 1056 2328 
Q 1056 1369 1301 889 
Q 1547 409 2034 409 
Q 2525 409 2770 889 
Q 3016 1369 3016 2328 
Q 3016 3291 2770 3770 
Q 2525 4250 2034 4250 
z
M 2034 4750 
Q 2819 4750 3233 4129 
Q 3647 3509 3647 2328 
Q 3647 1150 3233 529 
Q 2819 -91 2034 -91 
Q 1250 -91 836 529 
Q 422 1150 422 2328 
Q 422 3509 836 4129 
Q 1250 4750 2034 4750 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-30"/>
      </g>
     </g>
    </g>
    <g id="xtick_4">
     <g id="line2d_4">
      <path d="M 288.020113 273.312 
L 288.020113 7.2 
" clip-path="url(#p309b19a4dc)" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round"/>
     </g>
     <g id="text_4">
      <!-- 1 -->
      <g style="fill: #262626" transform="translate(284.838863 287.910437) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-31"/>
      </g>
     </g>
    </g>
    <g id="xtick_5">
     <g id="line2d_5">
      <path d="M 350.576823 273.312 
L 350.576823 7.2 
" clip-path="url(#p309b19a4dc)" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round"/>
     </g>
     <g id="text_5">
      <!-- 2 -->
      <g style="fill: #262626" transform="translate(347.395573 287.910437) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-32"/>
      </g>
     </g>
    </g>
   </g>
   <g id="matplotlib.axis_2">
    <g id="ytick_1">
     <g id="line2d_6">
      <path d="M 44.845313 263.17076 
L 401.965312 263.17076 
" clip-path="url(#p309b19a4dc)" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round"/>
     </g>
     <g id="text_6">
      <!-- −1.00 -->
      <g style="fill: #262626" transform="translate(7.2 266.969978) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-2e" d="M 684 794 
L 1344 794 
L 1344 0 
L 684 0 
L 684 794 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-2212"/>
       <use xlink:href="#DejaVuSans-31" x="83.789062"/>
       <use xlink:href="#DejaVuSans-2e" x="147.412109"/>
       <use xlink:href="#DejaVuSans-30" x="179.199219"/>
       <use xlink:href="#DejaVuSans-30" x="242.822266"/>
      </g>
     </g>
    </g>
    <g id="ytick_2">
     <g id="line2d_7">
      <path d="M 44.845313 232.665579 
L 401.965312 232.665579 
" clip-path="url(#p309b19a4dc)" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round"/>
     </g>
     <g id="text_7">
      <!-- −0.75 -->
      <g style="fill: #262626" transform="translate(7.2 236.464798) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-37" d="M 525 4666 
L 3525 4666 
L 3525 4397 
L 1831 0 
L 1172 0 
L 2766 4134 
L 525 4134 
L 525 4666 
z
" transform="scale(0.015625)"/>
        <path id="DejaVuSans-35" d="M 691 4666 
L 3169 4666 
L 3169 4134 
L 1269 4134 
L 1269 2991 
Q 1406 3038 1543 3061 
Q 1681 3084 1819 3084 
Q 2600 3084 3056 2656 
Q 3513 2228 3513 1497 
Q 3513 744 3044 326 
Q 2575 -91 1722 -91 
Q 1428 -91 1123 -41 
Q 819 9 494 109 
L 494 744 
Q 775 591 1075 516 
Q 1375 441 1709 441 
Q 2250 441 2565 725 
Q 2881 1009 2881 1497 
Q 2881 1984 2565 2268 
Q 2250 2553 1709 2553 
Q 1456 2553 1204 2497 
Q 953 2441 691 2322 
L 691 4666 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-2212"/>
       <use xlink:href="#DejaVuSans-30" x="83.789062"/>
       <use xlink:href="#DejaVuSans-2e" x="147.412109"/>
       <use xlink:href="#DejaVuSans-37" x="179.199219"/>
       <use xlink:href="#DejaVuSans-35" x="242.822266"/>
      </g>
     </g>
    </g>
    <g id="ytick_3">
     <g id="line2d_8">
      <path d="M 44.845313 202.160399 
L 401.965312 202.160399 
" clip-path="url(#p309b19a4dc)" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round"/>
     </g>
     <g id="text_8">
      <!-- −0.50 -->
      <g style="fill: #262626" transform="translate(7.2 205.959618) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-2212"/>
       <use xlink:href="#DejaVuSans-30" x="83.789062"/>
       <use xlink:href="#DejaVuSans-2e" x="147.412109"/>
       <use xlink:href="#DejaVuSans-35" x="179.199219"/>
       <use xlink:href="#DejaVuSans-30" x="242.822266"/>
      </g>
     </g>
    </g>
    <g id="ytick_4">
     <g id="line2d_9">
      <path d="M 44.845313 171.655219 
L 401.965312 171.655219 
" clip-path="url(#p309b19a4dc)" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round"/>
     </g>
     <g id="text_9">
      <!-- −0.25 -->
      <g style="fill: #262626" transform="translate(7.2 175.454437) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-2212"/>
       <use xlink:href="#DejaVuSans-30" x="83.789062"/>
       <use xlink:href="#DejaVuSans-2e" x="147.412109"/>
       <use xlink:href="#DejaVuSans-32" x="179.199219"/>
       <use xlink:href="#DejaVuSans-35" x="242.822266"/>
      </g>
     </g>
    </g>
    <g id="ytick_5">
     <g id="line2d_10">
      <path d="M 44.845313 141.150038 
L 401.965312 141.150038 
" clip-path="url(#p309b19a4dc)" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round"/>
     </g>
     <g id="text_10">
      <!-- 0.00 -->
      <g style="fill: #262626" transform="translate(15.579688 144.949257) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-30"/>
       <use xlink:href="#DejaVuSans-2e" x="63.623047"/>
       <use xlink:href="#DejaVuSans-30" x="95.410156"/>
       <use xlink:href="#DejaVuSans-30" x="159.033203"/>
      </g>
     </g>
    </g>
    <g id="ytick_6">
     <g id="line2d_11">
      <path d="M 44.845313 110.644858 
L 401.965312 110.644858 
" clip-path="url(#p309b19a4dc)" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round"/>
     </g>
     <g id="text_11">
      <!-- 0.25 -->
      <g style="fill: #262626" transform="translate(15.579688 114.444077) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-30"/>
       <use xlink:href="#DejaVuSans-2e" x="63.623047"/>
       <use xlink:href="#DejaVuSans-32" x="95.410156"/>
       <use xlink:href="#DejaVuSans-35" x="159.033203"/>
      </g>
     </g>
    </g>
    <g id="ytick_7">
     <g id="line2d_12">
      <path d="M 44.845313 80.139678 
L 401.965312 80.139678 
" clip-path="url(#p309b19a4dc)" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round"/>
     </g>
     <g id="text_12">
      <!-- 0.50 -->
      <g style="fill: #262626" transform="translate(15.579688 83.938896) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-30"/>
       <use xlink:href="#DejaVuSans-2e" x="63.623047"/>
       <use xlink:href="#DejaVuSans-35" x="95.410156"/>
       <use xlink:href="#DejaVuSans-30" x="159.033203"/>
      </g>
     </g>
    </g>
    <g id="ytick_8">
     <g id="line2d_13">
      <path d="M 44.845313 49.634497 
L 401.965312 49.634497 
" clip-path="url(#p309b19a4dc)" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round"/>
     </g>
     <g id="text_13">
      <!-- 0.75 -->
      <g style="fill: #262626" transform="translate(15.579688 53.433716) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-30"/>
       <use xlink:href="#DejaVuSans-2e" x="63.623047"/>
       <use xlink:href="#DejaVuSans-37" x="95.410156"/>
       <use xlink:href="#DejaVuSans-35" x="159.033203"/>
      </g>
     </g>
    </g>
    <g id="ytick_9">
     <g id="line2d_14">
      <path d="M 44.845313 19.129317 
L 401.965312 19.129317 
" clip-path="url(#p309b19a4dc)" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round"/>
     </g>
     <g id="text_14">
      <!-- 1.00 -->
      <g style="fill: #262626" transform="translate(15.579688 22.928536) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-31"/>
       <use xlink:href="#DejaVuSans-2e" x="63.623047"/>
       <use xlink:href="#DejaVuSans-30" x="95.410156"/>
       <use xlink:href="#DejaVuSans-30" x="159.033203"/>
      </g>
     </g>
    </g>
   </g>
   <g id="line2d_15">
    <defs>
     <path id="m377059fb3a" d="M -3 3 
L 3 -3 
M -3 -3 
L 3 3 
" style="stroke: #1f77b4"/>
    </defs>
    <g clip-path="url(#p309b19a4dc)">
     <use xlink:href="#m377059fb3a" x="95.094121" y="247.664352" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m377059fb3a" x="151.279883" y="254.119265" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m377059fb3a" x="61.07804" y="201.056726" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m377059fb3a" x="210.397374" y="170.022742" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m377059fb3a" x="351.297495" y="30.883122" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m377059fb3a" x="385.732585" y="74.490742" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m377059fb3a" x="310.661507" y="21.858316" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m377059fb3a" x="326.240845" y="19.296" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m377059fb3a" x="138.836775" y="261.216" style="fill: #1f77b4; stroke: #1f77b4"/>
     <use xlink:href="#m377059fb3a" x="279.523395" y="48.399543" style="fill: #1f77b4; stroke: #1f77b4"/>
    </g>
   </g>
   <g id="patch_3">
    <path d="M 44.845313 273.312 
L 44.845313 7.2 
" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="patch_4">
    <path d="M 401.965312 273.312 
L 401.965312 7.2 
" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="patch_5">
    <path d="M 44.845313 273.312 
L 401.965312 273.312 
" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="patch_6">
    <path d="M 44.845313 7.2 
L 401.965312 7.2 
" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
  </g>
 </g>
 <defs>
  <clipPath id="p309b19a4dc">
   <rect x="44.845313" y="7.2" width="357.12" height="266.112"/>
  </clipPath>
 </defs>
</svg>
"/>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedSVG jp-OutputArea-output" data-mime-type="image/svg+xml" tabindex="0">
<img alt="No description has been provided for this image" src="data:image/svg+xml;base64,<?xml version="1.0" encoding="utf-8" standalone="no"?>
<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN"
  "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">
<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="393.262187pt" height="297.190125pt" viewBox="0 0 393.262187 297.190125" xmlns="http://www.w3.org/2000/svg" version="1.1">
 <metadata>
  <rdf:RDF xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:cc="http://creativecommons.org/ns#" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#">
   <cc:Work>
    <dc:type rdf:resource="http://purl.org/dc/dcmitype/StillImage"/>
    <dc:date>2023-05-11T08:16:53.773609</dc:date>
    <dc:format>image/svg+xml</dc:format>
    <dc:creator>
     <cc:Agent>
      <dc:title>Matplotlib v3.7.1, https://matplotlib.org/</dc:title>
     </cc:Agent>
    </dc:creator>
   </cc:Work>
  </rdf:RDF>
 </metadata>
 <defs>
  <style type="text/css">*{stroke-linejoin: round; stroke-linecap: butt}</style>
 </defs>
 <g id="figure_1">
  <g id="patch_1">
   <path d="M 0 297.190125 
L 393.262187 297.190125 
L 393.262187 0 
L 0 0 
z
" style="fill: #ffffff"/>
  </g>
  <g id="axes_1">
   <g id="patch_2">
    <path d="M 28.942188 273.312 
L 386.062188 273.312 
L 386.062188 7.2 
L 28.942188 7.2 
z
" style="fill: #eaeaf2"/>
   </g>
   <g id="matplotlib.axis_1">
    <g id="xtick_1">
     <g id="line2d_1">
      <path d="M 42.757293 273.312 
L 42.757293 7.2 
" clip-path="url(#pcc6c9320a5)" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round"/>
     </g>
     <g id="text_1">
      <!-- −3 -->
      <g style="fill: #262626" transform="translate(35.3862 287.910437) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-2212" d="M 678 2272 
L 4684 2272 
L 4684 1741 
L 678 1741 
L 678 2272 
z
" transform="scale(0.015625)"/>
        <path id="DejaVuSans-33" d="M 2597 2516 
Q 3050 2419 3304 2112 
Q 3559 1806 3559 1356 
Q 3559 666 3084 287 
Q 2609 -91 1734 -91 
Q 1441 -91 1130 -33 
Q 819 25 488 141 
L 488 750 
Q 750 597 1062 519 
Q 1375 441 1716 441 
Q 2309 441 2620 675 
Q 2931 909 2931 1356 
Q 2931 1769 2642 2001 
Q 2353 2234 1838 2234 
L 1294 2234 
L 1294 2753 
L 1863 2753 
Q 2328 2753 2575 2939 
Q 2822 3125 2822 3475 
Q 2822 3834 2567 4026 
Q 2313 4219 1838 4219 
Q 1578 4219 1281 4162 
Q 984 4106 628 3988 
L 628 4550 
Q 988 4650 1302 4700 
Q 1616 4750 1894 4750 
Q 2613 4750 3031 4423 
Q 3450 4097 3450 3541 
Q 3450 3153 3228 2886 
Q 3006 2619 2597 2516 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-2212"/>
       <use xlink:href="#DejaVuSans-33" x="83.789062"/>
      </g>
     </g>
    </g>
    <g id="xtick_2">
     <g id="line2d_2">
      <path d="M 97.293342 273.312 
L 97.293342 7.2 
" clip-path="url(#pcc6c9320a5)" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round"/>
     </g>
     <g id="text_2">
      <!-- −2 -->
      <g style="fill: #262626" transform="translate(89.922248 287.910437) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-32" d="M 1228 531 
L 3431 531 
L 3431 0 
L 469 0 
L 469 531 
Q 828 903 1448 1529 
Q 2069 2156 2228 2338 
Q 2531 2678 2651 2914 
Q 2772 3150 2772 3378 
Q 2772 3750 2511 3984 
Q 2250 4219 1831 4219 
Q 1534 4219 1204 4116 
Q 875 4013 500 3803 
L 500 4441 
Q 881 4594 1212 4672 
Q 1544 4750 1819 4750 
Q 2544 4750 2975 4387 
Q 3406 4025 3406 3419 
Q 3406 3131 3298 2873 
Q 3191 2616 2906 2266 
Q 2828 2175 2409 1742 
Q 1991 1309 1228 531 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-2212"/>
       <use xlink:href="#DejaVuSans-32" x="83.789062"/>
      </g>
     </g>
    </g>
    <g id="xtick_3">
     <g id="line2d_3">
      <path d="M 151.82939 273.312 
L 151.82939 7.2 
" clip-path="url(#pcc6c9320a5)" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round"/>
     </g>
     <g id="text_3">
      <!-- −1 -->
      <g style="fill: #262626" transform="translate(144.458297 287.910437) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-31" d="M 794 531 
L 1825 531 
L 1825 4091 
L 703 3866 
L 703 4441 
L 1819 4666 
L 2450 4666 
L 2450 531 
L 3481 531 
L 3481 0 
L 794 0 
L 794 531 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-2212"/>
       <use xlink:href="#DejaVuSans-31" x="83.789062"/>
      </g>
     </g>
    </g>
    <g id="xtick_4">
     <g id="line2d_4">
      <path d="M 206.365439 273.312 
L 206.365439 7.2 
" clip-path="url(#pcc6c9320a5)" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round"/>
     </g>
     <g id="text_4">
      <!-- 0 -->
      <g style="fill: #262626" transform="translate(203.184189 287.910437) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-30" d="M 2034 4250 
Q 1547 4250 1301 3770 
Q 1056 3291 1056 2328 
Q 1056 1369 1301 889 
Q 1547 409 2034 409 
Q 2525 409 2770 889 
Q 3016 1369 3016 2328 
Q 3016 3291 2770 3770 
Q 2525 4250 2034 4250 
z
M 2034 4750 
Q 2819 4750 3233 4129 
Q 3647 3509 3647 2328 
Q 3647 1150 3233 529 
Q 2819 -91 2034 -91 
Q 1250 -91 836 529 
Q 422 1150 422 2328 
Q 422 3509 836 4129 
Q 1250 4750 2034 4750 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-30"/>
      </g>
     </g>
    </g>
    <g id="xtick_5">
     <g id="line2d_5">
      <path d="M 260.901488 273.312 
L 260.901488 7.2 
" clip-path="url(#pcc6c9320a5)" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round"/>
     </g>
     <g id="text_5">
      <!-- 1 -->
      <g style="fill: #262626" transform="translate(257.720238 287.910437) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-31"/>
      </g>
     </g>
    </g>
    <g id="xtick_6">
     <g id="line2d_6">
      <path d="M 315.437536 273.312 
L 315.437536 7.2 
" clip-path="url(#pcc6c9320a5)" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round"/>
     </g>
     <g id="text_6">
      <!-- 2 -->
      <g style="fill: #262626" transform="translate(312.256286 287.910437) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-32"/>
      </g>
     </g>
    </g>
    <g id="xtick_7">
     <g id="line2d_7">
      <path d="M 369.973585 273.312 
L 369.973585 7.2 
" clip-path="url(#pcc6c9320a5)" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round"/>
     </g>
     <g id="text_7">
      <!-- 3 -->
      <g style="fill: #262626" transform="translate(366.792335 287.910437) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-33"/>
      </g>
     </g>
    </g>
   </g>
   <g id="matplotlib.axis_2">
    <g id="ytick_1">
     <g id="line2d_8">
      <path d="M 28.942188 242.232656 
L 386.062188 242.232656 
" clip-path="url(#pcc6c9320a5)" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round"/>
     </g>
     <g id="text_8">
      <!-- −2 -->
      <g style="fill: #262626" transform="translate(7.2 246.031875) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-2212"/>
       <use xlink:href="#DejaVuSans-32" x="83.789062"/>
      </g>
     </g>
    </g>
    <g id="ytick_2">
     <g id="line2d_9">
      <path d="M 28.942188 194.239411 
L 386.062188 194.239411 
" clip-path="url(#pcc6c9320a5)" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round"/>
     </g>
     <g id="text_9">
      <!-- −1 -->
      <g style="fill: #262626" transform="translate(7.2 198.03863) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-2212"/>
       <use xlink:href="#DejaVuSans-31" x="83.789062"/>
      </g>
     </g>
    </g>
    <g id="ytick_3">
     <g id="line2d_10">
      <path d="M 28.942188 146.246166 
L 386.062188 146.246166 
" clip-path="url(#pcc6c9320a5)" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round"/>
     </g>
     <g id="text_10">
      <!-- 0 -->
      <g style="fill: #262626" transform="translate(15.579688 150.045385) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-30"/>
      </g>
     </g>
    </g>
    <g id="ytick_4">
     <g id="line2d_11">
      <path d="M 28.942188 98.252921 
L 386.062188 98.252921 
" clip-path="url(#pcc6c9320a5)" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round"/>
     </g>
     <g id="text_11">
      <!-- 1 -->
      <g style="fill: #262626" transform="translate(15.579688 102.052139) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-31"/>
      </g>
     </g>
    </g>
    <g id="ytick_5">
     <g id="line2d_12">
      <path d="M 28.942188 50.259675 
L 386.062188 50.259675 
" clip-path="url(#pcc6c9320a5)" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round"/>
     </g>
     <g id="text_12">
      <!-- 2 -->
      <g style="fill: #262626" transform="translate(15.579688 54.058894) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-32"/>
      </g>
     </g>
    </g>
   </g>
   <g id="line2d_13">
    <path d="M 45.174915 113.028432 
L 47.112558 114.680095 
L 48.10218 115.721849 
L 51.57324 120.595879 
L 52.393348 121.924783 
L 56.777699 129.285557 
L 63.056619 134.75288 
L 68.831813 128.774124 
L 72.601242 120.791205 
L 73.310544 119.17132 
L 73.467091 118.811019 
L 74.506077 116.384074 
L 80.468866 106.171061 
L 82.95637 104.509549 
L 85.796974 104.802638 
L 92.711354 112.970822 
L 101.633421 129.835103 
L 103.76435 134.036348 
L 105.462089 137.188143 
L 105.963179 138.152016 
L 109.024091 143.693122 
L 115.702999 153.749242 
L 116.502559 154.58033 
L 125.581936 152.284595 
L 130.732684 135.595789 
L 130.845577 135.04507 
L 136.888796 99.981307 
L 139.571659 81.598262 
L 139.891121 79.378969 
L 141.461528 68.713859 
L 141.693302 67.346203 
L 144.628659 49.791522 
L 145.870273 43.744176 
L 149.622474 32.467806 
L 150.104534 31.862443 
L 152.786482 33.024657 
L 155.103911 39.928323 
L 155.388051 41.114347 
L 158.625714 59.822922 
L 161.318754 81.048031 
L 164.893846 112.896635 
L 170.583714 157.558462 
L 173.570944 171.896532 
L 178.633102 176.566658 
L 181.602361 168.937312 
L 189.649773 130.376888 
L 189.847152 129.451406 
L 193.231089 115.21152 
L 194.421217 111.21063 
L 195.025779 109.581672 
L 197.277167 105.05915 
L 211.88137 129.041793 
L 212.31209 130.250523 
L 212.417572 130.558879 
L 214.250456 135.551469 
L 215.534774 138.681927 
L 217.039392 141.842355 
L 221.676286 147.001372 
L 222.980879 147.234722 
L 223.46472 147.187058 
L 225.300373 146.121831 
L 235.688519 122.346681 
L 239.209753 109.493414 
L 242.657303 96.252372 
L 243.021379 94.740035 
L 246.396695 82.025662 
L 247.749533 77.25704 
L 250.304477 69.188813 
L 253.49417 61.151556 
L 265.216288 60.259146 
L 265.691028 61.353051 
L 265.846581 61.734528 
L 269.383558 72.830854 
L 280.361517 134.934417 
L 280.639933 136.875654 
L 280.725237 137.456449 
L 294.221777 216.139152 
L 294.422735 216.925558 
L 294.68154 218.000874 
L 295.003193 219.389136 
L 296.332831 224.549113 
L 301.874953 241.100751 
L 306.572355 247.912993 
L 309.898136 247.487522 
L 316.065808 234.686047 
L 316.291596 233.897401 
L 316.836921 232.019711 
L 320.490073 217.665859 
L 322.354189 209.832616 
L 331.6266 178.928548 
L 334.579475 174.940569 
L 334.915237 174.737802 
L 335.905367 174.061295 
L 339.398349 173.707483 
L 344.526531 174.298907 
L 346.08583 173.737304 
L 358.60318 150.397999 
L 361.862697 145.279253 
L 366.333679 147.000496 
L 369.82946 156.652548 
" clip-path="url(#pcc6c9320a5)" style="fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: round"/>
   </g>
   <g id="line2d_14">
    <path d="M 45.174915 202.462208 
L 47.112558 197.731038 
L 48.10218 195.384804 
L 51.57324 189.178705 
L 52.393348 188.225502 
L 56.777699 187.481525 
L 63.056619 197.460697 
L 68.831813 211.31698 
L 72.601242 218.979822 
L 73.310544 220.114803 
L 73.467091 220.478104 
L 74.506077 221.960195 
L 80.468866 229.393254 
L 82.95637 232.055072 
L 85.796974 235.230177 
L 92.711354 242.268497 
L 101.633421 243.353045 
L 103.76435 240.970529 
L 105.462089 238.334876 
L 105.963179 237.551436 
L 109.024091 230.42711 
L 115.702999 208.148544 
L 116.502559 204.936456 
L 125.581936 168.763389 
L 130.732684 153.152774 
L 130.845577 152.947285 
L 136.888796 141.413735 
L 139.571659 137.231668 
L 139.891121 136.817008 
L 141.461528 134.228071 
L 141.693302 133.790468 
L 144.628659 128.402279 
L 145.870273 125.834245 
L 149.622474 117.180387 
L 150.104534 116.025678 
L 152.786482 109.668591 
L 155.103911 104.620514 
L 155.388051 104.064182 
L 158.625714 98.823764 
L 161.318754 96.408017 
L 164.893846 96.035075 
L 170.583714 101.925438 
L 173.570944 107.39368 
L 178.633102 118.980374 
L 181.602361 125.959495 
L 189.649773 141.362104 
L 189.847152 141.586071 
L 193.231089 145.573413 
L 194.421217 146.783606 
L 195.025779 147.245999 
L 197.277167 149.088243 
L 211.88137 162.658252 
L 212.31209 163.252071 
L 212.417572 163.535601 
L 214.250456 166.429838 
L 215.534774 168.890677 
L 217.039392 171.865212 
L 221.676286 182.303983 
L 222.980879 185.543842 
L 223.46472 186.426477 
L 225.300373 190.737593 
L 235.688519 200.578171 
L 239.209753 194.591162 
L 242.657303 184.114946 
L 243.021379 182.852131 
L 246.396695 169.916463 
L 247.749533 164.468408 
L 250.304477 155.120081 
L 253.49417 145.392967 
L 265.216288 147.134511 
L 265.691028 148.333654 
L 265.846581 148.606546 
L 269.383558 158.672069 
L 280.361517 188.613826 
L 280.639933 189.063094 
L 280.725237 189.346799 
L 294.221777 200.769169 
L 294.422735 200.780461 
L 294.68154 200.784661 
L 295.003193 200.764363 
L 296.332831 200.653519 
L 301.874953 200.307363 
L 306.572355 200.451757 
L 309.898136 200.945404 
L 316.065808 202.350767 
L 316.291596 202.378575 
L 316.836921 202.382873 
L 320.490073 201.771264 
L 322.354189 200.891969 
L 331.6266 185.756264 
L 334.579475 177.770849 
L 334.915237 176.770897 
L 335.905367 174.083813 
L 339.398349 163.821697 
L 344.526531 151.229965 
L 346.08583 148.201477 
L 358.60318 128.007455 
L 361.862697 122.475401 
L 366.333679 115.977121 
L 369.82946 113.376811 
" clip-path="url(#pcc6c9320a5)" style="fill: none; stroke: #ff7f0e; stroke-width: 1.5; stroke-linecap: round"/>
   </g>
   <g id="line2d_15">
    <path d="M 45.174915 104.891695 
L 47.112558 110.367213 
L 48.10218 113.388636 
L 51.57324 124.691511 
L 52.393348 127.515048 
L 56.777699 140.941026 
L 63.056619 154.443224 
L 68.831813 158.227801 
L 72.601242 155.93358 
L 73.310544 155.037694 
L 73.467091 154.854804 
L 74.506077 153.339273 
L 80.468866 141.015863 
L 82.95637 134.800509 
L 85.796974 127.690936 
L 92.711354 115.03447 
L 101.633421 115.045668 
L 103.76435 117.424564 
L 105.462089 119.589707 
L 105.963179 120.26662 
L 109.024091 124.476575 
L 115.702999 132.768343 
L 116.502559 133.496285 
L 125.581936 139.66918 
L 130.732684 141.542075 
L 130.845577 141.670005 
L 136.888796 144.20481 
L 139.571659 146.369714 
L 139.891121 146.711566 
L 141.461528 148.447033 
L 141.693302 148.803632 
L 144.628659 153.22954 
L 145.870273 155.584411 
L 149.622474 164.214876 
L 150.104534 165.396013 
L 152.786482 173.033416 
L 155.103911 180.027035 
L 155.388051 180.965985 
L 158.625714 191.570592 
L 161.318754 200.826687 
L 164.893846 213.377135 
L 170.583714 230.724978 
L 173.570944 236.415176 
L 178.633102 236.322944 
L 181.602361 229.239347 
L 189.649773 189.502216 
L 189.847152 188.377966 
L 193.231089 169.143747 
L 194.421217 163.018849 
L 195.025779 159.98706 
L 197.277167 150.312651 
L 211.88137 136.275833 
L 212.31209 136.374196 
L 212.417572 136.405839 
L 214.250456 136.718661 
L 215.534774 136.580857 
L 217.039392 136.106379 
L 221.676286 132.04302 
L 222.980879 130.545209 
L 223.46472 129.945544 
L 225.300373 127.894986 
L 235.688519 127.719729 
L 239.209753 132.022698 
L 242.657303 136.248162 
L 243.021379 136.692645 
L 246.396695 140.083496 
L 247.749533 141.420393 
L 250.304477 143.555674 
L 253.49417 147.167489 
L 265.216288 175.480896 
L 265.691028 177.073545 
L 265.846581 177.48522 
L 269.383558 188.560127 
L 280.361517 210.007388 
L 280.639933 210.166024 
L 280.725237 210.227296 
L 294.221777 209.52342 
L 294.422735 209.375506 
L 294.68154 209.149379 
L 295.003193 208.811285 
L 296.332831 207.436061 
L 301.874953 198.901435 
L 306.572355 189.898931 
L 309.898136 184.40764 
L 316.065808 179.600837 
L 316.291596 179.524173 
L 316.836921 179.595085 
L 320.490073 181.224877 
L 322.354189 182.842821 
L 331.6266 189.081267 
L 334.579475 187.906285 
L 334.915237 187.514361 
L 335.905367 186.502815 
L 339.398349 180.755747 
L 344.526531 166.054383 
L 346.08583 160.25198 
L 358.60318 117.002384 
L 361.862697 115.979213 
L 366.333679 126.243701 
L 369.82946 141.134448 
" clip-path="url(#pcc6c9320a5)" style="fill: none; stroke: #2ca02c; stroke-width: 1.5; stroke-linecap: round"/>
   </g>
   <g id="line2d_16">
    <path d="M 45.174915 247.357176 
L 47.112558 246.699911 
L 48.10218 245.487607 
L 51.57324 237.082665 
L 52.393348 234.243893 
L 56.777699 215.497356 
L 63.056619 184.822944 
L 68.831813 160.011087 
L 72.601242 147.561264 
L 73.310544 145.521064 
L 73.467091 145.223408 
L 74.506077 142.531024 
L 80.468866 133.689828 
L 82.95637 132.974522 
L 85.796974 133.656284 
L 92.711354 139.025342 
L 101.633421 139.00204 
L 103.76435 136.969943 
L 105.462089 135.069844 
L 105.963179 134.485125 
L 109.024091 131.17778 
L 115.702999 129.63668 
L 116.502559 130.356911 
L 125.581936 151.718611 
L 130.732684 167.807148 
L 130.845577 168.088683 
L 136.888796 176.853192 
L 139.571659 174.820187 
L 139.891121 174.335927 
L 141.461528 171.091675 
L 141.693302 170.471645 
L 144.628659 161.114803 
L 145.870273 156.180397 
L 149.622474 140.326796 
L 150.104534 138.320865 
L 152.786482 127.824209 
L 155.103911 120.816083 
L 155.388051 120.092966 
L 158.625714 114.047332 
L 161.318754 112.349112 
L 164.893846 113.410074 
L 170.583714 116.650836 
L 173.570944 116.582516 
L 178.633102 111.709074 
L 181.602361 107.486678 
L 189.649773 102.516642 
L 189.847152 102.779829 
L 193.231089 107.099479 
L 194.421217 109.386082 
L 195.025779 110.661195 
L 197.277167 115.835582 
L 211.88137 118.626897 
L 212.31209 117.515824 
L 212.417572 117.073166 
L 214.250456 111.402137 
L 215.534774 106.938928 
L 217.039392 101.823516 
L 221.676286 87.190206 
L 222.980879 83.923767 
L 223.46472 82.800511 
L 225.300373 79.239991 
L 235.688519 77.550728 
L 239.209753 83.222309 
L 242.657303 91.390607 
L 243.021379 92.210703 
L 246.396695 102.378982 
L 247.749533 106.812766 
L 250.304477 115.255737 
L 253.49417 125.007372 
L 265.216288 133.310749 
L 265.691028 132.538908 
L 265.846581 132.267434 
L 269.383558 124.301162 
L 280.361517 104.596083 
L 280.639933 104.73205 
L 280.725237 104.759438 
L 294.221777 137.108728 
L 294.422735 137.628837 
L 294.68154 138.332537 
L 295.003193 139.261012 
L 296.332831 142.511087 
L 301.874953 149.261804 
L 306.572355 146.272805 
L 309.898136 142.08543 
L 316.065808 138.038 
L 316.291596 138.042505 
L 316.836921 138.279454 
L 320.490073 143.109079 
L 322.354189 147.486233 
L 331.6266 177.750599 
L 334.579475 185.908788 
L 334.915237 186.681406 
L 335.905367 188.882824 
L 339.398349 194.461366 
L 344.526531 198.494908 
L 346.08583 199.275637 
L 358.60318 210.30234 
L 361.862697 213.221175 
L 366.333679 214.304112 
L 369.82946 212.081421 
" clip-path="url(#pcc6c9320a5)" style="fill: none; stroke: #d62728; stroke-width: 1.5; stroke-linecap: round"/>
   </g>
   <g id="line2d_17">
    <path d="M 45.174915 168.838514 
L 47.112558 164.126699 
L 48.10218 161.227793 
L 51.57324 149.427313 
L 52.393348 146.27179 
L 56.777699 130.012038 
L 63.056619 113.527268 
L 68.831813 108.839266 
L 72.601242 108.980869 
L 73.310544 109.010758 
L 73.467091 109.010027 
L 74.506077 108.906462 
L 80.468866 104.445128 
L 82.95637 99.939283 
L 85.796974 93.192278 
L 92.711354 77.342596 
L 101.633421 79.60222 
L 103.76435 84.45119 
L 105.462089 88.648113 
L 105.963179 90.052434 
L 109.024091 97.517886 
L 115.702999 102.496396 
L 116.502559 101.59217 
L 125.581936 74.348353 
L 130.732684 58.840116 
L 130.845577 58.578251 
L 136.888796 56.817039 
L 139.571659 62.62716 
L 139.891121 63.6951 
L 141.461528 69.106014 
L 141.693302 70.048333 
L 144.628659 82.819636 
L 145.870273 88.906366 
L 149.622474 108.215158 
L 150.104534 110.64293 
L 152.786482 123.858967 
L 155.103911 134.187649 
L 155.388051 135.236998 
L 158.625714 146.32482 
L 161.318754 152.267233 
L 164.893846 154.628051 
L 170.583714 146.535107 
L 173.570944 137.820538 
L 178.633102 121.307289 
L 181.602361 113.233776 
L 189.649773 108.670524 
L 189.847152 108.875278 
L 193.231089 115.261069 
L 194.421217 118.412024 
L 195.025779 120.065306 
L 197.277167 126.610097 
L 211.88137 153.312145 
L 212.31209 153.257021 
L 212.417572 153.267098 
L 214.250456 152.040623 
L 215.534774 150.760075 
L 217.039392 148.630082 
L 221.676286 139.570643 
L 222.980879 136.378129 
L 223.46472 134.987788 
L 225.300373 130.047199 
L 235.688519 101.29557 
L 239.209753 95.159779 
L 242.657303 92.770787 
L 243.021379 92.85557 
L 246.396695 95.161197 
L 247.749533 97.244942 
L 250.304477 102.745469 
L 253.49417 111.884748 
L 265.216288 149.45968 
L 265.691028 150.584101 
L 265.846581 150.831964 
L 269.383558 156.94197 
L 280.361517 147.367408 
L 280.639933 146.725348 
L 280.725237 146.42496 
L 294.221777 116.48995 
L 294.422735 116.310465 
L 294.68154 116.084254 
L 295.003193 115.608968 
L 296.332831 114.523144 
L 301.874953 112.526436 
L 306.572355 112.197666 
L 309.898136 111.616944 
L 316.065808 109.87941 
L 316.291596 109.654087 
L 316.836921 109.566808 
L 320.490073 108.566656 
L 322.354189 108.216631 
L 331.6266 107.300988 
L 334.579475 107.202428 
L 334.915237 107.117203 
L 335.905367 107.194862 
L 339.398349 107.941718 
L 344.526531 112.441989 
L 346.08583 115.202353 
L 358.60318 161.736255 
L 361.862697 175.64347 
L 366.333679 189.660324 
L 369.82946 195.023828 
" clip-path="url(#pcc6c9320a5)" style="fill: none; stroke: #9467bd; stroke-width: 1.5; stroke-linecap: round"/>
   </g>
   <g id="line2d_18">
    <path d="M 45.174915 170.376186 
L 47.112558 162.756995 
L 48.10218 159.222252 
L 51.57324 149.14901 
L 52.393348 147.388636 
L 56.777699 141.722553 
L 63.056619 142.328419 
L 68.831813 145.564759 
L 72.601242 146.143388 
L 73.310544 145.964972 
L 73.467091 146.02501 
L 74.506077 145.838632 
L 80.468866 143.981097 
L 82.95637 143.979532 
L 85.796974 145.17593 
L 92.711354 154.165111 
L 101.633421 170.642593 
L 103.76435 174.441384 
L 105.462089 177.386132 
L 105.963179 178.279175 
L 109.024091 183.952993 
L 115.702999 197.672805 
L 116.502559 199.133378 
L 125.581936 211.692436 
L 130.732684 213.436486 
L 130.845577 213.573698 
L 136.888796 217.132113 
L 139.571659 221.166718 
L 139.891121 221.758314 
L 141.461528 225.163187 
L 141.693302 225.748688 
L 144.628659 233.265601 
L 145.870273 236.755771 
L 149.622474 246.518765 
L 150.104534 247.597888 
L 152.786482 252.107551 
L 155.103911 253.514471 
L 155.388051 253.591415 
L 158.625714 250.757888 
L 161.318754 244.12963 
L 164.893846 230.782317 
L 170.583714 203.407336 
L 173.570944 188.645944 
L 178.633102 167.315193 
L 181.602361 158.029468 
L 189.649773 146.827331 
L 189.847152 146.712652 
L 193.231089 146.335068 
L 194.421217 146.325519 
L 195.025779 146.350964 
L 197.277167 145.944836 
L 211.88137 123.527922 
L 212.31209 122.562392 
L 212.417572 122.362518 
L 214.250456 118.575687 
L 215.534774 116.107312 
L 217.039392 113.731772 
L 221.676286 108.457606 
L 222.980879 107.490392 
L 223.46472 107.281393 
L 225.300373 106.472644 
L 235.688519 106.393687 
L 239.209753 109.719842 
L 242.657303 117.003124 
L 243.021379 117.853726 
L 246.396695 130.459188 
L 247.749533 137.011477 
L 250.304477 151.629577 
L 253.49417 173.08785 
L 265.216288 249.788346 
L 265.691028 251.68555 
L 265.846581 252.260815 
L 269.383558 261.216 
L 280.361517 230.638948 
L 280.639933 228.898111 
L 280.725237 228.370474 
L 294.221777 134.415512 
L 294.422735 133.160172 
L 294.68154 131.632084 
L 295.003193 129.571826 
L 296.332831 121.750817 
L 301.874953 95.473303 
L 306.572355 81.840463 
L 309.898136 77.380027 
L 316.065808 81.171162 
L 316.291596 81.562614 
L 316.836921 82.570497 
L 320.490073 91.481864 
L 322.354189 97.11272 
L 331.6266 124.413075 
L 334.579475 130.154663 
L 334.915237 130.689464 
L 335.905367 132.051351 
L 339.398349 135.823893 
L 344.526531 138.972151 
L 346.08583 139.933739 
L 358.60318 148.202633 
L 361.862697 148.455993 
L 366.333679 147.24216 
L 369.82946 146.526976 
" clip-path="url(#pcc6c9320a5)" style="fill: none; stroke: #8c564b; stroke-width: 1.5; stroke-linecap: round"/>
   </g>
   <g id="line2d_19">
    <path d="M 45.174915 159.554624 
L 47.112558 158.331521 
L 48.10218 157.38156 
L 51.57324 152.608352 
L 52.393348 151.254785 
L 56.777699 144.797708 
L 63.056619 140.092415 
L 68.831813 142.861953 
L 72.601242 148.057202 
L 73.310544 149.321254 
L 73.467091 149.676994 
L 74.506077 151.592909 
L 80.468866 165.013505 
L 82.95637 170.783657 
L 85.796974 176.542115 
L 92.711354 179.719361 
L 101.633421 153.656775 
L 103.76435 144.378816 
L 105.462089 136.885387 
L 105.963179 134.770829 
L 109.024091 123.07415 
L 115.702999 111.212706 
L 116.502559 111.359851 
L 125.581936 138.797608 
L 130.732684 168.926701 
L 130.845577 169.61684 
L 136.888796 204.689151 
L 139.571659 216.242517 
L 139.891121 217.294686 
L 141.461528 221.974254 
L 141.693302 222.520158 
L 144.628659 226.553115 
L 145.870273 226.6838 
L 149.622474 221.877297 
L 150.104534 220.714515 
L 152.786482 213.172522 
L 155.103911 205.570777 
L 155.388051 204.674273 
L 158.625714 193.84226 
L 161.318754 186.016404 
L 164.893846 177.902136 
L 170.583714 168.831934 
L 173.570944 164.009478 
L 178.633102 153.426604 
L 181.602361 145.981214 
L 189.649773 126.054921 
L 189.847152 125.580938 
L 193.231089 119.479956 
L 194.421217 117.67946 
L 195.025779 116.702267 
L 197.277167 113.265316 
L 211.88137 79.986134 
L 212.31209 78.6505 
L 212.417572 78.310304 
L 214.250456 72.51878 
L 215.534774 68.439776 
L 217.039392 63.733845 
L 221.676286 50.877703 
L 222.980879 48.087957 
L 223.46472 47.024102 
L 225.300373 44.346896 
L 235.688519 58.208791 
L 239.209753 74.939684 
L 242.657303 94.129184 
L 243.021379 96.243552 
L 246.396695 114.255248 
L 247.749533 120.442217 
L 250.304477 130.136216 
L 253.49417 137.73515 
L 265.216288 133.813991 
L 265.691028 133.257167 
L 265.846581 133.272921 
L 269.383558 130.929714 
L 280.361517 146.946258 
L 280.639933 147.933458 
L 280.725237 148.083887 
L 294.221777 191.178362 
L 294.422735 191.557062 
L 294.68154 192.118203 
L 295.003193 192.676832 
L 296.332831 194.397572 
L 301.874953 194.418662 
L 306.572355 185.575066 
L 309.898136 176.206833 
L 316.065808 158.267807 
L 316.291596 157.743151 
L 316.836921 156.444985 
L 320.490073 150.039384 
L 322.354189 148.724917 
L 331.6266 159.197278 
L 334.579475 165.823991 
L 334.915237 166.592812 
L 335.905367 168.702697 
L 339.398349 175.088796 
L 344.526531 178.797374 
L 346.08583 178.508877 
L 358.60318 161.409179 
L 361.862697 156.50841 
L 366.333679 152.104238 
L 369.82946 150.874634 
" clip-path="url(#pcc6c9320a5)" style="fill: none; stroke: #e377c2; stroke-width: 1.5; stroke-linecap: round"/>
   </g>
   <g id="line2d_20">
    <path d="M 45.174915 90.713909 
L 47.112558 83.757234 
L 48.10218 80.611065 
L 51.57324 72.313128 
L 52.393348 71.199963 
L 56.777699 71.378527 
L 63.056619 93.576611 
L 68.831813 133.94572 
L 72.601242 165.154098 
L 73.310544 170.889539 
L 73.467091 172.290302 
L 74.506077 180.460627 
L 80.468866 218.521786 
L 82.95637 227.392286 
L 85.796974 230.988771 
L 92.711354 213.041222 
L 101.633421 162.542733 
L 103.76435 151.881883 
L 105.462089 144.793064 
L 105.963179 143.027321 
L 109.024091 134.322727 
L 115.702999 130.447918 
L 116.502559 131.080167 
L 125.581936 147.770218 
L 130.732684 159.592849 
L 130.845577 159.861837 
L 136.888796 168.605159 
L 139.571659 168.565509 
L 139.891121 168.452207 
L 141.461528 166.759728 
L 141.693302 166.305552 
L 144.628659 159.683561 
L 145.870273 155.707396 
L 149.622474 139.55512 
L 150.104534 137.112634 
L 152.786482 122.500387 
L 155.103911 109.011834 
L 155.388051 107.271214 
L 158.625714 88.187931 
L 161.318754 73.38633 
L 164.893846 56.49464 
L 170.583714 38.710968 
L 173.570944 34.088328 
L 178.633102 33.184753 
L 181.602361 36.091133 
L 189.649773 50.708456 
L 189.847152 51.082728 
L 193.231089 57.531467 
L 194.421217 59.478148 
L 195.025779 60.341634 
L 197.277167 63.122004 
L 211.88137 68.680245 
L 212.31209 69.313493 
L 212.417572 69.365475 
L 214.250456 72.460265 
L 215.534774 75.333238 
L 217.039392 79.384355 
L 221.676286 96.953193 
L 222.980879 102.785509 
L 223.46472 105.037605 
L 225.300373 113.508649 
L 235.688519 147.224315 
L 239.209753 150.194392 
L 242.657303 150.290755 
L 243.021379 150.163097 
L 246.396695 149.761181 
L 247.749533 149.733868 
L 250.304477 150.288043 
L 253.49417 151.894891 
L 265.216288 153.455429 
L 265.691028 153.16907 
L 265.846581 153.15828 
L 269.383558 151.690354 
L 280.361517 154.001047 
L 280.639933 154.188717 
L 280.725237 154.121706 
L 294.221777 135.797586 
L 294.422735 135.106513 
L 294.68154 134.155384 
L 295.003193 132.953307 
L 296.332831 127.818688 
L 301.874953 104.151126 
L 306.572355 84.732307 
L 309.898136 72.919304 
L 316.065808 56.590312 
L 316.291596 56.164032 
L 316.836921 55.217935 
L 320.490073 49.937721 
L 322.354189 48.323515 
L 331.6266 47.514887 
L 334.579475 47.560436 
L 334.915237 47.40786 
L 335.905367 47.222987 
L 339.398349 45.69361 
L 344.526531 41.395831 
L 346.08583 40.264796 
L 358.60318 44.390744 
L 361.862697 50.661525 
L 366.333679 61.314053 
L 369.82946 70.748134 
" clip-path="url(#pcc6c9320a5)" style="fill: none; stroke: #7f7f7f; stroke-width: 1.5; stroke-linecap: round"/>
   </g>
   <g id="line2d_21">
    <path d="M 45.174915 91.960882 
L 47.112558 92.213094 
L 48.10218 92.935857 
L 51.57324 98.396028 
L 52.393348 100.39458 
L 56.777699 112.642086 
L 63.056619 135.209521 
L 68.831813 158.549191 
L 72.601242 173.900734 
L 73.310544 176.770728 
L 73.467091 177.274298 
L 74.506077 181.39375 
L 80.468866 200.973871 
L 82.95637 206.842984 
L 85.796974 211.482802 
L 92.711354 211.405115 
L 101.633421 192.349582 
L 103.76435 186.892455 
L 105.462089 182.740885 
L 105.963179 181.571019 
L 109.024091 175.147561 
L 115.702999 164.925098 
L 116.502559 163.779105 
L 125.581936 146.74533 
L 130.732684 131.43441 
L 130.845577 131.072718 
L 136.888796 112.225336 
L 139.571659 105.781115 
L 139.891121 105.156052 
L 141.461528 102.337308 
L 141.693302 101.997177 
L 144.628659 99.059614 
L 145.870273 98.61367 
L 149.622474 99.801034 
L 150.104534 100.331056 
L 152.786482 102.9584 
L 155.103911 106.006468 
L 155.388051 106.411193 
L 158.625714 110.788842 
L 161.318754 114.664166 
L 164.893846 119.861238 
L 170.583714 129.770615 
L 173.570944 136.307185 
L 178.633102 148.031676 
L 181.602361 153.770753 
L 189.649773 154.935415 
L 189.847152 154.616038 
L 193.231089 147.271298 
L 194.421217 143.68362 
L 195.025779 141.698244 
L 197.277167 134.145368 
L 211.88137 112.905009 
L 212.31209 113.611339 
L 212.417572 113.77818 
L 214.250456 118.085974 
L 215.534774 121.930092 
L 217.039392 126.725871 
L 221.676286 143.844733 
L 222.980879 148.593846 
L 223.46472 150.202566 
L 225.300373 156.424989 
L 235.688519 177.948275 
L 239.209753 181.931056 
L 242.657303 185.364573 
L 243.021379 185.637187 
L 246.396695 188.70968 
L 247.749533 189.759655 
L 250.304477 190.701257 
L 253.49417 190.351671 
L 265.216288 164.665467 
L 265.691028 163.148969 
L 265.846581 162.693617 
L 269.383558 150.456671 
L 280.361517 129.094816 
L 280.639933 128.938837 
L 280.725237 128.921266 
L 294.221777 146.422845 
L 294.422735 146.801805 
L 294.68154 147.304136 
L 295.003193 147.937443 
L 296.332831 150.669753 
L 301.874953 161.228474 
L 306.572355 168.455201 
L 309.898136 172.083088 
L 316.065808 176.221348 
L 316.291596 176.483058 
L 316.836921 176.796319 
L 320.490073 178.875943 
L 322.354189 180.122688 
L 331.6266 187.363279 
L 334.579475 187.654933 
L 334.915237 187.730828 
L 335.905367 187.250522 
L 339.398349 183.98065 
L 344.526531 174.126912 
L 346.08583 170.249332 
L 358.60318 139.083102 
L 361.862697 133.132867 
L 366.333679 127.063586 
L 369.82946 124.261537 
" clip-path="url(#pcc6c9320a5)" style="fill: none; stroke: #bcbd22; stroke-width: 1.5; stroke-linecap: round"/>
   </g>
   <g id="line2d_22">
    <path d="M 45.174915 200.392277 
L 47.112558 202.307643 
L 48.10218 203.036147 
L 51.57324 204.331042 
L 52.393348 204.500161 
L 56.777699 204.278505 
L 63.056619 203.091655 
L 68.831813 198.281605 
L 72.601242 189.941266 
L 73.310544 187.751028 
L 73.467091 187.205041 
L 74.506077 183.555121 
L 80.468866 156.48292 
L 82.95637 143.343391 
L 85.796974 129.079162 
L 92.711354 103.70018 
L 101.633421 95.406083 
L 103.76435 95.78017 
L 105.462089 96.681164 
L 105.963179 96.926431 
L 109.024091 99.008131 
L 115.702999 106.27516 
L 116.502559 107.367049 
L 125.581936 122.042051 
L 130.732684 130.518233 
L 130.845577 130.769672 
L 136.888796 139.586122 
L 139.571659 142.542768 
L 139.891121 142.83102 
L 141.461528 143.847111 
L 141.693302 144.040866 
L 144.628659 143.828851 
L 145.870273 142.911992 
L 149.622474 135.998189 
L 150.104534 134.65067 
L 152.786482 124.947001 
L 155.103911 114.265742 
L 155.388051 112.80229 
L 158.625714 94.430533 
L 161.318754 77.850054 
L 164.893846 56.549914 
L 170.583714 30.038729 
L 173.570944 22.114611 
L 178.633102 19.296 
L 181.602361 23.926988 
L 189.649773 54.368753 
L 189.847152 55.393744 
L 193.231089 72.71929 
L 194.421217 78.949759 
L 195.025779 82.048818 
L 197.277167 93.263385 
L 211.88137 141.446755 
L 212.31209 142.357399 
L 212.417572 142.537513 
L 214.250456 145.653044 
L 215.534774 147.50916 
L 217.039392 149.381917 
L 221.676286 151.154639 
L 222.980879 150.527457 
L 223.46472 150.132218 
L 225.300373 147.862452 
L 235.688519 121.11554 
L 239.209753 113.780902 
L 242.657303 111.133731 
L 243.021379 111.233129 
L 246.396695 114.27371 
L 247.749533 116.779181 
L 250.304477 122.918251 
L 253.49417 132.159419 
L 265.216288 156.055274 
L 265.691028 156.397995 
L 265.846581 156.266946 
L 269.383558 156.836767 
L 280.361517 153.750669 
L 280.639933 153.890691 
L 280.725237 153.944902 
L 294.221777 176.596305 
L 294.422735 177.077301 
L 294.68154 177.568882 
L 295.003193 178.472527 
L 296.332831 181.541127 
L 301.874953 192.355613 
L 306.572355 197.539439 
L 309.898136 199.026549 
L 316.065808 197.712588 
L 316.291596 197.449259 
L 316.836921 197.176026 
L 320.490073 193.446579 
L 322.354189 190.634906 
L 331.6266 168.508761 
L 334.579475 159.359147 
L 334.915237 158.333324 
L 335.905367 155.256584 
L 339.398349 144.860291 
L 344.526531 133.346239 
L 346.08583 131.040972 
L 358.60318 128.534083 
L 361.862697 129.407816 
L 366.333679 129.267954 
L 369.82946 128.892449 
" clip-path="url(#pcc6c9320a5)" style="fill: none; stroke: #17becf; stroke-width: 1.5; stroke-linecap: round"/>
   </g>
   <g id="patch_3">
    <path d="M 28.942188 273.312 
L 28.942188 7.2 
" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="patch_4">
    <path d="M 386.062188 273.312 
L 386.062188 7.2 
" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="patch_5">
    <path d="M 28.942187 273.312 
L 386.062187 273.312 
" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="patch_6">
    <path d="M 28.942187 7.2 
L 386.062187 7.2 
" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
  </g>
 </g>
 <defs>
  <clipPath id="pcc6c9320a5">
   <rect x="28.942188" y="7.2" width="357.12" height="266.112"/>
  </clipPath>
 </defs>
</svg>
"/>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [230]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="n">K_ss</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[230]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>()</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>Here we add the test data to comupte the posterior. Not anymore zero mean after posterior. compare to the
$$
\mathbf{\mu}_{\mathbf{*}}\mathbf{= \ \mu}\left( \mathbf{X}_{\mathbf{*}} \right)\mathbf{+}\mathbf{K}_{\mathbf{*}}^{\mathbf{T}}\mathbf{K}^{\mathbf{- 1}}\mathbf{(f - \mu}\left( \mathbf{X} \right)\mathbf{)}\tag{15.8}
$$		
$$
\mathbf{\Sigma}_{\mathbf{*}}\mathbf{=}\mathbf{K}_{\mathbf{**\ }}\mathbf{-}\mathbf{K}_{\mathbf{*}}^{\mathbf{T}}\mathbf{K}^{\mathbf{- 1}}\mathbf{K}_{\mathbf{*}}\tag{15.9}
$$
and the algorithm
\begin{aligned}
&amp; \overline{f_*}=\mathbf{k}_*^T \mathbf{K}_y^{-1} \mathbf{y}\\
&amp; \mathbf{K}_y=\mathbf{L L}^T \\
&amp; \boldsymbol{\alpha}=\mathbf{K}_y^{-1} \mathbf{y}=\mathbf{L}^{-T} \mathbf{L}^{-1} \mathbf{y}
\end{aligned}</p>
<p>$$
\begin{array}{ll}
\hline \text { Algorithm 15.l: GP regression } \\
\hline 1 &amp; \mathbf{L}=\text { cholesky }\left(\mathbf{K}+\sigma_y^2 \mathbf{I}\right) ; \\
2 &amp; \boldsymbol{\alpha}=\mathbf{L}^T \backslash(\mathbf{L} \backslash \mathbf{y}) ; \\
3 &amp; \mathbb{E}\left[f_*\right]=\mathbf{k}_*^T \boldsymbol{\alpha} ; \\
4 &amp; \mathbf{v}=\mathbf{L} \backslash \mathbf{k}_* ; \\
5 &amp; \operatorname{var}\left[f_*\right]=\kappa\left(\mathbf{x}_* \cdot \mathbf{x}_*\right)-\mathbf{v}^T \mathbf{v} ; \\
6 &amp; \log p(\mathbf{y} \mid \mathbf{X})=-\frac{1}{2} \mathbf{y}^T \boldsymbol{\alpha}-\sum_i \log L_{i i}-\frac{N}{2} \log (2 \pi) \\
\hline
\end{array}
$$</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="n">K</span> <span class="o">=</span> <span class="n">kernel</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
<span class="n">L</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cholesky</span><span class="p">(</span><span class="n">K</span><span class="p">)</span>
<span class="n">m</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">L</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">alpha</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">L</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span>
<span class="n">K_s</span> <span class="o">=</span> <span class="n">kernel</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Xtest</span><span class="p">)</span>
<span class="n">mu</span> <span class="o">=</span> <span class="n">K_s</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">alpha</span>
<span class="n">K_ss</span> <span class="o">=</span> <span class="n">kernel</span><span class="p">(</span><span class="n">Xtest</span><span class="p">,</span> <span class="n">Xtest</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-8</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">Xtest</span><span class="p">))</span> <span class="c1">#after adding 1e-8 * np.eye(len(Xtest)), the L_ss can be computed. so adding some very small number make the K_ss postive???</span>
<span class="n">L_ss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cholesky</span><span class="p">(</span><span class="n">K_ss</span><span class="p">)</span>  <span class="c1"># this is always cannot be solved (Matrix is not positive definite), why?</span>
<span class="n">beta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">K</span><span class="p">,</span> <span class="n">K_s</span><span class="p">)</span>
<span class="n">cov</span> <span class="o">=</span> <span class="n">K_ss</span> <span class="o">-</span> <span class="n">K_s</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">beta</span>
<span class="n">L_cov</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cholesky</span><span class="p">(</span><span class="n">cov</span><span class="p">)</span>
<span class="n">f_posterior</span> <span class="o">=</span> <span class="n">mu</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">L_cov</span> <span class="o">@</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">n_samples</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">"black"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">Xtest</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s2">"red"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">Xtest</span><span class="p">,</span> <span class="n">f_posterior</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s2">"gray"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">Xtest</span><span class="p">,</span> <span class="n">f</span><span class="p">(</span><span class="n">Xtest</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="s2">"green"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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
"/>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="kn">from</span> <span class="nn">numpy.linalg</span> <span class="kn">import</span> <span class="n">inv</span>
<span class="kn">from</span> <span class="nn">numpy.linalg</span> <span class="kn">import</span> <span class="n">cholesky</span>

<span class="k">def</span> <span class="nf">posterior_predictive</span><span class="p">(</span><span class="n">X_s</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">l</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">sigma_f</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">sigma_y</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">):</span>
<span class="w">    </span><span class="sd">''' Computes the suffifient statistics of the GP posterior predictive distribution from m training data X_train and Y_train </span>
<span class="sd">    and n new inputs X_s. Args: X_s: New input locations (n x d). X_train: Training locations (m x d). Y_train: Training targets (m x 1).</span>
<span class="sd">    l: Kernel length parameter. sigma_f: Kernel vertical variation parameter. sigma_y: Noise parameter. </span>
<span class="sd">    Returns: Posterior mean vector (n x d) and covariance matrix (n x n). '''</span>
    <span class="n">K</span> <span class="o">=</span> <span class="n">kernel_advance</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">l</span><span class="p">,</span> <span class="n">sigma_f</span><span class="p">)</span> <span class="o">+</span> <span class="n">sigma_y</span><span class="o">**</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">))</span> <span class="c1">#add the noise variance...sigma_y**2 * np.eye(len(X_train)</span>
    <span class="n">K_s</span> <span class="o">=</span> <span class="n">kernel_advance</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_s</span><span class="p">,</span> <span class="n">l</span><span class="p">,</span> <span class="n">sigma_f</span><span class="p">)</span>
    <span class="n">K_ss</span> <span class="o">=</span> <span class="n">kernel_advance</span><span class="p">(</span><span class="n">X_s</span><span class="p">,</span> <span class="n">X_s</span><span class="p">,</span> <span class="n">l</span><span class="p">,</span> <span class="n">sigma_f</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-8</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X_s</span><span class="p">))</span>
    <span class="n">L_ss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cholesky</span><span class="p">(</span><span class="n">K_ss</span><span class="p">)</span>
    <span class="n">K_inv</span> <span class="o">=</span> <span class="n">inv</span><span class="p">(</span><span class="n">K</span><span class="p">)</span>
    
    <span class="c1"># Equation (4)</span>
    <span class="n">mu_s</span> <span class="o">=</span> <span class="n">K_s</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">K_inv</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Y_train</span><span class="p">)</span>

    <span class="c1"># Equation (5)</span>
    <span class="n">cov_s</span> <span class="o">=</span> <span class="n">K_ss</span> <span class="o">-</span> <span class="n">K_s</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">K_inv</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">K_s</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">mu_s</span><span class="p">,</span> <span class="n">cov_s</span> 

<span class="n">mu_s</span><span class="p">,</span> <span class="n">cov_s</span> <span class="o">=</span> <span class="n">posterior_predictive</span><span class="p">(</span><span class="n">Xtest</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span><span class="n">l</span><span class="o">=</span><span class="p">(</span><span class="mf">0.1</span><span class="o">**</span><span class="mf">0.5</span><span class="p">),</span> <span class="n">sigma_f</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

<span class="n">L_cov</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cholesky</span><span class="p">(</span><span class="n">cov_s</span><span class="p">)</span>
<span class="n">f_posterior</span> <span class="o">=</span> <span class="n">mu</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">L_cov</span> <span class="o">@</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">n_samples</span><span class="p">))</span>
<span class="n">f</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mf">0.9</span> <span class="o">*</span> <span class="n">x</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">"black"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">Xtest</span><span class="p">,</span> <span class="n">mu_s</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s2">"red"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">Xtest</span><span class="p">,</span> <span class="n">f_posterior</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s2">"gray"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">Xtest</span><span class="p">,</span> <span class="n">f</span><span class="p">(</span><span class="n">Xtest</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="s2">"green"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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
"/>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>Different approach</p>
<p>\begin{aligned}
&amp; \overline{f_*}=\mathbf{K}_*^T \mathbf{K}_y^{-1} \mathbf{y}\\
&amp; \mathbf{K}_y=\mathbf{L L}^T \\
&amp; \boldsymbol{LK}=\mathbf{K_*}_y \mathbf{L^{-1}}
\end{aligned}</p>
<p>$$
\begin{array}{ll}
\hline \text { Algorithm } \\
\hline 1 &amp; \mathbf{L}=\text { cholesky }\left(\mathbf{K}+\sigma_y^2 \mathbf{I}\right) ; \\
2 &amp; \boldsymbol{LK}=\mathbf{K_*}_y \mathbf{L^{-1}} ; \\
3 &amp; \mathbb{E}\left[f_*\right]=(\boldsymbol{LK})^T \boldsymbol{yL^{-1}} = \frac{K_*^T}{L^T} \frac{y}{L} =K_*^TyK_y^{-1} ; \\
4 &amp; \mathbf{v}=\mathbf{L} \backslash \mathbf{k}_* ;  \\
5 &amp; \operatorname{var}\left[f_*\right]=\kappa\left(\mathbf{x}_* \cdot \mathbf{x}_*\right)-\mathbf{v}^T \mathbf{v} ; \\
6 &amp; \log p(\mathbf{y} \mid \mathbf{X})=-\frac{1}{2} \mathbf{y}^T \boldsymbol{\alpha}-\sum_i \log L_{i i}-\frac{N}{2} \log (2 \pi) \\
\hline
\end{array}
$$</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="n">N</span><span class="p">,</span> <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">Xtest</span><span class="p">)</span>
<span class="n">K</span> <span class="o">=</span> <span class="n">kernel</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
<span class="n">L</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cholesky</span><span class="p">(</span><span class="n">K</span> <span class="o">+</span> <span class="n">noise_var</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">N</span><span class="p">))</span> <span class="c1">#add the noise variance...</span>
<span class="n">K_</span> <span class="o">=</span> <span class="n">kernel</span><span class="p">(</span><span class="n">Xtest</span><span class="p">,</span> <span class="n">Xtest</span><span class="p">)</span>           <span class="c1">#k**</span>
<span class="n">Lk</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">L</span><span class="p">,</span> <span class="n">kernel</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Xtest</span><span class="p">))</span>  <span class="c1">#LK =k*/L</span>
<span class="n">mu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Lk</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">L</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>   <span class="c1"># (k*T y)/LLT</span>
<span class="n">cov</span> <span class="o">=</span> <span class="n">K_</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Lk</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">Lk</span><span class="p">)</span>
<span class="n">L_cov</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cholesky</span><span class="p">(</span> <span class="n">cov</span> <span class="o">+</span> <span class="n">noise_var</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">n</span><span class="p">))</span>  <span class="c1">#add the noise variance...</span>
<span class="n">f_post</span> <span class="o">=</span> <span class="n">mu</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">L_cov</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">n_samples</span><span class="p">)))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">"red"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">Xtest</span><span class="p">,</span> <span class="n">f_post</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s2">"gray"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">Xtest</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s2">"blue"</span> <span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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
"/>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="k">def</span> <span class="nf">posterior</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Xtest</span><span class="p">,</span> <span class="n">l2</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">noise_var</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">,</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="c1"># compute the mean at our test points.</span>
    <span class="n">N</span><span class="p">,</span> <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">Xtest</span><span class="p">)</span>
    <span class="n">K</span> <span class="o">=</span> <span class="n">kernel</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">l2</span><span class="p">)</span> 
    <span class="n">L</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cholesky</span><span class="p">(</span><span class="n">K</span> <span class="o">+</span> <span class="n">noise_var</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">N</span><span class="p">))</span> <span class="c1">#add the noise variance...</span>
    <span class="n">Lk</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">L</span><span class="p">,</span> <span class="n">kernel</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Xtest</span><span class="p">,</span> <span class="n">l2</span><span class="p">))</span>  <span class="c1">#k*</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Lk</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">L</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>
    <span class="c1"># compute the variance at our test points.</span>
    <span class="n">K_</span> <span class="o">=</span> <span class="n">kernel</span><span class="p">(</span><span class="n">Xtest</span><span class="p">,</span> <span class="n">Xtest</span><span class="p">,</span> <span class="n">l2</span><span class="p">)</span> <span class="c1">#K**</span>
    <span class="n">sd</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">K_</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">Lk</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
    <span class="n">L</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cholesky</span><span class="p">(</span><span class="n">K_</span> <span class="o">+</span> <span class="n">noise_var</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Lk</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">Lk</span><span class="p">))</span> <span class="c1">#add the noise variance...</span>
    <span class="n">f_post</span> <span class="o">=</span> <span class="n">mu</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">L</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">n_samples</span><span class="p">)))</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">sd</span><span class="p">,</span> <span class="n">f_post</span><span class="p">)</span>

<span class="n">mu</span><span class="p">,</span> <span class="n">sd</span><span class="p">,</span> <span class="n">f_post</span> <span class="o">=</span> <span class="n">posterior</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Xtest</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="n">n_samples</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">"red"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">Xtest</span><span class="p">,</span> <span class="n">f_post</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">Xtest</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s2">"black"</span> <span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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
"/>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span><span class="n">xlim</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="c1"># Start plotting</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span> 
<span class="n">gs</span> <span class="o">=</span> <span class="n">gridspec</span><span class="o">.</span><span class="n">GridSpec</span><span class="p">(</span>
    <span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figure</span><span class="o">=</span><span class="n">fig</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.4</span><span class="p">)</span>
<span class="n">plot_kernel</span><span class="p">(</span>
    <span class="n">Xtest</span><span class="p">,</span> <span class="n">f_post</span><span class="p">,</span> <span class="n">L_cov</span><span class="p">,</span> <span class="s1">'$</span><span class="se">\\</span><span class="s1">ell = 0.1$, $</span><span class="se">\\</span><span class="s1">sigma = 0.5$'</span><span class="p">,</span> 
    <span class="n">fig</span><span class="p">,</span> <span class="n">gs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">xlim</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedSVG jp-OutputArea-output" data-mime-type="image/svg+xml" tabindex="0">
<img alt="No description has been provided for this image" src="data:image/svg+xml;base64,<?xml version="1.0" encoding="utf-8" standalone="no"?>
<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN"
  "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">
<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="479.317369pt" height="178.830572pt" viewBox="0 0 479.317369 178.830572" xmlns="http://www.w3.org/2000/svg" version="1.1">
 <metadata>
  <rdf:RDF xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:cc="http://creativecommons.org/ns#" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#">
   <cc:Work>
    <dc:type rdf:resource="http://purl.org/dc/dcmitype/StillImage"/>
    <dc:date>2023-05-11T07:15:47.159506</dc:date>
    <dc:format>image/svg+xml</dc:format>
    <dc:creator>
     <cc:Agent>
      <dc:title>Matplotlib v3.7.1, https://matplotlib.org/</dc:title>
     </cc:Agent>
    </dc:creator>
   </cc:Work>
  </rdf:RDF>
 </metadata>
 <defs>
  <style type="text/css">*{stroke-linejoin: round; stroke-linecap: butt}</style>
 </defs>
 <g id="figure_1">
  <g id="patch_1">
   <path d="M 0 178.830572 
L 479.317369 178.830572 
L 479.317369 0 
L 0 0 
z
" style="fill: #ffffff"/>
  </g>
  <g id="axes_1">
   <g id="patch_2">
    <path d="M 41.52375 142.370885 
L 280.422833 142.370885 
L 280.422833 35.7555 
L 41.52375 35.7555 
z
" style="fill: #eaeaf2"/>
   </g>
   <g id="matplotlib.axis_1">
    <g id="xtick_1">
     <g id="line2d_1">
      <path d="M 41.52375 142.370885 
L 41.52375 35.7555 
" clip-path="url(#pb7e17334f2)" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round"/>
     </g>
     <g id="text_1">
      <!-- −4 -->
      <g style="fill: #262626" transform="translate(34.152656 156.969322) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-2212" d="M 678 2272 
L 4684 2272 
L 4684 1741 
L 678 1741 
L 678 2272 
z
" transform="scale(0.015625)"/>
        <path id="DejaVuSans-34" d="M 2419 4116 
L 825 1625 
L 2419 1625 
L 2419 4116 
z
M 2253 4666 
L 3047 4666 
L 3047 1625 
L 3713 1625 
L 3713 1100 
L 3047 1100 
L 3047 0 
L 2419 0 
L 2419 1100 
L 313 1100 
L 313 1709 
L 2253 4666 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-2212"/>
       <use xlink:href="#DejaVuSans-34" x="83.789062"/>
      </g>
     </g>
    </g>
    <g id="xtick_2">
     <g id="line2d_2">
      <path d="M 101.248521 142.370885 
L 101.248521 35.7555 
" clip-path="url(#pb7e17334f2)" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round"/>
     </g>
     <g id="text_2">
      <!-- −2 -->
      <g style="fill: #262626" transform="translate(93.877427 156.969322) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-32" d="M 1228 531 
L 3431 531 
L 3431 0 
L 469 0 
L 469 531 
Q 828 903 1448 1529 
Q 2069 2156 2228 2338 
Q 2531 2678 2651 2914 
Q 2772 3150 2772 3378 
Q 2772 3750 2511 3984 
Q 2250 4219 1831 4219 
Q 1534 4219 1204 4116 
Q 875 4013 500 3803 
L 500 4441 
Q 881 4594 1212 4672 
Q 1544 4750 1819 4750 
Q 2544 4750 2975 4387 
Q 3406 4025 3406 3419 
Q 3406 3131 3298 2873 
Q 3191 2616 2906 2266 
Q 2828 2175 2409 1742 
Q 1991 1309 1228 531 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-2212"/>
       <use xlink:href="#DejaVuSans-32" x="83.789062"/>
      </g>
     </g>
    </g>
    <g id="xtick_3">
     <g id="line2d_3">
      <path d="M 160.973291 142.370885 
L 160.973291 35.7555 
" clip-path="url(#pb7e17334f2)" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round"/>
     </g>
     <g id="text_3">
      <!-- 0 -->
      <g style="fill: #262626" transform="translate(157.792041 156.969322) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-30" d="M 2034 4250 
Q 1547 4250 1301 3770 
Q 1056 3291 1056 2328 
Q 1056 1369 1301 889 
Q 1547 409 2034 409 
Q 2525 409 2770 889 
Q 3016 1369 3016 2328 
Q 3016 3291 2770 3770 
Q 2525 4250 2034 4250 
z
M 2034 4750 
Q 2819 4750 3233 4129 
Q 3647 3509 3647 2328 
Q 3647 1150 3233 529 
Q 2819 -91 2034 -91 
Q 1250 -91 836 529 
Q 422 1150 422 2328 
Q 422 3509 836 4129 
Q 1250 4750 2034 4750 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-30"/>
      </g>
     </g>
    </g>
    <g id="xtick_4">
     <g id="line2d_4">
      <path d="M 220.698062 142.370885 
L 220.698062 35.7555 
" clip-path="url(#pb7e17334f2)" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round"/>
     </g>
     <g id="text_4">
      <!-- 2 -->
      <g style="fill: #262626" transform="translate(217.516812 156.969322) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-32"/>
      </g>
     </g>
    </g>
    <g id="xtick_5">
     <g id="line2d_5">
      <path d="M 280.422833 142.370885 
L 280.422833 35.7555 
" clip-path="url(#pb7e17334f2)" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round"/>
     </g>
     <g id="text_5">
      <!-- 4 -->
      <g style="fill: #262626" transform="translate(277.241583 156.969322) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-34"/>
      </g>
     </g>
    </g>
    <g id="text_6">
     <!-- $x$ -->
     <g style="fill: #262626" transform="translate(157.073291 168.926978) scale(0.13 -0.13)">
      <defs>
       <path id="DejaVuSans-Oblique-78" d="M 3841 3500 
L 2234 1784 
L 3219 0 
L 2559 0 
L 1819 1388 
L 531 0 
L -166 0 
L 1556 1844 
L 641 3500 
L 1300 3500 
L 1972 2234 
L 3144 3500 
L 3841 3500 
z
" transform="scale(0.015625)"/>
      </defs>
      <use xlink:href="#DejaVuSans-Oblique-78" transform="translate(0 0.3125)"/>
     </g>
    </g>
   </g>
   <g id="matplotlib.axis_2">
    <g id="ytick_1">
     <g id="line2d_6">
      <path d="M 41.52375 136.360006 
L 280.422833 136.360006 
" clip-path="url(#pb7e17334f2)" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round"/>
     </g>
     <g id="text_7">
      <!-- −2 -->
      <g style="fill: #262626" transform="translate(19.781563 140.159224) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-2212"/>
       <use xlink:href="#DejaVuSans-32" x="83.789062"/>
      </g>
     </g>
    </g>
    <g id="ytick_2">
     <g id="line2d_7">
      <path d="M 41.52375 96.144055 
L 280.422833 96.144055 
" clip-path="url(#pb7e17334f2)" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round"/>
     </g>
     <g id="text_8">
      <!-- 0 -->
      <g style="fill: #262626" transform="translate(28.16125 99.943274) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-30"/>
      </g>
     </g>
    </g>
    <g id="ytick_3">
     <g id="line2d_8">
      <path d="M 41.52375 55.928105 
L 280.422833 55.928105 
" clip-path="url(#pb7e17334f2)" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round"/>
     </g>
     <g id="text_9">
      <!-- 2 -->
      <g style="fill: #262626" transform="translate(28.16125 59.727323) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-32"/>
      </g>
     </g>
    </g>
    <g id="text_10">
     <!-- $y$ -->
     <g style="fill: #262626" transform="translate(17.051563 92.963192) rotate(-90) scale(0.13 -0.13)">
      <defs>
       <path id="DejaVuSans-Oblique-79" d="M 1588 -325 
Q 1188 -997 936 -1164 
Q 684 -1331 294 -1331 
L -159 -1331 
L -63 -850 
L 269 -850 
Q 509 -850 678 -719 
Q 847 -588 1056 -206 
L 1234 128 
L 459 3500 
L 1069 3500 
L 1650 819 
L 3256 3500 
L 3859 3500 
L 1588 -325 
z
" transform="scale(0.015625)"/>
      </defs>
      <use xlink:href="#DejaVuSans-Oblique-79" transform="translate(0 0.3125)"/>
     </g>
    </g>
   </g>
   <g id="line2d_9">
    <path d="M 72.709956 111.637865 
L 73.770954 111.06238 
L 74.312843 110.641231 
L 76.213496 108.689823 
L 76.662564 108.172363 
L 79.06331 105.754265 
L 82.501467 106.005817 
L 85.663799 111.509524 
L 87.727831 116.743638 
L 88.116224 117.703212 
L 88.201945 117.899769 
L 88.770864 119.249421 
L 92.035917 124.077996 
L 93.398003 124.054003 
L 94.953437 122.43819 
L 98.739555 113.662411 
L 103.625024 103.456932 
L 104.79186 102.469082 
L 105.721493 102.135709 
L 105.995876 102.083125 
L 107.671944 102.511603 
L 111.329124 106.09144 
L 111.76694 106.666818 
L 116.738548 113.323483 
L 119.558951 115.89814 
L 119.620768 115.906345 
L 122.929863 116.411697 
L 124.398922 115.641418 
L 124.57385 115.562377 
L 125.43376 114.841173 
L 125.560673 114.715892 
L 127.167991 113.046484 
L 127.847863 112.23497 
L 129.902461 109.466859 
L 130.166424 109.083654 
L 131.634982 107.057799 
L 132.90394 105.234354 
L 133.059527 104.983334 
L 134.832379 102.614557 
L 136.307011 100.772328 
L 138.264629 98.443865 
L 141.380239 95.604177 
L 143.015961 94.668959 
L 145.787854 94.311 
L 147.413736 94.864752 
L 151.820269 98.8134 
L 151.928348 98.890233 
L 153.781296 100.941973 
L 154.432976 101.600456 
L 154.764017 101.914955 
L 155.996813 102.976161 
L 163.993658 101.350166 
L 164.229508 100.9753 
L 164.287267 100.920358 
L 165.290902 99.2375 
L 165.994158 97.912398 
L 166.818044 96.159351 
L 169.357074 89.86841 
L 170.071433 87.968494 
L 170.33637 87.276724 
L 171.341521 84.726261 
L 177.029774 75.672747 
L 178.957901 75.513322 
L 180.845681 76.403399 
L 181.045039 76.501529 
L 182.893266 77.902625 
L 183.634041 78.577308 
L 185.033056 79.63255 
L 186.779641 80.896256 
L 193.198338 82.432767 
L 193.458293 82.390747 
L 193.543469 82.378626 
L 195.480216 81.500706 
L 201.491434 76.628132 
L 201.643886 76.522284 
L 201.690597 76.483569 
L 209.080917 76.045757 
L 209.190956 76.144193 
L 209.33267 76.234566 
L 209.508798 76.342886 
L 210.23687 76.878132 
L 213.271578 79.525587 
L 215.843742 81.178573 
L 217.664844 81.275681 
L 221.042086 77.932623 
L 221.165721 77.811875 
L 221.464325 77.260744 
L 223.464687 73.560371 
L 224.485424 71.575067 
L 229.562731 67.077243 
L 231.179642 68.621482 
L 231.363496 68.936177 
L 231.905663 69.89125 
L 233.81832 74.407452 
L 236.626366 82.734494 
L 237.480194 85.166616 
L 244.334338 91.120687 
L 246.119157 87.923955 
L 248.567339 81.864963 
L 250.481529 77.431026 
" clip-path="url(#pb7e17334f2)" style="fill: none; stroke: #1f77b4; stroke-opacity: 0.8; stroke-width: 1.5; stroke-linecap: round"/>
   </g>
   <g id="line2d_10">
    <path d="M 72.709956 76.437304 
L 73.770954 78.979765 
L 74.312843 80.38168 
L 76.213496 85.746379 
L 76.662564 87.134932 
L 79.06331 95.018923 
L 82.501467 106.077516 
L 85.663799 113.641808 
L 87.727831 116.664091 
L 88.116224 117.116746 
L 88.201945 117.160391 
L 88.770864 117.616159 
L 92.035917 118.531606 
L 93.398003 118.157873 
L 94.953437 117.317765 
L 98.739555 113.686789 
L 103.625024 106.02694 
L 104.79186 103.859266 
L 105.721493 102.103973 
L 105.995876 101.614798 
L 107.671944 98.887226 
L 111.329124 96.906915 
L 111.76694 97.19015 
L 116.738548 108.048525 
L 119.558951 115.809178 
L 119.620768 115.934992 
L 122.929863 118.9843 
L 124.398922 117.368422 
L 124.57385 117.017709 
L 125.43376 115.069227 
L 125.560673 114.76814 
L 127.167991 109.70255 
L 127.847863 107.230796 
L 129.902461 99.099865 
L 130.166424 98.071753 
L 131.634982 92.523206 
L 132.90394 88.472103 
L 133.059527 88.016882 
L 134.832379 84.142918 
L 136.307011 82.60411 
L 138.264629 83.098051 
L 141.380239 88.300979 
L 143.015961 92.07996 
L 145.787854 98.14626 
L 147.413736 100.760469 
L 151.820269 102.724599 
L 151.928348 102.688807 
L 153.781296 100.907697 
L 154.432976 99.872081 
L 154.764017 99.29564 
L 155.996813 96.612191 
L 163.993658 70.261879 
L 164.229508 69.648179 
L 164.287267 69.485123 
L 165.290902 67.257835 
L 165.994158 66.155176 
L 166.818044 65.398058 
L 169.357074 66.496773 
L 170.071433 67.697458 
L 170.33637 68.330574 
L 171.341521 70.752421 
L 177.029774 87.387578 
L 178.957901 90.159481 
L 180.845681 90.296373 
L 181.045039 90.157424 
L 182.893266 88.034976 
L 183.634041 86.772137 
L 185.033056 84.151193 
L 186.779641 80.891905 
L 193.198338 76.487756 
L 193.458293 76.57799 
L 193.543469 76.596675 
L 195.480216 77.367557 
L 201.491434 76.592319 
L 201.643886 76.432059 
L 201.690597 76.403191 
L 209.080917 76.050612 
L 209.190956 76.180028 
L 209.33267 76.287874 
L 209.508798 76.465272 
L 210.23687 77.278585 
L 213.271578 80.430488 
L 215.843742 81.369045 
L 217.664844 80.723435 
L 221.042086 77.936829 
L 221.165721 77.850925 
L 221.464325 77.614024 
L 223.464687 76.392839 
L 224.485424 76.090412 
L 229.562731 76.904627 
L 231.179642 77.716836 
L 231.363496 77.796563 
L 231.905663 78.119393 
L 233.81832 79.69615 
L 236.626366 83.518361 
L 237.480194 85.151972 
L 244.334338 103.584627 
L 246.119157 108.114092 
L 248.567339 112.970985 
L 250.481529 115.467659 
" clip-path="url(#pb7e17334f2)" style="fill: none; stroke: #ff7f0e; stroke-opacity: 0.8; stroke-width: 1.5; stroke-linecap: round"/>
   </g>
   <g id="line2d_11">
    <path d="M 72.709956 95.027909 
L 73.770954 97.28108 
L 74.312843 98.312059 
L 76.213496 101.110034 
L 76.662564 101.627812 
L 79.06331 103.747252 
L 82.501467 106.024985 
L 85.663799 108.429338 
L 87.727831 110.265901 
L 88.116224 110.550715 
L 88.201945 110.703717 
L 88.770864 111.180871 
L 92.035917 113.764952 
L 93.398003 114.473392 
L 94.953437 114.941411 
L 98.739555 113.645241 
L 103.625024 108.368031 
L 104.79186 107.080924 
L 105.721493 106.200858 
L 105.995876 106.002061 
L 107.671944 105.017678 
L 111.329124 105.601958 
L 111.76694 105.954415 
L 116.738548 112.16853 
L 119.558951 115.852524 
L 119.620768 115.939315 
L 122.929863 117.219846 
L 124.398922 116.245703 
L 124.57385 116.031901 
L 125.43376 114.962838 
L 125.560673 114.763835 
L 127.167991 111.987918 
L 127.847863 110.60948 
L 129.902461 106.136048 
L 130.166424 105.576009 
L 131.634982 102.526348 
L 132.90394 100.201458 
L 133.059527 99.927706 
L 134.832379 97.338674 
L 136.307011 95.817271 
L 138.264629 94.756366 
L 141.380239 95.406452 
L 143.015961 96.67907 
L 145.787854 99.715529 
L 147.413736 101.242085 
L 151.820269 101.911981 
L 151.928348 101.863236 
L 153.781296 100.892242 
L 154.432976 100.555843 
L 154.764017 100.381354 
L 155.996813 99.909831 
L 163.993658 107.710136 
L 164.229508 108.08192 
L 164.287267 108.124073 
L 165.290902 109.623369 
L 165.994158 110.485088 
L 166.818044 111.358374 
L 169.357074 112.700503 
L 170.071433 112.680732 
L 170.33637 112.655604 
L 171.341521 112.383298 
L 177.029774 107.785775 
L 178.957901 104.946633 
L 180.845681 101.115605 
L 181.045039 100.627862 
L 182.893266 95.419287 
L 183.634041 92.928554 
L 185.033056 87.78507 
L 186.779641 80.848759 
L 193.198338 63.374172 
L 193.458293 63.278065 
L 193.543469 63.273275 
L 195.480216 64.215136 
L 201.491434 76.192147 
L 201.643886 76.451962 
L 201.690597 76.547159 
L 209.080917 76.060825 
L 209.190956 75.962636 
L 209.33267 75.787048 
L 209.508798 75.539986 
L 210.23687 74.618344 
L 213.271578 71.840389 
L 215.843742 71.976618 
L 217.664844 73.460601 
L 221.042086 77.984033 
L 221.165721 78.11716 
L 221.464325 78.602758 
L 223.464687 81.424854 
L 224.485424 82.773281 
L 229.562731 87.831961 
L 231.179642 88.720815 
L 231.363496 88.750944 
L 231.905663 88.922836 
L 233.81832 88.891664 
L 236.626366 86.478105 
L 237.480194 85.14327 
L 244.334338 65.990155 
L 246.119157 59.761112 
L 248.567339 51.750494 
L 250.481529 46.481478 
" clip-path="url(#pb7e17334f2)" style="fill: none; stroke: #2ca02c; stroke-opacity: 0.8; stroke-width: 1.5; stroke-linecap: round"/>
   </g>
   <g id="line2d_12">
    <path d="M 72.709956 83.667088 
L 73.770954 84.760065 
L 74.312843 85.537469 
L 76.213496 88.976587 
L 76.662564 90.011162 
L 79.06331 96.166829 
L 82.501467 106.011762 
L 85.663799 113.28735 
L 87.727831 116.095694 
L 88.116224 116.412145 
L 88.201945 116.527616 
L 88.770864 116.910835 
L 92.035917 116.997042 
L 93.398003 116.468045 
L 94.953437 115.636302 
L 98.739555 113.724577 
L 103.625024 111.131154 
L 104.79186 110.555007 
L 105.721493 110.171376 
L 105.995876 110.07825 
L 107.671944 109.668336 
L 111.329124 110.660629 
L 111.76694 110.88458 
L 116.738548 114.537102 
L 119.558951 115.964508 
L 119.620768 115.971807 
L 122.929863 116.050231 
L 124.398922 115.484844 
L 124.57385 115.372697 
L 125.43376 114.815233 
L 125.560673 114.706949 
L 127.167991 113.356986 
L 127.847863 112.670869 
L 129.902461 110.377632 
L 130.166424 110.122627 
L 131.634982 108.55235 
L 132.90394 107.453675 
L 133.059527 107.309541 
L 134.832379 106.357337 
L 136.307011 106.057386 
L 138.264629 106.223317 
L 141.380239 106.831766 
L 143.015961 106.882736 
L 145.787854 105.939665 
L 147.413736 104.946213 
L 151.820269 102.112881 
L 151.928348 102.06746 
L 153.781296 100.925189 
L 154.432976 100.499031 
L 154.764017 100.314008 
L 155.996813 99.465534 
L 163.993658 94.831569 
L 164.229508 94.85453 
L 164.287267 94.811778 
L 165.290902 94.899544 
L 165.994158 95.01388 
L 166.818044 95.318267 
L 169.357074 96.220162 
L 170.071433 96.357981 
L 170.33637 96.431866 
L 171.341521 96.436967 
L 177.029774 93.469277 
L 178.957901 91.776095 
L 180.845681 89.980107 
L 181.045039 89.809735 
L 182.893266 87.572843 
L 183.634041 86.573985 
L 185.033056 84.274797 
L 186.779641 80.873763 
L 193.198338 69.68217 
L 193.458293 69.51875 
L 193.543469 69.449152 
L 195.480216 69.45917 
L 201.491434 76.308941 
L 201.643886 76.504975 
L 201.690597 76.52857 
L 209.080917 76.058045 
L 209.190956 75.971789 
L 209.33267 75.947689 
L 209.508798 75.841988 
L 210.23687 75.561707 
L 213.271578 75.639578 
L 215.843742 76.842524 
L 217.664844 77.637917 
L 221.042086 78.001272 
L 221.165721 77.936234 
L 221.464325 77.844686 
L 223.464687 77.393311 
L 224.485424 77.252604 
L 229.562731 79.723479 
L 231.179642 81.776297 
L 231.363496 82.028785 
L 231.905663 82.731649 
L 233.81832 84.922093 
L 236.626366 85.77605 
L 237.480194 85.135662 
L 244.334338 63.797961 
L 246.119157 55.755212 
L 248.567339 45.939497 
L 250.481529 40.601654 
" clip-path="url(#pb7e17334f2)" style="fill: none; stroke: #d62728; stroke-opacity: 0.8; stroke-width: 1.5; stroke-linecap: round"/>
   </g>
   <g id="line2d_13">
    <path d="M 72.709956 109.650277 
L 73.770954 107.860247 
L 74.312843 106.929979 
L 76.213496 104.142383 
L 76.662564 103.623439 
L 79.06331 102.376832 
L 82.501467 106.11032 
L 85.663799 113.829102 
L 87.727831 119.214979 
L 88.116224 120.126438 
L 88.201945 120.344401 
L 88.770864 121.520048 
L 92.035917 124.911332 
L 93.398003 124.271873 
L 94.953437 122.222845 
L 98.739555 113.702337 
L 103.625024 105.379573 
L 104.79186 104.875579 
L 105.721493 104.920703 
L 105.995876 105.001516 
L 107.671944 106.014867 
L 111.329124 109.771705 
L 111.76694 110.236226 
L 116.738548 114.459083 
L 119.558951 115.940934 
L 119.620768 115.93617 
L 122.929863 116.18042 
L 124.398922 115.582928 
L 124.57385 115.492143 
L 125.43376 114.854896 
L 125.560673 114.770471 
L 127.167991 113.203752 
L 127.847863 112.43532 
L 129.902461 109.765385 
L 130.166424 109.417704 
L 131.634982 107.510441 
L 132.90394 106.046618 
L 133.059527 105.866136 
L 134.832379 104.275016 
L 136.307011 103.425732 
L 138.264629 103.044563 
L 141.380239 103.650422 
L 143.015961 104.254397 
L 145.787854 105.295263 
L 147.413736 105.508008 
L 151.820269 103.179749 
L 151.928348 103.062563 
L 153.781296 100.87102 
L 154.432976 100.019932 
L 154.764017 99.602601 
L 155.996813 97.988788 
L 163.993658 92.662321 
L 164.229508 92.601198 
L 164.287267 92.606983 
L 165.290902 92.299695 
L 165.994158 91.966596 
L 166.818044 91.5535 
L 169.357074 89.137229 
L 170.071433 88.173599 
L 170.33637 87.816776 
L 171.341521 86.257466 
L 177.029774 78.029773 
L 178.957901 77.091161 
L 180.845681 77.359804 
L 181.045039 77.4447 
L 182.893266 78.560324 
L 183.634041 79.08659 
L 185.033056 80.024483 
L 186.779641 80.896312 
L 193.198338 79.536405 
L 193.458293 79.429327 
L 193.543469 79.351307 
L 195.480216 78.415502 
L 201.491434 76.468654 
L 201.643886 76.461128 
L 201.690597 76.433878 
L 209.080917 76.098343 
L 209.190956 76.053457 
L 209.33267 76.120416 
L 209.508798 76.168198 
L 210.23687 76.313772 
L 213.271578 77.360535 
L 215.843742 78.182308 
L 217.664844 78.549246 
L 221.042086 77.952021 
L 221.165721 77.899503 
L 221.464325 77.767508 
L 223.464687 76.680982 
L 224.485424 76.10154 
L 229.562731 74.814122 
L 231.179642 75.879768 
L 231.363496 76.033977 
L 231.905663 76.615017 
L 233.81832 79.236602 
L 236.626366 83.894636 
L 237.480194 85.19265 
L 244.334338 87.296411 
L 246.119157 86.215329 
L 248.567339 85.778065 
L 250.481529 86.856764 
" clip-path="url(#pb7e17334f2)" style="fill: none; stroke: #9467bd; stroke-opacity: 0.8; stroke-width: 1.5; stroke-linecap: round"/>
   </g>
   <g id="line2d_14">
    <path d="M 72.709956 80.530084 
L 73.770954 81.514994 
L 74.312843 82.279846 
L 76.213496 85.922113 
L 76.662564 87.020421 
L 79.06331 93.980482 
L 82.501467 106.019417 
L 85.663799 116.408356 
L 87.727831 121.211179 
L 88.116224 121.862133 
L 88.201945 121.972879 
L 88.770864 122.71877 
L 92.035917 123.133007 
L 93.398003 121.627895 
L 94.953437 119.283827 
L 98.739555 113.643934 
L 103.625024 109.838388 
L 104.79186 109.075992 
L 105.721493 108.403828 
L 105.995876 108.244345 
L 107.671944 106.872889 
L 111.329124 105.101425 
L 111.76694 105.176175 
L 116.738548 110.922499 
L 119.558951 115.841638 
L 119.620768 115.927589 
L 122.929863 117.820443 
L 124.398922 116.610748 
L 124.57385 116.441407 
L 125.43376 114.957513 
L 125.560673 114.757585 
L 127.167991 111.096938 
L 127.847863 109.277571 
L 129.902461 103.35994 
L 130.166424 102.606767 
L 131.634982 98.653775 
L 132.90394 95.878656 
L 133.059527 95.586369 
L 134.832379 93.306685 
L 136.307011 92.920968 
L 138.264629 94.396978 
L 141.380239 99.620959 
L 143.015961 102.495861 
L 145.787854 105.46101 
L 147.413736 105.733396 
L 151.820269 102.55098 
L 151.928348 102.516372 
L 153.781296 100.940616 
L 154.432976 100.528487 
L 154.764017 100.355699 
L 155.996813 99.945227 
L 163.993658 101.767078 
L 164.229508 101.791678 
L 164.287267 101.79526 
L 165.290902 101.822922 
L 165.994158 101.746706 
L 166.818044 101.593584 
L 169.357074 100.652031 
L 170.071433 100.353463 
L 170.33637 100.170088 
L 171.341521 99.64425 
L 177.029774 95.036011 
L 178.957901 92.661715 
L 180.845681 89.839656 
L 181.045039 89.514445 
L 182.893266 86.547842 
L 183.634041 85.334962 
L 185.033056 83.144592 
L 186.779641 80.851426 
L 193.198338 78.622342 
L 193.458293 78.732117 
L 193.543469 78.749811 
L 195.480216 79.125181 
L 201.491434 76.615262 
L 201.643886 76.482042 
L 201.690597 76.485347 
L 209.080917 76.063306 
L 209.190956 76.170713 
L 209.33267 76.268859 
L 209.508798 76.497 
L 210.23687 77.194075 
L 213.271578 80.271849 
L 215.843742 81.457367 
L 217.664844 81.100993 
L 221.042086 78.026447 
L 221.165721 77.870434 
L 221.464325 77.436844 
L 223.464687 74.847099 
L 224.485424 73.621629 
L 229.562731 70.520877 
L 231.179642 71.321437 
L 231.363496 71.515949 
L 231.905663 72.051507 
L 233.81832 75.106273 
L 236.626366 82.411403 
L 237.480194 85.162253 
L 244.334338 107.187932 
L 246.119157 110.140939 
L 248.567339 111.121934 
L 250.481529 109.705342 
" clip-path="url(#pb7e17334f2)" style="fill: none; stroke: #8c564b; stroke-opacity: 0.8; stroke-width: 1.5; stroke-linecap: round"/>
   </g>
   <g id="line2d_15">
    <path d="M 72.709956 81.48413 
L 73.770954 83.139169 
L 74.312843 84.203206 
L 76.213496 88.687025 
L 76.662564 89.961697 
L 79.06331 96.939717 
L 82.501467 106.020699 
L 85.663799 111.541895 
L 87.727831 113.731549 
L 88.116224 114.028127 
L 88.201945 114.09434 
L 88.770864 114.557183 
L 92.035917 116.391167 
L 93.398003 116.766029 
L 94.953437 116.774526 
L 98.739555 113.673453 
L 103.625024 103.993439 
L 104.79186 101.677701 
L 105.721493 100.062515 
L 105.995876 99.734907 
L 107.671944 98.077742 
L 111.329124 100.256742 
L 111.76694 101.011909 
L 116.738548 111.957047 
L 119.558951 115.892696 
L 119.620768 115.929269 
L 122.929863 115.971384 
L 124.398922 115.222889 
L 124.57385 115.122979 
L 125.43376 114.769952 
L 125.560673 114.704195 
L 127.167991 114.728656 
L 127.847863 115.113161 
L 129.902461 117.685082 
L 130.166424 118.15799 
L 131.634982 121.499855 
L 132.90394 124.98519 
L 133.059527 125.442806 
L 134.832379 130.55496 
L 136.307011 134.328514 
L 138.264629 137.524731 
L 141.380239 136.730697 
L 143.015961 133.34847 
L 145.787854 124.338723 
L 147.413736 118.277593 
L 151.820269 104.688918 
L 151.928348 104.476511 
L 153.781296 100.912424 
L 154.432976 99.974071 
L 154.764017 99.571701 
L 155.996813 98.16895 
L 163.993658 91.958563 
L 164.229508 91.734407 
L 164.287267 91.701254 
L 165.290902 90.726557 
L 165.994158 90.068515 
L 166.818044 89.227965 
L 169.357074 86.2631 
L 170.071433 85.357021 
L 170.33637 84.984028 
L 171.341521 83.626324 
L 177.029774 75.960333 
L 178.957901 74.581379 
L 180.845681 74.43934 
L 181.045039 74.468297 
L 182.893266 75.707045 
L 183.634041 76.543393 
L 185.033056 78.300831 
L 186.779641 80.889178 
L 193.198338 85.738125 
L 193.458293 85.674174 
L 193.543469 85.680364 
L 195.480216 84.337849 
L 201.491434 76.636709 
L 201.643886 76.488825 
L 201.690597 76.401087 
L 209.080917 76.06155 
L 209.190956 76.178405 
L 209.33267 76.314411 
L 209.508798 76.431034 
L 210.23687 77.034811 
L 213.271578 78.995165 
L 215.843742 79.326224 
L 217.664844 78.931754 
L 221.042086 78.00319 
L 221.165721 77.96962 
L 221.464325 77.919684 
L 223.464687 77.675714 
L 224.485424 77.586445 
L 229.562731 77.585545 
L 231.179642 77.964867 
L 231.363496 77.996318 
L 231.905663 78.245345 
L 233.81832 79.753717 
L 236.626366 83.647817 
L 237.480194 85.098099 
L 244.334338 94.724171 
L 246.119157 95.746045 
L 248.567339 96.83143 
L 250.481529 97.708019 
" clip-path="url(#pb7e17334f2)" style="fill: none; stroke: #e377c2; stroke-opacity: 0.8; stroke-width: 1.5; stroke-linecap: round"/>
   </g>
   <g id="line2d_16">
    <path d="M 72.709956 117.925678 
L 73.770954 115.156168 
L 74.312843 113.80382 
L 76.213496 109.932969 
L 76.662564 109.232015 
L 79.06331 106.612797 
L 82.501467 106.035593 
L 85.663799 107.186069 
L 87.727831 108.147275 
L 88.116224 108.376081 
L 88.201945 108.455387 
L 88.770864 108.717596 
L 92.035917 110.610309 
L 93.398003 111.426633 
L 94.953437 112.309379 
L 98.739555 113.726683 
L 103.625024 114.799435 
L 104.79186 115.339517 
L 105.721493 115.821199 
L 105.995876 116.027437 
L 107.671944 117.122225 
L 111.329124 118.801041 
L 111.76694 118.82565 
L 116.738548 117.250295 
L 119.558951 115.902456 
L 119.620768 115.92562 
L 122.929863 115.114588 
L 124.398922 114.912833 
L 124.57385 114.898786 
L 125.43376 114.724057 
L 125.560673 114.726699 
L 127.167991 114.550142 
L 127.847863 114.431401 
L 129.902461 114.128093 
L 130.166424 114.067888 
L 131.634982 113.684343 
L 132.90394 113.177562 
L 133.059527 113.109312 
L 134.832379 111.811149 
L 136.307011 110.125402 
L 138.264629 107.184977 
L 141.380239 101.973446 
L 143.015961 99.843772 
L 145.787854 98.184203 
L 147.413736 98.469016 
L 151.820269 100.445533 
L 151.928348 100.480508 
L 153.781296 100.895545 
L 154.432976 100.990322 
L 154.764017 100.99553 
L 155.996813 100.929652 
L 163.993658 98.488273 
L 164.229508 98.330736 
L 164.287267 98.294656 
L 165.290902 97.454873 
L 165.994158 96.799425 
L 166.818044 95.917668 
L 169.357074 93.383064 
L 170.071433 92.816833 
L 170.33637 92.601115 
L 171.341521 92.051539 
L 177.029774 93.100095 
L 178.957901 93.602938 
L 180.845681 92.91247 
L 181.045039 92.755464 
L 182.893266 90.307598 
L 183.634041 88.841599 
L 185.033056 85.580592 
L 186.779641 80.860645 
L 193.198338 68.73732 
L 193.458293 68.568539 
L 193.543469 68.602913 
L 195.480216 69.147538 
L 201.491434 76.325879 
L 201.643886 76.457148 
L 201.690597 76.477068 
L 209.080917 76.033889 
L 209.190956 75.979768 
L 209.33267 75.783789 
L 209.508798 75.649838 
L 210.23687 74.960851 
L 213.271578 72.367024 
L 215.843742 71.732838 
L 217.664844 72.72383 
L 221.042086 77.978771 
L 221.165721 78.201028 
L 221.464325 78.826359 
L 223.464687 83.029869 
L 224.485424 85.114723 
L 229.562731 89.538435 
L 231.179642 88.716402 
L 231.363496 88.54573 
L 231.905663 88.109046 
L 233.81832 86.225765 
L 236.626366 84.859252 
L 237.480194 85.151171 
L 244.334338 99.864251 
L 246.119157 104.853691 
L 248.567339 109.408654 
L 250.481529 110.431408 
" clip-path="url(#pb7e17334f2)" style="fill: none; stroke: #7f7f7f; stroke-opacity: 0.8; stroke-width: 1.5; stroke-linecap: round"/>
   </g>
   <g id="line2d_17">
    <path d="M 72.709956 113.286382 
L 73.770954 113.123383 
L 74.312843 112.913419 
L 76.213496 111.823255 
L 76.662564 111.496715 
L 79.06331 109.268461 
L 82.501467 105.970189 
L 85.663799 105.233137 
L 87.727831 106.851177 
L 88.116224 107.321266 
L 88.201945 107.477633 
L 88.770864 108.237875 
L 92.035917 113.910719 
L 93.398003 115.861645 
L 94.953437 117.064818 
L 98.739555 113.682521 
L 103.625024 100.591556 
L 104.79186 97.710017 
L 105.721493 95.766169 
L 105.995876 95.262888 
L 107.671944 93.17456 
L 111.329124 94.49232 
L 111.76694 95.216157 
L 116.738548 108.05298 
L 119.558951 115.809821 
L 119.620768 115.929371 
L 122.929863 119.330916 
L 124.398922 117.668085 
L 124.57385 117.323913 
L 125.43376 115.126314 
L 125.560673 114.799348 
L 127.167991 108.542129 
L 127.847863 105.19682 
L 129.902461 93.210741 
L 130.166424 91.522633 
L 131.634982 82.077185 
L 132.90394 73.977295 
L 133.059527 73.019092 
L 134.832379 63.185337 
L 136.307011 56.987786 
L 138.264629 52.074021 
L 141.380239 52.958827 
L 143.015961 57.205735 
L 145.787854 68.384422 
L 147.413736 76.101794 
L 151.820269 95.306768 
L 151.928348 95.697665 
L 153.781296 100.870692 
L 154.432976 102.145101 
L 154.764017 102.691596 
L 155.996813 103.982166 
L 163.993658 87.181293 
L 164.229508 86.166663 
L 164.287267 85.959081 
L 165.290902 81.710598 
L 165.994158 78.680823 
L 166.818044 75.197751 
L 169.357074 65.629269 
L 170.071433 63.491949 
L 170.33637 62.718687 
L 171.341521 60.407796 
L 177.029774 60.570567 
L 178.957901 64.583922 
L 180.845681 69.191068 
L 181.045039 69.708626 
L 182.893266 74.148004 
L 183.634041 75.713054 
L 185.033056 78.342619 
L 186.779641 80.84883 
L 193.198338 81.892103 
L 193.458293 81.788374 
L 193.543469 81.712378 
L 195.480216 80.396422 
L 201.491434 76.561368 
L 201.643886 76.478244 
L 201.690597 76.464149 
L 209.080917 76.046586 
L 209.190956 76.085414 
L 209.33267 76.097862 
L 209.508798 76.110174 
L 210.23687 76.145206 
L 213.271578 76.160194 
L 215.843742 76.0113 
L 217.664844 76.159063 
L 221.042086 77.95786 
L 221.165721 78.113075 
L 221.464325 78.361119 
L 223.464687 80.483995 
L 224.485424 81.616834 
L 229.562731 83.783847 
L 231.179642 83.134526 
L 231.363496 83.055949 
L 231.905663 82.832536 
L 233.81832 82.21963 
L 236.626366 83.798542 
L 237.480194 85.199997 
L 244.334338 104.324885 
L 246.119157 108.224174 
L 248.567339 110.54168 
L 250.481529 109.49279 
" clip-path="url(#pb7e17334f2)" style="fill: none; stroke: #bcbd22; stroke-opacity: 0.8; stroke-width: 1.5; stroke-linecap: round"/>
   </g>
   <g id="line2d_18">
    <path d="M 72.709956 104.815017 
L 73.770954 104.648762 
L 74.312843 104.442319 
L 76.213496 103.396376 
L 76.662564 103.209696 
L 79.06331 102.756892 
L 82.501467 106.065567 
L 85.663799 112.013191 
L 87.727831 115.608455 
L 88.116224 116.171848 
L 88.201945 116.263936 
L 88.770864 116.941516 
L 92.035917 117.92309 
L 93.398003 117.191049 
L 94.953437 116.00365 
L 98.739555 113.72112 
L 103.625024 115.993745 
L 104.79186 117.075769 
L 105.721493 117.893572 
L 105.995876 118.156335 
L 107.671944 119.410788 
L 111.329124 120.16254 
L 111.76694 120.030001 
L 116.738548 117.379042 
L 119.558951 115.983824 
L 119.620768 116.001032 
L 122.929863 115.071032 
L 124.398922 114.861723 
L 124.57385 114.823735 
L 125.43376 114.724388 
L 125.560673 114.758159 
L 127.167991 114.799028 
L 127.847863 114.914875 
L 129.902461 115.723948 
L 130.166424 115.881615 
L 131.634982 116.999241 
L 132.90394 118.191295 
L 133.059527 118.397927 
L 134.832379 120.397615 
L 136.307011 122.000674 
L 138.264629 123.50016 
L 141.380239 123.177978 
L 143.015961 121.495535 
L 145.787854 116.508969 
L 147.413736 112.931794 
L 151.820269 103.728881 
L 151.928348 103.525631 
L 153.781296 100.928816 
L 154.432976 100.190752 
L 154.764017 99.809324 
L 155.996813 98.718753 
L 163.993658 92.72542 
L 164.229508 92.478746 
L 164.287267 92.425831 
L 165.290902 91.39646 
L 165.994158 90.600938 
L 166.818044 89.782326 
L 169.357074 87.255631 
L 170.071433 86.657497 
L 170.33637 86.40878 
L 171.341521 85.655652 
L 177.029774 80.657577 
L 178.957901 78.876457 
L 180.845681 77.651414 
L 181.045039 77.553232 
L 182.893266 77.476871 
L 183.634041 77.771196 
L 185.033056 78.857093 
L 186.779641 80.829424 
L 193.198338 84.935266 
L 193.458293 84.702174 
L 193.543469 84.694645 
L 195.480216 82.841772 
L 201.491434 76.523521 
L 201.643886 76.478441 
L 201.690597 76.475575 
L 209.080917 76.029196 
L 209.190956 76.057089 
L 209.33267 76.076228 
L 209.508798 76.0491 
L 210.23687 76.102544 
L 213.271578 76.516524 
L 215.843742 77.223619 
L 217.664844 77.685493 
L 221.042086 77.999297 
L 221.165721 78.000473 
L 221.464325 77.938239 
L 223.464687 77.686938 
L 224.485424 77.519171 
L 229.562731 78.555692 
L 231.179642 79.697594 
L 231.363496 79.873803 
L 231.905663 80.278322 
L 233.81832 82.086195 
L 236.626366 84.520497 
L 237.480194 85.183549 
L 244.334338 91.65828 
L 246.119157 95.339083 
L 248.567339 102.197633 
L 250.481529 108.398391 
" clip-path="url(#pb7e17334f2)" style="fill: none; stroke: #17becf; stroke-opacity: 0.8; stroke-width: 1.5; stroke-linecap: round"/>
   </g>
   <g id="patch_3">
    <path d="M 41.52375 142.370885 
L 41.52375 35.7555 
" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="patch_4">
    <path d="M 280.422833 142.370885 
L 280.422833 35.7555 
" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="patch_5">
    <path d="M 41.52375 142.370885 
L 280.422833 142.370885 
" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="patch_6">
    <path d="M 41.52375 35.7555 
L 280.422833 35.7555 
" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="text_11">
    <!-- Samples from $\ell = 0.1$, $\sigma = 0.5$ -->
    <g style="fill: #262626" transform="translate(73.493291 29.7555) scale(0.12 -0.12)">
     <defs>
      <path id="DejaVuSans-53" d="M 3425 4513 
L 3425 3897 
Q 3066 4069 2747 4153 
Q 2428 4238 2131 4238 
Q 1616 4238 1336 4038 
Q 1056 3838 1056 3469 
Q 1056 3159 1242 3001 
Q 1428 2844 1947 2747 
L 2328 2669 
Q 3034 2534 3370 2195 
Q 3706 1856 3706 1288 
Q 3706 609 3251 259 
Q 2797 -91 1919 -91 
Q 1588 -91 1214 -16 
Q 841 59 441 206 
L 441 856 
Q 825 641 1194 531 
Q 1563 422 1919 422 
Q 2459 422 2753 634 
Q 3047 847 3047 1241 
Q 3047 1584 2836 1778 
Q 2625 1972 2144 2069 
L 1759 2144 
Q 1053 2284 737 2584 
Q 422 2884 422 3419 
Q 422 4038 858 4394 
Q 1294 4750 2059 4750 
Q 2388 4750 2728 4690 
Q 3069 4631 3425 4513 
z
" transform="scale(0.015625)"/>
      <path id="DejaVuSans-61" d="M 2194 1759 
Q 1497 1759 1228 1600 
Q 959 1441 959 1056 
Q 959 750 1161 570 
Q 1363 391 1709 391 
Q 2188 391 2477 730 
Q 2766 1069 2766 1631 
L 2766 1759 
L 2194 1759 
z
M 3341 1997 
L 3341 0 
L 2766 0 
L 2766 531 
Q 2569 213 2275 61 
Q 1981 -91 1556 -91 
Q 1019 -91 701 211 
Q 384 513 384 1019 
Q 384 1609 779 1909 
Q 1175 2209 1959 2209 
L 2766 2209 
L 2766 2266 
Q 2766 2663 2505 2880 
Q 2244 3097 1772 3097 
Q 1472 3097 1187 3025 
Q 903 2953 641 2809 
L 641 3341 
Q 956 3463 1253 3523 
Q 1550 3584 1831 3584 
Q 2591 3584 2966 3190 
Q 3341 2797 3341 1997 
z
" transform="scale(0.015625)"/>
      <path id="DejaVuSans-6d" d="M 3328 2828 
Q 3544 3216 3844 3400 
Q 4144 3584 4550 3584 
Q 5097 3584 5394 3201 
Q 5691 2819 5691 2113 
L 5691 0 
L 5113 0 
L 5113 2094 
Q 5113 2597 4934 2840 
Q 4756 3084 4391 3084 
Q 3944 3084 3684 2787 
Q 3425 2491 3425 1978 
L 3425 0 
L 2847 0 
L 2847 2094 
Q 2847 2600 2669 2842 
Q 2491 3084 2119 3084 
Q 1678 3084 1418 2786 
Q 1159 2488 1159 1978 
L 1159 0 
L 581 0 
L 581 3500 
L 1159 3500 
L 1159 2956 
Q 1356 3278 1631 3431 
Q 1906 3584 2284 3584 
Q 2666 3584 2933 3390 
Q 3200 3197 3328 2828 
z
" transform="scale(0.015625)"/>
      <path id="DejaVuSans-70" d="M 1159 525 
L 1159 -1331 
L 581 -1331 
L 581 3500 
L 1159 3500 
L 1159 2969 
Q 1341 3281 1617 3432 
Q 1894 3584 2278 3584 
Q 2916 3584 3314 3078 
Q 3713 2572 3713 1747 
Q 3713 922 3314 415 
Q 2916 -91 2278 -91 
Q 1894 -91 1617 61 
Q 1341 213 1159 525 
z
M 3116 1747 
Q 3116 2381 2855 2742 
Q 2594 3103 2138 3103 
Q 1681 3103 1420 2742 
Q 1159 2381 1159 1747 
Q 1159 1113 1420 752 
Q 1681 391 2138 391 
Q 2594 391 2855 752 
Q 3116 1113 3116 1747 
z
" transform="scale(0.015625)"/>
      <path id="DejaVuSans-6c" d="M 603 4863 
L 1178 4863 
L 1178 0 
L 603 0 
L 603 4863 
z
" transform="scale(0.015625)"/>
      <path id="DejaVuSans-65" d="M 3597 1894 
L 3597 1613 
L 953 1613 
Q 991 1019 1311 708 
Q 1631 397 2203 397 
Q 2534 397 2845 478 
Q 3156 559 3463 722 
L 3463 178 
Q 3153 47 2828 -22 
Q 2503 -91 2169 -91 
Q 1331 -91 842 396 
Q 353 884 353 1716 
Q 353 2575 817 3079 
Q 1281 3584 2069 3584 
Q 2775 3584 3186 3129 
Q 3597 2675 3597 1894 
z
M 3022 2063 
Q 3016 2534 2758 2815 
Q 2500 3097 2075 3097 
Q 1594 3097 1305 2825 
Q 1016 2553 972 2059 
L 3022 2063 
z
" transform="scale(0.015625)"/>
      <path id="DejaVuSans-73" d="M 2834 3397 
L 2834 2853 
Q 2591 2978 2328 3040 
Q 2066 3103 1784 3103 
Q 1356 3103 1142 2972 
Q 928 2841 928 2578 
Q 928 2378 1081 2264 
Q 1234 2150 1697 2047 
L 1894 2003 
Q 2506 1872 2764 1633 
Q 3022 1394 3022 966 
Q 3022 478 2636 193 
Q 2250 -91 1575 -91 
Q 1294 -91 989 -36 
Q 684 19 347 128 
L 347 722 
Q 666 556 975 473 
Q 1284 391 1588 391 
Q 1994 391 2212 530 
Q 2431 669 2431 922 
Q 2431 1156 2273 1281 
Q 2116 1406 1581 1522 
L 1381 1569 
Q 847 1681 609 1914 
Q 372 2147 372 2553 
Q 372 3047 722 3315 
Q 1072 3584 1716 3584 
Q 2034 3584 2315 3537 
Q 2597 3491 2834 3397 
z
" transform="scale(0.015625)"/>
      <path id="DejaVuSans-20" transform="scale(0.015625)"/>
      <path id="DejaVuSans-66" d="M 2375 4863 
L 2375 4384 
L 1825 4384 
Q 1516 4384 1395 4259 
Q 1275 4134 1275 3809 
L 1275 3500 
L 2222 3500 
L 2222 3053 
L 1275 3053 
L 1275 0 
L 697 0 
L 697 3053 
L 147 3053 
L 147 3500 
L 697 3500 
L 697 3744 
Q 697 4328 969 4595 
Q 1241 4863 1831 4863 
L 2375 4863 
z
" transform="scale(0.015625)"/>
      <path id="DejaVuSans-72" d="M 2631 2963 
Q 2534 3019 2420 3045 
Q 2306 3072 2169 3072 
Q 1681 3072 1420 2755 
Q 1159 2438 1159 1844 
L 1159 0 
L 581 0 
L 581 3500 
L 1159 3500 
L 1159 2956 
Q 1341 3275 1631 3429 
Q 1922 3584 2338 3584 
Q 2397 3584 2469 3576 
Q 2541 3569 2628 3553 
L 2631 2963 
z
" transform="scale(0.015625)"/>
      <path id="DejaVuSans-6f" d="M 1959 3097 
Q 1497 3097 1228 2736 
Q 959 2375 959 1747 
Q 959 1119 1226 758 
Q 1494 397 1959 397 
Q 2419 397 2687 759 
Q 2956 1122 2956 1747 
Q 2956 2369 2687 2733 
Q 2419 3097 1959 3097 
z
M 1959 3584 
Q 2709 3584 3137 3096 
Q 3566 2609 3566 1747 
Q 3566 888 3137 398 
Q 2709 -91 1959 -91 
Q 1206 -91 779 398 
Q 353 888 353 1747 
Q 353 2609 779 3096 
Q 1206 3584 1959 3584 
z
" transform="scale(0.015625)"/>
      <path id="DejaVuSans-Oblique-2113" d="M 950 838 
Q 1078 213 1350 213 
Q 1531 213 1766 572 
L 2181 572 
Q 1994 253 1775 88 
Q 1538 -91 1319 -91 
Q 831 -91 634 344 
L 400 0 
L -88 0 
Q 250 459 500 888 
Q 469 1131 469 1397 
Q 469 1872 566 2347 
Q 931 4131 1256 4497 
Q 1481 4750 1866 4750 
Q 2256 4750 2256 4209 
Q 2253 3966 2197 3675 
Q 1972 2484 950 838 
z
M 947 1656 
Q 1531 2744 1709 3613 
Q 1803 4072 1803 4191 
Q 1803 4406 1725 4406 
Q 1384 4134 1081 2516 
Q 997 2063 947 1656 
z
" transform="scale(0.015625)"/>
      <path id="DejaVuSans-3d" d="M 678 2906 
L 4684 2906 
L 4684 2381 
L 678 2381 
L 678 2906 
z
M 678 1631 
L 4684 1631 
L 4684 1100 
L 678 1100 
L 678 1631 
z
" transform="scale(0.015625)"/>
      <path id="DejaVuSans-2e" d="M 684 794 
L 1344 794 
L 1344 0 
L 684 0 
L 684 794 
z
" transform="scale(0.015625)"/>
      <path id="DejaVuSans-31" d="M 794 531 
L 1825 531 
L 1825 4091 
L 703 3866 
L 703 4441 
L 1819 4666 
L 2450 4666 
L 2450 531 
L 3481 531 
L 3481 0 
L 794 0 
L 794 531 
z
" transform="scale(0.015625)"/>
      <path id="DejaVuSans-2c" d="M 750 794 
L 1409 794 
L 1409 256 
L 897 -744 
L 494 -744 
L 750 256 
L 750 794 
z
" transform="scale(0.015625)"/>
      <path id="DejaVuSans-Oblique-3c3" d="M 2219 3044 
Q 1744 3044 1422 2700 
Q 1081 2341 969 1747 
Q 844 1119 1044 756 
Q 1241 397 1706 397 
Q 2166 397 2503 759 
Q 2844 1122 2966 1747 
Q 3075 2319 2881 2700 
Q 2700 3044 2219 3044 
z
M 2309 3503 
L 4219 3500 
L 4106 2925 
L 3463 2925 
Q 3706 2438 3575 1747 
Q 3406 888 2884 400 
Q 2359 -91 1609 -91 
Q 856 -91 525 400 
Q 194 888 363 1747 
Q 528 2609 1050 3097 
Q 1484 3503 2309 3503 
z
" transform="scale(0.015625)"/>
      <path id="DejaVuSans-35" d="M 691 4666 
L 3169 4666 
L 3169 4134 
L 1269 4134 
L 1269 2991 
Q 1406 3038 1543 3061 
Q 1681 3084 1819 3084 
Q 2600 3084 3056 2656 
Q 3513 2228 3513 1497 
Q 3513 744 3044 326 
Q 2575 -91 1722 -91 
Q 1428 -91 1123 -41 
Q 819 9 494 109 
L 494 744 
Q 775 591 1075 516 
Q 1375 441 1709 441 
Q 2250 441 2565 725 
Q 2881 1009 2881 1497 
Q 2881 1984 2565 2268 
Q 2250 2553 1709 2553 
Q 1456 2553 1204 2497 
Q 953 2441 691 2322 
L 691 4666 
z
" transform="scale(0.015625)"/>
     </defs>
     <use xlink:href="#DejaVuSans-53" transform="translate(0 0.015625)"/>
     <use xlink:href="#DejaVuSans-61" transform="translate(63.476562 0.015625)"/>
     <use xlink:href="#DejaVuSans-6d" transform="translate(124.755859 0.015625)"/>
     <use xlink:href="#DejaVuSans-70" transform="translate(222.167969 0.015625)"/>
     <use xlink:href="#DejaVuSans-6c" transform="translate(285.644531 0.015625)"/>
     <use xlink:href="#DejaVuSans-65" transform="translate(313.427734 0.015625)"/>
     <use xlink:href="#DejaVuSans-73" transform="translate(374.951172 0.015625)"/>
     <use xlink:href="#DejaVuSans-20" transform="translate(427.050781 0.015625)"/>
     <use xlink:href="#DejaVuSans-66" transform="translate(458.837891 0.015625)"/>
     <use xlink:href="#DejaVuSans-72" transform="translate(494.042969 0.015625)"/>
     <use xlink:href="#DejaVuSans-6f" transform="translate(535.15625 0.015625)"/>
     <use xlink:href="#DejaVuSans-6d" transform="translate(596.337891 0.015625)"/>
     <use xlink:href="#DejaVuSans-20" transform="translate(693.75 0.015625)"/>
     <use xlink:href="#DejaVuSans-Oblique-2113" transform="translate(725.537109 0.015625)"/>
     <use xlink:href="#DejaVuSans-3d" transform="translate(786.328125 0.015625)"/>
     <use xlink:href="#DejaVuSans-30" transform="translate(889.599609 0.015625)"/>
     <use xlink:href="#DejaVuSans-2e" transform="translate(953.222656 0.015625)"/>
     <use xlink:href="#DejaVuSans-31" transform="translate(985.009766 0.015625)"/>
     <use xlink:href="#DejaVuSans-2c" transform="translate(1048.632812 0.015625)"/>
     <use xlink:href="#DejaVuSans-20" transform="translate(1080.419922 0.015625)"/>
     <use xlink:href="#DejaVuSans-Oblique-3c3" transform="translate(1112.207031 0.015625)"/>
     <use xlink:href="#DejaVuSans-3d" transform="translate(1195.068359 0.015625)"/>
     <use xlink:href="#DejaVuSans-30" transform="translate(1298.339844 0.015625)"/>
     <use xlink:href="#DejaVuSans-2e" transform="translate(1361.962891 0.015625)"/>
     <use xlink:href="#DejaVuSans-35" transform="translate(1393.75 0.015625)"/>
    </g>
   </g>
  </g>
  <g id="axes_2">
   <g id="patch_7">
    <path d="M 315.705902 142.370885 
L 422.321287 142.370885 
L 422.321287 35.7555 
L 315.705902 35.7555 
z
" style="fill: #eaeaf2"/>
   </g>
   <g clip-path="url(#pf15a82cfb2)">
    <image xlink:href="data:image/png;base64,
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" id="image118e46dddb" transform="scale(1 -1) translate(0 -106.56)" x="315.705902" y="-35.28046" width="106.56" height="106.56"/>
   </g>
   <g id="matplotlib.axis_3">
    <g id="xtick_6">
     <g id="text_12">
      <!-- -4 -->
      <g style="fill: #262626" transform="translate(311.251171 156.969322) scale(0.1 -0.1)">
       <defs>
        <path id="DejaVuSans-2d" d="M 313 2009 
L 1997 2009 
L 1997 1497 
L 313 1497 
L 313 2009 
z
" transform="scale(0.015625)"/>
       </defs>
       <use xlink:href="#DejaVuSans-2d"/>
       <use xlink:href="#DejaVuSans-34" x="36.083984"/>
      </g>
     </g>
    </g>
    <g id="xtick_7">
     <g id="text_13">
      <!-- -2 -->
      <g style="fill: #262626" transform="translate(337.772411 156.969322) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-2d"/>
       <use xlink:href="#DejaVuSans-32" x="36.083984"/>
      </g>
     </g>
    </g>
    <g id="xtick_8">
     <g id="text_14">
      <!-- 0 -->
      <g style="fill: #262626" transform="translate(366.097557 156.969322) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-30"/>
      </g>
     </g>
    </g>
    <g id="xtick_9">
     <g id="text_15">
      <!-- 2 -->
      <g style="fill: #262626" transform="translate(392.618797 156.969322) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-32"/>
      </g>
     </g>
    </g>
    <g id="xtick_10">
     <g id="text_16">
      <!-- 4 -->
      <g style="fill: #262626" transform="translate(419.140037 156.969322) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-34"/>
      </g>
     </g>
    </g>
    <g id="text_17">
     <!-- X -->
     <g style="fill: #262626" transform="translate(365.588595 166.647447) scale(0.1 -0.1)">
      <defs>
       <path id="DejaVuSans-58" d="M 403 4666 
L 1081 4666 
L 2241 2931 
L 3406 4666 
L 4084 4666 
L 2584 2425 
L 4184 0 
L 3506 0 
L 2194 1984 
L 872 0 
L 191 0 
L 1856 2491 
L 403 4666 
z
" transform="scale(0.015625)"/>
      </defs>
      <use xlink:href="#DejaVuSans-58"/>
     </g>
    </g>
   </g>
   <g id="matplotlib.axis_4">
    <g id="ytick_4">
     <g id="text_18">
      <!-- -4 -->
      <g style="fill: #262626" transform="translate(298.73559 40.085144) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-2d"/>
       <use xlink:href="#DejaVuSans-34" x="36.083984"/>
      </g>
     </g>
    </g>
    <g id="ytick_5">
     <g id="text_19">
      <!-- -2 -->
      <g style="fill: #262626" transform="translate(298.73559 66.606384) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-2d"/>
       <use xlink:href="#DejaVuSans-32" x="36.083984"/>
      </g>
     </g>
    </g>
    <g id="ytick_6">
     <g id="text_20">
      <!-- 0 -->
      <g style="fill: #262626" transform="translate(302.343402 93.127623) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-30"/>
      </g>
     </g>
    </g>
    <g id="ytick_7">
     <g id="text_21">
      <!-- 2 -->
      <g style="fill: #262626" transform="translate(302.343402 119.648863) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-32"/>
      </g>
     </g>
    </g>
    <g id="ytick_8">
     <g id="text_22">
      <!-- 4 -->
      <g style="fill: #262626" transform="translate(302.343402 146.170103) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-34"/>
      </g>
     </g>
    </g>
    <g id="text_23">
     <!-- X -->
     <g style="fill: #262626" transform="translate(296.655902 92.488192) rotate(-90) scale(0.1 -0.1)">
      <use xlink:href="#DejaVuSans-58"/>
     </g>
    </g>
   </g>
   <g id="patch_8">
    <path d="M 315.705902 142.370885 
L 315.705902 35.7555 
" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="patch_9">
    <path d="M 422.321287 142.370885 
L 422.321287 35.7555 
" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="patch_10">
    <path d="M 315.705902 142.370885 
L 422.321287 142.370885 
" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="patch_11">
    <path d="M 315.705902 35.7555 
L 422.321287 35.7555 
" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
   <g id="text_24">
    <!-- Covariance matrix -->
    <g style="fill: #262626" transform="translate(313.855782 16.318125) scale(0.12 -0.12)">
     <defs>
      <path id="DejaVuSans-43" d="M 4122 4306 
L 4122 3641 
Q 3803 3938 3442 4084 
Q 3081 4231 2675 4231 
Q 1875 4231 1450 3742 
Q 1025 3253 1025 2328 
Q 1025 1406 1450 917 
Q 1875 428 2675 428 
Q 3081 428 3442 575 
Q 3803 722 4122 1019 
L 4122 359 
Q 3791 134 3420 21 
Q 3050 -91 2638 -91 
Q 1578 -91 968 557 
Q 359 1206 359 2328 
Q 359 3453 968 4101 
Q 1578 4750 2638 4750 
Q 3056 4750 3426 4639 
Q 3797 4528 4122 4306 
z
" transform="scale(0.015625)"/>
      <path id="DejaVuSans-76" d="M 191 3500 
L 800 3500 
L 1894 563 
L 2988 3500 
L 3597 3500 
L 2284 0 
L 1503 0 
L 191 3500 
z
" transform="scale(0.015625)"/>
      <path id="DejaVuSans-69" d="M 603 3500 
L 1178 3500 
L 1178 0 
L 603 0 
L 603 3500 
z
M 603 4863 
L 1178 4863 
L 1178 4134 
L 603 4134 
L 603 4863 
z
" transform="scale(0.015625)"/>
      <path id="DejaVuSans-6e" d="M 3513 2113 
L 3513 0 
L 2938 0 
L 2938 2094 
Q 2938 2591 2744 2837 
Q 2550 3084 2163 3084 
Q 1697 3084 1428 2787 
Q 1159 2491 1159 1978 
L 1159 0 
L 581 0 
L 581 3500 
L 1159 3500 
L 1159 2956 
Q 1366 3272 1645 3428 
Q 1925 3584 2291 3584 
Q 2894 3584 3203 3211 
Q 3513 2838 3513 2113 
z
" transform="scale(0.015625)"/>
      <path id="DejaVuSans-63" d="M 3122 3366 
L 3122 2828 
Q 2878 2963 2633 3030 
Q 2388 3097 2138 3097 
Q 1578 3097 1268 2742 
Q 959 2388 959 1747 
Q 959 1106 1268 751 
Q 1578 397 2138 397 
Q 2388 397 2633 464 
Q 2878 531 3122 666 
L 3122 134 
Q 2881 22 2623 -34 
Q 2366 -91 2075 -91 
Q 1284 -91 818 406 
Q 353 903 353 1747 
Q 353 2603 823 3093 
Q 1294 3584 2113 3584 
Q 2378 3584 2631 3529 
Q 2884 3475 3122 3366 
z
" transform="scale(0.015625)"/>
      <path id="DejaVuSans-74" d="M 1172 4494 
L 1172 3500 
L 2356 3500 
L 2356 3053 
L 1172 3053 
L 1172 1153 
Q 1172 725 1289 603 
Q 1406 481 1766 481 
L 2356 481 
L 2356 0 
L 1766 0 
Q 1100 0 847 248 
Q 594 497 594 1153 
L 594 3053 
L 172 3053 
L 172 3500 
L 594 3500 
L 594 4494 
L 1172 4494 
z
" transform="scale(0.015625)"/>
      <path id="DejaVuSans-78" d="M 3513 3500 
L 2247 1797 
L 3578 0 
L 2900 0 
L 1881 1375 
L 863 0 
L 184 0 
L 1544 1831 
L 300 3500 
L 978 3500 
L 1906 2253 
L 2834 3500 
L 3513 3500 
z
" transform="scale(0.015625)"/>
     </defs>
     <use xlink:href="#DejaVuSans-43"/>
     <use xlink:href="#DejaVuSans-6f" x="69.824219"/>
     <use xlink:href="#DejaVuSans-76" x="131.005859"/>
     <use xlink:href="#DejaVuSans-61" x="190.185547"/>
     <use xlink:href="#DejaVuSans-72" x="251.464844"/>
     <use xlink:href="#DejaVuSans-69" x="292.578125"/>
     <use xlink:href="#DejaVuSans-61" x="320.361328"/>
     <use xlink:href="#DejaVuSans-6e" x="381.640625"/>
     <use xlink:href="#DejaVuSans-63" x="445.019531"/>
     <use xlink:href="#DejaVuSans-65" x="500"/>
     <use xlink:href="#DejaVuSans-20" x="561.523438"/>
     <use xlink:href="#DejaVuSans-6d" x="593.310547"/>
     <use xlink:href="#DejaVuSans-61" x="690.722656"/>
     <use xlink:href="#DejaVuSans-74" x="752.001953"/>
     <use xlink:href="#DejaVuSans-72" x="791.210938"/>
     <use xlink:href="#DejaVuSans-69" x="832.324219"/>
     <use xlink:href="#DejaVuSans-78" x="860.107422"/>
    </g>
    <!-- $\ell = 0.1$, $\sigma = 0.5$ -->
    <g style="fill: #262626" transform="translate(325.093595 29.7555) scale(0.12 -0.12)">
     <use xlink:href="#DejaVuSans-Oblique-2113" transform="translate(0 0.78125)"/>
     <use xlink:href="#DejaVuSans-3d" transform="translate(60.791016 0.78125)"/>
     <use xlink:href="#DejaVuSans-30" transform="translate(164.0625 0.78125)"/>
     <use xlink:href="#DejaVuSans-2e" transform="translate(227.685547 0.78125)"/>
     <use xlink:href="#DejaVuSans-31" transform="translate(259.472656 0.78125)"/>
     <use xlink:href="#DejaVuSans-2c" transform="translate(323.095703 0.78125)"/>
     <use xlink:href="#DejaVuSans-20" transform="translate(354.882812 0.78125)"/>
     <use xlink:href="#DejaVuSans-Oblique-3c3" transform="translate(386.669922 0.78125)"/>
     <use xlink:href="#DejaVuSans-3d" transform="translate(469.53125 0.78125)"/>
     <use xlink:href="#DejaVuSans-30" transform="translate(572.802734 0.78125)"/>
     <use xlink:href="#DejaVuSans-2e" transform="translate(636.425781 0.78125)"/>
     <use xlink:href="#DejaVuSans-35" transform="translate(668.212891 0.78125)"/>
    </g>
   </g>
  </g>
  <g id="axes_3">
   <g id="patch_12">
    <path d="M 423.761287 142.370885 
L 429.092056 142.370885 
L 429.092056 35.7555 
L 423.761287 35.7555 
z
" style="fill: #eaeaf2"/>
   </g>
   <g id="matplotlib.axis_5"/>
   <g id="matplotlib.axis_6">
    <g id="ytick_9">
     <g id="line2d_19">
      <path d="M 423.761287 140.268945 
L 429.092056 140.268945 
" clip-path="url(#pb8949fd265)" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round"/>
     </g>
     <g id="line2d_20">
      <defs>
       <path id="m9a83162e76" d="M 0 0 
L 3.5 0 
" style="stroke: #262626; stroke-width: 0.8"/>
      </defs>
      <g>
       <use xlink:href="#m9a83162e76" x="429.092056" y="140.268945" style="fill: #262626; stroke: #262626; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_25">
      <!-- −0.2 -->
      <g style="fill: #262626" transform="translate(436.092056 144.068164) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-2212"/>
       <use xlink:href="#DejaVuSans-30" x="83.789062"/>
       <use xlink:href="#DejaVuSans-2e" x="147.412109"/>
       <use xlink:href="#DejaVuSans-32" x="179.199219"/>
      </g>
     </g>
    </g>
    <g id="ytick_10">
     <g id="line2d_21">
      <path d="M 423.761287 105.531778 
L 429.092056 105.531778 
" clip-path="url(#pb8949fd265)" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round"/>
     </g>
     <g id="line2d_22">
      <g>
       <use xlink:href="#m9a83162e76" x="429.092056" y="105.531778" style="fill: #262626; stroke: #262626; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_26">
      <!-- 0.0 -->
      <g style="fill: #262626" transform="translate(436.092056 109.330997) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-30"/>
       <use xlink:href="#DejaVuSans-2e" x="63.623047"/>
       <use xlink:href="#DejaVuSans-30" x="95.410156"/>
      </g>
     </g>
    </g>
    <g id="ytick_11">
     <g id="line2d_23">
      <path d="M 423.761287 70.794612 
L 429.092056 70.794612 
" clip-path="url(#pb8949fd265)" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round"/>
     </g>
     <g id="line2d_24">
      <g>
       <use xlink:href="#m9a83162e76" x="429.092056" y="70.794612" style="fill: #262626; stroke: #262626; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_27">
      <!-- 0.2 -->
      <g style="fill: #262626" transform="translate(436.092056 74.593831) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-30"/>
       <use xlink:href="#DejaVuSans-2e" x="63.623047"/>
       <use xlink:href="#DejaVuSans-32" x="95.410156"/>
      </g>
     </g>
    </g>
    <g id="ytick_12">
     <g id="line2d_25">
      <path d="M 423.761287 36.057446 
L 429.092056 36.057446 
" clip-path="url(#pb8949fd265)" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linecap: round"/>
     </g>
     <g id="line2d_26">
      <g>
       <use xlink:href="#m9a83162e76" x="429.092056" y="36.057446" style="fill: #262626; stroke: #262626; stroke-width: 0.8"/>
      </g>
     </g>
     <g id="text_28">
      <!-- 0.4 -->
      <g style="fill: #262626" transform="translate(436.092056 39.856664) scale(0.1 -0.1)">
       <use xlink:href="#DejaVuSans-30"/>
       <use xlink:href="#DejaVuSans-2e" x="63.623047"/>
       <use xlink:href="#DejaVuSans-34" x="95.410156"/>
      </g>
     </g>
    </g>
    <g id="text_29">
     <!-- $K(X,X)$ -->
     <g style="fill: #262626" transform="translate(470.453619 102.343192) rotate(-90) scale(0.08 -0.08)">
      <defs>
       <path id="DejaVuSans-Oblique-4b" d="M 1081 4666 
L 1716 4666 
L 1331 2700 
L 3781 4666 
L 4622 4666 
L 1850 2438 
L 3878 0 
L 3109 0 
L 1247 2272 
L 806 0 
L 172 0 
L 1081 4666 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-28" d="M 1984 4856 
Q 1566 4138 1362 3434 
Q 1159 2731 1159 2009 
Q 1159 1288 1364 580 
Q 1569 -128 1984 -844 
L 1484 -844 
Q 1016 -109 783 600 
Q 550 1309 550 2009 
Q 550 2706 781 3412 
Q 1013 4119 1484 4856 
L 1984 4856 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-Oblique-58" d="M 878 4666 
L 1516 4666 
L 2316 2981 
L 3763 4666 
L 4500 4666 
L 2578 2438 
L 3738 0 
L 3103 0 
L 2163 1966 
L 459 0 
L -275 0 
L 1906 2509 
L 878 4666 
z
" transform="scale(0.015625)"/>
       <path id="DejaVuSans-29" d="M 513 4856 
L 1013 4856 
Q 1481 4119 1714 3412 
Q 1947 2706 1947 2009 
Q 1947 1309 1714 600 
Q 1481 -109 1013 -844 
L 513 -844 
Q 928 -128 1133 580 
Q 1338 1288 1338 2009 
Q 1338 2731 1133 3434 
Q 928 4138 513 4856 
z
" transform="scale(0.015625)"/>
      </defs>
      <use xlink:href="#DejaVuSans-Oblique-4b" transform="translate(0 0.125)"/>
      <use xlink:href="#DejaVuSans-28" transform="translate(65.576172 0.125)"/>
      <use xlink:href="#DejaVuSans-Oblique-58" transform="translate(104.589844 0.125)"/>
      <use xlink:href="#DejaVuSans-2c" transform="translate(173.095703 0.125)"/>
      <use xlink:href="#DejaVuSans-Oblique-58" transform="translate(224.365234 0.125)"/>
      <use xlink:href="#DejaVuSans-29" transform="translate(292.871094 0.125)"/>
     </g>
    </g>
   </g>
   <image xlink:href="data:image/png;base64,
iVBORw0KGgoAAAANSUhEUgAAAAcAAACUCAYAAABfoDM+AAABGElEQVR4nMXXUY7DQAgDUEbi/ufrXZpCTzAPiWq1+UW2sWEmyal+dVye7P7capERV2BkB5DVtURac03LhiJIq6Lia8e3pyVya+VzbzayVEQtsvosNXvd0GAFDdHKPiH7lOZAKyvrbh8WaztP0r5F+9zXdrBi2jVy0ETR8d2BA3LQRJHH4b3eBGbb0txvH2wOITxsaL0JtsKL8R80Tcu95YKp2LilsnAeftIUEleYNU3LbqVppK2sGwLvFB+KgfzySDOUkGmJtKa+GEV7cNckvgknTRztPETqlJHW2dIKQ9gPW1Y8bG/C34yMa8Kp/LC32/jc7T4+3pq4MbL4G8Q/nX5AWyoK6dfVWpPd0icTGjRJu+22NM+15hcw2TvZ9lU+zwAAAABJRU5ErkJggg==" id="image2e58ddebd9" transform="scale(1 -1) translate(0 -106.56)" x="424.08" y="-35.28" width="5.04" height="106.56"/>
   <g id="LineCollection_1"/>
   <g id="patch_13">
    <path d="M 423.761287 142.370885 
L 426.426672 142.370885 
L 429.092056 142.370885 
L 429.092056 35.7555 
L 426.426672 35.7555 
L 423.761287 35.7555 
L 423.761287 142.370885 
z
" style="fill: none; stroke: #ffffff; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square"/>
   </g>
  </g>
 </g>
 <defs>
  <clipPath id="pb7e17334f2">
   <rect x="41.52375" y="35.7555" width="238.899083" height="106.615385"/>
  </clipPath>
  <clipPath id="pf15a82cfb2">
   <rect x="315.705902" y="35.7555" width="106.615385" height="106.615385"/>
  </clipPath>
  <clipPath id="pb8949fd265">
   <rect x="423.761287" y="35.7555" width="5.330769" height="106.615385"/>
  </clipPath>
 </defs>
</svg>
"/>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-python"><pre><span></span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
</main>
</body>
</html>]]></content><author><name>Zhu Tianda</name></author><category term="coding" /><category term="LEARNING" /><category term="AI" /><summary type="html"><![CDATA[]]></summary></entry></feed>