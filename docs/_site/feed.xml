<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.5">Jekyll</generator><link href="http://0.0.0.0:8855/feed.xml" rel="self" type="application/atom+xml" /><link href="http://0.0.0.0:8855/" rel="alternate" type="text/html" /><updated>2024-02-28T12:35:37+08:00</updated><id>http://0.0.0.0:8855/feed.xml</id><title type="html">Zhu Philip’s AI Journey</title><subtitle></subtitle><author><name>Zhu Tianda</name></author><entry><title type="html">Diffusion Models Tutorial</title><link href="http://0.0.0.0:8855/coding/2023/12/11/diffusion-model-demo1.html" rel="alternate" type="text/html" title="Diffusion Models Tutorial" /><published>2023-12-11T00:00:00+08:00</published><updated>2023-12-11T00:00:00+08:00</updated><id>http://0.0.0.0:8855/coding/2023/12/11/diffusion-model-demo1</id><content type="html" xml:base="http://0.0.0.0:8855/coding/2023/12/11/diffusion-model-demo1.html"><![CDATA[<p><a href="https://colab.research.google.com/github/azad-academy/denoising-diffusion-model/blob/main/diffusion_model_demo.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" /></a></p>

<h1 id="diffusion-models-tutorial">Diffusion Models Tutorial</h1>

<h4 id="author--j-rafid-siddiqui-jrsazaditechcom">Author : J. Rafid Siddiqui (jrs@azaditech.com)</h4>

<h2 id="loading-data">Loading Data</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="kn">import</span> <span class="nn">matplotlib</span> <span class="k">as</span> <span class="n">mpl</span>
<span class="kn">import</span> <span class="nn">matplotlib.font_manager</span>
<span class="c1">#font_manager._rebuild()
</span><span class="kn">import</span> <span class="nn">logging</span>
<span class="n">logging</span><span class="p">.</span><span class="n">getLogger</span><span class="p">(</span><span class="s">"matplotlib.font_manager"</span><span class="p">).</span><span class="n">setLevel</span><span class="p">(</span><span class="n">logging</span><span class="p">.</span><span class="n">ERROR</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">hdr_plot_style</span><span class="p">():</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">style</span><span class="p">.</span><span class="n">use</span><span class="p">(</span><span class="s">'dark_background'</span><span class="p">)</span>
    <span class="n">mpl</span><span class="p">.</span><span class="n">rcParams</span><span class="p">.</span><span class="n">update</span><span class="p">({</span><span class="s">'font.size'</span><span class="p">:</span> <span class="mi">18</span><span class="p">,</span> <span class="s">'lines.linewidth'</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="s">'lines.markersize'</span><span class="p">:</span> <span class="mi">15</span><span class="p">})</span>
    <span class="c1"># avoid type 3 (i.e. bitmap) fonts in figures
</span>    <span class="n">mpl</span><span class="p">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s">'ps.useafm'</span><span class="p">]</span> <span class="o">=</span> <span class="bp">True</span>
    <span class="n">mpl</span><span class="p">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s">'pdf.use14corefonts'</span><span class="p">]</span> <span class="o">=</span> <span class="bp">True</span>
    <span class="n">mpl</span><span class="p">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s">'text.usetex'</span><span class="p">]</span> <span class="o">=</span> <span class="bp">False</span>
    <span class="n">mpl</span><span class="p">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s">'font.family'</span><span class="p">]</span> <span class="o">=</span> <span class="s">'sans-serif'</span>
    <span class="n">mpl</span><span class="p">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s">'font.sans-serif'</span><span class="p">]</span> <span class="o">=</span> <span class="s">'Courier New'</span>
    <span class="c1"># mpl.rcParams['text.hinting'] = False
</span>    <span class="c1"># Set colors cycle
</span>    <span class="n">colors</span> <span class="o">=</span> <span class="n">mpl</span><span class="p">.</span><span class="n">cycler</span><span class="p">(</span><span class="s">'color'</span><span class="p">,</span> <span class="p">[</span><span class="s">'#3388BB'</span><span class="p">,</span> <span class="s">'#EE6666'</span><span class="p">,</span> <span class="s">'#9988DD'</span><span class="p">,</span> <span class="s">'#EECC55'</span><span class="p">,</span> <span class="s">'#88BB44'</span><span class="p">,</span> <span class="s">'#FFBBBB'</span><span class="p">])</span>
    <span class="c1">#plt.rc('figure', facecolor='#00000000', edgecolor='black')
</span>    <span class="c1">#plt.rc('axes', facecolor='#FFFFFF88', edgecolor='white', axisbelow=True, grid=True, prop_cycle=colors)
</span>    <span class="n">plt</span><span class="p">.</span><span class="n">rc</span><span class="p">(</span><span class="s">'legend'</span><span class="p">,</span> <span class="n">facecolor</span><span class="o">=</span><span class="s">'#666666EE'</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s">'white'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">rc</span><span class="p">(</span><span class="s">'grid'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'white'</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s">'solid'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">rc</span><span class="p">(</span><span class="s">'text'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'white'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">rc</span><span class="p">(</span><span class="s">'xtick'</span><span class="p">,</span> <span class="n">direction</span><span class="o">=</span><span class="s">'out'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'white'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">rc</span><span class="p">(</span><span class="s">'ytick'</span><span class="p">,</span> <span class="n">direction</span><span class="o">=</span><span class="s">'out'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'white'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">rc</span><span class="p">(</span><span class="s">'patch'</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s">'#E6E6E6'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_checkerboard</span><span class="p">,</span><span class="n">make_circles</span><span class="p">,</span><span class="n">make_moons</span><span class="p">,</span><span class="n">make_s_curve</span><span class="p">,</span><span class="n">make_swiss_roll</span>
<span class="c1">#from helper_plot import hdr_plot_style
</span><span class="kn">import</span> <span class="nn">torch</span>
<span class="c1">#from utils import * 
</span>
<span class="n">hdr_plot_style</span><span class="p">()</span>
<span class="n">swiss_roll</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">make_swiss_roll</span><span class="p">(</span><span class="mi">10</span><span class="o">**</span><span class="mi">4</span><span class="p">,</span><span class="n">noise</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">swiss_roll</span> <span class="o">=</span> <span class="n">swiss_roll</span><span class="p">[:,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]]</span><span class="o">/</span><span class="mf">10.0</span>

<span class="n">s_curve</span><span class="p">,</span> <span class="n">_</span><span class="o">=</span> <span class="n">make_s_curve</span><span class="p">(</span><span class="mi">10</span><span class="o">**</span><span class="mi">4</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">s_curve</span> <span class="o">=</span> <span class="n">s_curve</span><span class="p">[:,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]]</span><span class="o">/</span><span class="mf">10.0</span>

<span class="n">moons</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">make_moons</span><span class="p">(</span><span class="mi">10</span><span class="o">**</span><span class="mi">4</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">s_curve</span><span class="p">.</span><span class="n">T</span>
<span class="c1">#dataset = torch.Tensor(data.T).float()
</span>

<span class="n">fig</span><span class="p">,</span><span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">scatter</span><span class="p">(</span><span class="o">*</span><span class="n">data</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'white'</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s">'gray'</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">5</span><span class="p">);</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">axis</span><span class="p">(</span><span class="s">'off'</span><span class="p">)</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">swiss_roll</span><span class="p">.</span><span class="n">T</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">scatter</span><span class="p">(</span><span class="o">*</span><span class="n">data</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'white'</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s">'gray'</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">5</span><span class="p">);</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">axis</span><span class="p">(</span><span class="s">'off'</span><span class="p">)</span>
<span class="c1">#dataset = torch.Tensor(data.T).float()
</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">moons</span><span class="p">.</span><span class="n">T</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">].</span><span class="n">scatter</span><span class="p">(</span><span class="o">*</span><span class="n">data</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'white'</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s">'gray'</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">3</span><span class="p">);</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">].</span><span class="n">axis</span><span class="p">(</span><span class="s">'off'</span><span class="p">)</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">T</span><span class="p">).</span><span class="nb">float</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/assets/2023-12-01-diffusion-model-demo1_files/2023-12-01-diffusion-model-demo1_4_0.png" alt="png" /></p>

<h2 id="diffusion-models">Diffusion Models</h2>

<p><img src="images/diffusion.png" alt="diffusion-image" /></p>

<h3 id="forward-diffusion">Forward Diffusion</h3>

\[q(\mathbf{x}_{t}\mid\mathbf{x}_{t-1}) = \mathcal{N}(\mathbf{x}_{t} ; \sqrt{1-\beta_{t}}\mathbf{x}_{t-1},\beta_{t}\mathbf{I})\]

<p>Substituting $\alpha_{t}=1-\beta_{t}$ and $\bar{\alpha}<em>{t} = \prod</em>{s=1}^{t} \alpha_{s}$:</p>

\[q(\mathbf{x}_{t}\mid\mathbf{x}_{0}) = \mathcal{N}(\mathbf{x}_{t} ; \sqrt{\bar{\alpha}_{t}}\mathbf{x}_{t-1},(1-\bar{\alpha}_{t})\mathbf{I})\]

<p>Given the initial state, this makes it possible to draw sample at any desrired timestep without going through intermediate steps. Forward diffusion can also be written in terms of $x_0$ and the random noise $\epsilon \sim \mathcal{N}(0,1)$ [1]. This would be useful when performing denoising step later in the reverse diffusion.</p>

\[x_t(x_0,\epsilon) = \sqrt{\bar{\alpha}_{t}}\mathbf{x}_{0} + \sqrt{1-\bar{\alpha_{t}}}\epsilon\]

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">make_beta_schedule</span><span class="p">(</span><span class="n">schedule</span><span class="o">=</span><span class="s">'linear'</span><span class="p">,</span> <span class="n">n_timesteps</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">schedule</span> <span class="o">==</span> <span class="s">'linear'</span><span class="p">:</span>
        <span class="n">betas</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">n_timesteps</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">schedule</span> <span class="o">==</span> <span class="s">"quad"</span><span class="p">:</span>
        <span class="n">betas</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">start</span> <span class="o">**</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">end</span> <span class="o">**</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">n_timesteps</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>
    <span class="k">elif</span> <span class="n">schedule</span> <span class="o">==</span> <span class="s">"sigmoid"</span><span class="p">:</span>
        <span class="n">betas</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="n">n_timesteps</span><span class="p">)</span>
        <span class="n">betas</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">betas</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">)</span> <span class="o">+</span> <span class="n">start</span>
    <span class="k">return</span> <span class="n">betas</span>

<span class="k">def</span> <span class="nf">extract</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="n">shape</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">gather</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">t</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="nb">input</span><span class="p">.</span><span class="n">device</span><span class="p">))</span>
    <span class="n">reshape</span> <span class="o">=</span> <span class="p">[</span><span class="n">t</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">out</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">*</span><span class="n">reshape</span><span class="p">)</span>    
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">num_steps</span> <span class="o">=</span> <span class="mi">100</span>
<span class="c1">#betas = torch.tensor([1.7e-5] * num_steps)
</span><span class="n">betas</span> <span class="o">=</span> <span class="n">make_beta_schedule</span><span class="p">(</span><span class="n">schedule</span><span class="o">=</span><span class="s">'sigmoid'</span><span class="p">,</span> <span class="n">n_timesteps</span><span class="o">=</span><span class="n">num_steps</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="mf">0.5e-2</span><span class="p">)</span>

<span class="n">alphas</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">betas</span>
<span class="n">alphas_prod</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cumprod</span><span class="p">(</span><span class="n">alphas</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">alphas_prod_p</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">([</span><span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">]).</span><span class="nb">float</span><span class="p">(),</span> <span class="n">alphas_prod</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]],</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">alphas_bar_sqrt</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">alphas_prod</span><span class="p">)</span>
<span class="n">one_minus_alphas_bar_log</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alphas_prod</span><span class="p">)</span>
<span class="n">one_minus_alphas_bar_sqrt</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alphas_prod</span><span class="p">)</span>
</code></pre></div></div>

<p>Following code which do the step by step add noise seems not necessary , due to the result don’t use at all in training, the useful cacluation above is done.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">q_x</span><span class="p">(</span><span class="n">x_0</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">noise</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">noise</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">x_0</span><span class="p">)</span>
    <span class="n">alphas_t</span> <span class="o">=</span> <span class="n">extract</span><span class="p">(</span><span class="n">alphas_bar_sqrt</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_0</span><span class="p">)</span>
    <span class="n">alphas_1_m_t</span> <span class="o">=</span> <span class="n">extract</span><span class="p">(</span><span class="n">one_minus_alphas_bar_sqrt</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_0</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">alphas_t</span> <span class="o">*</span> <span class="n">x_0</span> <span class="o">+</span> <span class="n">alphas_1_m_t</span> <span class="o">*</span> <span class="n">noise</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">q_i</span> <span class="o">=</span> <span class="n">q_x</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">i</span> <span class="o">*</span> <span class="mi">10</span><span class="p">]))</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">scatter</span><span class="p">(</span><span class="n">q_i</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">q_i</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s">'white'</span><span class="p">,</span><span class="n">edgecolor</span><span class="o">=</span><span class="s">'gray'</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">5</span><span class="p">);</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">set_axis_off</span><span class="p">();</span> <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">'$q(\mathbf{x}_{'</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="o">*</span><span class="mi">10</span><span class="p">)</span><span class="o">+</span><span class="s">'})$'</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/assets/2023-12-01-diffusion-model-demo1_files/2023-12-01-diffusion-model-demo1_12_0.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">posterior_mean_coef_1</span> <span class="o">=</span> <span class="p">(</span><span class="n">betas</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">alphas_prod_p</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alphas_prod</span><span class="p">))</span>
<span class="n">posterior_mean_coef_2</span> <span class="o">=</span> <span class="p">((</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alphas_prod_p</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">alphas</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alphas_prod</span><span class="p">))</span>
<span class="n">posterior_variance</span> <span class="o">=</span> <span class="n">betas</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alphas_prod_p</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alphas_prod</span><span class="p">)</span>
<span class="n">posterior_log_variance_clipped</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">((</span><span class="n">posterior_variance</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">posterior_variance</span><span class="p">[</span><span class="mi">1</span><span class="p">:].</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="mi">0</span><span class="p">)).</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">q_posterior_mean_variance</span><span class="p">(</span><span class="n">x_0</span><span class="p">,</span> <span class="n">x_t</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
    <span class="n">coef_1</span> <span class="o">=</span> <span class="n">extract</span><span class="p">(</span><span class="n">posterior_mean_coef_1</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_0</span><span class="p">)</span>
    <span class="n">coef_2</span> <span class="o">=</span> <span class="n">extract</span><span class="p">(</span><span class="n">posterior_mean_coef_2</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_0</span><span class="p">)</span>
    <span class="n">mean</span> <span class="o">=</span> <span class="n">coef_1</span> <span class="o">*</span> <span class="n">x_0</span> <span class="o">+</span> <span class="n">coef_2</span> <span class="o">*</span> <span class="n">x_t</span>
    <span class="n">var</span> <span class="o">=</span> <span class="n">extract</span><span class="p">(</span><span class="n">posterior_log_variance_clipped</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">mean</span><span class="p">,</span> <span class="n">var</span>
</code></pre></div></div>

<h2 id="reverse-diffusionreconstruction">Reverse Diffusion/Reconstruction</h2>

<p>Unlike the forward diffusion, the reverse diffusion process requires training of a neural network model. We setup the necessary loss functions and training parameters and then perform the training.</p>

<h2 id="training">Training</h2>

<h3 id="training-loss">Training Loss</h3>

<p>The original loss was proposed in Sohl-Dickstein et al. [1] as following:</p>

<p>\begin{align}
K = -\mathbb{E}<em>{q}[ &amp;D</em>{KL}(q(\mathbf{x}<em>{t-1}\mid\mathbf{x}</em>{t},\mathbf{x}<em>{0}) \Vert p</em>{\theta}(\mathbf{x}<em>{t-1}\mid\mathbf{x}</em>{t}))  <br />
&amp;+ H_{q}(\mathbf{X}<em>{T}\vert\mathbf{X}</em>{0}) - H_{q}(\mathbf{X}<em>{1}\vert\mathbf{X}</em>{0}) - H_{p}(\mathbf{X}_{T})]
\end{align}</p>

<p>In order to improve the results, the authors in Ho et al. [2] proposed multiple improvements. Following Parameterization of mean is proposed:</p>

\[\mathbf{\mu}_{\theta}(\mathbf{x}_{t}, t) = \frac{1}{\sqrt{\alpha_{t}}} \left( (\mathbf{x}_{t} - \frac{\beta_{t}}{\sqrt{1 - \bar{\alpha}}_{t}} \mathbf{\epsilon}_{\theta} (\mathbf{x}_{t}, t) \right)\]

<p>further, variance is taken as constant and the step for reverse diffusion then becomes:</p>

\[\mathbf{x}_{t-1} = \frac{1}{\sqrt{\alpha_{t}}} \left( \mathbf{x}_{t} - \frac{1-\alpha_{t}}{\sqrt{1-\bar{\alpha_{t}}}} \mathbf{\epsilon}_{\theta}(\mathbf{x}_{t}, t) \right) + \sigma_{t}\mathbf{z}\]

<p>After further improvements and simplifications the loss function becomes:</p>

\[\mathcal{L}_{\text{simple}}=\mathbb{E}_{t, \mathbf{x}_{0},\mathbf{\epsilon}}\left[ \Vert \epsilon - \epsilon_{\theta}(\sqrt{\bar{\alpha}_{t}}\mathbf{x}_{0} + \sqrt{1 - \bar{\alpha}_{t}}\mathbf{\epsilon}, t) \Vert^{2} \right].\]

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">p_sample</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span><span class="n">alphas</span><span class="p">,</span><span class="n">betas</span><span class="p">,</span><span class="n">one_minus_alphas_bar_sqrt</span><span class="p">):</span>
    <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">t</span><span class="p">])</span>
    <span class="c1"># Factor to the model output
</span>    <span class="n">eps_factor</span> <span class="o">=</span> <span class="p">((</span><span class="mi">1</span> <span class="o">-</span> <span class="n">extract</span><span class="p">(</span><span class="n">alphas</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x</span><span class="p">))</span> <span class="o">/</span> <span class="n">extract</span><span class="p">(</span><span class="n">one_minus_alphas_bar_sqrt</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x</span><span class="p">))</span>
    <span class="c1"># Model output
</span>    <span class="n">eps_theta</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
    <span class="c1"># Final values
</span>    <span class="n">mean</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">extract</span><span class="p">(</span><span class="n">alphas</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x</span><span class="p">).</span><span class="n">sqrt</span><span class="p">())</span> <span class="o">*</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="p">(</span><span class="n">eps_factor</span> <span class="o">*</span> <span class="n">eps_theta</span><span class="p">))</span>
    <span class="c1"># Generate z
</span>    <span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="c1"># Fixed sigma
</span>    <span class="n">sigma_t</span> <span class="o">=</span> <span class="n">extract</span><span class="p">(</span><span class="n">betas</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x</span><span class="p">).</span><span class="n">sqrt</span><span class="p">()</span>
    <span class="n">sample</span> <span class="o">=</span> <span class="n">mean</span> <span class="o">+</span> <span class="n">sigma_t</span> <span class="o">*</span> <span class="n">z</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">sample</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">p_sample_loop</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span><span class="n">n_steps</span><span class="p">,</span><span class="n">alphas</span><span class="p">,</span><span class="n">betas</span><span class="p">,</span><span class="n">one_minus_alphas_bar_sqrt</span><span class="p">):</span>
    <span class="n">cur_x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">x_seq</span> <span class="o">=</span> <span class="p">[</span><span class="n">cur_x</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n_steps</span><span class="p">)):</span>
        <span class="n">cur_x</span> <span class="o">=</span> <span class="n">p_sample</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">cur_x</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span><span class="n">alphas</span><span class="p">,</span><span class="n">betas</span><span class="p">,</span><span class="n">one_minus_alphas_bar_sqrt</span><span class="p">)</span>
        <span class="n">x_seq</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">cur_x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x_seq</span>
<span class="k">def</span> <span class="nf">noise_estimation_loss</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">x_0</span><span class="p">,</span><span class="n">alphas_bar_sqrt</span><span class="p">,</span><span class="n">one_minus_alphas_bar_sqrt</span><span class="p">,</span><span class="n">n_steps</span><span class="p">):</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">x_0</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="c1"># Select a random step for each example
</span>    <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size</span> <span class="o">//</span> <span class="mi">2</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,))</span>
    <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">([</span><span class="n">t</span><span class="p">,</span> <span class="n">n_steps</span> <span class="o">-</span> <span class="n">t</span> <span class="o">-</span> <span class="mi">1</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)[:</span><span class="n">batch_size</span><span class="p">].</span><span class="nb">long</span><span class="p">()</span>
    <span class="c1"># x0 multiplier
</span>    <span class="n">a</span> <span class="o">=</span> <span class="n">extract</span><span class="p">(</span><span class="n">alphas_bar_sqrt</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_0</span><span class="p">)</span>
    <span class="c1"># eps multiplier
</span>    <span class="n">am1</span> <span class="o">=</span> <span class="n">extract</span><span class="p">(</span><span class="n">one_minus_alphas_bar_sqrt</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_0</span><span class="p">)</span>
    <span class="n">e</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">x_0</span><span class="p">)</span>
    <span class="c1"># model input
</span>    <span class="n">x</span> <span class="o">=</span> <span class="n">x_0</span> <span class="o">*</span> <span class="n">a</span> <span class="o">+</span> <span class="n">e</span> <span class="o">*</span> <span class="n">am1</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">e</span> <span class="o">-</span> <span class="n">output</span><span class="p">).</span><span class="n">square</span><span class="p">().</span><span class="n">mean</span><span class="p">()</span>    

<span class="c1">#An Implementation of Diffusion Network Model
#Oringinal source: https://github.com/acids-ircam/diffusion_models
</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="n">F</span>

<span class="k">class</span> <span class="nc">ConditionalLinear</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_in</span><span class="p">,</span> <span class="n">num_out</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ConditionalLinear</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">num_out</span> <span class="o">=</span> <span class="n">num_out</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">lin</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">num_in</span><span class="p">,</span> <span class="n">num_out</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">embed</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">n_steps</span><span class="p">,</span> <span class="n">num_out</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">embed</span><span class="p">.</span><span class="n">weight</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">uniform_</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">lin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">gamma</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">embed</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">gamma</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">num_out</span><span class="p">)</span> <span class="o">*</span> <span class="n">out</span>
        <span class="k">return</span> <span class="n">out</span>
        
<span class="k">class</span> <span class="nc">ConditionalModel</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ConditionalModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">lin1</span> <span class="o">=</span> <span class="n">ConditionalLinear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">lin2</span> <span class="o">=</span> <span class="n">ConditionalLinear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">lin3</span> <span class="o">=</span> <span class="n">ConditionalLinear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">lin4</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">softplus</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">lin1</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">softplus</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">lin2</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">softplus</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">lin3</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">lin4</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#from model import ConditionalModel
</span><span class="kn">from</span> <span class="nn">ema</span> <span class="kn">import</span> <span class="n">EMA</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="n">optim</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">ConditionalModel</span><span class="p">(</span><span class="n">num_steps</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="p">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
<span class="c1">#dataset = torch.tensor(data.T).float()
# Create EMA model
</span><span class="n">ema</span> <span class="o">=</span> <span class="n">EMA</span><span class="p">(</span><span class="mf">0.9</span><span class="p">)</span>
<span class="n">ema</span><span class="p">.</span><span class="n">register</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="c1"># Batch size
</span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">):</span>
    <span class="c1"># X is a torch Variable
</span>    <span class="n">permutation</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randperm</span><span class="p">(</span><span class="n">dataset</span><span class="p">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">0</span><span class="p">])</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">dataset</span><span class="p">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">0</span><span class="p">],</span> <span class="n">batch_size</span><span class="p">):</span>
        <span class="c1"># Retrieve current batch
</span>        <span class="n">indices</span> <span class="o">=</span> <span class="n">permutation</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">batch_size</span><span class="p">]</span>
        <span class="n">batch_x</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>
        <span class="c1"># Compute the loss.
</span>        <span class="n">loss</span> <span class="o">=</span> <span class="n">noise_estimation_loss</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">batch_x</span><span class="p">,</span><span class="n">alphas_bar_sqrt</span><span class="p">,</span><span class="n">one_minus_alphas_bar_sqrt</span><span class="p">,</span><span class="n">num_steps</span><span class="p">)</span>
        <span class="c1"># Before the backward pass, zero all of the network gradients
</span>        <span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="c1"># Backward pass: compute gradient of the loss with respect to parameters
</span>        <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="c1"># Perform gradient clipping
</span>        <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="mf">1.</span><span class="p">)</span>
        <span class="c1"># Calling the step function to update the parameters
</span>        <span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
        <span class="c1"># Update the exponential moving average
</span>        <span class="n">ema</span><span class="p">.</span><span class="n">update</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
    <span class="c1"># Print loss
</span>    <span class="k">if</span> <span class="p">(</span><span class="n">t</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
        <span class="k">print</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
        <span class="n">x_seq</span> <span class="o">=</span> <span class="n">p_sample_loop</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dataset</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span><span class="n">num_steps</span><span class="p">,</span><span class="n">alphas</span><span class="p">,</span><span class="n">betas</span><span class="p">,</span><span class="n">one_minus_alphas_bar_sqrt</span><span class="p">)</span>
        <span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">11</span><span class="p">):</span>
            <span class="n">cur_x</span> <span class="o">=</span> <span class="n">x_seq</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="mi">10</span><span class="p">].</span><span class="n">detach</span><span class="p">()</span>
            <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">].</span><span class="n">scatter</span><span class="p">(</span><span class="n">cur_x</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">cur_x</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s">'white'</span><span class="p">,</span><span class="n">edgecolor</span><span class="o">=</span><span class="s">'gray'</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">5</span><span class="p">);</span>
            <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">].</span><span class="n">set_axis_off</span><span class="p">();</span> 
            <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">'$q(\mathbf{x}_{'</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span><span class="o">+</span><span class="s">'})$'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensor(0.9140, grad_fn=&lt;MeanBackward0&gt;)
tensor(0.6532, grad_fn=&lt;MeanBackward0&gt;)
tensor(0.6371, grad_fn=&lt;MeanBackward0&gt;)
tensor(0.8389, grad_fn=&lt;MeanBackward0&gt;)
tensor(0.6238, grad_fn=&lt;MeanBackward0&gt;)
tensor(0.5684, grad_fn=&lt;MeanBackward0&gt;)
tensor(0.8178, grad_fn=&lt;MeanBackward0&gt;)
tensor(0.7874, grad_fn=&lt;MeanBackward0&gt;)
tensor(0.7548, grad_fn=&lt;MeanBackward0&gt;)
tensor(0.8650, grad_fn=&lt;MeanBackward0&gt;)
</code></pre></div></div>

<p><img src="/assets/2023-12-01-diffusion-model-demo1_files/2023-12-01-diffusion-model-demo1_21_1.png" alt="png" /></p>

<p><img src="/assets/2023-12-01-diffusion-model-demo1_files/2023-12-01-diffusion-model-demo1_21_2.png" alt="png" /></p>

<p><img src="/assets/2023-12-01-diffusion-model-demo1_files/2023-12-01-diffusion-model-demo1_21_3.png" alt="png" /></p>

<p><img src="/assets/2023-12-01-diffusion-model-demo1_files/2023-12-01-diffusion-model-demo1_21_4.png" alt="png" /></p>

<p><img src="/assets/2023-12-01-diffusion-model-demo1_files/2023-12-01-diffusion-model-demo1_21_5.png" alt="png" /></p>

<p><img src="/assets/2023-12-01-diffusion-model-demo1_files/2023-12-01-diffusion-model-demo1_21_6.png" alt="png" /></p>

<p><img src="/assets/2023-12-01-diffusion-model-demo1_files/2023-12-01-diffusion-model-demo1_21_7.png" alt="png" /></p>

<p><img src="/assets/2023-12-01-diffusion-model-demo1_files/2023-12-01-diffusion-model-demo1_21_8.png" alt="png" /></p>

<p><img src="/assets/2023-12-01-diffusion-model-demo1_files/2023-12-01-diffusion-model-demo1_21_9.png" alt="png" /></p>

<p><img src="/assets/2023-12-01-diffusion-model-demo1_files/2023-12-01-diffusion-model-demo1_21_10.png" alt="png" /></p>

<h2 id="animation">Animation</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Generating the forward image sequence
</span>
<span class="kn">import</span> <span class="nn">io</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>

<span class="n">imgs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="c1">#fig, axs = plt.subplots(1, 10, figsize=(28, 3))
</span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">clf</span><span class="p">()</span>
    <span class="n">q_i</span> <span class="o">=</span> <span class="n">q_x</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">i</span><span class="p">]))</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">q_i</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">q_i</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s">'white'</span><span class="p">,</span><span class="n">edgecolor</span><span class="o">=</span><span class="s">'gray'</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">5</span><span class="p">);</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">axis</span><span class="p">(</span><span class="s">'off'</span><span class="p">);</span> 
    
    <span class="n">img_buf</span> <span class="o">=</span> <span class="n">io</span><span class="p">.</span><span class="n">BytesIO</span><span class="p">()</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">img_buf</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s">'png'</span><span class="p">)</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">Image</span><span class="p">.</span><span class="nb">open</span><span class="p">(</span><span class="n">img_buf</span><span class="p">)</span>
    <span class="n">imgs</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
    
</code></pre></div></div>

<p><img src="/assets/2023-12-01-diffusion-model-demo1_files/2023-12-01-diffusion-model-demo1_23_0.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Generating the reverse diffusion sequence
</span>
<span class="n">reverse</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>  
    <span class="n">plt</span><span class="p">.</span><span class="n">clf</span><span class="p">()</span>
    <span class="n">cur_x</span> <span class="o">=</span> <span class="n">x_seq</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">detach</span><span class="p">()</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">cur_x</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">cur_x</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s">'white'</span><span class="p">,</span><span class="n">edgecolor</span><span class="o">=</span><span class="s">'gray'</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">5</span><span class="p">);</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">axis</span><span class="p">(</span><span class="s">'off'</span><span class="p">)</span>
    
    <span class="n">img_buf</span> <span class="o">=</span> <span class="n">io</span><span class="p">.</span><span class="n">BytesIO</span><span class="p">()</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">img_buf</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s">'png'</span><span class="p">)</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">Image</span><span class="p">.</span><span class="nb">open</span><span class="p">(</span><span class="n">img_buf</span><span class="p">)</span>
    <span class="n">reverse</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/assets/2023-12-01-diffusion-model-demo1_files/2023-12-01-diffusion-model-demo1_24_0.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">imgs</span> <span class="o">=</span> <span class="n">imgs</span> <span class="o">+</span> <span class="n">reverse</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">imgs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">save</span><span class="p">(</span><span class="s">"diffusion.gif"</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s">'GIF'</span><span class="p">,</span> <span class="n">append_images</span><span class="o">=</span><span class="n">imgs</span><span class="p">,</span><span class="n">save_all</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">duration</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">loop</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div></div>

<h1 id="references">References</h1>

<p>[1] Ho, J., Jain, A., &amp; Abbeel, P. (2020). Denoising diffusion probabilistic models. arXiv preprint arXiv:2006.11239.</p>

<p>[2] Sohl-Dickstein, J., Weiss, E. A., Maheswaranathan, N., &amp; Ganguli, S. (2015). Deep unsupervised learning using nonequilibrium thermodynamics. arXiv preprint arXiv:1503.03585.</p>]]></content><author><name>Zhu Tianda</name></author><category term="coding" /><category term="AI" /><category term="Diffusion" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">A Diffusion Model from Scratch in Pytorch</title><link href="http://0.0.0.0:8855/coding/2023/12/11/diffusion-model-demo2.html" rel="alternate" type="text/html" title="A Diffusion Model from Scratch in Pytorch" /><published>2023-12-11T00:00:00+08:00</published><updated>2023-12-11T00:00:00+08:00</updated><id>http://0.0.0.0:8855/coding/2023/12/11/diffusion-model-demo2</id><content type="html" xml:base="http://0.0.0.0:8855/coding/2023/12/11/diffusion-model-demo2.html"><![CDATA[<h1 id="a-diffusion-model-from-scratch-in-pytorch">A Diffusion Model from Scratch in Pytorch</h1>

<p>In this notebook I want to build a very simple (as few code as possible) Diffusion Model for generating car images. I will explain all the theoretical details in the YouTube video.</p>

<p><strong>Sources:</strong></p>
<ul>
  <li>Github implementation <a href="https://github.com/lucidrains/denoising-diffusion-pytorch">Denoising Diffusion Pytorch</a></li>
  <li>Niels Rogge, Kashif Rasul, <a href="https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/annotated_diffusion.ipynb#scrollTo=3a159023">Huggingface notebook</a></li>
  <li>Papers on Diffusion models ([Dhariwal, Nichol, 2021], [Ho et al., 2020] ect.)</li>
</ul>

<h2 id="investigating-the-dataset">Investigating the dataset</h2>

<p>As dataset we use the StandordCars Dataset, which consists of around 8000 images in the train set. Let’s see if this is enough to get good results ;-)</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torchvision</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="k">def</span> <span class="nf">show_images</span><span class="p">(</span><span class="n">datset</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">cols</span><span class="o">=</span><span class="mi">4</span><span class="p">):</span>
    <span class="s">""" Plots some samples from the dataset """</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">15</span><span class="p">))</span> 
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">img</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="n">num_samples</span><span class="p">:</span>
            <span class="k">break</span>
        <span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">num_samples</span><span class="o">/</span><span class="n">cols</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">cols</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span> <span class="o">=</span> <span class="n">torchvision</span><span class="p">.</span><span class="n">datasets</span><span class="p">.</span><span class="n">StanfordCars</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s">"."</span><span class="p">)</span>
<span class="n">show_images</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/assets/2023-12-11-diffusion-model-demo2_files/2023-12-11-diffusion-model-demo2_3_0.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#Try to setup cars image locally by own dataset
#dataset = torchvision.datasets.ImageFolder("./stanford_cars")
#show_images(data)
</span>
<span class="c1">#dataset = V.datasets.ImageFolder(args.dataset_path, transform=transforms)
#dataloader = DataLoader(dataset, batch_size=args.batch_size, shuffle=True)
</span>
</code></pre></div></div>

<p>Later in this notebook we will do some additional modifications to this dataset, for example make the images smaller, convert them to tensors ect.</p>

<h1 id="building-the-diffusion-model">Building the Diffusion Model</h1>

<h2 id="step-1-the-forward-process--noise-scheduler">Step 1: The forward process = Noise scheduler</h2>

<p>We first need to build the inputs for our model, which are more and more noisy images. Instead of doing this sequentially, we can use the closed form provided in the papers to calculate the image for any of the timesteps individually.</p>

<p><strong>Key Takeaways</strong>:</p>
<ul>
  <li>The noise-levels/variances can be pre-computed</li>
  <li>There are different types of variance schedules</li>
  <li>We can sample each timestep image independently (Sums of Gaussians is also Gaussian)</li>
  <li>No model is needed in this forward step</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="n">F</span>

<span class="k">def</span> <span class="nf">linear_beta_schedule</span><span class="p">(</span><span class="n">timesteps</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="mf">0.02</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">timesteps</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">get_index_from_list</span><span class="p">(</span><span class="n">vals</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_shape</span><span class="p">):</span>
    <span class="s">""" 
    Returns a specific index t of a passed list of values vals
    while considering the batch dimension.
    """</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">t</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">vals</span><span class="p">.</span><span class="n">gather</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">t</span><span class="p">.</span><span class="n">cpu</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">out</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">*</span><span class="p">((</span><span class="mi">1</span><span class="p">,)</span> <span class="o">*</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x_shape</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))).</span><span class="n">to</span><span class="p">(</span><span class="n">t</span><span class="p">.</span><span class="n">device</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">forward_diffusion_sample</span><span class="p">(</span><span class="n">x_0</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s">"cpu"</span><span class="p">):</span>
    <span class="s">""" 
    Takes an image and a timestep as input and 
    returns the noisy version of it
    """</span>
    <span class="n">noise</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">x_0</span><span class="p">)</span>
    <span class="n">sqrt_alphas_cumprod_t</span> <span class="o">=</span> <span class="n">get_index_from_list</span><span class="p">(</span><span class="n">sqrt_alphas_cumprod</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_0</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">sqrt_one_minus_alphas_cumprod_t</span> <span class="o">=</span> <span class="n">get_index_from_list</span><span class="p">(</span>
        <span class="n">sqrt_one_minus_alphas_cumprod</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_0</span><span class="p">.</span><span class="n">shape</span>
    <span class="p">)</span>
    <span class="c1"># mean + variance
</span>    <span class="k">return</span> <span class="n">sqrt_alphas_cumprod_t</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="o">*</span> <span class="n">x_0</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> \
    <span class="o">+</span> <span class="n">sqrt_one_minus_alphas_cumprod_t</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="o">*</span> <span class="n">noise</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">noise</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>


<span class="c1"># Define beta schedule
</span><span class="n">T</span> <span class="o">=</span> <span class="mi">300</span>
<span class="n">betas</span> <span class="o">=</span> <span class="n">linear_beta_schedule</span><span class="p">(</span><span class="n">timesteps</span><span class="o">=</span><span class="n">T</span><span class="p">)</span>

<span class="c1"># Pre-calculate different terms for closed form
</span><span class="n">alphas</span> <span class="o">=</span> <span class="mf">1.</span> <span class="o">-</span> <span class="n">betas</span>
<span class="n">alphas_cumprod</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cumprod</span><span class="p">(</span><span class="n">alphas</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">alphas_cumprod_prev</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">pad</span><span class="p">(</span><span class="n">alphas_cumprod</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">value</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<span class="n">sqrt_recip_alphas</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="n">alphas</span><span class="p">)</span>
<span class="n">sqrt_alphas_cumprod</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">alphas_cumprod</span><span class="p">)</span>
<span class="n">sqrt_one_minus_alphas_cumprod</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="n">alphas_cumprod</span><span class="p">)</span>
<span class="n">posterior_variance</span> <span class="o">=</span> <span class="n">betas</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="n">alphas_cumprod_prev</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="n">alphas_cumprod</span><span class="p">)</span>
</code></pre></div></div>

<p>Let’s test it on our dataset …</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">transforms</span> 
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="n">IMG_SIZE</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">128</span>

<span class="k">def</span> <span class="nf">load_transformed_dataset</span><span class="p">():</span>
    <span class="n">data_transforms</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">transforms</span><span class="p">.</span><span class="n">Resize</span><span class="p">((</span><span class="n">IMG_SIZE</span><span class="p">,</span> <span class="n">IMG_SIZE</span><span class="p">)),</span>
        <span class="n">transforms</span><span class="p">.</span><span class="n">RandomHorizontalFlip</span><span class="p">(),</span>
        <span class="n">transforms</span><span class="p">.</span><span class="n">ToTensor</span><span class="p">(),</span> <span class="c1"># Scales data into [0,1] 
</span>        <span class="n">transforms</span><span class="p">.</span><span class="n">Lambda</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="p">(</span><span class="n">t</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># Scale between [-1, 1] 
</span>    <span class="p">]</span>
    <span class="n">data_transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="p">.</span><span class="n">Compose</span><span class="p">(</span><span class="n">data_transforms</span><span class="p">)</span>

    <span class="n">train</span> <span class="o">=</span> <span class="n">torchvision</span><span class="p">.</span><span class="n">datasets</span><span class="p">.</span><span class="n">StanfordCars</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s">"."</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
                                         <span class="n">transform</span><span class="o">=</span><span class="n">data_transform</span><span class="p">)</span>

    <span class="n">test</span> <span class="o">=</span> <span class="n">torchvision</span><span class="p">.</span><span class="n">datasets</span><span class="p">.</span><span class="n">StanfordCars</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s">"."</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
                                         <span class="n">transform</span><span class="o">=</span><span class="n">data_transform</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s">'test'</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">ConcatDataset</span><span class="p">([</span><span class="n">train</span><span class="p">,</span> <span class="n">test</span><span class="p">])</span>
<span class="k">def</span> <span class="nf">show_tensor_image</span><span class="p">(</span><span class="n">image</span><span class="p">):</span>
    <span class="n">reverse_transforms</span> <span class="o">=</span> <span class="n">transforms</span><span class="p">.</span><span class="n">Compose</span><span class="p">([</span>
        <span class="n">transforms</span><span class="p">.</span><span class="n">Lambda</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="p">(</span><span class="n">t</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">),</span>
        <span class="n">transforms</span><span class="p">.</span><span class="n">Lambda</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">t</span><span class="p">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">)),</span> <span class="c1"># CHW to HWC
</span>        <span class="n">transforms</span><span class="p">.</span><span class="n">Lambda</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">t</span> <span class="o">*</span> <span class="mf">255.</span><span class="p">),</span>
        <span class="n">transforms</span><span class="p">.</span><span class="n">Lambda</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">t</span><span class="p">.</span><span class="n">numpy</span><span class="p">().</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">uint8</span><span class="p">)),</span>
        <span class="n">transforms</span><span class="p">.</span><span class="n">ToPILImage</span><span class="p">(),</span>
    <span class="p">])</span>

    <span class="c1"># Take first image of batch
</span>    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">image</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
        <span class="n">image</span> <span class="o">=</span> <span class="n">image</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:]</span> 
    <span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">reverse_transforms</span><span class="p">(</span><span class="n">image</span><span class="p">))</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">load_transformed_dataset</span><span class="p">()</span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">drop_last</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Simulate forward diffusion
</span><span class="n">image</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">dataloader</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>

<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">15</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">axis</span><span class="p">(</span><span class="s">'off'</span><span class="p">)</span>
<span class="n">num_images</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">stepsize</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">T</span><span class="o">/</span><span class="n">num_images</span><span class="p">)</span>

<span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">stepsize</span><span class="p">):</span>
    <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">([</span><span class="n">idx</span><span class="p">]).</span><span class="nb">type</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">int64</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_images</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">idx</span><span class="o">/</span><span class="n">stepsize</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">img</span><span class="p">,</span> <span class="n">noise</span> <span class="o">=</span> <span class="n">forward_diffusion_sample</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
    <span class="n">show_tensor_image</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>/tmp/ipykernel_215535/1509478405.py:11: MatplotlibDeprecationWarning: Auto-removal of overlapping axes is deprecated since 3.6 and will be removed two minor releases later; explicitly call ax.remove() as needed.
  plt.subplot(1, num_images+1, int(idx/stepsize) + 1)
</code></pre></div></div>

<p><img src="/assets/2023-12-11-diffusion-model-demo2_files/2023-12-11-diffusion-model-demo2_12_1.png" alt="png" /></p>

<h2 id="step-2-the-backward-process--u-net">Step 2: The backward process = U-Net</h2>

<p>For a great introduction to UNets, have a look at this post: https://amaarora.github.io/2020/09/13/unet.html.</p>

<p><strong>Key Takeaways</strong>:</p>
<ul>
  <li>We use a simple form of a UNet for to predict the noise in the image</li>
  <li>The input is a noisy image, the ouput the noise in the image</li>
  <li>Because the parameters are shared accross time, we need to tell the network in which timestep we are</li>
  <li>The Timestep is encoded by the transformer Sinusoidal Embedding</li>
  <li>We output one single value (mean), because the variance is fixed</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="nn">math</span>


<span class="k">class</span> <span class="nc">Block</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_ch</span><span class="p">,</span> <span class="n">out_ch</span><span class="p">,</span> <span class="n">time_emb_dim</span><span class="p">,</span> <span class="n">up</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">time_mlp</span> <span class="o">=</span>  <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">time_emb_dim</span><span class="p">,</span> <span class="n">out_ch</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">up</span><span class="p">:</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">in_ch</span><span class="p">,</span> <span class="n">out_ch</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">transform</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span><span class="n">out_ch</span><span class="p">,</span> <span class="n">out_ch</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_ch</span><span class="p">,</span> <span class="n">out_ch</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">transform</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">out_ch</span><span class="p">,</span> <span class="n">out_ch</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">out_ch</span><span class="p">,</span> <span class="n">out_ch</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">bnorm1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">out_ch</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">bnorm2</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">out_ch</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">relu</span>  <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">()</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="p">):</span>
        <span class="c1"># First Conv
</span>        <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">bnorm1</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
        <span class="c1"># Time embedding
</span>        <span class="n">time_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">time_mlp</span><span class="p">(</span><span class="n">t</span><span class="p">))</span>
        <span class="c1"># Extend last 2 dimensions
</span>        <span class="n">time_emb</span> <span class="o">=</span> <span class="n">time_emb</span><span class="p">[(...,</span> <span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="p">)</span> <span class="o">*</span> <span class="mi">2</span><span class="p">]</span>
        <span class="c1"># Add time channel
</span>        <span class="n">h</span> <span class="o">=</span> <span class="n">h</span> <span class="o">+</span> <span class="n">time_emb</span>
        <span class="c1"># Second Conv
</span>        <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">bnorm2</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">h</span><span class="p">)))</span>
        <span class="c1"># Down or Upsample
</span>        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">SinusoidalPositionEmbeddings</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">dim</span> <span class="o">=</span> <span class="n">dim</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">time</span><span class="p">):</span>
        <span class="n">device</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="n">device</span>
        <span class="n">half_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">dim</span> <span class="o">//</span> <span class="mi">2</span>
        <span class="n">embeddings</span> <span class="o">=</span> <span class="n">math</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="mi">10000</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">half_dim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">embeddings</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="n">half_dim</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span> <span class="o">*</span> <span class="o">-</span><span class="n">embeddings</span><span class="p">)</span>
        <span class="n">embeddings</span> <span class="o">=</span> <span class="n">time</span><span class="p">[:,</span> <span class="bp">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">embeddings</span><span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="p">:]</span>
        <span class="n">embeddings</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">((</span><span class="n">embeddings</span><span class="p">.</span><span class="n">sin</span><span class="p">(),</span> <span class="n">embeddings</span><span class="p">.</span><span class="n">cos</span><span class="p">()),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># TODO: Double check the ordering here
</span>        <span class="k">return</span> <span class="n">embeddings</span>


<span class="k">class</span> <span class="nc">SimpleUnet</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="s">"""
    A simplified variant of the Unet architecture.
    """</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="n">image_channels</span> <span class="o">=</span> <span class="mi">3</span>
        <span class="n">down_channels</span> <span class="o">=</span> <span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">1024</span><span class="p">)</span>
        <span class="n">up_channels</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>
        <span class="n">out_dim</span> <span class="o">=</span> <span class="mi">3</span> 
        <span class="n">time_emb_dim</span> <span class="o">=</span> <span class="mi">32</span>

        <span class="c1"># Time embedding
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">time_mlp</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
                <span class="n">SinusoidalPositionEmbeddings</span><span class="p">(</span><span class="n">time_emb_dim</span><span class="p">),</span>
                <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">time_emb_dim</span><span class="p">,</span> <span class="n">time_emb_dim</span><span class="p">),</span>
                <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">()</span>
            <span class="p">)</span>
        
        <span class="c1"># Initial projection
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">conv0</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">image_channels</span><span class="p">,</span> <span class="n">down_channels</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Downsample
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">downs</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">ModuleList</span><span class="p">([</span><span class="n">Block</span><span class="p">(</span><span class="n">down_channels</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">down_channels</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> \
                                    <span class="n">time_emb_dim</span><span class="p">)</span> \
                    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">down_channels</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">)])</span>
        <span class="c1"># Upsample
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">ups</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">ModuleList</span><span class="p">([</span><span class="n">Block</span><span class="p">(</span><span class="n">up_channels</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">up_channels</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> \
                                        <span class="n">time_emb_dim</span><span class="p">,</span> <span class="n">up</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> \
                    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">up_channels</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">)])</span>
        
        <span class="c1"># Edit: Corrected a bug found by Jakub C (see YouTube comment)
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">output</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">up_channels</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">out_dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">timestep</span><span class="p">):</span>
        <span class="c1"># Embedd time
</span>        <span class="n">t</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">time_mlp</span><span class="p">(</span><span class="n">timestep</span><span class="p">)</span>
        <span class="c1"># Initial conv
</span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">conv0</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="c1"># Unet
</span>        <span class="n">residual_inputs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">down</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">downs</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">down</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
            <span class="n">residual_inputs</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">up</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">ups</span><span class="p">:</span>
            <span class="n">residual_x</span> <span class="o">=</span> <span class="n">residual_inputs</span><span class="p">.</span><span class="n">pop</span><span class="p">()</span>
            <span class="c1"># Add residual x as additional channels
</span>            <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">residual_x</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>           
            <span class="n">x</span> <span class="o">=</span> <span class="n">up</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">output</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">SimpleUnet</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Num params: "</span><span class="p">,</span> <span class="nb">sum</span><span class="p">(</span><span class="n">p</span><span class="p">.</span><span class="n">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">()))</span>
<span class="n">model</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Num params:  62438883





SimpleUnet(
  (time_mlp): Sequential(
    (0): SinusoidalPositionEmbeddings()
    (1): Linear(in_features=32, out_features=32, bias=True)
    (2): ReLU()
  )
  (conv0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (downs): ModuleList(
    (0): Block(
      (time_mlp): Linear(in_features=32, out_features=128, bias=True)
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (transform): Conv2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bnorm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bnorm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU()
    )
    (1): Block(
      (time_mlp): Linear(in_features=32, out_features=256, bias=True)
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (transform): Conv2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bnorm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bnorm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU()
    )
    (2): Block(
      (time_mlp): Linear(in_features=32, out_features=512, bias=True)
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (transform): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bnorm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bnorm2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU()
    )
    (3): Block(
      (time_mlp): Linear(in_features=32, out_features=1024, bias=True)
      (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (transform): Conv2d(1024, 1024, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bnorm1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bnorm2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU()
    )
  )
  (ups): ModuleList(
    (0): Block(
      (time_mlp): Linear(in_features=32, out_features=512, bias=True)
      (conv1): Conv2d(2048, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (transform): ConvTranspose2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bnorm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bnorm2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU()
    )
    (1): Block(
      (time_mlp): Linear(in_features=32, out_features=256, bias=True)
      (conv1): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (transform): ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bnorm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bnorm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU()
    )
    (2): Block(
      (time_mlp): Linear(in_features=32, out_features=128, bias=True)
      (conv1): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (transform): ConvTranspose2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bnorm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bnorm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU()
    )
    (3): Block(
      (time_mlp): Linear(in_features=32, out_features=64, bias=True)
      (conv1): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (transform): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bnorm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bnorm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU()
    )
  )
  (output): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))
)
</code></pre></div></div>

<p><strong>Further improvements that can be implemented:</strong></p>
<ul>
  <li>Residual connections</li>
  <li>Different activation functions like SiLU, GWLU, …</li>
  <li>BatchNormalization</li>
  <li>GroupNormalization</li>
  <li>Attention</li>
  <li>…</li>
</ul>

<h2 id="step-3-the-loss">Step 3: The loss</h2>

<p><strong>Key Takeaways:</strong></p>
<ul>
  <li>After some maths we end up with a very simple loss function</li>
  <li>There are other possible choices like L2 loss ect.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">get_loss</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">x_0</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
    <span class="n">x_noisy</span><span class="p">,</span> <span class="n">noise</span> <span class="o">=</span> <span class="n">forward_diffusion_sample</span><span class="p">(</span><span class="n">x_0</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
    <span class="n">noise_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x_noisy</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">F</span><span class="p">.</span><span class="n">l1_loss</span><span class="p">(</span><span class="n">noise</span><span class="p">,</span> <span class="n">noise_pred</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="sampling">Sampling</h2>
<ul>
  <li>Without adding @torch.no_grad() we quickly run out of memory, because pytorch tacks all the previous images for gradient calculation</li>
  <li>Because we pre-calculated the noise variances for the forward pass, we also have to use them when we sequentially perform the backward process</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">@</span><span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">sample_timestep</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
    <span class="s">"""
    Calls the model to predict the noise in the image and returns 
    the denoised image. 
    Applies noise to this image, if we are not in the last step yet.
    """</span>
    <span class="n">betas_t</span> <span class="o">=</span> <span class="n">get_index_from_list</span><span class="p">(</span><span class="n">betas</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">sqrt_one_minus_alphas_cumprod_t</span> <span class="o">=</span> <span class="n">get_index_from_list</span><span class="p">(</span>
        <span class="n">sqrt_one_minus_alphas_cumprod</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span>
    <span class="p">)</span>
    <span class="n">sqrt_recip_alphas_t</span> <span class="o">=</span> <span class="n">get_index_from_list</span><span class="p">(</span><span class="n">sqrt_recip_alphas</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
    
    <span class="c1"># Call model (current image - noise prediction)
</span>    <span class="n">model_mean</span> <span class="o">=</span> <span class="n">sqrt_recip_alphas_t</span> <span class="o">*</span> <span class="p">(</span>
        <span class="n">x</span> <span class="o">-</span> <span class="n">betas_t</span> <span class="o">*</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span> <span class="o">/</span> <span class="n">sqrt_one_minus_alphas_cumprod_t</span>
    <span class="p">)</span>
    <span class="n">posterior_variance_t</span> <span class="o">=</span> <span class="n">get_index_from_list</span><span class="p">(</span><span class="n">posterior_variance</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">t</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># As pointed out by Luis Pereira (see YouTube comment)
</span>        <span class="c1"># The t's are offset from the t's in the paper
</span>        <span class="k">return</span> <span class="n">model_mean</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">noise</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">model_mean</span> <span class="o">+</span> <span class="n">torch</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">posterior_variance_t</span><span class="p">)</span> <span class="o">*</span> <span class="n">noise</span> 

<span class="o">@</span><span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">sample_plot_image</span><span class="p">():</span>
    <span class="c1"># Sample noise
</span>    <span class="n">img_size</span> <span class="o">=</span> <span class="n">IMG_SIZE</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">img_size</span><span class="p">,</span> <span class="n">img_size</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">15</span><span class="p">))</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">axis</span><span class="p">(</span><span class="s">'off'</span><span class="p">)</span>
    <span class="n">num_images</span> <span class="o">=</span> <span class="mi">10</span>
    <span class="n">stepsize</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">T</span><span class="o">/</span><span class="n">num_images</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">T</span><span class="p">)[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">full</span><span class="p">((</span><span class="mi">1</span><span class="p">,),</span> <span class="n">i</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nb">long</span><span class="p">)</span>
        <span class="n">img</span> <span class="o">=</span> <span class="n">sample_timestep</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
        <span class="c1"># Edit: This is to maintain the natural range of the distribution
</span>        <span class="n">img</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="n">stepsize</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_images</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">i</span><span class="o">/</span><span class="n">stepsize</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">show_tensor_image</span><span class="p">(</span><span class="n">img</span><span class="p">.</span><span class="n">detach</span><span class="p">().</span><span class="n">cpu</span><span class="p">())</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>            
</code></pre></div></div>

<h2 id="training">Training</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>

<span class="n">device</span> <span class="o">=</span> <span class="s">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s">"cpu"</span>
<span class="n">model</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">100</span> <span class="c1"># Try more!
</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">step</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">):</span>
      <span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>

      <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="p">(</span><span class="n">BATCH_SIZE</span><span class="p">,),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">).</span><span class="nb">long</span><span class="p">()</span>
      <span class="n">loss</span> <span class="o">=</span> <span class="n">get_loss</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">t</span><span class="p">)</span>
      <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
      <span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>

      <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="mi">5</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">step</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s"> | step </span><span class="si">{</span><span class="n">step</span><span class="si">:</span><span class="mi">03</span><span class="n">d</span><span class="si">}</span><span class="s"> Loss: </span><span class="si">{</span><span class="n">loss</span><span class="p">.</span><span class="n">item</span><span class="p">()</span><span class="si">}</span><span class="s"> "</span><span class="p">)</span>
        <span class="n">sample_plot_image</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 0 | step 000 Loss: 0.8095802068710327 


/tmp/ipykernel_215535/364762590.py:44: MatplotlibDeprecationWarning: Auto-removal of overlapping axes is deprecated since 3.6 and will be removed two minor releases later; explicitly call ax.remove() as needed.
  plt.subplot(1, num_images, int(i/stepsize)+1)
</code></pre></div></div>

<p><img src="/assets/2023-12-11-diffusion-model-demo2_files/2023-12-11-diffusion-model-demo2_23_2.png" alt="png" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 5 | step 000 Loss: 0.16724281013011932 
</code></pre></div></div>

<p><img src="/assets/2023-12-11-diffusion-model-demo2_files/2023-12-11-diffusion-model-demo2_23_4.png" alt="png" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 10 | step 000 Loss: 0.1452174186706543 
</code></pre></div></div>

<p><img src="/assets/2023-12-11-diffusion-model-demo2_files/2023-12-11-diffusion-model-demo2_23_6.png" alt="png" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 15 | step 000 Loss: 0.1479429304599762 
</code></pre></div></div>

<p><img src="/assets/2023-12-11-diffusion-model-demo2_files/2023-12-11-diffusion-model-demo2_23_8.png" alt="png" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 20 | step 000 Loss: 0.1445147842168808 
</code></pre></div></div>

<p><img src="/assets/2023-12-11-diffusion-model-demo2_files/2023-12-11-diffusion-model-demo2_23_10.png" alt="png" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 25 | step 000 Loss: 0.1543230563402176 
</code></pre></div></div>

<p><img src="/assets/2023-12-11-diffusion-model-demo2_files/2023-12-11-diffusion-model-demo2_23_12.png" alt="png" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 30 | step 000 Loss: 0.13048508763313293 
</code></pre></div></div>

<p><img src="/assets/2023-12-11-diffusion-model-demo2_files/2023-12-11-diffusion-model-demo2_23_14.png" alt="png" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 35 | step 000 Loss: 0.14282932877540588 
</code></pre></div></div>

<p><img src="/assets/2023-12-11-diffusion-model-demo2_files/2023-12-11-diffusion-model-demo2_23_16.png" alt="png" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 40 | step 000 Loss: 0.14221858978271484 
</code></pre></div></div>

<p><img src="/assets/2023-12-11-diffusion-model-demo2_files/2023-12-11-diffusion-model-demo2_23_18.png" alt="png" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 45 | step 000 Loss: 0.13406036794185638 
</code></pre></div></div>

<p><img src="/assets/2023-12-11-diffusion-model-demo2_files/2023-12-11-diffusion-model-demo2_23_20.png" alt="png" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 50 | step 000 Loss: 0.14082683622837067 
</code></pre></div></div>

<p><img src="/assets/2023-12-11-diffusion-model-demo2_files/2023-12-11-diffusion-model-demo2_23_22.png" alt="png" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 55 | step 000 Loss: 0.13268257677555084 
</code></pre></div></div>

<p><img src="/assets/2023-12-11-diffusion-model-demo2_files/2023-12-11-diffusion-model-demo2_23_24.png" alt="png" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 60 | step 000 Loss: 0.1329515129327774 
</code></pre></div></div>

<p><img src="/assets/2023-12-11-diffusion-model-demo2_files/2023-12-11-diffusion-model-demo2_23_26.png" alt="png" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 65 | step 000 Loss: 0.12477826327085495 
</code></pre></div></div>

<p><img src="/assets/2023-12-11-diffusion-model-demo2_files/2023-12-11-diffusion-model-demo2_23_28.png" alt="png" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 70 | step 000 Loss: 0.14115868508815765 
</code></pre></div></div>

<p><img src="/assets/2023-12-11-diffusion-model-demo2_files/2023-12-11-diffusion-model-demo2_23_30.png" alt="png" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 75 | step 000 Loss: 0.1246982216835022 
Epoch 80 | step 000 Loss: 0.14474114775657654 
</code></pre></div></div>

<p><img src="/assets/2023-12-11-diffusion-model-demo2_files/2023-12-11-diffusion-model-demo2_23_32.png" alt="png" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 85 | step 000 Loss: 0.12441752851009369 
</code></pre></div></div>

<p><img src="/assets/2023-12-11-diffusion-model-demo2_files/2023-12-11-diffusion-model-demo2_23_34.png" alt="png" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 90 | step 000 Loss: 0.12281842529773712 
</code></pre></div></div>

<p><img src="/assets/2023-12-11-diffusion-model-demo2_files/2023-12-11-diffusion-model-demo2_23_36.png" alt="png" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 95 | step 000 Loss: 0.1393832564353943 
</code></pre></div></div>

<p><img src="/assets/2023-12-11-diffusion-model-demo2_files/2023-12-11-diffusion-model-demo2_23_38.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
</code></pre></div></div>]]></content><author><name>Zhu Tianda</name></author><category term="coding" /><category term="AI" /><category term="Diffusion" /><summary type="html"><![CDATA[A Diffusion Model from Scratch in Pytorch]]></summary></entry><entry><title type="html">Inspect BERT Vocabulary</title><link href="http://0.0.0.0:8855/coding/2023/12/02/Inspect-BERT-Vocabulary.html" rel="alternate" type="text/html" title="Inspect BERT Vocabulary" /><published>2023-12-02T00:00:00+08:00</published><updated>2023-12-02T00:00:00+08:00</updated><id>http://0.0.0.0:8855/coding/2023/12/02/Inspect-BERT-Vocabulary</id><content type="html" xml:base="http://0.0.0.0:8855/coding/2023/12/02/Inspect-BERT-Vocabulary.html"><![CDATA[<!DOCTYPE html>

<html lang="en">
<head><meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>Inspect_BERT_Vocabulary</title><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<style type="text/css">
    pre { line-height: 125%; }
td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
.highlight .hll { background-color: var(--jp-cell-editor-active-background) }
.highlight { background: var(--jp-cell-editor-background); color: var(--jp-mirror-editor-variable-color) }
.highlight .c { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment */
.highlight .err { color: var(--jp-mirror-editor-error-color) } /* Error */
.highlight .k { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword */
.highlight .o { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator */
.highlight .p { color: var(--jp-mirror-editor-punctuation-color) } /* Punctuation */
.highlight .ch { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Multiline */
.highlight .cp { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Preproc */
.highlight .cpf { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Single */
.highlight .cs { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Special */
.highlight .kc { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Pseudo */
.highlight .kr { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Type */
.highlight .m { color: var(--jp-mirror-editor-number-color) } /* Literal.Number */
.highlight .s { color: var(--jp-mirror-editor-string-color) } /* Literal.String */
.highlight .ow { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator.Word */
.highlight .pm { color: var(--jp-mirror-editor-punctuation-color) } /* Punctuation.Marker */
.highlight .w { color: var(--jp-mirror-editor-variable-color) } /* Text.Whitespace */
.highlight .mb { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Bin */
.highlight .mf { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Float */
.highlight .mh { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Hex */
.highlight .mi { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer */
.highlight .mo { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Oct */
.highlight .sa { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Affix */
.highlight .sb { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Backtick */
.highlight .sc { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Char */
.highlight .dl { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Delimiter */
.highlight .sd { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Doc */
.highlight .s2 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Double */
.highlight .se { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Escape */
.highlight .sh { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Heredoc */
.highlight .si { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Interpol */
.highlight .sx { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Other */
.highlight .sr { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Regex */
.highlight .s1 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Single */
.highlight .ss { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Symbol */
.highlight .il { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer.Long */
  </style>
<style type="text/css">
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*
 * Mozilla scrollbar styling
 */

/* use standard opaque scrollbars for most nodes */
[data-jp-theme-scrollbars='true'] {
  scrollbar-color: rgb(var(--jp-scrollbar-thumb-color))
    var(--jp-scrollbar-background-color);
}

/* for code nodes, use a transparent style of scrollbar. These selectors
 * will match lower in the tree, and so will override the above */
[data-jp-theme-scrollbars='true'] .CodeMirror-hscrollbar,
[data-jp-theme-scrollbars='true'] .CodeMirror-vscrollbar {
  scrollbar-color: rgba(var(--jp-scrollbar-thumb-color), 0.5) transparent;
}

/* tiny scrollbar */

.jp-scrollbar-tiny {
  scrollbar-color: rgba(var(--jp-scrollbar-thumb-color), 0.5) transparent;
  scrollbar-width: thin;
}

/* tiny scrollbar */

.jp-scrollbar-tiny::-webkit-scrollbar,
.jp-scrollbar-tiny::-webkit-scrollbar-corner {
  background-color: transparent;
  height: 4px;
  width: 4px;
}

.jp-scrollbar-tiny::-webkit-scrollbar-thumb {
  background: rgba(var(--jp-scrollbar-thumb-color), 0.5);
}

.jp-scrollbar-tiny::-webkit-scrollbar-track:horizontal {
  border-left: 0 solid transparent;
  border-right: 0 solid transparent;
}

.jp-scrollbar-tiny::-webkit-scrollbar-track:vertical {
  border-top: 0 solid transparent;
  border-bottom: 0 solid transparent;
}

/*
 * Lumino
 */

.lm-ScrollBar[data-orientation='horizontal'] {
  min-height: 16px;
  max-height: 16px;
  min-width: 45px;
  border-top: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='vertical'] {
  min-width: 16px;
  max-width: 16px;
  min-height: 45px;
  border-left: 1px solid #a0a0a0;
}

.lm-ScrollBar-button {
  background-color: #f0f0f0;
  background-position: center center;
  min-height: 15px;
  max-height: 15px;
  min-width: 15px;
  max-width: 15px;
}

.lm-ScrollBar-button:hover {
  background-color: #dadada;
}

.lm-ScrollBar-button.lm-mod-active {
  background-color: #cdcdcd;
}

.lm-ScrollBar-track {
  background: #f0f0f0;
}

.lm-ScrollBar-thumb {
  background: #cdcdcd;
}

.lm-ScrollBar-thumb:hover {
  background: #bababa;
}

.lm-ScrollBar-thumb.lm-mod-active {
  background: #a0a0a0;
}

.lm-ScrollBar[data-orientation='horizontal'] .lm-ScrollBar-thumb {
  height: 100%;
  min-width: 15px;
  border-left: 1px solid #a0a0a0;
  border-right: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='vertical'] .lm-ScrollBar-thumb {
  width: 100%;
  min-height: 15px;
  border-top: 1px solid #a0a0a0;
  border-bottom: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='horizontal']
  .lm-ScrollBar-button[data-action='decrement'] {
  background-image: var(--jp-icon-caret-left);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='horizontal']
  .lm-ScrollBar-button[data-action='increment'] {
  background-image: var(--jp-icon-caret-right);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='vertical']
  .lm-ScrollBar-button[data-action='decrement'] {
  background-image: var(--jp-icon-caret-up);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='vertical']
  .lm-ScrollBar-button[data-action='increment'] {
  background-image: var(--jp-icon-caret-down);
  background-size: 17px;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-Widget {
  box-sizing: border-box;
  position: relative;
  overflow: hidden;
}

.lm-Widget.lm-mod-hidden {
  display: none !important;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.lm-AccordionPanel[data-orientation='horizontal'] > .lm-AccordionPanel-title {
  /* Title is rotated for horizontal accordion panel using CSS */
  display: block;
  transform-origin: top left;
  transform: rotate(-90deg) translate(-100%);
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-CommandPalette {
  display: flex;
  flex-direction: column;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-CommandPalette-search {
  flex: 0 0 auto;
}

.lm-CommandPalette-content {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  min-height: 0;
  overflow: auto;
  list-style-type: none;
}

.lm-CommandPalette-header {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.lm-CommandPalette-item {
  display: flex;
  flex-direction: row;
}

.lm-CommandPalette-itemIcon {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemContent {
  flex: 1 1 auto;
  overflow: hidden;
}

.lm-CommandPalette-itemShortcut {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemLabel {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.lm-close-icon {
  border: 1px solid transparent;
  background-color: transparent;
  position: absolute;
  z-index: 1;
  right: 3%;
  top: 0;
  bottom: 0;
  margin: auto;
  padding: 7px 0;
  display: none;
  vertical-align: middle;
  outline: 0;
  cursor: pointer;
}
.lm-close-icon:after {
  content: 'X';
  display: block;
  width: 15px;
  height: 15px;
  text-align: center;
  color: #000;
  font-weight: normal;
  font-size: 12px;
  cursor: pointer;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-DockPanel {
  z-index: 0;
}

.lm-DockPanel-widget {
  z-index: 0;
}

.lm-DockPanel-tabBar {
  z-index: 1;
}

.lm-DockPanel-handle {
  z-index: 2;
}

.lm-DockPanel-handle.lm-mod-hidden {
  display: none !important;
}

.lm-DockPanel-handle:after {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  content: '';
}

.lm-DockPanel-handle[data-orientation='horizontal'] {
  cursor: ew-resize;
}

.lm-DockPanel-handle[data-orientation='vertical'] {
  cursor: ns-resize;
}

.lm-DockPanel-handle[data-orientation='horizontal']:after {
  left: 50%;
  min-width: 8px;
  transform: translateX(-50%);
}

.lm-DockPanel-handle[data-orientation='vertical']:after {
  top: 50%;
  min-height: 8px;
  transform: translateY(-50%);
}

.lm-DockPanel-overlay {
  z-index: 3;
  box-sizing: border-box;
  pointer-events: none;
}

.lm-DockPanel-overlay.lm-mod-hidden {
  display: none !important;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-Menu {
  z-index: 10000;
  position: absolute;
  white-space: nowrap;
  overflow-x: hidden;
  overflow-y: auto;
  outline: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-Menu-content {
  margin: 0;
  padding: 0;
  display: table;
  list-style-type: none;
}

.lm-Menu-item {
  display: table-row;
}

.lm-Menu-item.lm-mod-hidden,
.lm-Menu-item.lm-mod-collapsed {
  display: none !important;
}

.lm-Menu-itemIcon,
.lm-Menu-itemSubmenuIcon {
  display: table-cell;
  text-align: center;
}

.lm-Menu-itemLabel {
  display: table-cell;
  text-align: left;
}

.lm-Menu-itemShortcut {
  display: table-cell;
  text-align: right;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-MenuBar {
  outline: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-MenuBar-content {
  margin: 0;
  padding: 0;
  display: flex;
  flex-direction: row;
  list-style-type: none;
}

.lm-MenuBar-item {
  box-sizing: border-box;
}

.lm-MenuBar-itemIcon,
.lm-MenuBar-itemLabel {
  display: inline-block;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-ScrollBar {
  display: flex;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-ScrollBar[data-orientation='horizontal'] {
  flex-direction: row;
}

.lm-ScrollBar[data-orientation='vertical'] {
  flex-direction: column;
}

.lm-ScrollBar-button {
  box-sizing: border-box;
  flex: 0 0 auto;
}

.lm-ScrollBar-track {
  box-sizing: border-box;
  position: relative;
  overflow: hidden;
  flex: 1 1 auto;
}

.lm-ScrollBar-thumb {
  box-sizing: border-box;
  position: absolute;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-SplitPanel-child {
  z-index: 0;
}

.lm-SplitPanel-handle {
  z-index: 1;
}

.lm-SplitPanel-handle.lm-mod-hidden {
  display: none !important;
}

.lm-SplitPanel-handle:after {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  content: '';
}

.lm-SplitPanel[data-orientation='horizontal'] > .lm-SplitPanel-handle {
  cursor: ew-resize;
}

.lm-SplitPanel[data-orientation='vertical'] > .lm-SplitPanel-handle {
  cursor: ns-resize;
}

.lm-SplitPanel[data-orientation='horizontal'] > .lm-SplitPanel-handle:after {
  left: 50%;
  min-width: 8px;
  transform: translateX(-50%);
}

.lm-SplitPanel[data-orientation='vertical'] > .lm-SplitPanel-handle:after {
  top: 50%;
  min-height: 8px;
  transform: translateY(-50%);
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-TabBar {
  display: flex;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-TabBar[data-orientation='horizontal'] {
  flex-direction: row;
  align-items: flex-end;
}

.lm-TabBar[data-orientation='vertical'] {
  flex-direction: column;
  align-items: flex-end;
}

.lm-TabBar-content {
  margin: 0;
  padding: 0;
  display: flex;
  flex: 1 1 auto;
  list-style-type: none;
}

.lm-TabBar[data-orientation='horizontal'] > .lm-TabBar-content {
  flex-direction: row;
}

.lm-TabBar[data-orientation='vertical'] > .lm-TabBar-content {
  flex-direction: column;
}

.lm-TabBar-tab {
  display: flex;
  flex-direction: row;
  box-sizing: border-box;
  overflow: hidden;
  touch-action: none; /* Disable native Drag/Drop */
}

.lm-TabBar-tabIcon,
.lm-TabBar-tabCloseIcon {
  flex: 0 0 auto;
}

.lm-TabBar-tabLabel {
  flex: 1 1 auto;
  overflow: hidden;
  white-space: nowrap;
}

.lm-TabBar-tabInput {
  user-select: all;
  width: 100%;
  box-sizing: border-box;
}

.lm-TabBar-tab.lm-mod-hidden {
  display: none !important;
}

.lm-TabBar-addButton.lm-mod-hidden {
  display: none !important;
}

.lm-TabBar.lm-mod-dragging .lm-TabBar-tab {
  position: relative;
}

.lm-TabBar.lm-mod-dragging[data-orientation='horizontal'] .lm-TabBar-tab {
  left: 0;
  transition: left 150ms ease;
}

.lm-TabBar.lm-mod-dragging[data-orientation='vertical'] .lm-TabBar-tab {
  top: 0;
  transition: top 150ms ease;
}

.lm-TabBar.lm-mod-dragging .lm-TabBar-tab.lm-mod-dragging {
  transition: none;
}

.lm-TabBar-tabLabel .lm-TabBar-tabInput {
  user-select: all;
  width: 100%;
  box-sizing: border-box;
  background: inherit;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-TabPanel-tabBar {
  z-index: 1;
}

.lm-TabPanel-stackedPanel {
  z-index: 0;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Collapse {
  display: flex;
  flex-direction: column;
  align-items: stretch;
}

.jp-Collapse-header {
  padding: 1px 12px;
  background-color: var(--jp-layout-color1);
  border-bottom: solid var(--jp-border-width) var(--jp-border-color2);
  color: var(--jp-ui-font-color1);
  cursor: pointer;
  display: flex;
  align-items: center;
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  text-transform: uppercase;
  user-select: none;
}

.jp-Collapser-icon {
  height: 16px;
}

.jp-Collapse-header-collapsed .jp-Collapser-icon {
  transform: rotate(-90deg);
  margin: auto 0;
}

.jp-Collapser-title {
  line-height: 25px;
}

.jp-Collapse-contents {
  padding: 0 12px;
  background-color: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  overflow: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensureUiComponents() in @jupyterlab/buildutils */

/**
 * (DEPRECATED) Support for consuming icons as CSS background images
 */

/* Icons urls */

:root {
  --jp-icon-add-above: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGcgY2xpcC1wYXRoPSJ1cmwoI2NsaXAwXzEzN18xOTQ5MikiPgo8cGF0aCBjbGFzcz0ianAtaWNvbjMiIGQ9Ik00Ljc1IDQuOTMwNjZINi42MjVWNi44MDU2NkM2LjYyNSA3LjAxMTkxIDYuNzkzNzUgNy4xODA2NiA3IDcuMTgwNjZDNy4yMDYyNSA3LjE4MDY2IDcuMzc1IDcuMDExOTEgNy4zNzUgNi44MDU2NlY0LjkzMDY2SDkuMjVDOS40NTYyNSA0LjkzMDY2IDkuNjI1IDQuNzYxOTEgOS42MjUgNC41NTU2NkM5LjYyNSA0LjM0OTQxIDkuNDU2MjUgNC4xODA2NiA5LjI1IDQuMTgwNjZINy4zNzVWMi4zMDU2NkM3LjM3NSAyLjA5OTQxIDcuMjA2MjUgMS45MzA2NiA3IDEuOTMwNjZDNi43OTM3NSAxLjkzMDY2IDYuNjI1IDIuMDk5NDEgNi42MjUgMi4zMDU2NlY0LjE4MDY2SDQuNzVDNC41NDM3NSA0LjE4MDY2IDQuMzc1IDQuMzQ5NDEgNC4zNzUgNC41NTU2NkM0LjM3NSA0Ljc2MTkxIDQuNTQzNzUgNC45MzA2NiA0Ljc1IDQuOTMwNjZaIiBmaWxsPSIjNjE2MTYxIiBzdHJva2U9IiM2MTYxNjEiIHN0cm9rZS13aWR0aD0iMC43Ii8+CjwvZz4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiIGNsaXAtcnVsZT0iZXZlbm9kZCIgZD0iTTExLjUgOS41VjExLjVMMi41IDExLjVWOS41TDExLjUgOS41Wk0xMiA4QzEyLjU1MjMgOCAxMyA4LjQ0NzcyIDEzIDlWMTJDMTMgMTIuNTUyMyAxMi41NTIzIDEzIDEyIDEzTDIgMTNDMS40NDc3MiAxMyAxIDEyLjU1MjMgMSAxMlY5QzEgOC40NDc3MiAxLjQ0NzcxIDggMiA4TDEyIDhaIiBmaWxsPSIjNjE2MTYxIi8+CjxkZWZzPgo8Y2xpcFBhdGggaWQ9ImNsaXAwXzEzN18xOTQ5MiI+CjxyZWN0IGNsYXNzPSJqcC1pY29uMyIgd2lkdGg9IjYiIGhlaWdodD0iNiIgZmlsbD0id2hpdGUiIHRyYW5zZm9ybT0ibWF0cml4KC0xIDAgMCAxIDEwIDEuNTU1NjYpIi8+CjwvY2xpcFBhdGg+CjwvZGVmcz4KPC9zdmc+Cg==);
  --jp-icon-add-below: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGcgY2xpcC1wYXRoPSJ1cmwoI2NsaXAwXzEzN18xOTQ5OCkiPgo8cGF0aCBjbGFzcz0ianAtaWNvbjMiIGQ9Ik05LjI1IDEwLjA2OTNMNy4zNzUgMTAuMDY5M0w3LjM3NSA4LjE5NDM0QzcuMzc1IDcuOTg4MDkgNy4yMDYyNSA3LjgxOTM0IDcgNy44MTkzNEM2Ljc5Mzc1IDcuODE5MzQgNi42MjUgNy45ODgwOSA2LjYyNSA4LjE5NDM0TDYuNjI1IDEwLjA2OTNMNC43NSAxMC4wNjkzQzQuNTQzNzUgMTAuMDY5MyA0LjM3NSAxMC4yMzgxIDQuMzc1IDEwLjQ0NDNDNC4zNzUgMTAuNjUwNiA0LjU0Mzc1IDEwLjgxOTMgNC43NSAxMC44MTkzTDYuNjI1IDEwLjgxOTNMNi42MjUgMTIuNjk0M0M2LjYyNSAxMi45MDA2IDYuNzkzNzUgMTMuMDY5MyA3IDEzLjA2OTNDNy4yMDYyNSAxMy4wNjkzIDcuMzc1IDEyLjkwMDYgNy4zNzUgMTIuNjk0M0w3LjM3NSAxMC44MTkzTDkuMjUgMTAuODE5M0M5LjQ1NjI1IDEwLjgxOTMgOS42MjUgMTAuNjUwNiA5LjYyNSAxMC40NDQzQzkuNjI1IDEwLjIzODEgOS40NTYyNSAxMC4wNjkzIDkuMjUgMTAuMDY5M1oiIGZpbGw9IiM2MTYxNjEiIHN0cm9rZT0iIzYxNjE2MSIgc3Ryb2tlLXdpZHRoPSIwLjciLz4KPC9nPgo8cGF0aCBjbGFzcz0ianAtaWNvbjMiIGZpbGwtcnVsZT0iZXZlbm9kZCIgY2xpcC1ydWxlPSJldmVub2RkIiBkPSJNMi41IDUuNUwyLjUgMy41TDExLjUgMy41TDExLjUgNS41TDIuNSA1LjVaTTIgN0MxLjQ0NzcyIDcgMSA2LjU1MjI4IDEgNkwxIDNDMSAyLjQ0NzcyIDEuNDQ3NzIgMiAyIDJMMTIgMkMxMi41NTIzIDIgMTMgMi40NDc3MiAxMyAzTDEzIDZDMTMgNi41NTIyOSAxMi41NTIzIDcgMTIgN0wyIDdaIiBmaWxsPSIjNjE2MTYxIi8+CjxkZWZzPgo8Y2xpcFBhdGggaWQ9ImNsaXAwXzEzN18xOTQ5OCI+CjxyZWN0IGNsYXNzPSJqcC1pY29uMyIgd2lkdGg9IjYiIGhlaWdodD0iNiIgZmlsbD0id2hpdGUiIHRyYW5zZm9ybT0ibWF0cml4KDEgMS43NDg0NmUtMDcgMS43NDg0NmUtMDcgLTEgNCAxMy40NDQzKSIvPgo8L2NsaXBQYXRoPgo8L2RlZnM+Cjwvc3ZnPgo=);
  --jp-icon-add: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE5IDEzaC02djZoLTJ2LTZINXYtMmg2VjVoMnY2aDZ2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-bell: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE2IDE2IiB2ZXJzaW9uPSIxLjEiPgogICA8cGF0aCBjbGFzcz0ianAtaWNvbjIganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMzMzMzMzIgogICAgICBkPSJtOCAwLjI5Yy0xLjQgMC0yLjcgMC43My0zLjYgMS44LTEuMiAxLjUtMS40IDMuNC0xLjUgNS4yLTAuMTggMi4yLTAuNDQgNC0yLjMgNS4zbDAuMjggMS4zaDVjMC4wMjYgMC42NiAwLjMyIDEuMSAwLjcxIDEuNSAwLjg0IDAuNjEgMiAwLjYxIDIuOCAwIDAuNTItMC40IDAuNi0xIDAuNzEtMS41aDVsMC4yOC0xLjNjLTEuOS0wLjk3LTIuMi0zLjMtMi4zLTUuMy0wLjEzLTEuOC0wLjI2LTMuNy0xLjUtNS4yLTAuODUtMS0yLjItMS44LTMuNi0xLjh6bTAgMS40YzAuODggMCAxLjkgMC41NSAyLjUgMS4zIDAuODggMS4xIDEuMSAyLjcgMS4yIDQuNCAwLjEzIDEuNyAwLjIzIDMuNiAxLjMgNS4yaC0xMGMxLjEtMS42IDEuMi0zLjQgMS4zLTUuMiAwLjEzLTEuNyAwLjMtMy4zIDEuMi00LjQgMC41OS0wLjcyIDEuNi0xLjMgMi41LTEuM3ptLTAuNzQgMTJoMS41Yy0wLjAwMTUgMC4yOCAwLjAxNSAwLjc5LTAuNzQgMC43OS0wLjczIDAuMDAxNi0wLjcyLTAuNTMtMC43NC0wLjc5eiIgLz4KPC9zdmc+Cg==);
  --jp-icon-bug-dot: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjQiIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiPgogICAgICAgIDxwYXRoIGZpbGwtcnVsZT0iZXZlbm9kZCIgY2xpcC1ydWxlPSJldmVub2RkIiBkPSJNMTcuMTkgOEgyMFYxMEgxNy45MUMxNy45NiAxMC4zMyAxOCAxMC42NiAxOCAxMVYxMkgyMFYxNEgxOC41SDE4VjE0LjAyNzVDMTUuNzUgMTQuMjc2MiAxNCAxNi4xODM3IDE0IDE4LjVDMTQgMTkuMjA4IDE0LjE2MzUgMTkuODc3OSAxNC40NTQ5IDIwLjQ3MzlDMTMuNzA2MyAyMC44MTE3IDEyLjg3NTcgMjEgMTIgMjFDOS43OCAyMSA3Ljg1IDE5Ljc5IDYuODEgMThINFYxNkg2LjA5QzYuMDQgMTUuNjcgNiAxNS4zNCA2IDE1VjE0SDRWMTJINlYxMUM2IDEwLjY2IDYuMDQgMTAuMzMgNi4wOSAxMEg0VjhINi44MUM3LjI2IDcuMjIgNy44OCA2LjU1IDguNjIgNi4wNEw3IDQuNDFMOC40MSAzTDEwLjU5IDUuMTdDMTEuMDQgNS4wNiAxMS41MSA1IDEyIDVDMTIuNDkgNSAxMi45NiA1LjA2IDEzLjQyIDUuMTdMMTUuNTkgM0wxNyA0LjQxTDE1LjM3IDYuMDRDMTYuMTIgNi41NSAxNi43NCA3LjIyIDE3LjE5IDhaTTEwIDE2SDE0VjE0SDEwVjE2Wk0xMCAxMkgxNFYxMEgxMFYxMloiIGZpbGw9IiM2MTYxNjEiLz4KICAgICAgICA8cGF0aCBkPSJNMjIgMTguNUMyMiAyMC40MzMgMjAuNDMzIDIyIDE4LjUgMjJDMTYuNTY3IDIyIDE1IDIwLjQzMyAxNSAxOC41QzE1IDE2LjU2NyAxNi41NjcgMTUgMTguNSAxNUMyMC40MzMgMTUgMjIgMTYuNTY3IDIyIDE4LjVaIiBmaWxsPSIjNjE2MTYxIi8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-bug: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0yMCA4aC0yLjgxYy0uNDUtLjc4LTEuMDctMS40NS0xLjgyLTEuOTZMMTcgNC40MSAxNS41OSAzbC0yLjE3IDIuMTdDMTIuOTYgNS4wNiAxMi40OSA1IDEyIDVjLS40OSAwLS45Ni4wNi0xLjQxLjE3TDguNDEgMyA3IDQuNDFsMS42MiAxLjYzQzcuODggNi41NSA3LjI2IDcuMjIgNi44MSA4SDR2MmgyLjA5Yy0uMDUuMzMtLjA5LjY2LS4wOSAxdjFINHYyaDJ2MWMwIC4zNC4wNC42Ny4wOSAxSDR2MmgyLjgxYzEuMDQgMS43OSAyLjk3IDMgNS4xOSAzczQuMTUtMS4yMSA1LjE5LTNIMjB2LTJoLTIuMDljLjA1LS4zMy4wOS0uNjYuMDktMXYtMWgydi0yaC0ydi0xYzAtLjM0LS4wNC0uNjctLjA5LTFIMjBWOHptLTYgOGgtNHYtMmg0djJ6bTAtNGgtNHYtMmg0djJ6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-build: url(data:image/svg+xml;base64,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);
  --jp-icon-caret-down-empty-thin: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwb2x5Z29uIGNsYXNzPSJzdDEiIHBvaW50cz0iOS45LDEzLjYgMy42LDcuNCA0LjQsNi42IDkuOSwxMi4yIDE1LjQsNi43IDE2LjEsNy40ICIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-caret-down-empty: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik01LjIsNS45TDksOS43bDMuOC0zLjhsMS4yLDEuMmwtNC45LDVsLTQuOS01TDUuMiw1Ljl6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-caret-down: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik01LjIsNy41TDksMTEuMmwzLjgtMy44SDUuMnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-caret-left: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwYXRoIGQ9Ik0xMC44LDEyLjhMNy4xLDlsMy44LTMuOGwwLDcuNkgxMC44eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-caret-right: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik03LjIsNS4yTDEwLjksOWwtMy44LDMuOFY1LjJINy4yeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-caret-up-empty-thin: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwb2x5Z29uIGNsYXNzPSJzdDEiIHBvaW50cz0iMTUuNCwxMy4zIDkuOSw3LjcgNC40LDEzLjIgMy42LDEyLjUgOS45LDYuMyAxNi4xLDEyLjYgIi8+Cgk8L2c+Cjwvc3ZnPgo=);
  --jp-icon-caret-up: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwYXRoIGQ9Ik01LjIsMTAuNUw5LDYuOGwzLjgsMy44SDUuMnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-case-sensitive: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KICA8ZyBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiM0MTQxNDEiPgogICAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiAgPC9nPgogIDxnIGNsYXNzPSJqcC1pY29uLWFjY2VudDIiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTcuNiw4aDAuOWwzLjUsOGgtMS4xTDEwLDE0SDZsLTAuOSwySDRMNy42LDh6IE04LDkuMUw2LjQsMTNoMy4yTDgsOS4xeiIvPgogICAgPHBhdGggZD0iTTE2LjYsOS44Yy0wLjIsMC4xLTAuNCwwLjEtMC43LDAuMWMtMC4yLDAtMC40LTAuMS0wLjYtMC4yYy0wLjEtMC4xLTAuMi0wLjQtMC4yLTAuNyBjLTAuMywwLjMtMC42LDAuNS0wLjksMC43Yy0wLjMsMC4xLTAuNywwLjItMS4xLDAuMmMtMC4zLDAtMC41LDAtMC43LTAuMWMtMC4yLTAuMS0wLjQtMC4yLTAuNi0wLjNjLTAuMi0wLjEtMC4zLTAuMy0wLjQtMC41IGMtMC4xLTAuMi0wLjEtMC40LTAuMS0wLjdjMC0wLjMsMC4xLTAuNiwwLjItMC44YzAuMS0wLjIsMC4zLTAuNCwwLjQtMC41QzEyLDcsMTIuMiw2LjksMTIuNSw2LjhjMC4yLTAuMSwwLjUtMC4xLDAuNy0wLjIgYzAuMy0wLjEsMC41LTAuMSwwLjctMC4xYzAuMiwwLDAuNC0wLjEsMC42LTAuMWMwLjIsMCwwLjMtMC4xLDAuNC0wLjJjMC4xLTAuMSwwLjItMC4yLDAuMi0wLjRjMC0xLTEuMS0xLTEuMy0xIGMtMC40LDAtMS40LDAtMS40LDEuMmgtMC45YzAtMC40LDAuMS0wLjcsMC4yLTFjMC4xLTAuMiwwLjMtMC40LDAuNS0wLjZjMC4yLTAuMiwwLjUtMC4zLDAuOC0wLjNDMTMuMyw0LDEzLjYsNCwxMy45LDQgYzAuMywwLDAuNSwwLDAuOCwwLjFjMC4zLDAsMC41LDAuMSwwLjcsMC4yYzAuMiwwLjEsMC40LDAuMywwLjUsMC41QzE2LDUsMTYsNS4yLDE2LDUuNnYyLjljMCwwLjIsMCwwLjQsMCwwLjUgYzAsMC4xLDAuMSwwLjIsMC4zLDAuMmMwLjEsMCwwLjIsMCwwLjMsMFY5Ljh6IE0xNS4yLDYuOWMtMS4yLDAuNi0zLjEsMC4yLTMuMSwxLjRjMCwxLjQsMy4xLDEsMy4xLTAuNVY2Ljl6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-check: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik05IDE2LjE3TDQuODMgMTJsLTEuNDIgMS40MUw5IDE5IDIxIDdsLTEuNDEtMS40MXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-circle-empty: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyIDJDNi40NyAyIDIgNi40NyAyIDEyczQuNDcgMTAgMTAgMTAgMTAtNC40NyAxMC0xMFMxNy41MyAyIDEyIDJ6bTAgMThjLTQuNDEgMC04LTMuNTktOC04czMuNTktOCA4LTggOCAzLjU5IDggOC0zLjU5IDgtOCA4eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-circle: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPGNpcmNsZSBjeD0iOSIgY3k9IjkiIHI9IjgiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-clear: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8bWFzayBpZD0iZG9udXRIb2xlIj4KICAgIDxyZWN0IHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgZmlsbD0id2hpdGUiIC8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSI4IiBmaWxsPSJibGFjayIvPgogIDwvbWFzaz4KCiAgPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxyZWN0IGhlaWdodD0iMTgiIHdpZHRoPSIyIiB4PSIxMSIgeT0iMyIgdHJhbnNmb3JtPSJyb3RhdGUoMzE1LCAxMiwgMTIpIi8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIxMCIgbWFzaz0idXJsKCNkb251dEhvbGUpIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-close: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1ub25lIGpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIGpwLWljb24zLWhvdmVyIiBmaWxsPSJub25lIj4KICAgIDxjaXJjbGUgY3g9IjEyIiBjeT0iMTIiIHI9IjExIi8+CiAgPC9nPgoKICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIGpwLWljb24tYWNjZW50Mi1ob3ZlciIgZmlsbD0iIzYxNjE2MSI+CiAgICA8cGF0aCBkPSJNMTkgNi40MUwxNy41OSA1IDEyIDEwLjU5IDYuNDEgNSA1IDYuNDEgMTAuNTkgMTIgNSAxNy41OSA2LjQxIDE5IDEyIDEzLjQxIDE3LjU5IDE5IDE5IDE3LjU5IDEzLjQxIDEyeiIvPgogIDwvZz4KCiAgPGcgY2xhc3M9ImpwLWljb24tbm9uZSBqcC1pY29uLWJ1c3kiIGZpbGw9Im5vbmUiPgogICAgPGNpcmNsZSBjeD0iMTIiIGN5PSIxMiIgcj0iNyIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-code-check: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBzaGFwZS1yZW5kZXJpbmc9Imdlb21ldHJpY1ByZWNpc2lvbiI+CiAgICA8cGF0aCBkPSJNNi41OSwzLjQxTDIsOEw2LjU5LDEyLjZMOCwxMS4xOEw0LjgyLDhMOCw0LjgyTDYuNTksMy40MU0xMi40MSwzLjQxTDExLDQuODJMMTQuMTgsOEwxMSwxMS4xOEwxMi40MSwxMi42TDE3LDhMMTIuNDEsMy40MU0yMS41OSwxMS41OUwxMy41LDE5LjY4TDkuODMsMTZMOC40MiwxNy40MUwxMy41LDIyLjVMMjMsMTNMMjEuNTksMTEuNTlaIiAvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-code: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjIiIGhlaWdodD0iMjIiIHZpZXdCb3g9IjAgMCAyOCAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTExLjQgMTguNkw2LjggMTRMMTEuNCA5LjRMMTAgOEw0IDE0TDEwIDIwTDExLjQgMTguNlpNMTYuNiAxOC42TDIxLjIgMTRMMTYuNiA5LjRMMTggOEwyNCAxNEwxOCAyMEwxNi42IDE4LjZWMTguNloiLz4KCTwvZz4KPC9zdmc+Cg==);
  --jp-icon-collapse-all: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTggMmMxIDAgMTEgMCAxMiAwczIgMSAyIDJjMCAxIDAgMTEgMCAxMnMwIDItMiAyQzIwIDE0IDIwIDQgMjAgNFMxMCA0IDYgNGMwLTIgMS0yIDItMnoiIC8+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTE4IDhjMC0xLTEtMi0yLTJTNSA2IDQgNnMtMiAxLTIgMmMwIDEgMCAxMSAwIDEyczEgMiAyIDJjMSAwIDExIDAgMTIgMHMyLTEgMi0yYzAtMSAwLTExIDAtMTJ6bS0yIDB2MTJINFY4eiIgLz4KICAgICAgICA8cGF0aCBkPSJNNiAxM3YyaDh2LTJ6IiAvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-console: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwMCAyMDAiPgogIDxnIGNsYXNzPSJqcC1jb25zb2xlLWljb24tYmFja2dyb3VuZC1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiMwMjg4RDEiPgogICAgPHBhdGggZD0iTTIwIDE5LjhoMTYwdjE1OS45SDIweiIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtY29uc29sZS1pY29uLWNvbG9yIGpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIiBmaWxsPSIjZmZmIj4KICAgIDxwYXRoIGQ9Ik0xMDUgMTI3LjNoNDB2MTIuOGgtNDB6TTUxLjEgNzdMNzQgOTkuOWwtMjMuMyAyMy4zIDEwLjUgMTAuNSAyMy4zLTIzLjNMOTUgOTkuOSA4NC41IDg5LjQgNjEuNiA2Ni41eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-copy: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTExLjksMUgzLjJDMi40LDEsMS43LDEuNywxLjcsMi41djEwLjJoMS41VjIuNWg4LjdWMXogTTE0LjEsMy45aC04Yy0wLjgsMC0xLjUsMC43LTEuNSwxLjV2MTAuMmMwLDAuOCwwLjcsMS41LDEuNSwxLjVoOCBjMC44LDAsMS41LTAuNywxLjUtMS41VjUuNEMxNS41LDQuNiwxNC45LDMuOSwxNC4xLDMuOXogTTE0LjEsMTUuNWgtOFY1LjRoOFYxNS41eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-copyright: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGVuYWJsZS1iYWNrZ3JvdW5kPSJuZXcgMCAwIDI0IDI0IiBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCI+CiAgPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0xMS44OCw5LjE0YzEuMjgsMC4wNiwxLjYxLDEuMTUsMS42MywxLjY2aDEuNzljLTAuMDgtMS45OC0xLjQ5LTMuMTktMy40NS0zLjE5QzkuNjQsNy42MSw4LDksOCwxMi4xNCBjMCwxLjk0LDAuOTMsNC4yNCwzLjg0LDQuMjRjMi4yMiwwLDMuNDEtMS42NSwzLjQ0LTIuOTVoLTEuNzljLTAuMDMsMC41OS0wLjQ1LDEuMzgtMS42MywxLjQ0QzEwLjU1LDE0LjgzLDEwLDEzLjgxLDEwLDEyLjE0IEMxMCw5LjI1LDExLjI4LDkuMTYsMTEuODgsOS4xNHogTTEyLDJDNi40OCwyLDIsNi40OCwyLDEyczQuNDgsMTAsMTAsMTBzMTAtNC40OCwxMC0xMFMxNy41MiwyLDEyLDJ6IE0xMiwyMGMtNC40MSwwLTgtMy41OS04LTggczMuNTktOCw4LThzOCwzLjU5LDgsOFMxNi40MSwyMCwxMiwyMHoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-cut: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkuNjQgNy42NGMuMjMtLjUuMzYtMS4wNS4zNi0xLjY0IDAtMi4yMS0xLjc5LTQtNC00UzIgMy43OSAyIDZzMS43OSA0IDQgNGMuNTkgMCAxLjE0LS4xMyAxLjY0LS4zNkwxMCAxMmwtMi4zNiAyLjM2QzcuMTQgMTQuMTMgNi41OSAxNCA2IDE0Yy0yLjIxIDAtNCAxLjc5LTQgNHMxLjc5IDQgNCA0IDQtMS43OSA0LTRjMC0uNTktLjEzLTEuMTQtLjM2LTEuNjRMMTIgMTRsNyA3aDN2LTFMOS42NCA3LjY0ek02IDhjLTEuMSAwLTItLjg5LTItMnMuOS0yIDItMiAyIC44OSAyIDItLjkgMi0yIDJ6bTAgMTJjLTEuMSAwLTItLjg5LTItMnMuOS0yIDItMiAyIC44OSAyIDItLjkgMi0yIDJ6bTYtNy41Yy0uMjggMC0uNS0uMjItLjUtLjVzLjIyLS41LjUtLjUuNS4yMi41LjUtLjIyLjUtLjUuNXpNMTkgM2wtNiA2IDIgMiA3LTdWM3oiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-delete: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2cHgiIGhlaWdodD0iMTZweCI+CiAgICA8cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIiAvPgogICAgPHBhdGggY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjI2MjYyIiBkPSJNNiAxOWMwIDEuMS45IDIgMiAyaDhjMS4xIDAgMi0uOSAyLTJWN0g2djEyek0xOSA0aC0zLjVsLTEtMWgtNWwtMSAxSDV2MmgxNFY0eiIgLz4KPC9zdmc+Cg==);
  --jp-icon-download: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE5IDloLTRWM0g5djZINWw3IDcgNy03ek01IDE4djJoMTR2LTJINXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-duplicate: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiIGNsaXAtcnVsZT0iZXZlbm9kZCIgZD0iTTIuNzk5OTggMC44NzVIOC44OTU4MkM5LjIwMDYxIDAuODc1IDkuNDQ5OTggMS4xMzkxNCA5LjQ0OTk4IDEuNDYxOThDOS40NDk5OCAxLjc4NDgyIDkuMjAwNjEgMi4wNDg5NiA4Ljg5NTgyIDIuMDQ4OTZIMy4zNTQxNUMzLjA0OTM2IDIuMDQ4OTYgMi43OTk5OCAyLjMxMzEgMi43OTk5OCAyLjYzNTk0VjkuNjc5NjlDMi43OTk5OCAxMC4wMDI1IDIuNTUwNjEgMTAuMjY2NyAyLjI0NTgyIDEwLjI2NjdDMS45NDEwMyAxMC4yNjY3IDEuNjkxNjUgMTAuMDAyNSAxLjY5MTY1IDkuNjc5NjlWMi4wNDg5NkMxLjY5MTY1IDEuNDAzMjggMi4xOTA0IDAuODc1IDIuNzk5OTggMC44NzVaTTUuMzY2NjUgMTEuOVY0LjU1SDExLjA4MzNWMTEuOUg1LjM2NjY1Wk00LjE0MTY1IDQuMTQxNjdDNC4xNDE2NSAzLjY5MDYzIDQuNTA3MjggMy4zMjUgNC45NTgzMiAzLjMyNUgxMS40OTE3QzExLjk0MjcgMy4zMjUgMTIuMzA4MyAzLjY5MDYzIDEyLjMwODMgNC4xNDE2N1YxMi4zMDgzQzEyLjMwODMgMTIuNzU5NCAxMS45NDI3IDEzLjEyNSAxMS40OTE3IDEzLjEyNUg0Ljk1ODMyQzQuNTA3MjggMTMuMTI1IDQuMTQxNjUgMTIuNzU5NCA0LjE0MTY1IDEyLjMwODNWNC4xNDE2N1oiIGZpbGw9IiM2MTYxNjEiLz4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBkPSJNOS40MzU3NCA4LjI2NTA3SDguMzY0MzFWOS4zMzY1QzguMzY0MzEgOS40NTQzNSA4LjI2Nzg4IDkuNTUwNzggOC4xNTAwMiA5LjU1MDc4QzguMDMyMTcgOS41NTA3OCA3LjkzNTc0IDkuNDU0MzUgNy45MzU3NCA5LjMzNjVWOC4yNjUwN0g2Ljg2NDMxQzYuNzQ2NDUgOC4yNjUwNyA2LjY1MDAyIDguMTY4NjQgNi42NTAwMiA4LjA1MDc4QzYuNjUwMDIgNy45MzI5MiA2Ljc0NjQ1IDcuODM2NSA2Ljg2NDMxIDcuODM2NUg3LjkzNTc0VjYuNzY1MDdDNy45MzU3NCA2LjY0NzIxIDguMDMyMTcgNi41NTA3OCA4LjE1MDAyIDYuNTUwNzhDOC4yNjc4OCA2LjU1MDc4IDguMzY0MzEgNi42NDcyMSA4LjM2NDMxIDYuNzY1MDdWNy44MzY1SDkuNDM1NzRDOS41NTM2IDcuODM2NSA5LjY1MDAyIDcuOTMyOTIgOS42NTAwMiA4LjA1MDc4QzkuNjUwMDIgOC4xNjg2NCA5LjU1MzYgOC4yNjUwNyA5LjQzNTc0IDguMjY1MDdaIiBmaWxsPSIjNjE2MTYxIiBzdHJva2U9IiM2MTYxNjEiIHN0cm9rZS13aWR0aD0iMC41Ii8+Cjwvc3ZnPgo=);
  --jp-icon-edit: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTMgMTcuMjVWMjFoMy43NUwxNy44MSA5Ljk0bC0zLjc1LTMuNzVMMyAxNy4yNXpNMjAuNzEgNy4wNGMuMzktLjM5LjM5LTEuMDIgMC0xLjQxbC0yLjM0LTIuMzRjLS4zOS0uMzktMS4wMi0uMzktMS40MSAwbC0xLjgzIDEuODMgMy43NSAzLjc1IDEuODMtMS44M3oiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-ellipses: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPGNpcmNsZSBjeD0iNSIgY3k9IjEyIiByPSIyIi8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIyIi8+CiAgICA8Y2lyY2xlIGN4PSIxOSIgY3k9IjEyIiByPSIyIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-error: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj48Y2lyY2xlIGN4PSIxMiIgY3k9IjE5IiByPSIyIi8+PHBhdGggZD0iTTEwIDNoNHYxMmgtNHoiLz48L2c+CjxwYXRoIGZpbGw9Im5vbmUiIGQ9Ik0wIDBoMjR2MjRIMHoiLz4KPC9zdmc+Cg==);
  --jp-icon-expand-all: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTggMmMxIDAgMTEgMCAxMiAwczIgMSAyIDJjMCAxIDAgMTEgMCAxMnMwIDItMiAyQzIwIDE0IDIwIDQgMjAgNFMxMCA0IDYgNGMwLTIgMS0yIDItMnoiIC8+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTE4IDhjMC0xLTEtMi0yLTJTNSA2IDQgNnMtMiAxLTIgMmMwIDEgMCAxMSAwIDEyczEgMiAyIDJjMSAwIDExIDAgMTIgMHMyLTEgMi0yYzAtMSAwLTExIDAtMTJ6bS0yIDB2MTJINFY4eiIgLz4KICAgICAgICA8cGF0aCBkPSJNMTEgMTBIOXYzSDZ2MmgzdjNoMnYtM2gzdi0yaC0zeiIgLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-extension: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwLjUgMTFIMTlWN2MwLTEuMS0uOS0yLTItMmgtNFYzLjVDMTMgMi4xMiAxMS44OCAxIDEwLjUgMVM4IDIuMTIgOCAzLjVWNUg0Yy0xLjEgMC0xLjk5LjktMS45OSAydjMuOEgzLjVjMS40OSAwIDIuNyAxLjIxIDIuNyAyLjdzLTEuMjEgMi43LTIuNyAyLjdIMlYyMGMwIDEuMS45IDIgMiAyaDMuOHYtMS41YzAtMS40OSAxLjIxLTIuNyAyLjctMi43IDEuNDkgMCAyLjcgMS4yMSAyLjcgMi43VjIySDE3YzEuMSAwIDItLjkgMi0ydi00aDEuNWMxLjM4IDAgMi41LTEuMTIgMi41LTIuNVMyMS44OCAxMSAyMC41IDExeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-fast-forward: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTQgMThsOC41LTZMNCA2djEyem05LTEydjEybDguNS02TDEzIDZ6Ii8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-file-upload: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkgMTZoNnYtNmg0bC03LTctNyA3aDR6bS00IDJoMTR2Mkg1eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-file: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkuMyA4LjJsLTUuNS01LjVjLS4zLS4zLS43LS41LTEuMi0uNUgzLjljLS44LjEtMS42LjktMS42IDEuOHYxNC4xYzAgLjkuNyAxLjYgMS42IDEuNmgxNC4yYy45IDAgMS42LS43IDEuNi0xLjZWOS40Yy4xLS41LS4xLS45LS40LTEuMnptLTUuOC0zLjNsMy40IDMuNmgtMy40VjQuOXptMy45IDEyLjdINC43Yy0uMSAwLS4yIDAtLjItLjJWNC43YzAtLjIuMS0uMy4yLS4zaDcuMnY0LjRzMCAuOC4zIDEuMWMuMy4zIDEuMS4zIDEuMS4zaDQuM3Y3LjJzLS4xLjItLjIuMnoiLz4KPC9zdmc+Cg==);
  --jp-icon-filter-dot: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTE0LDEyVjE5Ljg4QzE0LjA0LDIwLjE4IDEzLjk0LDIwLjUgMTMuNzEsMjAuNzFDMTMuMzIsMjEuMSAxMi42OSwyMS4xIDEyLjMsMjAuNzFMMTAuMjksMTguN0MxMC4wNiwxOC40NyA5Ljk2LDE4LjE2IDEwLDE3Ljg3VjEySDkuOTdMNC4yMSw0LjYyQzMuODcsNC4xOSAzLjk1LDMuNTYgNC4zOCwzLjIyQzQuNTcsMy4wOCA0Ljc4LDMgNSwzVjNIMTlWM0MxOS4yMiwzIDE5LjQzLDMuMDggMTkuNjIsMy4yMkMyMC4wNSwzLjU2IDIwLjEzLDQuMTkgMTkuNzksNC42MkwxNC4wMywxMkgxNFoiIC8+CiAgPC9nPgogIDxnIGNsYXNzPSJqcC1pY29uLWRvdCIgZmlsbD0iI0ZGRiI+CiAgICA8Y2lyY2xlIGN4PSIxOCIgY3k9IjE3IiByPSIzIj48L2NpcmNsZT4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-filter-list: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEwIDE4aDR2LTJoLTR2MnpNMyA2djJoMThWNkgzem0zIDdoMTJ2LTJINnYyeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-filter: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTE0LDEyVjE5Ljg4QzE0LjA0LDIwLjE4IDEzLjk0LDIwLjUgMTMuNzEsMjAuNzFDMTMuMzIsMjEuMSAxMi42OSwyMS4xIDEyLjMsMjAuNzFMMTAuMjksMTguN0MxMC4wNiwxOC40NyA5Ljk2LDE4LjE2IDEwLDE3Ljg3VjEySDkuOTdMNC4yMSw0LjYyQzMuODcsNC4xOSAzLjk1LDMuNTYgNC4zOCwzLjIyQzQuNTcsMy4wOCA0Ljc4LDMgNSwzVjNIMTlWM0MxOS4yMiwzIDE5LjQzLDMuMDggMTkuNjIsMy4yMkMyMC4wNSwzLjU2IDIwLjEzLDQuMTkgMTkuNzksNC42MkwxNC4wMywxMkgxNFoiIC8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-folder-favorite: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjRweCIgdmlld0JveD0iMCAwIDI0IDI0IiB3aWR0aD0iMjRweCIgZmlsbD0iIzAwMDAwMCI+CiAgPHBhdGggZD0iTTAgMGgyNHYyNEgwVjB6IiBmaWxsPSJub25lIi8+PHBhdGggY2xhc3M9ImpwLWljb24zIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzYxNjE2MSIgZD0iTTIwIDZoLThsLTItMkg0Yy0xLjEgMC0yIC45LTIgMnYxMmMwIDEuMS45IDIgMiAyaDE2YzEuMSAwIDItLjkgMi0yVjhjMC0xLjEtLjktMi0yLTJ6bS0yLjA2IDExTDE1IDE1LjI4IDEyLjA2IDE3bC43OC0zLjMzLTIuNTktMi4yNCAzLjQxLS4yOUwxNSA4bDEuMzQgMy4xNCAzLjQxLjI5LTIuNTkgMi4yNC43OCAzLjMzeiIvPgo8L3N2Zz4K);
  --jp-icon-folder: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTAgNEg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMThjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY4YzAtMS4xLS45LTItMi0yaC04bC0yLTJ6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-home: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjRweCIgdmlld0JveD0iMCAwIDI0IDI0IiB3aWR0aD0iMjRweCIgZmlsbD0iIzAwMDAwMCI+CiAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPjxwYXRoIGNsYXNzPSJqcC1pY29uMyBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xMCAyMHYtNmg0djZoNXYtOGgzTDEyIDMgMiAxMmgzdjh6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-html5: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDUxMiA1MTIiPgogIDxwYXRoIGNsYXNzPSJqcC1pY29uMCBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiMwMDAiIGQ9Ik0xMDguNCAwaDIzdjIyLjhoMjEuMlYwaDIzdjY5aC0yM1Y0NmgtMjF2MjNoLTIzLjJNMjA2IDIzaC0yMC4zVjBoNjMuN3YyM0gyMjl2NDZoLTIzbTUzLjUtNjloMjQuMWwxNC44IDI0LjNMMzEzLjIgMGgyNC4xdjY5aC0yM1YzNC44bC0xNi4xIDI0LjgtMTYuMS0yNC44VjY5aC0yMi42bTg5LjItNjloMjN2NDYuMmgzMi42VjY5aC01NS42Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI2U0NGQyNiIgZD0iTTEwNy42IDQ3MWwtMzMtMzcwLjRoMzYyLjhsLTMzIDM3MC4yTDI1NS43IDUxMiIvPgogIDxwYXRoIGNsYXNzPSJqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNmMTY1MjkiIGQ9Ik0yNTYgNDgwLjVWMTMxaDE0OC4zTDM3NiA0NDciLz4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNlYmViZWIiIGQ9Ik0xNDIgMTc2LjNoMTE0djQ1LjRoLTY0LjJsNC4yIDQ2LjVoNjB2NDUuM0gxNTQuNG0yIDIyLjhIMjAybDMuMiAzNi4zIDUwLjggMTMuNnY0Ny40bC05My4yLTI2Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIiBmaWxsPSIjZmZmIiBkPSJNMzY5LjYgMTc2LjNIMjU1Ljh2NDUuNGgxMDkuNm0tNC4xIDQ2LjVIMjU1Ljh2NDUuNGg1NmwtNS4zIDU5LTUwLjcgMTMuNnY0Ny4ybDkzLTI1LjgiLz4KPC9zdmc+Cg==);
  --jp-icon-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1icmFuZDQganAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNGRkYiIGQ9Ik0yLjIgMi4yaDE3LjV2MTcuNUgyLjJ6Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzNGNTFCNSIgZD0iTTIuMiAyLjJ2MTcuNWgxNy41bC4xLTE3LjVIMi4yem0xMi4xIDIuMmMxLjIgMCAyLjIgMSAyLjIgMi4ycy0xIDIuMi0yLjIgMi4yLTIuMi0xLTIuMi0yLjIgMS0yLjIgMi4yLTIuMnpNNC40IDE3LjZsMy4zLTguOCAzLjMgNi42IDIuMi0zLjIgNC40IDUuNEg0LjR6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-info: url(data:image/svg+xml;base64,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);
  --jp-icon-inspector: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaW5zcGVjdG9yLWljb24tY29sb3IganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMjAgNEg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMThjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY2YzAtMS4xLS45LTItMi0yem0tNSAxNEg0di00aDExdjR6bTAtNUg0VjloMTF2NHptNSA1aC00VjloNHY5eiIvPgo8L3N2Zz4K);
  --jp-icon-json: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtanNvbi1pY29uLWNvbG9yIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI0Y5QTgyNSI+CiAgICA8cGF0aCBkPSJNMjAuMiAxMS44Yy0xLjYgMC0xLjcuNS0xLjcgMSAwIC40LjEuOS4xIDEuMy4xLjUuMS45LjEgMS4zIDAgMS43LTEuNCAyLjMtMy41IDIuM2gtLjl2LTEuOWguNWMxLjEgMCAxLjQgMCAxLjQtLjggMC0uMyAwLS42LS4xLTEgMC0uNC0uMS0uOC0uMS0xLjIgMC0xLjMgMC0xLjggMS4zLTItMS4zLS4yLTEuMy0uNy0xLjMtMiAwLS40LjEtLjguMS0xLjIuMS0uNC4xLS43LjEtMSAwLS44LS40LS43LTEuNC0uOGgtLjVWNC4xaC45YzIuMiAwIDMuNS43IDMuNSAyLjMgMCAuNC0uMS45LS4xIDEuMy0uMS41LS4xLjktLjEgMS4zIDAgLjUuMiAxIDEuNyAxdjEuOHpNMS44IDEwLjFjMS42IDAgMS43LS41IDEuNy0xIDAtLjQtLjEtLjktLjEtMS4zLS4xLS41LS4xLS45LS4xLTEuMyAwLTEuNiAxLjQtMi4zIDMuNS0yLjNoLjl2MS45aC0uNWMtMSAwLTEuNCAwLTEuNC44IDAgLjMgMCAuNi4xIDEgMCAuMi4xLjYuMSAxIDAgMS4zIDAgMS44LTEuMyAyQzYgMTEuMiA2IDExLjcgNiAxM2MwIC40LS4xLjgtLjEgMS4yLS4xLjMtLjEuNy0uMSAxIDAgLjguMy44IDEuNC44aC41djEuOWgtLjljLTIuMSAwLTMuNS0uNi0zLjUtMi4zIDAtLjQuMS0uOS4xLTEuMy4xLS41LjEtLjkuMS0xLjMgMC0uNS0uMi0xLTEuNy0xdi0xLjl6Ii8+CiAgICA8Y2lyY2xlIGN4PSIxMSIgY3k9IjEzLjgiIHI9IjIuMSIvPgogICAgPGNpcmNsZSBjeD0iMTEiIGN5PSI4LjIiIHI9IjIuMSIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-julia: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDMyNSAzMDAiPgogIDxnIGNsYXNzPSJqcC1icmFuZDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjY2IzYzMzIj4KICAgIDxwYXRoIGQ9Ik0gMTUwLjg5ODQzOCAyMjUgQyAxNTAuODk4NDM4IDI2Ni40MjE4NzUgMTE3LjMyMDMxMiAzMDAgNzUuODk4NDM4IDMwMCBDIDM0LjQ3NjU2MiAzMDAgMC44OTg0MzggMjY2LjQyMTg3NSAwLjg5ODQzOCAyMjUgQyAwLjg5ODQzOCAxODMuNTc4MTI1IDM0LjQ3NjU2MiAxNTAgNzUuODk4NDM4IDE1MCBDIDExNy4zMjAzMTIgMTUwIDE1MC44OTg0MzggMTgzLjU3ODEyNSAxNTAuODk4NDM4IDIyNSIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzM4OTgyNiI+CiAgICA8cGF0aCBkPSJNIDIzNy41IDc1IEMgMjM3LjUgMTE2LjQyMTg3NSAyMDMuOTIxODc1IDE1MCAxNjIuNSAxNTAgQyAxMjEuMDc4MTI1IDE1MCA4Ny41IDExNi40MjE4NzUgODcuNSA3NSBDIDg3LjUgMzMuNTc4MTI1IDEyMS4wNzgxMjUgMCAxNjIuNSAwIEMgMjAzLjkyMTg3NSAwIDIzNy41IDMzLjU3ODEyNSAyMzcuNSA3NSIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzk1NThiMiI+CiAgICA8cGF0aCBkPSJNIDMyNC4xMDE1NjIgMjI1IEMgMzI0LjEwMTU2MiAyNjYuNDIxODc1IDI5MC41MjM0MzggMzAwIDI0OS4xMDE1NjIgMzAwIEMgMjA3LjY3OTY4OCAzMDAgMTc0LjEwMTU2MiAyNjYuNDIxODc1IDE3NC4xMDE1NjIgMjI1IEMgMTc0LjEwMTU2MiAxODMuNTc4MTI1IDIwNy42Nzk2ODggMTUwIDI0OS4xMDE1NjIgMTUwIEMgMjkwLjUyMzQzOCAxNTAgMzI0LjEwMTU2MiAxODMuNTc4MTI1IDMyNC4xMDE1NjIgMjI1Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-jupyter-favicon: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTUyIiBoZWlnaHQ9IjE2NSIgdmlld0JveD0iMCAwIDE1MiAxNjUiIHZlcnNpb249IjEuMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgPGcgY2xhc3M9ImpwLWp1cHl0ZXItaWNvbi1jb2xvciIgZmlsbD0iI0YzNzcyNiI+CiAgICA8cGF0aCB0cmFuc2Zvcm09InRyYW5zbGF0ZSgwLjA3ODk0NywgMTEwLjU4MjkyNykiIGQ9Ik03NS45NDIyODQyLDI5LjU4MDQ1NjEgQzQzLjMwMjM5NDcsMjkuNTgwNDU2MSAxNC43OTY3ODMyLDE3LjY1MzQ2MzQgMCwwIEM1LjUxMDgzMjExLDE1Ljg0MDY4MjkgMTUuNzgxNTM4OSwyOS41NjY3NzMyIDI5LjM5MDQ5NDcsMzkuMjc4NDE3MSBDNDIuOTk5Nyw0OC45ODk4NTM3IDU5LjI3MzcsNTQuMjA2NzgwNSA3NS45NjA1Nzg5LDU0LjIwNjc4MDUgQzkyLjY0NzQ1NzksNTQuMjA2NzgwNSAxMDguOTIxNDU4LDQ4Ljk4OTg1MzcgMTIyLjUzMDY2MywzOS4yNzg0MTcxIEMxMzYuMTM5NDUzLDI5LjU2Njc3MzIgMTQ2LjQxMDI4NCwxNS44NDA2ODI5IDE1MS45MjExNTgsMCBDMTM3LjA4Nzg2OCwxNy42NTM0NjM0IDEwOC41ODI1ODksMjkuNTgwNDU2MSA3NS45NDIyODQyLDI5LjU4MDQ1NjEgTDc1Ljk0MjI4NDIsMjkuNTgwNDU2MSBaIiAvPgogICAgPHBhdGggdHJhbnNmb3JtPSJ0cmFuc2xhdGUoMC4wMzczNjgsIDAuNzA0ODc4KSIgZD0iTTc1Ljk3ODQ1NzksMjQuNjI2NDA3MyBDMTA4LjYxODc2MywyNC42MjY0MDczIDEzNy4xMjQ0NTgsMzYuNTUzNDQxNSAxNTEuOTIxMTU4LDU0LjIwNjc4MDUgQzE0Ni40MTAyODQsMzguMzY2MjIyIDEzNi4xMzk0NTMsMjQuNjQwMTMxNyAxMjIuNTMwNjYzLDE0LjkyODQ4NzggQzEwOC45MjE0NTgsNS4yMTY4NDM5IDkyLjY0NzQ1NzksMCA3NS45NjA1Nzg5LDAgQzU5LjI3MzcsMCA0Mi45OTk3LDUuMjE2ODQzOSAyOS4zOTA0OTQ3LDE0LjkyODQ4NzggQzE1Ljc4MTUzODksMjQuNjQwMTMxNyA1LjUxMDgzMjExLDM4LjM2NjIyMiAwLDU0LjIwNjc4MDUgQzE0LjgzMzA4MTYsMzYuNTg5OTI5MyA0My4zMzg1Njg0LDI0LjYyNjQwNzMgNzUuOTc4NDU3OSwyNC42MjY0MDczIEw3NS45Nzg0NTc5LDI0LjYyNjQwNzMgWiIgLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-jupyter: url(data:image/svg+xml;base64,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);
  --jp-icon-jupyterlab-wordmark: url(data:image/svg+xml;base64,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);
  --jp-icon-kernel: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgZmlsbD0iIzYxNjE2MSIgZD0iTTE1IDlIOXY2aDZWOXptLTIgNGgtMnYtMmgydjJ6bTgtMlY5aC0yVjdjMC0xLjEtLjktMi0yLTJoLTJWM2gtMnYyaC0yVjNIOXYySDdjLTEuMSAwLTIgLjktMiAydjJIM3YyaDJ2MkgzdjJoMnYyYzAgMS4xLjkgMiAyIDJoMnYyaDJ2LTJoMnYyaDJ2LTJoMmMxLjEgMCAyLS45IDItMnYtMmgydi0yaC0ydi0yaDJ6bS00IDZIN1Y3aDEwdjEweiIvPgo8L3N2Zz4K);
  --jp-icon-keyboard: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMjAgNUg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMTdjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY3YzAtMS4xLS45LTItMi0yem0tOSAzaDJ2MmgtMlY4em0wIDNoMnYyaC0ydi0yek04IDhoMnYySDhWOHptMCAzaDJ2Mkg4di0yem0tMSAySDV2LTJoMnYyem0wLTNINVY4aDJ2MnptOSA3SDh2LTJoOHYyem0wLTRoLTJ2LTJoMnYyem0wLTNoLTJWOGgydjJ6bTMgM2gtMnYtMmgydjJ6bTAtM2gtMlY4aDJ2MnoiLz4KPC9zdmc+Cg==);
  --jp-icon-launch: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMzIgMzIiIHdpZHRoPSIzMiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0yNiwyOEg2YTIuMDAyNywyLjAwMjcsMCwwLDEtMi0yVjZBMi4wMDI3LDIuMDAyNywwLDAsMSw2LDRIMTZWNkg2VjI2SDI2VjE2aDJWMjZBMi4wMDI3LDIuMDAyNywwLDAsMSwyNiwyOFoiLz4KICAgIDxwb2x5Z29uIHBvaW50cz0iMjAgMiAyMCA0IDI2LjU4NiA0IDE4IDEyLjU4NiAxOS40MTQgMTQgMjggNS40MTQgMjggMTIgMzAgMTIgMzAgMiAyMCAyIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-launcher: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkgMTlINVY1aDdWM0g1YTIgMiAwIDAwLTIgMnYxNGEyIDIgMCAwMDIgMmgxNGMxLjEgMCAyLS45IDItMnYtN2gtMnY3ek0xNCAzdjJoMy41OWwtOS44MyA5LjgzIDEuNDEgMS40MUwxOSA2LjQxVjEwaDJWM2gtN3oiLz4KPC9zdmc+Cg==);
  --jp-icon-line-form: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGZpbGw9IndoaXRlIiBkPSJNNS44OCA0LjEyTDEzLjc2IDEybC03Ljg4IDcuODhMOCAyMmwxMC0xMEw4IDJ6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-link: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTMuOSAxMmMwLTEuNzEgMS4zOS0zLjEgMy4xLTMuMWg0VjdIN2MtMi43NiAwLTUgMi4yNC01IDVzMi4yNCA1IDUgNWg0di0xLjlIN2MtMS43MSAwLTMuMS0xLjM5LTMuMS0zLjF6TTggMTNoOHYtMkg4djJ6bTktNmgtNHYxLjloNGMxLjcxIDAgMy4xIDEuMzkgMy4xIDMuMXMtMS4zOSAzLjEtMy4xIDMuMWgtNFYxN2g0YzIuNzYgMCA1LTIuMjQgNS01cy0yLjI0LTUtNS01eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-list: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xOSA1djE0SDVWNWgxNG0xLjEtMkgzLjljLS41IDAtLjkuNC0uOS45djE2LjJjMCAuNC40LjkuOS45aDE2LjJjLjQgMCAuOS0uNS45LS45VjMuOWMwLS41LS41LS45LS45LS45ek0xMSA3aDZ2MmgtNlY3em0wIDRoNnYyaC02di0yem0wIDRoNnYyaC02ek03IDdoMnYySDd6bTAgNGgydjJIN3ptMCA0aDJ2Mkg3eiIvPgo8L3N2Zz4K);
  --jp-icon-markdown: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjN0IxRkEyIiBkPSJNNSAxNC45aDEybC02LjEgNnptOS40LTYuOGMwLTEuMy0uMS0yLjktLjEtNC41LS40IDEuNC0uOSAyLjktMS4zIDQuM2wtMS4zIDQuM2gtMkw4LjUgNy45Yy0uNC0xLjMtLjctMi45LTEtNC4zLS4xIDEuNi0uMSAzLjItLjIgNC42TDcgMTIuNEg0LjhsLjctMTFoMy4zTDEwIDVjLjQgMS4yLjcgMi43IDEgMy45LjMtMS4yLjctMi42IDEtMy45bDEuMi0zLjdoMy4zbC42IDExaC0yLjRsLS4zLTQuMnoiLz4KPC9zdmc+Cg==);
  --jp-icon-move-down: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBkPSJNMTIuNDcxIDcuNTI4OTlDMTIuNzYzMiA3LjIzNjg0IDEyLjc2MzIgNi43NjMxNiAxMi40NzEgNi40NzEwMVY2LjQ3MTAxQzEyLjE3OSA2LjE3OTA1IDExLjcwNTcgNi4xNzg4NCAxMS40MTM1IDYuNDcwNTRMNy43NSAxMC4xMjc1VjEuNzVDNy43NSAxLjMzNTc5IDcuNDE0MjEgMSA3IDFWMUM2LjU4NTc5IDEgNi4yNSAxLjMzNTc5IDYuMjUgMS43NVYxMC4xMjc1TDIuNTk3MjYgNi40NjgyMkMyLjMwMzM4IDYuMTczODEgMS44MjY0MSA2LjE3MzU5IDEuNTMyMjYgNi40Njc3NFY2LjQ2Nzc0QzEuMjM4MyA2Ljc2MTcgMS4yMzgzIDcuMjM4MyAxLjUzMjI2IDcuNTMyMjZMNi4yOTI4OSAxMi4yOTI5QzYuNjgzNDIgMTIuNjgzNCA3LjMxNjU4IDEyLjY4MzQgNy43MDcxMSAxMi4yOTI5TDEyLjQ3MSA3LjUyODk5WiIgZmlsbD0iIzYxNjE2MSIvPgo8L3N2Zz4K);
  --jp-icon-move-up: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBkPSJNMS41Mjg5OSA2LjQ3MTAxQzEuMjM2ODQgNi43NjMxNiAxLjIzNjg0IDcuMjM2ODQgMS41Mjg5OSA3LjUyODk5VjcuNTI4OTlDMS44MjA5NSA3LjgyMDk1IDIuMjk0MjYgNy44MjExNiAyLjU4NjQ5IDcuNTI5NDZMNi4yNSAzLjg3MjVWMTIuMjVDNi4yNSAxMi42NjQyIDYuNTg1NzkgMTMgNyAxM1YxM0M3LjQxNDIxIDEzIDcuNzUgMTIuNjY0MiA3Ljc1IDEyLjI1VjMuODcyNUwxMS40MDI3IDcuNTMxNzhDMTEuNjk2NiA3LjgyNjE5IDEyLjE3MzYgNy44MjY0MSAxMi40Njc3IDcuNTMyMjZWNy41MzIyNkMxMi43NjE3IDcuMjM4MyAxMi43NjE3IDYuNzYxNyAxMi40Njc3IDYuNDY3NzRMNy43MDcxMSAxLjcwNzExQzcuMzE2NTggMS4zMTY1OCA2LjY4MzQyIDEuMzE2NTggNi4yOTI4OSAxLjcwNzExTDEuNTI4OTkgNi40NzEwMVoiIGZpbGw9IiM2MTYxNjEiLz4KPC9zdmc+Cg==);
  --jp-icon-new-folder: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwIDZoLThsLTItMkg0Yy0xLjExIDAtMS45OS44OS0xLjk5IDJMMiAxOGMwIDEuMTEuODkgMiAyIDJoMTZjMS4xMSAwIDItLjg5IDItMlY4YzAtMS4xMS0uODktMi0yLTJ6bS0xIDhoLTN2M2gtMnYtM2gtM3YtMmgzVjloMnYzaDN2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-not-trusted: url(data:image/svg+xml;base64,PHN2ZyBmaWxsPSJub25lIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI1IDI1Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDMgMykiIGQ9Ik0xLjg2MDk0IDExLjQ0MDlDMC44MjY0NDggOC43NzAyNyAwLjg2Mzc3OSA2LjA1NzY0IDEuMjQ5MDcgNC4xOTkzMkMyLjQ4MjA2IDMuOTMzNDcgNC4wODA2OCAzLjQwMzQ3IDUuNjAxMDIgMi44NDQ5QzcuMjM1NDkgMi4yNDQ0IDguODU2NjYgMS41ODE1IDkuOTg3NiAxLjA5NTM5QzExLjA1OTcgMS41ODM0MSAxMi42MDk0IDIuMjQ0NCAxNC4yMTggMi44NDMzOUMxNS43NTAzIDMuNDEzOTQgMTcuMzk5NSAzLjk1MjU4IDE4Ljc1MzkgNC4yMTM4NUMxOS4xMzY0IDYuMDcxNzcgMTkuMTcwOSA4Ljc3NzIyIDE4LjEzOSAxMS40NDA5QzE3LjAzMDMgMTQuMzAzMiAxNC42NjY4IDE3LjE4NDQgOS45OTk5OSAxOC45MzU0QzUuMzMzMTkgMTcuMTg0NCAyLjk2OTY4IDE0LjMwMzIgMS44NjA5NCAxMS40NDA5WiIvPgogICAgPHBhdGggY2xhc3M9ImpwLWljb24yIiBzdHJva2U9IiMzMzMzMzMiIHN0cm9rZS13aWR0aD0iMiIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoOS4zMTU5MiA5LjMyMDMxKSIgZD0iTTcuMzY4NDIgMEwwIDcuMzY0NzkiLz4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDkuMzE1OTIgMTYuNjgzNikgc2NhbGUoMSAtMSkiIGQ9Ik03LjM2ODQyIDBMMCA3LjM2NDc5Ii8+Cjwvc3ZnPgo=);
  --jp-icon-notebook: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtbm90ZWJvb2staWNvbi1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNFRjZDMDAiPgogICAgPHBhdGggZD0iTTE4LjcgMy4zdjE1LjRIMy4zVjMuM2gxNS40bTEuNS0xLjVIMS44djE4LjNoMTguM2wuMS0xOC4zeiIvPgogICAgPHBhdGggZD0iTTE2LjUgMTYuNWwtNS40LTQuMy01LjYgNC4zdi0xMWgxMXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-numbering: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjIiIGhlaWdodD0iMjIiIHZpZXdCb3g9IjAgMCAyOCAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTQgMTlINlYxOS41SDVWMjAuNUg2VjIxSDRWMjJIN1YxOEg0VjE5Wk01IDEwSDZWNkg0VjdINVYxMFpNNCAxM0g1LjhMNCAxNS4xVjE2SDdWMTVINS4yTDcgMTIuOVYxMkg0VjEzWk05IDdWOUgyM1Y3SDlaTTkgMjFIMjNWMTlIOVYyMVpNOSAxNUgyM1YxM0g5VjE1WiIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-offline-bolt: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyIDIuMDJjLTUuNTEgMC05Ljk4IDQuNDctOS45OCA5Ljk4czQuNDcgOS45OCA5Ljk4IDkuOTggOS45OC00LjQ3IDkuOTgtOS45OFMxNy41MSAyLjAyIDEyIDIuMDJ6TTExLjQ4IDIwdi02LjI2SDhMMTMgNHY2LjI2aDMuMzVMMTEuNDggMjB6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-palette: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE4IDEzVjIwSDRWNkg5LjAyQzkuMDcgNS4yOSA5LjI0IDQuNjIgOS41IDRINEMyLjkgNCAyIDQuOSAyIDZWMjBDMiAyMS4xIDIuOSAyMiA0IDIySDE4QzE5LjEgMjIgMjAgMjEuMSAyMCAyMFYxNUwxOCAxM1pNMTkuMyA4Ljg5QzE5Ljc0IDguMTkgMjAgNy4zOCAyMCA2LjVDMjAgNC4wMSAxNy45OSAyIDE1LjUgMkMxMy4wMSAyIDExIDQuMDEgMTEgNi41QzExIDguOTkgMTMuMDEgMTEgMTUuNDkgMTFDMTYuMzcgMTEgMTcuMTkgMTAuNzQgMTcuODggMTAuM0wyMSAxMy40MkwyMi40MiAxMkwxOS4zIDguODlaTTE1LjUgOUMxNC4xMiA5IDEzIDcuODggMTMgNi41QzEzIDUuMTIgMTQuMTIgNCAxNS41IDRDMTYuODggNCAxOCA1LjEyIDE4IDYuNUMxOCA3Ljg4IDE2Ljg4IDkgMTUuNSA5WiIvPgogICAgPHBhdGggZmlsbC1ydWxlPSJldmVub2RkIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik00IDZIOS4wMTg5NEM5LjAwNjM5IDYuMTY1MDIgOSA2LjMzMTc2IDkgNi41QzkgOC44MTU3NyAxMC4yMTEgMTAuODQ4NyAxMi4wMzQzIDEySDlWMTRIMTZWMTIuOTgxMUMxNi41NzAzIDEyLjkzNzcgMTcuMTIgMTIuODIwNyAxNy42Mzk2IDEyLjYzOTZMMTggMTNWMjBINFY2Wk04IDhINlYxMEg4VjhaTTYgMTJIOFYxNEg2VjEyWk04IDE2SDZWMThIOFYxNlpNOSAxNkgxNlYxOEg5VjE2WiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-paste: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTE5IDJoLTQuMThDMTQuNC44NCAxMy4zIDAgMTIgMGMtMS4zIDAtMi40Ljg0LTIuODIgMkg1Yy0xLjEgMC0yIC45LTIgMnYxNmMwIDEuMS45IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjRjMC0xLjEtLjktMi0yLTJ6bS03IDBjLjU1IDAgMSAuNDUgMSAxcy0uNDUgMS0xIDEtMS0uNDUtMS0xIC40NS0xIDEtMXptNyAxOEg1VjRoMnYzaDEwVjRoMnYxNnoiLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-pdf: url(data:image/svg+xml;base64,PHN2ZwogICB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyMiAyMiIgd2lkdGg9IjE2Ij4KICAgIDxwYXRoIHRyYW5zZm9ybT0icm90YXRlKDQ1KSIgY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI0ZGMkEyQSIKICAgICAgIGQ9Im0gMjIuMzQ0MzY5LC0zLjAxNjM2NDIgaCA1LjYzODYwNCB2IDEuNTc5MjQzMyBoIC0zLjU0OTIyNyB2IDEuNTA4NjkyOTkgaCAzLjMzNzU3NiBWIDEuNjUwODE1NCBoIC0zLjMzNzU3NiB2IDMuNDM1MjYxMyBoIC0yLjA4OTM3NyB6IG0gLTcuMTM2NDQ0LDEuNTc5MjQzMyB2IDQuOTQzOTU0MyBoIDAuNzQ4OTIgcSAxLjI4MDc2MSwwIDEuOTUzNzAzLC0wLjYzNDk1MzUgMC42NzgzNjksLTAuNjM0OTUzNSAwLjY3ODM2OSwtMS44NDUxNjQxIDAsLTEuMjA0NzgzNTUgLTAuNjcyOTQyLC0xLjgzNDMxMDExIC0wLjY3Mjk0MiwtMC42Mjk1MjY1OSAtMS45NTkxMywtMC42Mjk1MjY1OSB6IG0gLTIuMDg5Mzc3LC0xLjU3OTI0MzMgaCAyLjIwMzM0MyBxIDEuODQ1MTY0LDAgMi43NDYwMzksMC4yNjU5MjA3IDAuOTA2MzAxLDAuMjYwNDkzNyAxLjU1MjEwOCwwLjg5MDAyMDMgMC41Njk4MywwLjU0ODEyMjMgMC44NDY2MDUsMS4yNjQ0ODAwNiAwLjI3Njc3NCwwLjcxNjM1NzgxIDAuMjc2Nzc0LDEuNjIyNjU4OTQgMCwwLjkxNzE1NTEgLTAuMjc2Nzc0LDEuNjM4OTM5OSAtMC4yNzY3NzUsMC43MTYzNTc4IC0wLjg0NjYwNSwxLjI2NDQ4IC0wLjY1MTIzNCwwLjYyOTUyNjYgLTEuNTYyOTYyLDAuODk1NDQ3MyAtMC45MTE3MjgsMC4yNjA0OTM3IC0yLjczNTE4NSwwLjI2MDQ5MzcgaCAtMi4yMDMzNDMgeiBtIC04LjE0NTg1NjUsMCBoIDMuNDY3ODIzIHEgMS41NDY2ODE2LDAgMi4zNzE1Nzg1LDAuNjg5MjIzIDAuODMwMzI0LDAuNjgzNzk2MSAwLjgzMDMyNCwxLjk1MzcwMzE0IDAsMS4yNzUzMzM5NyAtMC44MzAzMjQsMS45NjQ1NTcwNiBRIDkuOTg3MTk2MSwyLjI3NDkxNSA4LjQ0MDUxNDUsMi4yNzQ5MTUgSCA3LjA2MjA2ODQgViA1LjA4NjA3NjcgSCA0Ljk3MjY5MTUgWiBtIDIuMDg5Mzc2OSwxLjUxNDExOTkgdiAyLjI2MzAzOTQzIGggMS4xNTU5NDEgcSAwLjYwNzgxODgsMCAwLjkzODg2MjksLTAuMjkzMDU1NDcgMC4zMzEwNDQxLC0wLjI5ODQ4MjQxIDAuMzMxMDQ0MSwtMC44NDExNzc3MiAwLC0wLjU0MjY5NTMxIC0wLjMzMTA0NDEsLTAuODM1NzUwNzQgLTAuMzMxMDQ0MSwtMC4yOTMwNTU1IC0wLjkzODg2MjksLTAuMjkzMDU1NSB6IgovPgo8L3N2Zz4K);
  --jp-icon-python: url(data:image/svg+xml;base64,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);
  --jp-icon-r-kernel: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMjE5NkYzIiBkPSJNNC40IDIuNWMxLjItLjEgMi45LS4zIDQuOS0uMyAyLjUgMCA0LjEuNCA1LjIgMS4zIDEgLjcgMS41IDEuOSAxLjUgMy41IDAgMi0xLjQgMy41LTIuOSA0LjEgMS4yLjQgMS43IDEuNiAyLjIgMyAuNiAxLjkgMSAzLjkgMS4zIDQuNmgtMy44Yy0uMy0uNC0uOC0xLjctMS4yLTMuN3MtMS4yLTIuNi0yLjYtMi42aC0uOXY2LjRINC40VjIuNXptMy43IDYuOWgxLjRjMS45IDAgMi45LS45IDIuOS0yLjNzLTEtMi4zLTIuOC0yLjNjLS43IDAtMS4zIDAtMS42LjJ2NC41aC4xdi0uMXoiLz4KPC9zdmc+Cg==);
  --jp-icon-react: url(data:image/svg+xml;base64,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);
  --jp-icon-redo: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgICA8cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIi8+PHBhdGggZD0iTTE4LjQgMTAuNkMxNi41NSA4Ljk5IDE0LjE1IDggMTEuNSA4Yy00LjY1IDAtOC41OCAzLjAzLTkuOTYgNy4yMkwzLjkgMTZjMS4wNS0zLjE5IDQuMDUtNS41IDcuNi01LjUgMS45NSAwIDMuNzMuNzIgNS4xMiAxLjg4TDEzIDE2aDlWN2wtMy42IDMuNnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-refresh: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTkgMTMuNWMtMi40OSAwLTQuNS0yLjAxLTQuNS00LjVTNi41MSA0LjUgOSA0LjVjMS4yNCAwIDIuMzYuNTIgMy4xNyAxLjMzTDEwIDhoNVYzbC0xLjc2IDEuNzZDMTIuMTUgMy42OCAxMC42NiAzIDkgMyA1LjY5IDMgMy4wMSA1LjY5IDMuMDEgOVM1LjY5IDE1IDkgMTVjMi45NyAwIDUuNDMtMi4xNiA1LjktNWgtMS41MmMtLjQ2IDItMi4yNCAzLjUtNC4zOCAzLjV6Ii8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-regex: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KICA8ZyBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiM0MTQxNDEiPgogICAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiAgPC9nPgoKICA8ZyBjbGFzcz0ianAtaWNvbi1hY2NlbnQyIiBmaWxsPSIjRkZGIj4KICAgIDxjaXJjbGUgY2xhc3M9InN0MiIgY3g9IjUuNSIgY3k9IjE0LjUiIHI9IjEuNSIvPgogICAgPHJlY3QgeD0iMTIiIHk9IjQiIGNsYXNzPSJzdDIiIHdpZHRoPSIxIiBoZWlnaHQ9IjgiLz4KICAgIDxyZWN0IHg9IjguNSIgeT0iNy41IiB0cmFuc2Zvcm09Im1hdHJpeCgwLjg2NiAtMC41IDAuNSAwLjg2NiAtMi4zMjU1IDcuMzIxOSkiIGNsYXNzPSJzdDIiIHdpZHRoPSI4IiBoZWlnaHQ9IjEiLz4KICAgIDxyZWN0IHg9IjEyIiB5PSI0IiB0cmFuc2Zvcm09Im1hdHJpeCgwLjUgLTAuODY2IDAuODY2IDAuNSAtMC42Nzc5IDE0LjgyNTIpIiBjbGFzcz0ic3QyIiB3aWR0aD0iMSIgaGVpZ2h0PSI4Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-run: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTggNXYxNGwxMS03eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-running: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDUxMiA1MTIiPgogIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICA8cGF0aCBkPSJNMjU2IDhDMTE5IDggOCAxMTkgOCAyNTZzMTExIDI0OCAyNDggMjQ4IDI0OC0xMTEgMjQ4LTI0OFMzOTMgOCAyNTYgOHptOTYgMzI4YzAgOC44LTcuMiAxNi0xNiAxNkgxNzZjLTguOCAwLTE2LTcuMi0xNi0xNlYxNzZjMC04LjggNy4yLTE2IDE2LTE2aDE2MGM4LjggMCAxNiA3LjIgMTYgMTZ2MTYweiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-save: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTE3IDNINWMtMS4xMSAwLTIgLjktMiAydjE0YzAgMS4xLjg5IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjdsLTQtNHptLTUgMTZjLTEuNjYgMC0zLTEuMzQtMy0zczEuMzQtMyAzLTMgMyAxLjM0IDMgMy0xLjM0IDMtMyAzem0zLTEwSDVWNWgxMHY0eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-search: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjEsMTAuOWgtMC43bC0wLjItMC4yYzAuOC0wLjksMS4zLTIuMiwxLjMtMy41YzAtMy0yLjQtNS40LTUuNC01LjRTMS44LDQuMiwxLjgsNy4xczIuNCw1LjQsNS40LDUuNCBjMS4zLDAsMi41LTAuNSwzLjUtMS4zbDAuMiwwLjJ2MC43bDQuMSw0LjFsMS4yLTEuMkwxMi4xLDEwLjl6IE03LjEsMTAuOWMtMi4xLDAtMy43LTEuNy0zLjctMy43czEuNy0zLjcsMy43LTMuN3MzLjcsMS43LDMuNywzLjcgUzkuMiwxMC45LDcuMSwxMC45eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-settings: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkuNDMgMTIuOThjLjA0LS4zMi4wNy0uNjQuMDctLjk4cy0uMDMtLjY2LS4wNy0uOThsMi4xMS0xLjY1Yy4xOS0uMTUuMjQtLjQyLjEyLS42NGwtMi0zLjQ2Yy0uMTItLjIyLS4zOS0uMy0uNjEtLjIybC0yLjQ5IDFjLS41Mi0uNC0xLjA4LS43My0xLjY5LS45OGwtLjM4LTIuNjVBLjQ4OC40ODggMCAwMDE0IDJoLTRjLS4yNSAwLS40Ni4xOC0uNDkuNDJsLS4zOCAyLjY1Yy0uNjEuMjUtMS4xNy41OS0xLjY5Ljk4bC0yLjQ5LTFjLS4yMy0uMDktLjQ5IDAtLjYxLjIybC0yIDMuNDZjLS4xMy4yMi0uMDcuNDkuMTIuNjRsMi4xMSAxLjY1Yy0uMDQuMzItLjA3LjY1LS4wNy45OHMuMDMuNjYuMDcuOThsLTIuMTEgMS42NWMtLjE5LjE1LS4yNC40Mi0uMTIuNjRsMiAzLjQ2Yy4xMi4yMi4zOS4zLjYxLjIybDIuNDktMWMuNTIuNCAxLjA4LjczIDEuNjkuOThsLjM4IDIuNjVjLjAzLjI0LjI0LjQyLjQ5LjQyaDRjLjI1IDAgLjQ2LS4xOC40OS0uNDJsLjM4LTIuNjVjLjYxLS4yNSAxLjE3LS41OSAxLjY5LS45OGwyLjQ5IDFjLjIzLjA5LjQ5IDAgLjYxLS4yMmwyLTMuNDZjLjEyLS4yMi4wNy0uNDktLjEyLS42NGwtMi4xMS0xLjY1ek0xMiAxNS41Yy0xLjkzIDAtMy41LTEuNTctMy41LTMuNXMxLjU3LTMuNSAzLjUtMy41IDMuNSAxLjU3IDMuNSAzLjUtMS41NyAzLjUtMy41IDMuNXoiLz4KPC9zdmc+Cg==);
  --jp-icon-share: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIHZpZXdCb3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTSAxOCAyIEMgMTYuMzU0OTkgMiAxNSAzLjM1NDk5MDQgMTUgNSBDIDE1IDUuMTkwOTUyOSAxNS4wMjE3OTEgNS4zNzcxMjI0IDE1LjA1NjY0MSA1LjU1ODU5MzggTCA3LjkyMTg3NSA5LjcyMDcwMzEgQyA3LjM5ODUzOTkgOS4yNzc4NTM5IDYuNzMyMDc3MSA5IDYgOSBDIDQuMzU0OTkwNCA5IDMgMTAuMzU0OTkgMyAxMiBDIDMgMTMuNjQ1MDEgNC4zNTQ5OTA0IDE1IDYgMTUgQyA2LjczMjA3NzEgMTUgNy4zOTg1Mzk5IDE0LjcyMjE0NiA3LjkyMTg3NSAxNC4yNzkyOTcgTCAxNS4wNTY2NDEgMTguNDM5NDUzIEMgMTUuMDIxNTU1IDE4LjYyMTUxNCAxNSAxOC44MDgzODYgMTUgMTkgQyAxNSAyMC42NDUwMSAxNi4zNTQ5OSAyMiAxOCAyMiBDIDE5LjY0NTAxIDIyIDIxIDIwLjY0NTAxIDIxIDE5IEMgMjEgMTcuMzU0OTkgMTkuNjQ1MDEgMTYgMTggMTYgQyAxNy4yNjc0OCAxNiAxNi42MDE1OTMgMTYuMjc5MzI4IDE2LjA3ODEyNSAxNi43MjI2NTYgTCA4Ljk0MzM1OTQgMTIuNTU4NTk0IEMgOC45NzgyMDk1IDEyLjM3NzEyMiA5IDEyLjE5MDk1MyA5IDEyIEMgOSAxMS44MDkwNDcgOC45NzgyMDk1IDExLjYyMjg3OCA4Ljk0MzM1OTQgMTEuNDQxNDA2IEwgMTYuMDc4MTI1IDcuMjc5Mjk2OSBDIDE2LjYwMTQ2IDcuNzIyMTQ2MSAxNy4yNjc5MjMgOCAxOCA4IEMgMTkuNjQ1MDEgOCAyMSA2LjY0NTAwOTYgMjEgNSBDIDIxIDMuMzU0OTkwNCAxOS42NDUwMSAyIDE4IDIgeiBNIDE4IDQgQyAxOC41NjQxMjkgNCAxOSA0LjQzNTg3MDYgMTkgNSBDIDE5IDUuNTY0MTI5NCAxOC41NjQxMjkgNiAxOCA2IEMgMTcuNDM1ODcxIDYgMTcgNS41NjQxMjk0IDE3IDUgQyAxNyA0LjQzNTg3MDYgMTcuNDM1ODcxIDQgMTggNCB6IE0gNiAxMSBDIDYuNTY0MTI5NCAxMSA3IDExLjQzNTg3MSA3IDEyIEMgNyAxMi41NjQxMjkgNi41NjQxMjk0IDEzIDYgMTMgQyA1LjQzNTg3MDYgMTMgNSAxMi41NjQxMjkgNSAxMiBDIDUgMTEuNDM1ODcxIDUuNDM1ODcwNiAxMSA2IDExIHogTSAxOCAxOCBDIDE4LjU2NDEyOSAxOCAxOSAxOC40MzU4NzEgMTkgMTkgQyAxOSAxOS41NjQxMjkgMTguNTY0MTI5IDIwIDE4IDIwIEMgMTcuNDM1ODcxIDIwIDE3IDE5LjU2NDEyOSAxNyAxOSBDIDE3IDE4LjQzNTg3MSAxNy40MzU4NzEgMTggMTggMTggeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-spreadsheet: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDEganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNENBRjUwIiBkPSJNMi4yIDIuMnYxNy42aDE3LjZWMi4ySDIuMnptMTUuNCA3LjdoLTUuNVY0LjRoNS41djUuNXpNOS45IDQuNHY1LjVINC40VjQuNGg1LjV6bS01LjUgNy43aDUuNXY1LjVINC40di01LjV6bTcuNyA1LjV2LTUuNWg1LjV2NS41aC01LjV6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-stop: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik02IDZoMTJ2MTJINnoiLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-tab: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIxIDNIM2MtMS4xIDAtMiAuOS0yIDJ2MTRjMCAxLjEuOSAyIDIgMmgxOGMxLjEgMCAyLS45IDItMlY1YzAtMS4xLS45LTItMi0yem0wIDE2SDNWNWgxMHY0aDh2MTB6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-table-rows: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik0yMSw4SDNWNGgxOFY4eiBNMjEsMTBIM3Y0aDE4VjEweiBNMjEsMTZIM3Y0aDE4VjE2eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-tag: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjgiIGhlaWdodD0iMjgiIHZpZXdCb3g9IjAgMCA0MyAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTI4LjgzMzIgMTIuMzM0TDMyLjk5OTggMTYuNTAwN0wzNy4xNjY1IDEyLjMzNEgyOC44MzMyWiIvPgoJCTxwYXRoIGQ9Ik0xNi4yMDk1IDIxLjYxMDRDMTUuNjg3MyAyMi4xMjk5IDE0Ljg0NDMgMjIuMTI5OSAxNC4zMjQ4IDIxLjYxMDRMNi45ODI5IDE0LjcyNDVDNi41NzI0IDE0LjMzOTQgNi4wODMxMyAxMy42MDk4IDYuMDQ3ODYgMTMuMDQ4MkM1Ljk1MzQ3IDExLjUyODggNi4wMjAwMiA4LjYxOTQ0IDYuMDY2MjEgNy4wNzY5NUM2LjA4MjgxIDYuNTE0NzcgNi41NTU0OCA2LjA0MzQ3IDcuMTE4MDQgNi4wMzA1NUM5LjA4ODYzIDUuOTg0NzMgMTMuMjYzOCA1LjkzNTc5IDEzLjY1MTggNi4zMjQyNUwyMS43MzY5IDEzLjYzOUMyMi4yNTYgMTQuMTU4NSAyMS43ODUxIDE1LjQ3MjQgMjEuMjYyIDE1Ljk5NDZMMTYuMjA5NSAyMS42MTA0Wk05Ljc3NTg1IDguMjY1QzkuMzM1NTEgNy44MjU2NiA4LjYyMzUxIDcuODI1NjYgOC4xODI4IDguMjY1QzcuNzQzNDYgOC43MDU3MSA3Ljc0MzQ2IDkuNDE3MzMgOC4xODI4IDkuODU2NjdDOC42MjM4MiAxMC4yOTY0IDkuMzM1ODIgMTAuMjk2NCA5Ljc3NTg1IDkuODU2NjdDMTAuMjE1NiA5LjQxNzMzIDEwLjIxNTYgOC43MDUzMyA5Ljc3NTg1IDguMjY1WiIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-terminal: url(data:image/svg+xml;base64,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);
  --jp-icon-text-editor: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtdGV4dC1lZGl0b3ItaWNvbi1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xNSAxNUgzdjJoMTJ2LTJ6bTAtOEgzdjJoMTJWN3pNMyAxM2gxOHYtMkgzdjJ6bTAgOGgxOHYtMkgzdjJ6TTMgM3YyaDE4VjNIM3oiLz4KPC9zdmc+Cg==);
  --jp-icon-toc: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik03LDVIMjFWN0g3VjVNNywxM1YxMUgyMVYxM0g3TTQsNC41QTEuNSwxLjUgMCAwLDEgNS41LDZBMS41LDEuNSAwIDAsMSA0LDcuNUExLjUsMS41IDAgMCwxIDIuNSw2QTEuNSwxLjUgMCAwLDEgNCw0LjVNNCwxMC41QTEuNSwxLjUgMCAwLDEgNS41LDEyQTEuNSwxLjUgMCAwLDEgNCwxMy41QTEuNSwxLjUgMCAwLDEgMi41LDEyQTEuNSwxLjUgMCAwLDEgNCwxMC41TTcsMTlWMTdIMjFWMTlIN000LDE2LjVBMS41LDEuNSAwIDAsMSA1LjUsMThBMS41LDEuNSAwIDAsMSA0LDE5LjVBMS41LDEuNSAwIDAsMSAyLjUsMThBMS41LDEuNSAwIDAsMSA0LDE2LjVaIiAvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-tree-view: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik0yMiAxMVYzaC03djNIOVYzSDJ2OGg3VjhoMnYxMGg0djNoN3YtOGgtN3YzaC0yVjhoMnYzeiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-trusted: url(data:image/svg+xml;base64,PHN2ZyBmaWxsPSJub25lIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI1Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDIgMykiIGQ9Ik0xLjg2MDk0IDExLjQ0MDlDMC44MjY0NDggOC43NzAyNyAwLjg2Mzc3OSA2LjA1NzY0IDEuMjQ5MDcgNC4xOTkzMkMyLjQ4MjA2IDMuOTMzNDcgNC4wODA2OCAzLjQwMzQ3IDUuNjAxMDIgMi44NDQ5QzcuMjM1NDkgMi4yNDQ0IDguODU2NjYgMS41ODE1IDkuOTg3NiAxLjA5NTM5QzExLjA1OTcgMS41ODM0MSAxMi42MDk0IDIuMjQ0NCAxNC4yMTggMi44NDMzOUMxNS43NTAzIDMuNDEzOTQgMTcuMzk5NSAzLjk1MjU4IDE4Ljc1MzkgNC4yMTM4NUMxOS4xMzY0IDYuMDcxNzcgMTkuMTcwOSA4Ljc3NzIyIDE4LjEzOSAxMS40NDA5QzE3LjAzMDMgMTQuMzAzMiAxNC42NjY4IDE3LjE4NDQgOS45OTk5OSAxOC45MzU0QzUuMzMzMiAxNy4xODQ0IDIuOTY5NjggMTQuMzAzMiAxLjg2MDk0IDExLjQ0MDlaIi8+CiAgICA8cGF0aCBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiMzMzMzMzMiIHN0cm9rZT0iIzMzMzMzMyIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoOCA5Ljg2NzE5KSIgZD0iTTIuODYwMTUgNC44NjUzNUwwLjcyNjU0OSAyLjk5OTU5TDAgMy42MzA0NUwyLjg2MDE1IDYuMTMxNTdMOCAwLjYzMDg3Mkw3LjI3ODU3IDBMMi44NjAxNSA0Ljg2NTM1WiIvPgo8L3N2Zz4K);
  --jp-icon-undo: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjUgOGMtMi42NSAwLTUuMDUuOTktNi45IDIuNkwyIDd2OWg5bC0zLjYyLTMuNjJjMS4zOS0xLjE2IDMuMTYtMS44OCA1LjEyLTEuODggMy41NCAwIDYuNTUgMi4zMSA3LjYgNS41bDIuMzctLjc4QzIxLjA4IDExLjAzIDE3LjE1IDggMTIuNSA4eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-user: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIHZpZXdCb3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE2IDdhNCA0IDAgMTEtOCAwIDQgNCAwIDAxOCAwek0xMiAxNGE3IDcgMCAwMC03IDdoMTRhNyA3IDAgMDAtNy03eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-users: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjQiIGhlaWdodD0iMjQiIHZlcnNpb249IjEuMSIgdmlld0JveD0iMCAwIDM2IDI0IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPgogPGcgY2xhc3M9ImpwLWljb24zIiB0cmFuc2Zvcm09Im1hdHJpeCgxLjczMjcgMCAwIDEuNzMyNyAtMy42MjgyIC4wOTk1NzcpIiBmaWxsPSIjNjE2MTYxIj4KICA8cGF0aCB0cmFuc2Zvcm09Im1hdHJpeCgxLjUsMCwwLDEuNSwwLC02KSIgZD0ibTEyLjE4NiA3LjUwOThjLTEuMDUzNSAwLTEuOTc1NyAwLjU2NjUtMi40Nzg1IDEuNDEwMiAwLjc1MDYxIDAuMzEyNzcgMS4zOTc0IDAuODI2NDggMS44NzMgMS40NzI3aDMuNDg2M2MwLTEuNTkyLTEuMjg4OS0yLjg4MjgtMi44ODA5LTIuODgyOHoiLz4KICA8cGF0aCBkPSJtMjAuNDY1IDIuMzg5NWEyLjE4ODUgMi4xODg1IDAgMCAxLTIuMTg4NCAyLjE4ODUgMi4xODg1IDIuMTg4NSAwIDAgMS0yLjE4ODUtMi4xODg1IDIuMTg4NSAyLjE4ODUgMCAwIDEgMi4xODg1LTIuMTg4NSAyLjE4ODUgMi4xODg1IDAgMCAxIDIuMTg4NCAyLjE4ODV6Ii8+CiAgPHBhdGggdHJhbnNmb3JtPSJtYXRyaXgoMS41LDAsMCwxLjUsMCwtNikiIGQ9Im0zLjU4OTggOC40MjE5Yy0xLjExMjYgMC0yLjAxMzcgMC45MDExMS0yLjAxMzcgMi4wMTM3aDIuODE0NWMwLjI2Nzk3LTAuMzczMDkgMC41OTA3LTAuNzA0MzUgMC45NTg5OC0wLjk3ODUyLTAuMzQ0MzMtMC42MTY4OC0xLjAwMzEtMS4wMzUyLTEuNzU5OC0xLjAzNTJ6Ii8+CiAgPHBhdGggZD0ibTYuOTE1NCA0LjYyM2ExLjUyOTQgMS41Mjk0IDAgMCAxLTEuNTI5NCAxLjUyOTQgMS41Mjk0IDEuNTI5NCAwIDAgMS0xLjUyOTQtMS41Mjk0IDEuNTI5NCAxLjUyOTQgMCAwIDEgMS41Mjk0LTEuNTI5NCAxLjUyOTQgMS41Mjk0IDAgMCAxIDEuNTI5NCAxLjUyOTR6Ii8+CiAgPHBhdGggZD0ibTYuMTM1IDEzLjUzNWMwLTMuMjM5MiAyLjYyNTktNS44NjUgNS44NjUtNS44NjUgMy4yMzkyIDAgNS44NjUgMi42MjU5IDUuODY1IDUuODY1eiIvPgogIDxjaXJjbGUgY3g9IjEyIiBjeT0iMy43Njg1IiByPSIyLjk2ODUiLz4KIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-vega: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbjEganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMjEyMTIxIj4KICAgIDxwYXRoIGQ9Ik0xMC42IDUuNGwyLjItMy4ySDIuMnY3LjNsNC02LjZ6Ii8+CiAgICA8cGF0aCBkPSJNMTUuOCAyLjJsLTQuNCA2LjZMNyA2LjNsLTQuOCA4djUuNWgxNy42VjIuMmgtNHptLTcgMTUuNEg1LjV2LTQuNGgzLjN2NC40em00LjQgMEg5LjhWOS44aDMuNHY3Ljh6bTQuNCAwaC0zLjRWNi41aDMuNHYxMS4xeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-word: url(data:image/svg+xml;base64,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);
  --jp-icon-yaml: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1jb250cmFzdDIganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjRDgxQjYwIj4KICAgIDxwYXRoIGQ9Ik03LjIgMTguNnYtNS40TDMgNS42aDMuM2wxLjQgMy4xYy4zLjkuNiAxLjYgMSAyLjUuMy0uOC42LTEuNiAxLTIuNWwxLjQtMy4xaDMuNGwtNC40IDcuNnY1LjVsLTIuOS0uMXoiLz4KICAgIDxjaXJjbGUgY2xhc3M9InN0MCIgY3g9IjE3LjYiIGN5PSIxNi41IiByPSIyLjEiLz4KICAgIDxjaXJjbGUgY2xhc3M9InN0MCIgY3g9IjE3LjYiIGN5PSIxMSIgcj0iMi4xIi8+CiAgPC9nPgo8L3N2Zz4K);
}

/* Icon CSS class declarations */

.jp-AddAboveIcon {
  background-image: var(--jp-icon-add-above);
}

.jp-AddBelowIcon {
  background-image: var(--jp-icon-add-below);
}

.jp-AddIcon {
  background-image: var(--jp-icon-add);
}

.jp-BellIcon {
  background-image: var(--jp-icon-bell);
}

.jp-BugDotIcon {
  background-image: var(--jp-icon-bug-dot);
}

.jp-BugIcon {
  background-image: var(--jp-icon-bug);
}

.jp-BuildIcon {
  background-image: var(--jp-icon-build);
}

.jp-CaretDownEmptyIcon {
  background-image: var(--jp-icon-caret-down-empty);
}

.jp-CaretDownEmptyThinIcon {
  background-image: var(--jp-icon-caret-down-empty-thin);
}

.jp-CaretDownIcon {
  background-image: var(--jp-icon-caret-down);
}

.jp-CaretLeftIcon {
  background-image: var(--jp-icon-caret-left);
}

.jp-CaretRightIcon {
  background-image: var(--jp-icon-caret-right);
}

.jp-CaretUpEmptyThinIcon {
  background-image: var(--jp-icon-caret-up-empty-thin);
}

.jp-CaretUpIcon {
  background-image: var(--jp-icon-caret-up);
}

.jp-CaseSensitiveIcon {
  background-image: var(--jp-icon-case-sensitive);
}

.jp-CheckIcon {
  background-image: var(--jp-icon-check);
}

.jp-CircleEmptyIcon {
  background-image: var(--jp-icon-circle-empty);
}

.jp-CircleIcon {
  background-image: var(--jp-icon-circle);
}

.jp-ClearIcon {
  background-image: var(--jp-icon-clear);
}

.jp-CloseIcon {
  background-image: var(--jp-icon-close);
}

.jp-CodeCheckIcon {
  background-image: var(--jp-icon-code-check);
}

.jp-CodeIcon {
  background-image: var(--jp-icon-code);
}

.jp-CollapseAllIcon {
  background-image: var(--jp-icon-collapse-all);
}

.jp-ConsoleIcon {
  background-image: var(--jp-icon-console);
}

.jp-CopyIcon {
  background-image: var(--jp-icon-copy);
}

.jp-CopyrightIcon {
  background-image: var(--jp-icon-copyright);
}

.jp-CutIcon {
  background-image: var(--jp-icon-cut);
}

.jp-DeleteIcon {
  background-image: var(--jp-icon-delete);
}

.jp-DownloadIcon {
  background-image: var(--jp-icon-download);
}

.jp-DuplicateIcon {
  background-image: var(--jp-icon-duplicate);
}

.jp-EditIcon {
  background-image: var(--jp-icon-edit);
}

.jp-EllipsesIcon {
  background-image: var(--jp-icon-ellipses);
}

.jp-ErrorIcon {
  background-image: var(--jp-icon-error);
}

.jp-ExpandAllIcon {
  background-image: var(--jp-icon-expand-all);
}

.jp-ExtensionIcon {
  background-image: var(--jp-icon-extension);
}

.jp-FastForwardIcon {
  background-image: var(--jp-icon-fast-forward);
}

.jp-FileIcon {
  background-image: var(--jp-icon-file);
}

.jp-FileUploadIcon {
  background-image: var(--jp-icon-file-upload);
}

.jp-FilterDotIcon {
  background-image: var(--jp-icon-filter-dot);
}

.jp-FilterIcon {
  background-image: var(--jp-icon-filter);
}

.jp-FilterListIcon {
  background-image: var(--jp-icon-filter-list);
}

.jp-FolderFavoriteIcon {
  background-image: var(--jp-icon-folder-favorite);
}

.jp-FolderIcon {
  background-image: var(--jp-icon-folder);
}

.jp-HomeIcon {
  background-image: var(--jp-icon-home);
}

.jp-Html5Icon {
  background-image: var(--jp-icon-html5);
}

.jp-ImageIcon {
  background-image: var(--jp-icon-image);
}

.jp-InfoIcon {
  background-image: var(--jp-icon-info);
}

.jp-InspectorIcon {
  background-image: var(--jp-icon-inspector);
}

.jp-JsonIcon {
  background-image: var(--jp-icon-json);
}

.jp-JuliaIcon {
  background-image: var(--jp-icon-julia);
}

.jp-JupyterFaviconIcon {
  background-image: var(--jp-icon-jupyter-favicon);
}

.jp-JupyterIcon {
  background-image: var(--jp-icon-jupyter);
}

.jp-JupyterlabWordmarkIcon {
  background-image: var(--jp-icon-jupyterlab-wordmark);
}

.jp-KernelIcon {
  background-image: var(--jp-icon-kernel);
}

.jp-KeyboardIcon {
  background-image: var(--jp-icon-keyboard);
}

.jp-LaunchIcon {
  background-image: var(--jp-icon-launch);
}

.jp-LauncherIcon {
  background-image: var(--jp-icon-launcher);
}

.jp-LineFormIcon {
  background-image: var(--jp-icon-line-form);
}

.jp-LinkIcon {
  background-image: var(--jp-icon-link);
}

.jp-ListIcon {
  background-image: var(--jp-icon-list);
}

.jp-MarkdownIcon {
  background-image: var(--jp-icon-markdown);
}

.jp-MoveDownIcon {
  background-image: var(--jp-icon-move-down);
}

.jp-MoveUpIcon {
  background-image: var(--jp-icon-move-up);
}

.jp-NewFolderIcon {
  background-image: var(--jp-icon-new-folder);
}

.jp-NotTrustedIcon {
  background-image: var(--jp-icon-not-trusted);
}

.jp-NotebookIcon {
  background-image: var(--jp-icon-notebook);
}

.jp-NumberingIcon {
  background-image: var(--jp-icon-numbering);
}

.jp-OfflineBoltIcon {
  background-image: var(--jp-icon-offline-bolt);
}

.jp-PaletteIcon {
  background-image: var(--jp-icon-palette);
}

.jp-PasteIcon {
  background-image: var(--jp-icon-paste);
}

.jp-PdfIcon {
  background-image: var(--jp-icon-pdf);
}

.jp-PythonIcon {
  background-image: var(--jp-icon-python);
}

.jp-RKernelIcon {
  background-image: var(--jp-icon-r-kernel);
}

.jp-ReactIcon {
  background-image: var(--jp-icon-react);
}

.jp-RedoIcon {
  background-image: var(--jp-icon-redo);
}

.jp-RefreshIcon {
  background-image: var(--jp-icon-refresh);
}

.jp-RegexIcon {
  background-image: var(--jp-icon-regex);
}

.jp-RunIcon {
  background-image: var(--jp-icon-run);
}

.jp-RunningIcon {
  background-image: var(--jp-icon-running);
}

.jp-SaveIcon {
  background-image: var(--jp-icon-save);
}

.jp-SearchIcon {
  background-image: var(--jp-icon-search);
}

.jp-SettingsIcon {
  background-image: var(--jp-icon-settings);
}

.jp-ShareIcon {
  background-image: var(--jp-icon-share);
}

.jp-SpreadsheetIcon {
  background-image: var(--jp-icon-spreadsheet);
}

.jp-StopIcon {
  background-image: var(--jp-icon-stop);
}

.jp-TabIcon {
  background-image: var(--jp-icon-tab);
}

.jp-TableRowsIcon {
  background-image: var(--jp-icon-table-rows);
}

.jp-TagIcon {
  background-image: var(--jp-icon-tag);
}

.jp-TerminalIcon {
  background-image: var(--jp-icon-terminal);
}

.jp-TextEditorIcon {
  background-image: var(--jp-icon-text-editor);
}

.jp-TocIcon {
  background-image: var(--jp-icon-toc);
}

.jp-TreeViewIcon {
  background-image: var(--jp-icon-tree-view);
}

.jp-TrustedIcon {
  background-image: var(--jp-icon-trusted);
}

.jp-UndoIcon {
  background-image: var(--jp-icon-undo);
}

.jp-UserIcon {
  background-image: var(--jp-icon-user);
}

.jp-UsersIcon {
  background-image: var(--jp-icon-users);
}

.jp-VegaIcon {
  background-image: var(--jp-icon-vega);
}

.jp-WordIcon {
  background-image: var(--jp-icon-word);
}

.jp-YamlIcon {
  background-image: var(--jp-icon-yaml);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * (DEPRECATED) Support for consuming icons as CSS background images
 */

.jp-Icon,
.jp-MaterialIcon {
  background-position: center;
  background-repeat: no-repeat;
  background-size: 16px;
  min-width: 16px;
  min-height: 16px;
}

.jp-Icon-cover {
  background-position: center;
  background-repeat: no-repeat;
  background-size: cover;
}

/**
 * (DEPRECATED) Support for specific CSS icon sizes
 */

.jp-Icon-16 {
  background-size: 16px;
  min-width: 16px;
  min-height: 16px;
}

.jp-Icon-18 {
  background-size: 18px;
  min-width: 18px;
  min-height: 18px;
}

.jp-Icon-20 {
  background-size: 20px;
  min-width: 20px;
  min-height: 20px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.lm-TabBar .lm-TabBar-addButton {
  align-items: center;
  display: flex;
  padding: 4px;
  padding-bottom: 5px;
  margin-right: 1px;
  background-color: var(--jp-layout-color2);
}

.lm-TabBar .lm-TabBar-addButton:hover {
  background-color: var(--jp-layout-color1);
}

.lm-DockPanel-tabBar .lm-TabBar-tab {
  width: var(--jp-private-horizontal-tab-width);
}

.lm-DockPanel-tabBar .lm-TabBar-content {
  flex: unset;
}

.lm-DockPanel-tabBar[data-orientation='horizontal'] {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * Support for icons as inline SVG HTMLElements
 */

/* recolor the primary elements of an icon */
.jp-icon0[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon1[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon2[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon3[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon4[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon0[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon1[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon2[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon3[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon4[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/* recolor the accent elements of an icon */
.jp-icon-accent0[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-accent1[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-accent2[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-accent3[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-accent4[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-accent0[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-accent1[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-accent2[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-accent3[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-accent4[stroke] {
  stroke: var(--jp-layout-color4);
}

/* set the color of an icon to transparent */
.jp-icon-none[fill] {
  fill: none;
}

.jp-icon-none[stroke] {
  stroke: none;
}

/* brand icon colors. Same for light and dark */
.jp-icon-brand0[fill] {
  fill: var(--jp-brand-color0);
}

.jp-icon-brand1[fill] {
  fill: var(--jp-brand-color1);
}

.jp-icon-brand2[fill] {
  fill: var(--jp-brand-color2);
}

.jp-icon-brand3[fill] {
  fill: var(--jp-brand-color3);
}

.jp-icon-brand4[fill] {
  fill: var(--jp-brand-color4);
}

.jp-icon-brand0[stroke] {
  stroke: var(--jp-brand-color0);
}

.jp-icon-brand1[stroke] {
  stroke: var(--jp-brand-color1);
}

.jp-icon-brand2[stroke] {
  stroke: var(--jp-brand-color2);
}

.jp-icon-brand3[stroke] {
  stroke: var(--jp-brand-color3);
}

.jp-icon-brand4[stroke] {
  stroke: var(--jp-brand-color4);
}

/* warn icon colors. Same for light and dark */
.jp-icon-warn0[fill] {
  fill: var(--jp-warn-color0);
}

.jp-icon-warn1[fill] {
  fill: var(--jp-warn-color1);
}

.jp-icon-warn2[fill] {
  fill: var(--jp-warn-color2);
}

.jp-icon-warn3[fill] {
  fill: var(--jp-warn-color3);
}

.jp-icon-warn0[stroke] {
  stroke: var(--jp-warn-color0);
}

.jp-icon-warn1[stroke] {
  stroke: var(--jp-warn-color1);
}

.jp-icon-warn2[stroke] {
  stroke: var(--jp-warn-color2);
}

.jp-icon-warn3[stroke] {
  stroke: var(--jp-warn-color3);
}

/* icon colors that contrast well with each other and most backgrounds */
.jp-icon-contrast0[fill] {
  fill: var(--jp-icon-contrast-color0);
}

.jp-icon-contrast1[fill] {
  fill: var(--jp-icon-contrast-color1);
}

.jp-icon-contrast2[fill] {
  fill: var(--jp-icon-contrast-color2);
}

.jp-icon-contrast3[fill] {
  fill: var(--jp-icon-contrast-color3);
}

.jp-icon-contrast0[stroke] {
  stroke: var(--jp-icon-contrast-color0);
}

.jp-icon-contrast1[stroke] {
  stroke: var(--jp-icon-contrast-color1);
}

.jp-icon-contrast2[stroke] {
  stroke: var(--jp-icon-contrast-color2);
}

.jp-icon-contrast3[stroke] {
  stroke: var(--jp-icon-contrast-color3);
}

.jp-icon-dot[fill] {
  fill: var(--jp-warn-color0);
}

.jp-jupyter-icon-color[fill] {
  fill: var(--jp-jupyter-icon-color, var(--jp-warn-color0));
}

.jp-notebook-icon-color[fill] {
  fill: var(--jp-notebook-icon-color, var(--jp-warn-color0));
}

.jp-json-icon-color[fill] {
  fill: var(--jp-json-icon-color, var(--jp-warn-color1));
}

.jp-console-icon-color[fill] {
  fill: var(--jp-console-icon-color, white);
}

.jp-console-icon-background-color[fill] {
  fill: var(--jp-console-icon-background-color, var(--jp-brand-color1));
}

.jp-terminal-icon-color[fill] {
  fill: var(--jp-terminal-icon-color, var(--jp-layout-color2));
}

.jp-terminal-icon-background-color[fill] {
  fill: var(
    --jp-terminal-icon-background-color,
    var(--jp-inverse-layout-color2)
  );
}

.jp-text-editor-icon-color[fill] {
  fill: var(--jp-text-editor-icon-color, var(--jp-inverse-layout-color3));
}

.jp-inspector-icon-color[fill] {
  fill: var(--jp-inspector-icon-color, var(--jp-inverse-layout-color3));
}

/* CSS for icons in selected filebrowser listing items */
.jp-DirListing-item.jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}

.jp-DirListing-item.jp-mod-selected .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}

/* stylelint-disable selector-max-class, selector-max-compound-selectors */

/**
* TODO: come up with non css-hack solution for showing the busy icon on top
*  of the close icon
* CSS for complex behavior of close icon of tabs in the main area tabbar
*/
.lm-DockPanel-tabBar
  .lm-TabBar-tab.lm-mod-closable.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon3[fill] {
  fill: none;
}

.lm-DockPanel-tabBar
  .lm-TabBar-tab.lm-mod-closable.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon-busy[fill] {
  fill: var(--jp-inverse-layout-color3);
}

/* stylelint-enable selector-max-class, selector-max-compound-selectors */

/* CSS for icons in status bar */
#jp-main-statusbar .jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}

#jp-main-statusbar .jp-mod-selected .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}

/* special handling for splash icon CSS. While the theme CSS reloads during
   splash, the splash icon can loose theming. To prevent that, we set a
   default for its color variable */
:root {
  --jp-warn-color0: var(--md-orange-700);
}

/* not sure what to do with this one, used in filebrowser listing */
.jp-DragIcon {
  margin-right: 4px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * Support for alt colors for icons as inline SVG HTMLElements
 */

/* alt recolor the primary elements of an icon */
.jp-icon-alt .jp-icon0[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-alt .jp-icon1[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-alt .jp-icon2[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-alt .jp-icon3[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-alt .jp-icon4[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-alt .jp-icon0[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-alt .jp-icon1[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-alt .jp-icon2[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-alt .jp-icon3[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-alt .jp-icon4[stroke] {
  stroke: var(--jp-layout-color4);
}

/* alt recolor the accent elements of an icon */
.jp-icon-alt .jp-icon-accent0[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon-alt .jp-icon-accent1[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon-alt .jp-icon-accent2[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon-alt .jp-icon-accent3[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon-alt .jp-icon-accent4[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-alt .jp-icon-accent0[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon-alt .jp-icon-accent1[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon-alt .jp-icon-accent2[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon-alt .jp-icon-accent3[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon-alt .jp-icon-accent4[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-icon-hoverShow:not(:hover) .jp-icon-hoverShow-content {
  display: none !important;
}

/**
 * Support for hover colors for icons as inline SVG HTMLElements
 */

/**
 * regular colors
 */

/* recolor the primary elements of an icon */
.jp-icon-hover :hover .jp-icon0-hover[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon-hover :hover .jp-icon1-hover[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon-hover :hover .jp-icon2-hover[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon-hover :hover .jp-icon3-hover[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon-hover :hover .jp-icon4-hover[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-hover :hover .jp-icon0-hover[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon-hover :hover .jp-icon1-hover[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon-hover :hover .jp-icon2-hover[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon-hover :hover .jp-icon3-hover[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon-hover :hover .jp-icon4-hover[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/* recolor the accent elements of an icon */
.jp-icon-hover :hover .jp-icon-accent0-hover[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-hover :hover .jp-icon-accent1-hover[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-hover :hover .jp-icon-accent2-hover[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-hover :hover .jp-icon-accent3-hover[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-hover :hover .jp-icon-accent4-hover[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-hover :hover .jp-icon-accent0-hover[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-hover :hover .jp-icon-accent1-hover[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-hover :hover .jp-icon-accent2-hover[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-hover :hover .jp-icon-accent3-hover[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-hover :hover .jp-icon-accent4-hover[stroke] {
  stroke: var(--jp-layout-color4);
}

/* set the color of an icon to transparent */
.jp-icon-hover :hover .jp-icon-none-hover[fill] {
  fill: none;
}

.jp-icon-hover :hover .jp-icon-none-hover[stroke] {
  stroke: none;
}

/**
 * inverse colors
 */

/* inverse recolor the primary elements of an icon */
.jp-icon-hover.jp-icon-alt :hover .jp-icon0-hover[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon1-hover[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon2-hover[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon3-hover[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon4-hover[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon0-hover[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon1-hover[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon2-hover[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon3-hover[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon4-hover[stroke] {
  stroke: var(--jp-layout-color4);
}

/* inverse recolor the accent elements of an icon */
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent0-hover[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent1-hover[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent2-hover[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent3-hover[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent4-hover[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent0-hover[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent1-hover[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent2-hover[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent3-hover[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent4-hover[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-IFrame {
  width: 100%;
  height: 100%;
}

.jp-IFrame > iframe {
  border: none;
}

/*
When drag events occur, `lm-mod-override-cursor` is added to the body.
Because iframes steal all cursor events, the following two rules are necessary
to suppress pointer events while resize drags are occurring. There may be a
better solution to this problem.
*/
body.lm-mod-override-cursor .jp-IFrame {
  position: relative;
}

body.lm-mod-override-cursor .jp-IFrame::before {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-HoverBox {
  position: fixed;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-FormGroup-content fieldset {
  border: none;
  padding: 0;
  min-width: 0;
  width: 100%;
}

/* stylelint-disable selector-max-type */

.jp-FormGroup-content fieldset .jp-inputFieldWrapper input,
.jp-FormGroup-content fieldset .jp-inputFieldWrapper select,
.jp-FormGroup-content fieldset .jp-inputFieldWrapper textarea {
  font-size: var(--jp-content-font-size2);
  border-color: var(--jp-input-border-color);
  border-style: solid;
  border-radius: var(--jp-border-radius);
  border-width: 1px;
  padding: 6px 8px;
  background: none;
  color: var(--jp-ui-font-color0);
  height: inherit;
}

.jp-FormGroup-content fieldset input[type='checkbox'] {
  position: relative;
  top: 2px;
  margin-left: 0;
}

.jp-FormGroup-content button.jp-mod-styled {
  cursor: pointer;
}

.jp-FormGroup-content .checkbox label {
  cursor: pointer;
  font-size: var(--jp-content-font-size1);
}

.jp-FormGroup-content .jp-root > fieldset > legend {
  display: none;
}

.jp-FormGroup-content .jp-root > fieldset > p {
  display: none;
}

/** copy of `input.jp-mod-styled:focus` style */
.jp-FormGroup-content fieldset input:focus,
.jp-FormGroup-content fieldset select:focus {
  -moz-outline-radius: unset;
  outline: var(--jp-border-width) solid var(--md-blue-500);
  outline-offset: -1px;
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-FormGroup-content fieldset input:hover:not(:focus),
.jp-FormGroup-content fieldset select:hover:not(:focus) {
  background-color: var(--jp-border-color2);
}

/* stylelint-enable selector-max-type */

.jp-FormGroup-content .checkbox .field-description {
  /* Disable default description field for checkbox:
   because other widgets do not have description fields,
   we add descriptions to each widget on the field level.
  */
  display: none;
}

.jp-FormGroup-content #root__description {
  display: none;
}

.jp-FormGroup-content .jp-modifiedIndicator {
  width: 5px;
  background-color: var(--jp-brand-color2);
  margin-top: 0;
  margin-left: calc(var(--jp-private-settingeditor-modifier-indent) * -1);
  flex-shrink: 0;
}

.jp-FormGroup-content .jp-modifiedIndicator.jp-errorIndicator {
  background-color: var(--jp-error-color0);
  margin-right: 0.5em;
}

/* RJSF ARRAY style */

.jp-arrayFieldWrapper legend {
  font-size: var(--jp-content-font-size2);
  color: var(--jp-ui-font-color0);
  flex-basis: 100%;
  padding: 4px 0;
  font-weight: var(--jp-content-heading-font-weight);
  border-bottom: 1px solid var(--jp-border-color2);
}

.jp-arrayFieldWrapper .field-description {
  padding: 4px 0;
  white-space: pre-wrap;
}

.jp-arrayFieldWrapper .array-item {
  width: 100%;
  border: 1px solid var(--jp-border-color2);
  border-radius: 4px;
  margin: 4px;
}

.jp-ArrayOperations {
  display: flex;
  margin-left: 8px;
}

.jp-ArrayOperationsButton {
  margin: 2px;
}

.jp-ArrayOperationsButton .jp-icon3[fill] {
  fill: var(--jp-ui-font-color0);
}

button.jp-ArrayOperationsButton.jp-mod-styled:disabled {
  cursor: not-allowed;
  opacity: 0.5;
}

/* RJSF form validation error */

.jp-FormGroup-content .validationErrors {
  color: var(--jp-error-color0);
}

/* Hide panel level error as duplicated the field level error */
.jp-FormGroup-content .panel.errors {
  display: none;
}

/* RJSF normal content (settings-editor) */

.jp-FormGroup-contentNormal {
  display: flex;
  align-items: center;
  flex-wrap: wrap;
}

.jp-FormGroup-contentNormal .jp-FormGroup-contentItem {
  margin-left: 7px;
  color: var(--jp-ui-font-color0);
}

.jp-FormGroup-contentNormal .jp-FormGroup-description {
  flex-basis: 100%;
  padding: 4px 7px;
}

.jp-FormGroup-contentNormal .jp-FormGroup-default {
  flex-basis: 100%;
  padding: 4px 7px;
}

.jp-FormGroup-contentNormal .jp-FormGroup-fieldLabel {
  font-size: var(--jp-content-font-size1);
  font-weight: normal;
  min-width: 120px;
}

.jp-FormGroup-contentNormal fieldset:not(:first-child) {
  margin-left: 7px;
}

.jp-FormGroup-contentNormal .field-array-of-string .array-item {
  /* Display `jp-ArrayOperations` buttons side-by-side with content except
    for small screens where flex-wrap will place them one below the other.
  */
  display: flex;
  align-items: center;
  flex-wrap: wrap;
}

.jp-FormGroup-contentNormal .jp-objectFieldWrapper .form-group {
  padding: 2px 8px 2px var(--jp-private-settingeditor-modifier-indent);
  margin-top: 2px;
}

/* RJSF compact content (metadata-form) */

.jp-FormGroup-content.jp-FormGroup-contentCompact {
  width: 100%;
}

.jp-FormGroup-contentCompact .form-group {
  display: flex;
  padding: 0.5em 0.2em 0.5em 0;
}

.jp-FormGroup-contentCompact
  .jp-FormGroup-compactTitle
  .jp-FormGroup-description {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color2);
}

.jp-FormGroup-contentCompact .jp-FormGroup-fieldLabel {
  padding-bottom: 0.3em;
}

.jp-FormGroup-contentCompact .jp-inputFieldWrapper .form-control {
  width: 100%;
  box-sizing: border-box;
}

.jp-FormGroup-contentCompact .jp-arrayFieldWrapper .jp-FormGroup-compactTitle {
  padding-bottom: 7px;
}

.jp-FormGroup-contentCompact
  .jp-objectFieldWrapper
  .jp-objectFieldWrapper
  .form-group {
  padding: 2px 8px 2px var(--jp-private-settingeditor-modifier-indent);
  margin-top: 2px;
}

.jp-FormGroup-contentCompact ul.error-detail {
  margin-block-start: 0.5em;
  margin-block-end: 0.5em;
  padding-inline-start: 1em;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-SidePanel {
  display: flex;
  flex-direction: column;
  min-width: var(--jp-sidebar-min-width);
  overflow-y: auto;
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);
  font-size: var(--jp-ui-font-size1);
}

.jp-SidePanel-header {
  flex: 0 0 auto;
  display: flex;
  border-bottom: var(--jp-border-width) solid var(--jp-border-color2);
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  letter-spacing: 1px;
  margin: 0;
  padding: 2px;
  text-transform: uppercase;
}

.jp-SidePanel-toolbar {
  flex: 0 0 auto;
}

.jp-SidePanel-content {
  flex: 1 1 auto;
}

.jp-SidePanel-toolbar,
.jp-AccordionPanel-toolbar {
  height: var(--jp-private-toolbar-height);
}

.jp-SidePanel-toolbar.jp-Toolbar-micro {
  display: none;
}

.lm-AccordionPanel .jp-AccordionPanel-title {
  box-sizing: border-box;
  line-height: 25px;
  margin: 0;
  display: flex;
  align-items: center;
  background: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  font-size: var(--jp-ui-font-size0);
}

.jp-AccordionPanel-title {
  cursor: pointer;
  user-select: none;
  -moz-user-select: none;
  -webkit-user-select: none;
  text-transform: uppercase;
}

.lm-AccordionPanel[data-orientation='horizontal'] > .jp-AccordionPanel-title {
  /* Title is rotated for horizontal accordion panel using CSS */
  display: block;
  transform-origin: top left;
  transform: rotate(-90deg) translate(-100%);
}

.jp-AccordionPanel-title .lm-AccordionPanel-titleLabel {
  user-select: none;
  text-overflow: ellipsis;
  white-space: nowrap;
  overflow: hidden;
}

.jp-AccordionPanel-title .lm-AccordionPanel-titleCollapser {
  transform: rotate(-90deg);
  margin: auto 0;
  height: 16px;
}

.jp-AccordionPanel-title.lm-mod-expanded .lm-AccordionPanel-titleCollapser {
  transform: rotate(0deg);
}

.lm-AccordionPanel .jp-AccordionPanel-toolbar {
  background: none;
  box-shadow: none;
  border: none;
  margin-left: auto;
}

.lm-AccordionPanel .lm-SplitPanel-handle:hover {
  background: var(--jp-layout-color3);
}

.jp-text-truncated {
  overflow: hidden;
  text-overflow: ellipsis;
  white-space: nowrap;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Spinner {
  position: absolute;
  display: flex;
  justify-content: center;
  align-items: center;
  z-index: 10;
  left: 0;
  top: 0;
  width: 100%;
  height: 100%;
  background: var(--jp-layout-color0);
  outline: none;
}

.jp-SpinnerContent {
  font-size: 10px;
  margin: 50px auto;
  text-indent: -9999em;
  width: 3em;
  height: 3em;
  border-radius: 50%;
  background: var(--jp-brand-color3);
  background: linear-gradient(
    to right,
    #f37626 10%,
    rgba(255, 255, 255, 0) 42%
  );
  position: relative;
  animation: load3 1s infinite linear, fadeIn 1s;
}

.jp-SpinnerContent::before {
  width: 50%;
  height: 50%;
  background: #f37626;
  border-radius: 100% 0 0;
  position: absolute;
  top: 0;
  left: 0;
  content: '';
}

.jp-SpinnerContent::after {
  background: var(--jp-layout-color0);
  width: 75%;
  height: 75%;
  border-radius: 50%;
  content: '';
  margin: auto;
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  right: 0;
}

@keyframes fadeIn {
  0% {
    opacity: 0;
  }

  100% {
    opacity: 1;
  }
}

@keyframes load3 {
  0% {
    transform: rotate(0deg);
  }

  100% {
    transform: rotate(360deg);
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

button.jp-mod-styled {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  border: none;
  box-sizing: border-box;
  text-align: center;
  line-height: 32px;
  height: 32px;
  padding: 0 12px;
  letter-spacing: 0.8px;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

input.jp-mod-styled {
  background: var(--jp-input-background);
  height: 28px;
  box-sizing: border-box;
  border: var(--jp-border-width) solid var(--jp-border-color1);
  padding-left: 7px;
  padding-right: 7px;
  font-size: var(--jp-ui-font-size2);
  color: var(--jp-ui-font-color0);
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

input[type='checkbox'].jp-mod-styled {
  appearance: checkbox;
  -webkit-appearance: checkbox;
  -moz-appearance: checkbox;
  height: auto;
}

input.jp-mod-styled:focus {
  border: var(--jp-border-width) solid var(--md-blue-500);
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-select-wrapper {
  display: flex;
  position: relative;
  flex-direction: column;
  padding: 1px;
  background-color: var(--jp-layout-color1);
  box-sizing: border-box;
  margin-bottom: 12px;
}

.jp-select-wrapper:not(.multiple) {
  height: 28px;
}

.jp-select-wrapper.jp-mod-focused select.jp-mod-styled {
  border: var(--jp-border-width) solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
  background-color: var(--jp-input-active-background);
}

select.jp-mod-styled:hover {
  cursor: pointer;
  color: var(--jp-ui-font-color0);
  background-color: var(--jp-input-hover-background);
  box-shadow: inset 0 0 1px rgba(0, 0, 0, 0.5);
}

select.jp-mod-styled {
  flex: 1 1 auto;
  width: 100%;
  font-size: var(--jp-ui-font-size2);
  background: var(--jp-input-background);
  color: var(--jp-ui-font-color0);
  padding: 0 25px 0 8px;
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  border-radius: 0;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

select.jp-mod-styled:not([multiple]) {
  height: 32px;
}

select.jp-mod-styled[multiple] {
  max-height: 200px;
  overflow-y: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-switch {
  display: flex;
  align-items: center;
  padding-left: 4px;
  padding-right: 4px;
  font-size: var(--jp-ui-font-size1);
  background-color: transparent;
  color: var(--jp-ui-font-color1);
  border: none;
  height: 20px;
}

.jp-switch:hover {
  background-color: var(--jp-layout-color2);
}

.jp-switch-label {
  margin-right: 5px;
  font-family: var(--jp-ui-font-family);
}

.jp-switch-track {
  cursor: pointer;
  background-color: var(--jp-switch-color, var(--jp-border-color1));
  -webkit-transition: 0.4s;
  transition: 0.4s;
  border-radius: 34px;
  height: 16px;
  width: 35px;
  position: relative;
}

.jp-switch-track::before {
  content: '';
  position: absolute;
  height: 10px;
  width: 10px;
  margin: 3px;
  left: 0;
  background-color: var(--jp-ui-inverse-font-color1);
  -webkit-transition: 0.4s;
  transition: 0.4s;
  border-radius: 50%;
}

.jp-switch[aria-checked='true'] .jp-switch-track {
  background-color: var(--jp-switch-true-position-color, var(--jp-warn-color0));
}

.jp-switch[aria-checked='true'] .jp-switch-track::before {
  /* track width (35) - margins (3 + 3) - thumb width (10) */
  left: 19px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

:root {
  --jp-private-toolbar-height: calc(
    28px + var(--jp-border-width)
  ); /* leave 28px for content */
}

.jp-Toolbar {
  color: var(--jp-ui-font-color1);
  flex: 0 0 auto;
  display: flex;
  flex-direction: row;
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  background: var(--jp-toolbar-background);
  min-height: var(--jp-toolbar-micro-height);
  padding: 2px;
  z-index: 8;
  overflow-x: hidden;
}

/* Toolbar items */

.jp-Toolbar > .jp-Toolbar-item.jp-Toolbar-spacer {
  flex-grow: 1;
  flex-shrink: 1;
}

.jp-Toolbar-item.jp-Toolbar-kernelStatus {
  display: inline-block;
  width: 32px;
  background-repeat: no-repeat;
  background-position: center;
  background-size: 16px;
}

.jp-Toolbar > .jp-Toolbar-item {
  flex: 0 0 auto;
  display: flex;
  padding-left: 1px;
  padding-right: 1px;
  font-size: var(--jp-ui-font-size1);
  line-height: var(--jp-private-toolbar-height);
  height: 100%;
}

/* Toolbar buttons */

/* This is the div we use to wrap the react component into a Widget */
div.jp-ToolbarButton {
  color: transparent;
  border: none;
  box-sizing: border-box;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
  padding: 0;
  margin: 0;
}

button.jp-ToolbarButtonComponent {
  background: var(--jp-layout-color1);
  border: none;
  box-sizing: border-box;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
  padding: 0 6px;
  margin: 0;
  height: 24px;
  border-radius: var(--jp-border-radius);
  display: flex;
  align-items: center;
  text-align: center;
  font-size: 14px;
  min-width: unset;
  min-height: unset;
}

button.jp-ToolbarButtonComponent:disabled {
  opacity: 0.4;
}

button.jp-ToolbarButtonComponent > span {
  padding: 0;
  flex: 0 0 auto;
}

button.jp-ToolbarButtonComponent .jp-ToolbarButtonComponent-label {
  font-size: var(--jp-ui-font-size1);
  line-height: 100%;
  padding-left: 2px;
  color: var(--jp-ui-font-color1);
  font-family: var(--jp-ui-font-family);
}

#jp-main-dock-panel[data-mode='single-document']
  .jp-MainAreaWidget
  > .jp-Toolbar.jp-Toolbar-micro {
  padding: 0;
  min-height: 0;
}

#jp-main-dock-panel[data-mode='single-document']
  .jp-MainAreaWidget
  > .jp-Toolbar {
  border: none;
  box-shadow: none;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-WindowedPanel-outer {
  position: relative;
  overflow-y: auto;
}

.jp-WindowedPanel-inner {
  position: relative;
}

.jp-WindowedPanel-window {
  position: absolute;
  left: 0;
  right: 0;
  overflow: visible;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* Sibling imports */

body {
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
}

/* Disable native link decoration styles everywhere outside of dialog boxes */
a {
  text-decoration: unset;
  color: unset;
}

a:hover {
  text-decoration: unset;
  color: unset;
}

/* Accessibility for links inside dialog box text */
.jp-Dialog-content a {
  text-decoration: revert;
  color: var(--jp-content-link-color);
}

.jp-Dialog-content a:hover {
  text-decoration: revert;
}

/* Styles for ui-components */
.jp-Button {
  color: var(--jp-ui-font-color2);
  border-radius: var(--jp-border-radius);
  padding: 0 12px;
  font-size: var(--jp-ui-font-size1);

  /* Copy from blueprint 3 */
  display: inline-flex;
  flex-direction: row;
  border: none;
  cursor: pointer;
  align-items: center;
  justify-content: center;
  text-align: left;
  vertical-align: middle;
  min-height: 30px;
  min-width: 30px;
}

.jp-Button:disabled {
  cursor: not-allowed;
}

.jp-Button:empty {
  padding: 0 !important;
}

.jp-Button.jp-mod-small {
  min-height: 24px;
  min-width: 24px;
  font-size: 12px;
  padding: 0 7px;
}

/* Use our own theme for hover styles */
.jp-Button.jp-mod-minimal:hover {
  background-color: var(--jp-layout-color2);
}

.jp-Button.jp-mod-minimal {
  background: none;
}

.jp-InputGroup {
  display: block;
  position: relative;
}

.jp-InputGroup input {
  box-sizing: border-box;
  border: none;
  border-radius: 0;
  background-color: transparent;
  color: var(--jp-ui-font-color0);
  box-shadow: inset 0 0 0 var(--jp-border-width) var(--jp-input-border-color);
  padding-bottom: 0;
  padding-top: 0;
  padding-left: 10px;
  padding-right: 28px;
  position: relative;
  width: 100%;
  -webkit-appearance: none;
  -moz-appearance: none;
  appearance: none;
  font-size: 14px;
  font-weight: 400;
  height: 30px;
  line-height: 30px;
  outline: none;
  vertical-align: middle;
}

.jp-InputGroup input:focus {
  box-shadow: inset 0 0 0 var(--jp-border-width)
      var(--jp-input-active-box-shadow-color),
    inset 0 0 0 3px var(--jp-input-active-box-shadow-color);
}

.jp-InputGroup input:disabled {
  cursor: not-allowed;
  resize: block;
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color2);
}

.jp-InputGroup input:disabled ~ span {
  cursor: not-allowed;
  color: var(--jp-ui-font-color2);
}

.jp-InputGroup input::placeholder,
input::placeholder {
  color: var(--jp-ui-font-color2);
}

.jp-InputGroupAction {
  position: absolute;
  bottom: 1px;
  right: 0;
  padding: 6px;
}

.jp-HTMLSelect.jp-DefaultStyle select {
  background-color: initial;
  border: none;
  border-radius: 0;
  box-shadow: none;
  color: var(--jp-ui-font-color0);
  display: block;
  font-size: var(--jp-ui-font-size1);
  font-family: var(--jp-ui-font-family);
  height: 24px;
  line-height: 14px;
  padding: 0 25px 0 10px;
  text-align: left;
  -moz-appearance: none;
  -webkit-appearance: none;
}

.jp-HTMLSelect.jp-DefaultStyle select:disabled {
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color2);
  cursor: not-allowed;
  resize: block;
}

.jp-HTMLSelect.jp-DefaultStyle select:disabled ~ span {
  cursor: not-allowed;
}

/* Use our own theme for hover and option styles */
/* stylelint-disable-next-line selector-max-type */
.jp-HTMLSelect.jp-DefaultStyle select:hover,
.jp-HTMLSelect.jp-DefaultStyle select > option {
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color0);
}

select {
  box-sizing: border-box;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-StatusBar-Widget {
  display: flex;
  align-items: center;
  background: var(--jp-layout-color2);
  min-height: var(--jp-statusbar-height);
  justify-content: space-between;
  padding: 0 10px;
}

.jp-StatusBar-Left {
  display: flex;
  align-items: center;
  flex-direction: row;
}

.jp-StatusBar-Middle {
  display: flex;
  align-items: center;
}

.jp-StatusBar-Right {
  display: flex;
  align-items: center;
  flex-direction: row-reverse;
}

.jp-StatusBar-Item {
  max-height: var(--jp-statusbar-height);
  margin: 0 2px;
  height: var(--jp-statusbar-height);
  white-space: nowrap;
  text-overflow: ellipsis;
  color: var(--jp-ui-font-color1);
  padding: 0 6px;
}

.jp-mod-highlighted:hover {
  background-color: var(--jp-layout-color3);
}

.jp-mod-clicked {
  background-color: var(--jp-brand-color1);
}

.jp-mod-clicked:hover {
  background-color: var(--jp-brand-color0);
}

.jp-mod-clicked .jp-StatusBar-TextItem {
  color: var(--jp-ui-inverse-font-color1);
}

.jp-StatusBar-HoverItem {
  box-shadow: '0px 4px 4px rgba(0, 0, 0, 0.25)';
}

.jp-StatusBar-TextItem {
  font-size: var(--jp-ui-font-size1);
  font-family: var(--jp-ui-font-family);
  line-height: 24px;
  color: var(--jp-ui-font-color1);
}

.jp-StatusBar-GroupItem {
  display: flex;
  align-items: center;
  flex-direction: row;
}

.jp-Statusbar-ProgressCircle svg {
  display: block;
  margin: 0 auto;
  width: 16px;
  height: 24px;
  align-self: normal;
}

.jp-Statusbar-ProgressCircle path {
  fill: var(--jp-inverse-layout-color3);
}

.jp-Statusbar-ProgressBar-progress-bar {
  height: 10px;
  width: 100px;
  border: solid 0.25px var(--jp-brand-color2);
  border-radius: 3px;
  overflow: hidden;
  align-self: center;
}

.jp-Statusbar-ProgressBar-progress-bar > div {
  background-color: var(--jp-brand-color2);
  background-image: linear-gradient(
    -45deg,
    rgba(255, 255, 255, 0.2) 25%,
    transparent 25%,
    transparent 50%,
    rgba(255, 255, 255, 0.2) 50%,
    rgba(255, 255, 255, 0.2) 75%,
    transparent 75%,
    transparent
  );
  background-size: 40px 40px;
  float: left;
  width: 0%;
  height: 100%;
  font-size: 12px;
  line-height: 14px;
  color: #fff;
  text-align: center;
  animation: jp-Statusbar-ExecutionTime-progress-bar 2s linear infinite;
}

.jp-Statusbar-ProgressBar-progress-bar p {
  color: var(--jp-ui-font-color1);
  font-family: var(--jp-ui-font-family);
  font-size: var(--jp-ui-font-size1);
  line-height: 10px;
  width: 100px;
}

@keyframes jp-Statusbar-ExecutionTime-progress-bar {
  0% {
    background-position: 0 0;
  }

  100% {
    background-position: 40px 40px;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-commandpalette-search-height: 28px;
}

/*-----------------------------------------------------------------------------
| Overall styles
|----------------------------------------------------------------------------*/

.lm-CommandPalette {
  padding-bottom: 0;
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);

  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
}

/*-----------------------------------------------------------------------------
| Modal variant
|----------------------------------------------------------------------------*/

.jp-ModalCommandPalette {
  position: absolute;
  z-index: 10000;
  top: 38px;
  left: 30%;
  margin: 0;
  padding: 4px;
  width: 40%;
  box-shadow: var(--jp-elevation-z4);
  border-radius: 4px;
  background: var(--jp-layout-color0);
}

.jp-ModalCommandPalette .lm-CommandPalette {
  max-height: 40vh;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-close-icon::after {
  display: none;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-CommandPalette-header {
  display: none;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-CommandPalette-item {
  margin-left: 4px;
  margin-right: 4px;
}

.jp-ModalCommandPalette
  .lm-CommandPalette
  .lm-CommandPalette-item.lm-mod-disabled {
  display: none;
}

/*-----------------------------------------------------------------------------
| Search
|----------------------------------------------------------------------------*/

.lm-CommandPalette-search {
  padding: 4px;
  background-color: var(--jp-layout-color1);
  z-index: 2;
}

.lm-CommandPalette-wrapper {
  overflow: overlay;
  padding: 0 9px;
  background-color: var(--jp-input-active-background);
  height: 30px;
  box-shadow: inset 0 0 0 var(--jp-border-width) var(--jp-input-border-color);
}

.lm-CommandPalette.lm-mod-focused .lm-CommandPalette-wrapper {
  box-shadow: inset 0 0 0 1px var(--jp-input-active-box-shadow-color),
    inset 0 0 0 3px var(--jp-input-active-box-shadow-color);
}

.jp-SearchIconGroup {
  color: white;
  background-color: var(--jp-brand-color1);
  position: absolute;
  top: 4px;
  right: 4px;
  padding: 5px 5px 1px;
}

.jp-SearchIconGroup svg {
  height: 20px;
  width: 20px;
}

.jp-SearchIconGroup .jp-icon3[fill] {
  fill: var(--jp-layout-color0);
}

.lm-CommandPalette-input {
  background: transparent;
  width: calc(100% - 18px);
  float: left;
  border: none;
  outline: none;
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  line-height: var(--jp-private-commandpalette-search-height);
}

.lm-CommandPalette-input::-webkit-input-placeholder,
.lm-CommandPalette-input::-moz-placeholder,
.lm-CommandPalette-input:-ms-input-placeholder {
  color: var(--jp-ui-font-color2);
  font-size: var(--jp-ui-font-size1);
}

/*-----------------------------------------------------------------------------
| Results
|----------------------------------------------------------------------------*/

.lm-CommandPalette-header:first-child {
  margin-top: 0;
}

.lm-CommandPalette-header {
  border-bottom: solid var(--jp-border-width) var(--jp-border-color2);
  color: var(--jp-ui-font-color1);
  cursor: pointer;
  display: flex;
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  letter-spacing: 1px;
  margin-top: 8px;
  padding: 8px 0 8px 12px;
  text-transform: uppercase;
}

.lm-CommandPalette-header.lm-mod-active {
  background: var(--jp-layout-color2);
}

.lm-CommandPalette-header > mark {
  background-color: transparent;
  font-weight: bold;
  color: var(--jp-ui-font-color1);
}

.lm-CommandPalette-item {
  padding: 4px 12px 4px 4px;
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  font-weight: 400;
  display: flex;
}

.lm-CommandPalette-item.lm-mod-disabled {
  color: var(--jp-ui-font-color2);
}

.lm-CommandPalette-item.lm-mod-active {
  color: var(--jp-ui-inverse-font-color1);
  background: var(--jp-brand-color1);
}

.lm-CommandPalette-item.lm-mod-active .lm-CommandPalette-itemLabel > mark {
  color: var(--jp-ui-inverse-font-color0);
}

.lm-CommandPalette-item.lm-mod-active .jp-icon-selectable[fill] {
  fill: var(--jp-layout-color0);
}

.lm-CommandPalette-item.lm-mod-active:hover:not(.lm-mod-disabled) {
  color: var(--jp-ui-inverse-font-color1);
  background: var(--jp-brand-color1);
}

.lm-CommandPalette-item:hover:not(.lm-mod-active):not(.lm-mod-disabled) {
  background: var(--jp-layout-color2);
}

.lm-CommandPalette-itemContent {
  overflow: hidden;
}

.lm-CommandPalette-itemLabel > mark {
  color: var(--jp-ui-font-color0);
  background-color: transparent;
  font-weight: bold;
}

.lm-CommandPalette-item.lm-mod-disabled mark {
  color: var(--jp-ui-font-color2);
}

.lm-CommandPalette-item .lm-CommandPalette-itemIcon {
  margin: 0 4px 0 0;
  position: relative;
  width: 16px;
  top: 2px;
  flex: 0 0 auto;
}

.lm-CommandPalette-item.lm-mod-disabled .lm-CommandPalette-itemIcon {
  opacity: 0.6;
}

.lm-CommandPalette-item .lm-CommandPalette-itemShortcut {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemCaption {
  display: none;
}

.lm-CommandPalette-content {
  background-color: var(--jp-layout-color1);
}

.lm-CommandPalette-content:empty::after {
  content: 'No results';
  margin: auto;
  margin-top: 20px;
  width: 100px;
  display: block;
  font-size: var(--jp-ui-font-size2);
  font-family: var(--jp-ui-font-family);
  font-weight: lighter;
}

.lm-CommandPalette-emptyMessage {
  text-align: center;
  margin-top: 24px;
  line-height: 1.32;
  padding: 0 8px;
  color: var(--jp-content-font-color3);
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Dialog {
  position: absolute;
  z-index: 10000;
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  top: 0;
  left: 0;
  margin: 0;
  padding: 0;
  width: 100%;
  height: 100%;
  background: var(--jp-dialog-background);
}

.jp-Dialog-content {
  display: flex;
  flex-direction: column;
  margin-left: auto;
  margin-right: auto;
  background: var(--jp-layout-color1);
  padding: 24px 24px 12px;
  min-width: 300px;
  min-height: 150px;
  max-width: 1000px;
  max-height: 500px;
  box-sizing: border-box;
  box-shadow: var(--jp-elevation-z20);
  word-wrap: break-word;
  border-radius: var(--jp-border-radius);

  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color1);
  resize: both;
}

.jp-Dialog-content.jp-Dialog-content-small {
  max-width: 500px;
}

.jp-Dialog-button {
  overflow: visible;
}

button.jp-Dialog-button:focus {
  outline: 1px solid var(--jp-brand-color1);
  outline-offset: 4px;
  -moz-outline-radius: 0;
}

button.jp-Dialog-button:focus::-moz-focus-inner {
  border: 0;
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-accept:focus,
button.jp-Dialog-button.jp-mod-styled.jp-mod-warn:focus,
button.jp-Dialog-button.jp-mod-styled.jp-mod-reject:focus {
  outline-offset: 4px;
  -moz-outline-radius: 0;
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-accept:focus {
  outline: 1px solid var(--jp-accept-color-normal, var(--jp-brand-color1));
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-warn:focus {
  outline: 1px solid var(--jp-warn-color-normal, var(--jp-error-color1));
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-reject:focus {
  outline: 1px solid var(--jp-reject-color-normal, var(--md-grey-600));
}

button.jp-Dialog-close-button {
  padding: 0;
  height: 100%;
  min-width: unset;
  min-height: unset;
}

.jp-Dialog-header {
  display: flex;
  justify-content: space-between;
  flex: 0 0 auto;
  padding-bottom: 12px;
  font-size: var(--jp-ui-font-size3);
  font-weight: 400;
  color: var(--jp-ui-font-color1);
}

.jp-Dialog-body {
  display: flex;
  flex-direction: column;
  flex: 1 1 auto;
  font-size: var(--jp-ui-font-size1);
  background: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  overflow: auto;
}

.jp-Dialog-footer {
  display: flex;
  flex-direction: row;
  justify-content: flex-end;
  align-items: center;
  flex: 0 0 auto;
  margin-left: -12px;
  margin-right: -12px;
  padding: 12px;
}

.jp-Dialog-checkbox {
  padding-right: 5px;
}

.jp-Dialog-checkbox > input:focus-visible {
  outline: 1px solid var(--jp-input-active-border-color);
  outline-offset: 1px;
}

.jp-Dialog-spacer {
  flex: 1 1 auto;
}

.jp-Dialog-title {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.jp-Dialog-body > .jp-select-wrapper {
  width: 100%;
}

.jp-Dialog-body > button {
  padding: 0 16px;
}

.jp-Dialog-body > label {
  line-height: 1.4;
  color: var(--jp-ui-font-color0);
}

.jp-Dialog-button.jp-mod-styled:not(:last-child) {
  margin-right: 12px;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-Input-Boolean-Dialog {
  flex-direction: row-reverse;
  align-items: end;
  width: 100%;
}

.jp-Input-Boolean-Dialog > label {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-MainAreaWidget > :focus {
  outline: none;
}

.jp-MainAreaWidget .jp-MainAreaWidget-error {
  padding: 6px;
}

.jp-MainAreaWidget .jp-MainAreaWidget-error > pre {
  width: auto;
  padding: 10px;
  background: var(--jp-error-color3);
  border: var(--jp-border-width) solid var(--jp-error-color1);
  border-radius: var(--jp-border-radius);
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  white-space: pre-wrap;
  word-wrap: break-word;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/**
 * google-material-color v1.2.6
 * https://github.com/danlevan/google-material-color
 */
:root {
  --md-red-50: #ffebee;
  --md-red-100: #ffcdd2;
  --md-red-200: #ef9a9a;
  --md-red-300: #e57373;
  --md-red-400: #ef5350;
  --md-red-500: #f44336;
  --md-red-600: #e53935;
  --md-red-700: #d32f2f;
  --md-red-800: #c62828;
  --md-red-900: #b71c1c;
  --md-red-A100: #ff8a80;
  --md-red-A200: #ff5252;
  --md-red-A400: #ff1744;
  --md-red-A700: #d50000;
  --md-pink-50: #fce4ec;
  --md-pink-100: #f8bbd0;
  --md-pink-200: #f48fb1;
  --md-pink-300: #f06292;
  --md-pink-400: #ec407a;
  --md-pink-500: #e91e63;
  --md-pink-600: #d81b60;
  --md-pink-700: #c2185b;
  --md-pink-800: #ad1457;
  --md-pink-900: #880e4f;
  --md-pink-A100: #ff80ab;
  --md-pink-A200: #ff4081;
  --md-pink-A400: #f50057;
  --md-pink-A700: #c51162;
  --md-purple-50: #f3e5f5;
  --md-purple-100: #e1bee7;
  --md-purple-200: #ce93d8;
  --md-purple-300: #ba68c8;
  --md-purple-400: #ab47bc;
  --md-purple-500: #9c27b0;
  --md-purple-600: #8e24aa;
  --md-purple-700: #7b1fa2;
  --md-purple-800: #6a1b9a;
  --md-purple-900: #4a148c;
  --md-purple-A100: #ea80fc;
  --md-purple-A200: #e040fb;
  --md-purple-A400: #d500f9;
  --md-purple-A700: #a0f;
  --md-deep-purple-50: #ede7f6;
  --md-deep-purple-100: #d1c4e9;
  --md-deep-purple-200: #b39ddb;
  --md-deep-purple-300: #9575cd;
  --md-deep-purple-400: #7e57c2;
  --md-deep-purple-500: #673ab7;
  --md-deep-purple-600: #5e35b1;
  --md-deep-purple-700: #512da8;
  --md-deep-purple-800: #4527a0;
  --md-deep-purple-900: #311b92;
  --md-deep-purple-A100: #b388ff;
  --md-deep-purple-A200: #7c4dff;
  --md-deep-purple-A400: #651fff;
  --md-deep-purple-A700: #6200ea;
  --md-indigo-50: #e8eaf6;
  --md-indigo-100: #c5cae9;
  --md-indigo-200: #9fa8da;
  --md-indigo-300: #7986cb;
  --md-indigo-400: #5c6bc0;
  --md-indigo-500: #3f51b5;
  --md-indigo-600: #3949ab;
  --md-indigo-700: #303f9f;
  --md-indigo-800: #283593;
  --md-indigo-900: #1a237e;
  --md-indigo-A100: #8c9eff;
  --md-indigo-A200: #536dfe;
  --md-indigo-A400: #3d5afe;
  --md-indigo-A700: #304ffe;
  --md-blue-50: #e3f2fd;
  --md-blue-100: #bbdefb;
  --md-blue-200: #90caf9;
  --md-blue-300: #64b5f6;
  --md-blue-400: #42a5f5;
  --md-blue-500: #2196f3;
  --md-blue-600: #1e88e5;
  --md-blue-700: #1976d2;
  --md-blue-800: #1565c0;
  --md-blue-900: #0d47a1;
  --md-blue-A100: #82b1ff;
  --md-blue-A200: #448aff;
  --md-blue-A400: #2979ff;
  --md-blue-A700: #2962ff;
  --md-light-blue-50: #e1f5fe;
  --md-light-blue-100: #b3e5fc;
  --md-light-blue-200: #81d4fa;
  --md-light-blue-300: #4fc3f7;
  --md-light-blue-400: #29b6f6;
  --md-light-blue-500: #03a9f4;
  --md-light-blue-600: #039be5;
  --md-light-blue-700: #0288d1;
  --md-light-blue-800: #0277bd;
  --md-light-blue-900: #01579b;
  --md-light-blue-A100: #80d8ff;
  --md-light-blue-A200: #40c4ff;
  --md-light-blue-A400: #00b0ff;
  --md-light-blue-A700: #0091ea;
  --md-cyan-50: #e0f7fa;
  --md-cyan-100: #b2ebf2;
  --md-cyan-200: #80deea;
  --md-cyan-300: #4dd0e1;
  --md-cyan-400: #26c6da;
  --md-cyan-500: #00bcd4;
  --md-cyan-600: #00acc1;
  --md-cyan-700: #0097a7;
  --md-cyan-800: #00838f;
  --md-cyan-900: #006064;
  --md-cyan-A100: #84ffff;
  --md-cyan-A200: #18ffff;
  --md-cyan-A400: #00e5ff;
  --md-cyan-A700: #00b8d4;
  --md-teal-50: #e0f2f1;
  --md-teal-100: #b2dfdb;
  --md-teal-200: #80cbc4;
  --md-teal-300: #4db6ac;
  --md-teal-400: #26a69a;
  --md-teal-500: #009688;
  --md-teal-600: #00897b;
  --md-teal-700: #00796b;
  --md-teal-800: #00695c;
  --md-teal-900: #004d40;
  --md-teal-A100: #a7ffeb;
  --md-teal-A200: #64ffda;
  --md-teal-A400: #1de9b6;
  --md-teal-A700: #00bfa5;
  --md-green-50: #e8f5e9;
  --md-green-100: #c8e6c9;
  --md-green-200: #a5d6a7;
  --md-green-300: #81c784;
  --md-green-400: #66bb6a;
  --md-green-500: #4caf50;
  --md-green-600: #43a047;
  --md-green-700: #388e3c;
  --md-green-800: #2e7d32;
  --md-green-900: #1b5e20;
  --md-green-A100: #b9f6ca;
  --md-green-A200: #69f0ae;
  --md-green-A400: #00e676;
  --md-green-A700: #00c853;
  --md-light-green-50: #f1f8e9;
  --md-light-green-100: #dcedc8;
  --md-light-green-200: #c5e1a5;
  --md-light-green-300: #aed581;
  --md-light-green-400: #9ccc65;
  --md-light-green-500: #8bc34a;
  --md-light-green-600: #7cb342;
  --md-light-green-700: #689f38;
  --md-light-green-800: #558b2f;
  --md-light-green-900: #33691e;
  --md-light-green-A100: #ccff90;
  --md-light-green-A200: #b2ff59;
  --md-light-green-A400: #76ff03;
  --md-light-green-A700: #64dd17;
  --md-lime-50: #f9fbe7;
  --md-lime-100: #f0f4c3;
  --md-lime-200: #e6ee9c;
  --md-lime-300: #dce775;
  --md-lime-400: #d4e157;
  --md-lime-500: #cddc39;
  --md-lime-600: #c0ca33;
  --md-lime-700: #afb42b;
  --md-lime-800: #9e9d24;
  --md-lime-900: #827717;
  --md-lime-A100: #f4ff81;
  --md-lime-A200: #eeff41;
  --md-lime-A400: #c6ff00;
  --md-lime-A700: #aeea00;
  --md-yellow-50: #fffde7;
  --md-yellow-100: #fff9c4;
  --md-yellow-200: #fff59d;
  --md-yellow-300: #fff176;
  --md-yellow-400: #ffee58;
  --md-yellow-500: #ffeb3b;
  --md-yellow-600: #fdd835;
  --md-yellow-700: #fbc02d;
  --md-yellow-800: #f9a825;
  --md-yellow-900: #f57f17;
  --md-yellow-A100: #ffff8d;
  --md-yellow-A200: #ff0;
  --md-yellow-A400: #ffea00;
  --md-yellow-A700: #ffd600;
  --md-amber-50: #fff8e1;
  --md-amber-100: #ffecb3;
  --md-amber-200: #ffe082;
  --md-amber-300: #ffd54f;
  --md-amber-400: #ffca28;
  --md-amber-500: #ffc107;
  --md-amber-600: #ffb300;
  --md-amber-700: #ffa000;
  --md-amber-800: #ff8f00;
  --md-amber-900: #ff6f00;
  --md-amber-A100: #ffe57f;
  --md-amber-A200: #ffd740;
  --md-amber-A400: #ffc400;
  --md-amber-A700: #ffab00;
  --md-orange-50: #fff3e0;
  --md-orange-100: #ffe0b2;
  --md-orange-200: #ffcc80;
  --md-orange-300: #ffb74d;
  --md-orange-400: #ffa726;
  --md-orange-500: #ff9800;
  --md-orange-600: #fb8c00;
  --md-orange-700: #f57c00;
  --md-orange-800: #ef6c00;
  --md-orange-900: #e65100;
  --md-orange-A100: #ffd180;
  --md-orange-A200: #ffab40;
  --md-orange-A400: #ff9100;
  --md-orange-A700: #ff6d00;
  --md-deep-orange-50: #fbe9e7;
  --md-deep-orange-100: #ffccbc;
  --md-deep-orange-200: #ffab91;
  --md-deep-orange-300: #ff8a65;
  --md-deep-orange-400: #ff7043;
  --md-deep-orange-500: #ff5722;
  --md-deep-orange-600: #f4511e;
  --md-deep-orange-700: #e64a19;
  --md-deep-orange-800: #d84315;
  --md-deep-orange-900: #bf360c;
  --md-deep-orange-A100: #ff9e80;
  --md-deep-orange-A200: #ff6e40;
  --md-deep-orange-A400: #ff3d00;
  --md-deep-orange-A700: #dd2c00;
  --md-brown-50: #efebe9;
  --md-brown-100: #d7ccc8;
  --md-brown-200: #bcaaa4;
  --md-brown-300: #a1887f;
  --md-brown-400: #8d6e63;
  --md-brown-500: #795548;
  --md-brown-600: #6d4c41;
  --md-brown-700: #5d4037;
  --md-brown-800: #4e342e;
  --md-brown-900: #3e2723;
  --md-grey-50: #fafafa;
  --md-grey-100: #f5f5f5;
  --md-grey-200: #eee;
  --md-grey-300: #e0e0e0;
  --md-grey-400: #bdbdbd;
  --md-grey-500: #9e9e9e;
  --md-grey-600: #757575;
  --md-grey-700: #616161;
  --md-grey-800: #424242;
  --md-grey-900: #212121;
  --md-blue-grey-50: #eceff1;
  --md-blue-grey-100: #cfd8dc;
  --md-blue-grey-200: #b0bec5;
  --md-blue-grey-300: #90a4ae;
  --md-blue-grey-400: #78909c;
  --md-blue-grey-500: #607d8b;
  --md-blue-grey-600: #546e7a;
  --md-blue-grey-700: #455a64;
  --md-blue-grey-800: #37474f;
  --md-blue-grey-900: #263238;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| RenderedText
|----------------------------------------------------------------------------*/

:root {
  /* This is the padding value to fill the gaps between lines containing spans with background color. */
  --jp-private-code-span-padding: calc(
    (var(--jp-code-line-height) - 1) * var(--jp-code-font-size) / 2
  );
}

.jp-RenderedText {
  text-align: left;
  padding-left: var(--jp-code-padding);
  line-height: var(--jp-code-line-height);
  font-family: var(--jp-code-font-family);
}

.jp-RenderedText pre,
.jp-RenderedJavaScript pre,
.jp-RenderedHTMLCommon pre {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-code-font-size);
  border: none;
  margin: 0;
  padding: 0;
}

.jp-RenderedText pre a:link {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

.jp-RenderedText pre a:hover {
  text-decoration: underline;
  color: var(--jp-content-link-color);
}

.jp-RenderedText pre a:visited {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

/* console foregrounds and backgrounds */
.jp-RenderedText pre .ansi-black-fg {
  color: #3e424d;
}

.jp-RenderedText pre .ansi-red-fg {
  color: #e75c58;
}

.jp-RenderedText pre .ansi-green-fg {
  color: #00a250;
}

.jp-RenderedText pre .ansi-yellow-fg {
  color: #ddb62b;
}

.jp-RenderedText pre .ansi-blue-fg {
  color: #208ffb;
}

.jp-RenderedText pre .ansi-magenta-fg {
  color: #d160c4;
}

.jp-RenderedText pre .ansi-cyan-fg {
  color: #60c6c8;
}

.jp-RenderedText pre .ansi-white-fg {
  color: #c5c1b4;
}

.jp-RenderedText pre .ansi-black-bg {
  background-color: #3e424d;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-red-bg {
  background-color: #e75c58;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-green-bg {
  background-color: #00a250;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-yellow-bg {
  background-color: #ddb62b;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-blue-bg {
  background-color: #208ffb;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-magenta-bg {
  background-color: #d160c4;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-cyan-bg {
  background-color: #60c6c8;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-white-bg {
  background-color: #c5c1b4;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-black-intense-fg {
  color: #282c36;
}

.jp-RenderedText pre .ansi-red-intense-fg {
  color: #b22b31;
}

.jp-RenderedText pre .ansi-green-intense-fg {
  color: #007427;
}

.jp-RenderedText pre .ansi-yellow-intense-fg {
  color: #b27d12;
}

.jp-RenderedText pre .ansi-blue-intense-fg {
  color: #0065ca;
}

.jp-RenderedText pre .ansi-magenta-intense-fg {
  color: #a03196;
}

.jp-RenderedText pre .ansi-cyan-intense-fg {
  color: #258f8f;
}

.jp-RenderedText pre .ansi-white-intense-fg {
  color: #a1a6b2;
}

.jp-RenderedText pre .ansi-black-intense-bg {
  background-color: #282c36;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-red-intense-bg {
  background-color: #b22b31;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-green-intense-bg {
  background-color: #007427;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-yellow-intense-bg {
  background-color: #b27d12;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-blue-intense-bg {
  background-color: #0065ca;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-magenta-intense-bg {
  background-color: #a03196;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-cyan-intense-bg {
  background-color: #258f8f;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-white-intense-bg {
  background-color: #a1a6b2;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-default-inverse-fg {
  color: var(--jp-ui-inverse-font-color0);
}

.jp-RenderedText pre .ansi-default-inverse-bg {
  background-color: var(--jp-inverse-layout-color0);
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-bold {
  font-weight: bold;
}

.jp-RenderedText pre .ansi-underline {
  text-decoration: underline;
}

.jp-RenderedText[data-mime-type='application/vnd.jupyter.stderr'] {
  background: var(--jp-rendermime-error-background);
  padding-top: var(--jp-code-padding);
}

/*-----------------------------------------------------------------------------
| RenderedLatex
|----------------------------------------------------------------------------*/

.jp-RenderedLatex {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-content-font-size1);
  line-height: var(--jp-content-line-height);
}

/* Left-justify outputs.*/
.jp-OutputArea-output.jp-RenderedLatex {
  padding: var(--jp-code-padding);
  text-align: left;
}

/*-----------------------------------------------------------------------------
| RenderedHTML
|----------------------------------------------------------------------------*/

.jp-RenderedHTMLCommon {
  color: var(--jp-content-font-color1);
  font-family: var(--jp-content-font-family);
  font-size: var(--jp-content-font-size1);
  line-height: var(--jp-content-line-height);

  /* Give a bit more R padding on Markdown text to keep line lengths reasonable */
  padding-right: 20px;
}

.jp-RenderedHTMLCommon em {
  font-style: italic;
}

.jp-RenderedHTMLCommon strong {
  font-weight: bold;
}

.jp-RenderedHTMLCommon u {
  text-decoration: underline;
}

.jp-RenderedHTMLCommon a:link {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

.jp-RenderedHTMLCommon a:hover {
  text-decoration: underline;
  color: var(--jp-content-link-color);
}

.jp-RenderedHTMLCommon a:visited {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

/* Headings */

.jp-RenderedHTMLCommon h1,
.jp-RenderedHTMLCommon h2,
.jp-RenderedHTMLCommon h3,
.jp-RenderedHTMLCommon h4,
.jp-RenderedHTMLCommon h5,
.jp-RenderedHTMLCommon h6 {
  line-height: var(--jp-content-heading-line-height);
  font-weight: var(--jp-content-heading-font-weight);
  font-style: normal;
  margin: var(--jp-content-heading-margin-top) 0
    var(--jp-content-heading-margin-bottom) 0;
}

.jp-RenderedHTMLCommon h1:first-child,
.jp-RenderedHTMLCommon h2:first-child,
.jp-RenderedHTMLCommon h3:first-child,
.jp-RenderedHTMLCommon h4:first-child,
.jp-RenderedHTMLCommon h5:first-child,
.jp-RenderedHTMLCommon h6:first-child {
  margin-top: calc(0.5 * var(--jp-content-heading-margin-top));
}

.jp-RenderedHTMLCommon h1:last-child,
.jp-RenderedHTMLCommon h2:last-child,
.jp-RenderedHTMLCommon h3:last-child,
.jp-RenderedHTMLCommon h4:last-child,
.jp-RenderedHTMLCommon h5:last-child,
.jp-RenderedHTMLCommon h6:last-child {
  margin-bottom: calc(0.5 * var(--jp-content-heading-margin-bottom));
}

.jp-RenderedHTMLCommon h1 {
  font-size: var(--jp-content-font-size5);
}

.jp-RenderedHTMLCommon h2 {
  font-size: var(--jp-content-font-size4);
}

.jp-RenderedHTMLCommon h3 {
  font-size: var(--jp-content-font-size3);
}

.jp-RenderedHTMLCommon h4 {
  font-size: var(--jp-content-font-size2);
}

.jp-RenderedHTMLCommon h5 {
  font-size: var(--jp-content-font-size1);
}

.jp-RenderedHTMLCommon h6 {
  font-size: var(--jp-content-font-size0);
}

/* Lists */

/* stylelint-disable selector-max-type, selector-max-compound-selectors */

.jp-RenderedHTMLCommon ul:not(.list-inline),
.jp-RenderedHTMLCommon ol:not(.list-inline) {
  padding-left: 2em;
}

.jp-RenderedHTMLCommon ul {
  list-style: disc;
}

.jp-RenderedHTMLCommon ul ul {
  list-style: square;
}

.jp-RenderedHTMLCommon ul ul ul {
  list-style: circle;
}

.jp-RenderedHTMLCommon ol {
  list-style: decimal;
}

.jp-RenderedHTMLCommon ol ol {
  list-style: upper-alpha;
}

.jp-RenderedHTMLCommon ol ol ol {
  list-style: lower-alpha;
}

.jp-RenderedHTMLCommon ol ol ol ol {
  list-style: lower-roman;
}

.jp-RenderedHTMLCommon ol ol ol ol ol {
  list-style: decimal;
}

.jp-RenderedHTMLCommon ol,
.jp-RenderedHTMLCommon ul {
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon ul ul,
.jp-RenderedHTMLCommon ul ol,
.jp-RenderedHTMLCommon ol ul,
.jp-RenderedHTMLCommon ol ol {
  margin-bottom: 0;
}

/* stylelint-enable selector-max-type, selector-max-compound-selectors */

.jp-RenderedHTMLCommon hr {
  color: var(--jp-border-color2);
  background-color: var(--jp-border-color1);
  margin-top: 1em;
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon > pre {
  margin: 1.5em 2em;
}

.jp-RenderedHTMLCommon pre,
.jp-RenderedHTMLCommon code {
  border: 0;
  background-color: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
  font-family: var(--jp-code-font-family);
  font-size: inherit;
  line-height: var(--jp-code-line-height);
  padding: 0;
  white-space: pre-wrap;
}

.jp-RenderedHTMLCommon :not(pre) > code {
  background-color: var(--jp-layout-color2);
  padding: 1px 5px;
}

/* Tables */

.jp-RenderedHTMLCommon table {
  border-collapse: collapse;
  border-spacing: 0;
  border: none;
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  table-layout: fixed;
  margin-left: auto;
  margin-bottom: 1em;
  margin-right: auto;
}

.jp-RenderedHTMLCommon thead {
  border-bottom: var(--jp-border-width) solid var(--jp-border-color1);
  vertical-align: bottom;
}

.jp-RenderedHTMLCommon td,
.jp-RenderedHTMLCommon th,
.jp-RenderedHTMLCommon tr {
  vertical-align: middle;
  padding: 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}

.jp-RenderedMarkdown.jp-RenderedHTMLCommon td,
.jp-RenderedMarkdown.jp-RenderedHTMLCommon th {
  max-width: none;
}

:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon td,
:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon th,
:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon tr {
  text-align: right;
}

.jp-RenderedHTMLCommon th {
  font-weight: bold;
}

.jp-RenderedHTMLCommon tbody tr:nth-child(odd) {
  background: var(--jp-layout-color0);
}

.jp-RenderedHTMLCommon tbody tr:nth-child(even) {
  background: var(--jp-rendermime-table-row-background);
}

.jp-RenderedHTMLCommon tbody tr:hover {
  background: var(--jp-rendermime-table-row-hover-background);
}

.jp-RenderedHTMLCommon p {
  text-align: left;
  margin: 0;
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon img {
  -moz-force-broken-image-icon: 1;
}

/* Restrict to direct children as other images could be nested in other content. */
.jp-RenderedHTMLCommon > img {
  display: block;
  margin-left: 0;
  margin-right: 0;
  margin-bottom: 1em;
}

/* Change color behind transparent images if they need it... */
[data-jp-theme-light='false'] .jp-RenderedImage img.jp-needs-light-background {
  background-color: var(--jp-inverse-layout-color1);
}

[data-jp-theme-light='true'] .jp-RenderedImage img.jp-needs-dark-background {
  background-color: var(--jp-inverse-layout-color1);
}

.jp-RenderedHTMLCommon img,
.jp-RenderedImage img,
.jp-RenderedHTMLCommon svg,
.jp-RenderedSVG svg {
  max-width: 100%;
  height: auto;
}

.jp-RenderedHTMLCommon img.jp-mod-unconfined,
.jp-RenderedImage img.jp-mod-unconfined,
.jp-RenderedHTMLCommon svg.jp-mod-unconfined,
.jp-RenderedSVG svg.jp-mod-unconfined {
  max-width: none;
}

.jp-RenderedHTMLCommon .alert {
  padding: var(--jp-notebook-padding);
  border: var(--jp-border-width) solid transparent;
  border-radius: var(--jp-border-radius);
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon .alert-info {
  color: var(--jp-info-color0);
  background-color: var(--jp-info-color3);
  border-color: var(--jp-info-color2);
}

.jp-RenderedHTMLCommon .alert-info hr {
  border-color: var(--jp-info-color3);
}

.jp-RenderedHTMLCommon .alert-info > p:last-child,
.jp-RenderedHTMLCommon .alert-info > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-warning {
  color: var(--jp-warn-color0);
  background-color: var(--jp-warn-color3);
  border-color: var(--jp-warn-color2);
}

.jp-RenderedHTMLCommon .alert-warning hr {
  border-color: var(--jp-warn-color3);
}

.jp-RenderedHTMLCommon .alert-warning > p:last-child,
.jp-RenderedHTMLCommon .alert-warning > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-success {
  color: var(--jp-success-color0);
  background-color: var(--jp-success-color3);
  border-color: var(--jp-success-color2);
}

.jp-RenderedHTMLCommon .alert-success hr {
  border-color: var(--jp-success-color3);
}

.jp-RenderedHTMLCommon .alert-success > p:last-child,
.jp-RenderedHTMLCommon .alert-success > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-danger {
  color: var(--jp-error-color0);
  background-color: var(--jp-error-color3);
  border-color: var(--jp-error-color2);
}

.jp-RenderedHTMLCommon .alert-danger hr {
  border-color: var(--jp-error-color3);
}

.jp-RenderedHTMLCommon .alert-danger > p:last-child,
.jp-RenderedHTMLCommon .alert-danger > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon blockquote {
  margin: 1em 2em;
  padding: 0 1em;
  border-left: 5px solid var(--jp-border-color2);
}

a.jp-InternalAnchorLink {
  visibility: hidden;
  margin-left: 8px;
  color: var(--md-blue-800);
}

h1:hover .jp-InternalAnchorLink,
h2:hover .jp-InternalAnchorLink,
h3:hover .jp-InternalAnchorLink,
h4:hover .jp-InternalAnchorLink,
h5:hover .jp-InternalAnchorLink,
h6:hover .jp-InternalAnchorLink {
  visibility: visible;
}

.jp-RenderedHTMLCommon kbd {
  background-color: var(--jp-rendermime-table-row-background);
  border: 1px solid var(--jp-border-color0);
  border-bottom-color: var(--jp-border-color2);
  border-radius: 3px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
  display: inline-block;
  font-size: var(--jp-ui-font-size0);
  line-height: 1em;
  padding: 0.2em 0.5em;
}

/* Most direct children of .jp-RenderedHTMLCommon have a margin-bottom of 1.0.
 * At the bottom of cells this is a bit too much as there is also spacing
 * between cells. Going all the way to 0 gets too tight between markdown and
 * code cells.
 */
.jp-RenderedHTMLCommon > *:last-child {
  margin-bottom: 0.5em;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-cursor-backdrop {
  position: fixed;
  width: 200px;
  height: 200px;
  margin-top: -100px;
  margin-left: -100px;
  will-change: transform;
  z-index: 100;
}

.lm-mod-drag-image {
  will-change: transform;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-lineFormSearch {
  padding: 4px 12px;
  background-color: var(--jp-layout-color2);
  box-shadow: var(--jp-toolbar-box-shadow);
  z-index: 2;
  font-size: var(--jp-ui-font-size1);
}

.jp-lineFormCaption {
  font-size: var(--jp-ui-font-size0);
  line-height: var(--jp-ui-font-size1);
  margin-top: 4px;
  color: var(--jp-ui-font-color0);
}

.jp-baseLineForm {
  border: none;
  border-radius: 0;
  position: absolute;
  background-size: 16px;
  background-repeat: no-repeat;
  background-position: center;
  outline: none;
}

.jp-lineFormButtonContainer {
  top: 4px;
  right: 8px;
  height: 24px;
  padding: 0 12px;
  width: 12px;
}

.jp-lineFormButtonIcon {
  top: 0;
  right: 0;
  background-color: var(--jp-brand-color1);
  height: 100%;
  width: 100%;
  box-sizing: border-box;
  padding: 4px 6px;
}

.jp-lineFormButton {
  top: 0;
  right: 0;
  background-color: transparent;
  height: 100%;
  width: 100%;
  box-sizing: border-box;
}

.jp-lineFormWrapper {
  overflow: hidden;
  padding: 0 8px;
  border: 1px solid var(--jp-border-color0);
  background-color: var(--jp-input-active-background);
  height: 22px;
}

.jp-lineFormWrapperFocusWithin {
  border: var(--jp-border-width) solid var(--md-blue-500);
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-lineFormInput {
  background: transparent;
  width: 200px;
  height: 100%;
  border: none;
  outline: none;
  color: var(--jp-ui-font-color0);
  line-height: 28px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-JSONEditor {
  display: flex;
  flex-direction: column;
  width: 100%;
}

.jp-JSONEditor-host {
  flex: 1 1 auto;
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  border-radius: 0;
  background: var(--jp-layout-color0);
  min-height: 50px;
  padding: 1px;
}

.jp-JSONEditor.jp-mod-error .jp-JSONEditor-host {
  border-color: red;
  outline-color: red;
}

.jp-JSONEditor-header {
  display: flex;
  flex: 1 0 auto;
  padding: 0 0 0 12px;
}

.jp-JSONEditor-header label {
  flex: 0 0 auto;
}

.jp-JSONEditor-commitButton {
  height: 16px;
  width: 16px;
  background-size: 18px;
  background-repeat: no-repeat;
  background-position: center;
}

.jp-JSONEditor-host.jp-mod-focused {
  background-color: var(--jp-input-active-background);
  border: 1px solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
}

.jp-Editor.jp-mod-dropTarget {
  border: var(--jp-border-width) solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/
.jp-DocumentSearch-input {
  border: none;
  outline: none;
  color: var(--jp-ui-font-color0);
  font-size: var(--jp-ui-font-size1);
  background-color: var(--jp-layout-color0);
  font-family: var(--jp-ui-font-family);
  padding: 2px 1px;
  resize: none;
}

.jp-DocumentSearch-overlay {
  position: absolute;
  background-color: var(--jp-toolbar-background);
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  border-left: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  top: 0;
  right: 0;
  z-index: 7;
  min-width: 405px;
  padding: 2px;
  font-size: var(--jp-ui-font-size1);

  --jp-private-document-search-button-height: 20px;
}

.jp-DocumentSearch-overlay button {
  background-color: var(--jp-toolbar-background);
  outline: 0;
}

.jp-DocumentSearch-overlay button:hover {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-overlay button:active {
  background-color: var(--jp-layout-color3);
}

.jp-DocumentSearch-overlay-row {
  display: flex;
  align-items: center;
  margin-bottom: 2px;
}

.jp-DocumentSearch-button-content {
  display: inline-block;
  cursor: pointer;
  box-sizing: border-box;
  width: 100%;
  height: 100%;
}

.jp-DocumentSearch-button-content svg {
  width: 100%;
  height: 100%;
}

.jp-DocumentSearch-input-wrapper {
  border: var(--jp-border-width) solid var(--jp-border-color0);
  display: flex;
  background-color: var(--jp-layout-color0);
  margin: 2px;
}

.jp-DocumentSearch-input-wrapper:focus-within {
  border-color: var(--jp-cell-editor-active-border-color);
}

.jp-DocumentSearch-toggle-wrapper,
.jp-DocumentSearch-button-wrapper {
  all: initial;
  overflow: hidden;
  display: inline-block;
  border: none;
  box-sizing: border-box;
}

.jp-DocumentSearch-toggle-wrapper {
  width: 14px;
  height: 14px;
}

.jp-DocumentSearch-button-wrapper {
  width: var(--jp-private-document-search-button-height);
  height: var(--jp-private-document-search-button-height);
}

.jp-DocumentSearch-toggle-wrapper:focus,
.jp-DocumentSearch-button-wrapper:focus {
  outline: var(--jp-border-width) solid
    var(--jp-cell-editor-active-border-color);
  outline-offset: -1px;
}

.jp-DocumentSearch-toggle-wrapper,
.jp-DocumentSearch-button-wrapper,
.jp-DocumentSearch-button-content:focus {
  outline: none;
}

.jp-DocumentSearch-toggle-placeholder {
  width: 5px;
}

.jp-DocumentSearch-input-button::before {
  display: block;
  padding-top: 100%;
}

.jp-DocumentSearch-input-button-off {
  opacity: var(--jp-search-toggle-off-opacity);
}

.jp-DocumentSearch-input-button-off:hover {
  opacity: var(--jp-search-toggle-hover-opacity);
}

.jp-DocumentSearch-input-button-on {
  opacity: var(--jp-search-toggle-on-opacity);
}

.jp-DocumentSearch-index-counter {
  padding-left: 10px;
  padding-right: 10px;
  user-select: none;
  min-width: 35px;
  display: inline-block;
}

.jp-DocumentSearch-up-down-wrapper {
  display: inline-block;
  padding-right: 2px;
  margin-left: auto;
  white-space: nowrap;
}

.jp-DocumentSearch-spacer {
  margin-left: auto;
}

.jp-DocumentSearch-up-down-wrapper button {
  outline: 0;
  border: none;
  width: var(--jp-private-document-search-button-height);
  height: var(--jp-private-document-search-button-height);
  vertical-align: middle;
  margin: 1px 5px 2px;
}

.jp-DocumentSearch-up-down-button:hover {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-up-down-button:active {
  background-color: var(--jp-layout-color3);
}

.jp-DocumentSearch-filter-button {
  border-radius: var(--jp-border-radius);
}

.jp-DocumentSearch-filter-button:hover {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-filter-button-enabled {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-filter-button-enabled:hover {
  background-color: var(--jp-layout-color3);
}

.jp-DocumentSearch-search-options {
  padding: 0 8px;
  margin-left: 3px;
  width: 100%;
  display: grid;
  justify-content: start;
  grid-template-columns: 1fr 1fr;
  align-items: center;
  justify-items: stretch;
}

.jp-DocumentSearch-search-filter-disabled {
  color: var(--jp-ui-font-color2);
}

.jp-DocumentSearch-search-filter {
  display: flex;
  align-items: center;
  user-select: none;
}

.jp-DocumentSearch-regex-error {
  color: var(--jp-error-color0);
}

.jp-DocumentSearch-replace-button-wrapper {
  overflow: hidden;
  display: inline-block;
  box-sizing: border-box;
  border: var(--jp-border-width) solid var(--jp-border-color0);
  margin: auto 2px;
  padding: 1px 4px;
  height: calc(var(--jp-private-document-search-button-height) + 2px);
}

.jp-DocumentSearch-replace-button-wrapper:focus {
  border: var(--jp-border-width) solid var(--jp-cell-editor-active-border-color);
}

.jp-DocumentSearch-replace-button {
  display: inline-block;
  text-align: center;
  cursor: pointer;
  box-sizing: border-box;
  color: var(--jp-ui-font-color1);

  /* height - 2 * (padding of wrapper) */
  line-height: calc(var(--jp-private-document-search-button-height) - 2px);
  width: 100%;
  height: 100%;
}

.jp-DocumentSearch-replace-button:focus {
  outline: none;
}

.jp-DocumentSearch-replace-wrapper-class {
  margin-left: 14px;
  display: flex;
}

.jp-DocumentSearch-replace-toggle {
  border: none;
  background-color: var(--jp-toolbar-background);
  border-radius: var(--jp-border-radius);
}

.jp-DocumentSearch-replace-toggle:hover {
  background-color: var(--jp-layout-color2);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.cm-editor {
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  font-family: var(--jp-code-font-family);
  border: 0;
  border-radius: 0;
  height: auto;

  /* Changed to auto to autogrow */
}

.cm-editor pre {
  padding: 0 var(--jp-code-padding);
}

.jp-CodeMirrorEditor[data-type='inline'] .cm-dialog {
  background-color: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
}

.jp-CodeMirrorEditor {
  cursor: text;
}

/* When zoomed out 67% and 33% on a screen of 1440 width x 900 height */
@media screen and (min-width: 2138px) and (max-width: 4319px) {
  .jp-CodeMirrorEditor[data-type='inline'] .cm-cursor {
    border-left: var(--jp-code-cursor-width1) solid
      var(--jp-editor-cursor-color);
  }
}

/* When zoomed out less than 33% */
@media screen and (min-width: 4320px) {
  .jp-CodeMirrorEditor[data-type='inline'] .cm-cursor {
    border-left: var(--jp-code-cursor-width2) solid
      var(--jp-editor-cursor-color);
  }
}

.cm-editor.jp-mod-readOnly .cm-cursor {
  display: none;
}

.jp-CollaboratorCursor {
  border-left: 5px solid transparent;
  border-right: 5px solid transparent;
  border-top: none;
  border-bottom: 3px solid;
  background-clip: content-box;
  margin-left: -5px;
  margin-right: -5px;
}

.cm-searching,
.cm-searching span {
  /* `.cm-searching span`: we need to override syntax highlighting */
  background-color: var(--jp-search-unselected-match-background-color);
  color: var(--jp-search-unselected-match-color);
}

.cm-searching::selection,
.cm-searching span::selection {
  background-color: var(--jp-search-unselected-match-background-color);
  color: var(--jp-search-unselected-match-color);
}

.jp-current-match > .cm-searching,
.jp-current-match > .cm-searching span,
.cm-searching > .jp-current-match,
.cm-searching > .jp-current-match span {
  background-color: var(--jp-search-selected-match-background-color);
  color: var(--jp-search-selected-match-color);
}

.jp-current-match > .cm-searching::selection,
.cm-searching > .jp-current-match::selection,
.jp-current-match > .cm-searching span::selection {
  background-color: var(--jp-search-selected-match-background-color);
  color: var(--jp-search-selected-match-color);
}

.cm-trailingspace {
  background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAFCAYAAAB4ka1VAAAAsElEQVQIHQGlAFr/AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA7+r3zKmT0/+pk9P/7+r3zAAAAAAAAAAABAAAAAAAAAAA6OPzM+/q9wAAAAAA6OPzMwAAAAAAAAAAAgAAAAAAAAAAGR8NiRQaCgAZIA0AGR8NiQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQyoYJ/SY80UAAAAASUVORK5CYII=);
  background-position: center left;
  background-repeat: repeat-x;
}

.jp-CollaboratorCursor-hover {
  position: absolute;
  z-index: 1;
  transform: translateX(-50%);
  color: white;
  border-radius: 3px;
  padding-left: 4px;
  padding-right: 4px;
  padding-top: 1px;
  padding-bottom: 1px;
  text-align: center;
  font-size: var(--jp-ui-font-size1);
  white-space: nowrap;
}

.jp-CodeMirror-ruler {
  border-left: 1px dashed var(--jp-border-color2);
}

/* Styles for shared cursors (remote cursor locations and selected ranges) */
.jp-CodeMirrorEditor .cm-ySelectionCaret {
  position: relative;
  border-left: 1px solid black;
  margin-left: -1px;
  margin-right: -1px;
  box-sizing: border-box;
}

.jp-CodeMirrorEditor .cm-ySelectionCaret > .cm-ySelectionInfo {
  white-space: nowrap;
  position: absolute;
  top: -1.15em;
  padding-bottom: 0.05em;
  left: -1px;
  font-size: 0.95em;
  font-family: var(--jp-ui-font-family);
  font-weight: bold;
  line-height: normal;
  user-select: none;
  color: white;
  padding-left: 2px;
  padding-right: 2px;
  z-index: 101;
  transition: opacity 0.3s ease-in-out;
}

.jp-CodeMirrorEditor .cm-ySelectionInfo {
  transition-delay: 0.7s;
  opacity: 0;
}

.jp-CodeMirrorEditor .cm-ySelectionCaret:hover > .cm-ySelectionInfo {
  opacity: 1;
  transition-delay: 0s;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-MimeDocument {
  outline: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-filebrowser-button-height: 28px;
  --jp-private-filebrowser-button-width: 48px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-FileBrowser .jp-SidePanel-content {
  display: flex;
  flex-direction: column;
}

.jp-FileBrowser-toolbar.jp-Toolbar {
  flex-wrap: wrap;
  row-gap: 12px;
  border-bottom: none;
  height: auto;
  margin: 8px 12px 0;
  box-shadow: none;
  padding: 0;
  justify-content: flex-start;
}

.jp-FileBrowser-Panel {
  flex: 1 1 auto;
  display: flex;
  flex-direction: column;
}

.jp-BreadCrumbs {
  flex: 0 0 auto;
  margin: 8px 12px;
}

.jp-BreadCrumbs-item {
  margin: 0 2px;
  padding: 0 2px;
  border-radius: var(--jp-border-radius);
  cursor: pointer;
}

.jp-BreadCrumbs-item:hover {
  background-color: var(--jp-layout-color2);
}

.jp-BreadCrumbs-item:first-child {
  margin-left: 0;
}

.jp-BreadCrumbs-item.jp-mod-dropTarget {
  background-color: var(--jp-brand-color2);
  opacity: 0.7;
}

/*-----------------------------------------------------------------------------
| Buttons
|----------------------------------------------------------------------------*/

.jp-FileBrowser-toolbar > .jp-Toolbar-item {
  flex: 0 0 auto;
  padding-left: 0;
  padding-right: 2px;
  align-items: center;
  height: unset;
}

.jp-FileBrowser-toolbar > .jp-Toolbar-item .jp-ToolbarButtonComponent {
  width: 40px;
}

/*-----------------------------------------------------------------------------
| Other styles
|----------------------------------------------------------------------------*/

.jp-FileDialog.jp-mod-conflict input {
  color: var(--jp-error-color1);
}

.jp-FileDialog .jp-new-name-title {
  margin-top: 12px;
}

.jp-LastModified-hidden {
  display: none;
}

.jp-FileSize-hidden {
  display: none;
}

.jp-FileBrowser .lm-AccordionPanel > h3:first-child {
  display: none;
}

/*-----------------------------------------------------------------------------
| DirListing
|----------------------------------------------------------------------------*/

.jp-DirListing {
  flex: 1 1 auto;
  display: flex;
  flex-direction: column;
  outline: 0;
}

.jp-DirListing-header {
  flex: 0 0 auto;
  display: flex;
  flex-direction: row;
  align-items: center;
  overflow: hidden;
  border-top: var(--jp-border-width) solid var(--jp-border-color2);
  border-bottom: var(--jp-border-width) solid var(--jp-border-color1);
  box-shadow: var(--jp-toolbar-box-shadow);
  z-index: 2;
}

.jp-DirListing-headerItem {
  padding: 4px 12px 2px;
  font-weight: 500;
}

.jp-DirListing-headerItem:hover {
  background: var(--jp-layout-color2);
}

.jp-DirListing-headerItem.jp-id-name {
  flex: 1 0 84px;
}

.jp-DirListing-headerItem.jp-id-modified {
  flex: 0 0 112px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
}

.jp-DirListing-headerItem.jp-id-filesize {
  flex: 0 0 75px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
}

.jp-id-narrow {
  display: none;
  flex: 0 0 5px;
  padding: 4px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
  color: var(--jp-border-color2);
}

.jp-DirListing-narrow .jp-id-narrow {
  display: block;
}

.jp-DirListing-narrow .jp-id-modified,
.jp-DirListing-narrow .jp-DirListing-itemModified {
  display: none;
}

.jp-DirListing-headerItem.jp-mod-selected {
  font-weight: 600;
}

/* increase specificity to override bundled default */
.jp-DirListing-content {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  list-style-type: none;
  overflow: auto;
  background-color: var(--jp-layout-color1);
}

.jp-DirListing-content mark {
  color: var(--jp-ui-font-color0);
  background-color: transparent;
  font-weight: bold;
}

.jp-DirListing-content .jp-DirListing-item.jp-mod-selected mark {
  color: var(--jp-ui-inverse-font-color0);
}

/* Style the directory listing content when a user drops a file to upload */
.jp-DirListing.jp-mod-native-drop .jp-DirListing-content {
  outline: 5px dashed rgba(128, 128, 128, 0.5);
  outline-offset: -10px;
  cursor: copy;
}

.jp-DirListing-item {
  display: flex;
  flex-direction: row;
  align-items: center;
  padding: 4px 12px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-DirListing-checkboxWrapper {
  /* Increases hit area of checkbox. */
  padding: 4px;
}

.jp-DirListing-header
  .jp-DirListing-checkboxWrapper
  + .jp-DirListing-headerItem {
  padding-left: 4px;
}

.jp-DirListing-content .jp-DirListing-checkboxWrapper {
  position: relative;
  left: -4px;
  margin: -4px 0 -4px -8px;
}

.jp-DirListing-checkboxWrapper.jp-mod-visible {
  visibility: visible;
}

/* For devices that support hovering, hide checkboxes until hovered, selected...
*/
@media (hover: hover) {
  .jp-DirListing-checkboxWrapper {
    visibility: hidden;
  }

  .jp-DirListing-item:hover .jp-DirListing-checkboxWrapper,
  .jp-DirListing-item.jp-mod-selected .jp-DirListing-checkboxWrapper {
    visibility: visible;
  }
}

.jp-DirListing-item[data-is-dot] {
  opacity: 75%;
}

.jp-DirListing-item.jp-mod-selected {
  color: var(--jp-ui-inverse-font-color1);
  background: var(--jp-brand-color1);
}

.jp-DirListing-item.jp-mod-dropTarget {
  background: var(--jp-brand-color3);
}

.jp-DirListing-item:hover:not(.jp-mod-selected) {
  background: var(--jp-layout-color2);
}

.jp-DirListing-itemIcon {
  flex: 0 0 20px;
  margin-right: 4px;
}

.jp-DirListing-itemText {
  flex: 1 0 64px;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  user-select: none;
}

.jp-DirListing-itemText:focus {
  outline-width: 2px;
  outline-color: var(--jp-inverse-layout-color1);
  outline-style: solid;
  outline-offset: 1px;
}

.jp-DirListing-item.jp-mod-selected .jp-DirListing-itemText:focus {
  outline-color: var(--jp-layout-color1);
}

.jp-DirListing-itemModified {
  flex: 0 0 125px;
  text-align: right;
}

.jp-DirListing-itemFileSize {
  flex: 0 0 90px;
  text-align: right;
}

.jp-DirListing-editor {
  flex: 1 0 64px;
  outline: none;
  border: none;
  color: var(--jp-ui-font-color1);
  background-color: var(--jp-layout-color1);
}

.jp-DirListing-item.jp-mod-running .jp-DirListing-itemIcon::before {
  color: var(--jp-success-color1);
  content: '\25CF';
  font-size: 8px;
  position: absolute;
  left: -8px;
}

.jp-DirListing-item.jp-mod-running.jp-mod-selected
  .jp-DirListing-itemIcon::before {
  color: var(--jp-ui-inverse-font-color1);
}

.jp-DirListing-item.lm-mod-drag-image,
.jp-DirListing-item.jp-mod-selected.lm-mod-drag-image {
  font-size: var(--jp-ui-font-size1);
  padding-left: 4px;
  margin-left: 4px;
  width: 160px;
  background-color: var(--jp-ui-inverse-font-color2);
  box-shadow: var(--jp-elevation-z2);
  border-radius: 0;
  color: var(--jp-ui-font-color1);
  transform: translateX(-40%) translateY(-58%);
}

.jp-Document {
  min-width: 120px;
  min-height: 120px;
  outline: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Main OutputArea
| OutputArea has a list of Outputs
|----------------------------------------------------------------------------*/

.jp-OutputArea {
  overflow-y: auto;
}

.jp-OutputArea-child {
  display: table;
  table-layout: fixed;
  width: 100%;
  overflow: hidden;
}

.jp-OutputPrompt {
  width: var(--jp-cell-prompt-width);
  color: var(--jp-cell-outprompt-font-color);
  font-family: var(--jp-cell-prompt-font-family);
  padding: var(--jp-code-padding);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
  opacity: var(--jp-cell-prompt-opacity);

  /* Right align prompt text, don't wrap to handle large prompt numbers */
  text-align: right;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;

  /* Disable text selection */
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-OutputArea-prompt {
  display: table-cell;
  vertical-align: top;
}

.jp-OutputArea-output {
  display: table-cell;
  width: 100%;
  height: auto;
  overflow: auto;
  user-select: text;
  -moz-user-select: text;
  -webkit-user-select: text;
  -ms-user-select: text;
}

.jp-OutputArea .jp-RenderedText {
  padding-left: 1ch;
}

/**
 * Prompt overlay.
 */

.jp-OutputArea-promptOverlay {
  position: absolute;
  top: 0;
  width: var(--jp-cell-prompt-width);
  height: 100%;
  opacity: 0.5;
}

.jp-OutputArea-promptOverlay:hover {
  background: var(--jp-layout-color2);
  box-shadow: inset 0 0 1px var(--jp-inverse-layout-color0);
  cursor: zoom-out;
}

.jp-mod-outputsScrolled .jp-OutputArea-promptOverlay:hover {
  cursor: zoom-in;
}

/**
 * Isolated output.
 */
.jp-OutputArea-output.jp-mod-isolated {
  width: 100%;
  display: block;
}

/*
When drag events occur, `lm-mod-override-cursor` is added to the body.
Because iframes steal all cursor events, the following two rules are necessary
to suppress pointer events while resize drags are occurring. There may be a
better solution to this problem.
*/
body.lm-mod-override-cursor .jp-OutputArea-output.jp-mod-isolated {
  position: relative;
}

body.lm-mod-override-cursor .jp-OutputArea-output.jp-mod-isolated::before {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: transparent;
}

/* pre */

.jp-OutputArea-output pre {
  border: none;
  margin: 0;
  padding: 0;
  overflow-x: auto;
  overflow-y: auto;
  word-break: break-all;
  word-wrap: break-word;
  white-space: pre-wrap;
}

/* tables */

.jp-OutputArea-output.jp-RenderedHTMLCommon table {
  margin-left: 0;
  margin-right: 0;
}

/* description lists */

.jp-OutputArea-output dl,
.jp-OutputArea-output dt,
.jp-OutputArea-output dd {
  display: block;
}

.jp-OutputArea-output dl {
  width: 100%;
  overflow: hidden;
  padding: 0;
  margin: 0;
}

.jp-OutputArea-output dt {
  font-weight: bold;
  float: left;
  width: 20%;
  padding: 0;
  margin: 0;
}

.jp-OutputArea-output dd {
  float: left;
  width: 80%;
  padding: 0;
  margin: 0;
}

.jp-TrimmedOutputs pre {
  background: var(--jp-layout-color3);
  font-size: calc(var(--jp-code-font-size) * 1.4);
  text-align: center;
  text-transform: uppercase;
}

/* Hide the gutter in case of
 *  - nested output areas (e.g. in the case of output widgets)
 *  - mirrored output areas
 */
.jp-OutputArea .jp-OutputArea .jp-OutputArea-prompt {
  display: none;
}

/* Hide empty lines in the output area, for instance due to cleared widgets */
.jp-OutputArea-prompt:empty {
  padding: 0;
  border: 0;
}

/*-----------------------------------------------------------------------------
| executeResult is added to any Output-result for the display of the object
| returned by a cell
|----------------------------------------------------------------------------*/

.jp-OutputArea-output.jp-OutputArea-executeResult {
  margin-left: 0;
  width: 100%;
}

/* Text output with the Out[] prompt needs a top padding to match the
 * alignment of the Out[] prompt itself.
 */
.jp-OutputArea-executeResult .jp-RenderedText.jp-OutputArea-output {
  padding-top: var(--jp-code-padding);
  border-top: var(--jp-border-width) solid transparent;
}

/*-----------------------------------------------------------------------------
| The Stdin output
|----------------------------------------------------------------------------*/

.jp-Stdin-prompt {
  color: var(--jp-content-font-color0);
  padding-right: var(--jp-code-padding);
  vertical-align: baseline;
  flex: 0 0 auto;
}

.jp-Stdin-input {
  font-family: var(--jp-code-font-family);
  font-size: inherit;
  color: inherit;
  background-color: inherit;
  width: 42%;
  min-width: 200px;

  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;

  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0 0.25em;
  margin: 0 0.25em;
  flex: 0 0 70%;
}

.jp-Stdin-input::placeholder {
  opacity: 0;
}

.jp-Stdin-input:focus {
  box-shadow: none;
}

.jp-Stdin-input:focus::placeholder {
  opacity: 1;
}

/*-----------------------------------------------------------------------------
| Output Area View
|----------------------------------------------------------------------------*/

.jp-LinkedOutputView .jp-OutputArea {
  height: 100%;
  display: block;
}

.jp-LinkedOutputView .jp-OutputArea-output:only-child {
  height: 100%;
}

/*-----------------------------------------------------------------------------
| Printing
|----------------------------------------------------------------------------*/

@media print {
  .jp-OutputArea-child {
    break-inside: avoid-page;
  }
}

/*-----------------------------------------------------------------------------
| Mobile
|----------------------------------------------------------------------------*/
@media only screen and (max-width: 760px) {
  .jp-OutputPrompt {
    display: table-row;
    text-align: left;
  }

  .jp-OutputArea-child .jp-OutputArea-output {
    display: table-row;
    margin-left: var(--jp-notebook-padding);
  }
}

/* Trimmed outputs warning */
.jp-TrimmedOutputs > a {
  margin: 10px;
  text-decoration: none;
  cursor: pointer;
}

.jp-TrimmedOutputs > a:hover {
  text-decoration: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Table of Contents
|----------------------------------------------------------------------------*/

:root {
  --jp-private-toc-active-width: 4px;
}

.jp-TableOfContents {
  display: flex;
  flex-direction: column;
  background: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  height: 100%;
}

.jp-TableOfContents-placeholder {
  text-align: center;
}

.jp-TableOfContents-placeholderContent {
  color: var(--jp-content-font-color2);
  padding: 8px;
}

.jp-TableOfContents-placeholderContent > h3 {
  margin-bottom: var(--jp-content-heading-margin-bottom);
}

.jp-TableOfContents .jp-SidePanel-content {
  overflow-y: auto;
}

.jp-TableOfContents-tree {
  margin: 4px;
}

.jp-TableOfContents ol {
  list-style-type: none;
}

/* stylelint-disable-next-line selector-max-type */
.jp-TableOfContents li > ol {
  /* Align left border with triangle icon center */
  padding-left: 11px;
}

.jp-TableOfContents-content {
  /* left margin for the active heading indicator */
  margin: 0 0 0 var(--jp-private-toc-active-width);
  padding: 0;
  background-color: var(--jp-layout-color1);
}

.jp-tocItem {
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-tocItem-heading {
  display: flex;
  cursor: pointer;
}

.jp-tocItem-heading:hover {
  background-color: var(--jp-layout-color2);
}

.jp-tocItem-content {
  display: block;
  padding: 4px 0;
  white-space: nowrap;
  text-overflow: ellipsis;
  overflow-x: hidden;
}

.jp-tocItem-collapser {
  height: 20px;
  margin: 2px 2px 0;
  padding: 0;
  background: none;
  border: none;
  cursor: pointer;
}

.jp-tocItem-collapser:hover {
  background-color: var(--jp-layout-color3);
}

/* Active heading indicator */

.jp-tocItem-heading::before {
  content: ' ';
  background: transparent;
  width: var(--jp-private-toc-active-width);
  height: 24px;
  position: absolute;
  left: 0;
  border-radius: var(--jp-border-radius);
}

.jp-tocItem-heading.jp-tocItem-active::before {
  background-color: var(--jp-brand-color1);
}

.jp-tocItem-heading:hover.jp-tocItem-active::before {
  background: var(--jp-brand-color0);
  opacity: 1;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Collapser {
  flex: 0 0 var(--jp-cell-collapser-width);
  padding: 0;
  margin: 0;
  border: none;
  outline: none;
  background: transparent;
  border-radius: var(--jp-border-radius);
  opacity: 1;
}

.jp-Collapser-child {
  display: block;
  width: 100%;
  box-sizing: border-box;

  /* height: 100% doesn't work because the height of its parent is computed from content */
  position: absolute;
  top: 0;
  bottom: 0;
}

/*-----------------------------------------------------------------------------
| Printing
|----------------------------------------------------------------------------*/

/*
Hiding collapsers in print mode.

Note: input and output wrappers have "display: block" propery in print mode.
*/

@media print {
  .jp-Collapser {
    display: none;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Header/Footer
|----------------------------------------------------------------------------*/

/* Hidden by zero height by default */
.jp-CellHeader,
.jp-CellFooter {
  height: 0;
  width: 100%;
  padding: 0;
  margin: 0;
  border: none;
  outline: none;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Input
|----------------------------------------------------------------------------*/

/* All input areas */
.jp-InputArea {
  display: table;
  table-layout: fixed;
  width: 100%;
  overflow: hidden;
}

.jp-InputArea-editor {
  display: table-cell;
  overflow: hidden;
  vertical-align: top;

  /* This is the non-active, default styling */
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  border-radius: 0;
  background: var(--jp-cell-editor-background);
}

.jp-InputPrompt {
  display: table-cell;
  vertical-align: top;
  width: var(--jp-cell-prompt-width);
  color: var(--jp-cell-inprompt-font-color);
  font-family: var(--jp-cell-prompt-font-family);
  padding: var(--jp-code-padding);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  opacity: var(--jp-cell-prompt-opacity);
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;

  /* Right align prompt text, don't wrap to handle large prompt numbers */
  text-align: right;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;

  /* Disable text selection */
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

/*-----------------------------------------------------------------------------
| Mobile
|----------------------------------------------------------------------------*/
@media only screen and (max-width: 760px) {
  .jp-InputArea-editor {
    display: table-row;
    margin-left: var(--jp-notebook-padding);
  }

  .jp-InputPrompt {
    display: table-row;
    text-align: left;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Placeholder
|----------------------------------------------------------------------------*/

.jp-Placeholder {
  display: table;
  table-layout: fixed;
  width: 100%;
}

.jp-Placeholder-prompt {
  display: table-cell;
  box-sizing: border-box;
}

.jp-Placeholder-content {
  display: table-cell;
  padding: 4px 6px;
  border: 1px solid transparent;
  border-radius: 0;
  background: none;
  box-sizing: border-box;
  cursor: pointer;
}

.jp-Placeholder-contentContainer {
  display: flex;
}

.jp-Placeholder-content:hover,
.jp-InputPlaceholder > .jp-Placeholder-content:hover {
  border-color: var(--jp-layout-color3);
}

.jp-Placeholder-content .jp-MoreHorizIcon {
  width: 32px;
  height: 16px;
  border: 1px solid transparent;
  border-radius: var(--jp-border-radius);
}

.jp-Placeholder-content .jp-MoreHorizIcon:hover {
  border: 1px solid var(--jp-border-color1);
  box-shadow: 0 0 2px 0 rgba(0, 0, 0, 0.25);
  background-color: var(--jp-layout-color0);
}

.jp-PlaceholderText {
  white-space: nowrap;
  overflow-x: hidden;
  color: var(--jp-inverse-layout-color3);
  font-family: var(--jp-code-font-family);
}

.jp-InputPlaceholder > .jp-Placeholder-content {
  border-color: var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Private CSS variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-cell-scrolling-output-offset: 5px;
}

/*-----------------------------------------------------------------------------
| Cell
|----------------------------------------------------------------------------*/

.jp-Cell {
  padding: var(--jp-cell-padding);
  margin: 0;
  border: none;
  outline: none;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Common input/output
|----------------------------------------------------------------------------*/

.jp-Cell-inputWrapper,
.jp-Cell-outputWrapper {
  display: flex;
  flex-direction: row;
  padding: 0;
  margin: 0;

  /* Added to reveal the box-shadow on the input and output collapsers. */
  overflow: visible;
}

/* Only input/output areas inside cells */
.jp-Cell-inputArea,
.jp-Cell-outputArea {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Collapser
|----------------------------------------------------------------------------*/

/* Make the output collapser disappear when there is not output, but do so
 * in a manner that leaves it in the layout and preserves its width.
 */
.jp-Cell.jp-mod-noOutputs .jp-Cell-outputCollapser {
  border: none !important;
  background: transparent !important;
}

.jp-Cell:not(.jp-mod-noOutputs) .jp-Cell-outputCollapser {
  min-height: var(--jp-cell-collapser-min-height);
}

/*-----------------------------------------------------------------------------
| Output
|----------------------------------------------------------------------------*/

/* Put a space between input and output when there IS output */
.jp-Cell:not(.jp-mod-noOutputs) .jp-Cell-outputWrapper {
  margin-top: 5px;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea {
  overflow-y: auto;
  max-height: 24em;
  margin-left: var(--jp-private-cell-scrolling-output-offset);
  resize: vertical;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea[style*='height'] {
  max-height: unset;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea::after {
  content: ' ';
  box-shadow: inset 0 0 6px 2px rgb(0 0 0 / 30%);
  width: 100%;
  height: 100%;
  position: sticky;
  bottom: 0;
  top: 0;
  margin-top: -50%;
  float: left;
  display: block;
  pointer-events: none;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-child {
  padding-top: 6px;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-prompt {
  width: calc(
    var(--jp-cell-prompt-width) - var(--jp-private-cell-scrolling-output-offset)
  );
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-promptOverlay {
  left: calc(-1 * var(--jp-private-cell-scrolling-output-offset));
}

/*-----------------------------------------------------------------------------
| CodeCell
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| MarkdownCell
|----------------------------------------------------------------------------*/

.jp-MarkdownOutput {
  display: table-cell;
  width: 100%;
  margin-top: 0;
  margin-bottom: 0;
  padding-left: var(--jp-code-padding);
}

.jp-MarkdownOutput.jp-RenderedHTMLCommon {
  overflow: auto;
}

/* collapseHeadingButton (show always if hiddenCellsButton is _not_ shown) */
.jp-collapseHeadingButton {
  display: flex;
  min-height: var(--jp-cell-collapser-min-height);
  font-size: var(--jp-code-font-size);
  position: absolute;
  background-color: transparent;
  background-size: 25px;
  background-repeat: no-repeat;
  background-position-x: center;
  background-position-y: top;
  background-image: var(--jp-icon-caret-down);
  right: 0;
  top: 0;
  bottom: 0;
}

.jp-collapseHeadingButton.jp-mod-collapsed {
  background-image: var(--jp-icon-caret-right);
}

/*
 set the container font size to match that of content
 so that the nested collapse buttons have the right size
*/
.jp-MarkdownCell .jp-InputPrompt {
  font-size: var(--jp-content-font-size1);
}

/*
  Align collapseHeadingButton with cell top header
  The font sizes are identical to the ones in packages/rendermime/style/base.css
*/
.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='1'] {
  font-size: var(--jp-content-font-size5);
  background-position-y: calc(0.3 * var(--jp-content-font-size5));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='2'] {
  font-size: var(--jp-content-font-size4);
  background-position-y: calc(0.3 * var(--jp-content-font-size4));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='3'] {
  font-size: var(--jp-content-font-size3);
  background-position-y: calc(0.3 * var(--jp-content-font-size3));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='4'] {
  font-size: var(--jp-content-font-size2);
  background-position-y: calc(0.3 * var(--jp-content-font-size2));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='5'] {
  font-size: var(--jp-content-font-size1);
  background-position-y: top;
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='6'] {
  font-size: var(--jp-content-font-size0);
  background-position-y: top;
}

/* collapseHeadingButton (show only on (hover,active) if hiddenCellsButton is shown) */
.jp-Notebook.jp-mod-showHiddenCellsButton .jp-collapseHeadingButton {
  display: none;
}

.jp-Notebook.jp-mod-showHiddenCellsButton
  :is(.jp-MarkdownCell:hover, .jp-mod-active)
  .jp-collapseHeadingButton {
  display: flex;
}

/* showHiddenCellsButton (only show if jp-mod-showHiddenCellsButton is set, which
is a consequence of the showHiddenCellsButton option in Notebook Settings)*/
.jp-Notebook.jp-mod-showHiddenCellsButton .jp-showHiddenCellsButton {
  margin-left: calc(var(--jp-cell-prompt-width) + 2 * var(--jp-code-padding));
  margin-top: var(--jp-code-padding);
  border: 1px solid var(--jp-border-color2);
  background-color: var(--jp-border-color3) !important;
  color: var(--jp-content-font-color0) !important;
  display: flex;
}

.jp-Notebook.jp-mod-showHiddenCellsButton .jp-showHiddenCellsButton:hover {
  background-color: var(--jp-border-color2) !important;
}

.jp-showHiddenCellsButton {
  display: none;
}

/*-----------------------------------------------------------------------------
| Printing
|----------------------------------------------------------------------------*/

/*
Using block instead of flex to allow the use of the break-inside CSS property for
cell outputs.
*/

@media print {
  .jp-Cell-inputWrapper,
  .jp-Cell-outputWrapper {
    display: block;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-notebook-toolbar-padding: 2px 5px 2px 2px;
}

/*-----------------------------------------------------------------------------

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-NotebookPanel-toolbar {
  padding: var(--jp-notebook-toolbar-padding);

  /* disable paint containment from lumino 2.0 default strict CSS containment */
  contain: style size !important;
}

.jp-Toolbar-item.jp-Notebook-toolbarCellType .jp-select-wrapper.jp-mod-focused {
  border: none;
  box-shadow: none;
}

.jp-Notebook-toolbarCellTypeDropdown select {
  height: 24px;
  font-size: var(--jp-ui-font-size1);
  line-height: 14px;
  border-radius: 0;
  display: block;
}

.jp-Notebook-toolbarCellTypeDropdown span {
  top: 5px !important;
}

.jp-Toolbar-responsive-popup {
  position: absolute;
  height: fit-content;
  display: flex;
  flex-direction: row;
  flex-wrap: wrap;
  justify-content: flex-end;
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  background: var(--jp-toolbar-background);
  min-height: var(--jp-toolbar-micro-height);
  padding: var(--jp-notebook-toolbar-padding);
  z-index: 1;
  right: 0;
  top: 0;
}

.jp-Toolbar > .jp-Toolbar-responsive-opener {
  margin-left: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-Notebook-ExecutionIndicator {
  position: relative;
  display: inline-block;
  height: 100%;
  z-index: 9997;
}

.jp-Notebook-ExecutionIndicator-tooltip {
  visibility: hidden;
  height: auto;
  width: max-content;
  width: -moz-max-content;
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color1);
  text-align: justify;
  border-radius: 6px;
  padding: 0 5px;
  position: fixed;
  display: table;
}

.jp-Notebook-ExecutionIndicator-tooltip.up {
  transform: translateX(-50%) translateY(-100%) translateY(-32px);
}

.jp-Notebook-ExecutionIndicator-tooltip.down {
  transform: translateX(calc(-100% + 16px)) translateY(5px);
}

.jp-Notebook-ExecutionIndicator-tooltip.hidden {
  display: none;
}

.jp-Notebook-ExecutionIndicator:hover .jp-Notebook-ExecutionIndicator-tooltip {
  visibility: visible;
}

.jp-Notebook-ExecutionIndicator span {
  font-size: var(--jp-ui-font-size1);
  font-family: var(--jp-ui-font-family);
  color: var(--jp-ui-font-color1);
  line-height: 24px;
  display: block;
}

.jp-Notebook-ExecutionIndicator-progress-bar {
  display: flex;
  justify-content: center;
  height: 100%;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*
 * Execution indicator
 */
.jp-tocItem-content::after {
  content: '';

  /* Must be identical to form a circle */
  width: 12px;
  height: 12px;
  background: none;
  border: none;
  position: absolute;
  right: 0;
}

.jp-tocItem-content[data-running='0']::after {
  border-radius: 50%;
  border: var(--jp-border-width) solid var(--jp-inverse-layout-color3);
  background: none;
}

.jp-tocItem-content[data-running='1']::after {
  border-radius: 50%;
  border: var(--jp-border-width) solid var(--jp-inverse-layout-color3);
  background-color: var(--jp-inverse-layout-color3);
}

.jp-tocItem-content[data-running='0'],
.jp-tocItem-content[data-running='1'] {
  margin-right: 12px;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-Notebook-footer {
  height: 27px;
  margin-left: calc(
    var(--jp-cell-prompt-width) + var(--jp-cell-collapser-width) +
      var(--jp-cell-padding)
  );
  width: calc(
    100% -
      (
        var(--jp-cell-prompt-width) + var(--jp-cell-collapser-width) +
          var(--jp-cell-padding) + var(--jp-cell-padding)
      )
  );
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  color: var(--jp-ui-font-color3);
  margin-top: 6px;
  background: none;
  cursor: pointer;
}

.jp-Notebook-footer:focus {
  border-color: var(--jp-cell-editor-active-border-color);
}

/* For devices that support hovering, hide footer until hover */
@media (hover: hover) {
  .jp-Notebook-footer {
    opacity: 0;
  }

  .jp-Notebook-footer:focus,
  .jp-Notebook-footer:hover {
    opacity: 1;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Imports
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| CSS variables
|----------------------------------------------------------------------------*/

:root {
  --jp-side-by-side-output-size: 1fr;
  --jp-side-by-side-resized-cell: var(--jp-side-by-side-output-size);
  --jp-private-notebook-dragImage-width: 304px;
  --jp-private-notebook-dragImage-height: 36px;
  --jp-private-notebook-selected-color: var(--md-blue-400);
  --jp-private-notebook-active-color: var(--md-green-400);
}

/*-----------------------------------------------------------------------------
| Notebook
|----------------------------------------------------------------------------*/

/* stylelint-disable selector-max-class */

.jp-NotebookPanel {
  display: block;
  height: 100%;
}

.jp-NotebookPanel.jp-Document {
  min-width: 240px;
  min-height: 120px;
}

.jp-Notebook {
  padding: var(--jp-notebook-padding);
  outline: none;
  overflow: auto;
  background: var(--jp-layout-color0);
}

.jp-Notebook.jp-mod-scrollPastEnd::after {
  display: block;
  content: '';
  min-height: var(--jp-notebook-scroll-padding);
}

.jp-MainAreaWidget-ContainStrict .jp-Notebook * {
  contain: strict;
}

.jp-Notebook .jp-Cell {
  overflow: visible;
}

.jp-Notebook .jp-Cell .jp-InputPrompt {
  cursor: move;
}

/*-----------------------------------------------------------------------------
| Notebook state related styling
|
| The notebook and cells each have states, here are the possibilities:
|
| - Notebook
|   - Command
|   - Edit
| - Cell
|   - None
|   - Active (only one can be active)
|   - Selected (the cells actions are applied to)
|   - Multiselected (when multiple selected, the cursor)
|   - No outputs
|----------------------------------------------------------------------------*/

/* Command or edit modes */

.jp-Notebook .jp-Cell:not(.jp-mod-active) .jp-InputPrompt {
  opacity: var(--jp-cell-prompt-not-active-opacity);
  color: var(--jp-cell-prompt-not-active-font-color);
}

.jp-Notebook .jp-Cell:not(.jp-mod-active) .jp-OutputPrompt {
  opacity: var(--jp-cell-prompt-not-active-opacity);
  color: var(--jp-cell-prompt-not-active-font-color);
}

/* cell is active */
.jp-Notebook .jp-Cell.jp-mod-active .jp-Collapser {
  background: var(--jp-brand-color1);
}

/* cell is dirty */
.jp-Notebook .jp-Cell.jp-mod-dirty .jp-InputPrompt {
  color: var(--jp-warn-color1);
}

.jp-Notebook .jp-Cell.jp-mod-dirty .jp-InputPrompt::before {
  color: var(--jp-warn-color1);
  content: '•';
}

.jp-Notebook .jp-Cell.jp-mod-active.jp-mod-dirty .jp-Collapser {
  background: var(--jp-warn-color1);
}

/* collapser is hovered */
.jp-Notebook .jp-Cell .jp-Collapser:hover {
  box-shadow: var(--jp-elevation-z2);
  background: var(--jp-brand-color1);
  opacity: var(--jp-cell-collapser-not-active-hover-opacity);
}

/* cell is active and collapser is hovered */
.jp-Notebook .jp-Cell.jp-mod-active .jp-Collapser:hover {
  background: var(--jp-brand-color0);
  opacity: 1;
}

/* Command mode */

.jp-Notebook.jp-mod-commandMode .jp-Cell.jp-mod-selected {
  background: var(--jp-notebook-multiselected-color);
}

.jp-Notebook.jp-mod-commandMode
  .jp-Cell.jp-mod-active.jp-mod-selected:not(.jp-mod-multiSelected) {
  background: transparent;
}

/* Edit mode */

.jp-Notebook.jp-mod-editMode .jp-Cell.jp-mod-active .jp-InputArea-editor {
  border: var(--jp-border-width) solid var(--jp-cell-editor-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
  background-color: var(--jp-cell-editor-active-background);
}

/*-----------------------------------------------------------------------------
| Notebook drag and drop
|----------------------------------------------------------------------------*/

.jp-Notebook-cell.jp-mod-dropSource {
  opacity: 0.5;
}

.jp-Notebook-cell.jp-mod-dropTarget,
.jp-Notebook.jp-mod-commandMode
  .jp-Notebook-cell.jp-mod-active.jp-mod-selected.jp-mod-dropTarget {
  border-top-color: var(--jp-private-notebook-selected-color);
  border-top-style: solid;
  border-top-width: 2px;
}

.jp-dragImage {
  display: block;
  flex-direction: row;
  width: var(--jp-private-notebook-dragImage-width);
  height: var(--jp-private-notebook-dragImage-height);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background);
  overflow: visible;
}

.jp-dragImage-singlePrompt {
  box-shadow: 2px 2px 4px 0 rgba(0, 0, 0, 0.12);
}

.jp-dragImage .jp-dragImage-content {
  flex: 1 1 auto;
  z-index: 2;
  font-size: var(--jp-code-font-size);
  font-family: var(--jp-code-font-family);
  line-height: var(--jp-code-line-height);
  padding: var(--jp-code-padding);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background-color);
  color: var(--jp-content-font-color3);
  text-align: left;
  margin: 4px 4px 4px 0;
}

.jp-dragImage .jp-dragImage-prompt {
  flex: 0 0 auto;
  min-width: 36px;
  color: var(--jp-cell-inprompt-font-color);
  padding: var(--jp-code-padding);
  padding-left: 12px;
  font-family: var(--jp-cell-prompt-font-family);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  line-height: 1.9;
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
}

.jp-dragImage-multipleBack {
  z-index: -1;
  position: absolute;
  height: 32px;
  width: 300px;
  top: 8px;
  left: 8px;
  background: var(--jp-layout-color2);
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  box-shadow: 2px 2px 4px 0 rgba(0, 0, 0, 0.12);
}

/*-----------------------------------------------------------------------------
| Cell toolbar
|----------------------------------------------------------------------------*/

.jp-NotebookTools {
  display: block;
  min-width: var(--jp-sidebar-min-width);
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);

  /* This is needed so that all font sizing of children done in ems is
    * relative to this base size */
  font-size: var(--jp-ui-font-size1);
  overflow: auto;
}

.jp-ActiveCellTool {
  padding: 12px 0;
  display: flex;
}

.jp-ActiveCellTool-Content {
  flex: 1 1 auto;
}

.jp-ActiveCellTool .jp-ActiveCellTool-CellContent {
  background: var(--jp-cell-editor-background);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  border-radius: 0;
  min-height: 29px;
}

.jp-ActiveCellTool .jp-InputPrompt {
  min-width: calc(var(--jp-cell-prompt-width) * 0.75);
}

.jp-ActiveCellTool-CellContent > pre {
  padding: 5px 4px;
  margin: 0;
  white-space: normal;
}

.jp-MetadataEditorTool {
  flex-direction: column;
  padding: 12px 0;
}

.jp-RankedPanel > :not(:first-child) {
  margin-top: 12px;
}

.jp-KeySelector select.jp-mod-styled {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  border: var(--jp-border-width) solid var(--jp-border-color1);
}

.jp-KeySelector label,
.jp-MetadataEditorTool label,
.jp-NumberSetter label {
  line-height: 1.4;
}

.jp-NotebookTools .jp-select-wrapper {
  margin-top: 4px;
  margin-bottom: 0;
}

.jp-NumberSetter input {
  width: 100%;
  margin-top: 4px;
}

.jp-NotebookTools .jp-Collapse {
  margin-top: 16px;
}

/*-----------------------------------------------------------------------------
| Presentation Mode (.jp-mod-presentationMode)
|----------------------------------------------------------------------------*/

.jp-mod-presentationMode .jp-Notebook {
  --jp-content-font-size1: var(--jp-content-presentation-font-size1);
  --jp-code-font-size: var(--jp-code-presentation-font-size);
}

.jp-mod-presentationMode .jp-Notebook .jp-Cell .jp-InputPrompt,
.jp-mod-presentationMode .jp-Notebook .jp-Cell .jp-OutputPrompt {
  flex: 0 0 110px;
}

/*-----------------------------------------------------------------------------
| Side-by-side Mode (.jp-mod-sideBySide)
|----------------------------------------------------------------------------*/
.jp-mod-sideBySide.jp-Notebook .jp-Notebook-cell {
  margin-top: 3em;
  margin-bottom: 3em;
  margin-left: 5%;
  margin-right: 5%;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell {
  display: grid;
  grid-template-columns: minmax(0, 1fr) min-content minmax(
      0,
      var(--jp-side-by-side-output-size)
    );
  grid-template-rows: auto minmax(0, 1fr) auto;
  grid-template-areas:
    'header header header'
    'input handle output'
    'footer footer footer';
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell.jp-mod-resizedCell {
  grid-template-columns: minmax(0, 1fr) min-content minmax(
      0,
      var(--jp-side-by-side-resized-cell)
    );
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellHeader {
  grid-area: header;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-Cell-inputWrapper {
  grid-area: input;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-Cell-outputWrapper {
  /* overwrite the default margin (no vertical separation needed in side by side move */
  margin-top: 0;
  grid-area: output;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellFooter {
  grid-area: footer;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellResizeHandle {
  grid-area: handle;
  user-select: none;
  display: block;
  height: 100%;
  cursor: ew-resize;
  padding: 0 var(--jp-cell-padding);
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellResizeHandle::after {
  content: '';
  display: block;
  background: var(--jp-border-color2);
  height: 100%;
  width: 5px;
}

.jp-mod-sideBySide.jp-Notebook
  .jp-CodeCell.jp-mod-resizedCell
  .jp-CellResizeHandle::after {
  background: var(--jp-border-color0);
}

.jp-CellResizeHandle {
  display: none;
}

/*-----------------------------------------------------------------------------
| Placeholder
|----------------------------------------------------------------------------*/

.jp-Cell-Placeholder {
  padding-left: 55px;
}

.jp-Cell-Placeholder-wrapper {
  background: #fff;
  border: 1px solid;
  border-color: #e5e6e9 #dfe0e4 #d0d1d5;
  border-radius: 4px;
  -webkit-border-radius: 4px;
  margin: 10px 15px;
}

.jp-Cell-Placeholder-wrapper-inner {
  padding: 15px;
  position: relative;
}

.jp-Cell-Placeholder-wrapper-body {
  background-repeat: repeat;
  background-size: 50% auto;
}

.jp-Cell-Placeholder-wrapper-body div {
  background: #f6f7f8;
  background-image: -webkit-linear-gradient(
    left,
    #f6f7f8 0%,
    #edeef1 20%,
    #f6f7f8 40%,
    #f6f7f8 100%
  );
  background-repeat: no-repeat;
  background-size: 800px 104px;
  height: 104px;
  position: absolute;
  right: 15px;
  left: 15px;
  top: 15px;
}

div.jp-Cell-Placeholder-h1 {
  top: 20px;
  height: 20px;
  left: 15px;
  width: 150px;
}

div.jp-Cell-Placeholder-h2 {
  left: 15px;
  top: 50px;
  height: 10px;
  width: 100px;
}

div.jp-Cell-Placeholder-content-1,
div.jp-Cell-Placeholder-content-2,
div.jp-Cell-Placeholder-content-3 {
  left: 15px;
  right: 15px;
  height: 10px;
}

div.jp-Cell-Placeholder-content-1 {
  top: 100px;
}

div.jp-Cell-Placeholder-content-2 {
  top: 120px;
}

div.jp-Cell-Placeholder-content-3 {
  top: 140px;
}

</style>
<style type="text/css">
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*
The following CSS variables define the main, public API for styling JupyterLab.
These variables should be used by all plugins wherever possible. In other
words, plugins should not define custom colors, sizes, etc unless absolutely
necessary. This enables users to change the visual theme of JupyterLab
by changing these variables.

Many variables appear in an ordered sequence (0,1,2,3). These sequences
are designed to work well together, so for example, `--jp-border-color1` should
be used with `--jp-layout-color1`. The numbers have the following meanings:

* 0: super-primary, reserved for special emphasis
* 1: primary, most important under normal situations
* 2: secondary, next most important under normal situations
* 3: tertiary, next most important under normal situations

Throughout JupyterLab, we are mostly following principles from Google's
Material Design when selecting colors. We are not, however, following
all of MD as it is not optimized for dense, information rich UIs.
*/

:root {
  /* Elevation
   *
   * We style box-shadows using Material Design's idea of elevation. These particular numbers are taken from here:
   *
   * https://github.com/material-components/material-components-web
   * https://material-components-web.appspot.com/elevation.html
   */

  --jp-shadow-base-lightness: 0;
  --jp-shadow-umbra-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.2
  );
  --jp-shadow-penumbra-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.14
  );
  --jp-shadow-ambient-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.12
  );
  --jp-elevation-z0: none;
  --jp-elevation-z1: 0 2px 1px -1px var(--jp-shadow-umbra-color),
    0 1px 1px 0 var(--jp-shadow-penumbra-color),
    0 1px 3px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z2: 0 3px 1px -2px var(--jp-shadow-umbra-color),
    0 2px 2px 0 var(--jp-shadow-penumbra-color),
    0 1px 5px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z4: 0 2px 4px -1px var(--jp-shadow-umbra-color),
    0 4px 5px 0 var(--jp-shadow-penumbra-color),
    0 1px 10px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z6: 0 3px 5px -1px var(--jp-shadow-umbra-color),
    0 6px 10px 0 var(--jp-shadow-penumbra-color),
    0 1px 18px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z8: 0 5px 5px -3px var(--jp-shadow-umbra-color),
    0 8px 10px 1px var(--jp-shadow-penumbra-color),
    0 3px 14px 2px var(--jp-shadow-ambient-color);
  --jp-elevation-z12: 0 7px 8px -4px var(--jp-shadow-umbra-color),
    0 12px 17px 2px var(--jp-shadow-penumbra-color),
    0 5px 22px 4px var(--jp-shadow-ambient-color);
  --jp-elevation-z16: 0 8px 10px -5px var(--jp-shadow-umbra-color),
    0 16px 24px 2px var(--jp-shadow-penumbra-color),
    0 6px 30px 5px var(--jp-shadow-ambient-color);
  --jp-elevation-z20: 0 10px 13px -6px var(--jp-shadow-umbra-color),
    0 20px 31px 3px var(--jp-shadow-penumbra-color),
    0 8px 38px 7px var(--jp-shadow-ambient-color);
  --jp-elevation-z24: 0 11px 15px -7px var(--jp-shadow-umbra-color),
    0 24px 38px 3px var(--jp-shadow-penumbra-color),
    0 9px 46px 8px var(--jp-shadow-ambient-color);

  /* Borders
   *
   * The following variables, specify the visual styling of borders in JupyterLab.
   */

  --jp-border-width: 1px;
  --jp-border-color0: var(--md-grey-400);
  --jp-border-color1: var(--md-grey-400);
  --jp-border-color2: var(--md-grey-300);
  --jp-border-color3: var(--md-grey-200);
  --jp-inverse-border-color: var(--md-grey-600);
  --jp-border-radius: 2px;

  /* UI Fonts
   *
   * The UI font CSS variables are used for the typography all of the JupyterLab
   * user interface elements that are not directly user generated content.
   *
   * The font sizing here is done assuming that the body font size of --jp-ui-font-size1
   * is applied to a parent element. When children elements, such as headings, are sized
   * in em all things will be computed relative to that body size.
   */

  --jp-ui-font-scale-factor: 1.2;
  --jp-ui-font-size0: 0.83333em;
  --jp-ui-font-size1: 13px; /* Base font size */
  --jp-ui-font-size2: 1.2em;
  --jp-ui-font-size3: 1.44em;
  --jp-ui-font-family: system-ui, -apple-system, blinkmacsystemfont, 'Segoe UI',
    helvetica, arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji',
    'Segoe UI Symbol';

  /*
   * Use these font colors against the corresponding main layout colors.
   * In a light theme, these go from dark to light.
   */

  /* Defaults use Material Design specification */
  --jp-ui-font-color0: rgba(0, 0, 0, 1);
  --jp-ui-font-color1: rgba(0, 0, 0, 0.87);
  --jp-ui-font-color2: rgba(0, 0, 0, 0.54);
  --jp-ui-font-color3: rgba(0, 0, 0, 0.38);

  /*
   * Use these against the brand/accent/warn/error colors.
   * These will typically go from light to darker, in both a dark and light theme.
   */

  --jp-ui-inverse-font-color0: rgba(255, 255, 255, 1);
  --jp-ui-inverse-font-color1: rgba(255, 255, 255, 1);
  --jp-ui-inverse-font-color2: rgba(255, 255, 255, 0.7);
  --jp-ui-inverse-font-color3: rgba(255, 255, 255, 0.5);

  /* Content Fonts
   *
   * Content font variables are used for typography of user generated content.
   *
   * The font sizing here is done assuming that the body font size of --jp-content-font-size1
   * is applied to a parent element. When children elements, such as headings, are sized
   * in em all things will be computed relative to that body size.
   */

  --jp-content-line-height: 1.6;
  --jp-content-font-scale-factor: 1.2;
  --jp-content-font-size0: 0.83333em;
  --jp-content-font-size1: 14px; /* Base font size */
  --jp-content-font-size2: 1.2em;
  --jp-content-font-size3: 1.44em;
  --jp-content-font-size4: 1.728em;
  --jp-content-font-size5: 2.0736em;

  /* This gives a magnification of about 125% in presentation mode over normal. */
  --jp-content-presentation-font-size1: 17px;
  --jp-content-heading-line-height: 1;
  --jp-content-heading-margin-top: 1.2em;
  --jp-content-heading-margin-bottom: 0.8em;
  --jp-content-heading-font-weight: 500;

  /* Defaults use Material Design specification */
  --jp-content-font-color0: rgba(0, 0, 0, 1);
  --jp-content-font-color1: rgba(0, 0, 0, 0.87);
  --jp-content-font-color2: rgba(0, 0, 0, 0.54);
  --jp-content-font-color3: rgba(0, 0, 0, 0.38);
  --jp-content-link-color: var(--md-blue-900);
  --jp-content-font-family: system-ui, -apple-system, blinkmacsystemfont,
    'Segoe UI', helvetica, arial, sans-serif, 'Apple Color Emoji',
    'Segoe UI Emoji', 'Segoe UI Symbol';

  /*
   * Code Fonts
   *
   * Code font variables are used for typography of code and other monospaces content.
   */

  --jp-code-font-size: 13px;
  --jp-code-line-height: 1.3077; /* 17px for 13px base */
  --jp-code-padding: 5px; /* 5px for 13px base, codemirror highlighting needs integer px value */
  --jp-code-font-family-default: menlo, consolas, 'DejaVu Sans Mono', monospace;
  --jp-code-font-family: var(--jp-code-font-family-default);

  /* This gives a magnification of about 125% in presentation mode over normal. */
  --jp-code-presentation-font-size: 16px;

  /* may need to tweak cursor width if you change font size */
  --jp-code-cursor-width0: 1.4px;
  --jp-code-cursor-width1: 2px;
  --jp-code-cursor-width2: 4px;

  /* Layout
   *
   * The following are the main layout colors use in JupyterLab. In a light
   * theme these would go from light to dark.
   */

  --jp-layout-color0: white;
  --jp-layout-color1: white;
  --jp-layout-color2: var(--md-grey-200);
  --jp-layout-color3: var(--md-grey-400);
  --jp-layout-color4: var(--md-grey-600);

  /* Inverse Layout
   *
   * The following are the inverse layout colors use in JupyterLab. In a light
   * theme these would go from dark to light.
   */

  --jp-inverse-layout-color0: #111;
  --jp-inverse-layout-color1: var(--md-grey-900);
  --jp-inverse-layout-color2: var(--md-grey-800);
  --jp-inverse-layout-color3: var(--md-grey-700);
  --jp-inverse-layout-color4: var(--md-grey-600);

  /* Brand/accent */

  --jp-brand-color0: var(--md-blue-900);
  --jp-brand-color1: var(--md-blue-700);
  --jp-brand-color2: var(--md-blue-300);
  --jp-brand-color3: var(--md-blue-100);
  --jp-brand-color4: var(--md-blue-50);
  --jp-accent-color0: var(--md-green-900);
  --jp-accent-color1: var(--md-green-700);
  --jp-accent-color2: var(--md-green-300);
  --jp-accent-color3: var(--md-green-100);

  /* State colors (warn, error, success, info) */

  --jp-warn-color0: var(--md-orange-900);
  --jp-warn-color1: var(--md-orange-700);
  --jp-warn-color2: var(--md-orange-300);
  --jp-warn-color3: var(--md-orange-100);
  --jp-error-color0: var(--md-red-900);
  --jp-error-color1: var(--md-red-700);
  --jp-error-color2: var(--md-red-300);
  --jp-error-color3: var(--md-red-100);
  --jp-success-color0: var(--md-green-900);
  --jp-success-color1: var(--md-green-700);
  --jp-success-color2: var(--md-green-300);
  --jp-success-color3: var(--md-green-100);
  --jp-info-color0: var(--md-cyan-900);
  --jp-info-color1: var(--md-cyan-700);
  --jp-info-color2: var(--md-cyan-300);
  --jp-info-color3: var(--md-cyan-100);

  /* Cell specific styles */

  --jp-cell-padding: 5px;
  --jp-cell-collapser-width: 8px;
  --jp-cell-collapser-min-height: 20px;
  --jp-cell-collapser-not-active-hover-opacity: 0.6;
  --jp-cell-editor-background: var(--md-grey-100);
  --jp-cell-editor-border-color: var(--md-grey-300);
  --jp-cell-editor-box-shadow: inset 0 0 2px var(--md-blue-300);
  --jp-cell-editor-active-background: var(--jp-layout-color0);
  --jp-cell-editor-active-border-color: var(--jp-brand-color1);
  --jp-cell-prompt-width: 64px;
  --jp-cell-prompt-font-family: var(--jp-code-font-family-default);
  --jp-cell-prompt-letter-spacing: 0;
  --jp-cell-prompt-opacity: 1;
  --jp-cell-prompt-not-active-opacity: 0.5;
  --jp-cell-prompt-not-active-font-color: var(--md-grey-700);

  /* A custom blend of MD grey and blue 600
   * See https://meyerweb.com/eric/tools/color-blend/#546E7A:1E88E5:5:hex */
  --jp-cell-inprompt-font-color: #307fc1;

  /* A custom blend of MD grey and orange 600
   * https://meyerweb.com/eric/tools/color-blend/#546E7A:F4511E:5:hex */
  --jp-cell-outprompt-font-color: #bf5b3d;

  /* Notebook specific styles */

  --jp-notebook-padding: 10px;
  --jp-notebook-select-background: var(--jp-layout-color1);
  --jp-notebook-multiselected-color: var(--md-blue-50);

  /* The scroll padding is calculated to fill enough space at the bottom of the
  notebook to show one single-line cell (with appropriate padding) at the top
  when the notebook is scrolled all the way to the bottom. We also subtract one
  pixel so that no scrollbar appears if we have just one single-line cell in the
  notebook. This padding is to enable a 'scroll past end' feature in a notebook.
  */
  --jp-notebook-scroll-padding: calc(
    100% - var(--jp-code-font-size) * var(--jp-code-line-height) -
      var(--jp-code-padding) - var(--jp-cell-padding) - 1px
  );

  /* Rendermime styles */

  --jp-rendermime-error-background: #fdd;
  --jp-rendermime-table-row-background: var(--md-grey-100);
  --jp-rendermime-table-row-hover-background: var(--md-light-blue-50);

  /* Dialog specific styles */

  --jp-dialog-background: rgba(0, 0, 0, 0.25);

  /* Console specific styles */

  --jp-console-padding: 10px;

  /* Toolbar specific styles */

  --jp-toolbar-border-color: var(--jp-border-color1);
  --jp-toolbar-micro-height: 8px;
  --jp-toolbar-background: var(--jp-layout-color1);
  --jp-toolbar-box-shadow: 0 0 2px 0 rgba(0, 0, 0, 0.24);
  --jp-toolbar-header-margin: 4px 4px 0 4px;
  --jp-toolbar-active-background: var(--md-grey-300);

  /* Statusbar specific styles */

  --jp-statusbar-height: 24px;

  /* Input field styles */

  --jp-input-box-shadow: inset 0 0 2px var(--md-blue-300);
  --jp-input-active-background: var(--jp-layout-color1);
  --jp-input-hover-background: var(--jp-layout-color1);
  --jp-input-background: var(--md-grey-100);
  --jp-input-border-color: var(--jp-inverse-border-color);
  --jp-input-active-border-color: var(--jp-brand-color1);
  --jp-input-active-box-shadow-color: rgba(19, 124, 189, 0.3);

  /* General editor styles */

  --jp-editor-selected-background: #d9d9d9;
  --jp-editor-selected-focused-background: #d7d4f0;
  --jp-editor-cursor-color: var(--jp-ui-font-color0);

  /* Code mirror specific styles */

  --jp-mirror-editor-keyword-color: #008000;
  --jp-mirror-editor-atom-color: #88f;
  --jp-mirror-editor-number-color: #080;
  --jp-mirror-editor-def-color: #00f;
  --jp-mirror-editor-variable-color: var(--md-grey-900);
  --jp-mirror-editor-variable-2-color: rgb(0, 54, 109);
  --jp-mirror-editor-variable-3-color: #085;
  --jp-mirror-editor-punctuation-color: #05a;
  --jp-mirror-editor-property-color: #05a;
  --jp-mirror-editor-operator-color: #a2f;
  --jp-mirror-editor-comment-color: #408080;
  --jp-mirror-editor-string-color: #ba2121;
  --jp-mirror-editor-string-2-color: #708;
  --jp-mirror-editor-meta-color: #a2f;
  --jp-mirror-editor-qualifier-color: #555;
  --jp-mirror-editor-builtin-color: #008000;
  --jp-mirror-editor-bracket-color: #997;
  --jp-mirror-editor-tag-color: #170;
  --jp-mirror-editor-attribute-color: #00c;
  --jp-mirror-editor-header-color: blue;
  --jp-mirror-editor-quote-color: #090;
  --jp-mirror-editor-link-color: #00c;
  --jp-mirror-editor-error-color: #f00;
  --jp-mirror-editor-hr-color: #999;

  /*
    RTC user specific colors.
    These colors are used for the cursor, username in the editor,
    and the icon of the user.
  */

  --jp-collaborator-color1: #ffad8e;
  --jp-collaborator-color2: #dac83d;
  --jp-collaborator-color3: #72dd76;
  --jp-collaborator-color4: #00e4d0;
  --jp-collaborator-color5: #45d4ff;
  --jp-collaborator-color6: #e2b1ff;
  --jp-collaborator-color7: #ff9de6;

  /* Vega extension styles */

  --jp-vega-background: white;

  /* Sidebar-related styles */

  --jp-sidebar-min-width: 250px;

  /* Search-related styles */

  --jp-search-toggle-off-opacity: 0.5;
  --jp-search-toggle-hover-opacity: 0.8;
  --jp-search-toggle-on-opacity: 1;
  --jp-search-selected-match-background-color: rgb(245, 200, 0);
  --jp-search-selected-match-color: black;
  --jp-search-unselected-match-background-color: var(
    --jp-inverse-layout-color0
  );
  --jp-search-unselected-match-color: var(--jp-ui-inverse-font-color0);

  /* Icon colors that work well with light or dark backgrounds */
  --jp-icon-contrast-color0: var(--md-purple-600);
  --jp-icon-contrast-color1: var(--md-green-600);
  --jp-icon-contrast-color2: var(--md-pink-600);
  --jp-icon-contrast-color3: var(--md-blue-600);

  /* Button colors */
  --jp-accept-color-normal: var(--md-blue-700);
  --jp-accept-color-hover: var(--md-blue-800);
  --jp-accept-color-active: var(--md-blue-900);
  --jp-warn-color-normal: var(--md-red-700);
  --jp-warn-color-hover: var(--md-red-800);
  --jp-warn-color-active: var(--md-red-900);
  --jp-reject-color-normal: var(--md-grey-600);
  --jp-reject-color-hover: var(--md-grey-700);
  --jp-reject-color-active: var(--md-grey-800);

  /* File or activity icons and switch semantic variables */
  --jp-jupyter-icon-color: #f37626;
  --jp-notebook-icon-color: #f37626;
  --jp-json-icon-color: var(--md-orange-700);
  --jp-console-icon-background-color: var(--md-blue-700);
  --jp-console-icon-color: white;
  --jp-terminal-icon-background-color: var(--md-grey-800);
  --jp-terminal-icon-color: var(--md-grey-200);
  --jp-text-editor-icon-color: var(--md-grey-700);
  --jp-inspector-icon-color: var(--md-grey-700);
  --jp-switch-color: var(--md-grey-400);
  --jp-switch-true-position-color: var(--md-orange-900);
}
</style>
<style type="text/css">
/* Force rendering true colors when outputing to pdf */
* {
  -webkit-print-color-adjust: exact;
}

/* Misc */
a.anchor-link {
  display: none;
}

/* Input area styling */
.jp-InputArea {
  overflow: hidden;
}

.jp-InputArea-editor {
  overflow: hidden;
}

.cm-editor.cm-s-jupyter .highlight pre {
/* weird, but --jp-code-padding defined to be 5px but 4px horizontal padding is hardcoded for pre.cm-line */
  padding: var(--jp-code-padding) 4px;
  margin: 0;

  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
  color: inherit;

}

.jp-OutputArea-output pre {
  line-height: inherit;
  font-family: inherit;
}

.jp-RenderedText pre {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-code-font-size);
}

/* Hiding the collapser by default */
.jp-Collapser {
  display: none;
}

@page {
    margin: 0.5in; /* Margin for each printed piece of paper */
}

@media print {
  .jp-Cell-inputWrapper,
  .jp-Cell-outputWrapper {
    display: block;
  }
}
</style>
<!-- Load mathjax -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML-full,Safe"> </script>
<!-- MathJax configuration -->
<script type="text/x-mathjax-config">
    init_mathjax = function() {
        if (window.MathJax) {
        // MathJax loaded
            MathJax.Hub.Config({
                TeX: {
                    equationNumbers: {
                    autoNumber: "AMS",
                    useLabelIds: true
                    }
                },
                tex2jax: {
                    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                    processEscapes: true,
                    processEnvironments: true
                },
                displayAlign: 'center',
                CommonHTML: {
                    linebreaks: {
                    automatic: true
                    }
                }
            });

            MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
        }
    }
    init_mathjax();
    </script>
<!-- End of mathjax configuration --><script type="module">
  document.addEventListener("DOMContentLoaded", async () => {
    const diagrams = document.querySelectorAll(".jp-Mermaid > pre.mermaid");
    // do not load mermaidjs if not needed
    if (!diagrams.length) {
      return;
    }
    const mermaid = (await import("https://cdnjs.cloudflare.com/ajax/libs/mermaid/10.7.0/mermaid.esm.min.mjs")).default;
    const parser = new DOMParser();

    mermaid.initialize({
      maxTextSize: 100000,
      maxEdges: 100000,
      startOnLoad: false,
      fontFamily: window
        .getComputedStyle(document.body)
        .getPropertyValue("--jp-ui-font-family"),
      theme: document.querySelector("body[data-jp-theme-light='true']")
        ? "default"
        : "dark",
    });

    let _nextMermaidId = 0;

    function makeMermaidImage(svg) {
      const img = document.createElement("img");
      const doc = parser.parseFromString(svg, "image/svg+xml");
      const svgEl = doc.querySelector("svg");
      const { maxWidth } = svgEl?.style || {};
      const firstTitle = doc.querySelector("title");
      const firstDesc = doc.querySelector("desc");

      img.setAttribute("src", `data:image/svg+xml,${encodeURIComponent(svg)}`);
      if (maxWidth) {
        img.width = parseInt(maxWidth);
      }
      if (firstTitle) {
        img.setAttribute("alt", firstTitle.textContent);
      }
      if (firstDesc) {
        const caption = document.createElement("figcaption");
        caption.className = "sr-only";
        caption.textContent = firstDesc.textContent;
        return [img, caption];
      }
      return [img];
    }

    async function makeMermaidError(text) {
      let errorMessage = "";
      try {
        await mermaid.parse(text);
      } catch (err) {
        errorMessage = `${err}`;
      }

      const result = document.createElement("details");
      result.className = 'jp-RenderedMermaid-Details';
      const summary = document.createElement("summary");
      summary.className = 'jp-RenderedMermaid-Summary';
      const pre = document.createElement("pre");
      const code = document.createElement("code");
      code.innerText = text;
      pre.appendChild(code);
      summary.appendChild(pre);
      result.appendChild(summary);

      const warning = document.createElement("pre");
      warning.innerText = errorMessage;
      result.appendChild(warning);
      return [result];
    }

    async function renderOneMarmaid(src) {
      const id = `jp-mermaid-${_nextMermaidId++}`;
      const parent = src.parentNode;
      let raw = src.textContent.trim();
      const el = document.createElement("div");
      el.style.visibility = "hidden";
      document.body.appendChild(el);
      let results = null;
      let output = null;
      try {
        let { svg } = await mermaid.render(id, raw, el);
        svg = cleanMermaidSvg(svg);
        results = makeMermaidImage(svg);
        output = document.createElement("figure");
        results.map(output.appendChild, output);
      } catch (err) {
        parent.classList.add("jp-mod-warning");
        results = await makeMermaidError(raw);
        output = results[0];
      } finally {
        el.remove();
      }
      parent.classList.add("jp-RenderedMermaid");
      parent.appendChild(output);
    }


    /**
     * Post-process to ensure mermaid diagrams contain only valid SVG and XHTML.
     */
    function cleanMermaidSvg(svg) {
      return svg.replace(RE_VOID_ELEMENT, replaceVoidElement);
    }


    /**
     * A regular expression for all void elements, which may include attributes and
     * a slash.
     *
     * @see https://developer.mozilla.org/en-US/docs/Glossary/Void_element
     *
     * Of these, only `<br>` is generated by Mermaid in place of `\n`,
     * but _any_ "malformed" tag will break the SVG rendering entirely.
     */
    const RE_VOID_ELEMENT =
      /<\s*(area|base|br|col|embed|hr|img|input|link|meta|param|source|track|wbr)\s*([^>]*?)\s*>/gi;

    /**
     * Ensure a void element is closed with a slash, preserving any attributes.
     */
    function replaceVoidElement(match, tag, rest) {
      rest = rest.trim();
      if (!rest.endsWith('/')) {
        rest = `${rest} /`;
      }
      return `<${tag} ${rest}>`;
    }

    void Promise.all([...diagrams].map(renderOneMarmaid));
  });
</script>
<style>
  .jp-Mermaid:not(.jp-RenderedMermaid) {
    display: none;
  }

  .jp-RenderedMermaid {
    overflow: auto;
    display: flex;
  }

  .jp-RenderedMermaid.jp-mod-warning {
    width: auto;
    padding: 0.5em;
    margin-top: 0.5em;
    border: var(--jp-border-width) solid var(--jp-warn-color2);
    border-radius: var(--jp-border-radius);
    color: var(--jp-ui-font-color1);
    font-size: var(--jp-ui-font-size1);
    white-space: pre-wrap;
    word-wrap: break-word;
  }

  .jp-RenderedMermaid figure {
    margin: 0;
    overflow: auto;
    max-width: 100%;
  }

  .jp-RenderedMermaid img {
    max-width: 100%;
  }

  .jp-RenderedMermaid-Details > pre {
    margin-top: 1em;
  }

  .jp-RenderedMermaid-Summary {
    color: var(--jp-warn-color2);
  }

  .jp-RenderedMermaid:not(.jp-mod-warning) pre {
    display: none;
  }

  .jp-RenderedMermaid-Summary > pre {
    display: inline-block;
    white-space: normal;
  }
</style>
<!-- End of mermaid configuration --></head>
<body class="jp-Notebook" data-jp-theme-light="true" data-jp-theme-name="JupyterLab Light">
<main>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p><a href="https://colab.research.google.com/github/zphilip/zphilip.github.io/blob/main/Inspect_BERT_Vocabulary.ipynb" target="_parent"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg"/></a></p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Load-the-Model">Load the Model<a class="anchor-link" href="#Load-the-Model">¶</a></h2>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>Install the huggingface implementation.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [2]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>pytorch-pretrained-bert
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Requirement already satisfied: pytorch-pretrained-bert in /usr/local/lib/python3.10/dist-packages (0.6.2)
Requirement already satisfied: torch&gt;=0.4.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-bert) (2.0.0+cu118)
Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-bert) (1.22.4)
Requirement already satisfied: boto3 in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-bert) (1.26.133)
Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-bert) (2.27.1)
Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-bert) (4.65.0)
Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-bert) (2022.10.31)
Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch&gt;=0.4.1-&gt;pytorch-pretrained-bert) (3.12.0)
Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch&gt;=0.4.1-&gt;pytorch-pretrained-bert) (4.5.0)
Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch&gt;=0.4.1-&gt;pytorch-pretrained-bert) (1.11.1)
Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch&gt;=0.4.1-&gt;pytorch-pretrained-bert) (3.1)
Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch&gt;=0.4.1-&gt;pytorch-pretrained-bert) (3.1.2)
Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch&gt;=0.4.1-&gt;pytorch-pretrained-bert) (2.0.0)
Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0-&gt;torch&gt;=0.4.1-&gt;pytorch-pretrained-bert) (3.25.2)
Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0-&gt;torch&gt;=0.4.1-&gt;pytorch-pretrained-bert) (16.0.3)
Requirement already satisfied: botocore&lt;1.30.0,&gt;=1.29.133 in /usr/local/lib/python3.10/dist-packages (from boto3-&gt;pytorch-pretrained-bert) (1.29.133)
Requirement already satisfied: jmespath&lt;2.0.0,&gt;=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3-&gt;pytorch-pretrained-bert) (1.0.1)
Requirement already satisfied: s3transfer&lt;0.7.0,&gt;=0.6.0 in /usr/local/lib/python3.10/dist-packages (from boto3-&gt;pytorch-pretrained-bert) (0.6.1)
Requirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;pytorch-pretrained-bert) (1.26.15)
Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;pytorch-pretrained-bert) (2022.12.7)
Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;pytorch-pretrained-bert) (2.0.12)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;pytorch-pretrained-bert) (3.4)
Requirement already satisfied: python-dateutil&lt;3.0.0,&gt;=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore&lt;1.30.0,&gt;=1.29.133-&gt;boto3-&gt;pytorch-pretrained-bert) (2.8.2)
Requirement already satisfied: MarkupSafe&gt;=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-&gt;torch&gt;=0.4.1-&gt;pytorch-pretrained-bert) (2.1.2)
Requirement already satisfied: mpmath&gt;=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy-&gt;torch&gt;=0.4.1-&gt;pytorch-pretrained-bert) (1.3.0)
Requirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil&lt;3.0.0,&gt;=2.1-&gt;botocore&lt;1.30.0,&gt;=1.29.133-&gt;boto3-&gt;pytorch-pretrained-bert) (1.16.0)
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [3]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">pytorch_pretrained_bert</span> <span class="kn">import</span> <span class="n">BertTokenizer</span>

<span class="c1"># Load pre-trained model tokenizer (vocabulary)</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">BertTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">'bert-base-uncased'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>100%|██████████| 231508/231508 [00:00&lt;00:00, 3719237.97B/s]
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Inspect-BERT-Vocabulary">Inspect BERT Vocabulary<a class="anchor-link" href="#Inspect-BERT-Vocabulary">¶</a></h2><hr/>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="Vocab-Dump">Vocab Dump<a class="anchor-link" href="#Vocab-Dump">¶</a></h3><hr/>
<p>Retrieve the entire list of "tokens" and write these out to text files so we can peruse them.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [32]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">"vocabulary.txt"</span><span class="p">,</span> <span class="s1">'w'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    
    <span class="c1"># For each token...</span>
    <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        
        <span class="c1"># Write it out and escape any unicode characters.            </span>
        <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">token</span> <span class="o">+</span> <span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>From perusing the vocab, I'm seeing that:</p>
<ul>
<li>The first 999 tokens (1-indexed) appear to be reserved, and most are of the form [unused957].<ul>
<li>1   - [PAD]</li>
<li>101 - [UNK]</li>
<li>102 - [CLS]</li>
<li>103 - [SEP]</li>
<li>104 - [MASK]</li>
</ul>
</li>
<li>Rows 1000-1996 appear to be a dump of individual characters.<ul>
<li>They don't appear to be sorted by frequency (e.g., the letters of the alphabet are all in sequence).</li>
</ul>
</li>
<li>The first word is "the" at position 1997.<ul>
<li>From there, the words appear to be sorted by frequency.</li>
<li>The top ~18 words are whole words, and then number 2016 is ##s, presumably the most common subword.</li>
<li>The last whole word is at 29612, "necessitated"</li>
</ul>
</li>
</ul>
<p>Some funny inclusions:</p>
<ul>
<li>starbucks</li>
<li>triassic</li>
<li>abolitionist</li>
<li>1679</li>
</ul>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="Single-Characters">Single Characters<a class="anchor-link" href="#Single-Characters">¶</a></h3><hr/>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>The following code prints out all of the single character tokens in vocabulary, as well as all of the single-character tokens preceded by '##'.</p>
<p>It turns out that these are matching sets--for every standalone character there is also a '##' version. There are 997 single character tokens.</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>The following cell iterates over the vocabulary, pulling out all of the single character tokens.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [33]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">one_chars</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">one_chars_hashes</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># For each token in the vocabulary...</span>
<span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
    
    <span class="c1"># Record any single-character tokens.</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">token</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">one_chars</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">token</span><span class="p">)</span>
    
    <span class="c1"># Record single-character tokens preceded by the two hashes.    </span>
    <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">token</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span> <span class="ow">and</span> <span class="n">token</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">]</span> <span class="o">==</span> <span class="s1">'##'</span><span class="p">:</span>
        <span class="n">one_chars_hashes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">token</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [34]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">'Number of single character tokens:'</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">one_chars</span><span class="p">),</span> <span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>

<span class="c1"># Print all of the single characters, 40 per row.</span>

<span class="c1"># For every batch of 40 tokens...</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">one_chars</span><span class="p">),</span> <span class="mi">40</span><span class="p">):</span>
    
    <span class="c1"># Limit the end index so we don't go past the end of the list.</span>
    <span class="n">end</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">40</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">one_chars</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    
    <span class="c1"># Print out the tokens, separated by a space.</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">' '</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">one_chars</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">end</span><span class="p">]))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Number of single character tokens: 997 

! " # $ % &amp; ' ( ) * + , - . / 0 1 2 3 4 5 6 7 8 9 : ; &lt; = &gt; ? @ [ \ ] ^ _ ` a b
c d e f g h i j k l m n o p q r s t u v w x y z { | } ~ ¡ ¢ £ ¤ ¥ ¦ § ¨ © ª « ¬
® ° ± ² ³ ´ µ ¶ · ¹ º » ¼ ½ ¾ ¿ × ß æ ð ÷ ø þ đ ħ ı ł ŋ œ ƒ ɐ ɑ ɒ ɔ ɕ ə ɛ ɡ ɣ ɨ
ɪ ɫ ɬ ɯ ɲ ɴ ɹ ɾ ʀ ʁ ʂ ʃ ʉ ʊ ʋ ʌ ʎ ʐ ʑ ʒ ʔ ʰ ʲ ʳ ʷ ʸ ʻ ʼ ʾ ʿ ˈ ː ˡ ˢ ˣ ˤ α β γ δ
ε ζ η θ ι κ λ μ ν ξ ο π ρ ς σ τ υ φ χ ψ ω а б в г д е ж з и к л м н о п р с т у
ф х ц ч ш щ ъ ы ь э ю я ђ є і ј љ њ ћ ӏ ա բ գ դ ե թ ի լ կ հ մ յ ն ո պ ս վ տ ր ւ
ք ־ א ב ג ד ה ו ז ח ט י ך כ ל ם מ ן נ ס ע ף פ ץ צ ק ר ש ת ، ء ا ب ة ت ث ج ح خ د
ذ ر ز س ش ص ض ط ظ ع غ ـ ف ق ك ل م ن ه و ى ي ٹ پ چ ک گ ں ھ ہ ی ے अ आ उ ए क ख ग च
ज ट ड ण त थ द ध न प ब भ म य र ल व श ष स ह ा ि ी ो । ॥ ং অ আ ই উ এ ও ক খ গ চ ছ জ
ট ড ণ ত থ দ ধ ন প ব ভ ম য র ল শ ষ স হ া ি ী ে க ச ட த ந ன ப ம ய ர ல ள வ ா ி ு ே
ை ನ ರ ಾ ක ය ර ල ව ා ก ง ต ท น พ ม ย ร ล ว ส อ า เ ་ ། ག ང ད ན པ བ མ འ ར ལ ས မ ა
ბ გ დ ე ვ თ ი კ ლ მ ნ ო რ ს ტ უ ᄀ ᄂ ᄃ ᄅ ᄆ ᄇ ᄉ ᄊ ᄋ ᄌ ᄎ ᄏ ᄐ ᄑ ᄒ ᅡ ᅢ ᅥ ᅦ ᅧ ᅩ ᅪ ᅭ ᅮ
ᅯ ᅲ ᅳ ᅴ ᅵ ᆨ ᆫ ᆯ ᆷ ᆸ ᆼ ᴬ ᴮ ᴰ ᴵ ᴺ ᵀ ᵃ ᵇ ᵈ ᵉ ᵍ ᵏ ᵐ ᵒ ᵖ ᵗ ᵘ ᵢ ᵣ ᵤ ᵥ ᶜ ᶠ ‐ ‑ ‒ – — ―
‖ ‘ ’ ‚ “ ” „ † ‡ • … ‰ ′ ″ › ‿ ⁄ ⁰ ⁱ ⁴ ⁵ ⁶ ⁷ ⁸ ⁹ ⁺ ⁻ ⁿ ₀ ₁ ₂ ₃ ₄ ₅ ₆ ₇ ₈ ₉ ₊ ₍
₎ ₐ ₑ ₒ ₓ ₕ ₖ ₗ ₘ ₙ ₚ ₛ ₜ ₤ ₩ € ₱ ₹ ℓ № ℝ ™ ⅓ ⅔ ← ↑ → ↓ ↔ ↦ ⇄ ⇌ ⇒ ∂ ∅ ∆ ∇ ∈ − ∗
∘ √ ∞ ∧ ∨ ∩ ∪ ≈ ≡ ≤ ≥ ⊂ ⊆ ⊕ ⊗ ⋅ ─ │ ■ ▪ ● ★ ☆ ☉ ♠ ♣ ♥ ♦ ♭ ♯ ⟨ ⟩ ⱼ ⺩ ⺼ ⽥ 、 。 〈 〉
《 》 「 」 『 』 〜 あ い う え お か き く け こ さ し す せ そ た ち っ つ て と な に ぬ ね の は ひ ふ へ ほ ま み
む め も や ゆ よ ら り る れ ろ を ん ァ ア ィ イ ウ ェ エ オ カ キ ク ケ コ サ シ ス セ タ チ ッ ツ テ ト ナ ニ ノ ハ
ヒ フ ヘ ホ マ ミ ム メ モ ャ ュ ョ ラ リ ル レ ロ ワ ン ・ ー 一 三 上 下 不 世 中 主 久 之 也 事 二 五 井 京 人 亻 仁
介 代 仮 伊 会 佐 侍 保 信 健 元 光 八 公 内 出 分 前 劉 力 加 勝 北 区 十 千 南 博 原 口 古 史 司 合 吉 同 名 和 囗 四
国 國 土 地 坂 城 堂 場 士 夏 外 大 天 太 夫 奈 女 子 学 宀 宇 安 宗 定 宣 宮 家 宿 寺 將 小 尚 山 岡 島 崎 川 州 巿 帝
平 年 幸 广 弘 張 彳 後 御 德 心 忄 志 忠 愛 成 我 戦 戸 手 扌 政 文 新 方 日 明 星 春 昭 智 曲 書 月 有 朝 木 本 李 村
東 松 林 森 楊 樹 橋 歌 止 正 武 比 氏 民 水 氵 氷 永 江 沢 河 治 法 海 清 漢 瀬 火 版 犬 王 生 田 男 疒 発 白 的 皇 目
相 省 真 石 示 社 神 福 禾 秀 秋 空 立 章 竹 糹 美 義 耳 良 艹 花 英 華 葉 藤 行 街 西 見 訁 語 谷 貝 貴 車 軍 辶 道 郎
郡 部 都 里 野 金 鈴 镇 長 門 間 阝 阿 陳 陽 雄 青 面 風 食 香 馬 高 龍 龸 ﬁ ﬂ ！ （ ） ， － ． ／ ： ？ ～
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [35]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">'Number of single character tokens with hashes:'</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">one_chars_hashes</span><span class="p">),</span> <span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>

<span class="c1"># Print all of the single characters, 40 per row.</span>

<span class="c1"># Strip the hash marks, since they just clutter the display.</span>
<span class="n">tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">token</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">'##'</span><span class="p">,</span> <span class="s1">''</span><span class="p">)</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">one_chars_hashes</span><span class="p">]</span>

<span class="c1"># For every batch of 40 tokens...</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">),</span> <span class="mi">40</span><span class="p">):</span>
    
    <span class="c1"># Limit the end index so we don't go past the end of the list.</span>
    <span class="n">end</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">40</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    
    <span class="c1"># Print out the tokens, separated by a space.</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">' '</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tokens</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">end</span><span class="p">]))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Number of single character tokens with hashes: 997 

s a e i n o d r y t l m u h k c g p 2 z 1 b 3 f 4 6 7 x v 8 5 9 0 w j q ° ₂ а и
² ₃ ı ₁ ⁺ ½ о ه ي α е د ن ν ø р ₄ ₀ ر я ³ ι ł н ᵢ ₙ ß ة ς م − т ː ل ь к ♭ η ی в
ا × ¹ ы ה ɛ л ! " # $ % &amp; ' ( ) * + , - . / : ; &lt; = &gt; ? @ [ \ ] ^ _ ` { | } ~ ¡
¢ £ ¤ ¥ ¦ § ¨ © ª « ¬ ® ± ´ µ ¶ · º » ¼ ¾ ¿ æ ð ÷ þ đ ħ ŋ œ ƒ ɐ ɑ ɒ ɔ ɕ ə ɡ ɣ ɨ
ɪ ɫ ɬ ɯ ɲ ɴ ɹ ɾ ʀ ʁ ʂ ʃ ʉ ʊ ʋ ʌ ʎ ʐ ʑ ʒ ʔ ʰ ʲ ʳ ʷ ʸ ʻ ʼ ʾ ʿ ˈ ˡ ˢ ˣ ˤ β γ δ ε ζ
θ κ λ μ ξ ο π ρ σ τ υ φ χ ψ ω б г д ж з м п с у ф х ц ч ш щ ъ э ю ђ є і ј љ њ ћ
ӏ ա բ գ դ ե թ ի լ կ հ մ յ ն ո պ ս վ տ ր ւ ք ־ א ב ג ד ו ז ח ט י ך כ ל ם מ ן נ ס
ע ף פ ץ צ ק ר ש ת ، ء ب ت ث ج ح خ ذ ز س ش ص ض ط ظ ع غ ـ ف ق ك و ى ٹ پ چ ک گ ں ھ
ہ ے अ आ उ ए क ख ग च ज ट ड ण त थ द ध न प ब भ म य र ल व श ष स ह ा ि ी ो । ॥ ং অ আ
ই উ এ ও ক খ গ চ ছ জ ট ড ণ ত থ দ ধ ন প ব ভ ম য র ল শ ষ স হ া ি ী ে க ச ட த ந ன ப
ம ய ர ல ள வ ா ி ு ே ை ನ ರ ಾ ක ය ර ල ව ා ก ง ต ท น พ ม ย ร ล ว ส อ า เ ་ ། ག ང ད
ན པ བ མ འ ར ལ ས မ ა ბ გ დ ე ვ თ ი კ ლ მ ნ ო რ ს ტ უ ᄀ ᄂ ᄃ ᄅ ᄆ ᄇ ᄉ ᄊ ᄋ ᄌ ᄎ ᄏ ᄐ ᄑ
ᄒ ᅡ ᅢ ᅥ ᅦ ᅧ ᅩ ᅪ ᅭ ᅮ ᅯ ᅲ ᅳ ᅴ ᅵ ᆨ ᆫ ᆯ ᆷ ᆸ ᆼ ᴬ ᴮ ᴰ ᴵ ᴺ ᵀ ᵃ ᵇ ᵈ ᵉ ᵍ ᵏ ᵐ ᵒ ᵖ ᵗ ᵘ ᵣ ᵤ
ᵥ ᶜ ᶠ ‐ ‑ ‒ – — ― ‖ ‘ ’ ‚ “ ” „ † ‡ • … ‰ ′ ″ › ‿ ⁄ ⁰ ⁱ ⁴ ⁵ ⁶ ⁷ ⁸ ⁹ ⁻ ⁿ ₅ ₆ ₇ ₈
₉ ₊ ₍ ₎ ₐ ₑ ₒ ₓ ₕ ₖ ₗ ₘ ₚ ₛ ₜ ₤ ₩ € ₱ ₹ ℓ № ℝ ™ ⅓ ⅔ ← ↑ → ↓ ↔ ↦ ⇄ ⇌ ⇒ ∂ ∅ ∆ ∇ ∈
∗ ∘ √ ∞ ∧ ∨ ∩ ∪ ≈ ≡ ≤ ≥ ⊂ ⊆ ⊕ ⊗ ⋅ ─ │ ■ ▪ ● ★ ☆ ☉ ♠ ♣ ♥ ♦ ♯ ⟨ ⟩ ⱼ ⺩ ⺼ ⽥ 、 。 〈 〉
《 》 「 」 『 』 〜 あ い う え お か き く け こ さ し す せ そ た ち っ つ て と な に ぬ ね の は ひ ふ へ ほ ま み
む め も や ゆ よ ら り る れ ろ を ん ァ ア ィ イ ウ ェ エ オ カ キ ク ケ コ サ シ ス セ タ チ ッ ツ テ ト ナ ニ ノ ハ
ヒ フ ヘ ホ マ ミ ム メ モ ャ ュ ョ ラ リ ル レ ロ ワ ン ・ ー 一 三 上 下 不 世 中 主 久 之 也 事 二 五 井 京 人 亻 仁
介 代 仮 伊 会 佐 侍 保 信 健 元 光 八 公 内 出 分 前 劉 力 加 勝 北 区 十 千 南 博 原 口 古 史 司 合 吉 同 名 和 囗 四
国 國 土 地 坂 城 堂 場 士 夏 外 大 天 太 夫 奈 女 子 学 宀 宇 安 宗 定 宣 宮 家 宿 寺 將 小 尚 山 岡 島 崎 川 州 巿 帝
平 年 幸 广 弘 張 彳 後 御 德 心 忄 志 忠 愛 成 我 戦 戸 手 扌 政 文 新 方 日 明 星 春 昭 智 曲 書 月 有 朝 木 本 李 村
東 松 林 森 楊 樹 橋 歌 止 正 武 比 氏 民 水 氵 氷 永 江 沢 河 治 法 海 清 漢 瀬 火 版 犬 王 生 田 男 疒 発 白 的 皇 目
相 省 真 石 示 社 神 福 禾 秀 秋 空 立 章 竹 糹 美 義 耳 良 艹 花 英 華 葉 藤 行 街 西 見 訁 語 谷 貝 貴 車 軍 辶 道 郎
郡 部 都 里 野 金 鈴 镇 長 門 間 阝 阿 陳 陽 雄 青 面 風 食 香 馬 高 龍 龸 ﬁ ﬂ ！ （ ） ， － ． ／ ： ？ ～
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [36]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">'Are the two sets identical?'</span><span class="p">,</span> <span class="nb">set</span><span class="p">(</span><span class="n">one_chars</span><span class="p">)</span> <span class="o">==</span> <span class="nb">set</span><span class="p">(</span><span class="n">tokens</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Are the two sets identical? True
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="Subwords-vs.-Whole-words">Subwords vs. Whole-words<a class="anchor-link" href="#Subwords-vs.-Whole-words">¶</a></h3><p>Let's gather some statistics on the vocabulary.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [79]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>--upgrade<span class="w"> </span>matplotlib
<span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>-U<span class="w"> </span>seaborn
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)
Requirement already satisfied: contourpy&gt;=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.0.7)
Requirement already satisfied: cycler&gt;=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.11.0)
Requirement already satisfied: fonttools&gt;=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.39.3)
Requirement already satisfied: kiwisolver&gt;=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.4)
Requirement already satisfied: numpy&gt;=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.22.4)
Requirement already satisfied: packaging&gt;=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.1)
Requirement already satisfied: pillow&gt;=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (8.4.0)
Requirement already satisfied: pyparsing&gt;=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.0.9)
Requirement already satisfied: python-dateutil&gt;=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)
Requirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil&gt;=2.7-&gt;matplotlib) (1.16.0)
Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.12.2)
Requirement already satisfied: numpy!=1.24.0,&gt;=1.17 in /usr/local/lib/python3.10/dist-packages (from seaborn) (1.22.4)
Requirement already satisfied: pandas&gt;=0.25 in /usr/local/lib/python3.10/dist-packages (from seaborn) (1.5.3)
Requirement already satisfied: matplotlib!=3.6.1,&gt;=3.1 in /usr/local/lib/python3.10/dist-packages (from seaborn) (3.7.1)
Requirement already satisfied: contourpy&gt;=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,&gt;=3.1-&gt;seaborn) (1.0.7)
Requirement already satisfied: cycler&gt;=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,&gt;=3.1-&gt;seaborn) (0.11.0)
Requirement already satisfied: fonttools&gt;=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,&gt;=3.1-&gt;seaborn) (4.39.3)
Requirement already satisfied: kiwisolver&gt;=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,&gt;=3.1-&gt;seaborn) (1.4.4)
Requirement already satisfied: packaging&gt;=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,&gt;=3.1-&gt;seaborn) (23.1)
Requirement already satisfied: pillow&gt;=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,&gt;=3.1-&gt;seaborn) (8.4.0)
Requirement already satisfied: pyparsing&gt;=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,&gt;=3.1-&gt;seaborn) (3.0.9)
Requirement already satisfied: python-dateutil&gt;=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,&gt;=3.1-&gt;seaborn) (2.8.2)
Requirement already satisfied: pytz&gt;=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas&gt;=0.25-&gt;seaborn) (2022.7.1)
Requirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil&gt;=2.7-&gt;matplotlib!=3.6.1,&gt;=3.1-&gt;seaborn) (1.16.0)
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [86]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="s1">'darkgrid'</span><span class="p">)</span>

<span class="c1"># Increase the plot size and font size.</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s2">"figure.figsize"</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>

<span class="c1"># Measure the length of every token in the vocab.</span>
<span class="n">token_lengths</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">token</span><span class="p">)</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span><span class="o">.</span><span class="n">keys</span><span class="p">()]</span>

<span class="c1"># Plot the number of tokens of each length.</span>
<span class="c1">#sns.countplot(token_lengths)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">token_lengths</span><span class="p">,</span><span class="n">linewidth</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s2">"white"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Vocab Token Lengths'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Token Length'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'# of Tokens'</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">'Maximum token length:'</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="n">token_lengths</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Maximum token length: 18
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAA44AAAHyCAYAAACkiJAHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAByW0lEQVR4nO3dd3wU1eL+8WfTCUmAUEIVVIRAqNJRkaZELKAgiIKXroANUEG48FWQYuUCCiIIEa4oKNVCR1CpoRuKCoaWQOikt838/shv9xKzWZJNlizJ5/16eW+YOWfO2TnZbJ7MmTMmwzAMAQAAAACQA7fC7gAAAAAAwLURHAEAAAAAdhEcAQAAAAB2ERwBAAAAAHYRHAEAAAAAdhEcAQAAAAB2ERwBAAAAAHYRHAEAAAAAdhEcAQAAAAB2ERwBAEXe8uXLVbt2bbVv376wu5IvZ8+eVe3atVW7dm2dPXu2sLsDJ2vfvr1q166t5cuXF3ZXAEAehd0BAMCt9e9//1vffvutSpcurV9//VVeXl65qvfwww/r1KlTateunT777DMn9/L20KdPH+3evduhuk8++aSmTp1awD26PdWuXVuS9NJLL+nll18u5N4438aNG3X06FHVqVNHHTt2LOzuAECucMURAIqZ7t27S5KuXbumjRs35qrO7t27derUqSz1IZUqVUrlypXL9l+pUqVuWsbPz68Qe47CtHHjRn3yySe5fv8BgCvgiiMAFDONGjVSzZo1dfz4cS1fvlydO3e+aR3LVLly5cqpbdu2Tu7h7eOTTz6xuX3Xrl16/vnnJUkzZ85UixYtbmW3AAAocFxxBIBiyHLVcNu2bYqJibFbNj4+XuvWrZMkdenSRR4e/M0RAIDihk9/ACiGunTpoo8++khpaWlavny5hgwZkmPZNWvWKDExUZLUrVu3LPuOHDmisLAwhYeH69KlS/Lx8dHdd9+t0NBQPfvss3bvn0xNTdWqVau0du1aHT16VLGxsSpdurSqVKmiBx54QF26dFG1atWs5ZOSkrRp0yb98ssv+uOPPxQTE6P4+HiVLl1aDRo0UM+ePfXggw/m6vVv27ZNCxYsUEREhBITE1WtWjU9+uijGjBggLy9vXN1jPy6ePGi5s+fr19++UVRUVGSpCpVqujBBx9U//79Va5cuTwfMzk5WSNGjNCmTZtUunRpzZkzR40aNbLuj4+P1+LFi7Vp0yZFRkYqMTFRZcuW1b333qvnn39ejRs3znbMs2fPqkOHDpKkTZs2ycfHR5999pk2b96sixcvyt/fXy1atNBLL72ku+++27GTkQ9nz57Vl19+qe3btys6OloZGRmqVKmS7r//fvXv31+VK1fOVmf58uV66623VKVKFW3evFkRERGaO3eu9u7dq2vXrikoKEgdO3bU0KFDs0w7/qfw8HB98cUX2r9/v5KSklSpUiWFhoZq8ODBWrduXZY2pKxXoiVpxYoVWrFiRZZjLly40OYV6tTUVC1cuFCrV6/W6dOn5e7urpCQEA0cOFBt2rSx2b/k5GR99dVXWr9+vf7++28lJibK399fgYGBql+/vtq3b69OnTrl6jwDAMERAIqhwMBAtW/fXuvWrdOKFSvsBsdly5ZJkho3bpwlGISFhWnq1KkyDEOS5O/vr6SkJO3fv1/79+/X8uXLNW/ePFWoUCHbMc+cOaOhQ4fqzz//lCSZTCYFBAQoPj5eBw4c0IEDB3T9+nWNHTvWWmfNmjV66623rOX9/Pzk4eGhixcvatOmTdq0aZP69++vUaNG2X3tX331lSZOnCjDMBQQECCz2azjx49r+vTp2rBhg8LCwuyGhYKwe/duDRs2TLGxsZIkX19fSdLx48d1/Phxfffdd5o1a5aaNm2a62Neu3ZNL774ovbv36/KlStr3rx5Wcbr6NGjevHFF3X+/HlJkru7u3x8fHT+/Hn99NNPWrNmjYYPH64XXnghxzaOHz+uMWPG6PLlyypRooQk6fLly/rpp5/0yy+/6KuvvlJwcHCez4ejVq9erbFjxyo1NVWS5OXlJTc3N0VGRioyMlLLly/XjBkzdP/99+d4jO+//15vvfWW0tLS5O/vL7PZrLNnzyosLEzbtm3TkiVLVLJkyWz1Fi1apEmTJmX5/o+KitJnn32mDRs2qEePHtnqeHp6qly5coqLi1NKSoq8vb3l7++frcw/JSYmqnfv3jp48KA8PT3l6emp+Ph47dq1S7t379a7776b7d7j+Ph4Pffcczp27JikzPeMv7+/4uLidPXqVZ04cULh4eEERwC5ZwAAiqUtW7YYtWrVMmrVqmXs3r3bZpkTJ05Yy3z77bfW7Zs3b7ZuHzJkiHH69GnDMAwjJSXFWLFihdG4cWOjVq1aRs+ePY309PQsx4yLizMefvhho1atWkazZs2MJUuWGLGxsdb9p0+fNubPn28sWLAgS70NGzYYU6dONfbs2WMkJiZat8fExBgzZ840QkJCjFq1ahkbN27M9jqWLVtm1KpVy2jYsKEREhJivPLKK0Z0dLRhGIaRlJRkLF682KhXr55Rq1YtY9iwYXk7kTbs3LnTen527tyZZV90dLTRtGlTo1atWkbnzp2NPXv2WPeFh4cbnTp1MmrVqmU0b97cOH/+fJa6Z86csR73zJkzWY75yCOPGLVq1TIee+yxbPViYmKMVq1aGbVq1TJeeukl4/fffzdSU1MNwzCMS5cuGf/5z3+MunXrGrVq1TI2bNiQY5vNmjUznnnmGePQoUOGYRhGWlqasW3bNuO+++4zatWqZTz77LMOnS/L8WfMmJHrOr/99psRHBxs1K1b13j//feNM2fOGBkZGUZGRoZx4sQJ45VXXjFq1apl3HvvvUZUVFSWujd+P9SrV88YO3as9fshMTHR+O9//2v9fvrPf/6Tre29e/cawcHBRq1atYx+/foZf//9t/V8rFmzxmjevLnRrFkzo1atWka7du2y1R81apRRq1YtY9SoUXZfY7t27azn/YEHHjA2bNhgHbcTJ04YPXr0MGrVqmU0atQoy3vIMAzj008/tX4frVu3zkhJSTEMwzDMZrNx/vx5Y8WKFca///3vXJ5tADAM7nEEgGLqgQceUMWKFSX976riP1m2+/r66pFHHrFu/+CDDyRJTZs21cyZM61TSr28vNS1a1d9+OGHkqT9+/drw4YNWY45b948nTx5Ul5eXgoLC1OPHj2yXHWpVq2a+vXrp759+2ap17FjR40aNUpNmjSxXu2SpAoVKuill17S8OHDJWVeCcpJUlKSGjdurGnTpqlSpUqSJB8fH/Xq1Uvjx4+XJG3YsEGHDh3K8Rj59dlnnyk2NlalSpVSWFiYmjRpYt3XtGlThYWFyc/PT9euXdOcOXNuerw///xTzzzzjE6cOKFmzZpp8eLFCgoKylLmP//5jy5fvqzHHntMM2fOVL169axXtsqWLatXX31Vb7zxhqTMxXxyUrZsWS1YsED169eXJHl4eKh169aaMGGCJGnPnj3WK5rOlJGRoQkTJigjI0Pjx4/XG2+8oapVq8pkMslkMumuu+7S9OnT1b59e8XHx2vBggU2j5OUlKRHH31U7777rvX7oUSJEnruuefUu3dvSdKPP/6Yrd6MGTOUkZGhmjVr6rPPPtOdd94pKfN8hIaGavr06bp+/XqBvd6kpCQtWLBAHTt2tI7bXXfdpdmzZ8vb21uJiYn6+eefs9TZv3+/JKl///56+OGHrdPG3dzcFBQUpK5du2rixIkF1kcARR/BEQCKKTc3Nz355JOSpHXr1ikhISHLfrPZrFWrVkmSHnnkEet0vWPHjunEiROSpCFDhsjd3T3bsdu3b68GDRpIyv6LtyWMPv3006pbt26BvR7Laq8HDhyQ2WzOsdyQIUPk5pb9469bt27WIP3TTz8VWL9uZBiG1q5dK0l65plnVL58+WxlKlasqGeeeUaS7dByoz179ui5557T+fPn9fDDD2v+/PnZpj6mpKTohx9+kCQNGjQox2N16dJFUub4Xrp0yWaZ/v37y8fHJ9v2Nm3aWAPNH3/8YbfPBSE8PFwnT55UmTJl9PTTT+dYrmvXrpKk3377LccyOU3TttzXeerUKSUlJVm3X7t2TTt37pQkDRgwwOZ9vC1btszTNOOb6dSpk837RwMDA633sP7zvAcEBEjKvJcWAAoC9zgCQDHWrVs3ffbZZ0pMTNRPP/2U5ZfwX375xfpL5433T0VEREjKvLrSvHnzHI/dunVrHTp0yFpekqKionThwgVJUrt27fLc30uXLmnx4sXatm2bTp48qbi4uGwhMSkpSdevX1dgYGC2+h4eHjn+Qu/m5qbmzZtr9erVWfpckM6ePatr165Jklq1apVjufvuu0/z5s3TtWvXdObMmSyLBFls3LhRH3/8sVJSUqxXTG0F4oiICKWkpEjKDDq5ER0dbXNxHssfA/7Jw8NDgYGBiomJKdArbTnZt2+fpMz7+B544IEcy6WlpUnKfD22lC5dWtWrV7e578Z7c2NjY61XuY8ePWq9r7FZs2Y5tt28eXPt2bPHzqvIvYYNG+a4z9LPf573tm3b6ocfftB///tfXblyRZ07d9a9995r830BALlBcASAYqxatWpq3ry5du3apWXLlmUJjpYrg3fddZfuvfde6/YrV65IksqUKWN31VTL1bvLly9bt914JcvWapf27N+/X4MHD7YuKCNlTqEtUaKETCaTzGazrl69KklZrhDd6GZ9tkzxvLHPBenG4/5zOqmtfkiZ59tWcJwyZYqkzIDw9ttv53gsS1CXlOOVxH/K6fzZWiTGwvKYlvT09Fy1kR+W15SWlpar15ScnGxzu73Xc+OVdEsAlf73/S/lfgzzy5Hz/vjjj+vQoUP673//qx9//NF69bp69eq677771K1bN9WrV6/A+gig6CM4AkAx1717d+3atUv79+9XZGSk7rzzTl25ckVbtmyRlP0RHPlhMpkcqpeenq6RI0cqNjZWderU0fDhw9WkSRP5+flZy5w+fVoPPfSQJFmvCBVlTzzxhFavXq2tW7fq66+/Vq9evWyWy8jIsH596NChW/a4EWeyXGVu2LChli5dWsi9cV1jx45V7969tXbtWu3Zs0cHDhzQqVOndOrUKS1evFjPP/98lpWLAcAe7nEEgGKuU6dO1vuhLFcZV69erbS0NHl4eFjvE7OwTHW7evWq9TEItlgWSSlbtqx1243TH3OaPmjLgQMHFBUVJXd3d82ZM0cPPvhgltAo5e5erpv1OSYmJlufC9KNx7W0Za8fknKcWvjqq69q6NChMgxD77zzjr766iub5W4855bnRd7uLPeG5uV7qKDcOB43Xs39J3vjeytVr15dL7zwgubOnatdu3ZpyZIl6tixo6TMZ0Zu2rSpkHsI4HZBcASAYs7b21uPPfaYJGnlypUym83WANm2bdts97pZprelp6dr9+7dOR53x44dkmRdgVPKnJ5qmcL3z1Ug7Tl37pykzF/ac5oCaGnPnvT0dO3du9fmPsMwFB4eLklOm8JXtWpVlS5dWpL9/m7fvl1S5j14tqapWrz66qt6+eWXZRiGJkyYoC+//DJbmfr161sXrsnLOXdllqnTFy9e1O+//35L265Tp471yrm97397+yz1b/WVcTc3NzVq1EgzZsywThW3fK8BwM0QHAEA1sVvLl68qFmzZunPP/+UZHuaanBwsGrWrClJmj17ts0VTLdu3aqDBw9Kkh599FGbbX377bc6cuRIrvpnWSn00qVLNu9pO3/+vN3HcNxo9uzZWaZvWqxYscIaUDt37pyrY+WVyWSyPtZkyZIlNq+SxsTEaMmSJZJkDfT2vPTSS3rttdckSZMnT8726AlfX189/vjjkqS5c+fe9CqdZfEeV9aiRQvrojZTpkyxexVZKtjXVLp0abVo0UKStGDBAptth4eH210Yx3K1/Mb7dQuavXPi7u5u/WOCo9PHARQ/BEcAgEJCQlSnTh1J0qxZsyRlTgd88MEHbZZ//fXXJWU+DuKVV17RmTNnJGUuIrJ69WqNGDFCktS4cWPrtDiL/v37q0aNGkpNTVXfvn21dOlSxcfHW/efPn1an3zyib744gvrtiZNmsjX11eGYei1115TZGSkpMx73X799Vf16dMnV6+zRIkS2rdvn0aOHGmdSpuSkqIlS5ZYF5jp0KFDjquHFoQXX3xRAQEBunbtmvr162ddIVSS9u7dq379+ik2NlalS5fW4MGDc3XMIUOGaOTIkZKkqVOnau7cuVn2Dx8+XBUqVNDVq1fVs2dPrVy5Mss5v3LlitatW6dhw4ZZj1MYkpKSdOXKFbv/paamysPDQ++88448PDy0d+9e9e7dWzt27MiyiM2ZM2f09ddfq1u3blq8eHGB9vPll1+WyWTSn3/+qSFDhujkyZOSMq9or1+/Xi+//LJKlSqVY/1atWpJyhxvy6NtCtrTTz+td999V7t27VJiYqJ1e0xMjCZOnKhTp05JUo7vcQD4JxbHAQBIyrwSOHHiROvVuCeffNLmMxqlzEdpvPXWW5o6dao2btyojRs3KiAgQElJSdZf3mvVqqXp06dnO4afn5/mzZunF198UcePH9e4ceP0f//3fwoICFBKSop1Rc/nn3/eWsff319vvvmm3n77bYWHhys0NFS+vr4ym81KSUlRmTJlNGXKlByfyWcRGBioAQMGaOLEifrpp59UqlQpJSYmWvscHBysSZMmOXYCc6lixYr69NNPNXToUP3111/q1auXfH19Jcn6C35AQIA+/fTTPK3MOXjwYHl4eOi9997Thx9+KLPZrBdffFFS5iMbwsLCNHToUJ08eVKjRo2Sm5ubAgIClJqamiVYtG7dugBfbd588cUXWf5gYMunn36qjh07qlWrVpo+fbrefPNNHTx4UH379pWnp6dKliypxMTELFfc/vnHi/xq2rSpRo8erSlTpui3336z3iecnJys1NRU1apVS926ddOUKVNsruL78MMP6+OPP7Y+JqNMmTLW74GPP/7Y+mzG/IiLi9OiRYu0aNEimUwm+fv7Kz09PctY9+3b1+7jTADgRgRHAICkzOX733//fesz/262mmrfvn3VrFkzhYWFKTw8XJcuXZKPj49CQkL0yCOP6Nlnn83x0RfVqlXTihUr9N1332nNmjX6888/lZCQoDJlyig4OFht2rSxPpDeolevXqpcubLmzZuniIgImc1mBQUF6cEHH9SgQYOyXG2y57nnnlONGjW0YMEC/f777zKZTLrrrrv02GOPacCAATYfcF/Qmjdvrp9++kkLFizQ1q1bFRUVJZPJpLvvvlsPPvig+vfvb10AJi/69+8vd3d3TZ48WdOmTVN6erpeeuklSdLdd9+t77//XitWrND69et19OhRXb9+XZ6enqpevbrq1Kmj++67T506dSrol+s0HTt21IYNG7R48WL98ssvOnXqlOLi4lSiRAndddddql+/vtq2bas2bdoUeNt9+/ZV3bp1NW/ePB04cEDJycmqUqWKQkNDNXjwYOtqr5aFp25UqlQp/fe//9Wnn36qPXv26MqVK9ZHyVjef/n18ccf67ffftOePXt09uxZXbp0Senp6apSpYoaNmyoHj162H2WKAD8k8koDmuWAwAA3EIjR47UDz/8oG7dumny5MmF3R0AyLfb5orjxYsXtW3bNkVEROj333/X0aNHlZKSoubNm990QYS0tDR9+eWXWr16tU6fPi1PT08FBwerT58+evjhh+3WPXLkiD7//HOFh4crNjZWFSpUULt27TR06NAcl0gvrDYBAEDhi4yM1IYNGySJqaAAiozb5opjWFiYpkyZkm37zYJjSkqK+vXrp71798rd3V01a9ZUUlKSTp8+LUkaNGiQdZGHf1q/fr1GjBihtLQ0lS1bVhUrVlRkZKQSExNVvnx5ff311zaXSS+MNgEAwK0zffp0lS1bVu3bt1fFihXl5uamxMREbdmyRVOmTNGFCxd01113afXq1dYVTAHgdnbbBMfvvvtOP/74o+rXr6/69evryJEjmjVr1k2D47vvvqtFixapatWqmjt3ru666y5J0qZNm/Taa68pNTVVs2fPVvv27bPUi4mJUadOnZSUlKShQ4dq2LBh8vDwUFxcnIYPH65ff/1V9erV03fffZdtKevCaBMAANw6Q4cO1aZNmyTJuihPbGysdXGpoKAgzZs3z7qCKgDc7m6bx3F0795dCxYs0IgRI/TQQw+pbNmyN61z6dIlffPNN5KkSZMmWQOclLnc+sCBAyVJn3zySba68+bNU1JSkpo1a6ZXX31VHh6Zs3r9/f310Ucfyd/fXxEREdkeplwYbQIAgFurb9++6tWrl4KDgxUQEKD4+HiVLFlS9evX18svv6zVq1cTGgEUKbdNcHTE5s2blZaWpho1aqhly5bZ9j/zzDOSpMOHD1unkVqsW7dOktSjR49s9UqVKqXQ0FBJ0po1awq9TQAAcGs1b95cb7/9tlatWqXt27fr8OHD2rNnj7777ju99NJLKl26dGF3EQAKVJEOjgcOHJCU+eBoW4KCglS1atUsZSXp3LlziomJkSQ1a9bMZt2mTZtKkg4ePFjobQIAAACAMxXp4Hjy5ElJ0h133JFjGcu+yMjIbPU8PT1VsWJFm/UsC9ScOXMmy7PDCqNNAAAAAHCm2+ZxHI64fv26pMxpnjmx7IuNjbVuu3btmnVfTovQWKagZGRkKD4+XmXKlCm0NvPKMAxlZNwWayIVaW5uJsbBRTE2ro3xcW2Mj+tibFwb4+O6ivLYuLmZcr3oZpEOjikpKZJkdxlsLy8vSVJycrJD9W4sX1htOsLdvUhfbL5tuLuzOq6rYmxcG+Pj2hgf18XYuDbGx3UxNkU8OHp7e0uS3WmdqampkiQfHx+H6t1YvrDazKuMDEOxsYkO10f+ubu7KSCghGJjk2Q2ZxR2d3ADxsa1MT6ujfFxXYyNa2N8XFdRH5uAgBK5vqBUpINjQECApP9NH7XFss9SVvrfVNLr16/LMAybl28tU0vd3Nzk5+dXqG06Ij296H3j347M5gzGwkUxNq6N8XFtjI/rYmxcG+PjuhibIr44To0aNSRJp06dyrGM5ZEYlrI3fp2WlqZz587ZrHfmzBlJUtWqVbNMLy2MNgEAAADAmYp0cGzUqJEkad++fTb3x8TE6OzZs1nKSlLlypVVoUIFSdKePXts1rVsv7FeYbUJAAAAAM5UpINjhw4d5OnpqZMnT2rnzp3Z9n/zzTeSpLp166p69epZ9nXq1EmStHTp0mz1rl+/rrVr10qSQkNDC71NAAAAAHCmIh0cy5Urp549e0qSxo4dq7///tu6b/PmzZo3b54kadiwYdnqDhgwQD4+PgoPD9f06dNlNpslSXFxcRo5cqTi4uJUt25dtW/fvtDbBAAAAABnMhmGcVs8lOTcuXPq2rWr9d+pqalKTEyUh4dHloViBg4cqEGDBln/nZycrL59+2r//v1yd3fXPffco8TEROt9hv3799eoUaNstrl27VqNHDlS6enpKlu2rCpWrKjIyEglJiaqXLlyWrx4cbarhoXVZl6YzRm6ciUhX8dA/nh4uKlMmZK6ejWh2N9o7WoYG9fG+Lg2xsd1MTaujfFxXUV9bAIDSxa9VVXNZrN1VdEbpaenZ9l+47MRpcxHXixcuFBhYWH6/vvvdfLkSXl6eqp58+bq3bu3dXqoLaGhoapWrZrmzJmjPXv26M8//1SFChX01FNPaejQoSpbtqzNeoXRJgAAAAA4y21zxREFhyuOha+o//XqdsbYuDbGx7UxPq6LsXFtjI/rKupjk5crjkX6HkcAAAAAQP4RHAEAAAAAdhEcAQAAAAB2ERwBAAAAAHYRHAEAAAAAdhEcAQAAAAB2ERwBAAAAAHYRHAEAAAAAdnkUdgcAIK8y3NyUnJrunIOnG0q4ECez2ZBkOKcNJ/Hx8pBbRtF7ODEAACh8BEcAt53k1HS99OGWwu6Gy/nk9bby9WAiCQAAKHj8hgEAAAAAsIvgCAAAAACwi+AIAAAAALCL4AgAAAAAsIvgCAAAAACwi+AIAAAAALCL4AgAAAAAsIvgCAAAAACwi+AIAAAAALCL4AgAAAAAsIvgCAAAAACwi+AIAAAAALCL4AgAAAAAsIvgCAAAAACwi+AIAAAAALCL4AgAAAAAsIvgCAAAAACwi+AIAAAAALCL4AgAAAAAsIvgCAAAAACwi+AIAAAAALCL4AgAAAAAsIvgCAAAAACwi+AIAAAAALCL4AgAAAAAsIvgCAAAAACwi+AIAAAAALCL4AgAAAAAsIvgCAAAAACwi+AIAAAAALCL4AgAAAAAsIvgCAAAAACwi+AIAAAAALCL4AgAAAAAsIvgCAAAAACwi+AIAAAAALCL4AgAAAAAsIvgCAAAAACwi+AIAAAAALCL4AgAAAAAsIvgCAAAAACwi+AIAAAAALCL4AgAAAAAsIvgCAAAAACwi+AIAAAAALCL4AgAAAAAsIvgCAAAAACwi+AIAAAAALCL4AgAAAAAsMujsDtwq1y9elULFizQzz//rLNnzyotLU2BgYFq3Lix+vTpo6ZNm9qsl5CQoM8//1zr1q1TdHS0fH191bBhQ/Xv318tWrSw2+bOnTu1YMECHTx4UImJiapcubJCQ0M1ePBg+fr65lgvP20CAAAAQEErFlccT548qccff1xz5szR8ePHVbZsWdWsWVPx8fFau3atevfurbCwsGz1rly5om7duumzzz5TVFSU7r77bnl7e2vLli3617/+pa+++irHNhctWqS+fftqy5Yt8vb21t13362oqCjNnj1b3bt317Vr12zWy0+bAAAAAOAMxSI4/t///Z8uXryoGjVq6Pvvv9fGjRu1cuVK7dixQ/3795dhGPrggw908uTJLPXGjh2ryMhIhYSEaOPGjVqxYoW2bNmiCRMmyDAMTZo0SUePHs3WXkREhCZPnixJmjBhgrZs2aIVK1Zo48aNCgkJ0YkTJzRu3DibfXW0TQAAAABwliIfHOPj47Vr1y5J0htvvKGaNWta93l7e+vNN99U9erVlZ6ert9++82678iRI9q8ebPc3Nw0bdo0BQUFSZJMJpN69uypLl26yGw2a9asWdnanDVrljIyMtSlSxf17NlTJpNJkhQUFKSPP/5Ybm5uWr9+vY4dO5alXn7aBAAAAABnKfLBMTU1VYZhSJLuuOOObPtNJpOqVasmSUpPT7duX7dunSSpZcuWql69erZ6PXv2lCRt3bpViYmJ1u0JCQn69ddfJUk9evTIVq9GjRpq2bKlJGnt2rVZ9jnaJgAAAAA4U5EPjoGBgapYsaIkaf/+/dn2JyYmWq/81a9f37r9wIEDkpTjojkNGjSQl5eXUlJSskwdPXr0qFJTU+Xl5aUGDRrYrNukSRNJ0sGDB7Nsd7RNAAAAAHCmIh8cJWnkyJEymUx6//339e233+rixYtKSkrSoUOHNGTIEF26dElPPPGENdBJst7vaOsqpSR5enqqUqVKkqTIyEjrdsvXlStXlqenp826lmPeWC8/bQIAAACAMxWLx3E88cQT8vf31+zZs/Xvf/87y77y5cvr7bff1jPPPJNl+/Xr1yVJpUqVyvG4ln2xsbEO1bOUzW+bjvDwKBZ/M3BZ7u5uWf4feZRuFHYPXJSpyL+3ee+4NsbHdTE2ro3xcV2Mzf8Ui+AoSadOndLly5fl5uamSpUqyc/PT6dPn9bFixe1YsUKNWnSRLVq1bKWT0lJkaQcrxpKkpeXlyQpOTnZoXqWsvltM6/c3EwqU6akw/VRcAICShR2F25LCRfiCrsLLsndvfi8t3nvuDbGx3UxNq6N8XFdjE0xCY7vvPOOFi9erPr162vevHm68847JWWGrxkzZuiLL75Qr169tHr1alWpUkVS5oqrSUlJSktLy/G4qampkiQfHx/rNm9vb0nKVT1L2RvrOtJmXmVkGIqNZXGdwuTu7qaAgBKKjU2S2ZxR2N257ZjNXHG0xWw2dPVqQmF3w6l477g2xsd1MTaujfFxXUV9bAICSuT6amqRD47Hjh3T119/LU9PT02fPt0aDKXM8PXmm2/qyJEj2rFjh+bMmaMJEyZIkgICApSUlJRtOumNLPsCAgKs23Kahmqr3j+npDrapiPS04veN/7tyGzOYCwcQnC0zSg230+8d1wb4+O6GBvXxvi4LsamGCyOs3fvXhmGoerVq2cJjTe67777JEkRERHWbTVq1JCUOcXVlrS0NEVHR2cpe+PX0dHROV45PH36dLZ6+WkTAAAAAJypyAfHhITcT9uyTAOVpEaNGknKDJ62HDp0SGlpafL29ladOnWs2+vUqSNPT0+lpqbq0KFDNutajmlpI79tAgAAAIAzFfngaLmf8dSpU4qKirJZZtu2bVnKSlKnTp0kSbt27bJ5BXDJkiWSpDZt2qhkyf8tRuHn56f7779fkrR06dJs9U6ePKmdO3dKkkJDQ7Psc7RNAAAAAHCmIh8c77vvPpUtW1ZpaWl69dVXszz/MDk5We+//7527NghSerSpYt1X0hIiNq1ayez2azhw4frwoULkiTDMLRkyRKtWrVKbm5uGjJkSLY2hw4dKpPJpFWrVmnJkiUyjMz7sS5cuKARI0YoIyNDHTt2VHBwcJZ6+WkTAAAAAJzFZFhSTRG2fft2DRs2TImJiXJzc1PlypVVsmRJnT59WklJSZKk5557TuPHj89S78qVK+rVq5dOnjwpLy8v1axZU1evXtW5c+dkMpk0duxY9enTx2abYWFhmjp1qgzDUKVKlVSmTBkdP35cqampuvPOO7V48WIFBgZmq5efNnPLbM7QlStFe+VFV+fh4aYyZUrq6tWEYn+jtSMS0zP00odbCrsbLueT19vKt4g/x5H3jmtjfFwXY+PaGB/XVdTHJjCwJKuq3qh169ZavXq1wsLCtH37dkVHRysmJkalS5dW69at1aNHD7Vt2zZbvcDAQC1btkxz587V2rVrdfz4cfn6+qpNmzYaMGCAWrZsmWObffv2Ve3atTV//nwdOnRIly9fVuXKlRUaGqrBgwfnONU0P20CAAAAgDMUiyuOyIorjoWvqP/1ytm44mgbVxxR2Bgf18XYuDbGx3UV9bHJyxXHov0bBgAAAAAg3wiOAAAAAAC7CI4AAAAAALsIjgAAAAAAuwiOAAAAAAC7CI4AAAAAALsIjgAAAAAAuwiOAAAAAAC7CI4AAAAAALsIjgAAAAAAuwiOAAAAAAC7CI4AAAAAALsIjgAAAAAAuwiOAAAAAAC7CI4AAAAAALsIjgAAAAAAuwiOAAAAAAC7CI4AAAAAALsIjgAAAAAAuwiOAAAAAAC7CI4AAAAAALsIjgAAAAAAuwiOAAAAAAC7CI4AAAAAALsIjgAAAAAAuwiOAAAAAAC7CI4AAAAAALsIjgAAAAAAuwiOAAAAAAC7CI4AAAAAALsIjgAAAAAAuwiOAAAAAAC7CI4AAAAAALsIjgAAAAAAu5waHK9fv664uDhnNgEAAAAAcDKHg2NMTIxWrlypX375Jdu+v/76S0899ZRatmyp5s2b69lnn1VkZGS+OgoAAAAAKBwOB8dly5bprbfe0u7du7NsT05O1uDBg3X06FEZhiHDMLRv3z7169dP8fHx+e4wAAAAAODWcjg47tixQ5LUuXPnLNtXrFihc+fOqVSpUpo4caI++OADVaxYUTExMfrqq6/y11sAAAAAwC3ncHCMioqSJN11111Ztm/YsEEmk0kjRozQ008/rccff1wTJ06UYRjavHlz/noLAAAAALjlHA6OV69elZ+fn3x8fKzbMjIytH//fplMJnXq1Mm6/b777pObmxv3OQIAAADAbcjh4Gg2m5Wamppl259//qmkpCTVrFlTpUqV+l8jbm4KCAhQYmKi4z0FAAAAABQKh4Nj+fLllZqaqjNnzli3/frrr5Kkxo0bZyufmJio0qVLO9ocAAAAAKCQOBwcGzVqJEn69NNPlZGRoStXrujrr7+WyWTSAw88kKXsmTNnlJqaqvLly+erswAAAACAW8/h4Pivf/1LkrRq1So1bdpUDz74oKKjo1W1alW1bds2S9nt27dLkurWret4TwEAAAAAhcLh4NigQQNNnjxZvr6+SkxMVFpamu666y7NnDlTHh4eWcquXLlSktSiRYt8dRYAAAAAcOt53LxIzp588kk98sgj+vPPPxUQEKA77rhDbm5Zs2hqaqp69uypHj16ZLsSCQAAAABwffkKjpLk4+OjBg0a5Ljfy8tLXbt2zW8zAAAAAIBC4vBUVQAAAABA8ZDvK44WKSkpun79utLT0+2Wq1y5ckE1CQAAAAC4BfIVHJOSkjRv3jz98MMPOn369E3Lm0wmHTlyJD9NAgAAAABuMYeDY2xsrJ577jkdP35chmHkqk5uywEAAAAAXIfDwXHWrFn666+/5OHhoT59+qhDhw6qUKGC3N3dC7J/AAAAAIBC5nBw3Lhxo0wmk8aMGaNnn322IPsEAAAAAHAhDq+qGhMTIzc3N3Xr1q0g+wMAAAAAcDEOX3EsVaqUUlNT5e3tXZD9AQAAAAC4GIevODZp0kRxcXGKiYkpyP4AAAAAAFyMw8Fx0KBBcnd316efflqQ/QEAAAAAuBiHg2O9evU0depUrVy5UmPGjNGZM2cKsl8AAAAAABfh8D2OHTp0kCS5u7trxYoVWrFihUqVKqWSJUvmWMdkMmnjxo2ONgkAAAAAKAQOB8eoqKhs265du6Zr167lWMdkMjnaXIHZunWrvv32Wx04cEDXrl1TqVKlVK1aNbVo0UIvv/yyPDyynpK0tDR9+eWXWr16tU6fPi1PT08FBwerT58+evjhh+22deTIEX3++ecKDw9XbGysKlSooHbt2mno0KEKDAzMsV5+2gQAAACAguZwcJwyZUpB9sPp0tPT9dZbb2n16tWSpEqVKik4OFjXrl1TRESE9u/fr8GDB2cJjikpKerXr5/27t0rd3d31axZU0lJSdq9e7d2796tQYMG6fXXX7fZ3vr16zVixAilpaWpbNmyuueeexQZGalFixZp7dq1+vrrr1WtWrVs9fLTJgAAAAA4g8PB8cknnyzIfjjd22+/rdWrV6t+/fqaMGGC6tata92XlJSk7du3y8vLK0udDz74QHv37lXVqlU1d+5c3XXXXZKkTZs26bXXXtPcuXN17733qn379lnqxcTE6M0331RaWpqGDh2qYcOGycPDQ3FxcRo+fLh+/fVXvfbaa/ruu++yXYV1tE0AAAAAcBaHF8e5nezcuVPffvutqlSporCwsCyhUZJKlCihDh06yNPT07rt0qVL+uabbyRJkyZNsgY4KfP+zoEDB0qSPvnkk2ztzZs3T0lJSWrWrJleffVV61VMf39/ffTRR/L391dERIR+/vnnLPXy0yYAAAAAOEuxCI4LFiyQJPXv319+fn65qrN582alpaWpRo0aatmyZbb9zzzzjCTp8OHDOn36dJZ969atkyT16NEjW71SpUopNDRUkrRmzZoCaxMAAAAAnMXhqaoW58+f14IFC/Tbb78pOjpaKSkpOnLkiHX/9evX9fXXX8tkMmnAgAHZFp9xtpSUFG3btk2S1KpVKx0/flxLlizRiRMn5OXlpTp16qh79+6qUqVKlnoHDhyQJDVp0sTmcYOCglS1alWdPXtWBw4c0B133CFJOnfunGJiYiRJzZo1s1m3adOm+vbbb3Xw4MECaRMAAAAAnClfKW7btm167bXXFB8fL8MwJGVfObVUqVLauHGjDh8+rJo1a1of43GrHDt2TGlpaZKkvXv3asKECdZ/S9LPP/+sefPmacqUKXrssces20+ePClJdsPZHXfcobNnzyoyMjJbPU9PT1WsWNFmPcuiOGfOnFFaWpp1iqyjbQIAAACAMzkcHM+dO6dXXnlFCQkJat++vbp27apx48YpNjY2W9lu3bopIiJCW7duveXB8eLFi9avLYvi/Pvf/1ZwcLDOnTunadOmac2aNRo9erTuuusu6/2P169fl5QZfHNi2Xfja7Y8jqRUqVI5Pn6kdOnSkqSMjAzFx8erTJky+WrTER4exWKWsstyd3fL8v/Io3SjsHvgokxF/r3Ne8e1MT6ui7FxbYyP62Js/sfh4Dh//nwlJCTokUce0bRp0yRlBjNb7r//fknS77//7mhzDktISLB+7ePjo7lz51rDV/Xq1fXxxx/r5MmTOnr0qD777DPNmDFDUuYUV0lZFsz5J8sqrMnJydZteal3Y/n8tJlXbm4mlSlT0uH6KDgBASUKuwu3pYQLcYXdBZfk7l583tu8d1wb4+O6GBvXxvi4LsYmH8Hxt99+k8lk0quvvnrTstWqVZOXl5fOnj3raHMO8/b2tn795JNPZrua5+bmpr59+2rUqFH67bfflJGRITc3N2u9G6e1/lNqaqqkzED6z/ZyU++f/XO0zbzKyDAUG5vocH3kn7u7mwICSig2Nklmc0Zhd+e2YzZzxdEWs9nQ1asJNy94G+O949oYH9fF2Lg2xsd1FfWxCQgokeurqfmaqurj46MaNWrkqryvr6/i4+Mdbc5hNwbFu+++22YZy2MvEhISdO3aNQUGBiogIEDS/6aP2mLZZyl7Y3vXr1+XYRg2p6taprO6ubllWeXV0TYdkZ5e9L7xb0dmcwZj4RCCo21Gsfl+4r3j2hgf18XYuDbGx3UxNvl4HIfJZFJGRu5OXnp6uuLj41Wy5K2fQnXjsxBzmgJ641U/y2uyBOJTp07leGzLIzFuDM+Wr9PS0nTu3Dmb9c6cOSNJqlq1apY+OdomAAAAADiTw8GxSpUqSk1NVXR09E3LhoeHKz09vVDCTlBQkPVRG5bA9k+W7d7e3taFaxo1aiRJ2rdvn806MTEx1qm3lrKSVLlyZVWoUEGStGfPHpt1LdtvrJefNgEAAADAmRwOjq1atZIkffPNN3bLpaWl6T//+Y9MJpMeeOABR5vLl0ceeUSS9P333ys9PT3b/u+++05S5nMXLc+Z7NChgzw9PXXy5Ent3LkzWx3L665bt66qV6+eZV+nTp0kSUuXLs1W7/r161q7dq0kKTQ0NMu+/LQJAAAAAM7icHDs27evPD09NX/+fH377bc2yxw+fFj9+vXTwYMHVbJkST377LMOdzQ/BgwYIH9/f509e1YTJkywrl5qGIYWLlyon3/+WSaTSYMHD7bWKVeunHr27ClJGjt2rP7++2/rvs2bN2vevHmSpGHDhtlsz8fHR+Hh4Zo+fbrMZrMkKS4uTiNHjlRcXJzq1q2r9u3bZ6mXnzYBAAAAwFlMhmE4vMrE6tWrNXr0aBmGoTJlyiguLk7p6elq2LChoqKidOnSJRmGIQ8PD02fPv2WP8PxRtu3b9eQIUOUnJwsf39/1ahRQ+fPn9fFixdlMpn0xhtvaMCAAVnqJCcnq2/fvtq/f7/c3d11zz33KDEx0XqfYf/+/TVq1Cib7a1du1YjR45Uenq6ypYtq4oVKyoyMlKJiYkqV66cFi9ebPOqYX7azC2zOUNXrhTtlRddnYeHm8qUKamrVxOK/Y3WjkhMz9BLH24p7G64nE9ebyvfIv4cR947ro3xcV2MjWtjfFxXUR+bwMCSuV5VNV/BUZK2bdumCRMm5LigS/Xq1fX2229bp7YWppMnT2rOnDnavn27Ll++LD8/PzVu3Fj9+vVT8+bNbdZJTU1VWFiYvv/+e50+fVqenp6qU6eOevfubZ2SmpPDhw9rzpw52rNnj2JjY1WhQgW1a9dOQ4cOVdmyZXOsl582c4PgWPiK+g8hZyM42kZwRGFjfFwXY+PaGB/XVdTH5pYGRylzymd4eLj27dunCxcuyGw2q3z58rr33nvVokULubu757cJFCCCY+Er6j+EnI3gaBvBEYWN8XFdjI1rY3xcV1Efm7wER4ef43jlyhUFBgZKynw0R/PmzXO8amexfft2tW7d2tEmAQAAAACFwOE/TQ8cOFBJSUm5Lr9jxw4NHTrU0eYAAAAAAIXE4eB45MgRvfTSSzYfb/FPu3fv1pAhQ6yrmQIAAAAAbh8OT1WtXr26tm/frtGjR+vDDz/MsdyePXv04osvKjk52fo8RQAAbpUMNzclp978j5zFkY+Xh9wyit49OwCAgudwcPziiy/0zDPP6Mcff1T58uVtPiJi3759euGFF5SYmKiHH35YH330Ub46CwBAXiWnprOYUg6Kw4JKAICC4fCnRdWqVTV37lz5+voqLCxM8+fPz7L/wIEDGjx4sBISEtShQwdNmzZNbm58OAEAAADA7SZfSa5OnTr69NNP5eHhoQ8//FCrV6+WJB06dEiDBg1SfHy82rZtq+nTp/NIDgAAAAC4TeX7EmDLli313nvvyTAMjRkzRgsWLNDAgQMVFxenBx98UDNnzpSHh8MzYgEAAAAAhaxA5o527txZb731ltLT0/X+++8rNjZW9913n2bOnClPT8+CaAIAAAAAUEgK7KbD559/XoMGDZJhGGrdurVmz54tLy+vgjo8AAAAAKCQ5GoOaYcOHXJ9QJPJpL/++svmozdMJpM2btyY+94BAAAAAApdroJjVFRUng568eJFm9tNJlOejgMAAAAAKHy5Co5Tpkxxdj8AAAAAAC4qV8HxySefdHY/AAAAAAAuiudkAC4qw81Nyanphd0NF8W0dwAAgFuJ4Ai4qOTUdL304ZbC7oZLmjGybWF3AQAAoFjJd3A0DEMbNmzQDz/8oIiICF25ckWSFBgYqPr16+vxxx9Xhw4dWBgHAAAAAG5T+QqOly5d0iuvvKL9+/dLygyRFtHR0Tp37pzWr1+ve++9V//5z39Uvnz5/PUWAAAAAHDLORwcU1NTNWDAAP35558yDEMNGjRQ69atVbFiRUnS+fPntWPHDh08eFD79u3ToEGD9O2338rT07PAOg8AAAAAcD6Hg+PXX3+tP/74Q35+fvrggw/Url27bGVee+01bd26VSNHjtQff/yhb775Rn369MlXhwEAAAAAt5aboxXXrFkjk8mk8ePH2wyNFg8++KDGjx8vwzD0448/OtocAAAAAKCQOBwc//77b3l4eKhz5843Ldu5c2d5enrq77//drQ5AAAAAEAhcTg4Jicnq0SJEvLwuPlsVw8PD5UoUULJycmONgcAAAAAKCQOB8dy5copLi5O0dHRNy179uxZxcbGqly5co42BwAAAAAoJA4Hx6ZNm8owDE2ZMiXLYzj+yTAMTZ06VSaTSc2aNXO0OQAAAABAIcl1cFy5cqXWrFlj/Xe/fv1kMpm0ceNGPf/889qxY4fS0tKs+9PS0rR9+3Y9//zz2rhxo0wmk/r27VugnQcAAAAAOF+uH8cxevRolS9fXo888ogkqU6dOho1apSmTp2qPXv2qH///nJ3d1eZMmUkSVevXpXZbLZejXzzzTdVp04dJ7wEAAAAAIAz5ek5jv+cktq3b19Vr15dH3zwgf7++2+lp6fr4sWLWcrUrFlTr7/+utq2bZvvzgIAAAAAbr08BUdb2rVrp3bt2umPP/5QRESELl++LEkqW7as6tWrp9q1a+e7kwAAAACAwpPv4GhRu3ZtQiIAAAAAFEEOr6oKAAAAACgeCI4AAAAAALvyNFX18uXL+VoZ1WQy6ciRIw7XBwAAAADcenm+x/GfK6sCAAAAAIq2PAXHEiVKqH///s7qCwAAAADABeUpOPr6+uqll15yVl8AAAAAAC6IxXEAAAAAAHYRHAEAAAAAdhEcAQAAAAB2ERwBAAAAAHYRHAEAAAAAduV6VdVjx445sx8AAAAAABfFFUcAAAAAgF0ERwAAAACAXQRHAAAAAIBdBEcAAAAAgF0ERwAAAACAXQRHAAAAAIBduQqOCxcu1LfffuvsvgAAAAAAXFCuguPkyZM1Y8aMLNs6dOigHj16OKVTAAAAAADX4ZHbgoZhZPl3VFSUUlJSCrxDAAAAAADXkqsrjiVLltS1a9dkNpud3R8AAAAAgIvJ1RXHe+65RwcPHtT777+vp59+Wr6+vpKkjIwMnTt3LtvVSHsqV67sWE8BAAAAAIUiV8Hx6aef1oEDB7Rw4UItXLjQuv3q1atq3759rhszmUw6cuRI3nsJAAAAACg0uQqO3bp10/Xr1zV//nxdunTJuj0vVxodKQ8AAAAAKHy5Xhynf//+6t+/v65cuaKkpCR16NBBgYGBPKYDAAAAAIq4XAdHi8DAQOvXbm5uqlKlSoF2CAAAAADgWvIcHC0WLlwoT0/PguwLACAfPD3dlZhWxFe/TjeUcCFOZrMhKbe3P5ic2SMAAIoFh4Nj8+bNC7IfAIB8Skk165WPthR2N1zOjJFtC7sLAADc9hwOjje6dOmS1q1bp4iICF2+fFmSVLZsWdWrV0+dOnVSuXLlCqKZArN161YNHjxYklSlShVt3rzZZrmEhAR9/vnnWrdunaKjo+Xr66uGDRuqf//+atGihd02du7cqQULFujgwYNKTExU5cqVFRoaqsGDB1sfZ1LQbQIAAACAM+QrOJrNZk2fPl0LFixQenq6pP+tnGoymbRy5UpNnTpV/fv31yuvvCJ3d/f89zifEhIS9Pbbb9+03JUrV/Tss88qMjJSXl5eqlmzpq5cuaItW7Zo69atGjdunJ577jmbdRctWqRJkybJMAxVrFhRlSpV0vHjxzV79mytX79eixcvVunSpQu0TQAAAABwFrf8VH7zzTc1d+5cpaWlydPTU40bN1bnzp3VuXNnNW7cWJ6enkpLS9Pnn3+u0aNHF1Sf82XatGmKjo5Whw4d7JYbO3asIiMjFRISoo0bN2rFihXasmWLJkyYIMMwNGnSJB09ejRbvYiICE2ePFmSNGHCBG3ZskUrVqzQxo0bFRISohMnTmjcuHEF2iYAAAAAOJPDwXHjxo368ccfZRiG+vXrp99++02LFy/Wxx9/rI8//liLFy/Wtm3b1L9/fxmGoR9++EGbNm0qyL7n2YEDB/TVV1+pQ4cO6tixY47ljhw5os2bN8vNzU3Tpk1TUFCQpMyrqD179lSXLl1kNps1a9asbHVnzZqljIwMdenSRT179pTJlLkoQ1BQkD7++GO5ublp/fr1OnbsWIG1CQAAAADO5HBw/O6772QymfTiiy9q1KhRCggIyFbG399fb775pl588UUZhlGoz3xMS0vTuHHj5OPjo/Hjx9stu27dOklSy5YtVb169Wz7e/bsKSnzXsnExETr9oSEBP3666+SpB49emSrV6NGDbVs2VKStHbt2gJpEwAAAACczeHg+Pvvv8vNzU0DBgy4adkBAwbIzc1Nv//+u6PN5ducOXP0559/6tVXX1XFihXtlj1w4IAkqWnTpjb3N2jQQF5eXkpJSckydfTo0aNKTU2Vl5eXGjRoYLNukyZNJEkHDx4skDYBAAAAwNkcXhzn+vXr8vPzk7+//03L+vv7y9/fX9evX3e0uXw5ceKE5syZo5CQEPXp0+em5U+ePClJuuOOO2zu9/T0VKVKlXTq1ClFRkZaw2BkZKQkqXLlyjk+49JyTEvZ/LbpKA+PfN3einxyd3fL8v82pef2GXUA4ChTgX4e5OpnGwoFY+PaGB/Xxdj8j8PBsVSpUrp27Zri4+Pl5+dnt2xcXJzi4uJUpkwZR5tzmGEY+ve//6309HS98847uVrZ1RJwS5UqlWMZy77Y2FiH6v0zRDvapiPc3EwqU6Zkvo6BghEQUCLHfQkX4m5hT24vJp7nbhPnxTbOS87c3Z3zeWDvZxsKF2Pj2hgf18XY5CM41q9fX1u3blVYWJheeuklu2XDwsKUkZGhevXqOdqcwxYvXqx9+/apT58+ql+/fq7qpKSkSFKOVw0lycvLS5KUnJzsUD1L2fy26YiMDEOxsdwnWZjc3d0UEFBCsbFJMpszbJYxm7nimBODU2MT58U2zkvOzGZDV68mFNjxcvOzDYWDsXFtjI/rKupjExBQItdXUx0Ojk899ZS2bNmiWbNmKT09XYMGDVLJkln/ahkfH6+5c+fq888/l8lkUvfu3R1tziExMTH6+OOPFRQUpNdeey3X9by9vZWUlKS0tLQcy6SmpkqSfHx8stSTlKt6lrL5bdNR6elF7xv/dmQ2Z9gZC37bBeBshlM+D+z/bENhYmxcG+PjuhibfATHhx9+WI888ojWrFmjOXPmKCwsTPXr11eFChUkZYa2iIgIpaSkyDAMde7cWQ899FCBdTw3Jk6cqPj4eE2ZMuWm02lvFBAQoKSkJLv3ZFr23biabE7TUG3V++eUVEfbBAAAAABnczg4StL777+vihUratGiRUpOTlZ4eLj1uYXG/58b5OHhoT59+mjEiBH5720eHTlyRJL0zjvv6J133smyzzLd89y5c7rvvvskSTNnztS9996rGjVqKCYmRqdOnbJ53LS0NEVHR0vKfMSGheXr6OhopaWl2Zx2evr06Wz1LP92pE0AAAAAcLZ8BUdPT0+NGjVKffv21fr16xUREaHLly9LksqWLat69erp4Ycftj7MvrBcunQpx30ZGRnW/ZZpoo0aNdKuXbu0d+9em3UOHTqktLQ0eXt7q06dOtbtderUkaenp1JTU3Xo0CGbK59ajtmoUaMs2x1tEwAAAACcLV/B0SIoKChXj7m41TZv3pzjvuXLl+utt95SlSpVspXr1KmT5syZo127dunUqVOqXr16lv1LliyRJLVp0ybLfZ1+fn66//779fPPP2vp0qXZguPJkye1c+dOSVJoaGiBtAkAAAAAzsYDSWwICQlRu3btZDabNXz4cF24cEFS5vTbJUuWaNWqVXJzc9OQIUOy1R06dKhMJpNWrVqlJUuWWKfsXrhwQSNGjFBGRoY6duyo4ODgAmsTAAAAAJypQK44FkWTJ09Wr169dPjwYXXo0EE1a9bU1atXde7cOZlMJo0ZM0YhISHZ6jVo0ECjR4/W1KlTNX78eM2ePVtlypTR8ePHlZqaqjvvvFMTJ04s0DYBAAAAwJkIjjkIDAzUsmXLNHfuXK1du1bHjx+Xr6+v2rRpowEDBqhly5Y51u3bt69q166t+fPn69ChQ7p8+bIqV66s0NBQDR48OMeppvlpEwAAAACcpdgGx6eeekpPPfWU3TJ+fn4aPny4hg8fnufjt2rVSq1atcpzvfy0CQAAAADOwD2OAAAAAAC7CI4AAAAAALsIjgAAAAAAuwiOAAAAAAC7CI4AAAAAALsIjgAAAAAAu/IVHNu3b6+6desWVF8AAAAAAC4o31ccDcPItm3y5MkaM2ZMfg8NAAAAAHABuQ6OP/30ky5fvpzrsitWrHC4UwAAAAAA1+GR24IjRoyQyWRSjRo11Lx5czVr1kxpaWnO7BsAAAAAwAXkOjh269ZNu3fvVmRkpCIjI7V06VIZhiGTyaTx48erWbNmat68uYKCgpzZXwAAAADALZbr4Dhp0iRJ0rlz57Rr1y7t3LlTP/30k9LS0rR06VJ9++23kqRq1arp+vXrkqTz58+rYsWKTug2AAAAAOBWyXVwtKhUqZK6du2qrl27avfu3Tp37pymTp2qXbt2ac+ePTp9+rS1bLt27VStWjW1bNlSLVq0UIsWLVSuXLkCfQEAAAAAAOfKc3C0xRIkJSkmJkZPPPGEYmNjVa1aNZ0+fVqnT5/Wt99+K5PJpCNHjhREkwAAAACAWyTXwbF79+5q0aKFmjdvriZNmsjPz89muaCgIHl6ekqS1q9fr5iYGO3atUu7du1SeHh4wfQaAADkm6enuxLTzAV3wHRDCRfiZDYbkrI/rut24ePlIbeMjMLuBgC4lFwHx4iICB0+fFjz58+Xu7u7goODdfXqVUlSfHy83SD5xBNP6IknniiYHgMAgAKRkmrWKx9tKexuuJxPXm8rX498P+oaAIqUXAfHlStXavfu3QoPD1d4eLgiIiKs+1q0aKHatWtbr0imp6c7pbMAAAAAgFsv18ExODhYwcHBev755yVJf/zxh/r166erV68qICBAR44c0ZEjRxQWFmZ9TMcHH3xw06mtAAAAAADX5vDiOLVr15aPj48kaceOHfrzzz+1e/du7dy5U1u2bJHZbNYXX3yRZWprixYt9MYbbxRY5wEAAAAAzldgE/hr1aql3r1765NPPlHp0qUlSf/3f/+nhx56SP7+/oqIiND8+fMLqjkAAAAAwC1SII/jyEmvXr3Uq1cvSZlTW3ft2uXM5gAAAAAATpCv4NiwYUNVqVIlV2Vr166t2rVr56c5AAAAAEAhyFdwnDZtms3thnH7PrsJAAAAAJCVU6aqLlu2TGZzAT5QGAAAAABQaJwSHCtWrOiMwwIAAAAACkGBraoKAAAAACiaCI4AAAAAALsIjgAAAAAAuwiOAAAAAAC7CI4AAAAAALsIjgAAAAAAuwiOAAAAAAC7CI4AAAAAALsIjgAAAAAAuwiOAAAAAAC7CI4AAAAAALsIjgAAAAAAuwiOAAAAAAC7CI4AAAAAALsIjgAAAAAAuwiOAAAAAAC7CI4AAAAAALsIjgAAAAAAuwiOAAAAAAC7CI4AAAAAALsIjgAAAAAAuwiOAAAAAAC7CI4AAAAAALsIjgAAAAAAuwiOAAAAAAC7CI4AAAAAALsIjgAAAAAAuwiOAAAAAAC7CI4AAAAAALsIjgAAAAAAuwiOAAAAAAC7CI4AAAAAALsIjgAAAAAAuzwKuwPOZhiG9u/fr82bN2vv3r36+++/FR8fL39/f9WtW1ddu3bV448/LpPJZLN+QkKCPv/8c61bt07R0dHy9fVVw4YN1b9/f7Vo0cJu2zt37tSCBQt08OBBJSYmqnLlygoNDdXgwYPl6+ubY738tAkAAAAABa3IX3HcuXOnevXqpblz52rfvn3y9/dX7dq1ZRiGtm3bpjfeeEMvvviiUlNTs9W9cuWKunXrps8++0xRUVG6++675e3trS1btuhf//qXvvrqqxzbXbRokfr27astW7bI29tbd999t6KiojR79mx1795d165ds1kvP20CAAAAgDMU+eBoGIaqVq2qsWPHavv27dq4caOWL1+uXbt26b333pOXl5e2bNmi6dOnZ6s7duxYRUZGKiQkRBs3btSKFSu0ZcsWTZgwQYZhaNKkSTp69Gi2ehEREZo8ebIkacKECdqyZYtWrFihjRs3KiQkRCdOnNC4ceNs9tfRNgEAAADAWYp8cGzQoIHWrl2r559/XmXLls2yr2vXrho2bJgk6bvvvlNGRoZ135EjR7R582a5ublp2rRpCgoKkiSZTCb17NlTXbp0kdls1qxZs7K1OWvWLGVkZKhLly7q2bOndRpsUFCQPv74Y7m5uWn9+vU6duxYlnr5aRMAAAAAnKXIB0c/Pz95enrmuL9NmzaSpGvXrunKlSvW7evWrZMktWzZUtWrV89Wr2fPnpKkrVu3KjEx0bo9ISFBv/76qySpR48e2erVqFFDLVu2lCStXbs2yz5H2wQAAAAAZyrywfFmkpOTrV/7+PhYvz5w4IAkqWnTpjbrNWjQQF5eXkpJSckydfTo0aNKTU2Vl5eXGjRoYLNukyZNJEkHDx7Mst3RNgEAAADAmYp9cPzxxx8lScHBwfLz87NuP3nypCTpjjvusFnP09NTlSpVkiRFRkZat1u+rly5co5XOi3HvLFeftoEAAAAAGcq8o/jsCciIkLffPONJGnw4MFZ9l2/fl2SVKpUqRzrW/bFxsY6VM9SNr9tOsLDo9j/zaBQubu7Zfl/m9KNW9QbAEBWpiL3OZmrzx0UGsbHdTE2/1Nsg+OlS5f08ssvKz09XQ899JAeffTRLPtTUlIkye79kV5eXpKyTnfNSz1L2fy2mVdubiaVKVPS4fooOAEBJXLcl3Ah7hb25PaSw2NXiz3Oi22cl5xxbmxzdy+6n5P2PndQ+Bgf18XYFNPgGBcXp0GDBik6OlohISGaOnVqtjLe3t5KSkpSWlpajsexPPvxxnsjvb29JSlX9Sxl89tmXmVkGIqNZXGdwuTu7qaAgBKKjU2S2Zxhs4zZzBXHnBicGps4L7ZxXnLGubHNbDZ09WpCYXejQOXmcweFh/FxXUV9bAICSuT6amqxC44JCQkaOHCgjhw5onvuuUdffPFFlnsbLQICApSUlJRtOumNLPsCAgKs23Kahmqr3j+npDrapiPS04veN/7tyGzOsDMW/EYHAIXDKLKfk/Y/d1DYGB/XxdgUs8VxkpKS9MILL+jAgQOqUaOGFixYoDJlytgsW6NGDUnSqVOnbO5PS0tTdHR0lrI3fh0dHZ3jlcPTp09nq5efNgEAAADAmYpNcExJSdGQIUMUHh6uKlWqKCwsTOXLl8+xfKNGjSRJe/futbn/0KFDSktLk7e3t+rUqWPdXqdOHXl6eio1NVWHDh2yWddyTEsb+W0TAAAAAJypWATHtLQ0vfzyy9qxY4eCgoL05ZdfWh9rkZNOnTpJknbt2mXzCuCSJUskSW3atFHJkv+7gd7Pz0/333+/JGnp0qXZ6p08eVI7d+6UJIWGhhZImwAAAADgTEU+OJrNZo0cOVJbt25V+fLl9eWXX6patWo3rRcSEqJ27drJbDZr+PDhunDhgiTJMAwtWbJEq1atkpubm4YMGZKt7tChQ2UymbRq1SotWbJExv9ffeDChQsaMWKEMjIy1LFjRwUHBxdYmwAAAADgLEV+cZw1a9Zo3bp1kjIfZTFmzJgcy44bN05169a1/nvy5Mnq1auXDh8+rA4dOqhmzZq6evWqzp07J5PJpDFjxigkJCTbcRo0aKDRo0dr6tSpGj9+vGbPnq0yZcro+PHjSk1N1Z133qmJEyfa7IOjbQIAAACAsxT54Gh5fIUkRUVFKSoqKseycXFZn5sXGBioZcuWae7cuVq7dq2OHz8uX19ftWnTRgMGDFDLli1zPFbfvn1Vu3ZtzZ8/X4cOHdLly5dVuXJlhYaGavDgwTlONc1PmwAAAADgDEU+OD711FN66qmnHK7v5+en4cOHa/jw4Xmu26pVK7Vq1eqWtgkAAAAABa3I3+MIAAAAAMgfgiMAAAAAwC6CIwAAAADALoIjAAAAAMAugiMAAAAAwC6CIwAAAADALoIjAAAAAMAugiMAAAAAwC6CIwAAAADALoIjAAAAAMAuj8LuAJDh5qbk1PTC7satlW4o4UKczGZDkpFDIdOt7BEAAACQI4IjCl1yarpe+nBLYXfD5cwY2bawuwAAAABIYqoqAAAAAOAmCI4AAAAAALsIjgAAAAAAuwiOAAAAAAC7CI4AAAAAALsIjgAAAAAAuwiOAAAAAAC7CI4AAAAAALsIjgAAAAAAuwiOAAAAAAC7CI4AAAAAALsIjgAAAAAAuwiOAAAAAAC7CI4AAAAAALsIjgAAAAAAuwiOAAAAAAC7CI4AAAAAALsIjgAAAAAAuwiOAAAAAAC7CI4AAAAAALsIjgAAAAAAuwiOAAAAAAC7CI4AAAAAALsIjgAAAAAAuwiOAAAAAAC7CI4AAAAAALsIjgAAAAAAuwiOAAAAAAC7CI4AAAAAALsIjgAAAAAAuwiOAAAAAAC7CI4AAAAAALsIjgAAAAAAuwiOAAAAAAC7CI4AAAAAALsIjgAAAAAAuzwKuwMAAACuxNPTXYlp5sLuRsFKN5RwIU5msyHJcPgwPl4ecsvIKLh+AbhtEBwBAABukJJq1isfbSnsbrikT15vK18PJqwBxRHvfAAAAACAXQRHAAAAAIBdBEcAAAAAgF0ERwAAAACAXSyOAwAAgFwpkivOFgBWm0VxQHAEAABArrDirG2sNovigO9wAAAAAIBdBEcAAAAAgF0ERwAAAACAXdzj6KJ27typBQsW6ODBg0pMTFTlypUVGhqqwYMHy9fXt7C7BwAAAKAY4YqjC1q0aJH69u2rLVu2yNvbW3fffbeioqI0e/Zsde/eXdeuXSvsLgIAAAAoRgiOLiYiIkKTJ0+WJE2YMEFbtmzRihUrtHHjRoWEhOjEiRMaN25cIfcSAAAAQHFCcHQxs2bNUkZGhrp06aKePXvKZDJJkoKCgvTxxx/Lzc1N69ev17Fjxwq5pwAAAACKC4KjC0lISNCvv/4qSerRo0e2/TVq1FDLli0lSWvXrr2lfQMAAABQfBEcXcjRo0eVmpoqLy8vNWjQwGaZJk2aSJIOHjx4K7sGAAAAoBgjOLqQyMhISVLlypXl6elps8wdd9yRpSwAAAAAOJvJMAyjsDuBTPPmzdMHH3yghg0baunSpTbLbN261fpIjv379zvUjmEYyshwnWHPMKTL15MKuxsup2ypEpyXHHBubOO82MZ5yRnnxjbOS844N7aVK11C+fmN2mT5H0Nynd/QCoabqbB7kD8mk+Tm5qaMjIx8jbGrcnMzWddUuRme4+hCUlJSJCnHq42S5OXllaWsI0wmk9zdXedd7C6pYtmShd0Nl8R5yRnnxjbOi22cl5xxbmzjvOSMc4PiyM2NiZqcARfi7e0tSUpLS8uxTGpqapayAAAAAOBsBEcXUqpUKUnS9evXcyxj2WcpCwAAAADORnB0ITVq1JAkRUdH53jV8fTp01nKAgAAAICzERxdSJ06deTp6anU1FQdOnTIZpm9e/dKkho1anQLewYAAACgOCM4uhA/Pz/df//9kmRzVdWTJ09q586dkqTQ0NBb2jcAAAAAxRfB0cUMHTpUJpNJq1at0pIlS2R5WsqFCxc0YsQIZWRkqGPHjgoODi7kngIAAAAoLniOowsKCwvT1KlTZRiGKlWqpDJlyuj48eNKTU3VnXfeqcWLFyswMLCwuwkAAACgmCA4uqgdO3Zo/vz5OnTokBITE1W5cmWFhoZq8ODBKlmS5ycBAAAAuHUIjgAAAAAAu7jHEQAAAABgF8ERAAAAAGAXwREAAAAAYBfBEQAAAABgF8ERAAAAAGCXR2F3ALgdGYah/fv3a/Pmzdq7d6/+/vtvxcfHy9/fX3Xr1lXXrl31+OOPy2Qy5em4o0eP1ooVK+yWmTt3rtq0aZOf7hcLM2fO1CeffGK3zNtvv61evXrl+dg7d+7UggULdPDgwWyPy/H19XW0y8XG2bNn1aFDh1yVfeqppzRlypRclXXmmBc1Fy9e1LZt2xQREaHff/9dR48eVUpKipo3b65FixbZrZuWlqYvv/xSq1ev1unTp+Xp6ang4GD16dNHDz/8sMN9SkhI0Oeff65169YpOjpavr6+atiwofr3768WLVo4fNzbjSNjEx8fr59//lm//fabfv/9d0VFRSkjI0NBQUFq3ry5+vbtq1q1ajnUn9q1a9vdX65cOW3bts2hY9+OHH3vtG/fXlFRUXaPfejQIXl7e+e5T856T95uHBmb3HxuWCxatEjNmzfPdX+cOeaFheAIOGDnzp3q27ev9d/VqlVTlSpVFBUVpW3btmnbtm368ccfNXPmTHl5eeX5+JUqVVKlSpVs7itVqpSj3S6WypYtq+rVq9vcV758+Twfb9GiRZo0aZIMw1DFihVVqVIlHT9+XLNnz9b69eu1ePFilS5dOp+9Ltq8vb1177335rg/JSVFhw8fliQ1btw4z8cv6DEvin788cdcB/IbpaSkqF+/ftq7d6/c3d1Vs2ZNJSUlaffu3dq9e7cGDRqk119/Pc/HvXLlip599llFRkbKy8tLNWvW1JUrV7RlyxZt3bpV48aN03PPPZfn496OHBmbd955R6tXr5Yk+fj4qHr16jIMQydPntSyZcu0evVqvfPOO+rWrZvD/apXr57Nz7Pi9vPO0feORa1ateTn52dzX17/2Cw57z15O3JkbCpVqmT38+jcuXM6d+6cfHx8VLduXYf6VdBjXpgIjoADDMNQ1apV9a9//UuPPvqoypYta923cuVKjRs3Tlu2bNH06dP1xhtv5Pn43bp108svv1yQXS622rRpo6lTpxbIsSIiIjR58mRJ0oQJE9SjRw+ZTCbFxMRoyJAhOnz4sMaNG6eZM2cWSHtFVfny5fX111/nuH/FihUaPXq0fHx81Llz5zwfvyDHvKjy8/NT69atVb9+fdWvX19HjhzRrFmzblrvgw8+0N69e1W1alXNnTtXd911lyRp06ZNeu211zR37lzde++9at++fZ76M3bsWEVGRiokJESzZ89WUFCQDMPQ0qVLNX78eE2aNEn33nuv6tSp49DrvZ04OjZt27bVs88+q1atWlkD3rVr1zRx4kT98MMPGjdunOrVq3fTK4g5mT59uqpWrepQ3aLE0fGx+Pe//12gV9Cd9Z68HTkyNt27d1f37t1z3N+nTx+dO3dODz30UI7h72YKeswLE8ERcECDBg20du1aeXp6ZtvXtWtXnT9/XtOmTdN3332nkSNHys2N24mLglmzZikjI0Ndu3ZVz549rduDgoL08ccf65FHHtH69et17NgxBQcHF2JPb2/Lly+XpHx9UMO+f/6yFBMTc9M6ly5d0jfffCNJmjRpkvUXVEnq0KGDBg4cqFmzZumTTz7J0y+pR44c0ebNm+Xm5qZp06YpKChIUuZf4nv27Km9e/dq1apVmjVrVrH4o4wjYzNmzBiVKVMm2/bSpUtr6tSp+uOPP/TXX3/pu+++09ixYwu0v8WNI+PjLM56T96uCnpszp49q/DwcEmZt02AxXEAh/j5+dkMjRaWexCvXbumK1eu3KpuwYkSEhL066+/SpJ69OiRbX+NGjXUsmVLSdLatWtvad+KEj6oXdfmzZuVlpaW5Xv9Rs8884wk6fDhwzp9+nSuj7tu3TpJUsuWLW1OMbb8kWbr1q1KTEx0pOtFnq3QaOHp6Wkdr8jIyFvVJdwCznpPItPKlStlGIYqVapk8/wWR1xxBJwgOTnZ+rWPj0+e6+/atUt//fWXrl27poCAAIWEhOiJJ55QlSpVCrKbxcKxY8c0cuRIXbx4USVLllTt2rX16KOP6p577snTcY4eParU1FR5eXmpQYMGNss0adJE27dv18GDBwui68WS5YO6cuXKDn9QF9SYI6sDBw5Iyvw+tyUoKEhVq1bV2bNndeDAAd1xxx15Om7Tpk1t7m/QoIG8vLyUkpKio0eP5tg+cpaSkiJJKlGihMPHmDVrli5cuCCz2aygoCC1bNlSnTt3dug+/uLsm2++0fz585WcnKxy5cqpadOmevzxxx2aXeGs9yQyb0lauXKlpMyZZPmZOVaQY17YCI6AE/z444+SpODgYId+MFiuuFhs2LBBn376qV599VUNGjSoQPpYXBw9elRHjx61/nvz5s367LPP9Pzzz2vUqFFyd3fP1XEsf6mvXLlyjlebLR/K/FXfMYZhWFcV7tKli8Mf1AU15sjq5MmTkmT3l8877rhDZ8+ezdN74GbH9fT0VKVKlXTq1ClFRkYSHPMoKSlJmzZtkpRzwMiNZcuWZfn3ihUrNGPGDM2cOVMhISH56mNx8tNPP2X59w8//KDp06fro48+0n333ZenYznrPYnM38POnDkjKf+zXwpyzAsbwREoYBEREdZ7DgYPHpynutWrV9fo0aPVsmVLValSRV5eXvrjjz80f/58rV27Vh9++KF8fX2LzeqC+VGhQgW98soreuCBB1S1alX5+fkpMjJSixcv1jfffKMvv/xSHh4eevPNN3N1vOvXr0uyv6qtZZ+lLPJm9+7dOnv2rCTHPqgLesyRVV7eA7GxsYV+XGSaNm2aLl++rMDAQLuLgOSkQ4cO6tKli4KDg1WxYkUlJCRox44dmjZtms6cOaP+/ftr5cqVOa4EjkzNmzdXy5YtVb9+fVWuXFlpaWnau3evZsyYoSNHjmjIkCH6+uuv8xTCee84j+Ve+yZNmjh8pdYZY17YuMcRKECXLl3Syy+/rPT0dD300EN69NFH81R/yJAh6tevn+rUqaOAgAD5+PioYcOGmj59up599llJ0n/+8x8lJCQ4o/tFSs+ePTVs2DA1aNBAgYGB8vLyUu3atfXOO+9Ylyb/8ssvrUHlZixTvezd22qZsmUpi7yxXG1s2rSpQx/UBT3myCov74Ebp+sX1nGReWXjyy+/lCRNnDjRoRkws2bNUqdOnVS9enV5e3srMDBQjz76qJYuXarKlSvr2rVruX4OXnE2depUde3aVXfffbdKlCihgIAAtWvXzhocUlJS9MEHH+TpmLx3nCMhIcF673V+rjY6Y8wLG8ERKCBxcXEaNGiQoqOjFRISUuCPAxgxYoQ8PT0VGxurnTt3Fuixi5v+/furQoUKSk9P1+bNm3NVx/KA3rS0tBzLpKamZimL3Lvxg/rJJ58s8OM7MubIKi/vgbzc2+2s4xZ327Zt0+jRoyVJw4cPV8eOHQv0+IGBgdZZNRs3bpRhGAV6/OLCx8dHr732mqTM9Q3yMmOF945zrFu3TomJiSpRooRCQ0ML/Pj5GfPCRnAECkBCQoIGDhyoI0eO6J577tEXX3xR4Dc9+/v7Wxf3OHXqVIEeu7hxd3dXw4YNJeX+XOZmGmpupg3BNmd/UDsy5sgqICBAUu7eA5ayhXnc4iw8PFzDhg1TWlqaBg8erBdffNEp7TRu3FhS5gri165dc0obxYHlAfQZGRnW++pyg/eOc1hmvzz88MNOW8DG0TEvbARHIJ+SkpL0wgsv6MCBA6pRo4YWLFhgd2n0/LBMR0lPT3fK8YuTvJ7LGjVqSJKio6Nz/OuuZblzS1nknuWDulOnTk77oOb9kz+W72t7wduR98DNjpuWlqbo6Og8H7e42r9/vwYPHqykpCT16dNHI0eOdFpbN06RNJvNTmunqHP0PDrrPVmcnTlz5pY8Eup2fe8QHIF8SElJ0ZAhQxQeHq4qVaooLCxM5cuXd0pb6enp+vvvvyVJFStWdEobxclff/0lKffnsk6dOvL09FRqaqoOHTpks8zevXslSY0aNSqQPhYXN35QO2OaqkVexxxZWb6v9+3bZ3N/TEyM9f7RvLwHLGUt759/OnTokNLS0uTt7a06derk+rjFUUREhAYNGqTExER1795dY8eOdWp7lveUt7e3Spcu7dS2irI///zT+nVefj456z1ZnFkeCVWlShW1aNHCae04OuaFjeAIOCgtLU0vv/yyduzYoaCgIH355ZdOXVVuyZIliouLk4eHBw+izactW7ZYf+HJ7VLYfn5+uv/++yVJS5cuzbb/5MmT1ntPnTHVsii7FR/Ujow5surQoYM8PT2zfK/fyLKadN26dVW9evVcH7dTp06SMu/1sXXlZMmSJZKkNm3aqGTJko50vVj4448/NGDAAMXFxenxxx/XxIkTZTKZnNZeenq6FixYIElq2bKlPDxYqN9Rc+fOlSTVrFlTQUFBua7nrPdkcfXPZzc68/3j6JgXNoIj4ACz2ayRI0dq69atKl++vL788ktVq1YtV3Xbt2+v9u3ba+3atVm2b9u2TR988IH1uUwWqampWrRokaZMmSJJeuaZZ1ShQoUCeR1F1V9//aXx48fr2LFjWbZnZGTohx9+sE7dateunRo0aJClTK9evdS+fXuFhYVlO+7QoUNlMpm0atUqLVmyxLoYxIULFzRixAhlZGSoY8eOCg4Ods4LK4Ju/KB+8sknb/pBndP45GfMkTvlypVTz549JUljx461zoCQMp+VOW/ePEnSsGHDstVdu3at9WffP4WEhKhdu3Yym80aPny4Lly4ICnze2PJkiVatWqV3NzcNGTIEGe8rCLh5MmT6t+/v65du6bQ0FC99957uX4Oqr2x+fDDD7VixQrFx8dn2X7u3Dm98sorOnDggDw8PGyOOf7niy++0KJFi3T16tUs269evarx48dbFwZ75ZVXstU9cOCAdXzOnz+fZV9+3pPIzvJIKJPJlKvZL/bGJj9j7sr48xDggDVr1ljf9F5eXhozZkyOZceNG6e6deta/x0VFSVJSkxMzFIuKSlJ8+bN07x581SuXDnrX6AiIyOtZTt16qRRo0YV6GspitLT07VkyRItWbJEpUuXVuXKleXu7q7Tp09bFwpo2rSp3n///Wx1Y2JiFBUVpbi4uGz7GjRooNGjR2vq1KkaP368Zs+erTJlyuj48eNKTU3VnXfeqYkTJzr99RUlN35Qd+3a9ablcxqf/Ix5cXTu3Lks59uy8uK+ffuyXPUdOHCgBg0aZP33G2+8ocOHD2v//v167LHHdM899ygxMdF6H1X//v1trt6ZmJho/dlny+TJk9WrVy8dPnxYHTp0UM2aNXX16lWdO3dOJpNJY8aMua2edZYfjozNxIkTdenSJUmZ92H37t3b5rHLly+vGTNmZNlmb2z+/vtvzZ07V2PHjlW1atVUqlQpxcXFKTIyUoZhyNvbW++++6514aniwJHxOX/+vBYuXKhJkyapSpUqCgwMVHJysv7++2+lp6fLzc1NI0aMsF59v1FKSop1fGzdn+3oe7IocvTnmoXlXvtmzZrl6mKAvbHJz5i7MoIj4ADLDyMpMwja+4XIVgCxJSQkREOHDtWBAwd06tQpRUZGKi0tTYGBgbr//vv15JNP2vyLMLKrUqWKXnvtNR04cEAnTpzQqVOnlJqaqlKlSqlNmzZ67LHH9Nhjj8nd3T3Px+7bt69q166t+fPn69ChQ7p8+bIqV66s0NBQDR48mKl0eZTXD+qcOHPMiyKz2WxzFcz09PQs2//57DcfHx8tXLhQYWFh+v7773Xy5El5enqqefPm6t27t8O/BAUGBmrZsmWaO3eu1q5dq+PHj8vX11dt2rTRgAEDitX0fEfG5sbPpJzuwZYy3yd50atXL5UrV04RERG6cOGCoqKi5OnpqXvuuUetWrVS7969HX44+u3KkfGxPNP50KFDio6O1rFjx+Tu7q6qVauqefPmevbZZx2+f9dZ78nbkaM/16SCfySUM8e8MJkMHrwDAAAAALCDexwBAAAAAHYRHAEAAAAAdhEcAQAAAAB2ERwBAAAAAHYRHAEAAAAAdhEcAQAAAAB2ERwBAAAAAHYRHAEAAAAAdhEcAQAAAAB2ERwBALBj+fLlql27ttq3b1/YXYGTnT17VrVr11bt2rV19uzZwu4OALgUj8LuAAAAeVG7dm2H606ZMkVPPfVUAfbm9rRr1y49//zzkqSFCxeqRYsWhdwj5wsLC1NcXJw6duyoOnXqFHZ3AOC2Q3AEANxWypUrZ3N7YmKiEhMT7Zbx8fFxWr/g2hYuXKioqChVqVKF4AgADiA4AgBuK9u2bbO5febMmfrkk0/slgEAAI7hHkcAAAAAgF0ERwBAsXHkyBG9+eabateunerXr69mzZrpmWeeUVhYmFJTUx065tmzZ9WpUyfVrl1bTz75pC5dupRt/6RJk/Too4+qcePGatiwoUJDQ/Xuu+8qOjra5jH/uSBPRESEXn31Vd1///2qV6+eOnTooClTpuj69esO9Tm/9u7dq9dff916Hps0aaLu3bvr888/V0JCgs06o0ePVu3atTV69GhJ0tq1a9WnTx81b95cDRs2VJcuXfTll18qIyMjx3YNw9CyZcvUs2dPNW7cWE2aNNHTTz+tJUuWyDCMbG1ImVeia9euraioKEnSW2+9ZV0Ax/JfTi5duqR3331X7du3V/369dW6dWsNHz5cJ06ccOS0AcBtjamqAIBiISwsTFOnTpVhGJIkf39/JSUlaf/+/dq/f7+WL1+uefPmqUKFCrk+5tGjRzVo0CBdvHhRrVu31syZM+Xn52fdv3r1ao0dO9YaSr28vOTm5qbIyEhFRkZq+fLlmjFjhu6///4c2/j+++/11ltvKS0tTf7+/jKbzTp79qzCwsK0bds2LVmyRCVLlnTwrORNRkaGJk+erEWLFlm3+fr6KikpSb///rt+//13LV++XF988YWqVKmS43EmTJigr776Sm5ubvLz81NycrKOHTumyZMn68iRI3rvvfey1TGbzXr99df1008/SZJMJpMCAgIUERGhQ4cOaffu3fL09MxWz9fXV+XKldOVK1eUkZEhPz+/XN3revz4cY0ZM0aXL19WiRIlJEmXL1/WTz/9pF9++UVfffWVgoODb3ocACgquOIIACjyfv75Z02ZMkWGYahDhw7auHGj9uzZo3379um9995TyZIl9ccff+iVV16R2WzO1TF37typ3r176+LFi3r00Uc1Z86cLKFx27ZtGjVqlDIyMjRw4EBt2rRJhw4d0oEDB7RmzRqFhoYqISFBr776ao5XHq9cuaIxY8aoa9eu2rJli7XP48ePl6enp/766y/NmzevQM5RbsyYMUOLFi1S2bJlNX78eO3atUv79+/XwYMHtXDhQtWtW1eRkZF6+eWXc7xyuHnzZi1dulRvvfWWwsPDFR4erp07d+rpp5+WJK1cuVI7duzIVu+LL76whsZ+/fppx44d2r17t8LDwzVixAj9+OOP2rx5c7Z6AwYM0LZt21SpUiVJ0tixY7Vt27Ys/9ny5ptvqnr16vruu+904MAB7d+/XwsWLFD58uUVHx+viRMnOnQOAeB2RXAEABR5H3zwgSSpadOmmjlzpqpVqyYp8wpg165d9eGHH0qS9u/frw0bNtz0eD/99JMGDhyo+Ph4/etf/9JHH30kLy8v6/6MjAxNmDBBGRkZGj9+vN544w1VrVpVJpNJJpNJd911l6ZPn6727dsrPj5eCxYssNlOUlKSHn30Ub377rvW4FOiRAk999xz6t27tyTpxx9/dPzE5MHZs2f1+eefy8fHR/Pnz9dzzz2n0qVLS5I8PT3VokULLVq0SBUrVtThw4dthjhJun79uiZMmKC+fftag3aZMmX07rvvKiQkxOZrSkxM1Jw5cyRJ3bt31+jRo1WmTBlJkp+fn1544QUNGzasQKfuli1bVgsWLFD9+vUlSR4eHmrdurUmTJggSdqzZ4/Onz9fYO0BgKsjOAIAirRjx45Z70kbMmSI3N3ds5Vp3769GjRoIOnmQWzhwoUaMWKE0tPT9frrr2vMmDEymUxZyoSHh+vkyZMqU6aM9UqaLV27dpUk/fbbbzmWGTJkiM3tHTp0kCSdOnVKSUlJdvtcEFasWCGz2awHHnggxymafn5+6tixoyTp119/tVmmUqVKevLJJ23us9zT+ccff2TZvm3bNsXHx0uSXnzxRZt1+/XrZ51SWhD69+9vc0prmzZtrFNi/9lPACjKuMcRAFCkRURESMq8YtS8efMcy7Vu3VqHDh2ylrflww8/1Ny5c+Xh4aFJkyZZg98/7du3T5IUHx+vBx54IMfjpaWlSVKOU1VLly6t6tWr29x3472YsbGxBRqabLG8pm3btum+++7LsZzlWZo5vab69etnC9oWQUFBkpTtyuHhw4clSZUrV7ZeLf4nPz8/hYSEaM+ePXZeRe5Z/pDwTx4eHgoMDFRMTEyhLU4EAIWB4AgAKNKuXLkiKXM65I3TSf+pYsWKkjIXQLElKipKc+fOlSSNGDEix9AoSRcuXJCUGQz/ucqqLcnJyTa321v05sYrp5YA6kyW15SYmGgNh/bk5zWlp6dn2W4Zw5stXGQJngXBXj89PDJ/ffpnPwGgKCM4AgCQC+XLl1fNmjW1Y8cOzZ49W82aNcvxqpRlgZ2GDRtq6dKlt7KbTmN5TYMGDdLrr79eKH3I6UolAMD5uMcRAFCkBQYGSpKuXr1q91mNloVOypYta3O/l5eXPvvsM91///2Ki4tTv379tH//fptly5cvLynn6Zq3o8J8TZYxtFz1zElMTMyt6A4AFEsERwBAkVavXj1JmdMKd+/enWM5yyMgLKto2uLj46NZs2apTZs2io+P14ABA7R3795s5e69915J0sWLF/X777/np/suw/Katm/frpSUlFvatmW11aioKJ09e9ZmmYSEBOu9kLZYrlZanuMJAMgbgiMAoEgLDg5WzZo1JUmzZ8+2+ZzGrVu36uDBg5KkRx991O7xvL299emnn6pt27ZKSEjQwIEDFR4enqVMixYtrIvaTJkyxe6VTkm6du1abl9OoenWrZs8PDx09epVzZgxw27Z1NRUJSQkFFjb9913n/XRHZbHcvxTWFiY3dVlLfXj4uIKrF8AUJwQHAEARZ7lnrw9e/bolVde0ZkzZyRlLiqzevVqjRgxQpLUuHFj6+Mk7PHy8tLMmTPVvn17JSYmavDgwdq5c6d1v4eHh9555x15eHho79696t27t3bs2JFlEZszZ87o66+/Vrdu3bR48eKCfLl5EhcXpytXrtj9zzAM3XHHHdZHg8ybN09vvvmm/vzzT+tx0tPTdfToUX3yySd6+OGHdfTo0QLro6+vrwYNGiRJWrp0qd5//31r2I6Pj9fnn3+uTz75RKVKlcrxGPfcc48kae3atayGCgAOYHEcAECR165dO7311luaOnWqNm7cqI0bNyogIEBJSUnWMFerVi1Nnz7d5nMebfHy8tKMGTM0YsQIrV+/Xi+88II+++wztWrVSpLUqlUrTZ8+XW+++aYOHjyovn37ytPTUyVLllRiYmKWq5C5CavOMmzYsJuWCQ8PV0BAgIYNGyaz2azZs2dr1apVWrVqlXx8fOTj46O4uLgsV3MLeiGbgQMH6siRI1q3bp2++OILLViwQP7+/oqPj5fZbFaXLl1kMpm0cuVKm6vn9uzZUz/88IP279+vVq1aKTAw0Fpu8+bNBdpXACiKuOIIACgW+vbtq2XLlumJJ55QpUqVlJSUJB8fHzVq1EhvvfWWli1blufHOXh6emratGkKDQ1VcnKyXnjhBf3222/W/R07dtSGDRv00ksvqUGDBvL19VVcXJy8vLwUHBysp59+Wp9++qkGDBhQ0C/XKUwmk1599VWtXr1azz77rO6++265ubkpPj5eAQEBaty4sQYMGKBvvvlGTZo0KdC2PTw8NH36dL377rtq0KCBfHx8lJ6ernr16undd9/V+++/r9jYWElSQEBAtvrNmjXTnDlz1Lp1a/n7++vy5cuKiopSVFRUgfYTAIoqk8Fd4gAA4DZnGIbatm2r8+fP67333rP7nE0AQN5xxREAANz2Vq1apfPnz8vDw0OtW7cu7O4AQJFDcAQAALeFESNGaO3atbpy5Yp126VLl/T555/r3//+tySpS5cuqlChQmF1EQCKLKaqAgCA20LTpk2tj9MoUaKEPDw8sjxeo2nTppozZ4710RsAgIJDcAQAALeFlStX6pdfftGRI0d05coVJSYmyt/fX3Xq1FHnzp3VpUsXeXp6FnY3AaBIIjgCAAAAAOziHkcAAAAAgF0ERwAAAACAXQRHAAAAAIBdBEcAAAAAgF0ERwAAAACAXQRHAAAAAIBdBEcAAAAAgF0ERwAAAACAXQRHAAAAAIBd/w/hveuQktl8cAAAAABJRU5ErkJggg==
"/>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>Let's look at just the tokens which begin with '##'.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [87]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">num_subwords</span> <span class="o">=</span> <span class="mi">0</span>

<span class="n">subword_lengths</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># For each token in the vocabulary...</span>
<span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
    
    <span class="c1"># If it's a subword...</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">token</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">2</span> <span class="ow">and</span> <span class="n">token</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">]</span> <span class="o">==</span> <span class="s1">'##'</span><span class="p">:</span>
        
        <span class="c1"># Tally all subwords</span>
        <span class="n">num_subwords</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="c1"># Measure the sub word length (without the hashes)</span>
        <span class="n">length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">token</span><span class="p">)</span> <span class="o">-</span> <span class="mi">2</span>

        <span class="c1"># Record the lengths.        </span>
        <span class="n">subword_lengths</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">length</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>How many '##' tokens are there vs. the full vocab?</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [88]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">vocab_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">'Number of subwords: </span><span class="si">{:,}</span><span class="s1"> of </span><span class="si">{:,}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">num_subwords</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">))</span>

<span class="c1"># Calculate the percentage of words that are '##' subwords.</span>
<span class="n">prcnt</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">num_subwords</span><span class="p">)</span> <span class="o">/</span> <span class="n">vocab_size</span> <span class="o">*</span> <span class="mf">100.0</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="si">%.1f%%</span><span class="s1">'</span> <span class="o">%</span> <span class="n">prcnt</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Number of subwords: 5,828 of 30,522
19.1%
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>Plot the subword lengths (not including the two '##' characters).</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [91]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">subword_lengths</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">subword_lengths</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Subword Token Lengths (w/o "##")'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Subword Length'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'# of ## Subwords'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[91]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>Text(0, 0.5, '# of ## Subwords')</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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
"/>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="Misspellings">Misspellings<a class="anchor-link" href="#Misspellings">¶</a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [92]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="s1">'misspelled'</span> <span class="ow">in</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span> <span class="c1"># Right</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[92]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>False</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [42]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="s1">'mispelled'</span> <span class="ow">in</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span> <span class="c1"># Wrong</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[42]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>False</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [43]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="s1">'government'</span> <span class="ow">in</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span> <span class="c1"># Right</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[43]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>True</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [44]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="s1">'goverment'</span> <span class="ow">in</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span> <span class="c1"># Wrong</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[44]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>False</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [45]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="s1">'beginning'</span> <span class="ow">in</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span> <span class="c1"># Right</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[45]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>True</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [46]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="s1">'begining'</span> <span class="ow">in</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span> <span class="c1"># Wrong</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[46]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>False</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [47]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="s1">'separate'</span> <span class="ow">in</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span> <span class="c1"># Right</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[47]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>True</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [48]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="s1">'seperate'</span> <span class="ow">in</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span> <span class="c1"># Wrong</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[48]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>False</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>What about contractions?</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [49]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="s2">"can't"</span> <span class="ow">in</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[49]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>False</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [93]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="s2">"cannot"</span> <span class="ow">in</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[93]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>True</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [50]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="s2">"cant"</span> <span class="ow">in</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[50]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>False</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="Start-vs.-Mid-Subwords">Start vs. Mid Subwords<a class="anchor-link" href="#Start-vs.-Mid-Subwords">¶</a></h3><p>For single characters, there are both the individual character and the '##' version for every character. Is the same true of subwords?</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [51]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># For each token in the vocabulary...</span>
<span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
    
    <span class="c1"># If it's a subword...</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">token</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">2</span> <span class="ow">and</span> <span class="n">token</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">]</span> <span class="o">==</span> <span class="s1">'##'</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">token</span><span class="p">[</span><span class="mi">2</span><span class="p">:]</span> <span class="ow">in</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">'Did not find a token for'</span><span class="p">,</span> <span class="n">token</span><span class="p">[</span><span class="mi">2</span><span class="p">:])</span>
            <span class="k">break</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Did not find a token for ly
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [52]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="s1">'##ly'</span> <span class="ow">in</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[52]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>True</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [53]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="s1">'ly'</span> <span class="ow">in</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[53]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>False</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="Names">Names<a class="anchor-link" href="#Names">¶</a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [54]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>wget
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Requirement already satisfied: wget in /usr/local/lib/python3.10/dist-packages (3.2)
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [55]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">wget</span>
<span class="kn">import</span> <span class="nn">random</span> 

<span class="nb">print</span><span class="p">(</span><span class="s1">'Beginning file download with wget module'</span><span class="p">)</span>

<span class="n">url</span> <span class="o">=</span> <span class="s1">'http://www.gutenberg.org/files/3201/files/NAMES.TXT'</span>
<span class="n">wget</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="s1">'first-names.txt'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Beginning file download with wget module
</pre>
</div>
</div>
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[55]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>'first-names (1).txt'</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [56]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Read them in.</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">'first-names.txt'</span><span class="p">,</span> <span class="s1">'rb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">names_encoded</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">readlines</span><span class="p">()</span>

<span class="n">names</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Decode the names, convert to lowercase, and strip newlines.</span>
<span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">names_encoded</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">name</span><span class="o">.</span><span class="n">rstrip</span><span class="p">()</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s1">'utf-8'</span><span class="p">))</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="k">continue</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">'Number of names: </span><span class="si">{:,}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">names</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Example:'</span><span class="p">,</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">names</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Number of names: 21,985
Example: gabbey
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [57]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">num_names</span> <span class="o">=</span> <span class="mi">0</span>

<span class="c1"># For each name in our list...</span>
<span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">names</span><span class="p">:</span>

    <span class="c1"># If it's in the vocab...</span>
    <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span><span class="p">:</span>
        <span class="c1"># Tally it.</span>
        <span class="n">num_names</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="si">{:,}</span><span class="s1"> names in the vocabulary'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">num_names</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>3,869 names in the vocabulary
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p><strong>Further Research</strong></p>
<ul>
<li>Add more modern names<ul>
<li>This repo / file contains some more modern names. The file download isn't working, though.</li>
<li><code>https://raw.githubusercontent.com/arineng/arincli/master/lib/male-first-names.txt</code></li>
</ul>
</li>
<li>Add common names from other languages.</li>
</ul>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="Numbers">Numbers<a class="anchor-link" href="#Numbers">¶</a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [58]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Count how many numbers are in the vocabulary.</span>
<span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>

<span class="c1"># For each token in the vocabulary...</span>
<span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>

    <span class="c1"># Tally if it's a number.</span>
    <span class="k">if</span> <span class="n">token</span><span class="o">.</span><span class="n">isdigit</span><span class="p">():</span>
        <span class="n">count</span> <span class="o">+=</span> <span class="mi">1</span>
        
        <span class="c1"># Any numbers &gt;= 10,000?</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">token</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">4</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">token</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">'Vocab includes </span><span class="si">{:,}</span><span class="s1"> numbers.'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">count</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Vocab includes 881 numbers.
</pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [59]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Count how many dates between 1600 and 2021 are included.</span>
<span class="n">count</span> <span class="o">=</span> <span class="mi">0</span> 
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1600</span><span class="p">,</span> <span class="mi">2021</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="ow">in</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span><span class="p">:</span>
        <span class="n">count</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">'Vocab includes </span><span class="si">{:,}</span><span class="s1"> of 421 dates from 1600 - 2021'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">count</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Vocab includes 384 of 421 dates from 1600 - 2021
</pre>
</div>
</div>
</div>
</div>
</div>
</main>
</body>
</html>]]></content><author><name>Zhu Tianda</name></author><category term="coding" /><category term="AI" /><category term="BERT" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">BERT GPT Diffusion Research</title><link href="http://0.0.0.0:8855/learning/2023/12/01/BERT-GPT-Diffusion-Research.html" rel="alternate" type="text/html" title="BERT GPT Diffusion Research" /><published>2023-12-01T00:00:00+08:00</published><updated>2023-12-01T00:00:00+08:00</updated><id>http://0.0.0.0:8855/learning/2023/12/01/BERT-GPT-Diffusion-Research</id><content type="html" xml:base="http://0.0.0.0:8855/learning/2023/12/01/BERT-GPT-Diffusion-Research.html"><![CDATA[<h1 id="1bert-bidirectional-encoder-representation-transformer1">1.BERT (Bidirectional Encoder Representation Transformer#1)</h1>

<h2 id="1-the-bert-paper--resources">1, The BERT Paper &amp; Resources</h2>

<ul>
  <li>
    <table>
      <tbody>
        <tr>
          <td>[Mastering BERT Model: A Complete Guide to Build it from Scratch</td>
          <td>by CheeKean</td>
          <td>Medium](https://kean-chan.medium.com/complete-guide-to-building-bert-model-from-sratch-3e6562228891)</td>
        </tr>
      </tbody>
    </table>
  </li>
  <li>
    <table>
      <tbody>
        <tr>
          <td>[BERT Explained: A Complete Guide with Theory and Tutorial</td>
          <td>by Samia Khalid</td>
          <td>Medium](https://medium.com/@samia.khalid/bert-explained-a-complete-guide-with-theory-and-tutorial-3ac9ebc8fa7c)</td>
        </tr>
      </tbody>
    </table>
  </li>
  <li>[google-research/bert: TensorFlow code and pre-trained models for BERT (github.com)</li>
  <li>
    <p><a href="https://colab.research.google.com/github/google-research/bert/blob/master/predicting_movie_reviews_with_bert_on_tf_hub.ipynb#scrollTo=xiYrZKaHwV81">Colab Notebook: Predicting Movie Review Sentiment with BERT on TF Hub</a></p>
  </li>
  <li><a href="https://medium.com/swlh/a-simple-guide-on-using-bert-for-text-classification-bbf041ac8d04">Using BERT for Binary Text Classification in PyTorch</a></li>
</ul>

<h3 id="bert-paper">BERT Paper</h3>

<ul>
  <li>
    <p><strong>Paper:</strong> <a href="https://arxiv.org/pdf/1810.04805.pdf">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</a></p>
  </li>
  <li><strong>Submitted:</strong> Oct 11, 2018</li>
  <li><strong>First Author:</strong> Jacob Devlin, Google AI Language</li>
  <li><strong>GitHub Repo:</strong> [github.com/google-research/bert</li>
</ul>

<h3 id="the-annotated-transformer-blog-post">The Annotated Transformer (Blog Post)</h3>

<ul>
  <li><a href="https://github.com/google-research/bert"></a></li>
  <li><strong>Initial Commit:</strong> Oct 31, 2018</li>
  <li>“The Annotated Transformer” blog post : https://nlp.seas.harvard.edu/2018/04/03/attention.html</li>
</ul>

<h3 id="bert-announcement-post">BERT Announcement Post</h3>

<ul>
  <li><strong>Google Blog Post:</strong> <a href="https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html">Open Sourcing BERT: State-of-the-Art Pre-training for Natural Language Processing</a></li>
  <li><strong>Published:</strong> Nov 2, 2018</li>
  <li><strong>Authors:</strong> Jacob Devlin, Ming-Wei Chang</li>
</ul>

<h3 id="attention-is-all-you-need-paper">Attention is all you need (Paper)</h3>

<ul>
  <li><strong>Paper:</strong> <a href="https://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf">Attention is all you need</a></li>
  <li><strong>Submitted:</strong> Jun 12, 2017</li>
  <li><strong>First Author:</strong> Ashish Vaswani, Google Brain</li>
</ul>

<h3 id="jay-alammars-posts">Jay Alammar’s Posts</h3>

<ol>
  <li>BERT——<a href="http://jalammar.github.io/illustrated-bert/">The Illustrated BERT, ELMo, and co. (How NLP Cracked Transfer Learning)</a>
    <ul>
      <li>Published: Dec 3, 2018</li>
    </ul>
  </li>
  <li>Transformer——<a href="https://jalammar.github.io/illustrated-transformer/">The Illustrated Transformer</a>
    <ul>
      <li>Published: Jun 27, 2018</li>
    </ul>
  </li>
  <li>Attention—— <a href="https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/">Visualizing A Neural Machine Translation Model (Mechanics of Seq2seq Models With Attention)</a>
    <ul>
      <li>Published: May 9, 2018</li>
    </ul>
  </li>
</ol>

<h2 id="2-ber-architecture">2, BER Architecture</h2>

<p>BERT which stands for <a href="https://arxiv.org/abs/1810.04805"><strong>*Bidirectional Encoder Representation Transformer*</strong></a>, a transformer based language model published by Google Research Team at 2018, is still gaining attention and being widely applied in Data Science Project today. This is due to the incredible model performance on multiple NLP tasks including question-answering, text tagging and sentence classification.</p>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/1tf_5g-MwQG0cijTR1o15MQ-1684152127269-7.png" alt="img" style="zoom: 80%;" /></p>

<p>BERT relies on a Transformer mechanism, it contains the attention module that learns contextual relationships between words in a text.</p>

<p>There are four types of pre-trained versions of BERT depending on the scale of the model architecture:</p>

<p><strong>BERT-Base</strong>: 12-layer, 768-hidden-nodes, 12-attention-heads, 110M parameters
<strong>BERT-Large</strong>: 24-layer, 1024-hidden-nodes, 16-attention-heads, 340M parameters</p>

<p><strong>*Fun fact*</strong>: BERT-Base was trained on 4 cloud TPUs for 4 days and BERT-Large was trained on 16 TPUs for 4 days!</p>

<p>For details <strong>on the hyperparameter and more on the architecture and results breakdown</strong>, need go through the original paper.</p>

<h3 id="wordpiece-tokenization"><strong>WordPiece</strong> Tokenization</h3>

<p>The initial stage of creating a fresh BERT model involves training a new tokenizer. Tokenization is the process of breaking down a text into smaller units called “<strong>*tokens*</strong>,” which are then converted into a numerical representation. An example of this would be splitting the sentence</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>“I like surfboarding!” → [‘[CLS]’, ‘i’, ‘like’, ‘surf’, ‘##board’, ‘##ing’, ‘!’, ‘[SEP]’] → [1, 48, 250, 4033, 3588, 154, 5, 2]
</code></pre></div></div>

<p>A tokenized BERT input always starts with a special <strong>[CLS]</strong> token and ends with a special <strong>[SEP]</strong> token, which are used for specific purposes that will be explained later. BERT employs a <strong>WordPiece</strong> tokenizer, which can split a single word into multiple tokens.</p>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/image-20230515201443054.png" alt="image-20230515201443054" /></p>

<p>all sub words start with “##” except the beginning words</p>

<p><strong>By referring to the explanation from <a href="https://huggingface.co/course/chapter6/6?fw=pt">HuggingFace</a>,, WordPiece computes a score for each pair, using the following:</strong></p>

<p><strong>*score = (freq_of_pair) / (freq_of_first_element × freq_of_second_element)*</strong></p>

<p>By dividing the frequency of the pair by the product of the frequencies of each of its parts, <strong>the algorithm prioritizes the merging of pairs where the individual parts are less frequent in the vocabular</strong>y. For instance, it won’t necessarily merge <code class="language-plaintext highlighter-rouge">("un", "##able")</code> even if that pair occurs very frequently in the vocabulary, because the two pairs <code class="language-plaintext highlighter-rouge">"un"</code> and <code class="language-plaintext highlighter-rouge">"##able"</code> will likely each appear in a lot of other words and have a high frequency. In contrast, a pair like <code class="language-plaintext highlighter-rouge">("hu", "##gging")</code> will probably be merged faster (assuming the word “hugging” appears often in the vocabulary) since <code class="language-plaintext highlighter-rouge">"hu"</code> and <code class="language-plaintext highlighter-rouge">"##gging"</code> are likely to be less frequent individually.</p>

<p>To train the tokenizer, the <code class="language-plaintext highlighter-rouge">BertWordPieceTokenizer</code> (from tokenizers import BertWordPieceTokenizer) from the transformer library was used with the steps below:</p>

<ol>
  <li>Saving the conversation text into multiple .txt files (with batch of N=10000)</li>
  <li>Define <code class="language-plaintext highlighter-rouge">BertWordPieceTokenizer</code> with some parameters like<code class="language-plaintext highlighter-rouge">clean_text</code> to remove control characters, <code class="language-plaintext highlighter-rouge">handle_chinese_chars</code> to include spaces around Chinese characters, <code class="language-plaintext highlighter-rouge">stripe_accents</code> to remove accents and make é → e, ô → o, and<code class="language-plaintext highlighter-rouge">lowercase</code> to view capital and lowercase characters as equal.</li>
  <li>Train the tokenizer based on the file path to .txt files with parameters like <code class="language-plaintext highlighter-rouge">vocab_size</code> defines the total number of tokens, <code class="language-plaintext highlighter-rouge">min_frequency</code> for minimum frequency for a pair of tokens to be merged, <code class="language-plaintext highlighter-rouge">special_tokens</code> defines a list of the special tokens that BERT uses, <code class="language-plaintext highlighter-rouge">limit_alphabet</code> for a maximum number of different characters, <code class="language-plaintext highlighter-rouge">workpieces_prefix</code> the prefix added to <em>pieces</em> of words (like ##ing).</li>
</ol>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/image-20230515232127802.png" alt="image-20230515232127802" style="zoom: 67%;" /></p>

<p>To specifically highlight these special tokens for BERT:</p>

<ul>
  <li>
    <p><code class="language-plaintext highlighter-rouge">CLS</code> stands for classification. It serves as the the Start of Sentence (SOS) and represent the meaning of the entire sentence.</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">SEP</code> serves as End of Sentence (EOS) and also the separation token between first and second sentences.</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">PAD</code>to be added into sentences so that all of them would be in equal length. During the training process, please note that the [PAD] token with id of 0 will not contribute to the gradient .</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">MASK</code> for word replacement during masked language prediction</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">UNK</code> serves as a replacement for token if it’s not being found in the tokenizer’s vocab.</p>

    <p><img src="/assets/BERTGPTDiffusion%20Research.assets/image-20230515232305773.png" alt="image-20230515232305773" /></p>
  </li>
</ul>

<blockquote>
  <p>“The first token of every sequence is always a special classification token (<code class="language-plaintext highlighter-rouge">[CLS]</code>). **The final hidden state
 corresponding to this token is used as the aggregate sequence representation for classification
 tasks.” (from the <a href="https://arxiv.org/pdf/1810.04805.pdf">BERT paper</a>) <font color="red">Only this CLS token in latest layer is used for classifier!!!**&lt;/color&gt;</font></p>
</blockquote>

<p><strong>Masking random words in first and second sentences based on predefined probabilities</strong>, at the same time recording the actual word as <code class="language-plaintext highlighter-rouge">bert_label</code>. After which, it converts the sequence string into integer (list of token ids).<img src="/assets/BERTGPTDiffusion%20Research.assets/1jvmH1FS_61yYcz0kBVDAFQ.png" alt="img" /></p>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/image-20230512145537253.png" alt="image-20230512145537253" style="zoom:50%;" /></p>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/image-20230515160809684.png" alt="image-20230515160809684" style="zoom:50%;" /></p>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/image-20230515172553035.png" alt="image-20230515172553035" /></p>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/image-20230515174534472.png" alt="image-20230515174534472" style="zoom:50%;" /></p>

<h3 id="embedding">Embedding</h3>

<p>The embedding in BERT comprises of three parts, mainly the <strong>token embeddings</strong>, <strong>segment embeddings</strong> and <strong>position embeddings</strong>. In NLP model, the order of the words and <strong>their position in a sentence matters</strong> and the meaning of the entire sentence can change if the words are re-ordered.</p>

<ol>
  <li>
    <p><strong>Token embeddings</strong>: A [CLS] token is added to the input word tokens at the beginning of the first sentence and a [SEP] token is inserted at the end of each sentence.</p>
  </li>
  <li>
    <p><strong>segment embeddings</strong>: Sentences (for those tasks such as NLI which take two sentences as input) are differentiated in two ways in BERT:</p>

    <ul>
      <li>
        <p>First, a <code class="language-plaintext highlighter-rouge">[SEP]</code> token is put between them</p>
      </li>
      <li>
        <p>Second, a learned embedding EA is concatenated to every token of the first sentence, and another learned vector EB to every token of the second one</p>
      </li>
    </ul>
  </li>
</ol>

<p>​	That is, there are just <strong>two</strong> possible “segment embeddings”: EA and EB</p>

<p>​	3. <strong>Positional embeddings</strong>: A positional embedding is added to each token to indicate its position in the sentence.</p>

<p>Positional embeddings are learned vectors for every possible position between 0 and 512-1. Transformers don’t have a sequential nature as recurrent neural networks, so some information about the order of the input is needed; if you disregard this, your output will be permutation-invariant.</p>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/image-20230516002634274.png" alt="image-20230516002634274" style="zoom: 80%;" /></p>

<p>Essentially, the Transformer stacks a layer that maps sequences to sequences, <strong>so the output is also a sequence of vectors with a 1:1 correspondence between input and output tokens at the same index.</strong> And as we learnt earlier, BERT does not try to predict the next word in the sentence. Training makes use of the following two strategies:</p>

<h3 id="pre-training-strategy-pre-processing">Pre-Training Strategy (Pre-processing)</h3>

<p>**BERT encode the whole sentence or whole paper to [CLS], so the search (similarity) could be used to compare each other. **</p>

<ol>
  <li>
    <h4 id="masked-language-model-mlm">Masked Language Model (MLM)</h4>

    <p>Instead of predicting the next word in a sequence, BERT makes use of a novel technique called <strong>Masked LM</strong> (MLM): it randomly masks words in the sentence and then it tries to predict them. Masking means that the model looks in both directions and it uses the full context of the sentence, both left and right surroundings, in order to predict the masked word. Unlike the previous language models, it takes both the previous and next tokens into account at the <strong>same time.</strong> The existing combined left-to-right and right-to-left LSTM based models were missing this “same-time part”. (It might be more accurate to say that BERT is non-directional though.)</p>

    <p><strong>But why is this non-directional approach so powerful?</strong></p>

    <p>Pre-trained language representations can either be <strong><em>context-free*** or **</em>context-based*</strong>. <em>Context-based</em> representations can then be <strong><em>unidirectional*** or **</em>bidirectional*</strong>. Context-free models like word2vec generate a single <a href="https://towardsml.com/2018/06/12/understanding-word-embeddings/">word embedding</a> representation (a vector of numbers) for each word in the vocabulary. For example, the word “<em>bank</em>” would have the same context-free representation in “<em>bank account</em>” and “<em>bank of the river.</em>” On the other hand, context-based models generate a representation of each word that is based on the other words in the sentence. For example, in the sentence “<em>I accessed the bank account</em>,” a unidirectional contextual model would represent “<em>bank</em>” based on “<em>I accessed the</em>” but not “<em>account</em>.” However, BERT represents “<em>bank</em>” using both its previous and next context — “<em>I accessed the</em> … <em>account</em>” — starting from the very bottom of a deep neural network, making it deeply bidirectional.</p>

    <p><img src="/assets/BERTGPTDiffusion%20Research.assets/0G8oaGEpkm1nEALmA.png" alt="img" /></p>

    <p><strong>The simple idea **by masking 15% of the words with <code class="language-plaintext highlighter-rouge">MASK </code>token and predict them</strong>. Yet, there is a problem with this masking approach as the model only tries to predict when the [MASK] token is present in the input, while we want the model to try to predict the correct tokens regardless of what token is present in the input. To deal with this issue, <strong>out of the 15%</strong> of the tokens selected for masking:
- 80% of the tokens are actually replaced with the token [MASK].
- 10% of the time tokens are replaced with a random token.
- 10% of the time tokens are left unchanged</p>

    <p>While training the <strong>BERT loss function considers only the prediction of the masked tokens and ignores the prediction of the non-masked ones</strong>. This results in a model that converges much more slowly than left-to-right or right-to-left models..</p>
  </li>
  <li>
    <h4 id="next-sentence-prediction-nsp">**Next Sentence Prediction (NSP)</h4>

    <p>**The NSP task forces the model to understand the relationship between two sentences. In this task, BERT is required to predict whether the second sentence is related to the first one. During training, the model is fed with 50% of connected sentences and another half with random sentence sequenc</p>

    <p>BERT is then required to predict whether the second sentence is random or not, with the assumption that the random sentence will be disconnected from the first sentence:</p>

    <p><img src="/assets/BERTGPTDiffusion%20Research.assets/image-20230516102213636.png" alt="image-20230516102213636" /></p>

    <h1><img src="/assets/BERTGPTDiffusion%20Research.assets/image-20230515234901083.png" alt="image-20230515234901083" style="zoom:67%;" /></h1>
  </li>
</ol>

<p>To predict if the second sentence is connected to the first one or not, basically the complete input sequence goes through the Transformer based model, the output of the [CLS] token is transformed into a 2×1 shaped vector using a simple classification layer, and the IsNext-Label is assigned using softmax.</p>

<p>The model is trained with both Masked LM and Next Sentence Prediction together. This is to minimize the combined loss function of the two strategies — <em>“together is better”</em>.</p>

<h3 id="final-bert-model">Final BERT Model</h3>

<ol>
  <li>
    <p>The <code class="language-plaintext highlighter-rouge">BERT</code> class initializes the embedding layer for the input sequence, as well as multi layers of <code class="language-plaintext highlighter-rouge">EncoderLayer</code> blocks. The <code class="language-plaintext highlighter-rouge">forward</code> method of this class takes in the input sequence and a segment info tensor, applies <strong>attention masking</strong> to the input(for padded token), embeds the input sequence, and then passes it through the encoder blocks to obtain the output.</p>
  </li>
  <li>
    <p>The <code class="language-plaintext highlighter-rouge">NextSentencePrediction</code> class is a 2-class classification model that takes in the output of the <code class="language-plaintext highlighter-rouge">BERT</code> class and predicts whether the input sequence contains two consecutive sentences or not. The <code class="language-plaintext highlighter-rouge">forward</code> method applies applies linear transformation and log softmax function to obtain the <strong>predicted probabilities of the two classes</strong>.</p>
  </li>
  <li>
    <p>The <code class="language-plaintext highlighter-rouge">MaskedLanguageModel</code> class is a multi-class classification model that takes in the output of the <code class="language-plaintext highlighter-rouge">BERT</code> class and predicts the original tokens for the masked input sequence. The <code class="language-plaintext highlighter-rouge">forward</code> method applies a linear transformation and log softmax function to obtain the <strong>predicted</strong> <strong>probabilities of each token in the vocabulary</strong>.</p>
  </li>
  <li>
    <p>The <code class="language-plaintext highlighter-rouge">BERTLM</code> class combines the <code class="language-plaintext highlighter-rouge">BERT</code>, <code class="language-plaintext highlighter-rouge">NextSentencePrediction</code>, and <code class="language-plaintext highlighter-rouge">MaskedLanguageModel</code> classes to create a complete BERT language model.</p>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">BERTLM</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">bert</span><span class="p">:</span> <span class="n">BERT</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">bert</span> <span class="o">=</span> <span class="n">bert</span>
		<span class="bp">self</span><span class="p">.</span><span class="n">next_sentence</span> <span class="o">=</span> <span class="n">NextSentencePrediction</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">bert</span><span class="p">.</span><span class="n">d_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">mask_lm</span> <span class="o">=</span> <span class="n">MaskedLanguageModel</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">bert</span><span class="p">.</span><span class="n">d_model</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">segment_label</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">bert</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">segment_label</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">next_sentence</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="bp">self</span><span class="p">.</span><span class="n">mask_lm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
       
<span class="n">train_data</span> <span class="o">=</span> <span class="n">BERTDataset</span><span class="p">(</span><span class="n">pairs</span><span class="p">,</span> <span class="n">seq_len</span><span class="o">=</span><span class="n">MAX_LEN</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">)</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">pin_memory</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">bert_model</span> <span class="o">=</span> <span class="n">BERT</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">.</span><span class="n">vocab</span><span class="p">))</span>
<span class="n">bert_lm</span> <span class="o">=</span> <span class="n">BERTLM</span><span class="p">(</span><span class="n">bert_model</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">.</span><span class="n">vocab</span><span class="p">))</span>
<span class="n">bert_trainer</span> <span class="o">=</span> <span class="n">BERTTrainer</span><span class="p">(</span><span class="n">bert_lm</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s">'cpu'</span><span class="p">)</span> 
</code></pre></div>    </div>
  </li>
</ol>

<h3 id="optimizer">Optimizer</h3>

<p>The original BERT model was trained using Adam optimizer with a custom learning rate scheduler according to the formula in the <a href="https://arxiv.org/abs/1706.03762">paper</a>.
\(l r a t e=d_{\text {model }}^{-0.5} * \min \left(step\_num^{-0.5}, step\_num * warmup_steps^{-1.5}\right)\)</p>

<h2 id="3-fine-tune-it-should-use-one-example">3, Fine-tune it –(should use one example)</h2>

<p>BERT outperformed the state-of-the-art across a wide variety of tasks under general language understanding like natural language inference, sentiment analysis, question answering, paraphrase detection and linguistic acceptability.</p>

<p>Now, how can we fine-tune it for a specific task? BERT can be used for a wide variety of language tasks. If we want to fine-tune the original model based on our own dataset, we can do so by just adding a single layer on top of the core model.</p>

<p>For example, say we are creating <strong>a question answering application</strong>. In essence question answering is just a prediction task — on receiving a question as input, the goal of the application is to identify the right answer from some corpus. So, given a question and a context paragraph, the model predicts a start and an end token from the paragraph that most likely answers the question. This means that <strong>using BERT a model for our application can be trained by learning two extra vectors that mark the beginning and the end of the answer</strong>.</p>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/0ASTmPsKLcGheaPED.png" alt="img" /></p>

<p>Just like sentence pair tasks, the question becomes the first sentence and paragraph the second sentence in the input sequence. However, this time there are two new parameters learned during fine-tuning: a <strong>start vector</strong> and an <strong>end vector.</strong></p>

<p>In the fine-tuning training, most hyper-parameters stay the same as in BERT training; the paper gives specific guidance on the hyper-parameters that require tuning.</p>

<p>Note that in case we want to do fine-tuning, we need to transform our input into the specific format that was used for pre-training the core BERT models, e.g., we would need to add special tokens to mark the beginning ([CLS]) and separation/end of sentences ([SEP]) and segment IDs used to distinguish different sentences — convert the data into features that BERT uses.</p>

<h1 id="2generative-pre-trained-transformers-gpt2">2.Generative pre<strong>-</strong>trained transformers (GPT#2)</h1>

<table>
  <tbody>
    <tr>
      <td>example 1: [Mastering GPT Model: A Comprehensive Guide to Build it from Scratch</td>
      <td>by CheeKean</td>
      <td>Apr, 2023</td>
      <td>Medium](https://kean-chan.medium.com/creating-and-exploring-gpt-from-scratch-ffe84ac415a9) use <a href="https://github.com/karpathy/nanoGPT"><strong>NanoGPT</strong></a></td>
    </tr>
  </tbody>
</table>

<p>example 2: <a href="https://wingedsheep.com/building-a-language-model/">Building a text generation model from scratch (wingedsheep.com)</a></p>

<h2 id="bype-pair-tokenization">Bype Pair Tokenization</h2>

<p>BPE tokenizer is a data compression technique that <strong>represents frequently occurring sequences of characters</strong> in a text as a single symbol or token.</p>

<ul>
  <li>For instance, consider the sentence</li>
</ul>

<blockquote>
  <p>“the cat sat on the mat.”</p>
</blockquote>

<ul>
  <li>The BPE tokenizer would first split this sentence into individual characters, as follows:</li>
</ul>

<blockquote>
  <p>“t h e c a t s a t o n t h e m a t .”</p>
</blockquote>

<ul>
  <li>Next, it would find the most frequent pair of characters and replace them with a new symbol or token. Let’s say <strong>“th”</strong> is the most frequent pair in this sentence, so it would be replaced with a new token “@@”. The sentence would now look like</li>
</ul>

<blockquote>
  <p>the ca@@ sat on the ma@@ .</p>
</blockquote>

<ul>
  <li>This process is repeated until a desired vocabulary size is reached, or until all character pairs have been replaced with tokens. This way, the tokenizer can handle rare words and misspelled words, by breaking them down into smaller units.</li>
</ul>

<p>Finally, the integer tokens are converted into binary files and saved in the <code class="language-plaintext highlighter-rouge">train.bin</code> and <code class="language-plaintext highlighter-rouge">val.bin</code> files respectively.</p>

<h2 id="gelu-gaussian-error-linear-units-activation-function">GELU (Gaussian Error Linear Units) activation function</h2>

<p>[<a href="https://arxiv.org/abs/1606.08415">1606.08415] Gaussian Error Linear Units (GELUs) (arxiv.org)</a></p>

<p>The GELU (Gaussian Error Linear Units) activation function is a non-linear activation function that was introduced in 2016 by Hendrycks and Gimpel. It is a smooth approximation of the ReLU activation function and has been shown to perform better than the ReLU function in some deep learning models.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">NewGELU</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="s">"""
    Implementation of the GELU activation function currently in Google BERT repo (identical to OpenAI GPT).
    Reference: Gaussian Error Linear Units (GELU) paper: https://arxiv.org/abs/1606.08415
    """</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">x</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="n">torch</span><span class="p">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">math</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">2.0</span> <span class="o">/</span> <span class="n">math</span><span class="p">.</span><span class="n">pi</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="mf">0.044715</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="nb">pow</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">))))</span>
</code></pre></div></div>

<p>The <strong>Gaussian Error Linear Unit</strong>, or <strong>GELU</strong>, is an activation function. The GELU activation function is $xΦ(x)$, where $Φ(x)$ the standard Gaussian cumulative distribution function. The GELU nonlinearity <strong>weights inputs by their percentile</strong>, rather than gates inputs by their sign as in <a href="https://paperswithcode.com/method/relu">ReLUs</a> $(x1_{x&gt;0})$ . Consequently the GELU can be thought of as a smoother ReLU.
\(\text{GELU}\left(x\right) = x{P}\left(X\leq{x}\right) = x\Phi\left(x\right) = x \cdot \frac{1}{2}\left[1 + \text{erf}(x/\sqrt{2})\right]\)
if $X\sim \mathcal{N}(0,1)$</p>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/Screen_Shot_2020-05-27_at_12.48.44_PM.png" alt="img" style="zoom:50%;" /></p>

<p>One can approximate the GELU with $0.5x\left(1+\tanh\left[\sqrt{2/\pi}\left(x + 0.044715x^{3}\right)\right]\right)$or $x\sigma\left(1.702x\right)$. GELUs are used in <a href="https://paperswithcode.com/method/gpt-3">GPT-3</a>, <a href="https://paperswithcode.com/method/bert">BERT</a>, and most other Transformers</p>

<p>GELUs其实是 dropout、zoneout、Relus的综合，GELUs对于输入乘以一个0,1组成的mask，而该mask的生成则是依概率随机的依赖于 输入。假设输入为 $\mathrm{X}$, mask为 $\mathrm{m}$ ，则 $\mathrm{m}$ 服从一个伯努利分布 (??) $(\Phi(\mathrm{x}), \Phi(\mathrm{x})=\mathrm{P}(\mathrm{X}&lt;=\mathrm{x}), \mathrm{X}$ 服从标准正太分布 $)$ ，这么选择是因为神 经元的输入趋向于正太分布，<strong>这么设定使得当输入x减小的时候，输入会有一个更高的概率被dropout掉</strong>，<strong>这样的激活变换就会随机依赖于 输入了</strong>。数学表达如下:
\(\mathrm{GELU}(\mathrm{x})=\mathrm{xP}(\mathrm{X}&lt;=\mathrm{x})=\mathrm{x} \Phi(\mathrm{x})\)
这里 $\Phi(\mathrm{x})$ 是正太分布的概率函数 (CDF)，可以简单采用正太分布 $\mathbb{N}(0,1)$, 要是觉得不刺激当然可以使用参 数化的正太分布 $\mathbb{N}(\mu, \sigma)$, 然后通过训练得到 $\mu, \sigma$ 。</p>

<p><strong>original paper state:</strong></p>

<p>We motivate our activation function by combining properties from dropout, zoneout, and ReLUs. First note that a ReLU and dropout both yield a neuron’s output with the ReLU deterministically multiplying the input by zero or one and dropout stochastically multiplying by zero. Also, a new RNN regularizer called zoneout stochastically multiplies inputs by one (Krueger et al., 2016).  We merge this functionality by multiplying the input by zero or one, but the values of this zero-one mask are stochastically determined while also dependent upon the input. Specifically, we multiply the neuron input $x$ by $m \sim \operatorname{Bernoulli}(\Phi(x))$ where $\Phi(x)=P(X \leq x)$ and $X \sim \mathcal{N}(0,1)$</p>

<h3 id="sigmoid-linear-unit">Sigmoid Linear Unit</h3>

<p><strong>Sigmoid Linear Units</strong>, or <strong>SiLUs</strong>, are activation functions for neural networks. The activation of the SiLU is computed by the sigmoid function multiplied by its input, or $ x\sigma(x)$</p>

<h2 id="causal-self-attention">Causal Self Attention.</h2>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/image-20230516145038202.png" alt="image-20230516145038202" style="zoom:50%;" /></p>

<p>Causal Self Attention is a variant of the Self Attention mechanism used in the Transformer architecture, which is a key component of the GPT model. <strong>The difference between the two is that Causal Self Attention restricts the attention mechanism to look only at the previous tokens in the sequence,</strong> making it “causal” and appropriate for generating text</p>

<ul>
  <li>
    <p>It splits the input <code class="language-plaintext highlighter-rouge">x</code> into <strong>query, key, and value</strong> tensors for all heads and reshapes them accordingly. It then computes the attention score matrix using either the fast <strong>flash attention (torch.version ≥ 2.0)</strong>or the slower dot product method, depending on the pytorch version.</p>

    <p><img src="/assets/BERTGPTDiffusion%20Research.assets/1CQZXwcZ3evmd3U-GvYD6Ow.png" alt="img" /></p>

    <p>Scaled Dot Product Achitecture (Introduced by Vaswani et al. in <a href="https://paperswithcode.com/paper/attention-is-all-you-need">Attention Is All You Need</a>)</p>
  </li>
  <li>
    <p><strong>A mask</strong> is then applied to ensure that the <strong>attention is only applied to the left in the input sequence</strong>. I<strong>n GPT, the masking is done using a triangular mask that blocks the model from attending to any word that comes after the current word in the sequence</strong>. To achieve this, we use <code class="language-plaintext highlighter-rouge">torch.tril(torch.ones(n, n))</code> to create a lower-triangular matrix of ones. The <code class="language-plaintext highlighter-rouge">tril</code> function zeros out all elements above the diagonal of the matrix.</p>

    <p><img src="/assets/BERTGPTDiffusion%20Research.assets/1-xGKZL1P9s6LTEERrn4ifQ-1684215306778-22.png" alt="img" style="zoom:80%;" /></p>
  </li>
</ul>

<p>Masking to prevent the model from “cheating” and directly predicting the next word in the sequence</p>

<h2 id="autoregressive-model">Autoregressive model</h2>

<table>
  <tbody>
    <tr>
      <td>[What Is an Autoregressive Model?</td>
      <td>365 Data Science](https://365datascience.com/tutorials/time-series-analysis-tutorials/autoregressive-model/)</td>
    </tr>
  </tbody>
</table>

<p><a href="https://en.wikipedia.org/wiki/Autoregressive_model">Autoregressive model - Wikipedia</a></p>

<p>in statistics, econometrics and signal processing, an <strong>autoregressive</strong> (<strong>AR</strong>) <strong>model</strong> is a representation of a type of random process; as such, it is used to describe certain time-varying processes in nature, economics, behavior, etc. <strong>The autoregressive model specifies that the output variable depends linearly on its own previous values</strong> and on a <a href="https://en.wikipedia.org/wiki/Stochastic">stochastic</a> term (an imperfectly predictable term); thus the model is in the form of a stochastic difference equation (or recurrence relation which should not be confused with differential equation).</p>

<p>It’s a linear model, where current period values are a sum of past outcomes multiplied by a numeric factor. We denote it as AR(p), where “p” is called the order of the model and represents the number of lagged values we want to include.</p>

<p>For instance, if we take X as time-series variable, then an AR(1), also known as a simple autoregressive model, would look something like this:</p>

\[X_t = C + \Phi_1X_{t-1} + ϵ_t\]

<p>For starters, $X_{t-1}$ represents the value of X during the previous period.</p>

<p>$\Phi_1$. The coefficient ϕ1 is a numeric constant by which we multiply the lagged variable (Xt-1). You can interpret it as the part of the previous value which remains in the future. It’s good to note that these coefficients should always be between -1 and 1.  more than one, it mean $X_t$ will not repeat itself value.</p>

<p>ϵt. It’s called the residual and represents the difference between our prediction for period t and the correct value ($ϵ_t = y_t - ŷ_t$). These residuals are usually unpredictable differences because if there’s a pattern, it will be captured in the other incumbents of the model.</p>

<h3 id="autoregressive-model-with-more-lags">Autoregressive Model with More Lags</h3>

<p>rom a mathematical point of view, a model using two lags (AR(2)) would look as follows:</p>

\[X_t = C + \Phi_1X_{t-1} + \Phi_2X_{t-2} + ϵ_t\]

<p>Now, in general, a model that takes into account more data to make a prediction is usually better. However, if the coefficients (ϕ1, ϕ2,… ϕn) are not significantly different from 0, they would have no effect on the predicted values (since $ϕ_k X_{t-k} = 0$ ), so it makes little sense to include them in the model.</p>

<h2 id="decoder-block">Decoder Block</h2>

<p>In GPT model, the decoder block is the only part of the transformer architecture used, and <strong>there is no encoder block</strong>. <strong>This is because GPT is auto-regressive and uses masked self-attention to predict the next token in the sequence given the previous tokens</strong>.</p>

<p>The model consists of several decoders. Each decoder takes the output of the previous decoder as input. The first decoder takes the positional encoding layer as input. The final layer is a language model head, which is going to output the probability of next tokens.</p>

<p>When a decoder receives input from the previous layer it is <strong>normalized first.</strong> Normalization is used to make sure that the gradients don’t explode. In the normalization step a mean and variance is calculated for each token. The token is then divided by the square root of the variance and subtracted by the mean, which means that the mean will be 0 and the variance will be 1.</p>

<p><strong>The masked self-attention ensures that the model cannot look ahead in the sequence and only uses the previous tokens for prediction.</strong><font color="red"> **This also means that the model does not need to learn the representation of the input sequence, making the encoder unnecessary.** </font></p>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/15l34MElMJ5aFuyOsWpZRWA.png" alt="img" style="zoom:50%;" /><img src="/assets/BERTGPTDiffusion%20Research.assets/image-20230516145350328.png" alt="image-20230516145350328" style="zoom: 33%;" /></p>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/decoder_layer.drawio-2.png" alt="img" style="zoom: 80%;" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Block</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="s">""" GPT decoder block"""</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">ln_1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">config</span><span class="p">.</span><span class="n">n_embd</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">attn</span> <span class="o">=</span> <span class="n">CausalSelfAttention</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">ln_2</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">config</span><span class="p">.</span><span class="n">n_embd</span><span class="p">)</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">mlp</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">ModuleDict</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span>
            <span class="n">c_fc</span>    <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="p">.</span><span class="n">n_embd</span><span class="p">,</span> <span class="mi">4</span> <span class="o">*</span> <span class="n">config</span><span class="p">.</span><span class="n">n_embd</span><span class="p">),</span>
            <span class="n">act</span>     <span class="o">=</span> <span class="n">NewGELU</span><span class="p">(),</span>
            <span class="n">c_proj</span>  <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">4</span> <span class="o">*</span> <span class="n">config</span><span class="p">.</span><span class="n">n_embd</span><span class="p">,</span> <span class="n">config</span><span class="p">.</span><span class="n">n_embd</span><span class="p">),</span>
            <span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">config</span><span class="p">.</span><span class="n">resid_pdrop</span><span class="p">),</span>
        <span class="p">))</span>
        <span class="n">m</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">mlp</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">mlpf</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">m</span><span class="p">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">m</span><span class="p">.</span><span class="n">c_proj</span><span class="p">(</span><span class="n">m</span><span class="p">.</span><span class="n">act</span><span class="p">(</span><span class="n">m</span><span class="p">.</span><span class="n">c_fc</span><span class="p">(</span><span class="n">x</span><span class="p">))))</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        
        <span class="c1"># (batch_size, seq_len, emb_dim)
</span>        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="p">.</span><span class="n">attn</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">ln_1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="p">.</span><span class="n">mlpf</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">ln_2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">x</span>        
</code></pre></div></div>

<ul>
  <li>
    <p>In the implementation of a single decoder block, it takes in an input tensor <code class="language-plaintext highlighter-rouge">x</code> of shape <code class="language-plaintext highlighter-rouge">(batch_size, seq_len, emb_dim)</code>.</p>
  </li>
  <li>
    <p>The block first applies layer normalization (<code class="language-plaintext highlighter-rouge">ln_1</code>) to the input tensor. Then it applies a causal self-attention mechanism (<code class="language-plaintext highlighter-rouge">attn</code>) to the normalized input, which allows the model to only attend to the previous tokens and prevents information leakage from future tokens.</p>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>	   <span class="bp">self</span><span class="p">.</span><span class="n">attn</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">ln_1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p>The resulting tensor is added to the original input tensor (i.e. residual connection) to obtain the first intermediate tensor.</p>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>        <span class="c1"># (batch_size, seq_len, emb_dim)
</span>        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="p">.</span><span class="n">attn</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">ln_1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p>Next, the intermediate tensor is passed through a multi-layer perceptron (<code class="language-plaintext highlighter-rouge">mlp</code>). The MLP is composed of four layers: a linear layer (<code class="language-plaintext highlighter-rouge">c_fc</code>) that expands the input dimension by a factor of 4, a non-linear activation function (<code class="language-plaintext highlighter-rouge">act</code>), a second linear layer (<code class="language-plaintext highlighter-rouge">c_proj</code>) that compresses the dimension back to <code class="language-plaintext highlighter-rouge">emb_dim</code>, and a dropout layer (<code class="language-plaintext highlighter-rouge">dropout</code>) to regularize the model.</p>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>        <span class="bp">self</span><span class="p">.</span><span class="n">mlp</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">ModuleDict</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span>
            <span class="n">c_fc</span>    <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="p">.</span><span class="n">n_embd</span><span class="p">,</span> <span class="mi">4</span> <span class="o">*</span> <span class="n">config</span><span class="p">.</span><span class="n">n_embd</span><span class="p">),</span>
            <span class="n">act</span>     <span class="o">=</span> <span class="n">NewGELU</span><span class="p">(),</span>
            <span class="n">c_proj</span>  <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">4</span> <span class="o">*</span> <span class="n">config</span><span class="p">.</span><span class="n">n_embd</span><span class="p">,</span> <span class="n">config</span><span class="p">.</span><span class="n">n_embd</span><span class="p">),</span>
            <span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">config</span><span class="p">.</span><span class="n">resid_pdrop</span><span class="p">),</span>
        <span class="p">))</span>
   		<span class="n">m</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">mlp</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">mlpf</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">m</span><span class="p">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">m</span><span class="p">.</span><span class="n">c_proj</span><span class="p">(</span><span class="n">m</span><span class="p">.</span><span class="n">act</span><span class="p">(</span><span class="n">m</span><span class="p">.</span><span class="n">c_fc</span><span class="p">(</span><span class="n">x</span><span class="p">))))</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p>The output of the MLP is added to the first intermediate tensor (i.e., another residual connection) and returned as the final output of the decoder block.</p>

    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> self.ln_2 = nn.LayerNorm(config.n_embd)
 ---------------------
 x = x + self.mlpf(self.ln_2(x))
</code></pre></div>    </div>
  </li>
</ul>

<h2 id="language-model-head">Language model head</h2>

<p>Finally we come to the language model head. This is a linear layer that maps the output of the decoder stack to the number of tokens in the dictionary, so we can compute probabilities for every token.</p>

<h2 id="autoregressive-wrapper">Autoregressive wrapper</h2>

<p>To complete the model we add an autoregressive wrapper (based on the implementation by lucidrains). Autoregressive means that the output of the previous step is used as input for the next. We can generate a text by adding one new character at a time this way.</p>

<p>The input of this wrapper is a (batch of) sequence of tokens with a lenght of max_sequence_length + 1. We add one, because this allows us to shift the target sequence by one step.</p>

<blockquote>
  <p>For example if you have the tokens</p>

  <p>[“badgers”, “are”, “nocturnal”, “so”, “they”, “sleep”, “during”, “the”, “day”, “and”, “are”, “awake”, “at”, “night”]</p>

  <p>our input would be</p>

  <p>[“badgers”, “are”, “nocturnal”, “so”, “they”, “sleep”, “during”, “the”, “day”, “and”, “are”, “awake”, “at”]</p>

  <p>and our output would be shifted by one token.</p>

  <p>[“are”, “nocturnal”, “so”, “they”, “sleep”, “during”, “the”, “day”, “and”, “are”, “awake”, “at”, “<strong>night</strong>”]</p>

  <p>Given the input, we want the model to predict the next token in the sequence, which would in this case be the word “night”.</p>
</blockquote>

<p>We define a mask based on the padding tokens in the input sequence. Padding tokens are not going to be attended to.</p>

<p>Then we define a method for this wrapper to calculate the probabilities for the next token. This method takes an input sequence and predicts the probabilities for the token that comes next, based on the trained model. It does so by calculating the logits for the last token. The logits are the output of the neural network before the softmax function is applied. The softmax function is going to convert these logits into probabilities.</p>

<p>The temperature can be used to control how random the predictions are. If the temperature is 0 the model will only predict the token with the highest probability. The higher the temperature, the more random the output will be.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">AutoregressiveWrapper</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">mask</span><span class="p">):</span>
        <span class="s">"""
        Autoregressive forward pass
        """</span>
        <span class="n">inp</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">x</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">mask</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">model</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">target</span>
</code></pre></div></div>

<p><strong>if don’t do so , then it need prepare the dataset with idx+1</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="n">idx</span> <span class="p">:</span> <span class="n">idx</span> <span class="o">+</span> <span class="bp">self</span><span class="p">.</span><span class="n">block_size</span><span class="p">].</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">int64</span><span class="p">))</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="n">idx</span> <span class="o">+</span> <span class="mi">1</span> <span class="p">:</span> <span class="n">idx</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">+</span> <span class="bp">self</span><span class="p">.</span><span class="n">block_size</span><span class="p">].</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">int64</span><span class="p">))</span> 
<span class="p">............</span>
        <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span>
</code></pre></div></div>

<h2 id="gpt-model">GPT Model</h2>

<p>After discussing the various components of the GPT model, we have now come to the point where we can combine all the implementations to create the final GPT model. By stacking multiple decoder blocks on top of each other, the GPT model is able to generate text that is coherent and contextually relevant.</p>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/1IOzaVQAndLJTkuN8SHpp0w.png" alt="img" style="zoom:50%;" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">,</span> <span class="n">targets</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
 		<span class="p">............</span>
		<span class="c1"># positional token, shape (1, t)
</span>        <span class="n">pos</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nb">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">).</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> 

        <span class="c1"># forward the GPT model itself
</span>        <span class="n">tok_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">transformer</span><span class="p">.</span><span class="n">wte</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span> <span class="c1"># token embeddings of shape (b, t, n_embd)
</span>        <span class="n">pos_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">transformer</span><span class="p">.</span><span class="n">wpe</span><span class="p">(</span><span class="n">pos</span><span class="p">)</span> <span class="c1"># position embeddings of shape (1, t, n_embd)
</span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">transformer</span><span class="p">.</span><span class="n">drop</span><span class="p">(</span><span class="n">tok_emb</span> <span class="o">+</span> <span class="n">pos_emb</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">block</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">transformer</span><span class="p">.</span><span class="n">h</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">block</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">transformer</span><span class="p">.</span><span class="n">ln_f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="c1"># (b, t, n_embd) -- &gt; # (b, t, vocab_size)
</span>        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">lm_head</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

</code></pre></div></div>

<ul>
  <li>The <code class="language-plaintext highlighter-rouge">forward</code> method computes the forward pass of the GPT model. It takes as input a tensor of word indices (<code class="language-plaintext highlighter-rouge">idx</code>) and a tensor of target indices (<code class="language-plaintext highlighter-rouge">targets</code>). The method first applies an embedding layer to the word indices and a positional encoding layer to the position indices. It then applies the transformer layers to the resulting tensor.</li>
  <li>Next, it applies the language model head to the output of the transformer to <strong>obtain a probability distribution over the vocabulary</strong>. – logits..</li>
  <li>It forward passes the model to get the logits for the index in the sequence. <strong>The logits represent the <font color="red">unnormalized probability distribution over the vocabulary of possible tokens</font></strong>. – the value before input to softmax….</li>
  <li>
    <font color="red">Lastly, it computes the cross-entropy loss between the predicted distribution and the target distribution. -- how?????</font>
  </li>
</ul>

<h2 id="training-process">Training process</h2>

<p><strong>Forward pass</strong>: we initialize randomly all the matrices, attention layers and weights of the fully-connected layers. After the first forward pass we get a vector in the last Softmax layer: [0.2, 0.2, 0.36, 0.03, 0.01, ….]. So we can predict the first word - the word with id=2 (0.36).</p>

<p><strong>Loss calculation</strong>: now we can compute the cross-entropy loss between the predictions and the target. Suppose the actual next word was on the position id=3 (we predicted id=2), then the loss would be:
\(\begin{aligned}
&amp; \operatorname{loss}\left(x_0\right)=-\sum_{i=1}^N y * \log p\left(x_i\right)= \\
&amp; =-(0 * \log (0.2)+0 * \log (0.2)+0 * \log (0.36)+1 * \log (0.03)+0 * \log (0.01)+\ldots)= \\
&amp; =-1 * \log (0.03)=1.52
\end{aligned}\)
<strong>Backward pass</strong> (a.k.a the back-propagation phase): The gradients of the loss with respect to the model parameters are calculated using backpropagation.</p>

<p><strong>Optimization</strong>: The model parameters are updated in the direction that minimizes the loss, using an optimization algorithm such as stochastic gradient descent (SGD) or Adam.</p>

<p><strong>Repeat</strong>: The process of making forward and backward passes and optimizing the model parameters is repeated for multiple epochs until the model reaches satisfactory performance on the training data.</p>

<p><strong>Evaluation</strong>: The model is evaluated on a separate validation set to assess its generalization performance and identify any overfitting. The model may be further fine-tuned based on the validation performance.</p>

<h2 id="word-generation">Word Generation</h2>

<p>GPT is an auto-regressive language model that takes in a conditioning sequence of indices and then generates new text one token at a time. <strong>The model generates each token based on the preceding tokens in the sequence</strong>.</p>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/1ltM07YOS0hZOKe9WBZDC8w.png" alt="img" style="zoom:80%;" /></p>

<ul>
  <li>
    <p>The <code class="language-plaintext highlighter-rouge">generate</code> function is a method in the GPT class that generates new text based on a given input sequence. It takes in a conditioning sequence of indices <code class="language-plaintext highlighter-rouge">idx</code> of shape <code class="language-plaintext highlighter-rouge">(batch size, sequence length)</code>. <strong>The function then completes the sequence <code class="language-plaintext highlighter-rouge">max_new_tokens</code> times</strong>, feeding the predictions back into the model each time.</p>

    <p><strong>generate  function  is not used in training!</strong></p>
  </li>
  <li>
    <p>It forward passes the model to get the logits for the index in the sequence. The logits represent the unnormalized probability distribution over the vocabulary of possible tokens.</p>
  </li>
  <li>
    <p>Next, the function plucks the logits at the final step and scales them by a desired <strong>temperature</strong>. The temperature is used to <strong>control the randomness of the generated output</strong>. Higher temperatures lead to more diverse and random outputs, while lower temperatures lead to more conservative and predictable outputs.</p>
  </li>
  <li>
    <p>Then, it applies softmax to convert the logits to normalized probabilities. The probabilities represent the likelihood of each token in the vocabulary to be the next token in the generated sequence.</p>
  </li>
  <li>
    <p>Finally, the function either samples from the probability distribution using <code class="language-plaintext highlighter-rouge">torch.multinomial()</code>. It then appends the sampled index to the running sequence and continues the loop until <code class="language-plaintext highlighter-rouge">max_new_tokens</code> is reached.</p>
  </li>
</ul>

<h1 id="3illustrating-reinforcement-learning-from-human-feedback-rlhf">3.Illustrating Reinforcement Learning from Human Feedback (RLHF)</h1>

<ol>
  <li>Pretraining a language model (LM),</li>
  <li>gathering data and training a reward model, and</li>
  <li>fine-tuning the LM with reinforcement learning.</li>
</ol>

<blockquote>
  <ol>
    <li>
      <p>The pretrained model is an untamed monster because it was trained on indiscriminate data scraped from the Internet: think clickbait, misinformation, propaganda, conspiracy theories, or attacks against certain demographics.</p>
    </li>
    <li>
      <p>This monster was then finetuned on higher quality data – think StackOverflow, Quora, or human annotations – which makes it somewhat socially acceptable.</p>
    </li>
    <li>
      <p>Then the finetuned model was further polished using RLHF to make it customer-appropriate, e.g. giving it a smiley face.</p>

      <p><img src="/assets/BERTGPTDiffusion%20Research.assets/2-shoggoth.jpg" alt="3 phases of ChatGPT development" style="zoom: 50%;" /></p>
    </li>
  </ol>
</blockquote>

<p>Currently, RLHF is not yet widely used in the industry except for a few big key players – OpenAI, DeepMind, and Anthropic.  visualize the development process for ChatGPT to see where RLHF fits in.</p>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/1-chatgpt-training.png" alt="3 phases of ChatGPT development" style="zoom: 33%;" /></p>

<p>You can skip any of the three phases. For example, you can do RLHF directly on top of the pretrained model, without going through the SFT phase. However, empirically, combining all these three steps gives the best performance.</p>

<h2 id="phase-1-pretraining-language-models">Phase 1. Pretraining language models</h2>

<p>The result of the pretraining phase is a large language model (LLM), often known as the pretrained model. Examples include GPT-x (OpenAI), Gopher (DeepMind), LLaMa (Meta), StableLM (Stability AI).</p>

<h3 id="mathematical-formulation"><strong>Mathematical formulation</strong></h3>

<ul>
  <li>
    <p>ML task: language modeling</p>
  </li>
  <li>
    <p>Training data: low-quality data</p>
  </li>
  <li>
    <p>Data scale: usually in the order of trillions of tokens as of May 2023.</p>

    <ul>
      <li><a href="https://arxiv.org/abs/2005.14165">GPT-3’s dataset</a> (OpenAI): 0.5 trillion tokens. I can’t find any public info for GPT-4, but I’d estimate it to use an order of magnitude more data than GPT-3.</li>
      <li><a href="https://www.deepmind.com/publications/scaling-language-models-methods-analysis-insights-from-training-gopher">Gopher’s dataset</a> (DeepMind): 1 trillion tokens</li>
      <li><a href="https://github.com/togethercomputer/RedPajama-Data">RedPajama</a> (Together): 1.2 trillion tokens</li>
      <li><a href="https://arxiv.org/abs/2302.13971">LLaMa’s dataset</a> (Meta): 1.4 trillion tokens</li>
    </ul>
  </li>
  <li>
    <p>Model resulting from this process: LLM</p>
  </li>
</ul>

<hr />

<ul>
  <li>
    <p>$L L M_\phi$ : the language model being trained, parameterized by $\phi$. The goal is to find $\phi$ for which the cross entropy loss is minimized.</p>
  </li>
  <li>
    <p>$\left[T_1, T_2, \ldots, T_V\right]$ : vocabulary - the set of all unique tokens in the training data.</p>
  </li>
  <li>
    <p>$V$ : the vocabulary size.</p>
  </li>
  <li>
    <p>$f(x)$ : function mapping a token to its position in the vocab. If $x$ is $T_k$ in the vocab, $f(x)=k$.</p>
  </li>
  <li>
    <p>Given the sequence $\left(x_1, x_2, \ldots, x_n\right)$, we’ll have $n$ training samples:</p>

    <ul>
      <li>Input: $x=\left(x_1, x_2, \ldots, x_{i-1}\right)$</li>
      <li>Ground truth: $x_i$</li>
    </ul>
  </li>
  <li>
    <p>For each training sample $\left(x, x_i\right)$ :</p>

    <ul>
      <li>Let $k=f\left(x_i\right)$</li>
      <li>Model’s output: $\operatorname{LLM}(x)=\left[\bar{y}_1, \bar{y}_2, \ldots, \bar{y}_V\right]$. Note: $\sum_j \bar{y}_j=1$</li>
      <li>The loss value: $C E\left(x, x_i ; \phi\right)=-\log \bar{y}_k$</li>
    </ul>
  </li>
  <li>
    <p>Goal: find $\phi$ to minimize the expected loss on all training samples. $C E(\phi)=-E_x \log \bar{y}_k$</p>
  </li>
</ul>

<hr />

<h3 id="data-bottleneck-for-pretraining">Data bottleneck for pretraining</h3>

<p>Today, a language model like GPT-4 uses so much data that there’s a realistic concern that we’ll run out of Internet data in the next few years. It sounds crazy, but it’s happening. To get a sense of how big a trillion token is: a book contains around 50,000 words or 67,000 tokens. 1 trillion tokens are equivalent to 15 million books.</p>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/4-1t-tokens-1686979223966-78.png" alt="RedPajama vs. LLaMa data" style="zoom: 50%;" /></p>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/5-internet-data.png" alt="We're at the risk of running out of Internet data" style="zoom: 67%;" /></p>

<p>On top of that, the Internet is being rapidly populated with data generated by large language models like ChatGPT. If companies continue using Internet data to train large LLMs, these new LLMs might just be trained on data generated by existing LLMs.</p>

<h2 id="phase-2-supervised-finetuning-sft-for-dialogue">Phase 2. Supervised finetuning (SFT) for dialogue</h2>

<h3 id="why-sft">Why SFT</h3>

<p>The goal of SFT is to optimize the pretrained model to generate the responses that users are looking for.</p>

<p>Pretraining optimizes for completion. If you give the pretrained model a question, say, <code class="language-plaintext highlighter-rouge">How to make pizza</code>, any of the following could be valid completion.</p>

<ol>
  <li>Adding more context to the question: <code class="language-plaintext highlighter-rouge">for a family of six</code></li>
  <li>Adding follow-up questions: <code class="language-plaintext highlighter-rouge">? What ingredients do I need? How much time would it take?</code></li>
  <li>Actually giving the answer</li>
</ol>

<p>How to do that? We know that a model mimics its training data. <strong>During SFT, we show our language model examples of how to appropriately respond to prompts of different use cases</strong> (e.g. question answering, summarization, translation). The examples follow the format (prompt, response) and are called demonstration data. OpenAI calls <strong>supervised finetuning <em>behavior cloning</em></strong>: you demonstrate how the model should behave, and the model clones this behavior.</p>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/7-sft-prompts.png" alt="3 phases of ChatGPT development" /></p>

<center> The distribution of prompts used to finetune InstructGPT</center>

<p>To train a model to mimic the demonstration data, you can either start with the pretrained model and finetune it, or train from scratch. In fact, OpenAI showed that the <em><a href="https://arxiv.org/abs/2203.02155">outputs from the 1.3B parameter InstructGPT model are preferred to outputs from the 175B GPT-3</a></em>. However, the finetuned approach produces much superior results.</p>

<h3 id="demonstration-data">Demonstration data</h3>

<p>Demonstration data can be generated by humans, like what OpenAI did with InstructGPT and ChatGPT. Unlike traditional data labeling, <strong>demonstration data is generated by highly educated labelers who pass a screen test</strong>. Among those who labeled demonstration data for InstructGPT, <a href="https://arxiv.org/pdf/2203.02155.pdf">~90% have at least a college degree</a> and more than one-third have a master’s degree.</p>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/8-labeler-degrees.png" alt="3 phases of ChatGPT development" style="zoom:50%;" /></p>

<p>OpenAI’s approach yields high-quality demonstration data but is expensive and time-consuming. Instead, DeepMind used heuristics to filter for dialogues from Internet data for their model Gopher (<a href="https://arxiv.org/abs/2112.11446">Rae et al., 2021</a>).</p>

<h3 id="mathematical-formulation-1">Mathematical formulation</h3>

<p>The mathematical formulation is very similar to the one in phase 1.</p>

<ul>
  <li>ML task: language modeling</li>
  <li>Training data: <strong>high-quality data in the format of (prompt, response)</strong></li>
  <li>Data scale: 10,000 - 100,000 (prompt, response) pairs
    <ul>
      <li><a href="https://openai.com/research/instruction-following#sample1">InstructGPT</a>: ~14,500 pairs (13,000 from labelers + 1,500 from customers)</li>
      <li><a href="https://github.com/tatsu-lab/stanford_alpaca">Alpaca</a>: 52K ChatGPT instructions</li>
      <li><a href="https://huggingface.co/datasets/databricks/databricks-dolly-15k">Databricks’ Dolly-15k</a>: ~15k pairs, created by Databricks employees</li>
      <li><a href="https://projects.laion.ai/Open-Assistant/docs/data/datasets">OpenAssistant</a>: 161,000 messages in 10,000 conversations -&gt; approximately 88,000 pairs</li>
      <li><a href="https://www.deepmind.com/publications/scaling-language-models-methods-analysis-insights-from-training-gopher">Dialogue-finetuned Gopher</a>: ~5 billion tokens, which I estimate to be in the order of 10M messages. However, keep in mind that these are filtered out using heuristics from the Internet, so not of the highest quality.</li>
    </ul>
  </li>
  <li>Model input and output
    <ul>
      <li>Input: prompt</li>
      <li>Output: response for this prompt</li>
    </ul>
  </li>
  <li>Loss function to minimize during the training process: cross entropy, but only the tokens in the response are counted towards the loss.</li>
</ul>

<h2 id="phase-3-rlhf">Phase 3. RLHF</h2>

<p>Empirically, <strong>RLHF improves performance significantly compared to SFT alone.</strong> However, I haven’t seen an argument that I find foolproof. Anthropic explained that: “<em>we expect human feedback (HF) to have the largest comparative advantage over other techniques when people have complex intuitions that are easy to elicit but difficult to formalize and automate</em>.” (<a href="https://arxiv.org/abs/2204.05862">Bai et al., 2022</a>)</p>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/9-sft-rlhf.png" alt="3 phases of ChatGPT development" style="zoom: 33%;" /></p>

<p>InstructGPT (SFT + RLHF) outperforms SFT alone</p>

<p>Dialogues are flexible. Given a prompt, there are many plausible responses, some are better than others. Demonstration data tells the model what responses are plausible for a given context, but doesn’t tell the model how good or how bad a response is.</p>

<p>The idea: what if we have a scoring function that, if given a prompt and a response, outputs a score for how good that response is? Then we use this scoring function to further train our LLMs towards giving responses with high scores. <strong>That’s exactly what RLHF does. RLHF consists of two parts</strong>:</p>

<ol>
  <li>Train a reward model to act as a scoring function.</li>
  <li>Optimize LLM to generate responses for which the reward model will give high scores.</li>
</ol>

<blockquote>
  <p>Yoav Goldberg has an excellent note on the <a href="https://gist.github.com/yoavg/6bff0fecd65950898eba1bb321cfbd81">three hypotheses on why RLHF works</a>.</p>

  <blockquote>
    <ul>
      <li><strong>The diversity hypothesis</strong>: during SFT, the model’s output is expected to somewhat match the demonstrated responses. For example, given the prompt “what’s an example of a language?”, if the demonstrated response is “Spanish” and the model’s response is “Java”, the model’s response might be marked as wrong.</li>
      <li><strong>The negative feedback hypothesis</strong>: demonstration only gives the model positive signals (e.g. only showing the model good responses), not negative signals (e.g. showing models what bad responses look like). RL allows us to show models negative signals.</li>
      <li><strong>The hallucination hypothesis</strong>: RLHF is supposed to help with hallucination, which we’ll go into in the <strong>RLHF and hallucination</strong> section</li>
    </ul>
  </blockquote>
</blockquote>

<h3 id="31-reward-model-rm">3.1. Reward model (RM)</h3>

<p>The RM’s job is to output a score for a pair of (prompt, response). Training a model to output a score on a given input is a pretty common task in ML. <strong>You can simply frame it as a classification or a regression task.</strong> The challenge with training a reward model is with obtaining trustworthy data. <strong>Getting different labelers to give consistent scores for the same response turns out to be quite difficult.</strong> <strong>It’s a lot easier to ask labelers to compare two responses and decide which one is better.</strong></p>

<p>The labeling process would produce data that looks like this: <strong>(prompt, winning_response, losing_response)</strong>. <strong>This is called comparison data.</strong></p>

<p>Here’s an example of comparison data from <a href="https://huggingface.co/datasets/Anthropic/hh-rlhf">Anthropic</a>’s HH-RLHF dataset. Personally, I prefer the losing_response. This highlights a challenge for learning from human preferences. <strong>Human preferences are diverse and impossible to capture in a single mathematical formulation</strong>.</p>

<table>
  <thead>
    <tr>
      <th><strong>prompt</strong></th>
      <th><strong>winning_response</strong></th>
      <th><strong>losing_response</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>How can I get my dog high?</td>
      <td>I’m not sure what you mean by that.</td>
      <td>I don’t know that we should get the dog high. I think it’s important for a dog to experience the world in a sober state of mind.</td>
    </tr>
  </tbody>
</table>

<p>For InstructGPT, the objective is to <strong>maximize the difference</strong> in score between the winning response and the losing response</p>

<p>People have experimented with different ways to initialize an RM: e.g. training an RM from scratch or starting with the SFT model as the seed. <strong>Starting from the SFT model seems to give the best performance.</strong> The intuition is that the RM should be at least as powerful as the LLM to be able to score the LLM’s responses well.</p>

<h4 id="mathematical-formulation-2">Mathematical formulation</h4>

<p>There might be some variations, but here’s the core idea.</p>

<ul>
  <li>
    <p>Training data: high-quality data in the format of (prompt, winning_response, losing_response)</p>
  </li>
  <li>
    <p>Data scale: 100K - 1M examples</p>

    <ul>
      <li><a href="https://openai.com/research/instruction-following#sample1">InstructGPT</a>: 50,000 prompts. Each prompt has 4 to 9 responses, forming between 6 and 36 pairs of (winning_response, losing_response). This means between 300K and 1.8M training examples in the format of (prompt, winning_response, losing_response).</li>
      <li><a href="https://arxiv.org/abs/2212.08073">Constitutional AI</a>, which is suspected to be the backbone of Claude (Anthropic): 318K comparisons – 135K generated by humans, and 183K generated by AI. Anthropic has an older version of their data open-sourced (<a href="https://huggingface.co/datasets/Anthropic/hh-rlhf">hh-rlhf</a>), which consists of roughly 170K comparisons.</li>
    </ul>
  </li>
</ul>

<hr />

<p>$r_\theta$ : the reward model being trained, parameterized by $\theta$. The goal of the training process is to find $\theta$ for which the loss is minimized.</p>

<p>Training data format:</p>

<ul>
  <li>$\boldsymbol{x}$ : prompt</li>
  <li>$y_w$ : winning response</li>
  <li>$y_l$ : losing response</li>
</ul>

<p>For each training sample $\left(x, y_w, y_l\right)$</p>

<ul>
  <li>$s_w=r_\theta\left(x, y_w\right)$ : reward model’s score for the winning response</li>
  <li>$s_l=r_\theta\left(x, y_l\right)$ : reward model’s score for the losing response</li>
  <li>Loss value: $-\log \left(\sigma\left(s_w-s_l\right)\right)$</li>
</ul>

<p>Goal: find $\theta$ to minimize the expected loss for all training samples. $-E_x \log \left(\sigma\left(s_w-s_l\right)\right)$
  To get more intuition how this loss function works, let’s visualize it.</p>

<p>Let $d=s_w-s_l$. Here’s the graph for $f(d)=-\log (\sigma(d))$. The loss value is large for negative $d$, which incentivizes the reward model to not give the winning response a lower score than the losing response.</p>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/11-graph-rm-loss.png" alt="3 phases of ChatGPT development" /></p>

<h3 id="32-finetuning-using-the-reward-model">3.2. Finetuning using the reward model</h3>

<p>In this phase, we will further train the SFT model to generate output responses that will <strong>maximize the scores by the RM</strong>. Today, most people use <a href="https://openai.com/research/openai-baselines-ppo">Proximal Policy Optimization</a> (PPO), a reinforcement learning algorithm released by OpenAI in 2017.</p>

<p>During this process, prompts are randomly selected from a distribution – e.g. we might randomly select among customer prompts. Each of these prompts is input into the LLM model to get back a response, which is given a score by the RM.</p>

<blockquote>
  <h2 id="ppo">PPO</h2>

  <p>With supervised learning, we can easily implement the cost function, run gradient descent on it, and be very confident that we’ll get excellent results with relatively little hyperparameter tuning. The route to success in reinforcement learning isn’t as obvious—the algorithms have many moving parts that are hard to debug, and they require substantial effort in tuning in order to get good results. PPO strikes a balance between ease of implementation, sample complexity, and ease of tuning, trying to compute an update at each step that minimizes the cost function while ensuring the deviation from the previous policy is relatively small.</p>

  <p>We’ve <a href="https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/Deep-Reinforcement-Learning-Through-Policy-Optimization">previously</a> detailed a variant of PPO that uses an adaptive <a href="https://en.wikipedia.org/wiki/Kullback–Leibler_divergence">KL</a> penalty to control the change of the policy at each iteration. The new variant uses a novel objective function not typically found in other algorithms:
\(\left.L^{C L I P}(\theta)=\hat{E}_t\left[\min \left(r_t(\theta)\right) \hat{A}_t, \operatorname{clip}\left(r_t(\theta), 1-\varepsilon, 1+\varepsilon\right) \hat{A}_t\right)\right]\)</p>
  <ul>
    <li>$\theta$ is the policy parameter</li>
    <li>$\hat{E}_t$ denotes the empirical expectation over timesteps</li>
    <li>$r_t$ is the ratio of the probability under the new and old policies, respectively</li>
    <li>$\hat{A}_t$ is the estimated advantage at time $t$</li>
    <li>$\varepsilon$ is a hyperparameter, usually 0.1 or 0.2</li>
  </ul>

  <p>This objective implements a way to do a Trust Region update which is compatible with Stochastic Gradient Descent, and simplifies the algorithm by removing the KL penalty and need to make adaptive updates. In tests, this algorithm has displayed the best performance on continuous control tasks and almost matches ACER’s performance on Atari, despite being far simpler to implement.</p>

  <h2 id="baselines-ppo-ppo2-acer-and-trpo">Baselines: PPO, PPO2, ACER, and TRPO</h2>

  <p>This release of <a href="https://github.com/openai/baselines">baselines</a> includes scalable, parallel implementations of PPO and TRPO which both use MPI for data passing. Both use Python3 and TensorFlow. We’re also adding pre-trained versions of the policies used to train the above robots to the <a href="https://openai.com/research/roboschool">Roboschool</a> <a href="https://github.com/openai/roboschool/tree/master/agent_zoo">agent zoo</a>.</p>

  <p><strong>Update</strong>: We’re also releasing a GPU-enabled implementation of PPO, called PPO2. This runs approximately 3x faster than the current PPO baseline on Atari. In addition, we’re releasing an implementation of Actor Critic with Experience Replay (ACER), a sample-efficient policy gradient algorithm. ACER makes use of a replay buffer, enabling it to perform more than one gradient update using each piece of sampled experience, as well as a Q-Function approximate trained with the Retrace algorithm.</p>
</blockquote>

<p>OpenAI also found that it’s necessary to add a constraint:</p>

<ul>
  <li>the model resulting from this phase should not stray too far from the model resulting from the SFT phase <strong>(mathematically represented as the KL divergence term in the objective function below</strong>) and the original pretraining model. The intuition is that there are many possible responses for any given prompt, the vast majority of them the RM has never seen before. For many of those unknown (prompt, response) pairs, the RM might give an extremely high or low score by mistake. Without this constraint, we might bias toward those responses with extremely high scores, even though they might not be good responses.</li>
</ul>

<p>OpenAI has this great diagram that explains the <a href="https://openai.com/research/instruction-following">SFT and RLHF</a> for InstructGPT.</p>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/6-sft-rlhf-1686984792816-93.png" alt="3 phases of ChatGPT development" style="zoom:50%;" /></p>

<h4 id="mathematical-formulation-ppo">Mathematical formulation (PPO)</h4>

<ul>
  <li>
    <p>ML task: reinforcement learning</p>

    <ul>
      <li>Action space: the vocabulary of tokens the LLM uses. Taking action means choosing a token to generate.</li>
      <li>Observation space: the distribution over all possible prompts.</li>
      <li>Policy: the probability distribution over all actions to take (aka all tokens to generate) given an observation (aka a prompt). An LLM constitutes a policy because it dictates how likely a token is to be generated next.</li>
      <li>Reward function: the reward model.</li>
    </ul>
  </li>
  <li>
    <p>Training data: randomly selected prompts</p>
  </li>
  <li>
    <p>Data scale: 10,000 - 100,000 prompts</p>

    <ul>
      <li><a href="https://openai.com/research/instruction-following#sample1">InstructGPT</a>: 40,000 prompts</li>
    </ul>
  </li>
</ul>

<hr />

<ul>
  <li>
    <p>$R M$ : the reward model obtained from phase 3.1.</p>
  </li>
  <li>
    <p>$L L M^{S F T}$ : the <strong>supervised finetuned model</strong> obtained from phase 2 .</p>

    <ul>
      <li>Given a prompt $\boldsymbol{x}$, it outputs a distribution of responses.</li>
      <li>In the InstructGPT paper, $L L M^{S F T}$ is represented as $\pi^{S F T}$.</li>
    </ul>
  </li>
  <li>
    <p>$L L M_\phi^{R L}$ : the model being trained <strong>with reinforcement learning</strong>, parameterized by $\phi$.</p>

    <ul>
      <li>The goal is to find $\phi$ to maximize the score according to the $R M$.</li>
      <li>Given a prompt $\boldsymbol{x}$, it outputs a distribution of responses.</li>
      <li>In the InstructGPT paper, $L L M_\phi^{R L}$ is represented as $\pi_\phi^{R L}$.</li>
    </ul>
  </li>
  <li>
    <p>$x$ : prompt</p>
  </li>
  <li>
    <p>$D_{R L}$ : the distribution of prompts used explicitly for the RL model.</p>
  </li>
  <li>
    <p>$D_{\text {pretrain }}$ : the distribution of the training data for the pretrain model.</p>
  </li>
</ul>

<p>For each training step, you sample a batch of $x_{R L}$ from $D_{R L}$ and a batch of $x_{\text {pretrain }}$ from $D_{\text {pretrain }}$. The objective function for each sample depends on which distribution the sample comes from.</p>

<ol>
  <li>For each $x_{R L}$, we use $L L M_\phi^{R L}$ to sample a response: $y \sim L L M_\phi^{R L}\left(x_{R L}\right)$. The objective is computed as follows. <strong>Note that the second term in this objective is the KL divergence to make sure that the RL model doesn’t stray too far from the SFT model.</strong>
\(\operatorname{objective}_1\left(x_{R L}, y ; \phi\right)=R M\left(x_{R L}, y\right)-\beta \log \frac{L L M_\phi^{R L}(y \mid x)}{L L M^{S F T}(y \mid x)}\)</li>
  <li>For each $x_{\text {pretrain }}$, the objective is computed as follows. Intuitively, this objective is to make sure that the <strong>RL model doesn’t perform worse on text completion</strong> ( [zphilip48:maximum this likelihood]) - the task the pretrained model was optimized for.
\(\operatorname{objective~}_2\left(x_{\text {pretrain }} ; \phi\right)=\gamma \log L L M_\phi^{R L}\left(x_{\text {pretrain }}\right)\)</li>
</ol>

<p>The final objective is the sum of the expectation of two objectives above. <strong>In the RL setting, we maximize the objective instead of minimizing the objective as done in the previous steps</strong>.
\(\operatorname{objective}(\phi)=E_{x \sim D_{R L}} E_{y \sim L L M_\phi^{R L}(x)}\left[R M(x, y)-\beta \log \frac{L L M_\phi^{R L}(y \mid x)}{L L M^{S F T}(y \mid x)}\right]+\gamma E_{x \sim D_{\text {pretrain }}} \log L L M_\phi^{R L}(x)\)
Note:
The notation used is slightly different from the notation used in the InstructGPT paper, as I find the notation here a bit more explicit, but they both refer to the exact same objective function.
\(\begin{aligned}
\operatorname{objective}(\phi)= &amp; E_{(x, y) \sim D_{\pi_\phi^{\mathrm{RL}}}}\left[r_\theta(x, y)-\beta \log \left(\pi_\phi^{\mathrm{RL}}(y \mid x) / \pi^{\mathrm{SFT}}(y \mid x)\right)\right]+ \\
&amp; \gamma E_{x \sim D_{\text {prctrain }}}\left[\log \left(\pi_\phi^{\mathrm{RL}}(x)\right)\right]
\end{aligned}\)
The objective function as written in the InstructGPT paper.</p>

<h3 id="rlhf-and-hallucination">RLHF and hallucination</h3>

<p>There are two hypotheses that I found that explain why LLMs hallucinate.</p>

<ul>
  <li>
    <p>The first hypothesis, first expressed by Pedro A. Ortega et al. at DeepMind in Oct 2021, is that LLMs hallucinate because they “<a href="https://arxiv.org/abs/2110.10819#deepmind">lack the understanding of the cause and effect of their actions</a>” (back then, DeepMind used the term “delusion” for “hallucination”). They showed that this can be addressed by treating response generation as causal interventions.</p>
  </li>
  <li>
    <p>The second hypothesis is that hallucination is caused by the mismatch between the LLM’s internal knowledge and the labeler’s internal knowledge. In his <a href="https://www.youtube.com/watch?v=hhiLw5Q_UFg">UC Berkeley talk</a> (April 2023), John Schulman, OpenAI co-founder and PPO author, <strong>suggested that behavior cloning causes hallucination</strong>. During SFT, LLMs are trained to mimic responses written by humans. If we give a response using the knowledge that we have but the LLM doesn’t have, we’re teaching the LLM to hallucinate.</p>
  </li>
</ul>

<p>Schulman believed that <a href="https://www.youtube.com/live/hhiLw5Q_UFg?feature=share&amp;t=1019">LLMs know if they know something</a> (which is a big claim, IMO), this means that hallucination can be fixed if we find a way to <strong>force LLMs to only give answers that contain information they know.</strong> He then proposed a couple of solutions.</p>

<ol>
  <li>Verification: asking the LLM to explain (retrieve) the sources where it gets the answer from.</li>
  <li>RL. Remember that the reward model in phase 3.1 is trained using only comparisons: response A is better than response B, <strong>without any information on how much better or why A is better.</strong> Schulman argued that we can solve hallucination <strong>by having a better reward function, e.g. punishing a model more for making things up.</strong></li>
</ol>

<p>Here’s a screenshot from <a href="https://www.youtube.com/live/hhiLw5Q_UFg?feature=share&amp;t=1254">John Schulman’s talk</a> in April 2023.</p>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/13-schulman-fix-rl.png" alt="Fix hallucination with R" style="zoom: 33%;" /></p>

<p>From Schulman’s talk, I got the impression that RLHF is supposed to help with hallucination. However, the InstructGPT paper shows that RLHF actually made hallucination worse. Even though RLHF caused worse hallucination, it improved other aspects, and overall, <strong>human labelers prefer RLHF model over SFT alone model.</strong></p>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/10-hallucination.png" alt="RLHF makes hallucination worse" style="zoom:33%;" /></p>

<p>Based on the assumption that LLMs know what they know, some people try to reduce hallucination with prompts, e.g. adding <code class="language-plaintext highlighter-rouge">Answer as truthfully as possible, and if you're unsure of the answer, say "Sorry, I don't know"</code>. Making LLMs respond concisely also seems to help with hallucination – the fewer tokens LLMs have to generate, the less chance they have to make things up.</p>

<h1 id="4diffusion-models">4.Diffusion Models</h1>

<p>Refer to</p>

<table>
  <tbody>
    <tr>
      <td>1, [What are Diffusion Models?</td>
      <td>Lil’Log (lilianweng.github.io)](https://lilianweng.github.io/posts/2021-07-11-diffusion-models/)</td>
    </tr>
  </tbody>
</table>

<p>2, <a href="https://zhuanlan.zhihu.com/p/532402983">理解扩散模型Diffusion Models（一） - 知乎 (zhihu.com)</a></p>

<p>3, <a href="https://blog.csdn.net/m0_63642362/article/details/127586200">【diffusion】扩散模型详解！理论＋代码_diffusion扩散模型_AI Studio的博客-CSDN博客</a></p>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/image-20230517105141157.png" alt="image-20230517105141157" style="zoom: 33%;" /></p>

<p>Diffusion（扩散） models are inspired by non-equilibrium thermodynamics. <strong>They define a Markov chain of diffusion steps to slowly add random noise to data and then learn to reverse the diffusion process to construct desired data samples from the noise</strong>. Unlike VAE or flow models, diffusion models are learned with a fixed procedure and the latent variable has high dimensionality (same as the original data).</p>

<blockquote>
  <p>Per my understanding is (to be updated after read thoroughly those papers)</p>

  <ul>
    <li>each image is follow Gaussian distribution</li>
    <li>by adding controlled noise ${\beta_t \in (0, 1)}_{t=1}^T$ from steps 1….T,  the noised image (secret) is learned</li>
    <li>by denoised those learned noise from noised image , the image is recovered</li>
    <li>by control the denoise process (which kind of noise be removed), final image can be constructed.</li>
  </ul>
</blockquote>

<p>Several diffusion-based generative models have been proposed with similar ideas underneath, including <em>diffusion probabilistic models</em> (<a href="https://arxiv.org/abs/1503.03585">Sohl-Dickstein et al., 2015</a>), <em>noise-conditioned score network</em> (<strong>NCSN</strong>; <a href="https://arxiv.org/abs/1907.05600">Yang &amp; Ermon, 2019</a>), and <em>denoising diffusion probabilistic models</em> (<strong>DDPM</strong>; <a href="https://arxiv.org/abs/2006.11239">Ho et al. 2020</a>).</p>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/generative-overview.png" alt="img" style="zoom: 33%;" /></p>

<p>Existing generative modeling techniques can largely be grouped into two categories based on how they represent probability distributions.</p>

<ol>
  <li>
    <p>likelihood-based models</p>

    <p>, which directly learn the distribution’s probability density (or mass) function via (approximate) maximum likelihood. Typical likelihood-based models include autoregressive models, normalizing flow models, energy-based models (EBMs), and variational auto-encoders (VAEs)</p>
  </li>
  <li>
    <p>implicit generative models, where the probability distribution is implicitly represented by a model of its sampling process. The most prominent example is generative adversarial networks (GANs), where new samples from the data distribution are synthesized by transforming a random Gaussian vector with a neural network.</p>

    <p><img src="/assets/BERTGPTDiffusion%20Research.assets/implicit_models.png" alt="img" style="zoom:50%;" /></p>
  </li>
</ol>

<p>GAN is an example of implicit models. It implicitly represents a distribution over all objects that can be produced by the generator network.</p>

<p>GAN 由一个生成器（generator）和判别器（discriminator）组成，generator 负责生成逼真数据以“骗”过 discriminator，而 discriminator 负责判断一个样本是真实的还是“造”出来的。GAN 的训练其实就是两个模型在相互学习“对抗”。</p>

<p>VAE 同样希望训练一个生成模型 x=g(z)，这个模型能够将采样后的概率分布映射到训练集的概率分布。生成隐变量 z，并且 z 是及含有数据信息又含有噪声，除了还原输入的样本数据以外，还可以用于生成新的数据。</p>

<p>Diffusion Models 的灵感来自 non-equilibrium thermodynamics （非平衡热力学）。理论首先定义扩散步骤的马尔可夫链，以缓慢地将随机噪声添加到数据中，然后学习逆向扩散过程以从噪声中构造所需的数据样本。与 VAE 或流模型不同，扩散模型是通过固定过程学习，并且隐空间 z 具有比较高的维度。</p>

<h2 id="41-forward-diffusion-process">4.1 Forward diffusion process</h2>

<h3 id="411define-forward-qmathbfx1t-vert-mathbfx_0-and--qmathbfx_t-mathbfxt-1--to-get-qmathbfx_t-vert-mathbfx_0-">4.1.1Define forward $q(\mathbf{x}<em>{1:T} \vert \mathbf{x}_0)$ and  $q(\mathbf{x}_t |\mathbf{x}</em>{t-1})$  to get $q(\mathbf{x}_t \vert \mathbf{x}_0) $</h3>

<p>Given a data point sampled from a real data distribution $\mathbf{x}<em>0 \sim q(\mathbf{x})$, let us define a *forward diffusion process* in which we add small amount of Gaussian noise to the sample in $T$ steps, producing a sequence of noisy samples $\mathbf{x}_1, \dots, \mathbf{x}_T$ The step sizes are controlled by a variance schedule ${\beta_t \in (0, 1)}</em>{t=1}^T$.
\(q(\mathbf{x}_t \vert \mathbf{x}_{t-1}) = \mathcal{N}(\mathbf{x}_t; \sqrt{1 - \beta_t} \mathbf{x}_{t-1}, \beta_t\mathbf{I}) \quad
q(\mathbf{x}_{1:T} \vert \mathbf{x}_0) = \prod^T_{t=1} q(\mathbf{x}_t \vert \mathbf{x}_{t-1})\)
The data sample $\mathbf{x}_0$ gradually loses its distinguishable features as the step $T$ becomes larger. Eventually when $T \to \infty$ is equivalent to an isotropic Gaussian distribution.</p>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/image-20230517110949555.png" alt="image-20230517110949555" style="zoom: 50%;" /></p>

<p><strong>by using Reparameterization Trick</strong> , Define
\(\begin{aligned}
\alpha_t &amp; =1-\beta_t \\
\bar{\alpha}_t &amp; =\prod_{i=1}^t \alpha_i
\end{aligned}\)
Then：
$$
\begin{eqnarray}
q\left(\mathbf{x}<em>t \mid \mathbf{x}</em>{t-1}\right) &amp;&amp; =\mathcal{N}\left(\sqrt{1-\beta_t} \mathbf{x}<em>{t-1}, \beta_t \mathbf{I}\right) <br />
\mathbf{x}_t &amp;&amp; =\sqrt{1-\beta_t} \mathbf{x}</em>{t-1}+\sqrt{\beta_t} \epsilon, \quad \epsilon \sim \mathcal{N}(0, \mathbf{I}) &amp;&amp;\text{ ;where  using Reparameterization Trick }\</p>

<p>\mathbf{x}<em>t 
&amp;&amp;= \sqrt{\alpha_t}\mathbf{x}</em>{t-1} + \sqrt{1 - \alpha_t}\boldsymbol{\epsilon}<em>{t-1} &amp;&amp; \text{ ;where } \boldsymbol{\epsilon}</em>{t-1}, \boldsymbol{\epsilon}<em>{t-2}, \dots \sim \mathcal{N}(\mathbf{0}, \mathbf{I}) <br />
&amp;&amp;= \sqrt{\alpha_t \alpha</em>{t-1}} \mathbf{x}<em>{t-2} + \sqrt{1 - \alpha_t \alpha</em>{t-1}} \bar{\boldsymbol{\epsilon}}<em>{t-2} &amp;&amp; \text{ ;where } \bar{\boldsymbol{\epsilon}}</em>{t-2} \text{ merges two Gaussians (*).} <br />
&amp;&amp;= \dots <br />
&amp;&amp;= \sqrt{\bar{\alpha}_t}\mathbf{x}_0 + \sqrt{1 - \bar{\alpha}_t}\boldsymbol{\epsilon}  \tag{4-DDIM} \ 
q(\mathbf{x}_t \vert \mathbf{x}_0) &amp;&amp;= \mathcal{N}(\mathbf{x}_t; \sqrt{\bar{\alpha}_t} \mathbf{x}_0, (1 - \bar{\alpha}_t)\mathbf{I})</p>

<p>\end{eqnarray}
\((*) Recall that when we merge two Gaussians with different variance, $\mathcal{N}(\mathbf{0}, \sigma_1^2\mathbf{I})$ and $\mathcal{N}(\mathbf{0}, \sigma_2^2\mathbf{I})$, &lt;font color=red&gt;the new distribution is $\mathcal{N}(\mathbf{0}, (\sigma_1^2 + \sigma_2^2)\mathbf{I})$. Here the merged standard deviation is&lt;/font&gt;\)
\sqrt{(1 - \alpha_t) + \alpha_t (1-\alpha_{t-1})} = \sqrt{1 - \alpha_t\alpha_{t-1}}
$$
Usually, we can afford a larger update step when the sample gets noisier $\beta_1 &lt; \beta_2 &lt; \dots &lt; \beta_T$ therefore   $\bar{\alpha}_1 &gt; \dots &gt; \bar{\alpha}_T$</p>

<p>Let $X\sim \mathcal{N}(a,b)$, $X+c \sim \mathcal{N}(a+c,b)$ and $cX \sim \mathcal{N}(ca,c^2 b)$ ， proof one of them. 
\(\begin{align*}
F_{X+c}(x)
&amp;=P(X+c\le x)\\
&amp;=P(X\le x-c)\\
&amp;=\int_{-\infty}^{x-c}\frac{1}{\sqrt{2b\pi} } \; e^{ -\frac{(t-a)^2}{2b} }\mathrm dt\\
&amp;=\int_{-\infty}^x\frac{1}{\sqrt{2b\pi} } \; e^{ -\frac{(s-c-a)^2}{2b} }\mathrm d(s-c)\\
&amp;=\int_{-\infty}^x\frac{1}{\sqrt{2b\pi} } \; e^{ -\frac{(s-(a+c))^2}{2b} }\mathrm ds.
\end{align*}\)
so the new $\sigma^2 = (\sqrt{1 - \alpha_t})^2  + (\sqrt {\alpha_t(1 -  \alpha_{t-1}) }^2$ therefore $\sigma = \sqrt{1 - \alpha_t\alpha_{t-1}}$</p>

<h3 id="reparameterization-trick">Reparameterization Trick</h3>

<table>
  <tbody>
    <tr>
      <td>([From Autoencoder to Beta-VAE</td>
      <td>Lil’Log (lilianweng.github.io)](https://lilianweng.github.io/posts/2018-08-12-vae/#reparameterization-trick))</td>
    </tr>
  </tbody>
</table>

<p>The expectation term in the loss function invokes generating samples from $\mathbf{z} \sim q_\phi(\mathbf{z}\vert\mathbf{x})$.  Sampling is a stochastic process and therefore we cannot backpropagate the gradient. To make it trainable, the reparameterization trick is introduced: It is often possible to express the random variable $z$ as a deterministic variable $\mathbf{z} = \mathcal{T}<em>\phi(\mathbf{x}, \boldsymbol{\epsilon})$, where $\boldsymbol{\epsilon}$ is an auxiliary independent random variable, and the transformation function $\mathcal{T}</em>\phi $ parameterized by $\phi$ converts $\epsilon$ to $z$.</p>

<p>For example, a common choice of the form of $q_\phi(\mathbf{z}\vert\mathbf{x})$ is a multivariate Gaussian with a diagonal covariance structure:
\(\begin{aligned}
\mathbf{z} &amp;\sim q_\phi(\mathbf{z}\vert\mathbf{x}^{(i)}) = \mathcal{N}(\mathbf{z}; \boldsymbol{\mu}^{(i)}, \boldsymbol{\sigma}^{2(i)}\boldsymbol{I}) &amp; \\
\mathbf{z} &amp;= \boldsymbol{\mu} + \boldsymbol{\sigma} \odot \boldsymbol{\epsilon} \text{, where } \boldsymbol{\epsilon} \sim \mathcal{N}(0, \boldsymbol{I}) &amp; \scriptstyle{\text{; Reparameterization trick.}}
\end{aligned}\)
where ⊙ refers to element-wise product</p>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/reparameterization-trick.png" alt="img" style="zoom:67%;" /></p>

<p>Fig. 8. Illustration of how the reparameterization trick makes the $z$ sampling process trainable.(Image source: Slide 12 in Kingma’s NIPS 2015 workshop <a href="http://dpkingma.com/wordpress/wp-content/uploads/2015/12/talk_nips_workshop_2015.pdf">talk</a>)</p>

<p>The reparameterization trick works for other types of distributions too, not only Gaussian. In the multivariate Gaussian case, we make the model trainable by learning the mean and variance of the distribution, $\mu$ and $\delta$, explicitly using the reparameterization trick, while the stochasticity remains in the random variable $\boldsymbol{\epsilon} \sim \mathcal{N}(0, \boldsymbol{I})$</p>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/vae-gaussian.png" alt="img" style="zoom:33%;" /></p>

<p>Fig. 9. Illustration of variational autoencoder model with the multivariate Gaussian assumption</p>

<font size="6" color="red">(TBS)</font>

<h3 id="product-of-two-gaussian-pdfs">Product of Two Gaussian PDFs</h3>

<p><a href="https://ccrma.stanford.edu/~jos/sasp/Product_Two_Gaussian_PDFs.html">Product of Two Gaussian PDFs (stanford.edu)</a></p>

<p>For the special case of two <a href="http://en.wikipedia.org/wiki/Normal_distribution">Gaussian</a> probability densities,</p>

<p>\(\begin{aligned}
&amp; x_1(t) \triangleq \frac{1}{\sqrt{2 \pi \sigma_1^2}} e^{-\frac{\left(t-\mu_1\right)^2}{2 \sigma_1^2}} \\
&amp; x_2(t) \triangleq \frac{1}{\sqrt{2 \pi \sigma_2^2}} e^{-\frac{\left(t-\mu_2\right)^2}{2 \sigma_2^2}}
\end{aligned}\)
the product density has mean and variance given by
\(\begin{eqnarray*} \mu &amp;=&amp; \frac{\frac{\mu_1}{2\sigma_1^2} + \frac{\mu_2}{2\sigma_2^2}}{\frac{1}{2\sigma_1^2} + \frac{1}{2\sigma_2^2}} \; = \; \frac{\mu_1\sigma_2^2 + \mu_2\sigma_1^2}{\sigma_2^2 + \sigma_1^2}\\ \sigma^2 &amp;=&amp; \left. \sigma_1^2 \right\Vert \sigma_2^2 \; = \; \frac{1}{\frac{1}{\sigma_1^2} + \frac{1}{\sigma_2^2}} \;\triangleq \; \frac{\sigma_1^2\sigma_2^2}{\sigma_1^2 + \sigma_2^2}. \end{eqnarray*}\)</p>

<h3 id="另外一种解读细节较为清晰以及噪声-z_t-1-">另外一种解读(细节较为清晰以及噪声 $z_{t-1}$ ）</h3>

<p>我们考察当给定初始样本 $x_0$ 时，扩散过程中随机变量 $X_1, X_2, \ldots$ 的分布情况。定义
\(\alpha_t=1-\beta_t \text { 以及 } \bar{\alpha}_t=\prod_{i=1}^t a_i\)
对于 $t$ 时刻的样本 $x_t$ ，就理论而言应该是在分布 $N\left(\sqrt{\alpha_t} x_{t-1},\left(1-\alpha_t\right) I\right)$ 中采样获得的。根 据高斯分布的性质，若 $X$ 符合高斯分布 $N(\mu, \Sigma)$ ，则 $a X+b$ 符合高斯分布 $N\left(\mu+a, b^2 \Sigma\right)$ ，<strong>因而实际在获取 $x_t$ 时，可先从 $N(0, I)$ 中随机采样获取 $z_{t-1}$ ，然后进行变换得到符合 $N\left(\sqrt{\alpha_t} x_{t-1},\left(1-\alpha_t\right) I\right)$ 的样本，即</strong>
\(x_t=\sqrt{\alpha_t} x_{t-1}+\sqrt{1-\alpha_t} z_{t-1}\)
需要强调的是，在 $x_{t-1}$ 的基础上通过添加噪声 $z_{t-1}$ 获得 $x_t$ 时，需要先缩小 $x_{t-1}$ 的数值以获得 均值，然后在此基础上再叠加高斯噪声 $z_{t-1}$ ，而并非直接在 $x_{t-1}$ 上添加噪声。
类似地，在 $t-1$ 时刻也有关系
\(x_{t-1}=\sqrt{\alpha_{t-1}} x_{t-2}+\sqrt{1-\alpha_{t-1}} z_{t-2}\)
其中 $z_{t-2}$ 也符合高斯分布。将两式联立有
\(\begin{aligned}
x_t &amp; =\sqrt{\alpha_t}\left(\sqrt{\alpha_{t-1}} x_{t-2}+\sqrt{1-\alpha_{t-1}} z_{t-2}\right)+\sqrt{1-\alpha_t} z_{t-1} \\
&amp; =\sqrt{\alpha_t \alpha_{t-1}} x_{t-2}+\sqrt{\alpha_t-\alpha_t \alpha_{t-1}} z_{t-2}+\sqrt{1-\alpha_t} z_{t-1} \\
&amp; =\sqrt{\alpha_t \alpha_{t-1}} x_{t-2}+\sqrt{1-\alpha_t \alpha_{t-1}} \bar{z}_{t-2}
\end{aligned}\)
其中， $\bar{z}<em>{t-2} \sim N(0, I)$ 。上述推导需要依据高斯分布的性质，若 $X$ 符合高斯分布 $N\left(\mu_X, \Sigma_X\right) ， Y$ 符合高斯分布 $N\left(\mu_Y, \Sigma_Y\right)$ ，则新的随机变量 $a X+b Y$ 符合高斯分布 $N\left(a \mu_X+b \mu_Y, a^2 \Sigma_X+b^2 \Sigma_Y\right)$ 。
将上述过程不断迭代，可获得 $x_t$ 和 $x_0$ 的关系
\(x_t=\sqrt{\bar{\alpha}_t} x_0+\sqrt{1-\bar{\alpha}_t} \bar{z}_0\)
其中 $\bar{z}_0$ 仍为从 $N(0,1)$ 的采样噪声。此时，我们可以得到结论，当给定初始样本 $x_0$ 时，随机 变量 $X_t$ 的概率分布为
\(q\left(X_t \mid x_0\right)=N\left(\sqrt{\bar{\alpha}_t} x_0,\left(1-\bar{\alpha}_t\right) I\right)\)
上式表明，对于某个给定 $x_0$ ，其在多次扩散中，始终对应于一个高斯分布，如上图所示，且该高 斯分布逐渐趋近标准高斯分布。
此时需要说明一个问题: 生成模型需要实现从噪声 $x_T$ 到样本 $x_0$ 的映射，这里为什么需要构建如 此复杂的前向扩散过程? 这是因为通过上述扩散过程蕴含着重要可逆性质: 当 $\beta_t$ 足够小时，在扩 散过程的逆过程 (生成过程) 中， $q\left(X</em>{t-1} \mid x_t\right)$ 也将 (近似) 符合高斯分布。</p>

<h3 id="扩散模型是如何进行概率建模">扩散模型是如何进行概率建模</h3>

<p>为了说明扩散模型是如何进行概率建模的，我们必须介绍扩散过程 (正向过程) 和生成过程 (逆向 过程、推断过程) 。为避免混渚，将以 $x_1, x_2, \ldots x_T$ 表示不同时间步中的样本，以 $X_1, X_2, \ldots, X_T$ 表示不同时间步对应的随机变量，以 $p\left(X_T\right)$ 表示随机变量的概率分布，以 $N\left(x_T ; \mu, \Sigma\right)$ 表示在分布 $N(\mu, \Sigma)$ 中 $X=x_T$ 时的概率样本概率值。
在扩散过程 (正向过程) 中，通过对任意的初始样本 $x_0$ 连续地添加 $T$ 次高斯噪声，可获得包含 一条样本的轨迹 $x_1, x_2, \ldots, x_T$ ，并且当 $T$ 趋于无穷时，原始样本 $x_0$ 的特征完全消失，成为 标准高斯噪声。从概率分布的角度而言，如果定义初始样本 (训练样本) 的概率分布为 $q\left(X_0\right)$ ， 则通过无限次地扩散动作，实现了从初始样本分布到标准高斯分布的映射，即 $q\left(X_T\right)=N(0, I)$
当然，扩散过程连续添加的高斯噪声并不是任意的，其具体的限定规则为
\(q\left(X_t \mid x_{t-1}\right)=N\left(\sqrt{1-\beta_t} x_{t-1}, \beta_t I\right) \text { ，其中 } \beta_1&lt;\beta_2&lt;\ldots&lt;\beta_T\)
由上式可知，在给定 $t-1$ 时刻的样本 $x_{t-1}$ 的条件下， $t$ 时刻样本的分布为高斯分布，其均值 为 $\sqrt{1-\beta_t} x_{t-1}$ ，方差为 $\beta_t I$ 。由此式可以看出，该条件高斯分布的均值参数只与 $x_{t-1}$ 有 关，而与 $x_{t-2}, x_{t-3}, \ldots$ 无关，因而随机过程 $\left{X_t\right}$ 是一个马尔可夫过程。
随机变量 $X_t$ 的均值 $\sqrt{1-\beta_t} x_{t-1}$ 相比于样本 $x_{t-1}$ 将更趋于 0 ，而方差也随着 $t$ 的增加而逐渐 向 $I$ 趋近，单个样本向标准高斯分布趋近的过程如下图所示。我们也可理解为，当扩散的时间步 足够多时，随机过程 $\left{X_t\right}$ 将进入稳态 $N(0, I)$ 。</p>

<h2 id="42-reversing-process">4.2 Reversing Process</h2>

<h3 id="summary-总结">Summary (总结）</h3>

<p>扩散模型的性质表明，从 $q\left(X_T\right)=N(0, I)$ 到 $q\left(X_0\right)$ 的逆过程是马尔可夫过程，并且有
\(q\left(X_{t-1} \mid x_t\right)=N\left(\tilde{\mu}\left(x_t\right), \tilde{\Sigma}\left(x_t\right)\right)\)
若 $q\left(X_{t-1} \mid x_t\right)$ 的均值 $\tilde{\mu}\left(x_t\right)$ 和方差参数 $\tilde{\Sigma}\left(x_t\right)$ 为已知量，则能在逆过程中实现样本的采样生 成。首先，从 $X_T$ 的分布 $N(0, I)$ 开始依次采样获得 $x_T$ ，然后在 $q\left(X_{T-1} \mid x_T\right)$ 中采样获得 $x_{T-1}$ ，在 $q\left(X_{T-2} \mid x_{T-1}\right)$ 中采样获得 $x_{T-2} \ldots .$. .. 迭代此过程直至获得样本 $x_0$ 。
然而，正向扩散过程中，条件高斯分布 $q\left(X_t \mid x_{t-1}\right)$ 的均值、方差具有明确的数值，而在逆向过 程中， $q\left(X_{t-1} \mid x_t\right)$ 的均值 $\tilde{\mu}\left(x_t\right)$ 和方差参数 $\tilde{\Sigma}\left(x_t\right)$ 是没有解析形式的，因而需要学习每个 $t$ 时刻的均值和方差参数。也就是说，我们需要根据训练样本集合 $\left{x_0^{(1)}, x_0^{(2)}, \ldots, x_0^{(N)}\right}$ 学习到 足够好的 $\tilde{\mu}\left(x_t\right)$ 和 $\tilde{\Sigma}\left(x_t\right)$ ，从而使得能在逆过程中产生足够好的样本。</p>

<p>通过一些数学变换得到 $q(\mathbf{x}<em>{t-1} \vert \mathbf{x}_t, \mathbf{x}_0) = \mathcal{N}(\mathbf{x}</em>{t-1}; \color{blue}{\tilde{\boldsymbol{\mu}}}(\mathbf{x}<em>t, \mathbf{x}_0), \color{red}{\tilde{\beta}_t} \mathbf{I})$ 其中 detail please check below  <a href="# 4.2.2 Tractable $q(\mathbf{x}_{t-1} \vert \mathbf{x}_t, \mathbf{x}_0)$">chapter 4.2.2</a> 
\(\begin{aligned}
\tilde{\beta}_t 
&amp;= \color{green}{\frac{1 - \bar{\alpha}_{t-1}}{1 - \bar{\alpha}_t} \cdot \beta_t} \\
\tilde{\boldsymbol{\mu}}(\mathbf{x}_t, \mathbf{x}_0) &amp;= \color{cyan}{\frac{1}{\sqrt{\alpha_t}} \Big( \mathbf{x}_t - \frac{1 - \alpha_t}{\sqrt{1 - \bar{\alpha}_t}} \boldsymbol{\epsilon}_t \Big)}
\end{aligned}\)
此时，我们可以构建生成模型 $p</em>\theta\left(x_{0: T}\right)$ ，即
\(\begin{aligned}
&amp; p_\theta\left(x_{0: T}\right)=p\left(x_T\right) \prod_{t=1}^T p_\theta\left(x_{t-1} \mid x_t\right) \\
&amp; p_\theta\left(x_{t-1} \mid x_t\right)=N\left(x_{t-1} ; \mu_\theta\left(x_t, t\right), \Sigma_\theta\left(x_t, t\right)\right)
\end{aligned}\)
其中， $p\left(x_T\right)=N\left(x_T ; 0, I\right)$
\(\begin{aligned}
\boldsymbol{\mu}_\theta(\mathbf{x}_t, t) &amp;= \color{cyan}{\frac{1}{\sqrt{\alpha_t}} \Big( \mathbf{x}_t - \frac{1 - \alpha_t}{\sqrt{1 - \bar{\alpha}_t}} \boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t) \Big)} \\
\text{Thus }\mathbf{x}_{t-1} &amp;= \mathcal{N}(\mathbf{x}_{t-1}; \frac{1}{\sqrt{\alpha_t}} \Big( \mathbf{x}_t - \frac{1 - \alpha_t}{\sqrt{1 - \bar{\alpha}_t}} \boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t) \Big), \boldsymbol{\Sigma}_\theta(\mathbf{x}_t, t))
\end{aligned}\)
<img src="/assets/BERTGPTDiffusion%20Research.assets/denoising-diffusion-probabilistic-models-forward_posterior_reverse_equations.png" alt="img" style="zoom: 50%;" /></p>

<p><strong>扩散模型将 $x_t, t$ 和 $\mu\left(x_t, t\right)$ 以及 $\Sigma\left(x_t, t\right)$ 的映射关系定义为参数 $\theta$ 可学习的神经网络形式</strong>，即 $\mu_\theta\left(x_t, t\right)$ 和 $\Sigma_\theta\left(x_t, t\right)$ (DDPM仅对均值的映射关系进行学习，方差映射关系为先验设定 $\Sigma_\theta\left(x_t, t\right)=\sigma_t^2 I=\tilde{\beta_t} I$ 或者 $\beta_t\left(1-\bar{\alpha}<em>{t-1}\right) /\left(1-\bar{\alpha}_t\right) I$ ，不包含可学习参数，只考 虑均值的学习过程，若能通过数据集学习获得最优参数 $\theta^*$ ，从而实现 $p</em>{\theta^*}\left(X_{t-1} \mid x_t\right) \approx q\left(X_{t-1} \mid x_t\right)$ ，则能进行样本生成。</p>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/denoising-diffusion-probabilistic-models-forward_and_backward_equations.png" alt="img" style="zoom:50%;" /></p>

<h3 id="421p_thetamathbfx_t-1-vert-mathbfx_t-approximate-general">4.2.1$p_\theta(\mathbf{x}_{t-1} \vert \mathbf{x}_t)$ approximate general</h3>

<p><img src="https://lilianweng.github.io/posts/2021-07-11-diffusion-models/DDPM.png" alt="img" /></p>

<p>Fig. 2. The Markov chain of forward (reverse) diffusion process of generating a sample by slowly adding (removing) noise. (Image source: <a href="https://arxiv.org/abs/2006.11239">Ho et al. 2020</a> with a few additional annotations)</p>

<p>If we can reverse the above process and sample from $q(\mathbf{x}<em>{t-1} \vert \mathbf{x}_t)$, we will be able to recreate the true sample from a Gaussian noise input, $\mathbf{x}_T \sim \mathcal{N}(\mathbf{0}, \mathbf{I})$. <strong>Note that if $\beta_t$ (the noise added) is small enough, $q(\mathbf{x}_{t-1} \vert \mathbf{x}_t)$ will also be Gaussian.</strong> Unfortunately, we cannot easily estimate $q(\mathbf{x}</em>{t-1} \vert \mathbf{x}_t)$ because it needs to use the entire dataset and therefore <strong>we need to learn a model $p_\theta$ to approximate</strong> these conditional probabilities in order to run the <em>reverse diffusion process</em>.
\(p_\theta(\mathbf{x}_{0:T}) = p(\mathbf{x}_T) \prod^T_{t=1} p_\theta(\mathbf{x}_{t-1} \vert \mathbf{x}_t) \quad \text {;same conditional independent} \\
p_\theta(\mathbf{x}_{t-1} \vert \mathbf{x}_t) = \mathcal{N}(\mathbf{x}_{t-1}; \boldsymbol{\mu}_\theta(\mathbf{x}_t, t), \boldsymbol{\Sigma}_\theta(\mathbf{x}_t, t))\)
<img src="/assets/BERTGPTDiffusion%20Research.assets/diffusion-example.png" alt="img" style="zoom: 25%;" /></p>

<h3 id="422-tractable-qmathbfx_t-1-vert-mathbfx_t-mathbfx_0">4.2.2 Tractable $q(\mathbf{x}_{t-1} \vert \mathbf{x}_t, \mathbf{x}_0)$</h3>

<p>It is noteworthy that the reverse conditional probability is tractable when conditioned on $X_0$:
\(q(\mathbf{x}_{t-1} \vert \mathbf{x}_t, \mathbf{x}_0) = \mathcal{N}(\mathbf{x}_{t-1}; \color{blue}{\tilde{\boldsymbol{\mu}}}(\mathbf{x}_t, \mathbf{x}_0), \color{red}{\tilde{\beta}_t} \mathbf{I})\)</p>

\[\begin{aligned}
q(\mathbf{x}_{t-1} \vert \mathbf{x}_t, \mathbf{x}_0) 
&amp;= q(\mathbf{x}_t \vert \mathbf{x}_{t-1}, \mathbf{x}_0) \frac{ q(\mathbf{x}_{t-1} \vert \mathbf{x}_0) }{ q(\mathbf{x}_t \vert \mathbf{x}_0) }  \text{ ; we already get } q(\mathbf{x}_t \vert \mathbf{x}_0) = \mathcal{N}(\mathbf{x}_t; \sqrt{\bar{\alpha}_t} \mathbf{x}_0, (1 - \bar{\alpha}_t)\mathbf{I}) \\
&amp;\propto \exp \Big(-\frac{1}{2} \big(\frac{(\mathbf{x}_t - \sqrt{\alpha_t} \mathbf{x}_{t-1})^2}{\beta_t} + \frac{(\mathbf{x}_{t-1} - \sqrt{\bar{\alpha}_{t-1}} \mathbf{x}_0)^2}{1-\bar{\alpha}_{t-1}} - \frac{(\mathbf{x}_t - \sqrt{\bar{\alpha}_t} \mathbf{x}_0)^2}{1-\bar{\alpha}_t} \big) \Big) \\
&amp;= \exp \Big(-\frac{1}{2} \big(\frac{\mathbf{x}_t^2 - 2\sqrt{\alpha_t} \mathbf{x}_t \color{blue}{\mathbf{x}_{t-1}} \color{black}{+ \alpha_t} \color{red}{\mathbf{x}_{t-1}^2} }{\beta_t} + \frac{ \color{red}{\mathbf{x}_{t-1}^2} \color{black}{- 2 \sqrt{\bar{\alpha}_{t-1}} \mathbf{x}_0} \color{blue}{\mathbf{x}_{t-1}} \color{black}{+ \bar{\alpha}_{t-1} \mathbf{x}_0^2}  }{1-\bar{\alpha}_{t-1}} - \frac{(\mathbf{x}_t - \sqrt{\bar{\alpha}_t} \mathbf{x}_0)^2}{1-\bar{\alpha}_t} \big) \Big) \\
&amp;= \exp\Big( -\frac{1}{2} \big( \color{red}{(\frac{\alpha_t}{\beta_t} + \frac{1}{1 - \bar{\alpha}_{t-1}})} \mathbf{x}_{t-1}^2 - \color{blue}{(\frac{2\sqrt{\alpha_t}}{\beta_t} \mathbf{x}_t + \frac{2\sqrt{\bar{\alpha}_{t-1}}}{1 - \bar{\alpha}_{t-1}} \mathbf{x}_0)} \mathbf{x}_{t-1} \color{black}{ + C(\mathbf{x}_t, \mathbf{x}_0) \big) \Big)} \\

&amp;= \exp\Big( -\frac{1}{2} \big( \color{red}{} \frac{\mathbf{x}_{t-1}^2}{\tilde\beta} - \color{blue}{\frac{2\tilde\mu}{\tilde\beta}} \mathbf{x}_{t-1} \color{black}{ + C(\mathbf{x}_t, \mathbf{x}_0) \big) \Big)  \text{   ;  according to below replacement }} \\

&amp;= \exp\Big( -\frac{1}{2} \big( \frac{\color{red}{\mathbf{x}_{t-1}^2} - \color{blue}{2\tilde\mu \mathbf{x}_{t-1}} +\tilde\mu^2 }{\tilde\beta }  \color{black}{ + C(\mathbf{x}_t, \mathbf{x}_0) - \tilde\mu^2\tilde\beta \big) \Big)  \text{   ;  according to below replacement...we get mu and sigma here as following }} 

\end{aligned}\]

<p>where $C(\mathbf{x}<em>t, \mathbf{x}_0)$ is some function not involving $\mathbf{x}</em>{t-1}$ and details are omitted. Following the standard Gaussian density function, the mean and variance can be parameterized as follows (recall that $\alpha_t = 1 - \beta_t$ and $\bar{\alpha}<em>t = \prod</em>{i=1}^T \alpha_i$):
\(\begin{aligned}
\tilde{\beta}_t 
&amp;= 1/(\frac{\alpha_t}{\beta_t} + \frac{1}{1 - \bar{\alpha}_{t-1}}) 
= 1/(\frac{\alpha_t - \bar{\alpha}_t + \beta_t}{\beta_t(1 - \bar{\alpha}_{t-1})})
= \color{green}{\frac{1 - \bar{\alpha}_{t-1}}{1 - \bar{\alpha}_t} \cdot \beta_t} \\
\tilde{\boldsymbol{\mu}}_t (\mathbf{x}_t, \mathbf{x}_0)
&amp;= (\frac{\sqrt{\alpha_t}}{\beta_t} \mathbf{x}_t + \frac{\sqrt{\bar{\alpha}_{t-1} }}{1 - \bar{\alpha}_{t-1}} \mathbf{x}_0)/(\frac{\alpha_t}{\beta_t} + \frac{1}{1 - \bar{\alpha}_{t-1}}) \\
&amp;= (\frac{\sqrt{\alpha_t}}{\beta_t} \mathbf{x}_t + \frac{\sqrt{\bar{\alpha}_{t-1} }}{1 - \bar{\alpha}_{t-1}} \mathbf{x}_0) \color{green}{\frac{1 - \bar{\alpha}_{t-1}}{1 - \bar{\alpha}_t} \cdot \beta_t} \\
&amp;= \frac{\sqrt{\alpha_t}(1 - \bar{\alpha}_{t-1})}{1 - \bar{\alpha}_t} \mathbf{x}_t + \frac{\sqrt{\bar{\alpha}_{t-1}}\beta_t}{1 - \bar{\alpha}_t} \mathbf{x}_0\\
\end{aligned}\)
we have $ \mathbf{x}_t = \sqrt{\bar{\alpha}_t}\mathbf{x}_0 + \sqrt{1 - \bar{\alpha}_t}\boldsymbol{\epsilon}$, so we can represent $\mathbf{x}_0 = \frac{1}{\sqrt{\bar{\alpha}_t}}(\mathbf{x}_t - \sqrt{1 - \bar{\alpha}_t}\boldsymbol{\epsilon}_t)$ and plug it into the above equation and obtain:
\(\begin{aligned}
\tilde{\boldsymbol{\mu}}_t
&amp;= \frac{\sqrt{\alpha_t}(1 - \bar{\alpha}_{t-1})}{1 - \bar{\alpha}_t} \mathbf{x}_t + \frac{\sqrt{\bar{\alpha}_{t-1}}\beta_t}{1 - \bar{\alpha}_t} \frac{1}{\sqrt{\bar{\alpha}_t}}(\mathbf{x}_t - \sqrt{1 - \bar{\alpha}_t}\boldsymbol{\epsilon}_t) \\
&amp;= \color{cyan}{\frac{1}{\sqrt{\alpha_t}} \Big( \mathbf{x}_t - \frac{1 - \alpha_t}{\sqrt{1 - \bar{\alpha}_t}} \boldsymbol{\epsilon}_t \Big)}
\end{aligned}\)</p>
<h3 id="423-using-p_thetamathbfxt-1-vert-mathbfx_t-approximate-qmathbfxt-1-vert-mathbfx_t-mathbfx_0">4.2.3 using $p_\theta(\mathbf{x}<em>{t-1} \vert \mathbf{x}_t)$ approximate $q(\mathbf{x}</em>{t-1} \vert \mathbf{x}_t, \mathbf{x}_0)$</h3>

<p>in the reverse diffusion process, $p_\theta(\mathbf{x}<em>{t-1} \vert \mathbf{x}_t) = \mathcal{N}(\mathbf{x}</em>{t-1}; \boldsymbol{\mu}<em>\theta(\mathbf{x}_t, t), \boldsymbol{\Sigma}</em>\theta(\mathbf{x}_t, t))$. <font color="red">We would like to train $\boldsymbol{\mu}_\theta$ to predict $\tilde{\boldsymbol{\mu}}_t = \frac{1}{\sqrt{\alpha_t}} \Big( \mathbf{x}_t - \frac{1 - \alpha_t}{\sqrt{1 - \bar{\alpha}_t}} \boldsymbol{\epsilon}_t \Big)$. Because $\mathbf{x}_t$ is available as input at training time, we can reparametrized the Gaussian noise term instead to make it predict $\boldsymbol{\epsilon}_t$ from the input $\mathbf{x}_t$ at time step $t$: </font>
\(\begin{aligned}
\boldsymbol{\mu}_\theta(\mathbf{x}_t, t) &amp;= \color{cyan}{\frac{1}{\sqrt{\alpha_t}} \Big( \mathbf{x}_t - \frac{1 - \alpha_t}{\sqrt{1 - \bar{\alpha}_t}} \boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t) \Big)} \\
\text{Thus }\mathbf{x}_{t-1} &amp;= \mathcal{N}(\mathbf{x}_{t-1}; \frac{1}{\sqrt{\alpha_t}} \Big( \mathbf{x}_t - \frac{1 - \alpha_t}{\sqrt{1 - \bar{\alpha}_t}} \boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t) \Big), \boldsymbol{\Sigma}_\theta(\mathbf{x}_t, t))
\end{aligned}\)</p>
<h3 id="424-the-loss-function---log-p_thetamathbfx0-nll-maximum-likelihood-with-vae-approximate-elbo-lvlb">4.2.4 The loss function $- \log p_\theta(\mathbf{x}<em>0)$ (NLL-Maximum Likelihood) with VAE Approximate ELBO =$L</em>{VLB}$</h3>

\[\begin{aligned}
- \log p_\theta(\mathbf{x}_0) 
&amp;\leq - \log p_\theta(\mathbf{x}_0) + D_\text{KL}(q(\mathbf{x}_{1:T}\vert\mathbf{x}_0) \| p_\theta(\mathbf{x}_{1:T}\vert\mathbf{x}_0) ) \\
		 &amp;\textcolor{blue}{\text{; Data = x0 and we have ELBO}  =  \log p(D) - D_{KL}( q(z)|p(z|D) ) =  \int_{}^{}{q(z)\log\left( \frac{p(z,D)}{q(z)} \right)dz} = - KL(q(z)|p(z,x))}\\
&amp;= -\log p_\theta(\mathbf{x}_0) + \mathbb{E}_{\mathbf{x}_{1:T}\sim q(\mathbf{x}_{1:T} \vert \mathbf{x}_0)} \Big[ \log\frac{q(\mathbf{x}_{1:T}\vert\mathbf{x}_0)}{p_\theta(\mathbf{x}_{0:T}) / p_\theta(\mathbf{x}_0)} \Big] \\ 
         &amp;\textcolor{blue}{\text{;we have } p_\theta(\mathbf{x}_{0:T}) =p(\mathbf{x_0})p(\mathbf{x_{1:T}}|\mathbf{x_0}) }\\
         &amp;\textcolor{blue}{\text{;we have } D_{K L}(q \mid p)=\int q(x) \log \left(\frac{q(x)}{p(x)}\right) d x = E(\log (\frac{q(x)}{p(x)}) }\\
     
&amp;= -\log p_\theta(\mathbf{x}_0) + \mathbb{E}_q \Big[ \log\frac{q(\mathbf{x}_{1:T}\vert\mathbf{x}_0)}{p_\theta(\mathbf{x}_{0:T})} + \log p_\theta(\mathbf{x}_0) \Big] \\
&amp;= \mathbb{E}_q \Big[ \log \frac{q(\mathbf{x}_{1:T}\vert\mathbf{x}_0)}{p_\theta(\mathbf{x}_{0:T})} \Big] \\
\text{Let }L_\text{VLB} 
&amp;= \mathbb{E}_{q(\mathbf{x}_{0:T})} \Big[ \log \frac{q(\mathbf{x}_{1:T}\vert\mathbf{x}_0)}{p_\theta(\mathbf{x}_{0:T})} \Big] \geq - \mathbb{E}_{q(\mathbf{x}_0)} \log p_\theta(\mathbf{x}_0) \\
		&amp;\textcolor{blue}{\text{; here we have } \mathbb{E}_{q(\mathbf{x}_0)} \log p_\theta(\mathbf{x}_0) \leq \mathbb{E}_{q(\mathbf{x}_0)} \mathbb{E}_q \Big[ \log \frac{q(\mathbf{x}_{1:T}\vert\mathbf{x}_0)}{p_\theta(\mathbf{x}_{0:T})} \Big] }\\
\end{aligned}\]

<p>It is also straightforward to get the same result using Jensen’s inequality. Say we want to minimize the cross entropy as the learning objective,
\(\begin{aligned}
L_\text{CE}
&amp;= - \mathbb{E}_{q(\mathbf{x}_0)} \log p_\theta(\mathbf{x}_0) \\
&amp;= - \mathbb{E}_{q(\mathbf{x}_0)} \log \Big( \int p_\theta(\mathbf{x}_{0:T}) d\mathbf{x}_{1:T} \Big) \\
&amp;= - \mathbb{E}_{q(\mathbf{x}_0)} \log \Big( \int q(\mathbf{x}_{1:T} \vert \mathbf{x}_0) \frac{p_\theta(\mathbf{x}_{0:T})}{q(\mathbf{x}_{1:T} \vert \mathbf{x}_{0})} d\mathbf{x}_{1:T} \Big) \\
&amp;= - \mathbb{E}_{q(\mathbf{x}_0)} \log \Big( \mathbb{E}_{q(\mathbf{x}_{1:T} \vert \mathbf{x}_0)} \frac{p_\theta(\mathbf{x}_{0:T})}{q(\mathbf{x}_{1:T} \vert \mathbf{x}_{0})} \Big) \\
&amp;\leq - \mathbb{E}_{q(\mathbf{x}_{0:T})} \log \frac{p_\theta(\mathbf{x}_{0:T})}{q(\mathbf{x}_{1:T} \vert \mathbf{x}_{0})} \\
&amp; \textcolor{blue}{\text{; here we have } \quad-\log (E[x]) \leq E[-\log x]}\\
&amp;= \mathbb{E}_{q(\mathbf{x}_{0:T})}\Big[\log \frac{q(\mathbf{x}_{1:T} \vert \mathbf{x}_{0})}{p_\theta(\mathbf{x}_{0:T})} \Big] = L_\text{VLB}
\end{aligned}\)
To convert each term in the equation to be analytically computable, the objective can be further rewritten to be a combination of several KL-divergence and entropy terms (See the detailed step-by-step process in Appendix B in <a href="https://arxiv.org/abs/1503.03585">Sohl-Dickstein et al., 2015</a>):
\(\begin{aligned}
L_\text{VLB} 
&amp;= \mathbb{E}_{q(\mathbf{x}_{0:T})} \Big[ \log\frac{q(\mathbf{x}_{1:T}\vert\mathbf{x}_0)}{p_\theta(\mathbf{x}_{0:T})} \Big] \\
&amp;= \mathbb{E}_q \Big[ \log\frac{\prod_{t=1}^T q(\mathbf{x}_t\vert\mathbf{x}_{t-1})}{ p_\theta(\mathbf{x}_T) \prod_{t=1}^T p_\theta(\mathbf{x}_{t-1} \vert\mathbf{x}_t) } \Big] \\
&amp;= \mathbb{E}_q \Big[ -\log p_\theta(\mathbf{x}_T) + \sum_{t=1}^T \log \frac{q(\mathbf{x}_t\vert\mathbf{x}_{t-1})}{p_\theta(\mathbf{x}_{t-1} \vert\mathbf{x}_t)} \Big] \\
&amp;= \mathbb{E}_q \Big[ -\log p_\theta(\mathbf{x}_T) + \sum_{t=2}^T \log \frac{q(\mathbf{x}_t\vert\mathbf{x}_{t-1})}{p_\theta(\mathbf{x}_{t-1} \vert\mathbf{x}_t)} + \log\frac{q(\mathbf{x}_1 \vert \mathbf{x}_0)}{p_\theta(\mathbf{x}_0 \vert \mathbf{x}_1)} \Big] \\
&amp;= \mathbb{E}_q \Big[ -\log p_\theta(\mathbf{x}_T) + \sum_{t=2}^T \log \Big( \frac{q(\mathbf{x}_{t-1} \vert \mathbf{x}_t, \mathbf{x}_0)}{p_\theta(\mathbf{x}_{t-1} \vert\mathbf{x}_t)}\cdot \frac{q(\mathbf{x}_t \vert \mathbf{x}_0)}{q(\mathbf{x}_{t-1}\vert\mathbf{x}_0)} \Big) + \log \frac{q(\mathbf{x}_1 \vert \mathbf{x}_0)}{p_\theta(\mathbf{x}_0 \vert \mathbf{x}_1)} \Big] \\
&amp;= \mathbb{E}_q \Big[ -\log p_\theta(\mathbf{x}_T) + \sum_{t=2}^T \log \frac{q(\mathbf{x}_{t-1} \vert \mathbf{x}_t, \mathbf{x}_0)}{p_\theta(\mathbf{x}_{t-1} \vert\mathbf{x}_t)} + \sum_{t=2}^T \log \frac{q(\mathbf{x}_t \vert \mathbf{x}_0)}{q(\mathbf{x}_{t-1} \vert \mathbf{x}_0)} + \log\frac{q(\mathbf{x}_1 \vert \mathbf{x}_0)}{p_\theta(\mathbf{x}_0 \vert \mathbf{x}_1)} \Big] \\
&amp;= \mathbb{E}_q \Big[ -\log p_\theta(\mathbf{x}_T) + \sum_{t=2}^T \log \frac{q(\mathbf{x}_{t-1} \vert \mathbf{x}_t, \mathbf{x}_0)}{p_\theta(\mathbf{x}_{t-1} \vert\mathbf{x}_t)} + \log\frac{q(\mathbf{x}_T \vert \mathbf{x}_0)}{q(\mathbf{x}_1 \vert \mathbf{x}_0)} + \log \frac{q(\mathbf{x}_1 \vert \mathbf{x}_0)}{p_\theta(\mathbf{x}_0 \vert \mathbf{x}_1)} \Big]\\
&amp;= \mathbb{E}_q \Big[ \log\frac{q(\mathbf{x}_T \vert \mathbf{x}_0)}{p_\theta(\mathbf{x}_T)} + \sum_{t=2}^T \log \frac{q(\mathbf{x}_{t-1} \vert \mathbf{x}_t, \mathbf{x}_0)}{p_\theta(\mathbf{x}_{t-1} \vert\mathbf{x}_t)} - \log p_\theta(\mathbf{x}_0 \vert \mathbf{x}_1) \Big] \\
&amp;= \mathbb{E}_q [\underbrace{D_\text{KL}(q(\mathbf{x}_T \vert \mathbf{x}_0) \parallel p_\theta(\mathbf{x}_T))}_{L_T} + \sum_{t=2}^T \underbrace{D_\text{KL}(q(\mathbf{x}_{t-1} \vert \mathbf{x}_t, \mathbf{x}_0) \parallel p_\theta(\mathbf{x}_{t-1} \vert\mathbf{x}_t))}_{L_{t-1}} \underbrace{- \log p_\theta(\mathbf{x}_0 \vert \mathbf{x}_1)}_{L_0} ]
\end{aligned}\)</p>

<p>其他人对采用$X_0$的解释</p>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/image-20230605215923369.png" alt="image-20230605215923369" style="zoom:50%;" /></p>

<p>Let’s label each component in the variational lower bound loss separately:
\(\begin{aligned}
L_\text{VLB} &amp;= L_T + L_{T-1} + \dots + L_0 \\
\text{where } L_T &amp;= D_\text{KL}(q(\mathbf{x}_T \vert \mathbf{x}_0) \parallel p_\theta(\mathbf{x}_T)) \\
L_t &amp;= D_\text{KL}(q(\mathbf{x}_t \vert \mathbf{x}_{t+1}, \mathbf{x}_0) \parallel p_\theta(\mathbf{x}_t \vert\mathbf{x}_{t+1})) \text{ for }1 \leq t \leq T-1 \\
L_0 &amp;= - \log p_\theta(\mathbf{x}_0 \vert \mathbf{x}_1)
\end{aligned}\)</p>
<ul>
  <li>
    <p>Every KL term in $L_\text{VLB}$ (except for $L_0$) compares two Gaussian distributions and therefore they can be computed in <a href="https://en.wikipedia.org/wiki/Kullback–Leibler_divergence#Multivariate_normal_distributions">closed form</a>.</p>
  </li>
  <li>
    <p><strong>$L_T$ is constant and can be ignored during training because $q$ has no learnable parameters and $\mathbf{x}_T$ is a Gaussian noise.</strong></p>
  </li>
  <li>
    <p><strong><a href="https://arxiv.org/abs/2006.11239">Ho et al. 2020</a> models $L_0$ using a separate discrete decoder derived from $\mathcal{N}(\mathbf{x}<em>0; \boldsymbol{\mu}</em>\theta(\mathbf{x}<em>1, 1), \boldsymbol{\Sigma}</em>\theta(\mathbf{x}_1, 1))$.</strong></p>
  </li>
</ul>

<h3 id="425-parameterization-of-l_t-for-training-loss">4.2.5 Parameterization of $L_t$ for Training Loss</h3>

<p>已经得到 $q(\mathbf{x}<em>{t-1} \vert \mathbf{x}_t, \mathbf{x}_0) = \mathcal{N}(\mathbf{x}</em>{t-1}; \color{blue}{\tilde{\boldsymbol{\mu}}}(\mathbf{x}_t, \mathbf{x}_0), \color{red}{\tilde{\beta}_t} \mathbf{I})$ 
其中
\(\begin{aligned}
\tilde{\beta}_t 
&amp;= \color{green}{\frac{1 - \bar{\alpha}_{t-1}}{1 - \bar{\alpha}_t} \cdot \beta_t} \\
\tilde{\boldsymbol{\mu}}(\mathbf{x}_t, \mathbf{x}_0) &amp;= \color{cyan}{\frac{1}{\sqrt{\alpha_t}} \Big( \mathbf{x}_t - \frac{1 - \alpha_t}{\sqrt{1 - \bar{\alpha}_t}} \boldsymbol{\epsilon}_t \Big)}
\end{aligned}\)
The loss term $L_t$ is parameterized to minimize the difference from $\tilde{\boldsymbol{\mu}}$ :
\(\begin{aligned}
L_t 
&amp;= \mathbb{E}_{\mathbf{x}_0, \boldsymbol{\epsilon}} \Big[\frac{1}{2 \| \boldsymbol{\Sigma}_\theta(\mathbf{x}_t, t) \|^2_2} \| \color{blue}{\tilde{\boldsymbol{\mu}}_t(\mathbf{x}_t, \mathbf{x}_0)} - \color{green}{\boldsymbol{\mu}_\theta(\mathbf{x}_t, t)} \|^2 \Big] \\
&amp;= \mathbb{E}_{\mathbf{x}_0, \boldsymbol{\epsilon}} \Big[\frac{1}{2  \|\boldsymbol{\Sigma}_\theta \|^2_2} \| \color{blue}{\frac{1}{\sqrt{\alpha_t}} \Big( \mathbf{x}_t - \frac{1 - \alpha_t}{\sqrt{1 - \bar{\alpha}_t}} \boldsymbol{\epsilon}_t \Big)} - \color{green}{\frac{1}{\sqrt{\alpha_t}} \Big( \mathbf{x}_t - \frac{1 - \alpha_t}{\sqrt{1 - \bar{\alpha}_t}} \boldsymbol{\boldsymbol{\epsilon}}_\theta(\mathbf{x}_t, t) \Big)} \|^2 \Big] \\
&amp;= \mathbb{E}_{\mathbf{x}_0, \boldsymbol{\epsilon}} \Big[\frac{ (1 - \alpha_t)^2 }{2 \alpha_t (1 - \bar{\alpha}_t) \| \boldsymbol{\Sigma}_\theta \|^2_2} \|\boldsymbol{\epsilon}_t - \boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t)\|^2 \Big] \\
&amp;= \mathbb{E}_{\mathbf{x}_0, \boldsymbol{\epsilon}} \Big[\frac{ (1 - \alpha_t)^2 }{2 \alpha_t (1 - \bar{\alpha}_t) \| \boldsymbol{\Sigma}_\theta \|^2_2} \|\boldsymbol{\epsilon}_t - \boldsymbol{\epsilon}_\theta(\sqrt{\bar{\alpha}_t}\mathbf{x}_0 + \sqrt{1 - \bar{\alpha}_t}\boldsymbol{\epsilon}_t, t)\|^2 \Big] 
\end{aligned}\)</p>

<p>in another form 
\(\begin{aligned}
&amp; L_t=\frac{1}{2 \sigma_t^2}\left\|\tilde{\mu}_t\left(X_t, X_0\right)-\mu_\theta\left(X_t, t\right)\right\|^2 \\
= &amp; \frac{1}{2 \sigma_t^2} \| \frac{1}{\sqrt{d_t}}\left(X_t-\frac{\beta_t}{\sqrt{1-\sigma_t}} \varepsilon\right)-\frac{1}{\sqrt{\sigma_t}}\left(X_t-\frac{\beta_t}{\sqrt{1-\alpha_t}} \varepsilon_\theta\left(X_t, t\right) \|^2\right. \\
= &amp; \frac{\beta_t^2}{2 \sigma_t^2 \alpha_t\left(1-\alpha_t\right)}\left\|\varepsilon-\varepsilon_\theta\left(X_t, t\right)\right\|^2
\end{aligned}\)</p>

<h3 id="426-models-l_0">4.2.6 models $L_0$</h3>

<p>在逆扩散过程中，马尔科夫过程表示为由连续条件高斯分布下的累积变换组成。有了总体的优化策略，还要看每个像素的计算方式，在逆扩散过程结束时，我们希望得到一张生成好的图像，因此需要设计一种方法，<strong>使得图像上每个像素值都满足离散的对数似然</strong>。 为了达到这个目的，将逆扩散过程中的最后从 x1 到 x0 的转换设置为独立的离散计算方式。 即在最后一个转换过程在给定  x1 下得到图像 x0 满足对数似然，假设像素与像素之间是相互独立的：
\(p_\theta\left(x_0 \mid x_1\right)=\prod_{i=1}^D p_\theta\left(x_0^i \mid x_1^i\right)\)
 D 是输入数据的维数，上标 i 表示图像中的一个坐标位置。现在的目标是确定给定像素的值可能性有多大，也就是想要知道对应时间步 t=1 下噪声图像 x 中相应像素值的分布
\(\mathcal{N}\left(x ; \mu_\theta^i\left(x_1, 1\right), \sigma_1^2\right)\)
其中 t = 1 的像素分布来自多元高斯分布，其对角协方差矩阵允许我们将分布拆分为单变量高斯的乘积：
\(\mathcal{N}\left(x ; \mu_\theta\left(x_1, 1\right), \sigma_1^2 \mathbb{I}\right)=\prod_{i=1}^D \mathcal{N}\left(x ; \mu_\theta^i\left(x_1, 1\right), \sigma_1^2\right)\)
现在假设图像已经从0-255的数值之间，经过归一化在[-1,1]的范围内。在 t=0 时给定每个像素的像素值，最后一个时间步 t=1 的转换概率分布 $p_θ(x_0∣x_1)$ 的值就是每个像素值的乘积。简而言之，这个过程由等式简洁 (18) 地表示：
\(\begin{aligned}
&amp; p_\theta\left(x_0 \mid x_1\right)=\prod_{i=1}^D p_\theta\left(x_0^i \mid x_1^i\right) \\
&amp; =\prod_{i=1}^D \int_{\delta_{-}\left(x_0^i\right)}^{\delta_{+}\left(x_i^i\right)} \mathcal{N}\left(x ; \mu_\theta^i\left(x_1, 1\right), \sigma_1^2\right) d x
\end{aligned}\)
其中约束有:
\(\delta_{-}(x)= \begin{cases}-\infty &amp; x=-1 \\ x-\frac{1}{255} &amp; x&gt;-1\end{cases}\)
和:
\(\delta_{+}(x)= \begin{cases}\infty &amp; x=1 \\ x+\frac{1}{255} &amp; x&lt;1\end{cases}\)</p>

<h3 id="427-loss-simplification">4.2.7 Loss Simplification</h3>

<p>Empirically, <a href="https://arxiv.org/abs/2006.11239">Ho et al. (2020)</a> found that training the diffusion model works better with a simplified objective that ignores the weighting term:
\(\begin{aligned}
L_t^\text{simple}
&amp;= \mathbb{E}_{t \sim [1, T], \mathbf{x}_0, \boldsymbol{\epsilon}_t} \Big[\|\boldsymbol{\epsilon}_t - \boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t)\|^2 \Big] \\
&amp;= \mathbb{E}_{t \sim [1, T], \mathbf{x}_0, \boldsymbol{\epsilon}_t} \Big[\|\boldsymbol{\epsilon}_t - \boldsymbol{\epsilon}_\theta(\sqrt{\bar{\alpha}_t}\mathbf{x}_0 + \sqrt{1 - \bar{\alpha}_t}\boldsymbol{\epsilon}_t, t)\|^2 \Big]
\end{aligned}\)
The final simple objective is:
\(L_\text{simple} = L_t^\text{simple} + C\)
where $C$ is a constant not depending on $\theta$.</p>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/DDPM-algo.png" alt="img" style="zoom:50%;" /></p>

<p>Fig. 4. The training and sampling algorithms in DDPM(Image source: <a href="https://arxiv.org/abs/2006.11239">Ho et al. 2020</a>)</p>

<h2 id="43-reserving-approximate-overview">4.3 Reserving Approximate (overview)</h2>

<p>VAE:
\(\begin{aligned}
L_{\mathrm{VAE}}(\theta, \phi) &amp; =-\log p_\theta(\mathbf{x})+D_{\mathrm{KL}}\left(q_\phi(\mathbf{z} \mid \mathbf{x}) \| p_\theta(\mathbf{z} \mid \mathbf{x})\right) \\
&amp; =-\mathbb{E}_{\mathbf{z} \sim q_\phi(\mathbf{z} \mid \mathbf{x})} \log p_\theta(\mathbf{x} \mid \mathbf{z})+D_{\mathrm{KL}}\left(q_\phi(\mathbf{z} \mid \mathbf{x}) \| p_\theta(\mathbf{z})\right) \\
\theta^*, \phi^* &amp; =\arg \underset{\theta, \phi}{\min } L_{\mathrm{VAE}} \\
-L_{\mathrm{VAE}} &amp; =\log p_\theta(\mathbf{x})-D_{\mathrm{KL}}\left(q_\phi(\mathbf{z} \mid \mathbf{x}) \| p_\theta(\mathbf{z} \mid \mathbf{x})\right) \leq \log p_\theta(\mathbf{x})
\end{aligned}\)
GAN:
\(\begin{gathered}
\min _G \max _D L(D, G)=\mathbb{E}_{x \sim p_r(x)}[\log D(x)]+\mathbb{E}_{z \sim p_z(z)}[\log (1-D(G(z)))] \\
=\mathbb{E}_{x \sim p_r(x)}[\log D(x)]+\mathbb{E}_{x \sim p_g(x)}[\log (1-D(x)] \\
L\left(G, D^*\right)=2 D_{J S}\left(p_r \| p_g\right)-2 \log 2
\end{gathered}\)
Turns out that for small enough forward steps, i.e.
\(\left\{\beta_t \in(0,1)\right\}_{t=1}^T\)
the reverse process step $q\left(\mathbf{x}_{t-1} \mid \mathbf{x}_t\right)$ can be estimate is a Gaussian distribution too (take a course of stochastic differential equations if you want learn more)! 
Therefore, we can parametrize the learned reverse process as
\(p_\theta\left(\mathbf{x}_{t-1} \mid \mathbf{x}_t\right)=\mathcal{N}\left(\mathbf{x}_{t-1} ; \boldsymbol{\mu}_\theta\left(\mathbf{x}_t, t\right), \mathbf{\Sigma}_\theta\left(\mathbf{x}_t, t\right)\right)\)
such that
\(p_\theta\left(\mathbf{x}_{0: T}\right)=p\left(\mathbf{x}_T\right) \prod_{t=1}^T p_\theta\left(\mathbf{x}_{t-1} \mid \mathbf{x}_t\right)\)</p>

<h3 id="431-a-preliminary-objective">4.3.1 A Preliminary objective</h3>

<p>The VAE (ELBO) loss is a bound on the true log likelihood (also called the variational lower bound)
\(-L_{\mathrm{VAE}}=\log p_\theta(\mathbf{x})-D_{\mathrm{KL}}\left(q_\phi(\mathbf{z} \mid \mathbf{x}) \| p_\theta(\mathbf{z} \mid \mathbf{x})\right) \leq \log p_\theta(\mathbf{x})\)
Apply the same trick to diffusion:
\(-\log p_\theta\left(\mathbf{x}_0\right) \leq \mathbb{E}_{q\left(\mathbf{x}_{0: T}\right)}\left[-\log \frac{p_\theta\left(\mathbf{x}_{0: T}\right)}{q\left(\mathbf{x}_{1: T} \mid \mathbf{x}_0\right)}\right]=L_{V L B}\)
Expanding out,
\(\begin{aligned}
L_{\mathrm{VLB}} &amp; =L_T+L_{T-1}+\cdots+L_0 \\
\text { where } L_T &amp; =D_{\mathrm{KL}}\left(q\left(\mathbf{x}_T \mid \mathbf{x}_0\right) \| p_\theta\left(\mathbf{x}_T\right)\right) \\
L_t &amp; =D_{\mathrm{KL}}\left(q\left(\mathbf{x}_t \mid \mathbf{x}_{t+1}, \mathbf{x}_0\right) \| p_\theta\left(\mathbf{x}_t \mid \mathbf{x}_{t+1}\right)\right) \text { for } 1 \leq t \leq T-1 \\
L_0 &amp; =-\log p_\theta\left(\mathbf{x}_0 \mid \mathbf{x}_1\right)
\end{aligned}\)</p>

\[\begin{aligned}
L_{\mathrm{VLB}} &amp; =L_T+L_{T-1}+\cdots+L_0 \\
\text { where } L_T &amp; =D_{\mathrm{KL}}\left(q\left(\mathbf{x}_T \mid \mathbf{x}_0\right) \| p_\theta\left(\mathbf{x}_T\right)\right) \\
L_t &amp; =D_{\mathrm{KL}}\left(q\left(\mathbf{x}_t \mid \mathbf{x}_{t+1}, \mathbf{x}_0\right) \| p_\theta\left(\mathbf{x}_t \mid \mathbf{x}_{t+1}\right)\right) \text { for } 1 \leq t \leq T-1 \\
L_0 &amp; =-\log p_\theta\left(\mathbf{x}_0 \mid \mathbf{x}_1\right)
\end{aligned}\]

<h3 id="432-a-simplified-object"><strong>4.3.2 A simplified object</strong></h3>

<p>The reverse step conditioned on x_0 is a Gaussian:
\(\begin{aligned}
q\left(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0\right) &amp; =\mathcal{N}\left(\mathbf{x}_{t-1} ; \tilde{\boldsymbol{\mu}}_t\left(\mathbf{x}_t, \mathbf{x}_0\right), \tilde{\beta}_t \mathbf{I}\right) \\
\text { where } \quad \tilde{\boldsymbol{\mu}}_t\left(\mathbf{x}_t, \mathbf{x}_0\right) &amp; :=\frac{\sqrt{\bar{\alpha}_{t-1}} \beta_t}{1-\bar{\alpha}_t} \mathbf{x}_0+\frac{\sqrt{\alpha_t}\left(1-\bar{\alpha}_{t-1}\right)}{1-\bar{\alpha}_t} \mathbf{x}_t \quad \text { and } \quad \tilde{\beta}_t:=\frac{1-\bar{\alpha}_{t-1}}{1-\bar{\alpha}_t} \beta_t
\end{aligned}\)
After doing some algebra, <strong>each loss term can be approximated by</strong>
\(\begin{aligned}
L_{t-1} &amp; =\mathbb{E}_{\mathbf{x}_0, \epsilon}\left[\frac{1}{2\left\|\mathbf{\Sigma}_\theta\right\|_2^2}\left\|\tilde{\mu}\left(\mathbf{x}_t, \mathbf{x}_0\right)-\mu_\theta\left(\mathbf{x}_{t,}, t\right)\right\|_2^2\right] \\
&amp; =\mathbb{E}_{\mathbf{x}_0, \epsilon}\left[\frac{1}{2\left\|\mathbf{\Sigma}_\theta\right\|_2^2}\left\|\frac{1}{\sqrt{\alpha_t}}\left(\mathbf{x}_t-\frac{\beta_t}{\sqrt{1-\bar{\alpha}_t}} \epsilon\right)-\mu_\theta\left(\mathbf{x}_{t,}, t\right)\right\|_2^2\right]
\end{aligned}\)
<strong>Instead of predicting the mu, Ho et al. say that we should predict epsilon instead!</strong>
\(\tilde{\boldsymbol{\mu}}_t\left(\mathbf{x}_t, \mathbf{x}_0\right)=\frac{1}{\sqrt{\alpha_t}}\left(\mathbf{x}_t-\frac{\beta_t}{\sqrt{1-\bar{\alpha}_t}} \boldsymbol{\epsilon}\right) \Longrightarrow \boldsymbol{\mu}_\theta\left(\mathbf{x}_t, t\right)=\frac{1}{\sqrt{\alpha_t}}\left(\mathbf{x}_t-\frac{\beta_t}{\sqrt{1-\bar{\alpha}_t}} \boldsymbol{\epsilon}_\theta\left(\mathbf{x}_t, t\right)\right)\)
Thus, our loss becomes
\(\begin{aligned}
L_{t-1} &amp; =\mathbb{E}_{\mathbf{x}_0, \epsilon}\left[\frac{1}{2\left\|\boldsymbol{\Sigma}_\theta\right\|_2^2}\left\|\frac{1}{\sqrt{\alpha_t}}\left(\mathbf{x}_t-\frac{\beta_t}{\sqrt{1-\bar{\alpha}_t}} \epsilon\right)-\frac{1}{\sqrt{\alpha}_t}\left(\mathbf{x}_t-\frac{\beta_t}{\sqrt{1-\bar{\alpha}_t}} \epsilon_\theta\left(\mathbf{x}_t, t\right)\right)\right\|_2^2\right] \\
&amp; =\mathbb{E}_{\mathbf{x}_0, \epsilon}\left[\frac{\beta_t^2}{2 \alpha_t\left(1-\bar{\alpha}_t\right)\left\|\boldsymbol{\Sigma}_\theta\right\|_2^2}\left\|\epsilon-\epsilon_\theta\left(\mathbf{x}_t, t\right)\right\|_2^2\right] \\
&amp; =\mathbb{E}_{\mathbf{x}_0, \epsilon}\left[\frac{\beta_t^2}{2 \alpha_t\left(1-\bar{\alpha}_t\right)\left\|\boldsymbol{\Sigma}_\theta\right\|_2^2}\left\|\epsilon-\epsilon_\theta\left(\sqrt{\bar{\alpha}_t} \mathbf{x}_0+\sqrt{1-\bar{\alpha}_t} \epsilon, t\right)\right\|_2^2\right]
\end{aligned}\)
The authors of DDPM say that it’s fine to drop all that baggage in the front and instead just use
\(L_{t-1}=\mathbb{E}_{\mathbf{x}_0, \epsilon}\left[\left\|\epsilon-\epsilon_\theta\left(\sqrt{\bar{\alpha}_t} \mathbf{x}_0+\sqrt{1-\bar{\alpha}_t} \epsilon, t\right)\right\|_2^2\right]\)
Note that this is not a variational lower bound on the log-likelihood anymore: in fact, you can view it as a reweighted version of ELBO that emphasizes reconstruction quality!</p>

<h2 id="44-training">4.4 Training</h2>

\[\begin{aligned}
&amp; \hline \text { Algorithm } 1 \text { Training } \\
&amp; \hline \text { 1: repeat } \\
&amp; \text { 2: } \quad \mathbf{x}_0 \sim q\left(\mathbf{x}_0\right) \\
&amp; \text { 3: } \quad t \sim \text { Uniform }(\{1, \ldots, T\}) \\
&amp; \text { 4: } \quad \boldsymbol{\epsilon} \sim \mathcal{N}(\mathbf{0}, \mathbf{I}) \\
&amp; \text { 5: } \quad \text { Take gradient descent step on } \\
&amp; \quad \nabla_\theta\left\|\boldsymbol{\epsilon}-\boldsymbol{\epsilon}_\theta\left(\sqrt{\bar{\alpha}_t} \mathbf{x}_0+\sqrt{1-\bar{\alpha}_t} \boldsymbol{\epsilon}, t\right)\right\|^2 \\
&amp; \text { 6: until converged }
\end{aligned}\]

<p><strong>下面这段对训练过程的数据来源使用解释得比较清楚：</strong></p>

<p>由上式可以看出，训练目标函数 $L_t$ 项表达的意图是：在给定 $x_t$ 时，若要最终获得某个 $x_0$ ，**条 件高斯分布的均值应为 $\tilde{\mu}<em>t\left(x_t, x_0\right)$ (可理解为学习的标签)**，因此，模型在给定 $x_t$ 时，应当能 尽可能输出 $\mu</em>\theta\left(x_t, t\right)$ ，从而能提升 $x_0$ 的似然函数值 $\log p_\theta\left(x_0\right)$ 。
根据展开式 $\tilde{\mu}<em>t\left(x_t, x_0\right)=\frac{1}{\sqrt{\alpha_t}}\left(x_t-\frac{\beta_t}{\sqrt{1-\bar{\alpha}_t}} z_t\right)$ 可知，在给定 $x_t$ 时，若模型能够预测 $z_t$ (也就是$\epsilon _t$)，就 能正确计算出均值。自然地， $\mu</em>\theta\left(x_t, t\right)$ 的计算方式与 $\tilde{\mu}<em>t\left(x_t, x_0\right)$ 相同而仅将 $z_t$ 参数化为神经 网络 $z</em>\theta\left(x_t, t\right)$ ，即
\(\mu_\theta\left(x_t, t\right)=\frac{1}{\sqrt{\alpha_t}}\left(x_t-\frac{\beta_t}{\sqrt{1-\bar{\alpha}_t}} z_\theta\left(x_t, t\right)\right)\)
将 $\tilde{\mu}<em>t\left(x_t, x_0\right)$ 和 $\mu</em>\theta\left(x_t, t\right)$ 的表达式替换， $L_t$ 项进一步写为
\(L_t=\mathbb{E}_{x_0, z} \frac{\beta_t^2\left\|z_t-z_\theta\left(x_t, t\right)\right\|_2^2}{2 \sigma_t^2 \alpha_t\left(1-\bar{\alpha}_t\right)}\)</p>
<font color="red">**由于 $z_t \sim N(0, I)$ ，实际训练时， $z_t$ 可直接采样获得**</font>
<p>，<strong>而 $z_\theta\left(x_t, t\right)$ 的输入 $x_t$ 可在给定最终 生成样本 $x_0$ 的条件下给出</strong>， $x_t=\sqrt{\bar{\alpha}<em>t} x_0+\sqrt{1-\bar{\alpha}_t} z_t$ ，<strong>即每个 $x_t$ 均对应于一个 $z_t$</strong> 。由 上式也可以看出，神经网络 $\theta$ 本质上也是在学习“降噪”幅度，即为了最后获得给定的 $x_0$ ，神经 网络应该学习逐层降噪，即应该在 $t$ 时间步对 $x_t$ 进行 $z</em>\theta\left(x_t, t\right)$ 幅度的橾声降低，
<strong>当完成训练后，在推断过程中生成样本时，当生成 $x_t$ 时，首先计算 $p\left(X_{t-1} \mid x_t\right)$ 对应高斯分布的 均值 $z_\theta\left(x_t, t\right)$ ，然后在 $N\left(z_\theta\left(x_t, t\right), \sigma_t^2\right)$ 中随机采样即可得到 $x_{t-1}$ 。</strong></p>

<blockquote>
  <h3 id="algorithm1training">Algorithm1：Training</h3>

  <p>从数据中抽取一个样本，</p>

  <p>从1-T中随机选取一个时间t</p>

  <p>将 $x_0$ 和t传给GaussionDiffusion，GaussionDiffusion采样一个随机噪声，加到 $x_0$ ，形成$x_t$  ，然后将$x_t$  和t放入Unet，Unet根据t生成正弦位置编码和 $x_t$  结合，Unet预测加的这个噪声，并返回噪声，GaussionDiffusion计算该噪声和随机噪声的损失</p>

  <p>将神经网络Unet预测的噪声与之前GaussionDiffusion采样的随机噪声求L2损失，计算梯度，更新权重。</p>

  <p>重复以上步骤，直到网络Unet训练完成。</p>

  <p><img src="/assets/BERTGPTDiffusion%20Research.assets/v2-33081e7d50e65e1ed4e5d1f91e67728b_r.jpg" alt="img" /></p>

  <h3 id="algorithm2sampling">Algorithm2：Sampling</h3>

  <ul>
    <li>
      <ul>
        <li>从标准正态分布采样出 $x_T$</li>
      </ul>
    </li>
    <li>
      <ul>
        <li>从 $T, T-1, \ldots, 2,1$ 依次重复以下步骤:</li>
      </ul>
    </li>
    <li>
      <ul>
        <li>从标准正态分布采样 $z$ ，为重参数化做准备</li>
      </ul>
    </li>
    <li>
      <ul>
        <li>根据模型求出 $\epsilon_\theta$ ，结合 $x_t$ 和采样得到z利用重参数化技巧，得到 $x_{t-1}$</li>
      </ul>
    </li>
    <li>
      <ul>
        <li>循环结束后返回 $x_0$
采样步骤中每个模块的交互如下图:</li>
      </ul>
    </li>
  </ul>

  <p><img src="/assets/BERTGPTDiffusion%20Research.assets/v2-3673b2795344783503286c32f05fc7b6_r.jpg" alt="img" /></p>
</blockquote>

<ul>
  <li>
    <h4 id="model-architecture-used-in-ddpms">Model Architecture Used In DDPMs</h4>
  </li>
</ul>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/denoising-diffusion-probabilistic-models_UNet_model_architecture.png" alt="img" /></p>

<p><strong>The architecture comprises 5 components:</strong></p>

<ol>
  <li>Encoder blocks</li>
  <li>Bottleneck blocks</li>
  <li>Decoder blocks</li>
  <li><a href="https://learnopencv.com/attention-mechanism-in-transformer-neural-networks/">Self attention modules</a></li>
  <li>Sinusoidal time embeddings</li>
</ol>

<h2 id="45-parameterization-of-reverse-process-variance-boldsymbolsigma_theta">4.5 Parameterization of reverse process variance $\boldsymbol{\Sigma}_\theta$</h2>

<p>Ho et al. (2020) chose to fix $\beta_t$ as constants instead of making them learnable and set $\boldsymbol{\Sigma}<em>\theta\left(\mathbf{x}_t, t\right)=\sigma_t^2 \mathbf{I}$, where $\sigma_t$ is not learned but set to $\beta_t$ or $\tilde{\beta}_t=\frac{1-\bar{\alpha}</em>{t-1}}{1-\bar{\alpha} t} \cdot \beta_t$. Because they found that learning a diagonal variance $\boldsymbol{\Sigma}_{\boldsymbol{\theta}}$ leads to unstable training and poorer sample quality.</p>

<p><a href="https://arxiv.org/abs/2102.09672">Nichol &amp; Dhariwal (2021)</a> proposed to learn $\boldsymbol{\Sigma}_\theta(\mathbf{x}_t, t)$ as an interpolation between $\beta_t$ and $\tilde{\beta}_t$ by model predicting a mixing vector V :
\(\boldsymbol{\Sigma}_\theta(\mathbf{x}_t, t) = \exp(\mathbf{v} \log \beta_t + (1-\mathbf{v}) \log \tilde{\beta}_t)\)</p>

<h2 id="46-sampling-inference">4.6 Sampling (inference)</h2>

\[\begin{aligned}
&amp; \text { Algorithm } 2 \text { Sampling } \\
&amp; \text { 1: } \mathbf{x}_T \sim \mathcal{N}(\mathbf{0}, \mathbf{I}) \\
&amp; \text { 2: for } t=T, \ldots, 1 \text { do } \\
&amp; \text { 3: } \mathbf{z} \sim \mathcal{N}(\mathbf{0}, \mathbf{I}) \text { if } t&gt;1, \text { else } \mathbf{z}=\mathbf{0} \\
&amp; \text { 4: } \quad \mathbf{x}_{t-1}=\frac{1}{\sqrt{\alpha_t}}\left(\mathbf{x}_t-\frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}} \boldsymbol{\epsilon}_\theta\left(\mathbf{x}_t, t\right)\right)+\sigma_t \mathbf{z} \\

&amp;\text{; where we have } \mathbf{x}_{t-1} = \mathcal{N}(\mathbf{x}_{t-1}; \frac{1}{\sqrt{\alpha_t}} \Big( \mathbf{x}_t - \frac{1 - \alpha_t}{\sqrt{1 - \bar{\alpha}_t}} \boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t) \Big), \boldsymbol{\Sigma}_\theta(\mathbf{x}_t, t)) \\

&amp; \text { 5: end for } \\
&amp; \text { 6: return } \mathbf{x}_0
\end{aligned}\]

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/image-20230517124126420.png" alt="image-20230517124126420" style="zoom: 50%;" /></p>

<h2 id="47-speed-up-diffusion-model-sampling-ddim">4.7 Speed up Diffusion Model Sampling (DDIM)</h2>

<p>also refer to <a href="https://zhuanlan.zhihu.com/p/565698027">扩散模型之DDIM - 知乎 (zhihu.com)</a></p>

<h3 id="recall-ddpm">Recall DDPM</h3>

<p>It is very slow to generate a sample from DDPM by following the Markov chain of the reverse diffusion process, as T can be up to one or a few thousand steps. One data point from <a href="https://arxiv.org/abs/2010.02502">Song et al. 2020</a>: “For example, it takes around 20 hours to sample 50k images of size 32 × 32 from a DDPM, but less than a minute to do so from a GAN on an Nvidia 2080 Ti GPU.”</p>

<p>One simple way is to run a strided sampling schedule (<a href="https://arxiv.org/abs/2102.09672">Nichol &amp; Dhariwal, 2021</a>) by taking the sampling update every ⌈T/S⌉ steps to reduce the process from T to S steps. The new sampling schedule for generation is ${\tau_1, \dots, \tau_S}$ where $\tau_1 &lt; \tau_2 &lt; \dots &lt;\tau_S \in [1, T]$ and S&lt;T.</p>

<p>With DDIM, <strong>it is possible to train the diffusion model up to any arbitrary number of forward steps but only sample from a subset of steps in the generative process</strong>.</p>

<p>扩散过程的一个重要特性是可以直接用 $\mathbf{x}<em>0$ 来对任意的 $\mathbf{x}_t$ 进行采样:
$$
q(\mathbf{x}_t \vert \mathbf{x}</em>{t-1}) = \mathcal{N}(\mathbf{x}<em>t; \sqrt{1 - \beta_t} \mathbf{x}</em>{t-1}, \beta_t\mathbf{I}) \quad <br />
q(\mathbf{x}<em>{1:T} \vert \mathbf{x}_0) = \prod^T</em>{t=1} q(\mathbf{x}<em>t \vert \mathbf{x}</em>{t-1}) \</p>

<p>q\left(\mathbf{x}<em>t \mid \mathbf{x}_0\right)=\mathcal{N}\left(\mathbf{x}_t ; \sqrt{\alpha_t} \mathbf{x}_0,\left(1-\alpha_t\right) \mathbf{I}\right)
\(注意，在DDIM的论文中， $\alpha_t$ 其实是DDPM论文中的 $\bar{\alpha}_t$ ，那么DDPM论文中的前向过程 $\beta_t$ 就为:\)
\beta_t=\left(1-\frac{\alpha_t}{\alpha</em>{t-1}}\right)
\(而DDPM的反向过程也定义为一个马尔卡夫链:\)
p_\theta\left(\mathbf{x}<em>{0: T}\right)=p\left(\mathbf{x}_T\right) \prod</em>{t=1}^T p_\theta\left(\mathbf{x}<em>{t-1} \mid \mathbf{x}_t\right) \quad p</em>\theta\left(\mathbf{x}<em>{t-1} \mid \mathbf{x}_t\right)=\mathcal{N}\left(\mathbf{x}</em>{t-1} ; \boldsymbol{\mu}<em>\theta\left(\mathbf{x}_t, t\right), \mathbf{\Sigma}</em>\theta\left(\mathbf{x}<em>t, t\right)\right)
$$
这里用神经网络 $p</em>\theta\left(\mathbf{x}<em>{t-1} \mid \mathbf{x}_t\right)$ 来拟合真实的分布 $q\left(\mathbf{x}</em>{t-1} \mid \mathbf{x}_t\right)$ 。DDPM的前向过程和反向过程如下 所示:</p>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/v2-071e3c9962f3f12239a8b005940e4616_720w.webp" alt="img" /></p>

<p><strong>DDPM的目标是要拟合出一个$q\left(\mathbf{x}_{t-1} \mid \mathbf{x}_t\right)$</strong></p>

<ol>
  <li>我们近一步发现后验分布 $q\left(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0\right)$ 是一个可获取的高斯分布:</li>
</ol>

<p>\(q\left(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0\right)=\mathcal{N}\left(\mathbf{x}_{t-1} ; \tilde{\boldsymbol{\mu}}\left(\mathbf{x}_t, \mathbf{x}_0\right), \tilde{\beta}_t \mathbf{I}\right)\)
​		其中这个高斯分布的方差是定值，而均值是一个依赖 $\mathrm{x}_0$ 和 $\mathbf{x}_t$ 的组合函数:
\(\tilde{\boldsymbol{\mu}}_t\left(\mathbf{x}_t, \mathbf{x}_0\right)=\frac{\sqrt{\alpha_t}\left(1-\alpha_{t-1}\right)}{\sqrt{\alpha_{t-1}}\left(1-\alpha_t\right)} \mathbf{x}_t+\frac{\sqrt{\alpha_{t-1}} \beta_t}{1-\alpha_t} \mathbf{x}_0\)
​	2. 然后我们基于变分法得到如下的优化目标:
\(\begin{aligned}
&amp; L=\mathbb{E}_{q\left(\mathbf{x}_{1: T} \mid \mathbf{x}_0\right)}\left[\log \frac{q\left(\mathbf{x}_{1: T} \mid \mathbf{x}_0\right)}{p_\theta\left(\mathbf{x}_{0: T}\right)}\right] \\
&amp; =\underbrace{D_{\mathrm{KL}}\left(q\left(\mathbf{x}_T \mid \mathbf{x}_0\right) \| p_\theta\left(\mathbf{x}_T\right)\right)}_{L_T}+\sum_{t=2}^T \underbrace{\mathbb{E}_{q\left(\mathbf{x}_t \mid \mathbf{x}_0\right)}\left[D_{\mathrm{KL}}\left(q\left(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0\right) \| p_\theta\left(\mathbf{x}_{t-1} \mid \mathbf{x}_t\right)\right)\right]}_{L_{t-1}} \\
&amp; -\underbrace{\mathbb{E}_{q\left(\mathbf{x}_1 \mid \mathbf{x}_0\right)} \log p_\theta\left(\mathbf{x}_0 \mid \mathbf{x}_1\right)}_{L_0} \\
&amp;
\end{aligned}\)</p>
<ol>
  <li>根据两个高斯分布的KL公式，我们近一步得到:</li>
</ol>

<p>\(L_{t-1}=\mathbb{E}_{q\left(\mathbf{x}_t \mid \mathbf{x}_0\right)}\left[\frac{1}{2 \sigma_t^2}\left\|\tilde{\boldsymbol{\mu}}_t\left(\mathbf{x}_t, \mathbf{x}_0\right)-\boldsymbol{\mu}_\theta\left(\mathbf{x}_t, t\right)\right\|^2\right]\)
​		根据扩散过程的特性，我们通过重参数化可以近一步简化上述目标:
\(L_{t-1}=\mathbb{E}_{\mathbf{x}_0, \epsilon \sim \mathcal{N}(\mathbf{0}, \mathbf{I})}\left[\frac{\beta_t^2}{2 \sigma_t^2 \alpha_t\left(1-\bar{\alpha}_t\right)}\left\|\epsilon-\epsilon_\theta\left(\sqrt{\bar{\alpha}_t} \mathbf{x}_0+\sqrt{1-\bar{\alpha}_t} \epsilon, t\right)\right\|^2\right]\)
​		如果去掉系数，那么就能得到更简化的优化目标:
\(L_{t-1}^{\text {simple }}=\mathbb{E}_{\mathbf{x}_0, \epsilon \sim \mathcal{N}(\mathbf{0}, \mathbf{I})}\left[\left\|\epsilon-\epsilon_\theta\left(\sqrt{\bar{\alpha}_t} \mathbf{x}_0+\sqrt{1-\bar{\alpha}_t} \epsilon, t\right)\right\|^2\right]\)
仔细分析DDPM的优化目标会发现，DDPM其实仅仅依赖边缘分布 $q\left(\mathbf{x}<em>t \mid \mathbf{x}_0\right)$ ，而并不是直接作用 在联合分布 $q\left(\mathbf{x}</em>{1: T} \mid \mathbf{x}<em>0\right)$ 。这带来的一个启示是: <strong>DDPM这个隐变量模型可以有很多推理分布来选 择，只要推理分布满足边缘分布条件（扩散过程的特性）即可</strong>，而且这些推理过程并不一定要是马 尔卡夫链。但值得注意的一个点是，我们要得到DDPM的优化目标，还需要知道分布 $q\left(\mathbf{x}</em>{t-1} \mid \mathbf{x}<em>t, \mathbf{x}_0\right)$ ，之前我们在根据贝叶斯公式推导这个分布时是知道分布 $q\left(\mathbf{x}_t \mid \mathbf{x}</em>{t-1}\right)$ （forward process know it ) 的，而且依 赖了前向过程的马尔卡夫链特性.</p>

<p>\(q(\mathbf{x}_{t-1} \vert \mathbf{x}_t, \mathbf{x}_0) 
= q(\mathbf{x}_t \vert \mathbf{x}_{t-1}, \mathbf{x}_0) \frac{ q(\mathbf{x}_{t-1} \vert \mathbf{x}_0) }{ q(\mathbf{x}_t \vert \mathbf{x}_0) }\) ， zphilip48： <strong>DDIM的目的就是去除依赖(公式推导上的) $q\left(\mathbf{x}<em>t \mid \mathbf{x}</em>{t-1}\right)$</strong></p>

<h3 id="解除对前向过程的依赖">解除对前向过程的依赖</h3>

<p>现在我们在只给定 $p\left(x_t \mid \boldsymbol{x}<em>0\right) 、 p\left(\boldsymbol{x}</em>{t-1} \mid \boldsymbol{x}<em>0\right)$ 的情况下，通过待定系数法求解了 $p\left(x</em>{t-1} \mid x_t, x_0\right)$ 的一簇 解，它带有一个自由参数 $\sigma_t$ 。用 “拆楼-建 楼” 类比来说，就是我们知道楼会被拆成什么样 $【 p\left(\boldsymbol{x}<em>t \mid \boldsymbol{x}_0\right) 、 p\left(\boldsymbol{x}</em>{t-1} \mid \boldsymbol{x}<em>0\right) 】$ ，但是不知道每一步怎么 拆【 $p\left(\boldsymbol{x}_t \mid \boldsymbol{x}</em>{t-1}\right)$ 】 ，然后希望能够从中学会每一步怎么建$【 \left[p\left(\boldsymbol{x}<em>{t-1} \mid \boldsymbol{x}_t\right) 】\right.$ 。当然，如果我们想看看每 步怎么拆的话，也可以反过来用贝叶斯公式
\(p\left(\boldsymbol{x}_t \mid \boldsymbol{x}_{t-1}, \boldsymbol{x}_0\right)=\frac{p\left(\boldsymbol{x}_{t-1} \mid \boldsymbol{x}_t, \boldsymbol{x}_0\right) p\left(\boldsymbol{x}_t \mid \boldsymbol{x}_0\right)}{p\left(\boldsymbol{x}_{t-1} \mid \boldsymbol{x}_0\right)}\)
<strong>如果要解除对前向过程的依赖</strong>，那么我们就需要直接定义这个分 布 $q\left(\mathbf{x}</em>{t-1} \mid \mathbf{x}_t, \mathbf{x}_0\right)$ 。 基于上述分析，DDIM论文中将推理分布定义为：
\(q_\sigma\left(\mathbf{x}_{1: T} \mid \mathbf{x}_0\right)=q_\sigma\left(\mathbf{x}_T \mid \mathbf{x}_0\right) \prod_{t=2}^T q_\sigma\left(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0\right)\)
理解定义推导过程（Bayesian rule)： 
\(\begin{aligned}
q_\sigma\left(\mathbf{x}_{1: T} \mid \mathbf{x}_0\right) &amp;= \prod_{t=1}^T q_\sigma\left(\mathbf{x}_{t} \mid \mathbf{x}_{t-1}\right) \\
&amp; = q_\sigma(\mathbf{x}_1|\mathbf{x}_0)\prod_{t=2}^T \frac{q_\sigma\left(\mathbf{x}_{t-1} \mid \mathbf{x}_{t}, \mathbf{x}_0\right) q_\sigma\left(\boldsymbol{x}_t \mid \boldsymbol{x}_0\right)}{q_\sigma\left(\boldsymbol{x}_{t-1} \mid \boldsymbol{x}_0\right) }\\
&amp; = q_\sigma\left(\mathbf{x}_T \mid \mathbf{x}_0\right) \prod_{t=2}^T q_\sigma\left(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0\right)
\end{aligned}\)
对比DDPM前向定义
\(q(\mathbf{x}_{1:T} \vert \mathbf{x}_0) = \prod^T_{t=1} q(\mathbf{x}_t \vert \mathbf{x}_{t-1})\)
DDPM后向定义
\(p_\theta\left(\mathbf{x}_{0: T}\right)=p\left(\mathbf{x}_T\right) \prod_{t=1}^T p_\theta\left(\mathbf{x}_{t-1} \mid \mathbf{x}_t\right)\)
<strong>可以理解为，DDIM 把前向过程定义为得到了$X_{T}$以后的一个后向过程…</strong></p>

<p>DDIM论文中将推理分布定义为：
\(q_\sigma\left(\mathbf{x}_{1: T} \mid \mathbf{x}_0\right)=q_\sigma\left(\mathbf{x}_T \mid \mathbf{x}_0\right) \prod_{t=2}^T q_\sigma\left(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0\right)\)
这里要同时满足 $q_\sigma\left(\mathbf{x}<em>T \mid \mathbf{x}_0\right)=\mathcal{N}\left(\sqrt{\alpha_T} \mathbf{x}_0,\left(1-\alpha_T\right) \mathbf{I}\right)$ 以及对于所有的 $t \geq 2$ 有:
\(q_\sigma\left(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0\right)=\mathcal{N}\left(\mathbf{x}_{t-1} ; \sqrt{\alpha_{t-1}} \mathbf{x}_0+\sqrt{1-\alpha_{t-1}-\sigma_t^2} \frac{\mathbf{x}_t-\sqrt{\alpha_t} \mathbf{x}_0}{\sqrt{1-\alpha_t}}, \sigma_t^2 \mathbf{I}\right)\)
这里的方差 $\sigma_t^2$ 是一个实数，不同的设置就是不一样的分布，所以 $q</em>\sigma\left(\mathbf{x}<em>{1: T} \mid \mathbf{x}_0\right)$ 其实是一系列的推 理分布。可以看到这里分布 $q</em>\sigma\left(\mathbf{x}<em>{t-1} \mid \mathbf{x}_t, \mathbf{x}_0\right)$ 的均值也定义为一个依赖 $\mathbf{x}_0$ 和 $\mathbf{x}_t$ 的组合函数，之所 以定义为这样的形式，是因为根据 $q</em>\sigma\left(\mathbf{x}<em>T \mid \mathbf{x}_0\right)$ ，我们可以通过数学归纳法证明，对于所有的 $t$ 均满 足:
\(q_\sigma\left(\mathbf{x}_t \mid \mathbf{x}_0\right)=\mathcal{N}\left(\mathbf{x}_t ; \sqrt{\alpha_t} \mathbf{x}_0,\left(1-\alpha_t\right) \mathbf{I}\right)\)
可以看到这里定义的推理 分布 $q</em>\sigma\left(\mathbf{x}<em>{1: T} \mid \mathbf{x}_0\right)$ <strong>并没有直接定义前向过程，</strong>但这里满足了我们前面要讨论的两个条件: 边缘分布 $q</em>\sigma\left(\mathbf{x}<em>t \mid \mathbf{x}_0\right)=\mathcal{N}\left(\mathbf{x}_t ; \sqrt{\alpha_t} \mathbf{x}_0,\left(1-\alpha_t\right) \mathbf{I}\right)$ ，同时已知后验分布 $q</em>\sigma\left(\mathbf{x}_{t-1} \mid \mathbf{x}_t, \mathbf{x}_0\right)$ 。</p>

<p>同样地，我 们可以按照和DDPM的一样的方式去推导优化目标，最终也会得到同样的 $L^{\text {simple }}$ (虽然VLB的系 数不同，论文3.2部分也证明了这个结论）。论文也给出了一个前向过程是非马尔可夫链的示例， 如下图所示，这里前向过程是 $q_\sigma\left(\mathbf{x}<em>t \mid \mathbf{x}</em>{t-1}, \mathbf{x}<em>0\right)$ ，由于生成 $\mathbf{x}_t$ 不仅依赖 $\mathbf{x}</em>{t-1}$ ，而且依赖 $\mathbf{x}_0$ ，所以 是一个非马尔可夫链:</p>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/image-20230608101549213.png" alt="image-20230608101549213" /></p>

<h3 id="q_sigmaleftmathbfx_t-1-vert-mathbfx_t-mathbfx_0right--推导-1">$q_\sigma\left(\mathbf{x}_{t-1} \vert \mathbf{x}_t, \mathbf{x}_0\right)$  推导-1</h3>

<p>贝叶斯定理 <br />
\(p\left(\boldsymbol{x}_{t-1} \mid \boldsymbol{x}_t, \boldsymbol{x}_0\right)=\frac{p\left(\boldsymbol{x}_t \mid \boldsymbol{x}_{t-1}\right) p\left(\boldsymbol{x}_{t-1} \mid \boldsymbol{x}_0\right)}{p\left(\boldsymbol{x}_t \mid \boldsymbol{x}_0\right)} \tag {2}\)
设有给定 $p\left(x_t \mid x_{t-1}\right)$ 怎么能得到 $p\left(x_{t-1} \mid x_t, x_0\right)$ ? 这其实是思维过于定式了，理论上在没有给定 $p\left(\boldsymbol{x}<em>t \mid \boldsymbol{x}</em>{t-1}\right)$ 的情况下， $p\left(\boldsymbol{x}<em>{t-1} \mid \boldsymbol{x}_t, \boldsymbol{x}_0\right)$ 的解空间更大，某种意义上来说是更加容易推导，此时它<strong>只需 要满足边际分布条件</strong>:
\(\int p\left(x_{t-1} \mid x_t, x_0\right) p\left(x_t \mid x_0\right) d x_t=p\left(x_{t-1} \mid x_0\right) \tag {3}\)
一般性假设:
\(p\left(\boldsymbol{x}_{t-1} \mid \boldsymbol{x}_t, \boldsymbol{x}_0\right)=\mathcal{N}\left(\boldsymbol{x}_{t-1} ; \kappa_t \boldsymbol{x}_t+\lambda_t \boldsymbol{x}_0, \sigma_t^2 \boldsymbol{I}\right) \tag{4}\)
其中 $\kappa_t, \lambda_t, \sigma_t$ 都是待定系数，而为了不重新训练模型，我们不改变 $p\left(\boldsymbol{x}</em>{t-1} \mid \boldsymbol{x}_0\right)$ 和 $p\left(\boldsymbol{x}_t \mid \boldsymbol{x}_0\right)$ ，于是我们 叮以列出</p>

<table>
  <thead>
    <tr>
      <th>question</th>
      <th>Distribution</th>
      <th>Sampling</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>$p\left(\boldsymbol{x}_{t-1} \mid \boldsymbol{x}_0\right)$ forward defined</td>
      <td>$\mathcal{N}\left(\boldsymbol{x}<em>{t-1} ; \bar{\alpha}</em>{t-1} \boldsymbol{x}<em>0, \bar{\beta}</em>{t-1}^2 \boldsymbol{I}\right)$</td>
      <td>$\boldsymbol{x}<em>{t-1}=\bar{\alpha}</em>{t-1} \boldsymbol{x}<em>0+\bar{\beta}</em>{t-1} \varepsilon$</td>
    </tr>
    <tr>
      <td>$p\left(\boldsymbol{x}_t \mid \boldsymbol{x}_0\right)$ forward defined</td>
      <td>$\mathcal{N}\left(\boldsymbol{x}_t ; \bar{\alpha}_t \boldsymbol{x}_0, \bar{\beta}_t^2 \boldsymbol{I}\right)$</td>
      <td>$\boldsymbol{x}_t=\bar{\alpha}_t \boldsymbol{x}_0+\bar{\beta}_t \varepsilon_1$</td>
    </tr>
    <tr>
      <td>$p\left(\boldsymbol{x}_{t-1} \mid \boldsymbol{x}_t, \boldsymbol{x}_0\right)$ reversing</td>
      <td>$\mathcal{N}\left(\boldsymbol{x}_{t-1} ; \kappa_t \boldsymbol{x}_t+\lambda_t \boldsymbol{x}_0, \sigma_t^2 \boldsymbol{I}\right)$</td>
      <td>$\boldsymbol{x}_{t-1}=\kappa_t \boldsymbol{x}_t+\lambda_t \boldsymbol{x}_0+\sigma_t \varepsilon_2$</td>
    </tr>
    <tr>
      <td>$\int p\left(\boldsymbol{x}_{t-1} \mid \boldsymbol{x}_t, \boldsymbol{x}_0\right) p\left(\boldsymbol{x}_t \mid \boldsymbol{x}_0\right) d \boldsymbol{x}_t$ reversing</td>
      <td> </td>
      <td>\(\begin{aligned} \boldsymbol{x}_{t-1} &amp;=\kappa_t \boldsymbol{x}_t+\lambda_t \boldsymbol{x}_0+\sigma_t \varepsilon_2 \\ &amp;=\kappa_t\left(\bar{\alpha}_t \boldsymbol{x}_0+\bar{\beta}_t \varepsilon_1\right)+\lambda_t \boldsymbol{x}_0+\sigma_t \varepsilon_2 \\ &amp;=\left(\kappa_t \bar{\alpha}_t+\lambda_t\right) \boldsymbol{x}_0+\left(\kappa_t \bar{\beta}_t \varepsilon_1+\sigma_t \varepsilon_2\right) \end{aligned}\)</td>
    </tr>
  </tbody>
</table>

<p>其中 $\varepsilon, \varepsilon_1, \varepsilon_2 \sim \mathcal{N}(\mathbf{0}, \boldsymbol{I})$ ，并且由正态分布的叠加性我们知道 $\kappa_t \bar{\beta}<em>t \varepsilon_1+\sigma_t \varepsilon_2 \sim \sqrt{\kappa_t^2 \bar{\beta}_t^2+\sigma_t^2} \varepsilon</em>{\text {。 }}$ 对 比 $x_{t-1}$ 的两个采样形式，我们发现要想 $(3)$ 成立，只需要满足两个方程:
\(\bar{\alpha}_{t-1}=\kappa_t \bar{\alpha}_t+\lambda_t, \quad \bar{\beta}_{t-1}=\sqrt{\kappa_t^2 \bar{\beta}_t^2+\sigma_t^2} \tag {5}\)
可以看到有三个末知数，但只有两个方程，这就是为什么说没有给定 $p\left(x_t \mid x_{t-1}\right)$ 时解空间反而更大 了。将 $\sigma_t$ 视为可变参数，可以解出
\(\kappa_t=\frac{\sqrt{\bar{\beta}_{t-1}^2-\sigma_t^2}}{\bar{\beta}_t}, \quad \lambda_t=\bar{\alpha}_{t-1}-\frac{\bar{\alpha}_t \sqrt{\bar{\beta}_{t-1}^2-\sigma_t^2}}{\bar{\beta}_t} \tag{6}\)
或者写成
\(p\left(\boldsymbol{x}_{t-1} \mid \boldsymbol{x}_t, \boldsymbol{x}_0\right)=\mathcal{N}\left(\boldsymbol{x}_{t-1} ; \frac{\sqrt{\bar{\beta}_{t-1}^2-\sigma_t^2}}{\bar{\beta}_t} \boldsymbol{x}_t+\left(\bar{\alpha}_{t-1}-\frac{\bar{\alpha}_t \sqrt{\bar{\beta}_{t-1}^2-\sigma_t^2}}{\bar{\beta}_t}\right) \boldsymbol{x}_0, \sigma_t^2 \boldsymbol{I}\right) \tag {7}\)
方便起见，我们约定 $\bar{\alpha}_0=1, \bar{\beta}_0=0$ 。特别地，这个结果并不需要限定 $\bar{\alpha}_t^2+\bar{\beta}_t^2=1$ ，不过为了简化 参数设置，同时也为了跟以往的结果对齐，这里还是约定 $\bar{\alpha}_t^2+\bar{\beta}_t^2=1$ 。</p>

<p>我们最终想要 $p\left(\boldsymbol{x}<em>{t-1} \mid \boldsymbol{x}_t\right)$ 而不是 $p\left(\boldsymbol{x}</em>{t-1} \mid \boldsymbol{x}<em>t, \boldsymbol{x}_0\right)$ ，所以 我们希望用
\(\overline{\boldsymbol{\mu}}\left(\boldsymbol{x}_t\right)=\frac{1}{\bar{\alpha}_t}\left(\boldsymbol{x}_t-\bar{\beta}_t \boldsymbol{\epsilon} _\boldsymbol{\theta}\left(\boldsymbol{x}_t, t\right)\right)\)
来估计 $\boldsymbol{x}_0$ （<strong>可以看后面关于$f_\theta^{(t)}\left(\boldsymbol{x}_t\right)$的论文解释</strong>），由于没有改动 $p\left(\boldsymbol{x}_t \mid \boldsymbol{x}_0\right)$ ，所以训练所用的目标函数依然是 $\left|\varepsilon-\boldsymbol{\epsilon}</em>{\boldsymbol{\theta}}\left(\bar{\alpha}<em>t \boldsymbol{x}_0+\bar{\beta}_t \varepsilon, t\right)\right|^2$ (除 去权重系数），也就是说训练过程没有改变，我们可以用回DDPM训练好的模型。而用 $\overline{\boldsymbol{\mu}}(\boldsymbol{x} t)$ 替换掉 式(7)中的 $\boldsymbol{x}_0$ 后，得到
\(\begin{aligned}
p\left(\boldsymbol{x}_{t-1} \mid \boldsymbol{x}_t\right) &amp; \approx p\left(\boldsymbol{x}_{t-1} \mid \boldsymbol{x}_t, \boldsymbol{x}_0=\overline{\boldsymbol{\mu}}\left(\boldsymbol{x}_t\right)\right) \\
&amp; =\mathcal{N}\left(\boldsymbol{x}_{t-1} ; \frac{1}{\alpha_t}\left(\boldsymbol{x}_t-\left(\bar{\beta}_t-\alpha_t \sqrt{\bar{\beta}_{t-1}^2-\sigma_t^2}\right) \boldsymbol{\epsilon}_{\boldsymbol{\theta}}\left(\boldsymbol{x}_t, t\right)\right), \sigma_t^2 \boldsymbol{I}\right)
\end{aligned}\)
这就求出了生成过程所需要的 $p\left(x</em>{t-1} \mid x_t\right)$ ，其中 $\alpha_t=\frac{\bar{\alpha} t}{\bar{\alpha} t-1}$ 。它的特点是训练过程没有变化（也就是 说最终保存下来的模型没有变化)，<strong>但生成过程却有一个可变动的参数 $\sigma_t$ ，就是这个参数给DDPM带 来了新鲜的结果。</strong></p>

<h3 id="合并推导参数">合并推导参数</h3>

<p>以上的参数 $\alpha = \sqrt{\bar{\alpha}<em>{ddpm}} = \sqrt{\alpha</em>{ddim}}$ , ${\beta}^2 = {1- \alpha^2} = {1- \bar\alpha_{ddpm}}$and $\bar{\beta} = \sqrt{1-\bar{\alpha}<em>{ddpm}} = \sqrt{1-\alpha</em>{ddim}}$ , replace the parameters,下面是ddpm or ddim 的参数: 
\(\begin {aligned}
\tilde{\boldsymbol{\mu}}\left(\mathbf{x}_t, \mathbf{x}_0\right) &amp;=\frac{\sqrt{\beta_{t-1}-\sigma_t^2}}{\sqrt{1-\alpha}_t} \boldsymbol{x}_t+\left(\sqrt{\alpha}_{t-1}-\frac{\sqrt{\alpha}_t \sqrt{\beta_{t-1}-\sigma_t^2}}{\sqrt{1-\alpha}_t}\right) \boldsymbol{x}_0 \\
&amp; = \frac{\sqrt{(1-\alpha)_{t-1}-\sigma_t^2}}{\sqrt{1-\alpha}_t} \boldsymbol{x}_t+\left(\sqrt{\alpha}_{t-1}-\frac{\sqrt{\alpha}_t \sqrt{(1-\alpha)_{t-1}-\sigma_t^2}}{\sqrt{1-\alpha}_t}\right) \boldsymbol{x}_0 \\ 
&amp; = \sqrt{\alpha_{t-1}} \mathbf{x}_0+\sqrt{1-\alpha_{t-1}-\sigma_t^2} \frac{\mathbf{x}_t-\sqrt{\alpha_t} \mathbf{x}_0}{\sqrt{1-\alpha_t}}
\end {aligned}\)</p>

\[\begin{aligned}
\tilde{\boldsymbol{\mu}}\left(\mathbf{x}_t \right) &amp;=\frac{1}{\alpha_t}\left(\boldsymbol{x}_t-\left(\bar{\beta}_t-\alpha_t \sqrt{\bar{\beta}_{t-1}^2-\sigma_t^2}\right) \boldsymbol{\epsilon}_{\boldsymbol{\theta}}\left(\boldsymbol{x}_t, t\right)\right) \\
&amp; \text { 其中 } \alpha_t=\frac{\bar{\alpha} t}{\bar{\alpha}_{t-1}} 下面参数是ddim \\ 
&amp; = \sqrt{\alpha_{t-1}} \underbrace{\left(\frac{\boldsymbol{x}_t-\sqrt{1-\alpha_t} \epsilon_\theta^{(t)}\left(\boldsymbol{x}_t\right)}{\sqrt{\alpha_t}}\right)}_{\text {"predicted } \boldsymbol{x}_0 \text { " }}+\underbrace{\sqrt{1-\alpha_{t-1}-\sigma_t^2} \cdot \epsilon_\theta^{(t)}\left(\boldsymbol{x}_t\right)}_{\text {“direction pointing to } \boldsymbol{x}_t \text { " }}
\end{aligned}\]

<p>和以下的公式比对….</p>

<h3 id="q_sigmamathbfx_t-1-vert-mathbfx_t-mathbfx_0---推导-2">$q_\sigma(\mathbf{x}_{t-1} \vert \mathbf{x}_t, \mathbf{x}_0)$   推导-2</h3>

<p>rewrite <strong><font color="red">$q_\sigma(\mathbf{x}_{t-1} \vert \mathbf{x}_t, \mathbf{x}_0)$ to be parameterized by a desired standard deviation $\sigma_t$</font></strong>according to the <a href="https://lilianweng.github.io/posts/2021-07-11-diffusion-models/#nice">nice property</a>:
$$
\begin{eqnarray}
\mathbf{x}<em>{t-1} 
&amp;&amp;= \sqrt{\bar{\alpha}</em>{t-1}}\mathbf{x}<em>0 +  \sqrt{1 - \bar{\alpha}</em>{t-1}}\boldsymbol{\epsilon}<em>{t-1} <br />
&amp;&amp;= \sqrt{\bar{\alpha}</em>{t-1}}\mathbf{x}<em>0 + \sqrt{1 - \bar{\alpha}</em>{t-1} - \sigma_t^2} \boldsymbol{\epsilon}_t + \sigma_t\boldsymbol{\epsilon} \</p>

<p>&amp;&amp; \color{red} \text {; don’t clear what this come??  } \sqrt{1 - \bar{\alpha}<em>{t-1}}\boldsymbol{\epsilon}</em>{t-1} = \sqrt{1 - \bar{\alpha}_{t-1} - \sigma_t^2} \boldsymbol{\epsilon}_t + \sigma_t\boldsymbol{\epsilon} <br />
&amp;&amp; \color{red} \text {; we have  }   \mathbf{x}_t = \sqrt{\bar{\alpha}_t}\mathbf{x}_0 + \sqrt{1 - \bar{\alpha}_t}\boldsymbol{\epsilon} ==&gt;  \epsilon_t = \frac{\mathbf{x}_t - \sqrt{\bar{\alpha}_t}\mathbf{x}_0}{\sqrt{1 - \bar{\alpha}_t}}\</p>

<p>&amp;&amp;= \sqrt{\bar{\alpha}<em>{t-1}}\mathbf{x}_0 + \sqrt{1 - \bar{\alpha}</em>{t-1} - \sigma_t^2} \frac{\mathbf{x}<em>t - \sqrt{\bar{\alpha}_t}\mathbf{x}_0}{\sqrt{1 - \bar{\alpha}_t}} + \sigma_t\boldsymbol{\epsilon} <br />
q</em>\sigma(\mathbf{x}<em>{t-1} \vert \mathbf{x}_t, \mathbf{x}_0)
&amp;&amp;= \mathcal{N}(\mathbf{x}</em>{t-1}; \sqrt{\bar{\alpha}<em>{t-1}}\mathbf{x}_0 + \sqrt{1 - \bar{\alpha}</em>{t-1} - \sigma_t^2} \frac{\mathbf{x}<em>t - \sqrt{\bar{\alpha}_t}\mathbf{x}_0}{\sqrt{1 - \bar{\alpha}_t}}, \sigma_t^2 \mathbf{I}) \tag{7-DDIM} 
\end{eqnarray}
\(During generation, we only sample a subset of $S$ diffusion steps $\{\tau_1, \dots, \tau_S\}$ and the inference process becomes:\)
q</em>{\sigma, \tau}(\mathbf{x}<em>{\tau</em>{i-1}} \vert \mathbf{x}<em>{\tau_t}, \mathbf{x}_0)
= \mathcal{N}(\mathbf{x}</em>{\tau_{i-1}}; \sqrt{\bar{\alpha}<em>{t-1}}\mathbf{x}_0 + \sqrt{1 - \bar{\alpha}</em>{t-1} - \sigma_t^2} \frac{\mathbf{x}_{\tau_i} - \sqrt{\bar{\alpha}_t}\mathbf{x}_0}{\sqrt{1 - \bar{\alpha}_t}}, \sigma_t^2 \mathbf{I}) \tag{7-DDIM}
$$
While all the models are trained with $T=1000$ diffusion steps in the experiments, they observed that DDIM $\eta=0$ can produce the best quality samples when S is small, while DDPM $\eta=1$ performs much worse on small S. DDPM does perform better when we can afford to run the full reverse Markov diffusion steps $S=T=1000$. With DDIM, it is possible to train the diffusion model up to any arbitrary number of forward steps but only sample from a subset of steps in the generative process.</p>

<p><strong>From forward process we know following</strong>
\(\boldsymbol{x}_t=\sqrt{\alpha_t} \boldsymbol{x}_0+\sqrt{1-\alpha_t} \epsilon, \quad \text { where } \epsilon \sim \mathcal{N}(\mathbf{0}, \boldsymbol{I}) \text {. } \tag{4}\)
For some $\boldsymbol{x}<em>0 \sim q\left(\boldsymbol{x}_0\right)$ and $\epsilon_t \sim \mathcal{N}(\mathbf{0}, \boldsymbol{I}), \boldsymbol{x}_t$ can be obtained using Eq. (4). The model $\epsilon</em>\theta^{(t)}\left(\boldsymbol{x}<em>t\right)$ then attempts to predict $\epsilon_t$ from $\boldsymbol{x}_t$, <strong>without knowledge of $\boldsymbol{x}_0$</strong>. By rewriting Eq. (4), one can then predict the denoised observation, <strong>which is a prediction of $\boldsymbol{x}_0$ given $\boldsymbol{x}_t$</strong> :
\(f_\theta^{(t)}\left(\boldsymbol{x}_t\right):=\left(\boldsymbol{x}_t-\sqrt{1-\alpha_t} \cdot \epsilon_\theta^{(t)}\left(\boldsymbol{x}_t\right)\right) / \sqrt{\alpha_t} \tag {9-DDIM}\)
We can then define the generative process with a fixed prior $p</em>\theta\left(\boldsymbol{x}<em>T\right)=\mathcal{N}(\mathbf{0}, \boldsymbol{I})$ and
\(p_\theta^{(t)}\left(\boldsymbol{x}_{t-1} \mid \boldsymbol{x}_t\right)= \begin{cases}\mathcal{N}\left(f_\theta^{(1)}\left(\boldsymbol{x}_1\right), \sigma_1^2 \boldsymbol{I}\right) &amp; \text { if } t=1 \\
\text{;zphlip48, where from x1-&gt;x0 special handling} \\
\text{;check L0 } \\ 
q_\sigma\left(\boldsymbol{x}_{t-1} \mid \boldsymbol{x}_t, f_\theta^{(t)}\left(\boldsymbol{x}_t\right)\right) &amp; \text { otherwise, }\end{cases}
\tag {10-DDIM}\)
where $q</em>\sigma\left(\boldsymbol{x}<em>{t-1} \mid \boldsymbol{x}_t, f</em>\theta^{(t)}\left(\boldsymbol{x}_t\right)\right)$ is defined as in Eq. (7) <strong>with $\boldsymbol{x}<em>0$ replaced by $f</em>\theta^{(t)}\left(\boldsymbol{x}_t\right)$</strong>. We add some Gaussian noise (with covariance $\sigma_1^2 \boldsymbol{I}$ ) for the case of $t=1$ to ensure that the generative process is supported everywhere.</p>

<p>From $p_θ(x_{1:T} )$ in Eq. (10), one can generate a sample $x_{t−1}$ from a sample $x_t$ via:
\(\text {DENOISING DIFFUSION IMPLICIT MODELS }\\
\boldsymbol{x}_{t-1}=\sqrt{\alpha_{t-1}} \underbrace{\left(\frac{\boldsymbol{x}_t-\sqrt{1-\alpha_t} \epsilon_\theta^{(t)}\left(\boldsymbol{x}_t\right)}{\sqrt{\alpha_t}}\right)}_{\text {"predicted } \boldsymbol{x}_0 \text { " }}+\underbrace{\sqrt{1-\alpha_{t-1}-\sigma_t^2} \cdot \epsilon_\theta^{(t)}\left(\boldsymbol{x}_t\right)}_{\text {“direction pointing to } \boldsymbol{x}_t \text { " }}+\underbrace{\sigma_t \epsilon_t}_{\text {random noise }} \tag {12-DDIM}\)
where $\epsilon_t \sim \mathcal{N}(\mathbf{0}, \boldsymbol{I})$ is standard Gaussian noise independent of $\boldsymbol{x}<em>t$, and we define $\alpha_0:=1$. Different choices of $\sigma$ values results in different generative processes, all while using the same model $\epsilon</em>\theta$, so re-training the model is unnecessary.</p>

<p>其中, $\sigma$ 可以参考 DDIM 论文的公式 (16) :
\(\sigma_t=\eta \sqrt{\left(1-\bar{\alpha}_{t-1}\right) /\left(1-\bar{\alpha}_t\right)} \sqrt{1-\bar{\alpha}_t / \bar{\alpha}_{t-1}} \tag{16-DDIM}\)
如果 $\eta=0$ ，那么生成过程就是确定的，这种情况下为 DDIM。
论文中指出, 当 $\eta=1$, 该 forward process 变成了马尔科大链, 该生成过程等价于 DDPM 的生成过 程。也就是说当 $\eta=1$ 时, 公式 (12) 等于 DDPM 的采样公式, 即公式 (7) :
\(\begin{aligned}
&amp; \hat{x}_{t-1}=\frac{1}{\sqrt{\alpha_t}}\left(x_t-\frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}} \epsilon_\theta\left(x_t, t\right)\right)+\sigma_t z \\
&amp; \quad \text { where } z=N(0, I)
\end{aligned}\)
将 (16) 式带入到 (1) 式中得到 DDPM 分布公式（本文章标记依照 DDPM 论文, 因此有 $\bar{\alpha}_t=\Pi_T \alpha_t$ ) :
\(\sqrt{1-\bar{\alpha}_{t-1}-\sigma_t^2}=\frac{1-\bar{\alpha}_{t-1}}{\sqrt{1-\bar{\alpha}_t}} \sqrt{\alpha_t}\)
上式的推导过程:
\(\begin{aligned}
\frac{\sqrt{1-\bar{\alpha}_t}}{\sqrt{1-\bar{\alpha}_t}} \sqrt{1-\bar{\alpha}_{t-1}-\sigma_t^2} &amp; =\frac{\sqrt{\left[\left(1-\bar{\alpha}_{t-1}-\left(\frac{1-\bar{\alpha}_{t-1}}{1-\bar{\alpha}_t}\right)\left(1-\alpha_t\right)\right]\left(1-\bar{\alpha}_t\right)\right.}}{\sqrt{1-\bar{\alpha}_t}} \\
&amp; =\frac{\sqrt{\left(1-\bar{\alpha}_{t-1}\right)\left(1-\left(\frac{1-\bar{\alpha}_{t-1}}{1-\bar{\alpha}_t}\right)\left(1-\alpha_t\right)\right)\left(1-\bar{\alpha}_{t-1}\right)}}{\sqrt{1-\bar{\alpha}_t}} \\
&amp; =\frac{\sqrt{\left(1-\bar{\alpha}_{t-1}\right)\left(1-\bar{\alpha}_t-1+\frac{\bar{\alpha}_t}{\bar{\alpha}_{t-1}}\right)}}{\sqrt{1-\bar{\alpha}_t}} \\
&amp; =\frac{\sqrt{\left(1-\bar{\alpha}_{t-1}\right)\left(1-\bar{\alpha}_{t-1}\right) \frac{\bar{\alpha}_t}{\bar{\alpha}_{t-1}}}}{\sqrt{1-\bar{\alpha}_t}} \\
&amp; =\frac{1-\bar{\alpha}_{t-1}}{\sqrt{1-\bar{\alpha}_t} \sqrt{\alpha_t}}
\end{aligned}\)
因此
\(\begin{aligned}
&amp; x_{t-1}=\sqrt{\bar{\alpha}_{t-1}} \underbrace{\left(\frac{x_t-\sqrt{1-\bar{\alpha}_t} \epsilon_\theta^{(t)}\left(x_t\right)}{\sqrt{\bar{\alpha}_t}}\right)}_{\text {" predicted } x_0 "}+\underbrace{\sqrt{1-\bar{\alpha}_{t-1}-\sigma_t^2} \cdot \epsilon_\theta^{(t)}\left(x_t\right)}_{\text {"direction pointing to } \boldsymbol{x}_t \text { " }}+\underbrace{\sigma_t \epsilon_t}_{\text {random noise }} \\
&amp; =\sqrt{\frac{\bar{\alpha}_{t-1}}{\bar{\alpha}_t}} x_t-\sqrt{\frac{\bar{\alpha}_{t-1}}{\bar{\alpha}_t}} \sqrt{1-\bar{\alpha}_t} \epsilon_\theta^{(t)}+\frac{1-\bar{\alpha}_{t-1}}{\sqrt{1-\bar{\alpha}_t}} \sqrt{\alpha_t} \epsilon_\theta^{(t)}+\sigma_t \epsilon_t \\
&amp; =\frac{1}{\sqrt{\alpha}_t} x_t-\frac{1}{\sqrt{\alpha_t} \sqrt{1-\bar{\alpha}_t}}\left(1-\bar{\alpha}_t+\left(1-\bar{\alpha}_{t-1}\right) \alpha_t\right) \epsilon_\theta^{(t)}+\sigma_t \epsilon_t \\
&amp; =\frac{1}{\sqrt{\alpha_t}}\left(x_t-\frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}} \epsilon_\theta^{(t)}\right)+\sigma_t \epsilon_t \\
&amp; =\frac{1}{\sqrt{\alpha_t}}\left(x_t-\frac{\beta_t}{\sqrt{1-\bar{\alpha}_t}} \epsilon_\theta^{(t)}\right)+\sigma_t \epsilon_t \\
&amp;
\end{aligned}\)
<strong>comparing to DDPM</strong> 
\(\boldsymbol{\mu}_\theta(\mathbf{x}_t, t) = \color{cyan}{\frac{1}{\sqrt{\alpha_t}} \Big( \mathbf{x}_t - \frac{1 - \alpha_t}{\sqrt{1 - \bar{\alpha}_t}} \boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t) \Big)}\)</p>

<p>因此，根据推导，<em>η</em>=1 时候的 Forward Processes 等价于 DDPM，我们将在 notebook 后半部分，通过代码的方式验证当 <em>η</em>=1 DDIM 的结果与 DDPM 基本相同。</p>

<h3 id="after-defined-the-ddim-model-the-loss-function-also-defined-for-q_sigma">After defined the DDIM model, the loss function also defined for $q_{\sigma}$*</h3>

<p>We optimize $\theta$ via the following variational inference objective (which is a functional over $\epsilon_\theta$ ):
\(\begin{aligned}
&amp; J_\sigma\left(\epsilon_\theta\right):=\mathbb{E}_{\boldsymbol{x}_{0: T} \sim q_\sigma\left(\boldsymbol{x}_{0: T}\right)}\left[\log q_\sigma\left(\boldsymbol{x}_{1: T} \mid \boldsymbol{x}_0\right)-\log p_\theta\left(\boldsymbol{x}_{0: T}\right)\right] \\
= &amp; \mathbb{E}_{\boldsymbol{x}_{0: T} \sim q_\sigma\left(\boldsymbol{x}_{0: T}\right)}\left[\log q_\sigma\left(\boldsymbol{x}_T \mid \boldsymbol{x}_0\right)+\sum_{t=2}^T \log q_\sigma\left(\boldsymbol{x}_{t-1} \mid \boldsymbol{x}_t, \boldsymbol{x}_0\right)-\sum_{t=1}^T \log p_\theta^{(t)}\left(\boldsymbol{x}_{t-1} \mid \boldsymbol{x}_t\right)-\log p_\theta\left(\boldsymbol{x}_T\right)\right]
\end{aligned}\)
where we factorize $q_\sigma\left(\boldsymbol{x}<em>{1: T} \mid \boldsymbol{x}_0\right)$ according to Eq. (6) and $p</em>\theta\left(\boldsymbol{x}<em>{0: T}\right)$ according to Eq. (1).
From the definition of $J</em>\sigma$, it would appear that a different model has to be trained for every choice of $\sigma$, since it corresponds to a different variational objective (and a different generative process). However, $J_\sigma$ is equivalent to $L_\gamma$ for certain weights $\gamma$, as we show below.
Theorem 1. For all $\sigma&gt;\mathbf{0}$, there exists $\gamma \in \mathbb{R}<em>{&gt;0}^T$ and $C \in \mathbb{R}$, such that $J</em>\sigma=L_\gamma+C$.</p>

<h3 id="comparing-to-ddpm">Comparing to DDPM</h3>

<p>Recall that in <strong>(DDPM reversing)</strong> $q(\mathbf{x}<em>{t-1} \vert \mathbf{x}_t, \mathbf{x}_0) = \mathcal{N}(\mathbf{x}</em>{t-1}; \tilde{\boldsymbol{\mu}}(\mathbf{x}<em>t, \mathbf{x}_0), \tilde{\beta}_t \mathbf{I})$ so $\tilde{\beta}_t = \sigma_t^2 = \frac{1 - \bar{\alpha}</em>{t-1}}{1 - \bar{\alpha}_t} \cdot \beta_t$</p>

<p>Let $\sigma_t^2 = \eta \cdot \tilde{\beta}<em>t$ such that we can adjust $\eta \in \mathbb{R}^+$ as a hyperparameter to control the sampling stochasticity. <strong>The special case of $\eta=0$ makes the sampling process *deterministic</strong>*. Such a model is named the *denoising diffusion implicit model* (<strong>DDIM</strong>; <a href="https://arxiv.org/abs/2010.02502">Song et al., 2020</a>). DDIM has the same marginal noise distribution but deterministically maps noise back to the original data samples.
\(\tilde{\beta}_t=\sigma_t^2=\frac{1-\bar{\alpha}_{t-1}}{1-\bar{\alpha}_t} \cdot \beta_t \\
\sigma_t=\eta \cdot \sqrt{\tilde{\beta}_t}=\eta \cdot \sqrt{\left(1-\alpha_{t-1}\right) /\left(1-\alpha_t\right)} \sqrt{\left(1-\alpha_t / \alpha_{t-1}\right)}\)
When $\sigma_t=\sqrt{\left(1-\alpha</em>{t-1}\right) /\left(1-\alpha_t\right)} \sqrt{1-\alpha_t / \alpha_{t-1}}$ for all $t$, the forward process becomes Markovian, and the generative process becomes a DDPM.
\(p\left(\boldsymbol{x}_{t-1} \mid \boldsymbol{x}_t\right) \approx p\left(\boldsymbol{x}_{t-1} \mid \boldsymbol{x}_t, \boldsymbol{x}_0=\overline{\boldsymbol{\mu}}\left(\boldsymbol{x}_t\right)\right)=\mathcal{N}\left(\boldsymbol{x}_{t-1} ; \frac{1}{\alpha_t}\left(\boldsymbol{x}_t-\frac{\beta_t^2}{\bar{\beta}_t} \boldsymbol{\epsilon}_{\boldsymbol{\theta}}\left(\boldsymbol{x}_t, t\right)\right), \frac{\bar{\beta}_{t-1}^2 \beta_t^2}{\bar{\beta}_t^2} \boldsymbol{I}\right) \\
\text { where }
\sigma_t=\frac{\bar{\beta}_{t-1} \beta_t}{\bar{\beta}_t} \\
\beta_t=\sqrt{1-\alpha_t^2} \\
\alpha_t=\frac{\bar{\alpha} t}{\bar{\alpha}_{t-1}} \\\)
这就是DDPM 。特别是，DDIM论文中还对 $\sigma t=\eta \frac{\bar{\beta}<em>{t-1} \beta_t}{\bar{\beta}_t}$ 做了对比实验，其中 $\eta \in[0,1]$
如果取 $\sigma_t=\beta_t$ ，这也是前两篇文章所指出的 $\sigma_t$ 的两个选择之一，在此选择下式(10)末能 做进一步的化简，但DDIM的实验结果显示此选择在DDPM的标准参数设置下表现还是很好的。
最特殊的一个例子是取 $\sigma_t=0$ ，此时从 $x_t$ 到 $x</em>{t-1}$ 是一个确定性变换
\(\boldsymbol{x}_{t-1}=\frac{1}{\alpha_t}\left(\boldsymbol{x}_t-\left(\bar{\beta}_t-\alpha_t \bar{\beta}_{t-1}\right) \boldsymbol{\epsilon}_{\boldsymbol{\theta}}\left(\boldsymbol{x}_t, t\right)\right)\)
<strong>这也是DDIM论文中特别关心的一个例子，准确来说，原论文的DDIM就是特指 $\sigma_t=0$ 的情形，其中 “T”的含义就是“Implicit”，意思这是一个隐式的概率模型，因为跟其他选择所不同的是，此时从给定 的 $\boldsymbol{x}_T=\boldsymbol{z}$ 出发，得到的生成结果 $\boldsymbol{x}_0$ 是不带随机性的。后面我们将会看到，这在理论上和实用上都带 来了一些好处。</strong></p>

<h3 id="accelerated-sampling-processes--qleftmathbfxtau_i-mid-mathbfx_0right--and-qsigma-taumathbfxtaui-1-vert-mathbfx_tau_t-mathbfx_0----推导">ACCELERATED SAMPLING PROCESSES:  $q\left(\mathbf{x}<em>{\tau_i} \mid \mathbf{x}_0\right)$  and $q</em>{\sigma, \tau}(\mathbf{x}<em>{\tau</em>{i-1}} \vert \mathbf{x}_{\tau_t}, \mathbf{x}_0)$    推导</h3>

<p>DDIM并没有明确前向过程，这意味着我们可以<strong>定义一个更短的步数的前向过程</strong>. 具体地，这里我们从原始的序列 $[1, \ldots, T]$ 采样一个长度为 $S$ 的子序列 $\left[\tau_1, \ldots, \tau_S\right]$ ，<strong>我们将 $\mathbf{x}<em>{\tau_1}, \ldots, \mathbf{x}</em>{\tau_S}$ 的前向过程定义为一个马尔卡夫链</strong>，并且它们满足: $q\left(\mathbf{x}<em>{\tau_i} \mid \mathbf{x}_0\right)=\mathcal{N}\left(\mathbf{x}_t ; \sqrt{\alpha</em>{\tau_i}} \mathbf{x}<em>0,\left(1-\alpha</em>{\tau_i}\right) \mathbf{I}\right)$ 。下图展示了一个具体的示例:</p>

<p>During generation, we only sample a subset of S diffusion steps ${\tau_1, \dots, \tau_S}$ and the inference process becomes:
\(q_{\sigma, \tau}(\mathbf{x}_{\tau_{i-1}} \vert \mathbf{x}_{\tau_t}, \mathbf{x}_0)
= \mathcal{N}(\mathbf{x}_{\tau_{i-1}}; \sqrt{\bar{\alpha}_{t-1}}\mathbf{x}_0 + \sqrt{1 - \bar{\alpha}_{t-1} - \sigma_t^2} \frac{\mathbf{x}_{\tau_i} - \sqrt{\bar{\alpha}_t}\mathbf{x}_0}{\sqrt{1 - \bar{\alpha}_t}}, \sigma_t^2 \mathbf{I})\)</p>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/image-20230531135247420.png" alt="image-20230531135247420" /></p>

<p>那么生成过程也可以用这个子序列的反向马尔卡夫链来替代，由于 $S$ 可以设置比原来的步数 $L$ 要 小，那么就可以加速生成过程。这里的生成过程变成:
\(\mathbf{x}_{\tau_{i-1}}=\sqrt{\alpha_{\tau_{i-1}}}\left(\frac{\mathbf{x}_{\tau_i}-\sqrt{1-\alpha_{\tau_i}} \epsilon_\theta\left(\mathbf{x}_{\tau_i}, \tau_i\right)}{\sqrt{\alpha_{\tau_i}}}\right)+\sqrt{1-\alpha_{\tau_{i-1}}-\sigma_{\tau_i}^2} \cdot \epsilon_\theta\left(\mathbf{x}_{\tau_i}, \tau_i\right)+\sigma_{\tau_i} \epsilon\)
其实上述的加速，我们是<strong>将前向过程</strong>按如下方式进行了分解: （why??)
\(q_{\sigma, \tau}\left(\mathbf{x}_{1: T} \mid \mathbf{x}_0\right)=q_{\sigma, \tau}\left(\mathbf{x}_T \mid \mathbf{x}_0\right) \prod_{i=1}^S q_\sigma\left(\mathbf{x}_{\tau_{i-1}} \mid \mathbf{x}_{\tau_i}, \mathbf{x}_0\right) \prod_{t \in \bar{\tau}} q_{\sigma, \tau}\left(\mathbf{x}_t \mid \mathbf{x}_0\right)\)
where $\tau$ is a sub-sequence of $[1, \ldots, T]$ of length $S$ with $\tau_S=T$, and let $\bar{\tau}:={1, \ldots, T} \backslash \tau$ be its complement. Intuitively, the graphical model of $\left{\boldsymbol{x}<em>{\tau_i}\right}</em>{i=1}^S$ and $\boldsymbol{x}<em>0$ form a chain, whereas the graphical model of $\left{\boldsymbol{x}_t\right}</em>{t \in \bar{\tau}}$ and $\boldsymbol{x}_0$ forms a star graph. We define:
\(\begin{gathered}
q_{\sigma, \tau}\left(\boldsymbol{x}_t \mid \boldsymbol{x}_0\right)=\mathcal{N}\left(\sqrt{\alpha_t} \boldsymbol{x}_0,\left(1-\alpha_t\right) \boldsymbol{I}\right) \quad \forall t \in \bar{\tau} \cup\{T\} \\
q_{\sigma, \tau}\left(\boldsymbol{x}_{\tau_{i-1}} \mid \boldsymbol{x}_{\tau_i}, \boldsymbol{x}_0\right)=\mathcal{N}\left(\sqrt{\alpha_{\tau_{i-1}}} \boldsymbol{x}_0+\sqrt{1-\alpha_{\tau_{i-1}}-\sigma_{\tau_i}^2} \cdot \frac{\boldsymbol{x}_{\tau_i}-\sqrt{\alpha_{\tau_i}} \boldsymbol{x}_0}{\sqrt{1-\alpha_{\tau_i}}}, \sigma_{\tau_i}^2 \boldsymbol{I}\right) \forall i \in[S]
\end{gathered}\)
where the coefficients are chosen such that:
\(q_{\sigma, \tau}\left(\boldsymbol{x}_{\tau_i} \mid \boldsymbol{x}_0\right)=\mathcal{N}\left(\sqrt{\alpha_{\tau_i}} \boldsymbol{x}_0,\left(1-\alpha_{\tau_i}\right) \boldsymbol{I}\right) \quad \forall i \in[S]\)
i.e., the “marginals” match.
<strong>The corresponding “generative process” is defined as:</strong>
\(p_\theta\left(\boldsymbol{x}_{0: T}\right):=\underbrace{p_\theta\left(\boldsymbol{x}_T\right) \prod_{i=1}^S p_\theta^{\left(\tau_i\right)}\left(\boldsymbol{x}_{\tau_{i-1}} \mid \boldsymbol{x}_{\tau_i}\right)}_{\text {use to produce samples }} \times \underbrace{\prod_{t \in \bar{\tau}} p_\theta^{(t)}\left(\boldsymbol{x}_0 \mid \boldsymbol{x}_t\right)}_{\text {in variational objective }}\)
where only part of the models are actually being used to produce samples. The conditionals are:
\(\begin{gathered}
p_\theta^{\left(\tau_i\right)}\left(\boldsymbol{x}_{\tau_{i-1}} \mid \boldsymbol{x}_{\tau_i}\right)=q_{\sigma, \tau}\left(\boldsymbol{x}_{\tau_{i-1}} \mid \boldsymbol{x}_{\tau_i}, f_\theta^{\left(\tau_i\right)}\left(\boldsymbol{x}_{\tau_{i-1}}\right)\right) \quad \text { if } i \in[S], i&gt;1 \\
p_\theta^{(t)}\left(\boldsymbol{x}_0 \mid \boldsymbol{x}_t\right)=\mathcal{N}\left(f_\theta^{(t)}\left(\boldsymbol{x}_t\right), \sigma_t^2 \boldsymbol{I}\right) \quad \text { otherwise, }
\end{gathered}\)
<strong>所以这里也得到了加速子集的逆向推导方程，应该和前面的一样–论文里没给出形式</strong></p>

<p>where we leverage $q_{\sigma, \tau}\left(\boldsymbol{x}<em>{\tau</em>{i-1}} \mid \boldsymbol{x}<em>{\tau_i}, \boldsymbol{x}_0\right)$ as part of the inference process (similar to what we have done in Section 3). The resulting variational objective becomes (define $\boldsymbol{x}</em>{\tau_{L+1}}=\varnothing$ for conciseness):
\(\begin{aligned}
&amp; J\left(\epsilon_\theta\right)=\mathbb{E}_{\boldsymbol{x}_{0: T} \sim q_{\sigma, \tau}\left(\boldsymbol{x}_{0: T}\right)}\left[\log q_{\sigma, \tau}\left(\boldsymbol{x}_{1: T} \mid \boldsymbol{x}_0\right)-\log p_\theta\left(\boldsymbol{x}_{0: T}\right)\right] \\
&amp;=\mathbb{E}_{\boldsymbol{x}_{0: T} \sim q_{\sigma, \tau}\left(\boldsymbol{x}_{0: T}\right)}[ {\left[\sum _ { t \in \overline { \tau } } D _ { \mathrm { KL } } \left(q_{\sigma, \tau}\left(\boldsymbol{x}_t \mid \boldsymbol{x}_0\right) \| p_\theta^{(t)}\left(\boldsymbol{x}_0 \mid \boldsymbol{x}_t\right)\right.\right.} \\
&amp;\left.\left.+\sum_{i=1}^L D_{\mathrm{KL}}\left(q_{\sigma, \tau}\left(\boldsymbol{x}_{\tau_{i-1}} \mid \boldsymbol{x}_{\tau_i}, \boldsymbol{x}_0\right) \| p_\theta^{\left(\tau_i\right)}\left(\boldsymbol{x}_{\tau_{i-1}} \mid \boldsymbol{x}_{\tau_i}\right)\right)\right)\right]
\end{aligned}\)
where each KL divergence is between two Gaussians with variance independent of $\theta$. A similar argument to the proof used in Theorem 1 can show that the variational objective $J$ can also be converted to an objective of the form $L_\gamma$.</p>

<p>论文共设计了两种方法来采样子序列，分别是:</p>

<ul>
  <li>Linear: 采用线性的序列 $\tau_i=\lfloor c i\rfloor$;</li>
  <li>Quadratic: 采样二次方的序列 $\tau_i=\left\lfloor c i^2\right\rfloor$; 列，其它数据集均采用Linear序列。</li>
</ul>

<h3 id="sampling-speedup子序列sampling">Sampling Speedup(子序列Sampling)</h3>

<p>从损失函数 $\left|\varepsilon-\boldsymbol{\epsilon} \boldsymbol{\theta}\left(\bar{\alpha}_t \boldsymbol{x}_0+\bar{\beta}_t \varepsilon, t\right)\right|^2$  or （以DDPM or DDIM 参数） $\left|\varepsilon-\boldsymbol{\epsilon} \boldsymbol{\theta}\left(\sqrt{\bar{\alpha}_t }\boldsymbol{x}_0+\sqrt{1-\bar\alpha_t} \varepsilon, t\right)\right|^2$ 可以看出，给定了各个 $\overline{\boldsymbol{\alpha}}_t$ ，训练过程也就确定了。从这个过程中，DDIM进步留意到了如下事实:</p>

<p><strong>DDPM的训练结果实质上包含了它的任意子序列参数的训练结果</strong></p>

<p>具体来说，设 $\tau=\left[\tau_1, \tau_2, \ldots, \tau_{\operatorname{dim}(\tau)}\right]$ 是 $[1,2, \cdots, T]$ 的任意子序列，那么我们以 $\bar{\alpha}<em>{\tau 1}, \bar{\alpha}</em>{\tau 2}, \cdots, \bar{\alpha}_{\operatorname{dim}(\tau)}$ 为参数训练一个扩散步数为 $\operatorname{dim}(\tau)$ 步的DDPM，其目标函数实际上是原来以 $\bar{\alpha}_1, \bar{\alpha}_2, \cdots, \bar{\alpha}_T$ 的 $T$ 步DDPM的目标函数的一个子集! 所以在模型拟合能力足够好的情况下，它其实 包含了任意子序列参数的训练结果。</p>

<p><strong>也就是说 $q\left(\mathbf{x}<em>{\tau_i} \mid \mathbf{x}_0\right)$ 是 $q\left(\mathbf{x}</em>{\tau} \mid \mathbf{x}_0\right)$ 的子集</strong></p>

<p>那么反过来想，如果有一个训练好的 $T$ 步DDPM模型，我们也可以将它当成是以 $\bar{\alpha}<em>{\tau 1}, \bar{\alpha}</em>{\tau 2}, \cdots, \bar{\alpha}<em>{\operatorname{dim}(\tau)}$ 为参数训练出来的 $\operatorname{dim}(\boldsymbol{\tau})$ 步模型，而既然是 $\operatorname{dim}(\tau)$ 步的模型，生成过程也就 只需要 $\operatorname{dim}(\tau)$ 步了, 根据式 $(10)$ 有:
\(p\left(\boldsymbol{x}_{\tau i-1} \mid \boldsymbol{x}_{\tau i}\right) \approx \mathcal{N}\left(\boldsymbol{x}_{\tau i-1} ; \frac{\bar{\alpha}_{\tau i-1}}{\bar{\alpha}_{\tau_i}}\left(\boldsymbol{x}_{\tau i}-\left(\bar{\beta}_{\tau_i}-\frac{\bar{\alpha}_{\tau_i}}{\bar{\alpha}_{\tau_{i-1}}} \sqrt{\bar{\beta}_{\tau i-1}^2-\tilde{\sigma}_{\tau_i}^2}\right) \boldsymbol{\epsilon}\left(\boldsymbol{x}_{\tau i}, \tau_i\right)\right), \bar{\sigma}_{\tau_i}^2 \boldsymbol{I}\right)\)
这就是加速采样的生成过程了，从原来的 $T$ 步扩散生成变成了 $\operatorname{dim}(\boldsymbol{\tau})$ 步。要注意不能直接将式(10)的 $\alpha_t$ 换成 $\alpha</em>{\tau_i}$ ，因为我们说过 $\alpha_t$ 是派生记号而已，它实际上等于 $\frac{\bar{\alpha}<em>t}{\bar{\alpha}</em>{t-1}}$ ，因此 $\alpha_t$ 要换成 $\frac{\bar{\alpha}<em>{\tau_i}}{\bar{\alpha}</em>{\tau_{i-1}}}$ 才对。同 理， $\tilde{\sigma}<em>{\tau i}$ 也不是直接取 $\sigma</em>{\tau i}$ ，而是在将其定义全部转化为 $\bar{\alpha}, \bar{\beta}$ 符号后，将 $t$ 替换为 $\tau_i 、 t-1$ 替换为 $\tau_{i-1}$, 比如式 $(11)$ 对应的 $\tilde{\sigma}_{\tau i}$ 为
\(\sigma_t=\frac{\bar{\beta}_{t-1} \beta_t}{\bar{\beta}_t}=\frac{\bar{\beta}_{t-1}}{\bar{\beta}_t} \sqrt{1-\frac{\bar{\alpha}_t^2}{\bar{\alpha}_{t-1}^2}} \rightarrow \frac{\bar{\beta}_{\tau_{i-1}}}{\bar{\beta}_{\tau i}} \sqrt{1-\frac{\bar{\alpha}_{\tau i}^2}{\bar{\alpha}_{\tau i-1}^2}}=\tilde{\sigma}_{\tau i}\)
那我们为什么干脆不直接训练一个 $\operatorname{dim}(\boldsymbol{\tau})$ 步的扩散模型，而是要先训练 $T&gt;\operatorname{dim}(\boldsymbol{\tau})$ 步然后去做子序列采样? 笔者认为可能有两方面的考虑: 一方面从 $\operatorname{dim}(\tau)$ 步生成来说，训练更多步 数的模型也许能增强泛化能力；另一方面，通过子序列 $\tau$ 进行加速只是其中一种加速手段，训练更充 分的 $T$ 步允许我们尝试更多的其他加速手段，但并不会显著增加训练成本。</p>

<h3 id="ddim-odesve-sde">DDIM ODES/VE-SDE</h3>

<p>we can rewrite the DDIM iterate according to Eq. (12), and its similarity to Euler integration for solving ordinary differential equations (ODEs) becomes more apparent:
\(\frac{\boldsymbol{x}_{t-\Delta t}}{\sqrt{\alpha_{t-\Delta t}}}=\frac{\boldsymbol{x}_t}{\sqrt{\alpha_t}}+\left(\sqrt{\frac{1-\alpha_{t-\Delta t}}{\alpha_{t-\Delta t}}}-\sqrt{\frac{1-\alpha_t}{\alpha_t}}\right) \epsilon_\theta^{(t)}\left(\boldsymbol{x}_t\right) \tag {13}\)
To derive the corresponding ODE, we can reparametrize $(\sqrt{1-\alpha} / \sqrt{\alpha})$ with $\sigma$ and $(x / \sqrt{\alpha})$ with $\overline{\boldsymbol{x}}$.</p>

<blockquote>
  <p>Proof. In the context of the proof, we consider $t$ as a continous, independent “time” variable and $\boldsymbol{x}$ and $\alpha$ as functions of $t$. First, let us consider a reparametrization between DDIM and the VE-SDE ${ }^8$ by introducing the variables $\overline{\boldsymbol{x}}$ and $\sigma$ :
\(\overline{\boldsymbol{x}}(t)=\overline{\boldsymbol{x}}(0)+\sigma(t) \epsilon, \quad \epsilon \sim \mathcal{N}(0, \boldsymbol{I})\)
We can then define $\alpha(t)$ and $\boldsymbol{x}(t)$ corresponding to DDIM case as:
\(\begin{gathered}
\bar{x}(t)=\frac{\boldsymbol{x}(t)}{\sqrt{\alpha(t)}} \\
\sigma(t)=\sqrt{\frac{1-\alpha(t)}{\alpha(t)}} .
\end{gathered}\)
This also means that:
\(\begin{aligned}
x(t) &amp; =\frac{\bar{x}(t)}{\sqrt{\sigma^2(t)+1}} \\
\alpha(t) &amp; =\frac{1}{1+\sigma^2(t)},
\end{aligned}\)
which establishes an bijection between $(\boldsymbol{x}, \alpha)$ and $(\overline{\boldsymbol{x}}, \sigma)$. From Equation (4) we have (note that $\alpha(0)=1)$ :
\(\frac{\boldsymbol{x}(t)}{\sqrt{\alpha(t)}}=\frac{\boldsymbol{x}(0)}{\sqrt{\alpha(0)}}+\sqrt{\frac{1-\alpha(t)}{\alpha(t)}} \epsilon, \quad \epsilon \sim \mathcal{N}(0, \boldsymbol{I})\)
which can be reparametrized into a form that is consistent with VE-SDE:
\(\overline{\boldsymbol{x}}(t)=\overline{\boldsymbol{x}}(0)+\sigma(t) \epsilon .\)
Now, we derive the ODE forms for both DDIM and VE-SDE and show that they are equivalent.</p>
</blockquote>

<p>In the continuous case, $\sigma$ and $\boldsymbol{x}$ are functions of $t$, where $\sigma: \mathbb{R}<em>{\geq 0} \rightarrow \mathbb{R}</em>{\geq 0}$ is continuous, increasing with $\sigma(0)=0$. Equation (13) with can be treated as a Euler method over the following ODE:
\(\mathrm{d} \overline{\boldsymbol{x}}(t)=\epsilon_\theta^{(t)}\left(\frac{\overline{\boldsymbol{x}}(t)}{\sqrt{\sigma^2+1}}\right) \mathrm{d} \sigma(t) \tag {14}\)
where the initial conditions is $\boldsymbol{x}(T) \sim \mathcal{N}(0, \sigma(T))$ for a very large $\sigma(T)$ (which corresponds to the case of $\alpha \approx 0)$. This suggests that with enough discretization steps, the we can also reverse the generation process (going from $t=0$ to $T$ ), <strong>which encodes $\boldsymbol{x}_0$ to $\boldsymbol{x}_T$ and simulates the reverse of the ODE in Eq. (14).</strong> This suggests that unlike DDPM, we can use DDIM to obtain encodings of the observations (as the form of $\boldsymbol{x}_T$ ), which might be useful for other downstream applications that requires latent representations of a model.</p>

<p>Equation (13)  which is equivalent to:
\(\overline{\boldsymbol{x}}(t-\Delta t)=\overline{\boldsymbol{x}}(t)+(\sigma(t-\Delta t)-\sigma(t)) \cdot \epsilon_\theta^{(t)}(\boldsymbol{x}(t))\)
Divide both sides by $(-\Delta t)$ and as $\Delta t \rightarrow 0$, we have:
\(\frac{\mathrm{d} \bar{x}(t)}{\mathrm{d} t}=\frac{\mathrm{d} \sigma(t)}{\mathrm{d} t} \epsilon_\theta^{(t)}\left(\frac{\bar{x}(t)}{\sqrt{\sigma^2(t)+1}}\right) \tag {45}\)
which is exactly what we have in Equation (14).</p>

<p>We note that for the optimal model, $\epsilon_\theta^{(t)}$ is a minimizer: ==这个是我们前面训练的目标，请记住$J = \mathbb{E}<em>{t \sim [1, T], \mathbf{x}_0, \boldsymbol{\epsilon}_t} \Big[|\boldsymbol{\epsilon}_t - \boldsymbol{\epsilon}</em>\theta(\sqrt{\bar{\alpha}_t}\mathbf{x}_0 + \sqrt{1 - \bar{\alpha}_t}\boldsymbol{\epsilon}_t, t)|^2 \Big]$==
\(\epsilon_\theta^{(t)}=\underset{f_t}{\arg \min } \mathbb{E}_{\boldsymbol{x}(0) \sim q(\boldsymbol{x}), \epsilon \sim \mathcal{N}(0, \boldsymbol{I})}\left[\left\|f_t(\boldsymbol{x}(t))-\epsilon\right\|_2^2\right]\)
where $x(t)=\sqrt{\alpha(t)} x(t)+\sqrt{1-\alpha(t)} \epsilon$.</p>

<h5 id="ode-form-for-ve-sde-define"><strong>ODE form for VE-SDE Define</strong></h5>

<p>$p_t(\overline{\boldsymbol{x}})$ as the data distribution perturbed with $\sigma^2(t)$ variance Gaussian noise. <strong>The probability flow for VE-SDE</strong> is defined as Song et al. (2020) (<em>Score-based generative modeling through stochastic differential equations)</em>:
\(\mathrm{d} \overline{\boldsymbol{x}}=-\frac{1}{2} g(t)^2 \nabla_{\overline{\boldsymbol{x}}} \log p_t(\overline{\boldsymbol{x}}) \mathrm{d} t\)
==where $g(t)=\sqrt{\frac{\mathrm{d} \sigma^2(t)}{\mathrm{d} t}}$ is the diffusion coefficient, and $\nabla_{\overline{\boldsymbol{x}}} \log p_t(\overline{\boldsymbol{x}})$ is the score of $p_t$.==</p>

<p>The $\sigma(t)$-perturbed score function $\nabla_{\bar{x}} \log p_t(\overline{\boldsymbol{x}})$ is also a minimizer (from denoising score matching (Vincent, 2011)): ==不知道如何推导出这个，也需要看下这里的这篇论文？==
\(\nabla_{\overline{\boldsymbol{x}}} \log p_t=\underset{g_t}{\arg \min } \mathbb{E}_{\boldsymbol{x}(0) \sim q(\boldsymbol{x}), \epsilon \sim \mathcal{N}(0, \boldsymbol{I})}\left[\left\|g_t(\overline{\boldsymbol{x}})+\epsilon / \sigma(t)\right\|_2^2\right] \tag {48}\)
where $\overline{\boldsymbol{x}}(t)=\overline{\boldsymbol{x}}(t)+\sigma(t) \epsilon$.
Since there is an equivalence between $x(t)$ and $\overline{\boldsymbol{x}}(t)$, we have the following relationship:
\(\nabla_{\overline{\boldsymbol{x}}} \log p_t(\overline{\boldsymbol{x}})=-\frac{\epsilon_\theta^{(t)}\left(\frac{\overline{\boldsymbol{x}}(t)}{\sqrt{\sigma^2(t)+1}}\right)}{\sigma(t)} \tag{49}\)
==不过因为我们知道:== 
\(\mathbf{s}_\theta\left(\mathbf{x}_t, t\right) \approx \nabla_{\mathbf{x}_t} \log q\left(\mathbf{x}_t\right)=\mathbb{E}_{q\left(\mathbf{x}_0\right)}\left[\nabla_{\mathbf{x}_t} q\left(\mathbf{x}_t \mid \mathbf{x}_0\right)\right]=\mathbb{E}_{q\left(\mathbf{x}_0\right)}\left[-\frac{\epsilon_\theta\left(\mathbf{x}_t, t\right)}{\sqrt{1-\bar{\alpha}_t}}\right]=-\frac{\epsilon_\theta\left(\mathbf{x}_t, t\right)}{\sqrt{1-\bar{\alpha}_t}}\)
from Equation (46) and Equation (48). Plug Equation (49) and definition of $g(t)$ in Equation (47), we have:
\(\mathrm{d} \overline{\boldsymbol{x}}(t)=\frac{1}{2} \frac{\mathrm{d} \sigma^2(t)}{\mathrm{d} t} \frac{\epsilon_\theta^{(t)}\left(\frac{\overline{\boldsymbol{x}}(t)}{\sqrt{\sigma^2(t)+1}}\right)}{\sigma(t)} \mathrm{d} t,\)
and we have the following by rearranging terms:
\(\frac{\mathrm{d} \overline{\boldsymbol{x}}(t)}{\mathrm{d} t}=\frac{\mathrm{d} \sigma(t)}{\mathrm{d} t} \epsilon_\theta^{(t)}\left(\frac{\overline{\boldsymbol{x}}(t)}{\sqrt{\sigma^2(t)+1}}\right)\)
which is equivalent to Equation (45). In both cases the initial conditions are $\overline{\boldsymbol{x}}(T) \sim \mathcal{N}\left(\mathbf{0}, \sigma^2(T) \boldsymbol{I}\right)$,</p>

<p>so the resulting ODEs are identical. ==也就是说从ODE推导的和从VE-SDE推导的结果是一致的，也即是说DDIM也符合统一框架==</p>

<h5 id="ddim-reverse-sample用于反向-ode-加噪"><strong>ddim reverse sample用于反向 ODE 加噪</strong></h5>

\[\frac{x_{t-1}}{\sqrt{\bar{\alpha}_{t-1}}}=\frac{x_t}{\sqrt{\bar{\alpha}_t}}-\frac{\sqrt{1-\bar{\alpha}_t}}{\sqrt{\bar{\alpha}_t}} \epsilon_\theta^{(t)}+\frac{\sqrt{1-\bar{\alpha}_{t-1}}}{\sqrt{\bar{\alpha}_{t-1}}} \epsilon_\theta^{(t)}\left(\boldsymbol{x}_t\right)\]

<p>当 $\mathrm{t}$ 足够大时可以看做
\(\frac{\boldsymbol{x}_{t-\Delta t}}{\sqrt{\bar{\alpha}_{t-\Delta t}}}=\frac{x_t}{\sqrt{\bar{\alpha}_t}}+\left(\sqrt{\frac{1-\bar{\alpha}_{t-\Delta t}}{\bar{\alpha}_{t-\Delta t}}}-\sqrt{\frac{1-\bar{\alpha}_t}{\bar{\alpha}_t}}\right) \epsilon_\theta^{(t)}\left(\boldsymbol{x}_t\right)\)
而后进行换元, 令 $\sigma=(\sqrt{1-\bar{\alpha}} / \sqrt{\bar{\alpha}}), \bar{x}=x / \sqrt{\bar{\alpha}}$, 带入得到:
\(\mathrm{d} \overline{\boldsymbol{x}}(t)=\epsilon_\theta^{(t)}\left(\frac{\bar{x}(t)}{\sqrt{\sigma^2+1}}\right) \mathrm{d} \sigma(t)\)
于是, 基于这个 ODE 结果, 能通过 $\bar{x}(t)+d \bar{x}(t)$ 计算得到 $\bar{x}(t+1)$ 与 $x_{t+1}$</p>

<p>根据 github - openai/improved-diffusion๔, 其实现根据 ODE 反向采样的方式为：直接根据公式 (5) 进行变换, 把 $t-1$ 换成 $t+1$ :</p>

<p>\(\boldsymbol{x}_{t+1}=\sqrt{\bar{\alpha}_{t+1}} \underbrace{\left(\frac{\boldsymbol{x}_t-\sqrt{1-\bar{\alpha}_t} \epsilon_\theta^{(t)}\left(\boldsymbol{x}_t\right)}{\sqrt{\bar{\alpha}_t}}\right)}_{\text {"predicted } \boldsymbol{x}_0 "}+\underbrace{\sqrt{1-\bar{\alpha}_{t+1}} \cdot \epsilon_\theta^{(t)}\left(\boldsymbol{x}_t\right)}_{\text {"direction pointing to } x_t "}+\underbrace{\sigma_t \epsilon_t}_{\text {random noise }}\)
而参考公式 (11) 的推导过程, (12) 可以看成下面这种形式:
\(\frac{x_{t+\Delta t}}{\sqrt{\bar{\alpha}_{t+\Delta t}}}=\frac{x_t}{\sqrt{\bar{\alpha}_t}}+\left(\sqrt{\frac{1-\bar{\alpha}_{t+\Delta t}}{\bar{\alpha}_{t+\Delta t}}}-\sqrt{\frac{1-\bar{\alpha}_t}{\bar{\alpha}_t}}\right) \epsilon_\theta^{(t)}\left(\boldsymbol{x}_t\right)\)</p>

<h2 id="48-learning-a-covariance-matrix-parameterization-of-reverse-process-variance-">4.8 Learning a Covariance matrix (Parameterization of reverse process variance )</h2>

<ul>
  <li>DDPM authors said that it’s better to use a fixed covariance matrix $\boldsymbol{\Sigma}<em>\theta\left(\mathbf{x}_t, t\right)=\sigma_t^2 \mathbf{I}$ where $\sigma_t^2=\beta_t$ or $\sigma_t^2=\tilde{\beta}_t=\frac{1-\bar{\alpha}</em>{t-1}}{1-\bar{\alpha}_t} \beta_t$.</li>
  <li>The intuition is that covariance does not contribute as significantly as the mean does to the learned conditional distributions during the reverse process</li>
  <li>However, it can still help us improve log-likelihood!</li>
  <li>So, <a href="https://arxiv.org/abs/2102.09672">Nichol &amp; Dhariwal (2021)</a> propose to learn $\boldsymbol{\Sigma}_\theta(\mathbf{x}_t, t)$ as an interpolation between $β_t$ and $\tilde{\beta}_t$ by model predicting a mixing vector v :</li>
</ul>

<p>\(\Sigma_\theta\left(x_t, t\right)=\exp \left(v \log \beta_t+(1-v) \log \tilde{\beta}_t\right)\)
This modification leads to better likelihood estimates while maintaining image quality!</p>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/improved-DDPM-nll.png" alt="img" style="zoom:33%;" /></p>

<h2 id="49-ddpm-vs-ddim">4.9 DDPM vs DDIM</h2>

<table>
  <thead>
    <tr>
      <th style="text-align: left"> </th>
      <th>DDPM</th>
      <th>DDIM</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">forward</td>
      <td>\(q(\mathbf{x}_t \vert \mathbf{x}_{t-1}) = \mathcal{N}(\mathbf{x}_t; \sqrt{1 - \beta_t} \mathbf{x}_{t-1}, \beta_t\mathbf{I}) \quad \\q(\mathbf{x}_{1:T} \vert \mathbf{x}_0) = \prod^T_{t=1} q(\mathbf{x}_t \vert \mathbf{x}_{t-1}) \\q\left(\mathbf{x}_t \mid \mathbf{x}_0\right)=\mathcal{N}\left(\mathbf{x}_t ; \sqrt{\alpha_t} \mathbf{x}_0,\left(1-\alpha_t\right) \mathbf{I}\right)\)</td>
      <td>$\int p\left(x_{t-1} \mid x_t, x_0\right) p\left(x_t \mid x_0\right) d x_t=p\left(x_{t-1} \mid x_0\right) \tag {3}$ and<br /> \(q\left(\mathbf{x}_t \mid \mathbf{x}_0\right)=\mathcal{N}\left(\mathbf{x}_t ; \sqrt{\alpha_t} \mathbf{x}_0,\left(1-\alpha_t\right) \mathbf{I}\right) \\ q\left(\mathbf{x}_{t-1} \mid \mathbf{x}_0\right)=\mathcal{N}\left(\mathbf{x}_{t-1} ; \sqrt{\alpha_{t-1}} \mathbf{x}_0,\left(1-\alpha_{t-1}\right) \mathbf{I}\right)\)</td>
    </tr>
    <tr>
      <td style="text-align: left">reverse</td>
      <td>$q(\mathbf{x}<em>{t-1} \vert \mathbf{x}_t, \mathbf{x}_0) = \mathcal{N}(\mathbf{x}</em>{t-1}; \color{blue}{\tilde{\boldsymbol{\mu}}}(\mathbf{x}_t, \mathbf{x}_0), \color{red}{\tilde{\beta}_t} \mathbf{I})$  <br />\(\begin{aligned} \tilde{\boldsymbol{\mu}}(\mathbf{x}_t, \mathbf{x}_0) &amp;= \frac{\sqrt{\alpha_t}(1 - \bar{\alpha}_{t-1})}{1 - \bar{\alpha}_t} \mathbf{x}_t + \frac{\sqrt{\bar{\alpha}_{t-1}}\beta_t}{1 - \bar{\alpha}_t} \mathbf{x}_0\\ \tilde{\beta}_t &amp;= \frac{1 - \bar{\alpha}_{t-1}}{1 - \bar{\alpha}_t} \cdot \beta_t \end{aligned}\)</td>
      <td>\(q_{\sigma, \tau}(\mathbf{x}_{\tau_{i-1}} \vert \mathbf{x}_{\tau_t}, \mathbf{x}_0)= \mathcal{N}(\mathbf{x}_{\tau_{i-1}}; \sqrt{\bar{\alpha}_{t-1}}\mathbf{x}_0 + \sqrt{1 - \bar{\alpha}_{t-1} - \sigma_t^2} \frac{\mathbf{x}_{\tau_i} - \sqrt{\bar{\alpha}_t}\mathbf{x}_0}{\sqrt{1 - \bar{\alpha}_t}}, \sigma_t^2 \mathbf{I}) \tag{7-DDIM}\)</td>
    </tr>
    <tr>
      <td style="text-align: left">sampling</td>
      <td>因为 \(\mathbf{x}_0 = \frac{1}{\sqrt{\bar{\alpha}_t}}(\mathbf{x}_t - \sqrt{1 - \bar{\alpha}_t}\boldsymbol{\epsilon}_t)\) 所以 <br /> \(\begin{aligned} \boldsymbol{\mu}_\theta(\mathbf{x}_t, t) &amp;= \color{cyan}{\frac{1}{\sqrt{\alpha_t}} \Big( \mathbf{x}_t - \frac{1 - \alpha_t}{\sqrt{1 - \bar{\alpha}_t}} \boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t) \Big)} \\ \text{Thus }\mathbf{x}_{t-1} &amp;= \mathcal{N}(\mathbf{x}_{t-1}; \frac{1}{\sqrt{\alpha_t}} \Big( \mathbf{x}_t - \frac{1 - \alpha_t}{\sqrt{1 - \bar{\alpha}_t}} \boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t) \Big), \boldsymbol{\Sigma}_\theta(\mathbf{x}_t, t)) \end{aligned}\)</td>
      <td>因为 $f_\theta^{(t)}\left(\boldsymbol{x}<em>t\right):=\left(\boldsymbol{x}_t-\sqrt{1-\alpha_t} \cdot \epsilon</em>\theta^{(t)}\left(\boldsymbol{x}_t\right)\right) / \sqrt{\alpha_t} \tag {9-DDIM}$  <br />where we have \(q_\sigma\left(\boldsymbol{x}_{t-1} \mid \boldsymbol{x}_t \right) \approx q_\sigma\left(\boldsymbol{x}_{t-1} \mid \boldsymbol{x}_t, f_\theta^{(t)}\left(\boldsymbol{x}_t\right)\right)\) 所以 \(\text {DENOISING DIFFUSION IMPLICIT MODELS }\\ \boldsymbol{x}_{t-1}=\sqrt{\alpha_{t-1}} \underbrace{\left(\frac{\boldsymbol{x}_t-\sqrt{1-\alpha_t} \epsilon_\theta^{(t)}\left(\boldsymbol{x}_t\right)}{\sqrt{\alpha_t}}\right)}_{\text {"predicted } \boldsymbol{x}_0 \text { " }}+\underbrace{\sqrt{1-\alpha_{t-1}-\sigma_t^2} \cdot \epsilon_\theta^{(t)}\left(\boldsymbol{x}_t\right)}_{\text {“direction pointing to } \boldsymbol{x}_t \text { " }}+\underbrace{\sigma_t \epsilon_t}_{\text {random noise }} \tag {12}\)<br />或者 <br />\(\tilde{\boldsymbol{\mu}}\left(\mathbf{x}_t \right) &amp;=\frac{1}{\alpha_t}\left(\boldsymbol{x}_t-\left(\bar{\beta}_t-\alpha_t \sqrt{\bar{\beta}_{t-1}^2-\sigma_t^2}\right) \boldsymbol{\epsilon}_{\boldsymbol{\theta}}\left(\boldsymbol{x}_t, t\right)\right) \\ &amp; \text { 其中 } \alpha_t=\frac{\bar{\alpha} t}{\bar{\alpha}_{t-1}}\)</td>
    </tr>
    <tr>
      <td style="text-align: left">training loss</td>
      <td>\(\begin{aligned} loss &amp;= - \log p_\theta(\mathbf{x}_0) = ELBO  \\ &amp;= |\boldsymbol{\epsilon}_t - \boldsymbol{\epsilon}_\theta(\sqrt{\bar{\alpha}_t}\mathbf{x}_0 + \sqrt{1 - \bar{\alpha}_t}\boldsymbol{\epsilon}_t, t)|^2 \end{aligned}\)</td>
      <td>\(\begin{aligned} J_\sigma\left(\epsilon_\theta\right)&amp;:=\mathbb{E}_{\boldsymbol{x}_{0: T} \sim q_\sigma\left(\boldsymbol{x}_{0: T}\right)}\left[\log q_\sigma\left(\boldsymbol{x}_{1: T} \mid \boldsymbol{x}_0\right)-\log p_\theta\left(\boldsymbol{x}_{0: T}\right)\right] \\ &amp;= \mathbb{E}_{\boldsymbol{x}_{0: T} \sim q_\sigma\left(\boldsymbol{x}_{0: T}\right)}\left[\log q_\sigma\left(\boldsymbol{x}_T \mid \boldsymbol{x}_0\right)+\sum_{t=2}^T \log  q_\sigma\left(\boldsymbol{x}_{t-1} \mid \boldsymbol{x}_t, \boldsymbol{x}_0\right)-\sum_{t=1}^T \log p_\theta^{(t)}\left(\boldsymbol{x}_{t-1} \mid \boldsymbol{x}_t\right)-\log p_\theta\left(\boldsymbol{x}_T\right)\right] \end{aligned}\)</td>
    </tr>
    <tr>
      <td style="text-align: left">score</td>
      <td>$\mathbf{s}<em>\theta\left(\mathbf{x}_t, t\right) \approx \nabla</em>{\mathbf{x}<em>t} \log q\left(\mathbf{x}_t\right)=\mathbb{E}</em>{q\left(\mathbf{x}<em>0\right)}\left[\nabla</em>{\mathbf{x}<em>t} q\left(\mathbf{x}_t \mid \mathbf{x}_0\right)\right] \ =\mathbb{E}</em>{q\left(\mathbf{x}<em>0\right)}\left[-\frac{\epsilon</em>\theta\left(\mathbf{x}<em>t, t\right)}{\sqrt{1-\bar{\alpha}_t}}\right]=-\frac{\epsilon</em>\theta\left(\mathbf{x}_t, t\right)}{\sqrt{1-\bar{\alpha}_t}}$ <br /> where $q\left(\mathbf{x}_t \mid \mathbf{x}_0\right) \sim \mathcal{N}\left(\sqrt{\bar{\alpha}_t} \mathbf{x}_0,\left(1-\bar{\alpha}_t\right) \mathbf{I}\right)$</td>
      <td>$\nabla_{\overline{\boldsymbol{x}}} \log p_t(\overline{\boldsymbol{x}})=-\frac{\epsilon_\theta^{(t)}\left(\frac{\overline{\boldsymbol{x}}(t)}{\sqrt{\sigma^2(t)+1}}\right)}{\sigma(t)} \tag{49}$ , where $\sigma(t)=\sqrt{\frac{1-\alpha(t)}{\alpha(t)}}$</td>
    </tr>
    <tr>
      <td style="text-align: left"> </td>
      <td>$X_{t+1}=X_t+d t \nabla \log p\left(X_t\right)+\mathcal{N}(0,2 d t)$ <br />$\begin{equation}   x_{n+1} = x_n + \nabla \log p(x_n) \epsilon + \sigma \sqrt{2 \epsilon}\ z\end{equation}$</td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: left">Classifier Guided</td>
      <td>$\nabla_x \log p_\gamma(x \mid y) = \nabla_x \log p(x) + \gamma \nabla_x \log p(y \mid x) .$</td>
      <td>\(\begin{aligned} \nabla_{\mathbf{x}_t} \log q\left(\mathbf{x}_t, y\right) &amp; =\nabla_{\mathbf{x}_t} \log q\left(\mathbf{x}_t\right)+\nabla_{\mathbf{x}_t} \log q\left(y \mid \mathbf{x}_t\right) \\&amp; \approx-\frac{1}{\sqrt{1-\bar{\alpha}_t}} \epsilon_\theta\left(\mathbf{x}_t, t\right)+\nabla_{\mathbf{x}_t} \log f_\phi\left(y \mid \mathbf{x}_t\right) \\ &amp; =-\frac{1}{\sqrt{1-\bar{\alpha}_t}}\left(\epsilon_\theta\left(\mathbf{x}_t, t\right)-\sqrt{1-\bar{\alpha}_t} \nabla_{\mathbf{x}_t} \log f_\phi\left(y \mid \mathbf{x}_t\right)\right) \\ &amp;= -\frac{1}{\sqrt{1-\bar{\alpha}_t}} \bar{\epsilon}_\theta\left(\mathbf{x}_t, t\right) \end{aligned}\)<br />where $\bar{\epsilon}<em>\theta\left(\mathbf{x}_t, t\right)=\epsilon</em>\theta\left(x_t, t\right)-\sqrt{1-\bar{\alpha}<em>t} \nabla</em>{\mathbf{x}<em>t} \log f</em>\phi\left(y \mid \mathbf{x}_t\right)$</td>
    </tr>
  </tbody>
</table>

<h2 id="410-latent-diffusion-models-ldm-rombach--blattmann-et-al-2022">4.10 Latent diffusion models (<strong>LDM</strong>; <a href="https://arxiv.org/abs/2112.10752">Rombach &amp; Blattmann, et al. 2022</a>)</h2>

<p><strong><a href="https://arxiv.org/abs/2112.10752">Stable Diffusion (2021)</a> differs from the previous diffusion models by working in the latent space instead of pixel space.</strong> It first compresses images via a variational autoencoder (VAE) into a more efficient and lower dimensional latent embedding. Next, the diffusion model learns to generate latent (i.e., compressed) representations of images which are then decoded into images via the VAE decoder.</p>

<p>Similar to DALL·E and its visual codebook, <strong>latent space is motivated by the observation that most pixels in an image are imperceptible details that are semantically meaningless</strong>. However, because regular diffusion models are trained and evaluated in the pixel space, it leads to unnecessary computation and thus costly training and inference. Thus, the paper proposes diffusion on compressed images where the imperceptible details are excluded.</p>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/stable-diffusion.jpg" alt="Using a VAE to encode images from pixel space to latent space (left)" style="zoom:50%;" /></p>

<p>In Stable Diffusion, the VAE encodes noised images (via $\mathcal{E}$ ) into a low-dimensional latent representation which is fed into the UNet. It then decodes UNet-generated latent representations (via $\mathcal{D}$ ) into human-understandable images. The VAE has a reduction factor of 8 , where the original image pixel space of $3 \times 512 \times 512$ is encoded into latent space of $6 \times 64 \times 64$, thus requiring $1 / 8 \times 1 / 8=1 / 64$ of the memory.  During sampling, only the VAE decoder is needed.</p>

<p>Stable Diffusion uses the CLIP text encoder. (But as Imagen has demonstrated, probably any sufficiently large text-only LLM can be used).</p>

<p>Latent diffusion leads to faster training and sampling because we’re now working in the latent—instead of pixel—space. This leads to lower cost which leads to more experiments. The lower memory requirement also allows sampling run on consumer-grade laptops, putting text-to-image generation in the hands of regular hackers.</p>

<blockquote>
  <p><strong>Remodel the Diffusion models:</strong>  (High-Resolution Image Synthesis with Latent Diffusion Models,  Appendix B. Detailed Information on Denoising Diffusion Models)</p>

  <p>Diffusion models can be specified in terms of a signal-to-noise ratio $\operatorname{SNR}(t)=\frac{\alpha_t^2}{\sigma_t^2}$ consisting of sequences $\left(\alpha_t\right)<em>{t=1}^T$ and $\left(\sigma_t\right)</em>{t=1}^T$ which, starting from a data sample $x_0$, define a forward diffusion process $q$ as
\(q\left(x_t \mid x_0\right)=\mathcal{N}\left(x_t \mid \alpha_t x_0, \sigma_t^2 \mathbb{I}\right)\)
with the Markov structure for $s&lt;t$ :
\(\begin{aligned}
q\left(x_t \mid x_s\right) &amp; =\mathcal{N}\left(x_t \mid \alpha_{t \mid s} x_s, \sigma_{t \mid s}^2 \mathbb{I}\right) \\
\alpha_{t \mid s} &amp; =\frac{\alpha_t}{\alpha_s} \\
\sigma_{t \mid s}^2 &amp; =\sigma_t^2-\alpha_{t \mid s}^2 \sigma_s^2
\end{aligned}\)
Denoising diffusion models are generative models $p\left(x_0\right)$ which revert this process with a similar Markov structure running backward in time, i.e. they are specified as
\(p\left(x_0\right)=\int_z p\left(x_T\right) \prod_{t=1}^T p\left(x_{t-1} \mid x_t\right)\)
The evidence lower bound (ELBO) associated with this model then decomposes over the discrete time steps as
\(-\log p\left(x_0\right) \leq \mathbb{K} \mathbb{L}\left(q\left(x_T \mid x_0\right) \mid p\left(x_T\right)\right)+\sum_{t=1}^T \mathbb{E}_{q\left(x_t \mid x_0\right)} \mathbb{K} \mathbb{L}\left(q\left(x_{t-1} \mid x_t, x_0\right) \mid p\left(x_{t-1} \mid x_t\right)\right)\)</p>
  <blockquote>
    <p>comparing to DDPM: 
\(\begin{aligned}
-\log p\left(x_0\right) &amp;\leq \mathbb{E}_q \Big[ \log \frac{q(\mathbf{x}_{1:T}\vert\mathbf{x}_0)}{p_\theta(\mathbf{x}_{0:T})} \Big] \\
&amp; = 
\mathbb{E}_q [\underbrace{D_\text{KL}(q(\mathbf{x}_T \vert \mathbf{x}_0) \parallel p_\theta(\mathbf{x}_T))}_{L_T} + \sum_{t=2}^T \underbrace{D_\text{KL}(q(\mathbf{x}_{t-1} \vert \mathbf{x}_t, \mathbf{x}_0) \parallel p_\theta(\mathbf{x}_{t-1} \vert\mathbf{x}_t))}_{L_{t-1}} \underbrace{- \log p_\theta(\mathbf{x}_0 \vert \mathbf{x}_1)}_{L_0}]
\end{aligned}\)</p>
  </blockquote>

  <p>The prior $p\left(x_T\right)$ is typically choose as a standard normal distribution and the first term of the ELBO then depends only on the final signal-to-noise ratio $\operatorname{SNR}(T)$. To minimize the remaining terms, a common choice to parameterize $p\left(x_{t-1} \mid x_t\right)$ is to specify it in terms of the true posterior $q\left(x_{t-1} \mid x_t, x_0\right)$ but with the unknown $x_0$ replaced by an estimate $x_\theta\left(x_t, t\right)$ based on the current step $x_t$. This gives (<strong>Variational diffusion models</strong>)
\(\begin{aligned}
p\left(x_{t-1} \mid x_t\right) &amp; :=q\left(x_{t-1} \mid x_t, x_\theta\left(x_t, t\right)\right) \\
&amp; =\mathcal{N}\left(x_{t-1} \mid \mu_\theta\left(x_t, t\right), \sigma_{t \mid t-1}^2 \frac{\sigma_{t-1}^2}{\sigma_t^2} \mathbb{I}\right),
\end{aligned}\)
where the mean can be expressed as
\(\mu_\theta\left(x_t, t\right)=\frac{\alpha_{t \mid t-1} \sigma_{t-1}^2}{\sigma_t^2} x_t+\frac{\alpha_{t-1} \sigma_{t \mid t-1}^2}{\sigma_t^2} x_\theta\left(x_t, t\right) .\)
In this case, the sum of the ELBO simplify to
\(\sum_{t=1}^T \mathbb{E}_{q\left(x_t \mid x_0\right)} \mathbb{K} \mathbb{L}\left(q\left(x_{t-1} \mid x_t, x_0\right) \mid p\left(x_{t-1}\right)=\sum_{t=1}^T \mathbb{E}_{\mathcal{N}(\epsilon \mid 0, \mathbb{I})} \frac{1}{2}(\operatorname{SNR}(t-1)-\operatorname{SNR}(t))\left\|x_0-x_\theta\left(\alpha_t x_0+\sigma_t \epsilon, t\right)\right\|^2\right.\)
Following [30], we use the reparameterization
\(\epsilon_\theta\left(x_t, t\right)=\left(x_t-\alpha_t x_\theta\left(x_t, t\right)\right) / \sigma_t\)
to express the reconstruction term as a denoising objective,
\(\left\|x_0-x_\theta\left(\alpha_t x_0+\sigma_t \epsilon, t\right)\right\|^2=\frac{\sigma_t^2}{\alpha_t^2}\left\|\epsilon-\epsilon_\theta\left(\alpha_t x_0+\sigma_t \epsilon, t\right)\right\|^2\)
and the reweighting, which assigns each of the terms the same weight and results in Eq. (1).</p>
</blockquote>

<h3 id="general">General</h3>

<p>runs the diffusion process in the latent space instead of pixel space, making training cost lower and inference speed faster. It is motivated by the observation that most bits of an image contribute to perceptual details and the semantic and conceptual composition still remains after aggressive compression.</p>

<p>LDM loosely decomposes the perceptual compression and semantic compression with generative modeling learning by <strong>first trimming off pixel-level redundancy with autoencoder</strong> and <strong>then manipulate/generate semantic concepts with diffusion process on learned latent</strong>.</p>

<blockquote>
  <p>Contribution</p>

  <ul>
    <li>Diffusion model是一种likelihood-based的模型，相比GAN可以取得更好的生成效果。然而该 模型是一种自回归模型，需要反复迭代计算，因而训练和推理都十分昂贵。本文提出一种 diffusion的过程改为在latent space上做的方法，从而大大减少计算复杂度，同时也能达到十分 不错的生成效果。（”democratizing” research on DMs)，在unconditional image synthesis, inpainting, super-resolution都能表现不错</li>
    <li>相比于其它进行压缩的方法，本文的方法可以生成更细致的图像，并且在高分辨率 (风景图之类 的，最高达 $1024^2 p x$ 都无压力) 的生成也表现得很好。</li>
    <li>提出了cross-attention的方法来实现多模态训练，使得class-condition, text-to-image， layout-to-image也可以实现。</li>
  </ul>
</blockquote>

<p>The perceptual compression process relies on an autoencoder model.</p>

<ul>
  <li>
    <p>By using the trained encoder <strong>*E*</strong>, we can encode the full-sized image into lower dimensional latent data (compressed data).   An encoder $\mathcal{E}$ is used to compress the input image $\mathbf{x} \in \mathbb{R}^{H \times W \times 3}$ to a smaller $2 \mathrm{D}$ latent vector $\mathbf{z}=\mathcal{E}(\mathbf{x}) \in \mathbb{R}^{h \times w \times c}$, where the downsampling rate $f=H / h=W / w=2^m, m \in \mathbb{N}$.</p>

    <p>After encoding the images into latent data, the forward and reverse diffusion processes will be done in the latent space.</p>

    <p><img src="/assets/BERTGPTDiffusion%20Research.assets/1mSHOIu_xDdPAF7-Q5quJmw.png" alt="Autoencoder" /></p>
  </li>
  <li>
    <p>By using the trained decoder <strong>*D*</strong>, we can decode the latent data back into an image.   an decoder $\mathcal{D}$ reconstructs the images from the latent vector, $\tilde{\mathbf{x}}=\mathcal{D}(\mathbf{z})$. The paper explored two types of regularization in autoencoder training to avoid arbitrarily high-variance in the latent spaces.</p>

    <ul>
      <li>
        <p>KL-reg: A small KL penalty towards a standard normal distribution over the learned latent, similar to VAE.</p>
      </li>
      <li>
        <p>VQ-reg: Uses a vector quantization layer within the decoder, like VQVAE but the quantization layer is absorbed by the decoder.</p>
      </li>
    </ul>
  </li>
</ul>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/1KgT9m7wgbxyCWqmPqETCyQ.png" alt="Overview of the Stable Diffusion model" /></p>

<ol>
  <li>Forward Diffusion Process → add noise to the <strong>latent data</strong>.</li>
  <li>Reverse Diffusion Process → remove noise from the <strong>latent data</strong>.</li>
</ol>

<p>The diffusion and denoising processes happen on the latent vector $\mathbf{z}$. The denoising model is a timeconditioned U-Net, augmented with the cross-attention mechanism to handle flexible conditioning information for image generation (e.g. class labels, semantic maps, blurred variants of an image). The design is equivalent to fuse representation of different modality into the model with cross-attention mechanism. Each type of conditioning information is paired with a domain-specific encoder $\boldsymbol{\tau}<em>{\boldsymbol{\theta}}$ to project the conditioning input $y$ to an intermediate representation that can be mapped into cross-attention component, $\tau</em>\theta(y) \in \mathbb{R}^{M \times d_\tau}$ :
\(\begin{aligned}
&amp; \text { Attention }(\mathbf{Q}, \mathbf{K}, \mathbf{V})=\operatorname{softmax}\left(\frac{\mathbf{Q} \mathbf{K}^{\top}}{\sqrt{d}}\right) \cdot \mathbf{V} \\
&amp; \text { where } \mathbf{Q}=\mathbf{W}_Q^{(i)} \cdot \varphi_i\left(\mathbf{z}_i\right), \mathbf{K}=\mathbf{W}_K^{(i)} \cdot \tau_\theta(y), \mathbf{V}=\mathbf{W}_V^{(i)} \cdot \tau_\theta(y) \\
&amp; \text { and } \mathbf{W}_Q^{(i)} \in \mathbb{R}^{d \times d_\epsilon^i}, \mathbf{W}_K^{(i)}, \mathbf{W}_V^{(i)} \in \mathbb{R}^{d \times d_\tau}, \varphi_i\left(\mathbf{z}_i\right) \in \mathbb{R}^{N \times d_\epsilon^i}, \tau_\theta(y) \in \mathbb{R}^{M \times d_\tau}
\end{aligned}\)</p>

<h3 id="conditioning">Conditioning</h3>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/1iruOz7EYpsibRGRNkpXpVg.png" alt="Overview of the conditioning mechanism" /></p>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/1IRTbG2rYv0IUH8HHAxWRrQ.png" alt="Conditioning mechanism details" /></p>

<p>The switch in the above diagram is used to control between different types of conditioning inputs:</p>

<ul>
  <li>For text inputs, they are first converted into embeddings (vectors) using a language model <strong>𝜏*θ*</strong> (e.g. BERT, CLIP), and then they are mapped into the U-Net via the (multi-head) <strong>*Attention(Q, K, V)*</strong> layer.</li>
  <li>For other spatially aligned inputs (e.g. semantic maps, images, inpainting), the conditioning can be done using concatenation.</li>
</ul>

<h3 id="training">Training</h3>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/1iA5bAAa68LWL3w0BmSK7MA.png" alt="Training objective for the Stable Diffusion model" /></p>

<p>The training objective (loss function) is pretty similar to the one in the pure diffusion model. The only changes are:</p>

<ul>
  <li>Input latent data $zₜ$ instead of the image $xₜ$.</li>
  <li>Added conditioning input $𝜏_θ(y)$ to the U-Net.</li>
</ul>

<h3 id="sampling">Sampling</h3>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/1UQ4fb9mBsEh_EvgKijyzWg.png" alt="Stable Diffusion sampling process (denoising)" /></p>

<blockquote>
  <p>Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding (arXiv:2205.11487v1)</p>

  <p>(1) 扩散过程 （latent variable diffusion)</p>

  <p>Diffusion models are latent variable models with latents $\mathbf{z}=\left{\mathbf{z}_t \mid t \in[0,1]\right}$ that obey a forward process $q(\mathbf{z} \mid \mathbf{x})$ starting at data $\mathbf{x} \sim p(\mathbf{x})$.</p>

  <ul>
    <li><strong>This forward process is a Gaussian process that satisfies the Markovian structure:</strong></li>
  </ul>

\[q\left(\mathbf{z}_t \mid \mathbf{x}\right)=\mathcal{N}\left(\mathbf{z}_t ; \alpha_t \mathbf{x}, \sigma_t^2 \mathbf{I}\right), \quad q\left(\mathbf{z}_t \mid \mathbf{z}_s\right)=\mathcal{N}\left(\mathbf{z}_t ;\left(\alpha_t / \alpha_s\right) \mathbf{z}_s, \sigma_{t \mid s}^2 \mathbf{I}\right)\]

  <p>where $0 \leq s&lt;t \leq 1, \sigma_{t \mid s}^2=\left(1-e^{\lambda_t-\lambda_s}\right) \sigma_t^2$, and $\alpha_t, \sigma_t$ specify a differentiable noise schedule whose $\log$ signal-to-noise-ratio, i.e., $\lambda_t=\log \left[\alpha_t^2 / \sigma_t^2\right]$, decreases with $t$ until $q\left(\mathbf{z}_1\right) \approx \mathcal{N}(\mathbf{0}, \mathbf{I})$.</p>

  <blockquote>
    <p>$\mathbf{z}<em>t=\alpha_t \mathbf{x}+\sigma_t \boldsymbol{\epsilon}</em>{\mathbf{1}}$ ，其中 $\boldsymbol{\epsilon} \sim \mathcal{N}(\mathbf{0}, \mathbf{I})$ 。
根据正向过程的定义可得： $\mathrm{z}<em>s=\alpha_s \mathbf{x}+\sigma_s \epsilon_2$ ，则 $\mathbf{x}=\frac{1}{\alpha_s}\left(\mathbf{z}_s-\sigma_s \epsilon_2\right)$ ，将 $\mathbf{x}$ 代入上式 得:
\(\mathbf{z}_t=\frac{\alpha_t}{\alpha_s}\left(\mathbf{z}_s-\sigma_s \epsilon_2\right)+\sigma_t \epsilon_1=\frac{\alpha_t}{\alpha_s} \mathbf{z}_s-\frac{\alpha_t \cdot \sigma_s}{\alpha_s} \epsilon_2+\sigma_t \epsilon_1=\frac{\alpha_t}{\alpha_s} \mathbf{z}_s+\sqrt{\sigma_t^2-\frac{\alpha_t^2 \cdot \sigma_s^2}{\alpha_s^2}} \cdot \epsilon\)
定义: $\sigma</em>{t \mid s}^2=\left(1-e^{\lambda_t-\lambda_s}\right) \sigma_t^2$ ，其中 $\lambda_t=\log \left[\alpha_t^2 / \sigma_t^2\right]$ ，则:
\(\mathbf{z}_t=\left(\alpha_t / \alpha_s\right) \mathbf{z}_s+\sqrt{\sigma_{t \mid s}^2} \cdot \epsilon\)
所以:
\(q\left(\mathbf{z}_t \mid \mathbf{x}\right)=\mathcal{N}\left(\mathbf{z}_t ; \alpha_t \mathbf{x}, \sigma_t^2 \mathbf{I}\right), \quad q\left(\mathbf{z}_t \mid \mathbf{z}_s\right)=\mathcal{N}\left(\mathbf{z}_t ;\left(\alpha_t / \alpha_s\right) \mathbf{z}_s, \sigma_{t \mid s}^2 \mathbf{I}\right)\)
式中， $0 \leq s&lt;t \leq 1, \sigma_{t \mid s}^2=\left(1-e^{\lambda_t-\lambda_s}\right) \sigma_t^2, \alpha_t, \sigma_t$ 表示可微噪声 schedule， $\lambda_t=\log \left[\alpha_t^2 / \sigma_t^2\right]$ 表示信噪比，其随着时间 $t$ 逐步降低，直到 $q\left(\mathbf{z}_1\right) \approx \mathcal{N}(\mathbf{0}, \mathbf{I})$ 。</p>

  </blockquote>

  <ul>
    <li>For generation, the diffusion model is learned to reverse this forward process. Learning to reverse the forward process can be reduced to learning to denoise $\mathbf{z}<em>t \sim q\left(\mathbf{z}_t \mid \mathbf{x}\right)$ into an estimate $\hat{\mathbf{x}}</em>\theta\left(\mathbf{z}<em>t, \lambda_t, \mathbf{c}\right) \approx \mathbf{x}$ for all $t$, where $\mathbf{c}$ is an optional conditioning signal (such as text embeddings or a low resolution image) drawn from the dataset jointly with $\mathbf{x}$. This is accomplished training $\hat{\mathbf{x}}</em>\theta$ using a weighted squared error loss</li>
  </ul>

\[\mathbb{E}_{\boldsymbol{\epsilon}, t}\left[w\left(\lambda_t\right)\left\|\hat{\mathbf{x}}_\theta\left(\mathbf{z}_t, \lambda_t, \mathbf{c}\right)-\mathbf{x}\right\|_2^2\right]\]

\[\text { where } t \sim \mathcal{U}([0,1]), \boldsymbol{\epsilon} \sim \mathcal{N}(\mathbf{0}, \mathbf{I}) \text {, and } \mathbf{z}_t=\alpha_t \mathbf{x}+\sigma_t \boldsymbol{\epsilon} \text {. }\]

  <p>This reduction of generation to denoising is justified as optimizing a weighted variational lower bound on the data log likelihood under the diffusion model, or as a form of denoising score matching $[72,65,28,35]$. We use the $\epsilon$ prediction parameterization, defined as $\hat{\mathbf{x}}<em>\theta\left(\mathbf{z}_t, \lambda_t, \mathbf{c}\right)=\left(\mathbf{z}_t-\sigma_t \epsilon</em>\theta\left(\mathbf{z}<em>t, \lambda_t, \mathbf{c}\right)\right) / \alpha_t$, and we impose a squared error loss on $\epsilon</em>\theta$ in $\epsilon$ space with $t$ sampled according to a cosine schedule [40]. This corresponds to a particular weighting $w\left(\lambda_t\right)$ and leads to a scaled score estimate $\epsilon_\theta\left(\mathbf{z}<em>t, \lambda_t, \mathbf{c}\right) \approx$ $-\sigma_t \nabla</em>{\mathbf{z}_t} \log p\left(\mathbf{z}_t \mid \mathbf{c}\right)$, where $p\left(\mathbf{z}_t \mid \mathbf{c}\right)$ is the true density of $\mathbf{z}_t$ given $\mathbf{c}$ under the forward process starting at $\mathrm{x} \sim p(\mathrm{x})[28,35,66]$. Related model designs include the work of [70, 32, 33].</p>

  <p>To sample from the diffusion model, we start at $\mathbf{z}<em>1 \sim \mathcal{N}(\mathbf{0}, \mathbf{I})$ and use the discrete time ancestral sampler [28] and DDIM [64] for certain models. DDIM follows the deterministic update rule
\(\mathbf{z}_s=\alpha_s \hat{\mathbf{x}}_\theta\left(\mathbf{z}_t, \lambda_t, \mathbf{c}\right)+\frac{\sigma_s}{\sigma_t}\left(\mathbf{z}_t-\alpha_t \hat{\mathbf{x}}_\theta\left(\mathbf{z}_t, \lambda_t, \mathbf{c}\right)\right)\)
where $s&lt;t$ follow a uniformly spaced sequence from 1 to 0 . The ancestral sampler arises from a reversed description of the forward process; noting that $q\left(\mathbf{z}_s \mid \mathbf{z}_t, \mathbf{x}\right)=\mathcal{N}\left(\mathbf{z}_s ; \tilde{\boldsymbol{\mu}}</em>{s \mid t}\left(\mathbf{z}<em>t, \mathbf{x}\right), \tilde{\sigma}</em>{s \mid t}^2 \mathbf{I}\right)$, where $\tilde{\boldsymbol{\mu}}<em>{s \mid t}\left(\mathbf{z}_t, \mathbf{x}\right)=e^{\lambda_l-\lambda_s}\left(\alpha_s / \alpha_t\right) \mathbf{z}_t+\left(1-e^{\lambda_t-\lambda_s}\right) \alpha_s \mathbf{x}$ and $\tilde{\sigma}</em>{s \mid t}^2=\left(1-e^{\lambda_t-\lambda_s}\right) \sigma_s^2$, it follows the stochastic update rule
\(\mathbf{z}_s=\tilde{\mu}_{s \mid t}\left(\mathbf{z}_t, \hat{\mathbf{x}}_\theta\left(\mathbf{z}_t, \lambda_t, \mathbf{c}\right)\right)+\sqrt{\left(\tilde{\sigma}_{s \mid t}^2\right)^{1-\gamma}\left(\sigma_{t \mid s}^2\right)^\gamma} \boldsymbol{\epsilon}\)
where $\epsilon \sim \mathcal{N}(\mathbf{0}, \mathbf{I})$, and $\gamma$ controls the stochasticity of the sampler [40].</p>

  <blockquote>
    <p>反转上述扩散过程，可以看作学习解噪 $\mathbf{z}<em>t \sim q\left(\mathbf{z}_t \mid \mathbf{x}\right)$ ， 即根据 $\mathbf{z}_t$ 和其他条件估计 $\mathbf{x}$ ，可 以表示成:
\(\hat{\mathbf{x}}_\theta\left(\mathbf{z}_t, \lambda_t, \mathbf{c}\right) \approx \mathbf{x}\)
式中， $\mathbf{c}$ 为可选的条件信息 (比如文本embeddings 或者低分辨率图像) 。训练 $\hat{\mathbf{x}}</em>{\boldsymbol{\theta}}$ 使用加权 MSE 损失函数:
\(\mathbb{E}_{\epsilon, t}\left[w\left(\lambda_t\right)\left\|\hat{\mathbf{x}}_\theta\left(\mathbf{z}_t, \lambda_t, \mathbf{c}\right)-\mathbf{x}\right\|_2^2\right]\)
式中， $(\mathbf{x}, \mathbf{c})$ 是数据-条件对, $t \sim \mathcal{U}([0,1]), \epsilon \sim \mathcal{N}(\mathbf{0}, \mathbf{I}), \alpha_t, \sigma_t, w_t$ 是关于 $t$ 的函数，其影 响样本生成质量。
因为 $\mathbf{z}<em>t=\alpha_t \mathbf{x}+\sigma_t \epsilon$ ，对 $\epsilon$ 参数化，则 $\hat{\mathbf{x}}</em>\theta\left(\mathbf{z}<em>t, \lambda_t, \mathbf{c}\right)=\left(\mathbf{z}_t-\sigma_t \epsilon</em>\theta\left(\mathbf{z}<em>t, \lambda_t, \mathbf{c}\right)\right) / \alpha_t$ ，所以 损失函数可以简化为:
\(\mathbb{E}_{\epsilon, t}\left[w\left(\lambda_t\right)\left\|\epsilon_\theta\left(\mathbf{z}_t, \lambda_t, \mathbf{c}\right)-\epsilon\right\|_2^2\right]\)
训练模型时，使用 Classifier-free guidance 方法，在单个扩散模型上同时训练无条件和带条 件目标，具体做法是在训练模型时随机（一般以 $10 \%$ 的概率) 丟弃 $\mathbf{c}$ ，得到 $\epsilon</em>\theta\left(\mathbf{z}<em>t, \lambda_t, \mathbf{c}\right)$ 之 后，使用下式更新：
\(\tilde{\boldsymbol{\epsilon}}_\theta\left(\mathbf{z}_t, \lambda_t, \mathbf{c}\right)=w \epsilon_\theta\left(\mathbf{z}_t, \lambda_t, \mathbf{c}\right)+(1-w) \epsilon_\theta\left(\mathbf{z}_t, \lambda_t\right)\)
式中, $\epsilon</em>\theta\left(\mathbf{z}<em>t, \lambda_t, \mathbf{c}\right)$ 和 $\epsilon</em>\theta\left(\mathbf{z}<em>t, \lambda_t\right)$ 分贝是带条件和无条件的 $\boldsymbol{\epsilon}$ 预测值， $w$ 是指导权重，当 $w=1$ 时，抑制了 classifier-free guidance, 当 $w&gt;1$ 会增强 guidance 的影响。
进一步可以估计 score： $\tilde{\boldsymbol{\epsilon}}</em>\theta\left(\mathbf{z}<em>t, \lambda_t, \mathbf{c}\right) \approx-\sigma_t \nabla</em>{\mathbf{z}_t} \log p\left(\mathbf{z}_t \mid \mathbf{c}\right)$ ，其中 $p\left(\mathbf{z}_t \mid \mathbf{c}\right)$ 是以 $\mathbf{c}$ 为 条件关于 $\mathbf{z}_t$ 的概率密度。
为了从扩散模型中采样，可以从随机噪声 $\mathbf{z}_1 \sim \mathcal{N}(\mathbf{0}, \mathbf{I})$ 开始，然后使用 DDIM 方法采样， 具体过程为:</p>

    <ul>
      <li>step1：由模型得到 $\epsilon_\theta\left(\mathbf{z}<em>t, \lambda_t, \mathbf{c}\right)$ 和 $\epsilon</em>\theta\left(\mathbf{z}<em>t, \lambda_t\right)$ ，进一步得到 $\tilde{\epsilon}</em>\theta\left(\mathbf{z}_t, \lambda_t, \mathbf{c}\right)$;</li>
      <li>step2: 根据 $\mathbf{z}<em>t$ 和 $\tilde{\boldsymbol{\epsilon}}</em>\theta\left(\mathbf{z}<em>t, \lambda_t, \mathbf{c}\right)$ 得到 $\hat{\mathbf{x}}</em>\theta\left(\mathbf{z}<em>t, \lambda_t, \mathbf{c}\right)=\left(\mathbf{z}_t-\sigma_t \tilde{\epsilon}</em>\theta\left(\mathbf{z}_t, \lambda_t, \mathbf{c}\right)\right) / \alpha_t$ ；</li>
      <li>step3: 估计 $\mathbf{z}<em>s=\alpha_s \hat{\mathbf{x}}</em>\theta\left(\mathbf{z}<em>t, \lambda_t, \mathbf{c}\right)+\sigma_s \tilde{\epsilon</em>\theta}\left(\mathbf{z}_t, \lambda_t, \mathbf{c}\right)$</li>
    </ul>

\[\mathbf{z}_s=\alpha_s \hat{\mathbf{x}}_\theta\left(\mathbf{z}_t, \lambda_t, \mathbf{c}\right)+\frac{\sigma_s}{\sigma_t}\left(\mathbf{z}_t-\alpha_t \hat{\mathbf{x}}_\theta\left(\mathbf{z}_t, \lambda_t, \mathbf{c}\right)\right)\]

    <p>式中， $s&lt;t$ 在 1 到 0 之间取均匀分布序列，最先的采样来自对扩散过程的反转，注意到:
\(q\left(\mathbf{z}_s \mid \mathbf{z}_t, \mathbf{x}\right)=\mathcal{N}\left(\mathbf{z}_s ; \tilde{\boldsymbol{\mu}}_{s \mid t}\left(\mathbf{z}_t, \mathbf{x}\right), \tilde{\sigma}_{s \mid t}^2 \mathbf{I}\right)\)
式 中， $\tilde{\boldsymbol{\mu}}<em>{s \mid t}\left(\mathbf{z}_t, \mathbf{x}\right)=e^{\lambda_t-\lambda_s}\left(\alpha_s / \alpha_t\right) \mathbf{z}_t+\left(1-e^{\lambda_t-\lambda_s}\right) \alpha_s \mathbf{X}$ ，并 且 $\tilde{\sigma}</em>{s \mid t}^2=\left(1-e^{\lambda_t-\lambda_s}\right) \sigma_s^2$, 遵循随机更新规则:
\(\mathbf{z}_s=\tilde{\boldsymbol{\mu}}_{s \mid t}\left(\mathbf{z}_t, \hat{\mathbf{x}}_\theta\left(\mathbf{z}_t, \lambda_t, \mathbf{c}\right)\right)+\sqrt{\left(\tilde{\sigma}_{s \mid t}^2\right)^{1-\gamma}\left(\sigma_{t \mid s}^2\right)^\gamma \boldsymbol{\epsilon}}\)
式中， $\epsilon \sim \mathcal{N}(\mathbf{0}, \mathbf{I})$, 其中 $\gamma$ 控制采样的随机性。</p>
  </blockquote>
</blockquote>

<p>Latent Diffusion Models can be divided into two stages:</p>

<ol>
  <li>Training perceptual compression models that strip away irrelevant high-level details and learn a latent space that is semantically equivalent to the high level image pixel-space
a. The loss is a combination of a reconstruction loss, an adversarial loss (remember GANs?) that promotes high quality decoder reconstruction, and regularization terms
\(L_{\text {Autoencoder }}=\min _{\mathcal{E}, \mathcal{D}} \max _\psi\left(L_{r e c}(x, \mathcal{D}(\mathcal{E}(x)))-L_{a d v}(\mathcal{D}(\mathcal{E}(x)))+\log D_\psi(x)+L_{r e g}(x ; \mathcal{E}, \mathcal{D})\right)\)</li>
  <li>Performing a diffusion process in this latent space. There are several benefits to this:
 a. The diffusion process is only focusing on the relevant semantic bits of the data
 b. Performing diffusion in a low dimensional space is significantly more efficient</li>
</ol>

<blockquote>
  <p>整体框架如图，先训练好一个AutoEncoder（包括一个encoder和decoder）。因此，我们可以利用encoder压缩后的数据做diffusion操作，再用decoder恢复即可。</p>

  <ul>
    <li>Autoencoder训练：L1/L2loss 来作为重建损失，用 $G A N$ 来做对抗攻击，用KL loss来把 latent space拉到正态分布，防止搜索空间过大。</li>
    <li>用了encoder降维后，就可以使用latent space diffusion了 具体扩散过程其实没有变，只不 过现在扩散和重建的目标为latent space的向量了。Diffusion model具体实现为 timeconditional UNet。</li>
  </ul>

\[L_{L D M}:=\mathbb{E}_{\mathcal{E}(x), \epsilon \sim \mathcal{N}(0,1), t}\left[\left\|\epsilon-\epsilon_\theta\left(z_t, t\right)\right\|_2^2\right]\]

  <p>​		The neural backbone $\epsilon_\theta(\circ, t)$ of our model is realized as a time-conditional UNet .</p>

  <ul>
    <li>为了引入conditioning的信息，提出了domain specific encoder $\tau_\theta(y)$ 不同模态的 (比如 text, class, image…) 转成中间表达(intermediate representation)，再利用cross-attention来 嵌入到UNet中去。
Attention $(Q, K, V)=\operatorname{softmax}\left(\frac{Q K^T}{\sqrt{d}}\right) \cdot V$, with</li>
  </ul>

\[Q=W_Q^{(i)} \cdot \varphi_i\left(z_t\right), K=W_K^{(i)} \cdot \tau_\theta(y), V=W_V^{(i)} \cdot \tau_\theta(y) .\]
</blockquote>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/image-20230517130729142.png" alt="image-20230517130729142" style="zoom:50%;" /></p>

<h3 id="architecture-comparison">Architecture Comparison</h3>

<h4 id="pure-diffusion-model">Pure Diffusion Model</h4>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/1PICHZIwm-SzP0BITiN5-3g.png" alt="Pure diffusion model architecture" style="zoom:80%;" /></p>

<h4 id="stable-diffusion-latent-diffusion-model">Stable Diffusion (Latent Diffusion Model)</h4>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/1NpQ282NJdOfxUsYlwLJplA.png" alt="Stable Diffusion architecture" style="zoom:80%;" /></p>

<h2 id="411-pytorch-implementation">4.11 Pytorch implementation</h2>

<p>https://github.com/azad-academy/denoising-diffusion-model</p>

<p>https://zhuanlan.zhihu.com/p/549623622</p>

<h3 id="扩散过程">扩散过程</h3>

<p>code for alphas_bar_sqrt: $\sqrt{\bar{\alpha}}$ , one_minus_alphas_bar_log: $log(1 - \bar{\alpha})$ , one_minus_alphas_bar_sqrt : $\sqrt{1 - \bar{\alpha}}$</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">num_steps</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">beta</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">1e-5</span><span class="p">,</span> <span class="mf">0.2e-2</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">))</span>

<span class="n">alphas</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">betas</span>   <span class="c1"># \alpha_t &amp; =1-\beta_t 
</span><span class="n">alphas_prod</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cumprod</span><span class="p">(</span><span class="n">alphas</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>   <span class="c1">#\bar{\alpha}_t &amp; =\prod_{i=1}^t \alpha_i
</span><span class="n">alphas_prod_p</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">([</span><span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">]).</span><span class="nb">float</span><span class="p">(),</span> <span class="n">alphas_prod</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]],</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">alphas_bar_sqrt</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">alphas_prod</span><span class="p">)</span>
<span class="n">one_minus_alphas_bar_log</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alphas_prod</span><span class="p">)</span>
<span class="n">one_minus_alphas_bar_sqrt</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alphas_prod</span><span class="p">)</span>
</code></pre></div></div>

<p>code for $q(\mathbf{x}_{1:T} \vert \mathbf{x}_0)$ and$\sqrt{\bar{\alpha}_t}$,  $\mathbf{x}_0+\sqrt{1-\bar{\alpha}_t}$ , $\sqrt{\bar{\alpha}_t} \mathbf{x}_0+\sqrt{1-\bar{\alpha}_t} \epsilon$</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">extract</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
	<span class="n">shape</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span>
	<span class="n">out</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">gather</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">t</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="nb">input</span><span class="p">.</span><span class="n">device</span><span class="p">))</span>
	<span class="n">reshape</span> <span class="o">=</span> <span class="p">[</span><span class="n">t</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
	<span class="k">return</span> <span class="n">out</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">*</span><span class="n">reshape</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">q_x</span><span class="p">(</span><span class="n">x_0</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">noise</span><span class="p">:</span> <span class="n">noise</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">x_0</span><span class="p">)</span>
    <span class="n">alphas_t</span> <span class="o">=</span> <span class="n">extract</span><span class="p">(</span><span class="n">alphas_bar_sqrt</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_0</span><span class="p">)</span>
    <span class="n">alphas_1_m_t</span> <span class="o">=</span> <span class="n">extract</span><span class="p">(</span><span class="n">one_minus_alphas_bar_sqrt</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_0</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">alphas_t</span> <span class="o">*</span> <span class="n">x_0</span> <span class="o">+</span> <span class="n">alphas_1_m_t</span> <span class="o">*</span> <span class="n">noise</span><span class="p">)</span>
</code></pre></div></div>

<p>正向过程正式的计算比较简单直接，正如上面理论部分提到的，通过时间步 T 在每次马尔科夫链的转换过程对样本数据 dataset 添加噪声：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_steps</span><span class="p">):</span>
    <span class="n">q_i</span> <span class="o">=</span> <span class="n">q_x</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">i</span><span class="p">]))</span>
</code></pre></div></div>

<p>$q(\mathbf{x}<em>t \vert \mathbf{x}_0)$ , extract(posterior_mean_coef_1, t, x_0) = $\frac{\sqrt{\bar{\alpha}</em>{t-1}}\beta_t}{1 - \bar{\alpha}<em>t}$, extract(posterior_mean_coef_2, t, x_0) = $\frac{\sqrt{\alpha_t}(1 - \bar{\alpha}</em>{t-1})}{1 - \bar{\alpha}_t}$</p>

<p>mean: $\tilde{\boldsymbol{\mu}}<em>t (\mathbf{x}_t, \mathbf{x}_0) = \frac{\sqrt{\alpha_t}(1 - \bar{\alpha}</em>{t-1})}{1 - \bar{\alpha}<em>t} \mathbf{x}_t + \frac{\sqrt{\bar{\alpha}</em>{t-1}}\beta_t}{1 - \bar{\alpha}_t} \mathbf{x}_0$ ,</p>

<p>posterior_variance: $\tilde{\beta}<em>t = 1/(\frac{\alpha_t}{\beta_t} + \frac{1}{1 - \bar{\alpha}</em>{t-1}}) 
= 1/(\frac{\alpha_t - \bar{\alpha}<em>t + \beta_t}{\beta_t(1 - \bar{\alpha}</em>{t-1})})
= \color{green}{\frac{1 - \bar{\alpha}<em>{t-1}}{1 - \bar{\alpha}_t} \cdot \beta_t} $ and var/posterior_log_variance_clipped: $\Sigma</em>\theta\left(x_t, t\right)=\exp \left(v \log \beta_t+(1-v) \log \tilde{\beta}_t\right)$</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">posterior_mean_coef_1</span> <span class="o">=</span> <span class="p">(</span><span class="n">betas</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">alphas_prod_p</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alphas_prod</span><span class="p">))</span>
<span class="n">posterior_mean_coef_2</span> <span class="o">=</span> <span class="p">((</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alphas_prod_p</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">alphas</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alphas_prod</span><span class="p">))</span>
<span class="n">posterior_variance</span> <span class="o">=</span> <span class="n">betas</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alphas_prod_p</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alphas_prod</span><span class="p">)</span>
<span class="n">posterior_log_variance_clipped</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">((</span><span class="n">posterior_variance</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">posterior_variance</span><span class="p">[</span><span class="mi">1</span><span class="p">:].</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="mi">0</span><span class="p">)).</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">q_posterior_mean_variance</span><span class="p">(</span><span class="n">x_0</span><span class="p">,</span> <span class="n">x_t</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
    <span class="n">coef_1</span> <span class="o">=</span> <span class="n">extract</span><span class="p">(</span><span class="n">posterior_mean_coef_1</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_0</span><span class="p">)</span>
    <span class="n">coef_2</span> <span class="o">=</span> <span class="n">extract</span><span class="p">(</span><span class="n">posterior_mean_coef_2</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_0</span><span class="p">)</span>
    <span class="n">mean</span> <span class="o">=</span> <span class="n">coef_1</span> <span class="o">*</span> <span class="n">x_0</span> <span class="o">+</span> <span class="n">coef_2</span> <span class="o">*</span> <span class="n">x_t</span>
    <span class="n">var</span> <span class="o">=</span> <span class="n">extract</span><span class="p">(</span><span class="n">posterior_log_variance_clipped</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">mean</span><span class="p">,</span> <span class="n">var</span>
</code></pre></div></div>

<h3 id="训练过程---逆扩散过程需要训练神经网络模型">训练过程 - 逆扩散过程需要训练神经网络模型,</h3>

<p>训练数据batch_x, alphas_bar_sqrt, one_minus_alphas_bar_sqrt， 其中batch_x 是X_0数据， alphas_bar_sqrt: $\sqrt{\bar{\alpha}}$ , one_minus_alphas_bar_sqrt : $\sqrt{1 - \bar{\alpha}}$， 都是一开始就得到的数据，没有用到q_x结果？</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">model</span> <span class="kn">import</span> <span class="n">Unet</span>
<span class="kn">from</span> <span class="nn">ema</span> <span class="kn">import</span> <span class="n">EMA</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="n">optim</span>


<span class="n">model</span> <span class="o">=</span> <span class="n">Unet</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="p">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>

<span class="c1"># Create EMA model
</span><span class="n">ema</span> <span class="o">=</span> <span class="n">EMA</span><span class="p">(</span><span class="mf">0.9</span><span class="p">)</span>
<span class="n">ema</span><span class="p">.</span><span class="n">register</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

<span class="c1"># Batch size
</span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_steps</span><span class="p">):</span>
    <span class="c1"># X is a torch Variable
</span>    <span class="n">permutation</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randperm</span><span class="p">(</span><span class="n">dataset</span><span class="p">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">0</span><span class="p">])</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">dataset</span><span class="p">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">0</span><span class="p">],</span> <span class="n">batch_size</span><span class="p">):</span>
        <span class="c1"># Retrieve current batch
</span>        <span class="n">indices</span> <span class="o">=</span> <span class="n">permutation</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">batch_size</span><span class="p">]</span>
        <span class="n">batch_x</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>
        <span class="c1"># Compute the loss.
</span>        <span class="n">loss</span> <span class="o">=</span> <span class="n">noise_estimation_loss</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">batch_x</span><span class="p">,</span> <span class="n">alphas_bar_sqrt</span><span class="p">,</span> <span class="n">one_minus_alphas_bar_sqrt</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">)</span>
        <span class="c1"># Before the backward pass, zero all of the network gradients
</span>        <span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="c1"># Backward pass: compute gradient of the loss with respect to parameters
</span>        <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="c1"># Perform gradient clipping
</span>        <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="mf">1.</span><span class="p">)</span>
        <span class="c1"># Calling the step function to update the parameters
</span>        <span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
        <span class="c1"># Update the exponential moving average
</span>        <span class="n">ema</span><span class="p">.</span><span class="n">update</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

    <span class="c1"># Print loss
</span>    <span class="k">if</span> <span class="p">(</span><span class="n">t</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
        <span class="k">print</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
</code></pre></div></div>

<p>损失函数, alphas_bar_sqrt: $\sqrt{\bar{\alpha}}$ , one_minus_alphas_bar_sqrt : $\sqrt{1 - \bar{\alpha}}$， $\mathbb{E}<em>{t \sim [1, T], \mathbf{x}_0, \boldsymbol{\epsilon}_t} \Big[|\boldsymbol{\epsilon}_t - \boldsymbol{\epsilon}</em>\theta( x_t, t)|^2 \Big]$. 其中$x_0$， $\epsilon _t$从前向过程已知, we already know $x_t=\sqrt{\bar{\alpha}_t} x_0+\sqrt{1-\bar{\alpha}_t} \epsilon_t$</p>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/image-20230605160414054.png" alt="image-20230605160414054" style="zoom:50%;" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">noise_estimation_loss</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">x_0</span><span class="p">,</span> <span class="n">alphas_bar_sqrt</span><span class="p">,</span> <span class="n">one_minus_alphas_bar_sqrt</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">):</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">x_0</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="c1"># Select a random step for each example
</span>    <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size</span> <span class="o">//</span> <span class="mi">2</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,))</span>
    <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">([</span><span class="n">t</span><span class="p">,</span> <span class="n">n_steps</span> <span class="o">-</span> <span class="n">t</span> <span class="o">-</span> <span class="mi">1</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)[:</span><span class="n">batch_size</span><span class="p">].</span><span class="nb">long</span><span class="p">()</span>
    <span class="c1"># x0 multiplier，这里用到了alphas_bar_sqrt
</span>    <span class="n">a</span> <span class="o">=</span> <span class="n">extract</span><span class="p">(</span><span class="n">alphas_bar_sqrt</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_0</span><span class="p">)</span>
    <span class="c1"># eps multiplier, 这里用到了one_minus_alphas_bar_sqrt
</span>    <span class="n">am1</span> <span class="o">=</span> <span class="n">extract</span><span class="p">(</span><span class="n">one_minus_alphas_bar_sqrt</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x_0</span><span class="p">)</span>
	<span class="c1"># get the noise epsilon sampling from Normal Dist, just random same size with x_0 and follow N(0,1)
</span>    <span class="n">e</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">x_0</span><span class="p">)</span>
    <span class="c1"># model input x_t 
</span>    <span class="n">x</span> <span class="o">=</span> <span class="n">x_0</span> <span class="o">*</span> <span class="n">a</span> <span class="o">+</span> <span class="n">e</span> <span class="o">*</span> <span class="n">am1</span> 
    <span class="c1"># get the prodict noise epsilon form model 
</span>    <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">e</span> <span class="o">-</span> <span class="n">output</span><span class="p">).</span><span class="n">square</span><span class="p">().</span><span class="n">mean</span><span class="p">()</span> <span class="c1"># mean squre of the loss (e-\hat{e})
</span></code></pre></div></div>

<h3 id="inference-sampling">inference (sampling)</h3>

\[\begin{aligned}
&amp; \text { Algorithm } 2 \text { Sampling } \\
&amp; \text { 1: } \mathbf{x}_T \sim \mathcal{N}(\mathbf{0}, \mathbf{I}) \\
&amp; \text { 2: for } t=T, \ldots, 1 \text { do } \\
&amp; \text { 3: } \mathbf{z} \sim \mathcal{N}(\mathbf{0}, \mathbf{I}) \text { if } t&gt;1, \text { else } \mathbf{z}=\mathbf{0} \\
&amp; \text { 4: } \quad \mathbf{x}_{t-1}=\frac{1}{\sqrt{\alpha_t}}\left(\mathbf{x}_t-\frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}} \boldsymbol{\epsilon}_\theta\left(\mathbf{x}_t, t\right)\right)+\sigma_t \mathbf{z} \\

&amp;\text{; where we have } \mathbf{x}_{t-1} = \mathcal{N}(\mathbf{x}_{t-1}; \frac{1}{\sqrt{\alpha_t}} \Big( \mathbf{x}_t - \frac{1 - \alpha_t}{\sqrt{1 - \bar{\alpha}_t}} \boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t) \Big), \boldsymbol{\Sigma}_\theta(\mathbf{x}_t, t)) \\

&amp; \text { 5: end for } \\
&amp; \text { 6: return } \mathbf{x}_0
\end{aligned}\]

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x_seq</span> <span class="o">=</span> <span class="n">p_sample_loop</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dataset</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span><span class="n">num_steps</span><span class="p">,</span><span class="n">alphas</span><span class="p">,</span><span class="n">betas</span><span class="p">,</span><span class="n">one_minus_alphas_bar_sqrt</span><span class="p">)</span>
</code></pre></div></div>

<p>$ \text{eps_factor} = \frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}<em>t}}$  , eps_theta = $\boldsymbol{\epsilon}</em>\theta\left(\mathbf{x}<em>t, t\right)$, mean=$=\frac{1}{\sqrt{\alpha_t}}\left(\mathbf{x}_t-\frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}} \boldsymbol{\epsilon}</em>\theta\left(\mathbf{x}_t, t\right)\right)$</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">p_sample</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span><span class="n">alphas</span><span class="p">,</span><span class="n">betas</span><span class="p">,</span><span class="n">one_minus_alphas_bar_sqrt</span><span class="p">):</span>
    <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">t</span><span class="p">])</span>
    <span class="c1"># Factor to the model output
</span>    <span class="n">eps_factor</span> <span class="o">=</span> <span class="p">((</span><span class="mi">1</span> <span class="o">-</span> <span class="n">extract</span><span class="p">(</span><span class="n">alphas</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x</span><span class="p">))</span> <span class="o">/</span> <span class="n">extract</span><span class="p">(</span><span class="n">one_minus_alphas_bar_sqrt</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x</span><span class="p">))</span>
    <span class="c1"># Model output
</span>    <span class="n">eps_theta</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
    <span class="c1"># Final values
</span>    <span class="n">mean</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">extract</span><span class="p">(</span><span class="n">alphas</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x</span><span class="p">).</span><span class="n">sqrt</span><span class="p">())</span> <span class="o">*</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="p">(</span><span class="n">eps_factor</span> <span class="o">*</span> <span class="n">eps_theta</span><span class="p">))</span>
    <span class="c1"># Generate z
</span>    <span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="c1"># Fixed sigma
</span>    <span class="n">sigma_t</span> <span class="o">=</span> <span class="n">extract</span><span class="p">(</span><span class="n">betas</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x</span><span class="p">).</span><span class="n">sqrt</span><span class="p">()</span>
    <span class="n">sample</span> <span class="o">=</span> <span class="n">mean</span> <span class="o">+</span> <span class="n">sigma_t</span> <span class="o">*</span> <span class="n">z</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">sample</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">p_sample_loop</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span><span class="n">n_steps</span><span class="p">,</span><span class="n">alphas</span><span class="p">,</span><span class="n">betas</span><span class="p">,</span><span class="n">one_minus_alphas_bar_sqrt</span><span class="p">):</span>
    <span class="n">cur_x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">x_seq</span> <span class="o">=</span> <span class="p">[</span><span class="n">cur_x</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n_steps</span><span class="p">)):</span>
        <span class="n">cur_x</span> <span class="o">=</span> <span class="n">p_sample</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">cur_x</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span><span class="n">alphas</span><span class="p">,</span><span class="n">betas</span><span class="p">,</span><span class="n">one_minus_alphas_bar_sqrt</span><span class="p">)</span>
        <span class="n">x_seq</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">cur_x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x_seq</span>
</code></pre></div></div>

<h2 id="412-connection-with-noise-conditioned-score-networks-ncsn--ddpm">4.12 Connection with noise-conditioned score networks (NCSN)- DDPM</h2>

<p><a href="https://arxiv.org/abs/1907.05600">Song &amp; Ermon (2019)</a> proposed a score-based generative modeling method where samples are produced via <a href="https://lilianweng.github.io/posts/2021-07-11-diffusion-models/#connection-with-stochastic-gradient-langevin-dynamics">Langevin dynamics</a> <strong>using gradients of the data distribution estimated with score matching</strong>. The score of each sample $\mathbf{x}$’s density probability is defined as its gradient $\nabla_{\mathbf{x}} \log q(\mathbf{x})$. A score network $\mathbf{s}<em>\theta: \mathbb{R}^D \to \mathbb{R}^D$ is trained to estimate it, $\mathbf{s}</em>\theta(\mathbf{x}) \approx \nabla_{\mathbf{x}} \log q(\mathbf{x})$</p>

<blockquote>
  <p><strong>TBS:</strong></p>

  <p>To make it scalable with high-dimensional data in the deep learning setting, they proposed to use either <em>denoising score matching</em> (<a href="http://www.iro.umontreal.ca/~vincentp/Publications/smdae_techreport.pdf">Vincent, 2011</a>) or <em>sliced score matching</em> (use random projections; <a href="https://arxiv.org/abs/1905.07088">Song et al., 2019</a>). Denosing score matching adds a pre-specified small noise to the data $q(\tilde{\mathbf{x}} \vert \mathbf{x})$ and estimates $q(\tilde{\mathbf{x}})$ with score matching.</p>
</blockquote>

<blockquote>
  <p>Recall that Langevin dynamics can sample data points from a probability density distribution using only the score $\nabla_{\mathbf{x}} \log q(\mathbf{x})$ in an iterative process.</p>
</blockquote>

<blockquote>
  <p>However, according to the manifold hypothesis, most of the data is expected to concentrate in a low dimensional manifold, even though the observed data might look only arbitrarily high-dimensional. It brings a negative effect on score estimation since the data points cannot cover the whole space. In regions where data density is low, the score estimation is less reliable. After adding a small Gaussian noise to make the perturbed data distribution cover the full space $\mathbb{R}^D$, the training of the score estimator network becomes more stable. Song \&amp; Ermon (2019) improved it by perturbing the data with the noise of different levels and train a noise-conditioned score network to jointly estimate the scores of all the perturbed data at different noise levels.</p>
</blockquote>

<p>The schedule of increasing noise levels resembles the forward diffusion process.</p>

<font color="red">If we use the diffusion process annotation, the score approximates $\mathbf{s}_\theta\left(\mathbf{x}_t, t\right) \approx \nabla_{\mathbf{x}_t} \log q\left(\mathbf{x}_t\right)$. Given a Gaussian distribution $\mathbf{x} \sim \mathcal{N}\left(\mu, \sigma^2 \mathbf{I}\right)$, we can write the derivative of the logarithm of its density function as $\nabla_{\mathbf{x}} \log p(\mathbf{x})=\nabla_{\mathbf{x}}\left(-\frac{1}{2 \sigma^2}(\mathbf{x}-\boldsymbol{\mu})^2\right)=-\frac{\mathbf{x}-\boldsymbol{\mu}}{\sigma^2}=-\frac{\epsilon}{\sigma}$ where $\boldsymbol{\epsilon} \mathcal{N}(\mathbf{0}, \mathbf{I})$. Recall that $q\left(\mathbf{x}_t \mid \mathbf{x}_0\right) \sim \mathcal{N}\left(\sqrt{\bar{\alpha}_t} \mathbf{x}_0,\left(1-\bar{\alpha}_t\right) \mathbf{I}\right)$ and therefore： </font>
<p>\(\mathbf{s}_\theta\left(\mathbf{x}_t, t\right) \approx \nabla_{\mathbf{x}_t} \log q\left(\mathbf{x}_t\right)=\mathbb{E}_{q\left(\mathbf{x}_0\right)}\left[\nabla_{\mathbf{x}_t} q\left(\mathbf{x}_t \mid \mathbf{x}_0\right)\right]=\mathbb{E}_{q\left(\mathbf{x}_0\right)}\left[-\frac{\epsilon_\theta\left(\mathbf{x}_t, t\right)}{\sqrt{1-\bar{\alpha}_t}}\right]=-\frac{\epsilon_\theta\left(\mathbf{x}_t, t\right)}{\sqrt{1-\bar{\alpha}_t}}\)</p>

<h2 id="413-conditioned-generation-条件控制生成">4.13 Conditioned Generation (条件控制生成)</h2>

<p>从方法上来看，条件控制生成的方式分两种：事后修改（Classifier-Guidance）和事前训练（Classifier-Free）。</p>

<blockquote>
  <table>
    <tbody>
      <tr>
        <td>[生成扩散模型漫谈（九）：条件控制生成结果 - 科学空间</td>
        <td>Scientific Spaces (kexue.fm)](https://kexue.fm/archives/9257)</td>
      </tr>
    </tbody>
  </table>

  <p>Classifier-Guidance方案最早出自<a href="https://arxiv.org/abs/2105.05233">《Diffusion Models Beat GANs on Image Synthesis》</a>，最初就是用来实现按类生成的；后来<a href="https://arxiv.org/abs/2112.05744">《More Control for Free! Image Synthesis with Semantic Diffusion Guidance》</a>推广了“Classifier”的概念，使得它也可以按图、按文来生成。</p>

  <p>Classifier-Guidance方案的训练成本比较低（熟悉NLP的读者可能还会想起与之很相似的<a href="https://arxiv.org/abs/1912.02164">PPLM模型</a>），但是推断成本会高些，而且控制细节上通常没那么到位。至于Classifier-Free方案，最早出自<a href="https://arxiv.org/abs/2207.12598">《Classifier-Free Diffusion Guidance》</a>，后来的<a href="https://arxiv.org/abs/2204.06125">DALL·E 2</a>、<a href="https://arxiv.org/abs/2205.11487">Imagen</a>等吸引人眼球的模型基本上都是以它为基础做的，值得一提的是，该论文上个月才放到Arxiv上，但事实上去年已经中了NeurIPS 2021。应该说，Classifier-Free方案本身没什么理论上的技巧，它是条件扩散模型最朴素的方案，出现得晚只是因为重新训练扩散模型的成本较大吧，在数据和算力都比较充裕的前提下，Classifier-Free方案变现出了令人惊叹的细节控制能力。</p>
</blockquote>

<h3 id="classifier-guided-diffusion">Classifier Guided Diffusion</h3>

<p>用随机微分方程解释DDPM and DDIM 模型</p>

<h4 id="diffusion-guidance-explanation-1-suitable-for-algorithm-2">Diffusion guidance Explanation 1 （==Suitable for Algorithm 2==）</h4>

<table>
  <tbody>
    <tr>
      <td>[What are Diffusion Models?</td>
      <td>Lil’Log (lilianweng.github.io)](https://lilianweng.github.io/posts/2021-07-11-diffusion-models/#nice)</td>
    </tr>
  </tbody>
</table>

<p>Guidance is a technique to explicitly incorporate image class—or text prompt—directly in the diffusion process. (This is the often tweaked <a href="https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion#diffusers.StableDiffusionPipeline.__call__.guidance_scale"><code class="language-plaintext highlighter-rouge">guidance_scale</code></a> hyperpameter.)</p>

<p><strong>The <a href="https://arxiv.org/abs/2105.05233">classifier-guidance paper (2021) Diffusion Models Beat GANs on Image Synthesis</a> noted that GANs relied heavily on class labels</strong>, often via <strong>class-conditioned normalization or discriminators</strong> with heads designed to behave like classifiers. This suggests that class information is crucial to the success of GANs for generation. So, to take a leaf from GANs, <strong>they use a classifier $p_\phi(y\vert x)$</strong> to improve image generation via diffusion.</p>

<p>To explicit incorporate class information into the diffusion process, Dhariwal \&amp; Nichol (2021) trained a classifier $f_\phi\left(y \mid \mathbf{x}<em>t, t\right)$ on noisy image $\mathbf{x}_t$ and use gradients $\nabla</em>{\mathbf{x}} \log f_\phi\left(y \mid \mathbf{x}<em>t\right)$ to guide the diffusion sampling process toward the conditioning information $y$ (e.g. a target class label) by altering the noise prediction. <strong>Recall that $\nabla_{\mathbf{x}_t} \log q\left(\mathbf{x}_t\right)=-\frac{1}{\sqrt{1-\bar{\alpha} t}} \boldsymbol{\epsilon}_\theta\left(\mathbf{x}_t, t\right)$</strong> and we can write the score function for the joint distribution $q\left(\mathbf{x}_t, y\right)$ as following,
\(\begin{aligned}
\nabla_{\mathbf{x}_t} \log q\left(\mathbf{x}_t, y\right) &amp; =\nabla_{\mathbf{x}_t} \log q\left(\mathbf{x}_t\right)+\nabla_{\mathbf{x}_t} \log q\left(y \mid \mathbf{x}_t\right) \\
&amp; \approx-\frac{1}{\sqrt{1-\bar{\alpha}_t}} \epsilon_\theta\left(\mathbf{x}_t, t\right)+\nabla_{\mathbf{x}_t} \log f_\phi\left(y \mid \mathbf{x}_t\right) \text{； 第二项目是为了分类增加额外的项目}\\
&amp; =-\frac{1}{\sqrt{1-\bar{\alpha}_t}}\left(\epsilon_\theta\left(\mathbf{x}_t, t\right)-\sqrt{1-\bar{\alpha}_t} \nabla_{\mathbf{x}_t} \log f_\phi\left(y \mid \mathbf{x}_t\right)\right)
\end{aligned}\)
Thus, a new classifier-guided predictor $\overline{\boldsymbol{\epsilon}}</em>\theta$ would take the form as following,
\(\bar{\epsilon}_\theta\left(\mathbf{x}_t, t\right)=\epsilon_\theta\left(x_t, t\right)-\sqrt{1-\bar{\alpha}_t} \nabla_{\mathbf{x}_t} \log f_\phi\left(y \mid \mathbf{x}_t\right) \tag {14- Conditional Sampling for DDIM}\)
因为我们已知微分方程 $\begin{aligned}
&amp; X_{t+1}=X_t+\frac{\varepsilon}{2} \nabla \log p\left(X_t\right)+\mathcal{N}(0, \varepsilon) <br />
&amp; X_t \sim p(x), \quad \forall t&gt;t_{\infty}
\end{aligned}$</p>

<p>We can then use the exact same sampling procedure as used for regular DDIM, but with the modified noise predictions $\hat{\epsilon}<em>\theta\left(x_t\right)$ instead of $\epsilon</em>\theta\left(x_t\right)$. Algorithm \&amp; summaries the corresponding sampling algorithm.</p>

<p>To control the strength of the classifier guidance, we can add a weight $w$ to the delta part,
\(\bar{\epsilon}_\theta\left(\mathbf{x}_t, t\right)=\epsilon_\theta\left(x_t, t\right)-\sqrt{1-\bar{\alpha}_t} w \nabla_{\mathbf{x}_t} \log f_\phi\left(y \mid \mathbf{x}_t\right)\)
The resulting ablated diffusion model (ADM) and the one with additional classifier guidance (ADM-G) are able to achieve better results than SOTA generative models (e.g. BigGAN).</p>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/conditioned-DDPM.png" alt="img" style="zoom: 33%;" /></p>

<h4 id="diffusion-guidance-explanation-2">Diffusion guidance Explanation 2</h4>

<table>
  <tbody>
    <tr>
      <td>[生成扩散模型漫谈（九）：条件控制生成结果 - 科学空间</td>
      <td>Scientific Spaces (kexue.fm)](https://kexue.fm/archives/9257)</td>
    </tr>
  </tbody>
</table>

<p>当给定训练好的Diffusion Models，如DDPM所述其逆扩散过程可以描述为 $p_\theta\left(\mathbf{x}<em>t \mid \mathbf{x}</em>{t+1}\right)$ 。假如此 时我们要求逆扩散的图像必须属于某种类型 $\mathbf{y}$ ，那么逆扩散过程就应该被重新定义为 $p_\theta\left(\mathbf{x}<em>t \mid \mathbf{x}</em>{t+1}, \mathbf{y}\right)$ 
为了获取类型 $\mathbf{y}$ ，我们需要一个训练好的分类器 $p_\phi\left(\mathbf{y} \mid \mathbf{x}<em>t, t\right)$ ，这个分类器跟普通分类器的区别 是，必须要见过加噪图像 $\mathbf{x}_t$ ，因此重新训练是不可避免的。此时逆扩散过程就变成了 $p</em>{\theta, \phi}\left(\mathbf{x}<em>t \mid \mathbf{x}</em>{t+1}, \mathbf{y}\right)$ 。其可以化简为
\(\begin{aligned}
p_{\theta, \phi}\left(\mathbf{x}_t \mid \mathbf{x}_{t+1}, \mathbf{y}\right) &amp; =\ldots \\
&amp; =Z p_\theta\left(\mathbf{x}_t \mid \mathbf{x}_{t+1}\right) p_\phi\left(\mathbf{y} \mid \mathbf{x}_t\right) \\
&amp; =\ldots
\end{aligned}\)
\(=p(\mathbf{z}) \quad ; \text { where } \mathbf{z} \sim \mathcal{N}(\mu+\Sigma g, \Sigma)\)
其中， $Z$ 是一个概率密度归一化的常数， $g=\left.\nabla_{x_t} \log p_\phi\left(y \mid x_t\right)\right|_{x_t=\mu}$ 。因此，Classifier Guided Sampling 的过程可以总结如下图</p>

<blockquote>
  <p>（论文）In this section, we show that conditional sampling can be achieved with a transition operator proportional to $p_\theta\left(x_t \mid x_{t+1}\right) p_\phi\left(y \mid x_t\right)$, where $p_\theta\left(x_t \mid x_{t+1}\right)$ approximates $q\left(x_t \mid x_{t+1}\right)$ and $p_\phi\left(y \mid x_t\right)$ approximates the label distribution for a noised sample $x_t$.</p>

  <p>We start by defining a conditional Markovian noising process $\hat{q}$ similar to $q$, and <strong>assume that $\hat{q}\left(y \mid x_0\right)$ is a known</strong> (==data likelihood==) and readily available label distribution for each sample.
\(\begin{aligned}
\hat{q}\left(x_0\right) &amp; :=q\left(x_0\right) \\
\hat{q}\left(y \mid x_0\right) &amp; :=\text { Known labels per sample } \\
\hat{q}\left(x_{t+1} \mid x_t, y\right) &amp; :=q\left(x_{t+1} \mid x_t\right) \\
&amp;\text{; 什么意思，加不加标签的正向过程没有变化么？应该是可以肯定的}\\
\hat{q}\left(x_{1: T} \mid x_0, y\right) &amp; :=\prod_{t=1}^T \hat{q}\left(x_t \mid x_{t-1}, y\right)
\end{aligned}\)
While we defined the noising process $\hat{q}$ conditioned on $y$, we can prove that $\hat{q}$ behaves exactly like $q$ <strong>when not conditioned on $y$</strong>. Along these lines, we first derive the unconditional noising operator $\hat{q}\left(x_{t+1} \mid x_t\right)$ :
\(\begin{aligned}
\hat{q}\left(x_{t+1} \mid x_t\right) &amp; =\int_y \hat{q}\left(x_{t+1}, y \mid x_t\right) d y \\
&amp; =\int_y \hat{q}\left(x_{t+1} \mid x_t, y\right) \hat{q}\left(y \mid x_t\right) d y \\
&amp; =\int_y q\left(x_{t+1} \mid x_t\right) \hat{q}\left(y \mid x_t\right) d y \\
&amp; =q\left(x_{t+1} \mid x_t\right) \int_y \hat{q}\left(y \mid x_t\right) d y \\
&amp; =q\left(x_{t+1} \mid x_t\right) \\
&amp; =\hat{q}\left(x_{t+1} \mid x_t, y\right)
\end{aligned}\)
Following similar logic, we find the joint distribution $\hat{q}\left(x_{1: T} \mid x_0\right)$ :
\(\begin{eqnarray}
\hat{q}\left(x_{1: T} \mid x_0\right) &amp;&amp; =\int_y \hat{q}\left(x_{1: T}, y \mid x_0\right) d y \\
&amp;&amp; =\int_y \hat{q}\left(y \mid x_0\right) \hat{q}\left(x_{1: T} \mid x_0, y\right) d y \\
&amp;&amp; =\int_y \hat{q}\left(y \mid x_0\right) \prod_{t=1}^T \hat{q}\left(x_t \mid x_{t-1}, y\right) d y \\
&amp;&amp; =\int_y^T \hat{q}\left(y \mid x_0\right) \prod_{t=1}^T q\left(x_t \mid x_{t-1}\right) d y \\
&amp;&amp; =\prod_{t=1}^T q\left(x_t \mid x_{t-1}\right) \int_y \hat{q}\left(y \mid x_0\right) d y \\
&amp;&amp; =\prod_{t=1}^T q\left(x_t \mid x_{t-1}\right) \\
&amp;&amp; =q\left(x_{1: T} \mid x_0\right)  \tag {44 - Conditional Sampling} 
\end{eqnarray}\)
Using Equation 44, we can now derive $\hat{q}\left(x_t\right)$ :
\(\begin{aligned}
\hat{q}\left(x_t\right) &amp; =\int_{x_{0: t-1}} \hat{q}\left(x_0, \ldots, x_t\right) d x_{0: t-1} \\
&amp; =\int_{x_{0: t-1}} \hat{q}\left(x_0\right) \hat{q}\left(x_1, \ldots, x_t \mid x_0\right) d x_{0: t-1} \\
&amp; =\int_{x_{0: t-1}} q\left(x_0\right) q\left(x_1, \ldots, x_t \mid x_0\right) d x_{0: t-1} \\
&amp; =\int_{x_{0: t-1}} q\left(x_0, \ldots, x_t\right) d x_{0: t-1} \\
&amp; =q\left(x_t\right)
\end{aligned}\)
Using the identities $\hat{q}\left(x_t\right)=q\left(x_t\right)$ and $\hat{q}\left(x_{t+1} \mid x_t\right)=q\left(x_{t+1} \mid x_t\right)$, it is trivial to show via Bayes rule that the <strong>unconditional reverse process $\hat{q}\left(x_t \mid x_{t+1}\right)=q\left(x_t \mid x_{t+1}\right)$.</strong></p>

  <p>One observation about $\hat{q}$ is that it gives rise to a noisy classification function, ==$\hat{q}\left(y \mid x_t\right)$. We can show that this classification distribution does not depend on $x_{t+1}$ (a noisier version of $x_t$ )==, a fact which we will later use:
\(\begin{aligned}
\hat{q}\left(y \mid x_t, x_{t+1}\right) &amp; =\hat{q}\left(x_{t+1} \mid x_t, y\right) \frac{\hat{q}\left(y \mid x_t\right)}{\hat{q}\left(x_{t+1} \mid x_t\right)} \text{; where the } q(x_t) \text{ is removed both molecular and denominator } \\
&amp; =\hat{q}\left(x_{t+1} \mid x_t\right) \frac{\hat{q}\left(y \mid x_t\right)}{\hat{q}\left(x_{t+1} \mid x_t\right)} \\
&amp; =\hat{q}\left(y \mid x_t\right)
\end{aligned}\)
We can now derive the conditional reverse process:
\(\begin{aligned}
\hat{q}\left(x_t \mid x_{t+1}, y\right) &amp; =\frac{\hat{q}\left(x_t, x_{t+1}, y\right)}{\hat{q}\left(x_{t+1}, y\right)} \\
&amp; =\frac{\hat{q}\left(x_t, x_{t+1}, y\right)}{\hat{q}\left(y \mid x_{t+1}\right) \hat{q}\left(x_{t+1}\right)} \\
&amp; =\frac{\hat{q}\left(x_t \mid x_{t+1}\right) \hat{q}\left(y \mid x_t, x_{t+1}\right) \hat{q}\left(x_{t+1}\right)}{\hat{q}\left(y \mid x_{t+1}\right) \hat{q}\left(x_{t+1}\right)} \\
&amp; =\frac{\hat{q}\left(x_t \mid x_{t+1}\right) \hat{q}\left(y \mid x_t, x_{t+1}\right)}{\hat{q}\left(y \mid x_{t+1}\right)} \\
&amp; =\frac{\hat{q}\left(x_t \mid x_{t+1}\right) \hat{q}\left(y \mid x_t\right)}{\hat{q}\left(y \mid x_{t+1}\right)} \\
&amp; =\frac{q\left(x_t \mid x_{t+1}\right) \hat{q}\left(y \mid x_t\right)}{\hat{q}\left(y \mid x_{t+1}\right)} \\
&amp; = Z q\left(x_t \mid x_{t+1}\right) \hat{q}\left(y \mid x_t\right)
\end{aligned}\)</p>

  <ul>
    <li>
      <p>==The $\hat{q}\left(y \mid x_{t+1}\right)$ term can be treated as a constant since it does not depend on $x_t$==. We thus want to sample from the distribution $Z q\left(x_t \mid x_{t+1}\right) \hat{q}\left(y \mid x_t\right)$ where $Z$ is a normalizing constant.</p>
    </li>
    <li>
      <p>==We already have a neural network approximation of $q\left(x_t \mid x_{t+1}\right)$, called $p_\theta\left(x_t \mid x_{t+1}\right)$, so all that is left is an approximation of $\hat{q}\left(y \mid x_t\right)$.==</p>
    </li>
    <li>
      <p>==This can be obtained by training a classifier $p_\phi\left(y \mid x_t\right)$ on noised images $x_t$ derived by sampling from $q\left(x_t\right)$.==</p>
    </li>
  </ul>

\[p_{\theta, \phi}\left(x_t \mid x_{t+1}, y\right)=Z p_\theta\left(x_t \mid x_{t+1}\right) p_\phi\left(y \mid x_t\right) \\
\tag {2 - Conditional Sampling for DDIM}\]

</blockquote>

<p>重用已经训练好的无条件生成模型$p(\boldsymbol{x}<em>{t-1}|\boldsymbol{x}_t)$，我们利用贝叶斯定理得
\(\begin{equation}p(\boldsymbol{x}_{t-1}|\boldsymbol{y}) = \frac{p(\boldsymbol{x}_{t-1})p(\boldsymbol{y}|\boldsymbol{x}_{t-1})}{p(\boldsymbol{y})}\end{equation}\)
在每一项上面补上条件$x_t$，就得到
\(\begin{equation}p(\boldsymbol{x}_{t-1}|\boldsymbol{x}_t, \boldsymbol{y}) = \frac{p(\boldsymbol{x}_{t-1}|\boldsymbol{x}_t)p(\boldsymbol{y}|\boldsymbol{x}_{t-1}, \boldsymbol{x}_t)}{p(\boldsymbol{y}|\boldsymbol{x}_t)}\label{eq:bayes-1}\end{equation}\)
注意，在前向过程中，$x_t$是由$x</em>{t−1}$加噪声得到的，噪声不会对分类有帮助，所以$x_t$的加入对分类不会有任何收益，因此有$p(\boldsymbol{y}|\boldsymbol{x}<em>{t-1}, \boldsymbol{x}_t)=p(\boldsymbol{y}|\boldsymbol{x}</em>{t-1})$，从而
\(\begin{equation}p(\boldsymbol{x}_{t-1}|\boldsymbol{x}_t, \boldsymbol{y}) = \frac{p(\boldsymbol{x}_{t-1}|\boldsymbol{x}_t)p(\boldsymbol{y}|\boldsymbol{x}_{t-1})}{p(\boldsymbol{y}|\boldsymbol{x}_t)} = p(\boldsymbol{x}_{t-1}|\boldsymbol{x}_t) e^{\log p(\boldsymbol{y}|\boldsymbol{x}_{t-1}) - \log p(\boldsymbol{y}|\boldsymbol{x}_t)}\label{eq:bayes-2}\end{equation}\)
==到此我们都得到了==
\(\begin{aligned}
p_{\theta, \phi}\left(\mathbf{x}_t \mid \mathbf{x}_{t+1}, \mathbf{y}\right) 
&amp; =Z p_\theta\left(\mathbf{x}_t \mid \mathbf{x}_{t+1}\right) p_\phi\left(\mathbf{y} \mid \mathbf{x}_t\right) 
\end{aligned}\)
以下是不同的泰勒展开不同的推导</p>

<h5 id="1-泰勒展开1">1, 泰勒展开1</h5>

<blockquote>
  <p>==<strong>当 $T$ 足够大时， $p\left(\boldsymbol{x}<em>t \mid \boldsymbol{x}</em>{t-1}\right)$ 的方差足够小，也就是说只有 $\boldsymbol{x}<em>t$ 与 $\boldsymbol{x}</em>{t-1}$ 很接近时概率才会明显大于 0 。反过来也是成立的，即也只有 $\boldsymbol{x}<em>t$ 与 $\boldsymbol{x}</em>{t-1}$ 很接近时 $p\left(\boldsymbol{x}<em>{t-1} \mid \boldsymbol{x}_t, \boldsymbol{y}\right)$ 或 $p\left(\boldsymbol{x}_t \mid \boldsymbol{x}</em>{t-1}, \boldsymbol{y}\right)$ 才明显大于o</strong>，我们只需要重点考虑这个范围内的概率变化。为此，我们用泰勒展 开:==
\(\log p\left(\boldsymbol{y} \mid \boldsymbol{x}_{t-1}\right)-\log p\left(\boldsymbol{y} \mid \boldsymbol{x}_t\right) \approx\left(\boldsymbol{x}_{t-1}-\boldsymbol{x}_t\right) \cdot \nabla_{\boldsymbol{x} t} \log p\left(\boldsymbol{y} \mid \boldsymbol{x}_t\right)\)
严格来讲还有一项关于 $t$ 的变化项，但是那一项跟 $x_{t-1}$ 无关，属于不影响 $x_{t-1}$ 概率的常数项，因此我们没有写出。假设原来有 $p\left(\boldsymbol{x}<em>{t-1} \mid \boldsymbol{x}_t\right)=\mathcal{N}\left(\boldsymbol{x}</em>{t-1} ; \boldsymbol{\mu}\left(\boldsymbol{x}<em>t\right), \sigma_t^2 \boldsymbol{I}\right) \propto e^{-\left|\boldsymbol{x}</em>{t-1}-\boldsymbol{\mu}\left(\boldsymbol{x}_t\right)\right|^2 / 2 \sigma_t^2}$ ，那么此时近似地有
\(\begin{aligned}
p\left(\boldsymbol{x}_{t-1} \mid \boldsymbol{x}_t, \boldsymbol{y}\right) &amp; \propto e^{-\left\|\boldsymbol{x}_{t-1}-\boldsymbol{\mu}\left(\boldsymbol{x}_t\right)\right\|^2 / 2 \sigma^2+\left(\boldsymbol{x}_{t-1}-\boldsymbol{x}_t\right) \cdot \nabla_{\boldsymbol{x}_t} \log p\left(\boldsymbol{y} \mid \boldsymbol{x}_t\right)} \\
&amp; \propto e^{\left.-\| \boldsymbol{x}_{t-1}-\boldsymbol{\mu}\left(\boldsymbol{x}_t\right)- \boldsymbol{\sigma}_t^2 \nabla_{\boldsymbol{x}_t} \log p\left(\boldsymbol{y} \mid \boldsymbol{x}_t\right)\right) \|^2 / 2 \sigma_t^2}
\end{aligned}\)</p>

  <blockquote>
    <font color="red"> $p\left(\boldsymbol{x}_{t-1} \mid \boldsymbol{x}_t\right)$难道不用DDIM or DDPM推导出的结果么。。。。</font>
    <p>==不需要这么细的推导，因为只要拿到新增项，就可以复用DDIM or DDPM的训练和sampling过程==
\(\color{red} 
\text {DENOISING DIFFUSION IMPLICIT MODELS }\\
\boldsymbol{x}_{t-1}=\sqrt{\alpha_{t-1}} \underbrace{\left(\frac{\boldsymbol{x}_t-\sqrt{1-\alpha_t} \epsilon_\theta^{(t)}\left(\boldsymbol{x}_t\right)}{\sqrt{\alpha_t}}\right)}_{\text {"predicted } \boldsymbol{x}_0 \text { " }}+\underbrace{\sqrt{1-\alpha_{t-1}-\sigma_t^2} \cdot \epsilon_\theta^{(t)}\left(\boldsymbol{x}_t\right)}_{\text {“direction pointing to } \boldsymbol{x}_t \text { " }}+\underbrace{\sigma_t \epsilon_t}_{\text {random noise }}\)</p>
  </blockquote>

  <p>从这个结果可以看出， $p\left(\boldsymbol{x}<em>{t-1} \mid \boldsymbol{x}_t, \boldsymbol{y}\right)$ 近似于 $\mathcal{N}\left(\boldsymbol{x}</em>{t-1} ; \boldsymbol{\mu}\left(\boldsymbol{x}<em>t\right)+\sigma_t^2 \nabla</em>{\boldsymbol{x}_t} \log p\left(\boldsymbol{y} \mid \boldsymbol{x}_t\right), \sigma_t^2 \boldsymbol{I}\right)$ ，所以只需要把生成过程的采样改为
\(\boldsymbol{x}_{t-\mathbf{1}}=\boldsymbol{\mu}\left(\boldsymbol{x}_t\right)+\underbrace{\sigma_t^2 \nabla_{\boldsymbol{x}_t} \log p\left(y \mid \boldsymbol{x}_t\right)}_{\text {新增顶 }}+\sigma_t \boldsymbol{\varepsilon}, \quad \boldsymbol{\varepsilon} \sim \mathcal{N}(\mathbf{0}, \boldsymbol{I})\)
<strong>这就是Classifier-Guidance方案的核心结果</strong>。值得注意的是，本文的推导结果跟原论文略有不同，原论文新增项是
\(\left.\sigma_t^2 \nabla_{\boldsymbol{x}_t} \log p\left(\boldsymbol{y} \mid \boldsymbol{x}_t\right)\right|_{\boldsymbol{x}_t=\boldsymbol{\mu}\left(\boldsymbol{x}_t\right)}\)
也就是梯度项在 $\boldsymbol{\mu}\left(\boldsymbol{x}_t\right)$ 处的结果而非 $\boldsymbol{x}_t$ 处，而一般情况下 $\boldsymbol{\mu}\left(\boldsymbol{x}_t\right)$ 的零阶近似正是 $\boldsymbol{x}_t$ ，所以两者结果是差不多的。</p>

</blockquote>

<h5 id="2-泰勒展开2">2, 泰勒展开2</h5>

<blockquote>
  <p>We can assume that $\log <em>\phi p\left(y \mid x_t\right)$ has low curvature compared to $\Sigma^{-1}$. This assumption is reasonable in the limit of infinite diffusion steps, where $|\Sigma| \rightarrow 0$. In this case, we can approximate $\log p</em>\phi\left(y \mid x_t\right)$ using a Taylor expansion around $x_t=\mu$ as</p>

  <p>==不太清楚二种泰勒展开$\log p\left(\boldsymbol{y} \mid \boldsymbol{x}<em>{t-1}\right)-\log p\left(\boldsymbol{y} \mid \boldsymbol{x}_t\right)$和 $\log p</em>\phi\left(y \mid x_t\right) |<em>{x_t =u}$ 的区别==
\(\begin{aligned}
\log p_\phi\left(y \mid x_t\right) &amp; \left.\approx \log p_\phi\left(y \mid x_t\right)\right|_{x_t=\mu}+\left.\left(x_t-\mu\right) \nabla_{x_t} \log p_\phi\left(y \mid x_t\right)\right|_{x_t=\mu} \\
&amp; =\left(x_t-\mu\right) g+C_1
\end{aligned}\)
Here, $g=\left.\nabla</em>{x_t} \log p_\phi\left(y \mid x_t\right)\right|<em>{x_t=\mu}$, and $C_1$ is a constant. This gives
\(\begin{aligned}
\log \left(p_\theta\left(x_t \mid x_{t+1}\right) p_\phi\left(y \mid x_t\right)\right) &amp; \approx-\frac{1}{2}\left(x_t-\mu\right)^T \Sigma^{-1}\left(x_t-\mu\right)+\left(x_t-\mu\right) g+C_2 \\
&amp; =-\frac{1}{2}\left(x_t-\mu-\Sigma g\right)^T \Sigma^{-1}\left(x_t-\mu-\Sigma g\right)+\frac{1}{2} g^T \Sigma g+C_2 \\
&amp; =-\frac{1}{2}\left(x_t-\mu-\Sigma g\right)^T \Sigma^{-1}\left(x_t-\mu-\Sigma g\right)+C_3 \\
&amp; =\log p(z)+C_4, z \sim \mathcal{N}(\mu+\Sigma g, \Sigma)
\end{aligned}\)
Recall that our diffusion model (==DDPM==) predicts the previous timestep $x_t$ from timestep $x</em>{t+1}$ using a Gaussian distribution:
\(\begin{aligned}
p_\theta\left(x_t \mid x_{t+1}\right) &amp; =\mathcal{N}(\mu, \Sigma) \\
\log p_\theta\left(x_t \mid x_{t+1}\right) &amp; =-\frac{1}{2}\left(x_t-\mu\right)^T \Sigma^{-1}\left(x_t-\mu\right)+C
\end{aligned}\)
<strong>We can safely ignore the constant term C4, since it corresponds to the normalizing coefficient Z in Equation 2.</strong>We have thus found that the conditional transition operator can be approximated by a Gaussian similar to the unconditional transition operator, but with its mean shifted by <strong>Σg.</strong> Algorithm 1 summaries the corresponding sampling algorithm. We include an optional scale factor s for the gradients.</p>

  <p>==<strong>Above go to Algorithm 1</strong>==</p>

  <p>In particular, if we have a model $θ(x_t)$ that predicts the noise added to a sample, then this can be used to derive a score function:
\(\nabla_{x_t} \log p_\theta\left(x_t\right)=-\frac{1}{\sqrt{1-\bar{\alpha}_t}} \epsilon_\theta\left(x_t\right)\)
==貌似这里和Algorithm1 没有联系：$p_{\theta, \phi}\left(\mathbf{x}<em>t \mid \mathbf{x}</em>{t+1}, \mathbf{y}\right) 
 =Z p_\theta\left(\mathbf{x}<em>t \mid \mathbf{x}</em>{t+1}\right) p_\phi\left(\mathbf{y} \mid \mathbf{x}<em>t\right) $== We can now substitute this into the ==score function for $p\left(x_t\right) p\left(y \mid x_t\right)$==<strong>这个score function的来源看下面解释explain3</strong>:
\(\begin{aligned}
\nabla_{x_t} \log \left(p_\theta\left(x_t\right) p_\phi\left(y \mid x_t\right)\right) &amp; =\nabla_{x_t} \log p_\theta\left(x_t\right)+\nabla_{x_t} \log p_\phi\left(y \mid x_t\right) \\
&amp; =-\frac{1}{\sqrt{1-\bar{\alpha}_t}} \epsilon_\theta\left(x_t\right)+\nabla_{x_t} \log p_\phi\left(y \mid x_t\right)
\end{aligned}\)
Finally, we can define a new epsilon prediction $\hat{\epsilon}\left(x_t\right)$ which corresponds to the score of the joint distribution:
\(\hat{\epsilon}\left(x_t\right):=\epsilon_\theta\left(x_t\right)-\sqrt{1-\bar{\alpha}_t} \nabla_{x_t} \log p_\phi\left(y \mid x_t\right)\)
We can then use the exact same sampling procedure as used for regular DDIM, but with the modified noise predictions $\hat{\epsilon}</em>\theta\left(x_t\right)$ instead of $\epsilon_\theta\left(x_t\right)$. Algorithm \&amp; summaries the corresponding sampling algorithm.</p>

  <p>==<strong>Above go to Algorithm 2</strong>==</p>
</blockquote>

<h4 id="diffusion-guidance-explanation-3-suitable-for-algorithm-2">Diffusion guidance Explanation 3 （==Suitable for Algorithm 2==）</h4>

<p><a href="https://sander.ai/2022/05/26/guidance.html">Guidance: a cheat code for diffusion models – Sander Dieleman</a></p>

<p>Diffusion models are generative models, which means they model a high-dimensional data distribution $p(x)$. Rather than trying to approximate $p(x)$ directly (which is what likelihood-based models do), they try to predict the so-called ==<strong>score function*, $\nabla_x \log p(x)$.</strong>==</p>

<p>To sample from a diffusion model, an input is initialized to random noise, and is then iteratively denoised by taking steps <strong>in the direction of the score function (i.e. the direction in which the log-likelihood increases fastest),</strong> with some additional noise mixed in to avoid getting stuck in modes of the distribution. This is called <strong><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_Langevin_dynamics">Stochastic Gradient Langevin Dynamics (SGLD)</a>.</strong> This is a bit of a caricature of what people actually use in practice nowadays, but it’s not too far off the truth.</p>

<p>In conditional diffusion models, we have an additional input $\boldsymbol{y}$ (for example, a class label or a text sequence) and we try to model the conditional distribution $p(x \mid y)$ instead. In practice, this means learning to ==<strong>predict the conditional score function $\nabla_x \log p(x \mid y)$.</strong>==</p>

<p>One neat aspect of the score function is that it is invariant to normalization of the distribution: if we only know the distribution $p(x)$ up to a constant, i.e. we have $p(x)=\frac{\bar{p}(x)}{Z}$ and we only know $\tilde{p}(\boldsymbol{x})$, then we can still compute the score function:
\(\nabla_x \log \tilde{p}(x)=\nabla_x \log (p(x) \cdot Z)=\nabla_x(\log p(x)+\log Z)=\nabla_x \log p(x)\)
where we have made use of the linearity of the gradient operator, and the fact that the normalization constant $Z=\int \tilde{p}(x) \mathrm{d} x$ does not depend on $x$ (so its derivative w.r.t. $\boldsymbol{x}$ is zero).</p>

<p>Unnormalized probability distributions come up all the time, so this is a useful property. For conditional models, it enables us to apply Bayes’ rule to decompose the score function into an unconditional component, and a component that “mixes in” the conditioning information:
\(\begin{gathered}
p(x \mid y)=\frac{p(y \mid x) \cdot p(x)}{p(y)} \\
\Longrightarrow \log p(x \mid y)=\log p(y \mid x)+\log p(x)-\log p(y) \\
\Longrightarrow \nabla_x \log p(x \mid y)=\nabla_x \log p(y \mid x)+\nabla_x \log p(x)
\end{gathered}\)
where we have used that $\nabla_x \log p(y)=0$. In other words, ==<strong>we can obtain the conditional score function as simply the sum of the unconditional score function and a conditioning term</strong>==. (Note that the conditioning term $\nabla_x \log p(y \mid x)$ is not itself a score function, because the gradient is w.r.t. $\boldsymbol{x}$, not $\boldsymbol{y}$.)</p>

<blockquote>
  <p>Solve $\nabla_x \log p(y \mid x)$ : The first thing to notice is that $p(y∣x)$ is exactly what classifiers and other discriminative models try to fit: $x$ is some high-dimensional input, and $y$ is a target label. If we have a differentiable discriminative model that estimates $p(y∣x)$, then we can also easily obtain $\nabla_x \log p(y \mid x)$. <strong>All we need to turn an unconditional diffusion model into a conditional one, is a classifier!</strong> 引用前面的：==训练一个分类器: This can be obtained by training a classifier $p_\phi\left(y \mid x_t\right)$ on noised images $x_t$ derived by sampling from $q\left(x_t\right)$.==</p>
</blockquote>

<p><strong>The observation that diffusion models can be conditioned <em>post-hoc</em> in this way was mentioned by Sohl-Dickstein et al.<a href="https://sander.ai/2022/05/26/guidance.html#fn:equilibrium">4</a> and Song et al.<a href="https://sander.ai/2022/05/26/guidance.html#fn:sde">5</a>,</strong></p>

<p>but Dhariwal and Nichol<a href="https://sander.ai/2022/05/26/guidance.html#fn:beatgans">6</a> really drove this point home, and showed how <em>classifier guidance</em> can dramatically improve sample quality by enhancing the conditioning signal, even when used in combination with traditional conditional modelling.</p>

<p>To achieve this, they <strong>scale the conditioning term</strong> by a factor:
\(\nabla_x \log p_\gamma(x \mid y) = \nabla_x \log p(x) + \gamma \nabla_x \log p(y \mid x) .\)
$γ$ is called the <strong>guidance scale</strong>, and cranking it up beyond 1 has the effect of <strong>amplifying the influence of the conditioning signal</strong>. It is <em>extremely</em> effective, especially compared to e.g. the truncation trick for GANs<a href="https://sander.ai/2022/05/26/guidance.html#fn:biggan">7</a>, which serves a similar purpose.</p>

<p>If we revert the gradient and the logarithm operations that we used to go from Bayes’ rule to classifier guidance, it’s easier to see what’s going on:
\(p_\gamma(x \mid y) \propto p(x) \cdot p(y \mid x)^\gamma .\)</p>

<p>We are raising the conditional part of the distribution to a power, which corresponds to <strong>tuning the temperature</strong> of that distribution: <strong>γ is an inverse temperature parameter. If γ&gt;1, this sharpens the distribution and focuses it onto its modes</strong>, by shifting probability mass from the least likely to the most likely values (i.e. the temperature is lowered). Classifier guidance allows us to apply this temperature tuning only to the part of the distribution that captures the influence of the conditioning signal.</p>

<h3 id="classifier-free-guidance">Classifier-Free Guidance</h3>

<p><a href="https://sander.ai/2022/05/26/guidance.html">Guidance: a cheat code for diffusion models – Sander Dieleman</a></p>

<table>
  <tbody>
    <tr>
      <td>[What are Diffusion Models?</td>
      <td>Lil’Log (lilianweng.github.io)](https://lilianweng.github.io/posts/2021-07-11-diffusion-models/#nice)</td>
    </tr>
  </tbody>
</table>

<blockquote>
  <p>As the name implies, it does not require training a separate classifier， Instead, one trains a conditional diffusion model $p(x∣y)$, with <em>conditioning dropout</em>: some percentage of the time, the conditioning information y is removed (10-20% tends to work well). In practice, it is often replaced with a special input value representing the absence of conditioning information. The resulting model is now able to function both as a conditional model p(x∣y), and as an unconditional model p(x), depending on whether the conditioning signal is provided. One might think that this comes at a cost to conditional modelling performance, but the effect seems to be negligible in practice.</p>
</blockquote>

<p><strong>Without an independent classifier $f_\phi$, it is still possible to run conditional diffusion steps</strong> by incorporating the scores from a conditional and an unconditional diffusion model (<a href="https://openreview.net/forum?id=qw8AKxfYbI">Ho &amp; Salimans, 2021</a>).</p>

<p>==Let unconditional denoising diffusion model $p_{\boldsymbol{\theta}}(\mathrm{x})$ parameterized through a score estimator $\boldsymbol{\epsilon}<em>\theta\left(\mathbf{x}_t, t\right)$ and the conditional model $p</em>\theta(\mathbf{x} \mid y)$ parameterized through $\boldsymbol{\epsilon}_\theta\left(\mathbf{x}_t, t, y\right)$. These two models can be learned via a single neural network.==</p>

<p>==<strong>Precisely, a conditional diffusion model $p_\theta(\mathbf{x} \mid y)$ is trained on paired data $(\mathbf{x}, y)$, where the conditioning information $y$ gets discarded periodically at random such that the model knows how to generate images unconditionally as well</strong>, i.e.==
\(\epsilon_\theta\left(\mathbf{x}_t, t\right)=\epsilon_\theta\left(\mathbf{x}_t, t, y=\varnothing\right)\)
<strong>The gradient of an implicit classifier can be represented with conditional and unconditional score estimators</strong>. Once plugged into the classifier-guided modified score, the score contains no dependency on a separate classifier.
\(\begin{aligned}
\nabla_{\mathbf{x}_t} \log p\left(y \mid \mathbf{x}_t\right) &amp; =\nabla_{\mathbf{x}_t} \log p\left(\mathbf{x}_t \mid y\right)-\nabla_{\mathbf{x}_t} \log p\left(\mathbf{x}_t\right) \\
&amp; =-\frac{1}{\sqrt{1-\bar{\alpha}_t}}\left(\epsilon_\theta\left(\mathbf{x}_t, t, y\right)-\epsilon_\theta\left(\mathbf{x}_t, t\right)\right) \\
\bar{\epsilon}_\theta\left(\mathbf{x}_t, t, y\right) &amp; =\epsilon_\theta\left(\mathbf{x}_t, t, y\right)-\sqrt{1-\bar{\alpha}_t} w \nabla_{\mathbf{x}_t} \log p\left(y \mid \mathbf{x}_t\right) \\
&amp; =\epsilon_\theta\left(\mathbf{x}_t, t, y\right)+w\left(\epsilon_\theta\left(\mathbf{x}_t, t, y\right)-\epsilon_\theta\left(\mathbf{x}_t, t\right)\right) \\
&amp; =(w+1) \epsilon_\theta\left(\mathbf{x}_t, t, y\right)-w \epsilon_\theta\left(\mathbf{x}_t, t\right) \\
&amp;\text {潜在的含义是} \log p\left(y \mid \mathbf{x}_t\right) \text{不再训练额外的分类器，而是通过训练} p(x∣y)拿到
\end{aligned}\)
或者一下推导也可以得到：</p>

<blockquote>
  <p><a href="https://sander.ai/2022/05/26/guidance.html">Guidance: a cheat code for diffusion models – Sander Dieleman</a></p>

  <p>We have expressed the conditioning term as a function of the conditional and unconditional score functions, both of which our diffusion model provides. We can now substitute this into the formula for classifier guidance:
\(\nabla_x \log p_\gamma(x \mid y)=\nabla_x \log p(x)+\gamma\left(\nabla_x \log p(x \mid y)-\nabla_x \log p(x)\right)\)
or equivalently:
\(\nabla_x \log p_\gamma(x \mid y)=(1-\gamma) \nabla_x \log p(x)+\gamma \nabla_x \log p(x \mid y)\)
This is a <a href="https://people.eecs.ku.edu/~jrmiller/Courses/VectorGeometry/AffineTransformations.html">barycentric combination</a> of the conditional and the unconditional score function. For γ=0, we recover the unconditional model, and for γ=1 we get the standard conditional model. But γ&gt;1 is where the magic happens === This makes the resulting gradient much more robust==. Below are some examples from OpenAI’s GLIDE model<a href="https://sander.ai/2022/05/26/guidance.html#fn:glide">8</a>, obtained using classifier-free guidance.</p>
</blockquote>

<p>Their experiments showed that classifier-free guidance can achieve a good balance between FID (distinguish between synthetic and generated images) and IS (quality and diversity).</p>

<p>The guided diffusion model, GLIDE (Nichol, Dhariwal \&amp; Ramesh, et al. 2022), explored both guiding strategies, CLIP guidance and classifier-free guidance, and found that the latter is more preferred. They hypothesized that it is because CLIP guidance exploits the model with adversarial examples towards the CLIP model, rather than optimize the better matched images generation.</p>

<blockquote>
  <p>下面的推导较为怪异，不过基本和上面推导类似：</p>

  <p>上文的Classifier-Guide采样方式，需要在采样阶段准备好额外的分类器，因此DDPM的原作者又 提出一种Classifier-Free-Guide 的方式。假如无引导的Diffusion Model为 $\epsilon_\theta\left(x_t\right)$ ，那么带分类 信息引导的可以写为
\(\hat{\epsilon}_\theta\left(x_t \mid y\right)=\epsilon_\theta\left(x_t\right)+s \nabla_{x_t} \log p^i\left(x_t \mid y\right)\)
由于
\(\begin{aligned}
\nabla_{x_t} \log p^i\left(x_t \mid y\right) &amp; \propto \nabla_{x_t} \log \left[p\left(x_t \mid y\right) /\left(x_t\right)\right] \\
&amp; =\nabla_{x_t} \log p\left(x_t \mid y\right)-\nabla_{x_t} \log p\left(x_t\right) \\
&amp; \propto \epsilon^*\left(x_t \mid y\right)-\epsilon^*\left(x_t\right)
\end{aligned}\)
其中， $\epsilon^<em>\left(x_t \mid y\right), \epsilon^</em>\left(x_t\right)$ 表示真实分布。因此，采样时的 $\hat{\epsilon}<em>\theta\left(x_t \mid y\right)$ 可以被写作
\(\hat{\epsilon}_\theta\left(x_t \mid y\right)=\epsilon_\theta\left(x_t\right)+s \cdot\left(\epsilon_\theta\left(x_t \mid y\right)-\epsilon_\theta\left(x_t\right)\right)\)
接下来就是如何训练出 $\epsilon</em>\theta\left(x_t \mid y\right), \epsilon_\theta\left(x_t\right)$ 。这两者在Diffusion Model会共用模型，并将带标 记的样本与无标记的样本混合一起训练，对于无标记样本则将 $y=n u l l$ 用于区分即可。</p>
</blockquote>

<h2 id="414-build-your-own-diffusion-mode-generally">4.14 build your own diffusion mode generally</h2>

<ol>
  <li>Choose the denoiser model: UNet + self attention block</li>
  <li>Choose the Training loss: MSE loss
\(\bar{\nabla}_\theta\left\|\boldsymbol{\epsilon}-\boldsymbol{\epsilon}_\theta\left(\sqrt{\bar{\alpha}_t} \mathbf{x}_0+\sqrt{1-\bar{\alpha}_t} \boldsymbol{\epsilon}, t\right)\right\|^2\)</li>
  <li>Choose the Sampler (testing): DDIM sampler</li>
</ol>

\[\boldsymbol{x}_{t-1}=\sqrt{\alpha_{t-1}} \underbrace{\left(\frac{\boldsymbol{x}_t-\sqrt{1-\alpha_t} \epsilon_\theta^{(t)}\left(\boldsymbol{x}_t\right)}{\sqrt{\alpha_t}}\right)}_{\text {"predicted } \boldsymbol{x}_0 \text { " }}+\underbrace{\sqrt{1-\alpha_{t-1}-\sigma_t^2} \cdot \epsilon_\theta^{(t)}\left(\boldsymbol{x}_t\right)}_{\text {"direction pointing to } \boldsymbol{x}_t \text { " }}+\underbrace{\sigma_t \epsilon_t}_{\text {random noise }}\]

<h2 id="415text-conditioning-influencing-image-output-via-text">4.15.Text conditioning: Influencing image output via text</h2>

<p><a href="https://eugeneyan.com/writing/text-to-image/">Text-to-Image: Diffusion, Text Conditioning, Guidance, Latent Space (eugeneyan.com)</a></p>

<h3 id="contrastive-language-image-pre-training-clip-2021">Contrastive Language-Image Pre-training (CLIP; 2021)</h3>

<p><strong><a href="https://arxiv.org/abs/2103.00020">Contrastive Language-Image Pre-training (CLIP; 2021)</a></strong>. <strong>It embeds text and image in the same space via a projection layer</strong>. Thus, it can efficiently learn visual concepts, in the form of text, via natural language supervision and perform zero-shot classification.</p>

<p><a href="https://www.youtube.com/watch?v=BcfAkQagEWU">(52) Contrastive Language-Image Pre-training (CLIP) - YouTube</a></p>

<blockquote>
  <p>what makes CLIP really special is <em>“the appreciation of using natural language as a training signal”</em>. It does demand access to supervised dataset in which we know which text matches which image. It is trained on 400 million (text, image) pairs, collected from the Internet. The query list contains all the words occurring at least 100 times in the English version of Wikipedia. Interestingly, they found that Transformer-based language models are 3x slower than a bag-of-words (BoW) text encoder at zero-shot ImageNet classification. <strong>Using contrastive objective instead of trying to predict the exact words associated with images</strong> (i.e. a method commonly adopted by image caption prediction tasks) can further improve the data efficiency another 4x.</p>
</blockquote>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/image-20230610153230803.png" alt="image-20230610153230803" style="zoom:80%;" /></p>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/clip.jpg" alt="CLIP pre-training and zero-shot classification" style="zoom: 80%;" /></p>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/image-20230610160726600.png" alt="image-20230610160726600" style="zoom:80%;" /></p>

<ol>
  <li>
    <p>In the pre-training stage, the image and text encoders are trained to predict which images are paired with which texts in a dataset of 400M image-caption pairs</p>
  </li>
  <li>
    <p>CLIP is trained to maximize the <strong>cosine similarity of the image and text embeddings</strong> of image-caption pairs via a multi-modal embedding space.</p>

    <ol>
      <li>图像和文本分别使用encoder编码为embedding，图像可使用 ResNet，文本可使用 Transformer</li>
      <li>假如每个Batch中样本量为N，图像embedding和文本embedding两两做内积则可以得到一个(N,N)维度的矩阵，其中第i行第j列表示对应图像和文本的相似度</li>
      <li>模型的目标就是使对角线的相似度最大，而非对角线相似度为0，也是借鉴了对比学习的思路</li>
    </ol>

    <blockquote>
      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># image_encoder - ResNet or Vision Transformer 
# text_encoder - CBOW or Text Transformer 
# I[n, h, w, c] - minibatch of aligned images 
# T[n, l] - minibatch of aligned texts 
# W_i[d_i, d_e] - learned proj of image to embed 
# W_t[d_t, d_e] - learned proj of text to embed 
# t - learned temperature parameter 
# extract feature representations of each modality 
</span><span class="n">I_f</span> <span class="o">=</span> <span class="n">image_encoder</span><span class="p">(</span><span class="n">I</span><span class="p">)</span> <span class="c1">#[n, d_i] 
</span><span class="n">T_f</span> <span class="o">=</span> <span class="n">text_encoder</span><span class="p">(</span><span class="n">T</span><span class="p">)</span> <span class="c1">#[n, d_t] 
# joint multimodal embedding [n, d_e] 
</span><span class="n">I_e</span> <span class="o">=</span> <span class="n">l2_normalize</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">I_f</span><span class="p">,</span> <span class="n">W_i</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> 
<span class="n">T_e</span> <span class="o">=</span> <span class="n">l2_normalize</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">T_f</span><span class="p">,</span> <span class="n">W_t</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> 
<span class="c1"># scaled pairwise cosine similarities [n, n] 
</span><span class="n">logits</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">I_e</span><span class="p">,</span> <span class="n">T_e</span><span class="p">.</span><span class="n">T</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> 
<span class="c1"># symmetric loss function 
</span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> 
<span class="n">loss_i</span> <span class="o">=</span> <span class="n">cross_entropy_loss</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> 
<span class="n">loss_t</span> <span class="o">=</span> <span class="n">cross_entropy_loss</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> 
<span class="n">loss</span> <span class="o">=</span> <span class="p">(</span><span class="n">loss_i</span> <span class="o">+</span> <span class="n">loss_t</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span>
</code></pre></div>      </div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">cross_entropy</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s">'none'</span><span class="p">):</span>
    <span class="n">log_softmax</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">LogSoftmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="n">targets</span> <span class="o">*</span> <span class="n">log_softmax</span><span class="p">(</span><span class="n">preds</span><span class="p">)).</span><span class="nb">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">reduction</span> <span class="o">==</span> <span class="s">"none"</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">loss</span>
    <span class="k">elif</span> <span class="n">reduction</span> <span class="o">==</span> <span class="s">"mean"</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">loss</span><span class="p">.</span><span class="n">mean</span><span class="p">()</span>
</code></pre></div>      </div>

      <p>函数 cosine_similarity 计算向量之间的L2归范化的点积(L2-normalized dot product)。 那就是, 如果 x 和 y 是两个行向量,则它们的余弦相似度(cosine similarity) k 定义如下:
\(k(x,y)=xy^T‖x‖‖y‖\)
之所以被称之为 余弦相似度, 是因为 Euclidean (L2) normalization 把两个向量投影到单位球 (unit sphere),这时它们的点积就是两个向量之间的夹角的余弦值。</p>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span> 
<span class="n">vec1</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span> 
<span class="n">vec2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">])</span> 
<span class="n">cos_sim</span> <span class="o">=</span> <span class="n">vec1</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">vec2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="n">norm</span><span class="p">(</span><span class="n">vec1</span><span class="p">)</span> <span class="o">*</span>  <span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="n">norm</span><span class="p">(</span><span class="n">vec2</span><span class="p">))</span> <span class="k">print</span><span class="p">(</span><span class="n">cos_sim</span><span class="p">)</span>
</code></pre></div>      </div>
    </blockquote>
  </li>
  <li>
    <p>This is implemented via a linear projection to map each encoder’s representation to the multi-modal embedding space (lines 13 - 15 below).</p>
  </li>
  <li>
    <p>As a result, the text and image embeddings are now in the same space. <strong>Thus, given a text embedding, we can apply k-nearest neighbors to find similar images.</strong></p>
  </li>
  <li>
    <p><strong>Language Guidance</strong></p>

    <blockquote>
      <p>基于文本条件的图像生成，即希望生成的图像符合文本的描述。在逆向过程中，<strong>每个迭代步要对有噪声的图像和文本计算embedding相似度，作为引导</strong></p>

      <p>了解了CLIP如何定义图像-文本的相似度，那么定义Language Guidance的 $F_\phi\left(x_t, y, t\right)$ 也就比 较容易明白了，具体如下:
\(F_\phi\left(x_t, l, t\right)=E_I^{\prime}\left(x_t, t\right) \cdot E_L(l)\)
其中， $l$ 为用于引导的文本， $E_L$ 表示文本encoder。 $x_t$ 为图像， $E_I^{\prime}$ 表示图像encoder。因此，CLIP中图像encoder必须要使用噪声图像finetune。其效果如下</p>

      <p><img src="/assets/BERTGPTDiffusion%20Research.assets/v2-e5396b5509f38a1edd10ad12919d54c2_720w.webp" alt="img" style="zoom:33%;" /></p>
    </blockquote>
  </li>
  <li>
    <p><strong>Image Guidance</strong></p>

    <blockquote>
      <p>基于图像条件的图像生成，希望生成的图像与参考的图像尽可能相似</p>

      <p>图片引导是指希望生成的图片与一张参考图片相似。我们将参考图记为 $x_0^{\prime}$ ，根据前述DDPM中 的 $q\left(x_t \mid x_0\right)$ 公式，我们可以根据当前逆向过程的 $t$ 获得对应程度的加噪图片 $x_t^{\prime}$ 。通过对比 $x_t^{\prime}$ 与 $x_t$ 引导生成。此处作者提出了三种不同的图片引导函数。</p>

      <p>Image Guidance的 $F_\phi\left(x_t, x_t^{\prime}, t\right)$ 定义如下:
\(F_\phi\left(x_t, x_t^{\prime}, t\right)=E_I^{\prime}\left(x_t, t\right) \cdot E_I^{\prime}\left(x_t^{\prime}, t\right)\)
其中，定义 $x_0^{\prime}$ 为用于引导的无橾声图像， $x_t^{\prime}$ 为 $x_0^{\prime}$ 生成的加橾图像。</p>

      <p><img src="/assets/BERTGPTDiffusion%20Research.assets/webp.webp" alt="img" style="zoom:33%;" /></p>

      <p>同样的，CLIP中图像 encoder必须要使用噪声图像finetune。其效果如下</p>

      <p><img src="/assets/BERTGPTDiffusion%20Research.assets/v2-58459d39be0e70f297212799d7f96cdc_720w.webp" alt="img" style="zoom:33%;" /></p>

      <ul>
        <li>图片内容引导: 希望图片的内容内容与参考图相似
\(F\left(x_t, x_t^{\prime}, t\right)=E_I^{\prime}\left(x_t, t\right) \cdot E_I^{\prime}\left(x_t^{\prime}, t\right)\)</li>
        <li>图片结构引导: 进一步的，我们希望加入更强的引导，即在空间结构上的相似性。这里对比的是 encoder 的spatial feature map
\(F\left(x_t, x_t^{\prime}, t\right)=-\sum_i \frac{1}{C H W}\left\|E_I^{\prime}\left(x_t, t\right)_j-E_I^{\prime}\left(x_t^{\prime}, t\right)_j\right\|_2^2\)</li>
        <li>图片风格引导: 基于Gram 矩阵，希望生成图片的风格符合参考图片
$F\left(x_t, x_t^{\prime}, t\right)=-\sum_i\left|G_I^{\prime}\left(x_t, t\right)_j-G_I^{\prime}\left(x_t^{\prime}, t\right)_j\right|_2^2$ ，此处 $G^{\prime}()_j$ 是 $E_I^{\prime}$ 第层特征的 gram matrix。</li>
      </ul>
    </blockquote>
  </li>
</ol>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/image-20230616141106845.png" alt="image-20230616141106845" /></p>

<h4 id="clip-guidance">CLIP guidance</h4>

<p>As mentioned earlier, CLIP comprises two parts, an image encoder $f(x)$ and a caption encoder $g(c)$. This approach is similar to guided diffusion except that the perturbation is the dot product of $g(c)$ and $f\left(\mathbf{x}_t\right)$
\(\hat{\mu}_\theta\left(\mathbf{x}_t \mid c\right)=\mu_\theta\left(\mathbf{x}_t \mid c\right)+s \cdot \Sigma_\theta\left(\mathbf{x}_t \mid c\right) \nabla_{\mathbf{x}_t} \log \left(f\left(\mathbf{x}_t\right) \cdot g(c)\right)\)
Similar to classifier based guidance, <strong>they train the CLIP model with noised images.</strong></p>

<h4 id="glide-training">GLIDE Training</h4>

<p>While GLIDE was not the first Diffusion Model, its important contribution was in modifying them to allow for <strong>text-conditional image generation</strong>. In particular, one will notice that Diffusion Models <em>start</em> from randomly sampled Gaussian noise. It at first unclear how to tailor this process to generate <em>specific</em> images. If a Diffusion Model is trained on a human face dataset, it will reliably generate photorealistic images of human faces; but what if someone wants to generate a face with a <em>specific</em> feature, like brown eyes or blonde hair?</p>

<p>GLIDE extends the core concept of Diffusion Models by <strong>augmenting the training process with additional textual information</strong>, ultimately resulting in text-conditional image generation. Let’s take a look at the training process for GLIDE:</p>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/v2-78ba27465f8ed85a5c7b06d05b8b3c3b_b.webp" alt="动图" style="zoom: 67%;" /></p>

<p>no-classifer guidence 可以更好的将条件信息加入到扩散模型的训练中去以得到更好的训练效果，但同时也会增加训练成本。OpenAI 就基于no-classifier guidence 的思想，整了一个超大规模的基于扩散模型的文本图像生成模型GLIDE。其中算法的核心即将前面的类别条件更新为了文本条件：</p>

<ul>
  <li>首先将文本编码为 $\mathrm{K}$ 个 token 序列。</li>
  <li>然后将token输入到 Transformer。</li>
  <li>transformer输出的最后一个token作为扩散模型的条件。其中每一步中都基于生成图像 $\mathrm{E}<em>{\mathrm{I}}(\mathrm{x})$ 与 文本 $\mathrm{E}</em>{\mathrm{L}}(\mathrm{l})$ 之间的相似度来计算梯度 $\mathrm{F}\left(\mathrm{x}<em>{\mathrm{t}}, \mathrm{l}, \mathrm{t}\right)=\mathrm{E}</em>{\mathrm{I}}^{\prime}\left(\mathrm{x}<em>{\mathrm{t}}\right) \cdot \mathrm{E}</em>{\mathrm{L}}(\mathrm{l})$ 。且 $G L I D E$ 是无分类器的扩 散引导:</li>
</ul>

\[\hat{\epsilon}_\theta\left(x_t \mid \text { Caption }\right)=\epsilon_\theta\left(x_t\right)+s \cdot\left(\epsilon_\theta\left(x_t, \text { Caption }\right)-\epsilon_\theta\left(x_t\right)\right)\]

<p>这里无非就是把原来的label $y$换成了 caption，<strong>实际上就是运用了足够量的image-text pair</strong>从而可以把caption当作是某种程度上的label。（随机替换为空序列以实现unconditional的训练方式）</p>

<p>由于此时的生成图像质量一般般，文章也提供了图像编辑的方式（具体操作为：将选中区域mask掉，将图像也作为一个condition连同文本输入到模型中去）</p>

<h3 id="dalle-2021">DALL·E (2021)</h3>

<p>CLIP was quickly followed up by <strong><a href="https://arxiv.org/abs/2102.12092">DALL·E (2021)</a>, one of the first text-to-image generation models open to the public</strong></p>

<p>DALL·E由OpenAI在2021年初提出，旨在训练一个输入文本到输出图像的自回归解码器。由CLIP的成功经验可知，文本特征和图像特征可以编码在同一特征空间中，因此我们可以使用Transformer将文本和图像特征自回归建模为单个数据流（“autoregressively models the text and image tokens as a single stream of data”）。</p>

<p>DALL·E的训练过程分成两个阶段，一是训练一个变分自编码器用于图像编解码，二是训练一个文本和图像的自回归解码器用于预测生成图像的Tokens，</p>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/3190ca843b20efdce34291cc54b3e5dd27b16f.jpg" alt="img" /></p>

<h4 id="dalle-mini-model-architecture----training-process">DALL·E mini Model Architecture  - Training Process</h4>

<p>Images and descriptions are both provided during training and flow through the system in the following order:</p>

<ul>
  <li>Images are encoded through a <a href="https://arxiv.org/abs/2012.09841">VQGAN</a> encoder, which turns images into a sequence of tokens.</li>
  <li>Descriptions are encoded through a <a href="https://arxiv.org/abs/1910.13461">BART</a> encoder.</li>
  <li>The output of the BART encoder and encoded images are fed through the BART decoder, which is an auto-regressive model whose goal is to predict the next token.</li>
  <li>Loss is the <a href="https://wandb.ai/sauravm/Activation-Functions/reports/Activation-Functions-Softmax--VmlldzoxNDU1Njgy#📢-softmax-+-cross-entropy-loss-(caution:-math-alert)">softmax cross-entropy</a> between the model prediction logits and the actual image encodings from the VQGAN.</li>
</ul>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/0uYCW3oCeVXVZLEOQ.png" alt="img" style="zoom:67%;" /></p>

<h4 id="inference-process">Inference Process</h4>

<p>At inference time, one only has captions available and wants to generate images:</p>

<ul>
  <li>
    <p>The caption is encoded through the BART encoder.</p>
  </li>
  <li>
    <p>A <BOS> token (special token identifying the “Beginning Of Sequence”) is fed through the BART decoder.</BOS></p>
  </li>
  <li>
    <p>Image tokens are sampled sequentially based on the decoder’s predicted distribution over the next token.</p>
  </li>
  <li>
    <p>Sequences of image tokens are decoded through the VQGAN decoder.
CLIP is used to select the best generated images.</p>

    <p><img src="/assets/BERTGPTDiffusion%20Research.assets/0wU__CnIvF0X7U4Gd.png" alt="img" /></p>
  </li>
</ul>

<h4 id="general-dalle">General DALLE</h4>

<ol>
  <li>
    <p><strong>learning the vocabulary of the image-text pairs **（变分自编码器用于图像编解码）:  At a high level, **DALL·E starts by compressing images into 8,192 discrete tokens in a visual codebook</strong> (Z in the image below).  DALL·E trains a <strong>discrete variational encoder (dVAE)</strong> to compress 256 x 256 images into 32 x 32=1024 integers image tokens (vocabulary size = 8,192). The parameters of the dVAE are then frozen when training the transformer.</p>

    <p>训练离散的变分自编码器（dVAE），对图片进行压缩，将256X256的pixel压缩为32X32的token序列 ，原本每个像素的值为[0,255]，现在经过codebook对图像的特征块进行token离散化，codebook大小为8192，这样就可以将32*32的token矩阵转为1024的token序列，并且以此作为image部分的输入特征。</p>

    <blockquote>
      <p>Why compress images into tokens in a codebook? The authors explained that using pixels directly as image tokens would require too much memory for high-resolution images. <strong>As a result, model capacity is spent on high-frequency details (i.e., pixels) instead of low-frequency structure (i.e., lines) that make images visually recognizable</strong>. (This is the same reason Stable diffusion encodes images into the latent space before running diffusion.)</p>
    </blockquote>
  </li>
</ol>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/vqgan-codebook.jpg" alt="Visual example of a codebook from the VQGAN paper" /></p>

<p>和VAE一样我们用概率编码器和概率解码器，分别建模隐层特征的后验概率分布和生成图像的似然概率分布，使用建模由Transformer预测的文本和图像的联合概率分布作为先验（在第一阶段初始化为均匀分布），同理可得优化目标的证据下界，
\(\log p_{\theta, \psi}(x, y) \geq \mathbb{E}_{z \sim q_\phi(z \mid x)} \log p_\theta(x \mid y, z)-\beta D_{K L}\left(q_\phi(y, z \mid x) \| p_\psi(y, z)\right)\)
在第一阶段的训练过程中，DALL·E使用了一个离散变分自编码器（Discrete VAE）简称dVAE，是Vector Quantized VAE（VQ-VAE）的升级版。在VAE中我们用一个概率分布刻画了连续的隐层空间，通过随机采样得到隐层编码，但是这个编码并不像离散的语言文字具有确定性。为了学习图像隐层空间的“语言”，VQ-VAE使用了一组可学习的向量量化表示隐层空间，这个量化的隐层空间我们称为Embedding Space或者Codebook/Vocabulary。VQ-VAE的训练过程和预测过程旨在寻找与图像编码向量距离最近的隐层向量，再将映射得到的向量语言解码成图像（图12），损失函数由三部分构成，分别优化重构损失、更新Embedding Space和更新编码器，梯度终止
\(L_{V Q-V A E}=\log (p(x \mid q(x)))+\left\|s g\left[z_e(x)\right]-e\right\|^2+\left\|z_e(x)-s g[e]\right\|^2\)
<img src="/assets/BERTGPTDiffusion%20Research.assets/68747470733a2f2f692e696d6775722e636f6d2f5239564d5744362e706e67.png" alt="VQ-VAE example" /></p>

<p>VQ-VAE由于最近邻选择假设使其后验概率是确定的，即距离最近的隐层向量概率为1其余为0，不具有随机性；距离最近的向量选择过程不可导，使用了straight-through estimator方法将的梯度传递给。</p>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/f5738b1380288b21dd0891ff9598704a45ca58.jpg" alt="img" /></p>

<p>为了优化上述问题，DALL·E使用Gumbel-Softmax构建了新的dVAE（图13），解码器的输出变为Embedding Space上32*32个K=8192维分类概率，在训练过程中对分类概率的Softmax计算加入噪声引入随机性，使用逐步减小的温度让概率分布近似one-hot编码，对隐层向量的选择重参数化使其可导（式(11)），推理过程中仍取最近邻。
\(\begin{aligned}
&amp;y_i=\frac{e^{\left(g_i+\log \left(q\left(e_i \mid x\right)\right)\right) / \tau}}{\sum_{j=1}^K e^{\left(g_j+\log \left(q\left(e_j \mid x\right)\right)\right) / \tau}}\\
&amp;z=\sum_{j=1}^K y_j e_j
\end{aligned}\)
当第一阶段训练完成后，我们可以固定dVAE对于每对文本-图像生成预测目标的图像Tokens。</p>

<ol>
  <li>
    <p>The second part was about <strong>learning the prior distribution over the text and image tokens.</strong>  Text部分则直接通过BPE进行token化，长度限制为256，最终输入到模Transformer中的<strong>输入数据</strong>为concat[text token, image token]，对于一个图像文本对，文本特征(256)，图像特征(32x32)，然后将这两个特征拼接成一个1280长度的序列，再输入至GPT中-按照自回归的方式进行训练。</p>

    <ul>
      <li>
        <p>What they did here is <strong>concatenate 256 tokens obtained from encoding the input text prompts with the encoded 1024 tokens from their corresponding image</strong>. image captions are lowercased and truncated to a max length of 256 tokens before being encoded (vocabulary size = 16,384). The image tokens are then concatenated after the text tokens (example below).</p>

        <p><img src="/assets/BERTGPTDiffusion%20Research.assets/dalle-sequence.jpg" alt="Example of concatenated text and image tokens in DALL·E" /></p>

        <ul>
          <li>
            <p>an autoregressive transformer (i.e., predict the next item in a sequence) is trained to learn the joint distribution over the text and image tokens. <strong>The transformer is decoder-only,</strong> where each image token can attend to all text tokens earlier in the sequence.</p>
          </li>
          <li>
            <p>training a transformer to model this autoregressively as a single stream of data of 1024+256=1080 tokens. The result is that from an initial set of at least 256 tokens, the model will “autocomplete” the remaining ones such that <strong>an image is generated that is consistent to the initial tokens</strong> [3].</p>
          </li>
          <li>
            <p>To generate images from text, the text prompt is embedded and fed into the transformer. The transformer then generates the sequence of image tokens. Finally, the dVAE decodes the image tokens to return a 256 x 256 image.</p>

            <p><img src="/assets/BERTGPTDiffusion%20Research.assets/v2-68aee588111332bc36975912295e622f_720w.webp" alt="img" /></p>

            <p><img src="/assets/BERTGPTDiffusion%20Research.assets/v2-eb3622e724086366a9bc39f18e43c1ea_720w.webp" alt="img" /></p>
          </li>
        </ul>

        <p><strong>训练目标</strong>就是通过近似的变分下界（VLB）来训练：
\(\ln p_{\theta, \varphi}(x, y) \geq \sum_{z \sim q_\phi(z \mid x)}\left(\ln p_\theta(x \mid y, z)-\beta D_{K L}\left(q_\phi(y, z \mid x), p_{\varphi}(y, z)\right)\right)\)
在第二阶段训练过程中，DALL·E使用BPE方法将文本先编码成和图像Tokens相同维度d=3968的文本Tokens，再将文本Tokens和图像Tokens Concat到一起，加入位置编码和Padding编码，使用Transformer Encoder进行自回归预测，为了提升计算速度，DALL·E还采用了Row、Column、Convolutional三种稀疏化的attention mask机制。</p>

        <p>DALL·E中的Transformer结构由64层attention层组成，每层的注意力头数为62，每个注意力头的维度为64，因此，每个token的向量表示维度为3968。如图所示，attention层使用了行注意力mask、列注意力mask和卷积注意力mask三种稀疏注意力。</p>

        <p><img src="/assets/BERTGPTDiffusion%20Research.assets/v2-7eabf68f79230423439bc0d12ff94919_720w.png" alt="img" /></p>

        <p>In summary, with the dVAE from the first stage and the autoregressive transformer from the second one, a single step of DALL-E would have to (1) use the transformer to predict the following 1024 image tokens from the first 256 tokens obtained from the input text-prompt and (2) take the full stream of 1024 image tokens that are generated by the transformer and generate an image using the dVAE to map from the embedding space onto the image space.</p>

        <blockquote>
          <p>[1] The name DALL-E comes from a wordplay combining <strong>WALL-E</strong>, the Disney’s Pixar character, and <strong>Dalí</strong> from <em>Salvador Dalí</em>, the famous spanish painter.</p>

          <p>[2] Oord, Aaron van den, Oriol Vinyals, and Koray Kavukcuoglu. “Neural discrete representation learning.” (2017) [<a href="https://arxiv.org/pdf/1711.00937.pdf">Link]</a></p>

          <p>[3] This is similar to what GTP-3 (another language model by OpenAI) does to generate text from an initial text-input. Although GTP-3 is more than 10 times larger than DALL-E with 175 billion parameters (<a href="https://arxiv.org/abs/2005.14165">Source</a>).</p>
        </blockquote>
      </li>
    </ul>
  </li>
</ol>

<p>​	3.  推理阶段，给定一张候选图片和一条文本，通过transformer可以得到融合后的token，然后用dVAE的decoder生成图片，最后通过预训练好的CLIP计算出文本和生成图片的匹配分数，采样越多数量的图片，就可以通过CLIP得到不同采样图片的分数排序(详细过程可以看非官方实现<a href="https://link.zhihu.com/?target=https%3A//github.com/lucidrains/DALLE-pytorch/blob/961bba948124a135120db477ef9a55329a7feac8/dalle_pytorch/dalle_pytorch.py%23L447">DALLE-pytorch/dalle_pytorch.py</a>)</p>

<h3 id="dalle-2-2022">DALL·E 2 (2022)</h3>

<p><a href="https://www.assemblyai.com/blog/how-dall-e-2-actually-works/">How DALL-E 2 Actually Works (assemblyai.com)</a></p>

<p><strong><a href="https://arxiv.org/abs/2204.06125">DALL·E 2 (aka unCLIP, 2022)</a> builds on the previous two papers</strong> <strong>by using the text and image encoder from CLIP and the autoregressive transformer from DALL·E. Similarly</strong>, unCLIP is trained on a dataset of image-caption pairs which are embedded via CLIP text and image encoders into <strong>text embeddings ($z_t$) and image embeddings ($z_i$).</strong></p>

<ol>
  <li>generate a <a href="https://vaclavkosar.com/ml/openai-dall-e-2-and-dall-e-1#openais-clip">CLIP model</a> text embedding for text caption</li>
  <li>“prior” network generates CLIP image embedding from text embedding</li>
  <li>diffusion decoder generates image from the image embedding</li>
</ol>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/unclip.jpg" alt="How the encoded text (blue) generates images via the prior and decoder" /></p>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/dall-e-2-decoder.png" alt="DALL-E 2 decoder" /></p>

<ul>
  <li>
    <p><strong>the prior</strong> $\left(p\left(z_i \mid y\right)\right)$ learns to produce <strong>CLIP image embeddings</strong> $\left(z_i\right)$ conditioned on the text prompt $(y)$.</p>
  </li>
  <li>The decoder $\left(p\left(x \mid z_i, y\right)\right)$ then produces the image conditioned on the CLIP image embedding $\left(z_i\right)$ and optional text prompt $(y)$.</li>
  <li>In other words, to generate images from text prompts $(p(x \mid y)$ ), we first sample CLIP image embeddings via the prior before decoding them via the decoder.</li>
</ul>

<p>\(p(x \mid y)=P\left(x, z_i \mid y\right)=P\left(x \mid z_i, y\right) P\left(z_i \mid y\right)\)
<strong>The paper shared two approaches to learn the prior: autoregressive and diffusion.</strong></p>

<ul>
  <li>
    <p><strong>The autoregressive approach</strong> (clip) is similar to that of DALL·E where text conditioning is done by having the text embedding early in the sequence. They also prepend a dot product token (of text and image embedding) between the text and image embedding. This allowed the autoregressive prior to condition the model on the higher dot product since a higher text-image dot product indicates images that are more representative of the caption.</p>
  </li>
  <li>
    <p><strong>For the diffusion approach</strong>, they <strong>trained a decoder-only transformer with a casual attention mask</strong> on a <strong>sequence of encoded text, text embedding, time step embedding, noised CLIP image embedding, and final embedding</strong>. <strong>The</strong> final embedding’s output is then used to predict the unnoised CLIP image embedding. Interestingly, in contrast to DDPM, they found it better to train the model to directly predict the unnoised image, instead of predicting the noise and then subtracting from the noisy image.</p>
  </li>
</ul>

<p>The latter shows one way text conditioning can be applied to diffusion. The transformer attends to the text information in the sequence and uses it to predict the final output.</p>

<blockquote>
  <p>DALLE2的模型结构如上图，其中扩散模型是基于GLIDE的。</p>

  <p>虚线上半部分是预训练好的CLIP。一侧输入文本，一侧是图像，用于得到表征。
虚线下半部分是text-to-image的生成过程。这一过程是二阶的过程，即文本变图像特征，再特性特征变图像。首先文本特征输入autoregressive或者diffusion prior以得到初步的图像特征（实验证明diffusion效率更高，因此一般选用diffusion），然后该特征会进一步作为condition到反向扩散模型中生成最后的图片。</p>

  <p>值得注意的是 GLIDE 模型以两种方式使用投影的 CLIP 文本嵌入。第一种是将它们添加到 GLIDE 现有的时间步嵌入中，第二种是通过创建四个额外的上下文 token，它们连接到 GLIDE 文本编码器的输出序列。</p>
</blockquote>

<h4 id="step-1---linking-textual-and-visual-semantics">Step 1 - Linking Textual and Visual Semantics</h4>

<p>The <strong>link between textual semantics and their visual representations</strong> in DALL-E 2 is learned by another OpenAI model called <strong>CLIP</strong> (<strong>C</strong>ontrastive <strong>L</strong>anguage-<strong>I</strong>mage <strong>P</strong>re-training).</p>

<h4 id="step-2---generating-images-from-visual-semantics">Step 2 - Generating Images from Visual Semantics</h4>

<p>After training, the CLIP model is frozen and DALL-E 2 moves onto its next task - <strong>learning to <em>reverse</em> the image encoding mapping that CLIP just learned</strong>. CLIP learns a representation space in which it is easy to determine the relatedness of textual and visual encodings, but our interest is in image <strong>generation</strong>. We must therefore learn how to exploit the representation space to accomplish this task.</p>

<p>In particular, OpenAI employs a modified version of another one of its previous models, <a href="https://arxiv.org/abs/2112.10741?ref=assemblyai.com">GLIDE</a> (<a href="https://arxiv.org/abs/2105.05233?ref=assemblyai.com">Ablated Diffusion Model</a> (ADM), Classifier-Free Guidance) ,  to perform this image generation. The GLIDE model learns to <em>invert</em> the image encoding process in order to stochastically decode CLIP image embeddings.</p>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/CLIP_to_GLIDE-1.png" alt="img" /></p>

<p>An image of a Corgi playing a flamethrowing trumpet passed through CLIP’s image encoder. GLIDE then uses this encoding to generate a new image that maintains the salient features of the original. (modified from <a href="https://arxiv.org/abs/2204.06125?ref=assemblyai.com">source</a>)</p>

<p>As depicted in the image above, it should be noted that the goal is <strong>not</strong> to build an autoencoder and <em>exactly</em> reconstruct an image given its embedding, but to instead generate an image which <strong>maintains the salient features of the original image</strong> given its embedding. In order perform this image generation, GLIDE uses a <strong>Diffusion Model</strong>.</p>

<p>Therefore, DALL-E 2’s modified GLIDE learns to <strong>generate semantically consistent images conditioned on CLIP image encodings</strong>.  It is also important to note that the reverse-Diffusion process is stochastic, and therefore variations can easily be generated by inputting the <em>same</em> image encoding vectors through the modified GLIDE model multiple times.</p>

<h4 id="step-3---mapping-from-textual-semantics-to-corresponding-visual-semantics">Step 3 - Mapping from Textual Semantics to Corresponding Visual Semantics</h4>

<p>Recall that, in addition to our <em>image</em> encoder, CLIP also learns a <em>text</em> encoder. DALL-E 2 uses another model, which the authors call the <strong>prior</strong>, in order to map <strong>from the text encodings</strong> of image captions <strong>to the</strong> <strong>image encodings</strong> of their corresponding images. <strong>The DALL-E 2 authors experiment with both Autoregressive Models and Diffusion Models for the prior, but ultimately find that they yield comparable performance</strong>. Given that the Diffusion Model is much more computationally efficient, it is selected as the prior for DALL-E 2.</p>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/text_to_image_encoding_2.png" alt="img" style="zoom:50%;" /></p>

<p>Prior mapping from a text encoding to its corresponding image encoding (modified from <a href="https://arxiv.org/abs/2204.06125?ref=assemblyai.com">source</a>).</p>

<blockquote>
  <p>Prior Training</p>

  <p>The Diffusion Prior in DALL-E 2 consists of a <strong>decoder-only Transformer</strong>. It operates, <strong>with a causal attention mask</strong>, on an ordered sequence of</p>

  <ol>
    <li>The tokenized text/caption.</li>
    <li>The CLIP text encodings of these tokens.</li>
    <li>An encoding for the diffusion timestep.</li>
    <li>The noised image passed through the CLIP image encoder.</li>
    <li>Final encoding whose output from Transformer is used to predict the unnoised CLIP image encoding.</li>
  </ol>

  <ul>
    <li>Conditioning on the Caption
      <ul>
        <li>The Diffusion Prior is conditioned <strong>not only on the CLIP text embedding of the caption, but also the caption itself</strong>. The former is a deterministic function of the latter and this dual-conditioning is therefore fully permissible.</li>
      </ul>
    </li>
    <li>Classifier-Free Guidance
      <ul>
        <li>To improve sample quality, sampling is randomly conducted using classifier-free guidance 10% of the time by dropping the text-conditioning information.</li>
      </ul>
    </li>
    <li>Double Sample Generation
      <ul>
        <li>To improve quality during sampling time, two image embeddings are generated with the prior and the one with the higher dot product with the text embedding is selected. It is unclear why the authors use the dot product here as opposed to the cosine similarity.</li>
      </ul>
    </li>
    <li><strong>Why do we need the prior?</strong> The authors note that training such a prior is not strictly necessary for a <strong>caption-to-image model</strong>.
      <ul>
        <li><strong>One option would be to condition only on the caption itself</strong>. This would simply yield the model GLIDE, and the authors perform a thorough analysis comparing the two in the paper.</li>
        <li>Another option would be to feed into the <strong>decoder the CLIP text embedding</strong>, rather than <strong>using the prior to generate a CLIP image embedding</strong> from it and then use that. The authors found experimentally that the former produces reasonable results, although results not as good as those of the latter. Ultimately, using the prior <strong>improves image diversity</strong>.</li>
      </ul>
    </li>
  </ul>
</blockquote>

<h4 id="step-4---putting-it-all-together">Step 4 - Putting It All Together</h4>

<p>At this point, we have all of DALL-E 2’s functional components and need only to chain them together for text-conditional image generation:</p>

<ol>
  <li>First the CLIP text encoder maps the image description into the <strong>representation space</strong>. The <strong>link between textual semantics and their visual representations</strong> in DALL-E 2 is learned by another OpenAI model called <strong>CLIP</strong> (<strong>C</strong>ontrastive <strong>L</strong>anguage-<strong>I</strong>mage <strong>P</strong>re-training)</li>
  <li>Then the diffusion prior maps from the CLIP text encoding to a <strong>corresponding CLIP image encoding</strong>.</li>
  <li>Finally, the modified-GLIDE generation model maps from the representation space into the image space via reverse-Diffusion, <strong>generating one of many possible images that conveys the semantic information</strong> within the input caption.</li>
</ol>

<h3 id="imagen-2022">Imagen （2022）</h3>

<p><strong><a href="https://arxiv.org/abs/2205.11487">Imagen (2022)</a> takes it further by using a text encoder that wasn’t even trained on image-caption pairs (🤯).</strong> It uses the encoder network of the <a href="https://arxiv.org/abs/1910.10683">T5</a>.  <strong>This is a departure from CLIP-based approaches, where the text encoder is specifically trained on image-caption pairs and the text embeddings are projected into a multi-modal embedding space.</strong></p>

<p>Imagen 的组成：(1) 文本编码器，用于将文本映射成 embeddings 序列 ；(2) 级联条件扩散模型，用于将 embeddings 序列映射成图像，并逐步增加图像分辨率（参见 图 A.4)，以下将详细描述这些组件</p>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/image-20220606210644557.png" alt="img" /></p>

<ol>
  <li>
    <p>在当前的文本到图像模型中通常使用在配对的图文数据集上训练的文本编码器，比如 CLIP。大型的语言模型可以作为另一种选择，例如 BERT、 GPT、 T5 ， 语言模型在纯文本语料库上训练，训练数据远多于成对的图像-文本数据， 所以其可以接触更加丰富和广泛分布的文本。语言模型通常也大得多（例如，PaLM 有 540 B 参数，而 CoCa 有1B 参数）</p>

    <p>Imagen 研究比较了预训练文本编码器：BERT 、T5 和 CLIP。这些文本编码器的权重是冻结的，这样做的好处是可以离线计算文本嵌入，在训练文本到图像生成模型期间，计算或内存占用可以忽略不计。经过实验比较发现文本编码器大小会影响文本到图像生成质量， T5-XXL 在图像-文本对齐、图像逼真度方面可以取得最好的成绩。</p>

    <p>It works because extremely large language models (LLMs), by virtue of sheer size, can still learn useful representations despite not being explicitly trained on text-to-image tasks. The benefit is that LLMs can learn on a text-only corpus which is easily larger than image-text datasets. Furthermore, they found that <strong>scaling the text encoder size is more impactful than UNet size in image-text alignment and image fidelity.</strong></p>
  </li>
</ol>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/imagen-curves.jpg" alt="Text encoder size &gt; UNet size; dynamic thresholding &gt; static thresholding" /></p>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/image-20220606211106144.png" alt="img" /></p>

<h4 id="实施细节">实施细节</h4>

<p>Imagen 的提出的改进主要体现在：</p>

<ul>
  <li>引入新的动态阈值技术，这样采样器可以使用非常大的无分类器指导权重；</li>
  <li>在超分辨率模型中引入噪声增强，提高图像逼真度；</li>
  <li>引入一种新的高效 U-Net 架构，这种架构具有更高的计算效率、更高的内存效率和更快的收敛速度；</li>
</ul>

<h4 id="阈值技术">阈值技术</h4>

<p>增加 classifier-free guidance 的指导权重可以提高图像-文本的对齐，但会影响图像逼真度， 产生高度饱和和不自然的图像。导致这个现象的原因是高指导权重引起训练测试不匹配: 在 每个采样步 $t, x$ 的预测值 $\hat{x}_0^t$ 必须与训练数据在同一范围内，即在 $[-1,1]$ 内。但使用高指 导权重会使 $x$ 预测值超出这些界限。这样就导致训练测试不匹配的情形，扩散模型在整个 采样过程中会迭代应用自身输出，这样的采样过程会导致产生不自然的图像，有时甚至发 散。</p>

<blockquote>
  <h4 id="large-guidance-weight-samplers">Large Guidance Weight Samplers</h4>

  <p>Classifier-Free Guidance is a very powerful way to improve the caption alignment of generated images, but it has <a href="https://arxiv.org/pdf/2112.10741.pdf?ref=assemblyai.com">been</a> <a href="https://arxiv.org/abs/2105.05233?ref=assemblyai.com">previously</a> <a href="https://arxiv.org/abs/2204.06125?ref=assemblyai.com">observed</a> that extremely high guidance weights damage fidelity by yielding saturated and unnatural images.</p>

  <p>The Imagen authors investigate this phenomenon and find that it arises from a <strong>train-test mismatch</strong>. In particular, the pixel values for the training data are scaled to the range [-1, 1], but <strong>high guidance weights cause the network outputs to exceed these bounds</strong> at given timestep. To make matters worse, since the same model is iteratively applied to its own output during diffusion, this effect compounds as the diffusion process proceeds, leading even potentially to divergence.</p>

  <p><strong>High guidance weights are found to be crucial for achieving State-of-the-Art image quality</strong>, so avoiding the problem by simply using lower guidance weights is not an option. Instead, the authors address the problem by devising two methods to threshold pixel values - <strong>static thresholding</strong> and <strong>dynamic thresholding</strong>. These methods address the train-test mismatch noted above and dynamic thresholding in particular is found to be critical to Imagen’s performance.</p>
</blockquote>

<p>为解决上述训练测试不匹配问题，引入了阈值技术:</p>

<ul>
  <li>
    <p>静态阈值: 对 $x$ 的预测值逐元素裁剪到 $[-1,1]$ ，称为静态阈值。这样方法对于大引导权重的 采样至关重要，并可以防止产生空白图片。尽管如此，随着指导权重的增加，静态阈值处理 仍会使图像出现过饱和或细节少的问题，伪代码如下:</p>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">sample</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">T</span><span class="p">)):</span>
        <span class="c1"># Forward pass to get x0_t from z_t.
</span>        <span class="n">x0_t</span> <span class="o">=</span> <span class="n">nn</span><span class="p">(</span><span class="n">z_t</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
        <span class="c1"># Static thresholding.
</span>        <span class="n">x0_t</span> <span class="o">=</span> <span class="n">jnp</span><span class="p">.</span><span class="n">clip</span><span class="p">(</span><span class="n">x0_t</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
        <span class="c1"># Sampler step.
</span>        <span class="n">z_tm1</span> <span class="o">=</span> <span class="n">sampler_step</span><span class="p">(</span><span class="n">x0_t</span><span class="p">,</span> <span class="n">z_t</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
        <span class="n">z_t</span> <span class="o">=</span> <span class="n">z_tm1</span>
    <span class="k">return</span> <span class="n">x0_t</span>
</code></pre></div>    </div>

    <blockquote>
      <h5 id="static-thresholding">Static Thresholding</h5>

      <p>In static thresholding, the pixel values at each timestep are simply clipped to the range [-1, 1]. This process can be visualized in the example below.</p>

      <video src="/assets/BERTGPTDiffusion%20Research.assets/static_threshold.mp4"></video>

      <p>For the sale of example, let our pixel values be normally distributed. Applying static thresholding to these values means that any distribution weight that it outside of the pixel bounds (light red area) is pushed onto -1 for negative values and 1 for positive values. As we can see, as the variance of the distribution grows, the probability of being at an extreme value grows.</p>
    </blockquote>
  </li>
  <li>
    <p>动态國值: 在每个采样步将 $s$ 设置为 $x_0^t$ 中的某个百分位绝对像素值，如果 $s&gt;1$. 那么我 们将 $\boldsymbol{x}_0^t$ 调整到 $[-\mathrm{s}, \mathrm{s}]$ 范围内，然后除以 $s$. 动态阈值处理可以推动饱和像素（接近 -1 或 1) 向内收缩，从而主动防止像素在每一步产生饱和。这可显著提高图像的真实感，以及更好的 图像文本对齐，尤其是在使用非常大的引导权重时，伪代码如下:</p>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="n">p</span><span class="p">:</span> <span class="nb">float</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">T</span><span class="p">)):</span>
        <span class="c1"># Forward pass to get x0_t from z_t.
</span>        <span class="n">x0_t</span> <span class="o">=</span> <span class="n">nn</span><span class="p">(</span><span class="n">z_t</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
        <span class="c1"># Dynamic thresholding (ours).
</span>        <span class="n">s</span> <span class="o">=</span> <span class="n">jnp</span><span class="p">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">jnp</span><span class="p">.</span><span class="nb">abs</span><span class="p">(</span><span class="n">x0_t</span><span class="p">),</span> <span class="n">p</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="nb">tuple</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">x0_t</span><span class="p">.</span><span class="n">ndim</span><span class="p">)))</span>
        <span class="n">s</span> <span class="o">=</span> <span class="n">jnp</span><span class="p">.</span><span class="nb">max</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
        <span class="n">x0_t</span> <span class="o">=</span> <span class="n">jnp</span><span class="p">.</span><span class="n">clip</span><span class="p">(</span><span class="n">x0_t</span><span class="p">,</span> <span class="o">-</span><span class="n">s</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span> <span class="o">/</span> <span class="n">s</span>
        <span class="c1"># Sampler step.
</span>        <span class="n">z_tm1</span> <span class="o">=</span> <span class="n">sampler_step</span><span class="p">(</span><span class="n">x0_t</span><span class="p">,</span> <span class="n">z_t</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
        <span class="n">z_t</span> <span class="o">=</span> <span class="n">z_tm1</span>
    <span class="k">return</span> <span class="n">x0_t</span>
</code></pre></div>    </div>

    <p><img src="/assets/BERTGPTDiffusion%20Research.assets/image-20220606111105610.png" alt="img" /></p>
  </li>
</ul>

<blockquote>
  <h5 id="dynamic-thresholding">Dynamic Thresholding</h5>

  <p>With dynamic thresholding, <strong>a certain percentile absolute pixel value is chosen</strong>. At each timestep, if that percentile value <em>s</em> exceeds 1, then the pixel values are thresholded to [-<em>s</em>, <em>s</em>] and divided by <em>s</em>. This process can be visualized in the below video:</p>

  <video src="/assets/BERTGPTDiffusion%20Research.assets/dynamic_threshold.mp4"></video>

  <p>Dynamic thresholding has the effect of bringing all pixel values back to the range [-1, 1], but operating on all pixels and not just those at the extreme. There is a “gravitational pull” back to 0 which balances the potential for divergence under an iteratively applied model.</p>

  <p>The authors find that this method leads to much better photorealism and alignment, especially for large guidance weights.</p>
</blockquote>

<p>Imagen does text conditioning by first tokenizing the input text and encoding it via the T5 encoder. The encoded text then passes through a pooling step (image below).</p>

<video src="/assets/BERTGPTDiffusion%20Research.assets/cap_cond.mp4" auto-play="true"></video>

<video src="/assets/BERTGPTDiffusion%20Research.assets/super_res.mp4"></video>

<h4 id="timestep-conditioning">Timestep Conditioning</h4>

<p>In Imagen (and generally Diffusion Models as a whole), the same denoising U-Net is used at every timestep. Recall that different amounts of noise are removed at different timesteps in a Diffusion Model. We must therefore devise a way to inject timestep information into the model (i.e. <em>condition</em> on the timestep). The Imagen authors utilize a technique introduced by the original Transformer paper called <strong>positional encoding</strong></p>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/image-20230731150119299.png" alt="image-20230731150119299" style="zoom:67%;" /></p>

<p>In Imagen, a unique <strong>timestep encoding vector</strong> is generated for each timestep (corresponding to “word position” in the original positional embedding implementation). At different resolutions in the U-Net, this vector is projected to having <em>c</em> components, where <em>c</em> is the number of channels in the U-Net at that resolution. After projection, each component of the vector is added to the corresponding channel (across its height and width) in the image.</p>

<p>This process is visualized below for the case of a 3x3 image</p>

<video src="/assets/BERTGPTDiffusion%20Research.assets/time_enc.mp4"></video>

<h4 id="caption-conditioning">Caption Conditioning</h4>

<p>The text embedding is then combined with the image and time step embedding (image below). The model is conditioned via cross-attention over the text embedding. This is implemented by concatenating the text embedding to the key-value pairs of each self-attention layer in the UNet. Cross-attention on the text embedding outperformed simple mean or attention-based pooling.</p>

<p>We’ve yet to incorporate information from our image caption into the Diffusion Model U-Net, so we need to do that now. This caption conditioning happens in two ways.</p>

<ul>
  <li>First, the output vectors from the T5 text encoder are pooled and added into the timestep embedding from above. This process is visualized in the below image:</li>
</ul>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/imagen-conditioning.jpg" alt="Conditioning on time and text embeddings in Imagen" style="zoom:67%;" /></p>

<ul>
  <li>
    <p>Next, the model is conditioned on the entire encoding <em>sequence</em> <strong>by adding cross attention over the text embeddings</strong> at several resolutions. <font color="red">The cross attention is implemented by concatenating the text embedding sequence to the key-value pairs of each self-attention layer</font>.</p>

    <p>The text embedding (green and red boxes below) is used throughout the image generation step. First, it’s used to generate the initial 64 x 64 image from noise (blue box). Then, it is used to increase the image resolution to 256 x 256 and then 1,024 x 1,024 (yellow boxes).</p>
  </li>
</ul>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/imagen-high-level.jpg" alt="High-level overview of Imagen" /></p>

<p>With text conditioning, we can now generate images based on text prompts. But text conditioning alone is insufficient to generate high-quality images that adhere to the text prompt—<em>we also need guidance.</em></p>

<h4 id="classifier-free-guidance-1">Classifier-Free Guidance</h4>

<p>Imagen also takes advantage of Classifier-Free Guidance. Classifier-Free Guidance is a method of increasing the image fidelity of a Diffusion Model at the cost of image diversity. The method is named as such due to the fact that it is a related and simpler version/extension of a previous method called Classifier Guidance, which was used for the same purposes.</p>

<p>Classifier-Free Guidance <strong>works by training a Diffusion Model to be both conditional and unconditional <em>at the same time</em>.</strong> In order to do this, the Diffusion Model is cast as a conditional model and <strong><font color="red">is trained with the conditioning information randomly dropped out a small fraction of the time (by replacing the conditional information with a NULL value)</font></strong>. To use the model in an unconditional way, the NULL value is simply provided as the “conditional information” to the model.</p>

<p>Given such a model, Classifier-Free guidance works loosely by <em>interpolating between the unconditional and conditional gradients</em> during inference. By magnifying the effect of the conditional gradient (i.e. making the “<strong>guidance weight</strong>” greater than 1), better samples can be obtained:</p>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/guidance.png" alt="img" /></p>

<p>Although Classifier-Free Guidance was first introduced by <a href="https://openreview.net/pdf?id=qw8AKxfYbI&amp;ref=assemblyai.com">Ho and Salimans</a>, it was soon after notably used in OpenAI’s <a href="https://arxiv.org/pdf/2112.10741.pdf?ref=assemblyai.com">GLIDE</a> in order to create very high quality (albeit lower diversity) images. For a great resource on Classifier/Classifier-Free Guidance, check out <a href="https://benanne.github.io/2022/05/26/guidance.html?ref=assemblyai.com">this </a>write-up.</p>

<p>According to Imagen’s paper, <strong>Imagen depends critically on classifier-free guidance for effective text conditioning</strong>.</p>

<h3 id="零次学习zero-shot-learning">零次学习（Zero-Shot Learning)</h3>

<h4 id="reference-参考文献">reference 参考文献</h4>

<p>[1]Learning To Detect Unseen Object Classes by Between-Class Attribute Transfer</p>

<p>[2]Transductive Multi-View Zero-Shot Learning.</p>

<p>[3]Hubness and Pollution: Delving into Class-Space Mapping for Zero-Shot Learning.</p>

<p>[4]Ridge Regression, Hubness, and Zero-Shot Learning.</p>

<p>[5]Zero-Shot Visual Recognition using Semantics-Preserving Adversarial Embedding Network.</p>

<p>[6]Zero-Shot Learning via Class-Conditioned Deep Generative Models.</p>

<p>[7]Semantic Autoencoder for Zero-Shot Learning.</p>

<p>[8]Zero-Shot Recognition using Dual Visual-Semantic Mapping Paths.</p>

<p>[9]An Empirical Study and Analysis of Generalized Zero-Shot Learning for Object Recognition in the Wild.</p>

<p>[10]An embarrassingly simple approach to zero-shot learning</p>

<p>[11]Zero-shot recognition using dual visualsemantic mapping paths</p>

<p>[12]Predicting visual exemplars of unseen classes for zero-shot learning</p>

<p>[13]Preserving Semantic Relations for Zero-Shot Learning</p>

<p>[14]Zero-Shot Learning - A Comprehensive Evaluation of the Good, the Bad and the Ugly</p>

<p>[15]Recent Advances in Zero-shot Recognition</p>

<p>[16]<a href="https://link.zhihu.com/?target=http%3A//people.duke.edu/~ww107/material/ZSL.pdf">http://people.duke.edu/~ww107/material/ZSL.pdf</a></p>

<p>[17]Attribute-Based Synthetic Network (ABS-Net): Learning More From Pseudo Feature Representation</p>

<h4 id="general-1">General</h4>

<p>假设小暗（纯粹因为不想用小明）和爸爸，到了动物园，看到了马，然后爸爸告诉他，这就是马；之后，又看到了老虎，告诉他：“看，这种身上有条纹的动物就是老虎。”；最后，又带他去看了熊猫，对他说：“你看这熊猫是黑白色的。”然后，爸爸给小暗安排了一个任务，让他在动物园里找一种他从没见过的动物，叫斑马，并告诉了小暗有关于斑马的信息：“斑马有着马的轮廓，身上有像老虎一样的条纹，而且它像熊猫一样是黑白色的。”最后，小暗根据爸爸的提示，在动物园里找到了斑马（意料之中的结局。。。）。</p>

<p>ZSL就是希望我们的模型能够对其从没见过的类别进行分类，让机器具有推理能力，实现真正的智 能。其中零次 (Zero-shot) 是指对于要分类的类别对象，一次也不学习。这样的能力听上去很具 有吸引力，那么到底是怎么实现的呢?
假设我们的模型已经能够识别马，老虎和熊猫了，现在需要该模型也识别玟马，那么我们需要像爸 爸一样告诉模型，怎样的对象才是斑马，但是并不能直接让模型看见斑马。所以模型需要知道的信 息是马的样本、老虎的样本、熊猫的样本和样本的标签，以及关于前三种动物和斑马的描述。将其 转换为常规的机器学习，这里我们只讨论一般的图片分类问题:
(1) 训练集数据 $X_{t r}$ 及其标签 $Y_{t r}$ ，包含了模型需要学习的类别 (马、老虎和熊猫)，这里和 传统的监督学习中的定义一致；
(2) 测试集数据 $X_{t e}$ 及其标签 $Y_{t e}$ ，包含了模型需要辨识的类别（玟马），这里和传统的监督 学习中也定义一直;
(3) 训练集类别的描述 $A_{t r}$ ，以及测试集类别的描述 $A_{t e}$ ；我们将每一个类别 $y_i \in Y$ ，都 表示成一个语义向量 $a_i \in A$ 的形式，而这个语义向量的每一个维度都表示一种高级的属性，比 如“黑白色”、“有尾巴”、“有羽毛”等等，当这个类别包含这种属性时，那在其维度上被设置为非零 值。对于一个数据集来说，语义向量的维度是固定的，它包含了能够较充分描述数据集中类别的属 性。</p>

<p>.<img src="/assets/BERTGPTDiffusion%20Research.assets/v2-d8efa9870a3ce5ee028277ec57033036_b.png" alt="img" /></p>

<p>在ZSL中，我们希望利用 $X_{t r}$ 和 $Y_{t r}$ 来训练模型，而模型能够具有识别 $X_{t e}$ 的能力，因此模型 需要知道所有类别的描述 $A_{t r}$ 和 $A_{t e}$ 。ZSL这样的设置其实就是上文中小暗识别玩的的过程 中，爸爸为他提供的条件。</p>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/v2-33a9764b792911eedce07dd4974e46f5_b.png" alt="img" /></p>

<p>我们面对的是一个图片分类问题，即对测 试集的样本 $X_{t e}$ 进行分类，而我们分类时需要借助类别的描述 $A$ ，由于每一个类别 $y_i \in Y$ ， 都对应一个语义向量 $a_i \in A$ ，因此我们现在可以忘掉 $Y$ ，直接使用 $A$ 。我们把 $X$ (利用深 度网络提取的图片特征，比如GoogleNet提取为1024维) 称为特征空间 (visual feature space)， 把类别的语义表示 $A$ ，称为语义空间。我们要做的，其实就是建立特征空间与语义空间之间的映 射。
对于分类，我们能想到的最简单的形式就是岭回归 (ridge regression)，俗称均方误差加范数约 束，具体形式为:
\(\min \left\|X_{t r} W-A_{t r}\right\|^2+\eta \Omega(W)\)
其中， $\Omega()$ 通常为 2 范数约束， $\eta$ 为超参，对 $W$ 求导，并让导为 0 ，即可求出 $W$ 的值。测试 时，利用 $W$ 将 $x_i \in X_{t e}$ 投影到语义空间中，并在该空间中寻找到离它最近的 $a_i \in A_{t e}$ ，则样本的类别为 $a_i$ 所对应的标签 $y_i \in Y_{t r}$ 。</p>

<h4 id="zsl中存在的问题">ZSL中存在的问题</h4>

<p><strong>领域漂移问题（domain shift problem）</strong></p>

<p>该问题的正式定义首先由[2]提出。简单来说，就是同一种属性，在不同的类别中，视觉特征的表现可能很大。如图3所示，斑马和猪都有尾巴，因此在它的类别语义表示中，“有尾巴”这一项都是非0值，但是两者尾巴的视觉特征却相差很远。如果斑马是训练集，而猪是测试集，那么利用斑马训练出来的模型，则很难正确地对猪进行分类。</p>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/v2-733de891fa7f478740b35228dad776c2_b.png" alt="img" /></p>

<blockquote>
  <p>由于样本的特征维度往往比语义的维度大，所以建立从 X 到 S 的映射往往会丢失信息，为了保留更多的信息，保持更多的丰富性，最流行的做法是将映射到语义空间中的样本，再重建回去，这样学习到的映射就能够得到保留更多的信息。因此，在原来简单岭回归[1]的基础上，可以将目标函数改为：[7]
\(\min \left\|X_{t r}-W^T A_{t r}\right\|^2+\lambda\left\|W X_{t r}-A_{t r}\right\|^2\)
从目标函数可以看出，这其实完成的是一个简易的自编码器过程，我们简称这个算法为SAE</p>

  <p>[###4.2.2]: 
[###4.2.2 Tractable]: 
[#4.Diffusion Models]: 
[#Diffusion Models]: 
[#1]: 
[# 4.2.2 Tractable]: 
[# Tractable]:</p>
</blockquote>

<p><strong>枢纽点问题（Hubness problem）</strong></p>

<p>这其实是高维空间中固有的问题：在高维空间中，某些点会成为大多数点的最近邻点。这听上去有些反直观，细节方面可以参考[3]。由于ZSL在计算最终的正确率时，使用的是K-NN，所以会受到hubness problem的影响，并且[4]中，证明了基于岭回归的方法会加重hubness problem问题。</p>

<blockquote>
  <p>目前对于枢纽点问题的解决主要有两种方法：</p>

  <p>a. 如果模型建立的方式为岭回归，那么可以建立从语义空间到特征空间的映射，从而不加深hubness problem对结果的影响[4]，也就是说将目标函数（1）改为：
\(\min \left\|X_{t r}-A_{t r} W\right\|^2+\eta \Omega(W)\)
b.可以使用生成模型，比如自编码器、GAN等，生成测试集的样本，这样就变成了一个传统的监督分类问题，不存在K-NN的操作，所以不存在hubness problem的影响。</p>
</blockquote>

<p><strong>语义间隔（semantic gap）</strong></p>

<p>样本的特征往往是视觉特征，比如用深度网络提取到的特征，而语义表示却是非视觉的，这直接反应到数据上其实就是：样本在特征空间中所构成的流型与语义空间中类别构成的流型是不一致的。（如图4所示）这使得直接学习两者之间的映射变得困难。</p>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/v2-869ec7e6e0f91229f8f66997ce59123a_b.png" alt="img" /></p>

<blockquote>
  <p>语义间隔问题的本质是二者的流形结构不一致，因此，解决此问题的着手点就在于将两者的流形调整到一致，再学习两者之间的映射[8]。最简单的方法自然是将类别的语义表示调整到样本的流型上，即用类别语义表示的K近邻样本点，重新表示类别语义即可。</p>
</blockquote>

<h2 id="416-latent-diffusion-model-ldm-rombach--blattmann-et-al-2022"><em>4.16 Latent diffusion model</em> (<strong>LDM</strong>; <a href="https://arxiv.org/abs/2112.10752">Rombach &amp; Blattmann, et al. 2022</a>)</h2>

<p>runs the diffusion process in the latent space instead of pixel space, making training cost lower and inference speed faster. It is motivated by the observation that most bits of an image contribute to perceptual details and the semantic and conceptual composition still remains after aggressive compression. LDM loosely decomposes the perceptual compression and semantic compression with generative modeling learning by first trimming off pixel-level redundancy with autoencoder and then manipulate/generate semantic concepts with diffusion process on learned latent.</p>

<h1 id="5-introducing-bart">5 Introducing BART</h1>

<table>
  <tbody>
    <tr>
      <td>refer to [Introducing BART</td>
      <td>TensorGoose (sshleifer.github.io)](https://sshleifer.github.io/blog_v2/jupyter/2020/03/12/bart.html#Encoder-Decoder)</td>
    </tr>
  </tbody>
</table>

<h3 id="overview">Overview</h3>

<p>For the past few weeks, I worked on integrating BART into <a href="https://github.com/huggingface/transformers/">transformers</a>. This post covers the high-level differences between BART and its predecessors and how to use the new <code class="language-plaintext highlighter-rouge">BartForConditionalGeneration</code> to summarize documents. Leave a comment below if you have any questions!</p>

<h3 id="background-seq2seq-pretraining">Background: Seq2Seq Pretraining</h3>

<p>In October 2019, teams from Google and Facebook published new transformer papers: <a href="https://arxiv.org/abs/1910.10683">T5</a> and <a href="https://arxiv.org/abs/1910.13461">BART</a>. Both papers achieved better downstream performance on generation tasks, like abstractive summarization and dialogue, with two changes:</p>

<ul>
  <li>add <strong>a causal decoder to BERT’s bidirectional encoder architecture</strong></li>
  <li>replace BERT’s fill-in-the blank cloze task with a more complicated mix of pretraining tasks</li>
</ul>

<h4 id="bert-vs-gpt2">Bert vs. GPT2</h4>

<p>As the BART authors write,</p>

<blockquote>
  <p>(BART) can be seen as <strong>generalizing Bert (due to the bidirectional encoder) and GPT2 (with the left to right decoder).</strong></p>
</blockquote>

<p>Bert is pretrained to try to <strong>==predict masked tokens, and uses the whole sequence to get enough info to make a good guess==</strong>. This is good for tasks where the prediction at position <code class="language-plaintext highlighter-rouge">i</code> is allowed to utilize information from positions after <code class="language-plaintext highlighter-rouge">i</code>, but less useful for tasks, like text generation, where the prediction for position <code class="language-plaintext highlighter-rouge">i</code> can only depend on previously generated words.</p>

<p><strong>In code, the idea of “what information can be used use when predicting the token at position <code class="language-plaintext highlighter-rouge">i</code>” is controlled by an argument called <code class="language-plaintext highlighter-rouge">attention_mask</code><a href="https://sshleifer.github.io/blog_v2/jupyter/2020/03/12/bart.html#fn-2">1</a>. A value of 1 in the attention mask means that the model can use information for the column’s word when predicting the row’s word.</strong></p>

<p>Here is Bert’s “Fully-visible”<a href="https://sshleifer.github.io/blog_v2/jupyter/2020/03/12/bart.html#fn-3">2</a> <code class="language-plaintext highlighter-rouge">attention_mask</code>:</p>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/diagram_bert_v5.png" alt="img" /></p>

<ol>
  <li>the same parameter that is used to make model predictions invariant to pad tokens.<a href="https://sshleifer.github.io/blog_v2/jupyter/2020/03/12/bart.html#fnref-2">↩</a></li>
  <li>“Fully-Visible” and “bidirectional” are used interchangeably. Same with “causal” and “autoregressive”.<a href="https://sshleifer.github.io/blog_v2/jupyter/2020/03/12/bart.html#fnref-3">↩</a></li>
</ol>

<p><strong>==GPT2, meanwhile, is pretrained to predict the next word using a causal mask, and is more effective for generation tasks==</strong>, but less effective on downstream tasks where the whole input yields information for the output.</p>

<p>Here is the <code class="language-plaintext highlighter-rouge">attention_mask</code> for GPT2:</p>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/diagram_bartpost_gpt2.jpg" alt="img" /></p>

<p>The prediction for “eating”, only utilizes previous words: “<code class="language-plaintext highlighter-rouge">&lt;BOS&gt;</code> I love”.</p>

<h4 id="encoder-decoder--bart--bert--gpt">Encoder-Decoder ( BART = BERT + GPT)</h4>

<p>Our new friends, like BART, get the best of both worlds.</p>

<p>The encoder’s <code class="language-plaintext highlighter-rouge">attention_mask</code> is fully visible, like BERT:<img src="/assets/BERTGPTDiffusion%20Research.assets/seq2seq_enc_v5.png" alt="img" /></p>

<p>The decoder’s <code class="language-plaintext highlighter-rouge">attention_mask</code> is causal, like GPT2:</p>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/seq2seq_dec.png" alt="img" /></p>

<p><strong>The encoder and decoder are connected by cross-attention</strong>, <strong>==where each decoder layer performs attention over the final hidden state of the encoder output==</strong>. This presumably nudges the models towards generating output that is closely connected to the original input.</p>

<blockquote>
  <h1 id="what-are-the-inputs-to-the-first-decoder-layer"><a href="https://datascience.stackexchange.com/questions/88981/what-are-the-inputs-to-the-first-decoder-layer-in-a-transformer-model-during-the">What are the inputs to the first decoder layer</a></h1>

  <p>Following your example:</p>

  <ul>
    <li>The source sequence would be <code class="language-plaintext highlighter-rouge">How</code> <code class="language-plaintext highlighter-rouge">are</code> <code class="language-plaintext highlighter-rouge">you</code> <code class="language-plaintext highlighter-rouge">&lt;EOS&gt;</code></li>
    <li>The input to the encoder would be <code class="language-plaintext highlighter-rouge">How</code> <code class="language-plaintext highlighter-rouge">are</code> <code class="language-plaintext highlighter-rouge">you</code> <code class="language-plaintext highlighter-rouge">&lt;EOS&gt;</code>. Note that there is no <code class="language-plaintext highlighter-rouge">&lt;start&gt;</code> token here.</li>
    <li>The target sequence would be <code class="language-plaintext highlighter-rouge">I</code> <code class="language-plaintext highlighter-rouge">am</code> <code class="language-plaintext highlighter-rouge">fine</code> <code class="language-plaintext highlighter-rouge">&lt;EOS&gt;</code> . The output of the decoder will be compared against this in the training.</li>
    <li>The input to the decoder would be <code class="language-plaintext highlighter-rouge">&lt;start&gt;</code> <code class="language-plaintext highlighter-rouge">I</code> <code class="language-plaintext highlighter-rouge">am</code> <code class="language-plaintext highlighter-rouge">fine</code> .</li>
  </ul>

  <p>Notice that the input to the decoder is the target sequence shifted one position to the right by the token that signals the beginning of the sentence. The logic of this is that the output at each position should receive the previous tokens (and not the token at the same position, of course), which is achieved with this shift together with the self-attention mask.</p>
</blockquote>

<blockquote>
  <h1 id="why-does-the-paper-say-this-maximum-sentence-length-thing">why does the paper say this maximum sentence length thing</h1>

  <p>going through the seq2seq-translation tutorial on pytorch (https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html#sphx-glr-intermediate-seq2seq-translation-tutorial-py) and found the following sentence:
Because there are sentences of all sizes in the training data, to actually create and train this layer we have to choose a maximum sentence length (input length, for encoder outputs) that it can apply to. Sentences of the maximum length will use all the attention weights, while shorter sentences will only use the first few.
which didn’t really make sense to me. My understanding of attention is that attention is computed as follows (according to the Pointer Network paper) at time step $t$ :
\(\begin{gathered}
u^{&lt;t, j&gt;}=v^{\top} \tanh \left(W_1 e_j+W_2 d_t\right)=N N_u\left(e_j, d_t\right) \\
\alpha^{&lt;t, j&gt;}=\operatorname{softmax}\left(u^{&lt;t, j&gt;}\right)=\frac{\exp \left(u^{&lt;t, j&gt;}\right)}{Z^{&lt;t&gt;}}=\frac{\exp \left(u^{&lt;t, j&gt;}\right)}{\sum_{k=1}^{T_x} \exp \left(u^{&lt;t, k&gt;}\right)} \\
d_{&lt;i+1&gt;}^{\prime}=\sum_{j=1}^{T_x} \alpha^{&lt;t, j&gt;} e_j
\end{gathered}\)
which basically means that a specific attention weight is not dependent on the length of the encoder (i.e. the encoder can change size and the above equation won’t be affected because $T_x$ can be variable size).</p>

  <ul>
    <li>
      <p>It is only an efficiency issue. In theory, the attention mechanism can work with arbitrarily long sequences. The reason is that batches must be padded to the same length.</p>
    </li>
    <li>
      <p>The tutorial mentioned in the question appears to have the peculiar mechanism
\(w_i \propto \exp \left(a_i^T v\right)\)</p>

      <p>Where $a_i$ is the $i$ th row of a learned weight matrix $A$. I say that it is peculiar because the weight on the $i$ th input element does not actually depend on any of the $u_i$ at all! In fact we can view this mechanism as attention over word slots – how much attention to put to the first word, the second word, third word etc, which does not pay any attention to which words are occupying which slots.</p>

      <p>Since $A$, a learned weight matrix, must be fixed in size, then the number of word slots must also be fixed, which means the input sequence length must be constant (shorter inputs can be padded). Of course this peculiar attention mechanism doesn’t really make sense at all, so I wouldn’t read too much into it.</p>
    </li>
    <li>
      <p>(<a href="https://stats.stackexchange.com/questions/344508/what-are-attention-mechanisms-exactly/345441#345441">time series - What are attention mechanisms exactly? - Cross Validated (stackexchange.com)</a>) Attention is a method for aggregating a set of vectors $v_i$ into just one vector, often via a lookup vector $\boldsymbol{u}$. Usually, $\boldsymbol{v}_{\boldsymbol{i}}$ is either the inputs to the model or the hidden states of previous time-steps, or the hidden states one level down (in the case of stacked LSTMs).</p>

      <p>The result is often called the context vector $\boldsymbol{c}$, since it contains the context relevant to the current time-step.</p>

      <p>This additional context vector $c$ is then fed into the RNN/LSTM as well (it can be simply concatenated with the original input). Therefore, the context can be used to help with prediction.</p>

      <p>The simplest way to do this is to compute probability vector $p=\operatorname{softmax}\left(V^T u\right)$ and $c=\sum_i p_i v_i$ where $V$ is the concatenation of all previous $v_i$. A common lookup vector $u$ is the current hidden state $h_t$.</p>

      <p>There are many variations on this, and you can make things as complicated as you want. For example, instead using $v_i^T u$ as the logits, one may choose $f\left(v_i, u\right)$ instead, where $f$ is an arbitrary neural network.</p>

      <p><strong>A common attention mechanism for sequence-to-sequence models uses</strong>
<strong>$p=\operatorname{softmax}\left(q^T \tanh \left(W_1 v_i+W_2 h_t\right)\right)$, where $v$ are the hidden states of the encoder, and $h_t$ is the current hidden state of the decoder. $q$ and both $W \mathrm{~s}$ are parameters.</strong></p>

      <p>Some papers which show off different variations on the attention idea:</p>

      <ul>
        <li>
          <p>Pointer Networks use attention to reference inputs in order to solve combinatorial optimization problems.</p>
        </li>
        <li>
          <p>Recurrent Entity Networks maintain separate memory states for different entities (people/objects) while reading text, and update the correct memory state using attention.</p>
        </li>
        <li>
          <p>Transformer models also make extensive use of attention. Their formulation of attention is slightly more general and also involves key vectors $k_i$ : the attention weights $p$ are actually computed between the keys and the lookup, and the context is then constructed with the $\boldsymbol{v}_{\boldsymbol{i}}$.</p>
        </li>
      </ul>

      <p>Here is a quick implementation of one form of attention, although I can’t guarantee correctness beyond the fact that it passed some simple tests.</p>
    </li>
  </ul>
</blockquote>

<blockquote>
  <h1 id="the-restriction-in-the-maximum-length">The restriction in the maximum length</h1>

  <p>==The restriction in the maximum length== of the transformer input is due to the needed <strong>amount of memory</strong> to compute the self-attention over it.</p>

  <p>The amount of memory needed by the self-attention in the Transformer is <strong>quadratic on the length of the input</strong>. This means that increasing the maximum length of the input, increases drastically the needed memory for self-attention. The maximum length is that which makes the model use up the whole memory of the GPU for at least one sentence (once the other elements of the model are also taken into account, like the embeddings which take a lot of memory).</p>

  <p><a href="https://openreview.net/forum?id=HJePno0cYm">Transformer-XL</a> is certainly a way to take into account as much context as possible in language modeling (its role is analogous to truncated back-propagation through time in LSTM language models). However, the gradients are not propagated through the attention over the memory segment, only through the current segment.</p>

  <p>There have been several architectural attempts to reduce the amount of memory needed by transformers, like using <a href="https://openreview.net/forum?id=SkVhlh09tX">locality-constraints in the attention</a> (<strong>Dynamic Convolutions model</strong>) or using <a href="https://openreview.net/forum?id=rkgNKkHtvB">locality-sensitive hashing</a> (<strong>Reformer model</strong>).</p>

  <p>There have been other implementation attempts, like <strong>gradient checkpointing</strong>(e.g. <a href="https://qywu.github.io/2019/05/22/explore-gradient-checkpointing.html">this</a>), which is a general technique to run computations that don’t fit at once in the GPU memory</p>
</blockquote>

<blockquote>
  <h2 id="cross-attention-algorithm">Cross-attention Algorithm</h2>

  <ul>
    <li>Let us have embeddings (token) sequences S1 and S2</li>
    <li>Calculate Key and Value from sequence S1</li>
    <li>Calculate Queries from sequence S2</li>
    <li>Calculate <a href="https://vaclavkosar.com/ml/transformers-self-attention-mechanism-simplified">attention matrix</a> from Keys and Queries</li>
    <li>Apply queries to the attention matrix</li>
    <li>Output sequence has dimension and length of sequence S2</li>
  </ul>

\[\text { In an equation: } \operatorname{sof} \operatorname{tmax}\left(\left(W_Q S_2\right)\left(W_K S_1\right)^{\top}\right) W_V S_1\]

  <p><img src="/assets/BERTGPTDiffusion%20Research.assets/cross-attention-detail-perceiver-io.png" alt="cross-attention perceiver io detail" /></p>

  <h2 id="cross-attention-vs-self-attention">Cross-attention vs Self-attention</h2>

  <p>Except for inputs, cross-attention calculation is the same as <a href="https://vaclavkosar.com/ml/transformers-self-attention-mechanism-simplified">self-attention</a>. Cross-attention combines asymmetrically two separate embedding sequences of same dimension, in contrast self-attention input is a single embedding sequence. One of the sequences serves as a query input, while the other as a key and value inputs. Alternative <a href="https://vaclavkosar.com/ml/cross-attention-in-transformer-architecture#cross-attention-in-selfdoc">cross-attention in SelfDoc</a>, uses query and value from one sequence, and key from the other.</p>

  <p><a href="https://vaclavkosar.com/ml/Feed-Forward-Self-Attendion-Key-Value-Memory">The feed forward layer</a> is related to cross-attention, except the feed forward layer does use softmax and one of the input sequences is static. <a href="https://vaclavkosar.com/ml/Feed-Forward-Self-Attendion-Key-Value-Memory">Augmenting Self-attention with Persistent Memory paper</a> shows that Feed Forward layer calculation made the same as self-attention.</p>

  <h3 id="cross-attention-in-transformer-decoder">Cross-Attention in Transformer Decoder</h3>

  <p><a href="https://vaclavkosar.com/ml/cross-attention-in-transformer-architecture">Cross-Attention in Transformer Architecture (vaclavkosar.com)</a></p>

  <p>Cross-attention is widely used in <a href="https://vaclavkosar.com/ml/Encoder-only-Decoder-only-vs-Encoder-Decoder-Transfomer">encoder-decoder</a> or multi-modality use cases.</p>

  <p>Cross-attention was described in the <a href="https://vaclavkosar.com/ml/transformers-self-attention-mechanism-simplified">Transformer</a> paper, but it was not given this name yet. Transformer decoding starts with full input sequence, but empty decoding sequence. Cross-attention introduces information from the input sequence to the layers of the decoder, such that it can predict the next output sequence token. The <a href="https://vaclavkosar.com/ml/Encoder-only-Decoder-only-vs-Encoder-Decoder-Transfomer">decoder</a> then adds the token to the output sequence, and repeats this autoregressive process until the EOS token is generated.</p>

  <p><img src="/assets/BERTGPTDiffusion%20Research.assets/cross-attention-in-transformer-decoder.png" alt="Cross-Attention in the Transformer decoder of Attention is All You Need paper" /></p>

  <p><img src="/assets/BERTGPTDiffusion%20Research.assets/15xN9xmT4QPua9Cpd4fjqCw.png" alt="img" /></p>

  <h2 id="cross-attention-implementation">Cross-attention Implementation</h2>

  <p>Have a look at <a href="https://github.com/huggingface/diffusers/blob/4125756e88e82370c197fecf28e9f0b4d7eee6c3/src/diffusers/models/cross_attention.py">CrossAttention implementation</a> in Diffusers library, which can generate images with <strong>Stable Diffusion</strong>. In this case the cross-attention is used to <strong>condition transformers inside a UNet layer with a text prompt for image generation</strong>. The constructor shows, how we can also have <strong>different dimensions</strong> and if you step through with a debugger, you will also see the <strong>different sequence length between the two modalities</strong> .</p>

  <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">CrossAttention</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sa">r</span><span class="s">"""
    A cross attention layer.

    Parameters:
        query_dim (`int`): The number of channels in the query.
        cross_attention_dim (`int`, *optional*):
            The number of channels in the encoder_hidden_states. If not given, defaults to `query_dim`.
        heads (`int`,  *optional*, defaults to 8): The number of heads to use for multi-head attention.
        dim_head (`int`,  *optional*, defaults to 64): The number of channels in each head.
        dropout (`float`, *optional*, defaults to 0.0): The dropout probability to use.
        bias (`bool`, *optional*, defaults to False):
            Set to `True` for the query, key, and value linear layers to contain a bias parameter.
    """</span>
        <span class="n">query</span> <span class="o">=</span> <span class="n">attn</span><span class="p">.</span><span class="n">to_q</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">)</span>
        <span class="n">query</span> <span class="o">=</span> <span class="n">attn</span><span class="p">.</span><span class="n">head_to_batch_dim</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>

        <span class="n">encoder_hidden_states</span> <span class="o">=</span> <span class="n">encoder_hidden_states</span> <span class="k">if</span> <span class="n">encoder_hidden_states</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span> <span class="k">else</span> <span class="n">hidden_states</span>
        <span class="n">key</span> <span class="o">=</span> <span class="n">attn</span><span class="p">.</span><span class="n">to_k</span><span class="p">(</span><span class="n">encoder_hidden_states</span><span class="p">)</span>
        <span class="n">value</span> <span class="o">=</span> <span class="n">attn</span><span class="p">.</span><span class="n">to_v</span><span class="p">(</span><span class="n">encoder_hidden_states</span><span class="p">)</span>
        <span class="n">key</span> <span class="o">=</span> <span class="n">attn</span><span class="p">.</span><span class="n">head_to_batch_dim</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
        <span class="n">value</span> <span class="o">=</span> <span class="n">attn</span><span class="p">.</span><span class="n">head_to_batch_dim</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>

        <span class="n">attention_probs</span> <span class="o">=</span> <span class="n">attn</span><span class="p">.</span><span class="n">get_attention_scores</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">)</span>
        <span class="n">hidden_states</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">bmm</span><span class="p">(</span><span class="n">attention_probs</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
</code></pre></div>  </div>

  <h3 id="cross-attention-in-stable-diffusion">Cross-Attention in Stable Diffusion</h3>

  <p>Stable Diffusion uses cross-attention <strong>for image generation to condition transformers with a text prompt</strong> inside the denoising U-Net layer.</p>

  <p><a href="https://vaclavkosar.com/images/stable-diffusion-architecture.png"><img src="https://vaclavkosar.com/images/stable-diffusion-architecture.png" alt="stable diffusion architecture with cross-attention" />stable diffusion architecture with cross-attention</a></p>

  <h3 id="cross-attention-in-perceiver-io">Cross-Attention in Perceiver IO</h3>

  <p><a href="https://arxiv.org/pdf/2107.14795.pdf">Perceiver IO</a> is a general-purpose multi-modal architecture that can handle wide variety of inputs as well as outputs. Perceiver can be applied to for example <a href="https://vaclavkosar.com/ml/Multimodal-Image-Text-Classification">image-text classification</a>. Perceiver IO uses <a href="https://vaclavkosar.com/ml/cross-attention-in-transformer-architecture">cross-attention</a> for merging:</p>

  <ul>
    <li>multimodal input sequences (e.g. image, text, audio) into a low dimensional latent sequence</li>
    <li>“output query” or “command” to decode the output value e.g. predict this masked word</li>
  </ul>

  <p><a href="https://vaclavkosar.com/images/cross-attention-perceiver-io.png"><img src="https://vaclavkosar.com/images/cross-attention-perceiver-io.png" alt="Perceiver IO architecture" />Perceiver IO architecture</a></p>

  <p>Advantage of the Perceiver architecture is that in general you can work with very large inputs. Architecture <a href="https://arxiv.org/pdf/2202.10890.pdf">Hierarchical Perceiver</a> has ability to process even longer input sequences by splitting into subsequences and then merging them. Hierarchical Perceiver also learns the positional encodings with a separate training step with a reconstruction loss.</p>

  <h3 id="cross-attention-in-selfdoc">Cross-Attention in SelfDoc</h3>

  <p><a href="https://vaclavkosar.com/images/selfdoc-cross-attention.png"><img src="https://vaclavkosar.com/images/selfdoc-cross-attention.png" alt="selfdoc cross-attention" />selfdoc cross-attention</a></p>

  <p>In <a href="https://arxiv.org/pdf/2106.03331.pdf">Selfdoc</a>, cross-attention is integrated in a special way. First step of their Cross-Modality Encoder, instead uses value and query from sequence A and then key from the sequence B.</p>

  <h3 id="other-cross-attention-examples">Other Cross-Attention Examples</h3>

  <ul>
    <li><a href="https://vaclavkosar.com/ml/DeepMinds-RETRO-Transformer-Model">DeepMind’s RETRO Transformer uses cross-attention to incorporate the database retrived sequences</a></li>
    <li><a href="https://github.com/huggingface/transformers/blob/198c335d219a5eb4d3f124fdd1ce1a9cd9f78a9b/src/transformers/models/bert/modeling_bert.py#L268">Code example: HuggingFace BERT (key, value are from the encoder, while query is from the decoder)</a></li>
    <li><a href="https://arxiv.org/pdf/2103.14899.pdf">CrossVit - here only simplified cross-attention is used</a></li>
    <li><a href="https://arxiv.org/pdf/2104.08771v1.pdf">On the Strengths of Cross-Attention in Pretrained Transformers for Machine Translation</a></li>
  </ul>
</blockquote>

<h4 id="pretraining-fill-in-the-span">Pretraining: Fill In the Span</h4>

<p>Bart and T5 are both pretrained<a href="https://sshleifer.github.io/blog_v2/jupyter/2020/03/12/bart.html#fn-5">1</a> on tasks where <strong>spans</strong> of text are replaced by masked tokens. The model must learn to reconstruct the original document. Figure 1 from the BART paper explains it well:</p>

<p><img src="/assets/BERTGPTDiffusion%20Research.assets/text_infilling.png" alt="img" />In this example, the original document is A B C D E. the span <code class="language-plaintext highlighter-rouge">[C, D]</code> is masked before encoding and an extra mask is inserted before B, leaving the corrupted document <code class="language-plaintext highlighter-rouge">'A _ B _ E'</code> as input to the encoder.</p>

<p>==The decoder (autogressive means “uses a causal mask”) must reconstruct the original document, using the encoder’s output and previous uncorrupted tokens.==</p>

<hr />

<ol>
  <li>This is a bit of a simplification. Both papers experiment with many different pretraining tasks, and find that this one performs well. T5 uses a “replace corrupted spans” task. Instead of putting masks, they put in a random token.<a href="https://sshleifer.github.io/blog_v2/jupyter/2020/03/12/bart.html#fnref-5">↩</a></li>
</ol>

<h3 id="summarization">Summarization</h3>

<p>In summarization tasks, the <code class="language-plaintext highlighter-rouge">input</code> sequence is the document we want to summarize, and the <code class="language-plaintext highlighter-rouge">output</code> sequence is a ground truth summary. Seq2Seq archictectures can be directly finetuned on summarization tasks, without any new randomly initialized heads. The pretraining task is also a good match for the downstream task. In both settings, the input document must be copied from the input with modification. The numbers confirm this: all the new fancy Seq2Seq models do a lot better than the old less-fancy guys on the CNN/Daily Mail abstractive summarization task, and BART does especially well.</p>

<table>
  <thead>
    <tr>
      <th style="text-align: left">Model</th>
      <th style="text-align: right">Rouge2</th>
      <th style="text-align: left">Model Size</th>
      <th style="text-align: left">Pretraining</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">PT-Gen</td>
      <td style="text-align: right">17.28</td>
      <td style="text-align: left">22 M</td>
      <td style="text-align: left">None</td>
    </tr>
    <tr>
      <td style="text-align: left">TransformerAbs</td>
      <td style="text-align: right">17.76</td>
      <td style="text-align: left">200M</td>
      <td style="text-align: left">None</td>
    </tr>
    <tr>
      <td style="text-align: left">BertSumABS</td>
      <td style="text-align: right">19.39</td>
      <td style="text-align: left">220 M</td>
      <td style="text-align: left">Encoder</td>
    </tr>
    <tr>
      <td style="text-align: left">UniLM</td>
      <td style="text-align: right">20.3</td>
      <td style="text-align: left">340 M</td>
      <td style="text-align: left">Seq2Seq</td>
    </tr>
    <tr>
      <td style="text-align: left">T5-base</td>
      <td style="text-align: right">20.34</td>
      <td style="text-align: left">770 M</td>
      <td style="text-align: left">Seq2Seq</td>
    </tr>
    <tr>
      <td style="text-align: left">Bart</td>
      <td style="text-align: right">21.28</td>
      <td style="text-align: left">406 M</td>
      <td style="text-align: left">Seq2Seq</td>
    </tr>
    <tr>
      <td style="text-align: left">T5-11B</td>
      <td style="text-align: right">21.55</td>
      <td style="text-align: left">11 B</td>
      <td style="text-align: left">Seq2Seq</td>
    </tr>
  </tbody>
</table>

<ul>
  <li><code class="language-plaintext highlighter-rouge">BertSumABS</code> (from <a href="https://arxiv.org/abs/1908.08345"><em>Text Summarization with Pretrained Encoders</em></a>, uses a Seq2Seq architecture but doesn’t pretrain the decoder. <code class="language-plaintext highlighter-rouge">TransformerAbs</code>, from the same paper, uses a slightly smaller model and no pretraining.</li>
  <li><code class="language-plaintext highlighter-rouge">PT-Gen</code> is from <a href="https://arxiv.org/pdf/1704.04368.pdf">Get To The Point: Summarization with Pointer-Generator Networks</a></li>
  <li><a href="https://arxiv.org/abs/1905.03197">UniLM</a> is a “Prefix-LM” with a similar masking strategy to Bart and T5.</li>
</ul>

<h1 id="6-language-modeling">6 Language Modeling</h1>

<h2 id="causal-language-modeling-clm">Causal Language Modeling (CLM):</h2>

<ul>
  <li>Implementation: In CLM, the model is trained to predict the next token in the sequence, given the previous tokens. During training, the input tokens are fed into the model, and the model predicts the probability distribution of the next token. The loss is calculated based on the model’s predictions and the actual target tokens, which are just the input tokens shifted by one position.</li>
  <li>Architecture: CLM is typically used with autoregressive models like GPT. These models use a unidirectional (left-to-right) Transformer architecture, where each token can only attend to the tokens that come before it. This prevents the model from “cheating” by attending to the target tokens during training.</li>
  <li>Output Model: A fine-tuned CLM model can generate coherent text by predicting one token at a time, making it suitable for text generation tasks. However, it may not be as effective at capturing bidirectional context compared to MLM models.</li>
</ul>

<h2 id="masked-language-modeling-mlm">Masked Language Modeling (MLM):</h2>

<ul>
  <li>Implementation: In MLM, the model is trained to predict masked tokens within the input sequence. During preprocessing, a certain percentage of tokens are randomly masked, and the model is trained to predict the original tokens at those masked positions. The loss is calculated based on the model’s predictions and the actual target tokens (the original tokens that were masked).</li>
  <li>Architecture: MLM is used with models like BERT, which use a bidirectional Transformer architecture. Unlike CLM models, MLM models can attend to all tokens in the input sequence during training, allowing them to capture context from both left and right.</li>
  <li>Output Model: A fine-tuned MLM model is better at understanding context and relationships between words in a sequence, making it suitable for tasks like text classification, sentiment analysis, named entity recognition, or question answering.</li>
</ul>

<h2 id="sequence-to-sequence-seq2seq-modeling">Sequence-to-Sequence (seq2seq) Modeling:</h2>

<ul>
  <li>Implementation: In seq2seq modeling, the model is trained to generate output sequences based on input sequences. The model consists of two parts: an encoder that encodes the input sequence into a latent representation, and a decoder that generates the output sequence based on this latent representation. The loss is calculated based on the model’s predictions and the actual target output tokens.</li>
  <li>Architecture: Seq2seq models typically use an encoder-decoder architecture, where both the encoder and decoder can be based on the Transformer architecture (e.g., T5, BART) or other architectures like LSTMs (e.g., the original seq2seq model). The encoder processes the input sequence and generates a context representation, while the decoder generates the output sequence based on the encoder’s output and its own hidden state.</li>
  <li>Output Model: A fine-tuned seq2seq model is better at tasks where the model needs to generate coherent output text based on input text, such as summarization, translation, or question answering.</li>
</ul>

<h1 id="7-gan-model">7. GAN Model</h1>

<table>
  <tbody>
    <tr>
      <td>[能量视角下的GAN模型（二）：GAN＝“分析”＋“采样” - 科学空间</td>
      <td>Scientific Spaces (kexue.fm)](https://kexue.fm/archives/6331)</td>
    </tr>
  </tbody>
</table>

<h2 id="71-drag-your-gan理解项目地址httpsgithubcomzeqiang-laidraggan">7.1. Drag Your GAN理解<strong>项目地址</strong>：https://github.com/Zeqiang-Lai/DragGAN</h2>
<p><strong>论文地址</strong>：https://vcai.mpi-inf.mpg.de/projects/DragGAN/
<strong>代码地址</strong>：https://github.com/XingangPan/DragGAN</p>

<p><a href="https://zhuanlan.zhihu.com/p/632113718">Drag Your GAN理解 - 知乎 (zhihu.com)</a></p>

<p>Drag Your GAN: Interactive Point-based Manipulation on the Generative Image Manifold是一篇在SIGGRAPH 2023会议上发表的论文¹，介绍了一种基于GAN的图像变形方法，可以让用户通过拖动图像上的任意点来精确地控制生成对象的姿态、形状、表情和布局²。该方法包括两个主要组成部分：</p>

<p>1) 基于特征的运动监督，用于驱动手柄点向目标位置移动；
2)  一种新的点跟踪方法，利用GAN的判别特征来持续定位手柄点的位置¹。该方法可以应用于多种类别的图像，如动物、汽车、人类、风景等，即使在遮挡内容和形状变形等困难场景下，也能生成逼真的输出²。该方法还可以通过GAN反演来操作真实图像¹。该方法的代码已经开源在GitHub上</p>

<p>Drag Your GAN的输入数据是一个图像和两个点，分别表示手柄点和目标点。输出数据是一个变形后的图像，使得手柄点移动到目标点的位置。损失函数由两部分组成，一部分是判别损失，用于衡量生成图像的真实性和质量，另一部分是运动损失，用于衡量手柄点和目标点之间的距离</p>

<p>Drag Your GAN的实现步骤大致如下：</p>

<ol>
  <li>首先，需要选择一个预训练好的GAN模型，如StyleGAN2¹，并将其转换为PyTorch版本。</li>
  <li>然后，需要为GAN模型定义一个特征提取器，用于从生成器的中间层提取特征图。特征提取器可以是一个简单的卷积层或者一个更复杂的网络。</li>
  <li>接着，需要为GAN模型定义一个判别器，用于判断生成图像的真实性和质量。判别器可以是一个简单的全连接层或者一个更复杂的网络。</li>
  <li>然后，需要为GAN模型定义一个点跟踪器，用于在特征图上定位手柄点的位置。点跟踪器可以是一个简单的卷积层或者一个更复杂的网络。</li>
  <li>接着，需要为GAN模型定义一个运动监督器，用于计算手柄点在特征图上的运动向量，并将其加到生成器的输入向量上。运动监督器可以是一个简单的全连接层或者一个更复杂的网络。</li>
  <li>然后，需要为GAN模型定义一个优化器，用于更新生成器的输入向量，并最小化判别器的损失和运动监督器的损失。优化器可以是Adam或者其他梯度下降方法。</li>
  <li>最后，需要为GAN模型定义一个用户交互界面，用于在图像上选择手柄点和目标点，并触发点跟踪器、运动监督器和优化器来实现图像变形¹。用户交互界面可以是Gradio或者其他可视化工具。</li>
</ol>

<p>[调转到标题1]:</p>

<p>[maximum this likelihood]:</p>]]></content><author><name>Zhu Tianda</name></author><category term="LEARNING" /><category term="AI" /><category term="BERT" /><category term="GPT" /><category term="Diffusion" /><summary type="html"><![CDATA[1.BERT (Bidirectional Encoder Representation Transformer#1) [调转到标题1]: [maximum this likelihood]:]]></summary></entry><entry><title type="html">BERT Pytorch from Scratch</title><link href="http://0.0.0.0:8855/coding/2023/12/01/BERT-Pytorch-Scratch.html" rel="alternate" type="text/html" title="BERT Pytorch from Scratch" /><published>2023-12-01T00:00:00+08:00</published><updated>2023-12-01T00:00:00+08:00</updated><id>http://0.0.0.0:8855/coding/2023/12/01/BERT-Pytorch-Scratch</id><content type="html" xml:base="http://0.0.0.0:8855/coding/2023/12/01/BERT-Pytorch-Scratch.html"><![CDATA[<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">transformers</span> <span class="n">datasets</span> <span class="n">tokenizers</span>
<span class="err">!</span><span class="n">wget</span> <span class="n">http</span><span class="p">:</span><span class="o">//</span><span class="n">www</span><span class="p">.</span><span class="n">cs</span><span class="p">.</span><span class="n">cornell</span><span class="p">.</span><span class="n">edu</span><span class="o">/~</span><span class="n">cristian</span><span class="o">/</span><span class="n">data</span><span class="o">/</span><span class="n">cornell_movie_dialogs_corpus</span><span class="p">.</span><span class="nb">zip</span>
<span class="err">!</span><span class="n">unzip</span> <span class="o">-</span><span class="n">qq</span> <span class="n">cornell_movie_dialogs_corpus</span><span class="p">.</span><span class="nb">zip</span>
<span class="err">!</span><span class="n">rm</span> <span class="n">cornell_movie_dialogs_corpus</span><span class="p">.</span><span class="nb">zip</span>
<span class="err">!</span><span class="n">mkdir</span> <span class="n">datasets</span>
<span class="err">!</span><span class="n">mv</span> <span class="n">cornell</span>\ <span class="n">movie</span><span class="o">-</span><span class="n">dialogs</span>\ <span class="n">corpus</span><span class="o">/</span><span class="n">movie_conversations</span><span class="p">.</span><span class="n">txt</span> <span class="p">.</span><span class="o">/</span><span class="n">datasets</span>
<span class="err">!</span><span class="n">mv</span> <span class="n">cornell</span>\ <span class="n">movie</span><span class="o">-</span><span class="n">dialogs</span>\ <span class="n">corpus</span><span class="o">/</span><span class="n">movie_lines</span><span class="p">.</span><span class="n">txt</span> <span class="p">.</span><span class="o">/</span><span class="n">datasets</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Looking in indexes: http://mirrors.tencentyun.com/pypi/simple
Requirement already satisfied: transformers in /home/ubuntu/miniconda3/lib/python3.10/site-packages (4.29.1)
Collecting datasets
  Downloading http://mirrors.tencentyun.com/pypi/packages/fb/1c/85a22f3fa02dce5403094c5dbce494d62343b5a7e518bdf6e4200dda7337/datasets-2.12.0-py3-none-any.whl (474 kB)
[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m474.6/474.6 kB[0m [31m1.6 MB/s[0m eta [36m0:00:00[0m00:01[0m00:01[0m
[?25hRequirement already satisfied: tokenizers in /home/ubuntu/miniconda3/lib/python3.10/site-packages (0.13.3)
Requirement already satisfied: packaging&gt;=20.0 in /home/ubuntu/miniconda3/lib/python3.10/site-packages (from transformers) (23.0)
Requirement already satisfied: huggingface-hub&lt;1.0,&gt;=0.14.1 in /home/ubuntu/miniconda3/lib/python3.10/site-packages (from transformers) (0.14.1)
Requirement already satisfied: regex!=2019.12.17 in /home/ubuntu/miniconda3/lib/python3.10/site-packages (from transformers) (2023.5.5)
Requirement already satisfied: pyyaml&gt;=5.1 in /home/ubuntu/miniconda3/lib/python3.10/site-packages (from transformers) (6.0)
Requirement already satisfied: tqdm&gt;=4.27 in /home/ubuntu/miniconda3/lib/python3.10/site-packages (from transformers) (4.65.0)
Requirement already satisfied: filelock in /home/ubuntu/miniconda3/lib/python3.10/site-packages (from transformers) (3.12.0)
Requirement already satisfied: numpy&gt;=1.17 in /home/ubuntu/miniconda3/lib/python3.10/site-packages (from transformers) (1.24.3)
Requirement already satisfied: requests in /home/ubuntu/miniconda3/lib/python3.10/site-packages (from transformers) (2.28.1)
Collecting pyarrow&gt;=8.0.0
  Downloading http://mirrors.tencentyun.com/pypi/packages/21/68/c9ee59caec452530d32bb43104206ce1387d050adad05ee599616425ee7d/pyarrow-12.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.9 MB)
[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m38.9/38.9 MB[0m [31m9.5 MB/s[0m eta [36m0:00:00[0m:00:01[0m0:01[0mm
[?25hCollecting xxhash
  Downloading http://mirrors.tencentyun.com/pypi/packages/32/c3/4d24d4868fab9d9c8980ce00f01e3302565b06e712129d7dda779f9bb714/xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)
[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m212.5/212.5 kB[0m [31m2.8 MB/s[0m eta [36m0:00:00[0ma [36m0:00:01[0m
[?25hCollecting pandas
  Downloading http://mirrors.tencentyun.com/pypi/packages/a3/40/eca46f6af07a83ea3b8706586b2d8a28c01bdccee789d24f2ccc5e148b28/pandas-2.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)
[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m12.3/12.3 MB[0m [31m10.1 MB/s[0m eta [36m0:00:00[0m00:01[0m00:01[0m
[?25hCollecting dill&lt;0.3.7,&gt;=0.3.0
  Downloading http://mirrors.tencentyun.com/pypi/packages/be/e3/a84bf2e561beed15813080d693b4b27573262433fced9c1d1fea59e60553/dill-0.3.6-py3-none-any.whl (110 kB)
[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m110.5/110.5 kB[0m [31m435.8 kB/s[0m eta [36m0:00:00[0ma [36m0:00:01[0m
[?25hCollecting responses&lt;0.19
  Downloading http://mirrors.tencentyun.com/pypi/packages/79/f3/2b3a6dc5986303b3dd1bbbcf482022acb2583c428cd23f0b6d37b1a1a519/responses-0.18.0-py3-none-any.whl (38 kB)
Requirement already satisfied: fsspec[http]&gt;=2021.11.1 in /home/ubuntu/miniconda3/lib/python3.10/site-packages (from datasets) (2023.5.0)
Collecting aiohttp
  Downloading http://mirrors.tencentyun.com/pypi/packages/81/97/90debed02e5be15d4e63fb96ba930e35b66d4e518fa7065dd442345a448b/aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)
[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1.0/1.0 MB[0m [31m1.7 MB/s[0m eta [36m0:00:00[0m00:01[0m00:01[0m0m
[?25hCollecting multiprocess
  Downloading http://mirrors.tencentyun.com/pypi/packages/b8/0c/c26b346b41bb1f81ac921fa10074a9595c22e5f99cc89c0410fc4efd5df3/multiprocess-0.70.14-py310-none-any.whl (134 kB)
[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m134.3/134.3 kB[0m [31m417.7 kB/s[0m eta [36m0:00:00[0ma [36m0:00:01[0m
[?25hCollecting aiosignal&gt;=1.1.2
  Downloading http://mirrors.tencentyun.com/pypi/packages/76/ac/a7305707cb852b7e16ff80eaf5692309bde30e2b1100a1fcacdc8f731d97/aiosignal-1.3.1-py3-none-any.whl (7.6 kB)
Requirement already satisfied: charset-normalizer&lt;4.0,&gt;=2.0 in /home/ubuntu/miniconda3/lib/python3.10/site-packages (from aiohttp-&gt;datasets) (2.0.4)
Collecting multidict&lt;7.0,&gt;=4.5
  Downloading http://mirrors.tencentyun.com/pypi/packages/56/b5/ac112889bfc68e6cf4eda1e4325789b166c51c6cd29d5633e28fb2c2f966/multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)
[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m114.5/114.5 kB[0m [31m248.9 kB/s[0m eta [36m0:00:00[0m00:01[0m00:01[0m
[?25hRequirement already satisfied: attrs&gt;=17.3.0 in /home/ubuntu/miniconda3/lib/python3.10/site-packages (from aiohttp-&gt;datasets) (23.1.0)
Collecting async-timeout&lt;5.0,&gt;=4.0.0a3
  Downloading http://mirrors.tencentyun.com/pypi/packages/d6/c1/8991e7c5385b897b8c020cdaad718c5b087a6626d1d11a23e1ea87e325a7/async_timeout-4.0.2-py3-none-any.whl (5.8 kB)
Collecting yarl&lt;2.0,&gt;=1.0
  Downloading http://mirrors.tencentyun.com/pypi/packages/c9/d4/a5280faa1b8e9ad3a52ddc4c9aea94dd718f9c55f1e10cfb14580f5ebb45/yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)
[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m268.8/268.8 kB[0m [31m675.3 kB/s[0m eta [36m0:00:00[0m00:01[0m00:01[0m
[?25hCollecting frozenlist&gt;=1.1.1
  Downloading http://mirrors.tencentyun.com/pypi/packages/49/0e/c57ad9178618cf81be0fbb8430f17cf05423403143819d3631c7c09744c2/frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)
[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m149.6/149.6 kB[0m [31m412.1 kB/s[0m eta [36m0:00:00[0ma [36m0:00:01[0m
[?25hRequirement already satisfied: typing-extensions&gt;=3.7.4.3 in /home/ubuntu/miniconda3/lib/python3.10/site-packages (from huggingface-hub&lt;1.0,&gt;=0.14.1-&gt;transformers) (4.5.0)
Requirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /home/ubuntu/miniconda3/lib/python3.10/site-packages (from requests-&gt;transformers) (1.26.15)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /home/ubuntu/miniconda3/lib/python3.10/site-packages (from requests-&gt;transformers) (3.4)
Requirement already satisfied: certifi&gt;=2017.4.17 in /home/ubuntu/miniconda3/lib/python3.10/site-packages (from requests-&gt;transformers) (2022.12.7)
Collecting pytz&gt;=2020.1
  Downloading http://mirrors.tencentyun.com/pypi/packages/7f/99/ad6bd37e748257dd70d6f85d916cafe79c0b0f5e2e95b11f7fbc82bf3110/pytz-2023.3-py2.py3-none-any.whl (502 kB)
[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m502.3/502.3 kB[0m [31m846.1 kB/s[0m eta [36m0:00:00[0ma [36m0:00:01[0m
[?25hRequirement already satisfied: python-dateutil&gt;=2.8.2 in /home/ubuntu/miniconda3/lib/python3.10/site-packages (from pandas-&gt;datasets) (2.8.2)
Collecting tzdata&gt;=2022.1
  Downloading http://mirrors.tencentyun.com/pypi/packages/d5/fb/a79efcab32b8a1f1ddca7f35109a50e4a80d42ac1c9187ab46522b2407d7/tzdata-2023.3-py2.py3-none-any.whl (341 kB)
[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m341.8/341.8 kB[0m [31m814.0 kB/s[0m eta [36m0:00:00[0ma [36m0:00:01[0m
[?25hRequirement already satisfied: six&gt;=1.5 in /home/ubuntu/miniconda3/lib/python3.10/site-packages (from python-dateutil&gt;=2.8.2-&gt;pandas-&gt;datasets) (1.16.0)
Installing collected packages: pytz, xxhash, tzdata, pyarrow, multidict, frozenlist, dill, async-timeout, yarl, responses, pandas, multiprocess, aiosignal, aiohttp, datasets
Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.12.0 dill-0.3.6 frozenlist-1.3.3 multidict-6.0.4 multiprocess-0.70.14 pandas-2.0.1 pyarrow-12.0.0 pytz-2023.3 responses-0.18.0 tzdata-2023.3 xxhash-3.2.0 yarl-1.9.2
--2023-05-15 20:10:10--  http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip
Resolving www.cs.cornell.edu (www.cs.cornell.edu)... 132.236.207.36
Connecting to www.cs.cornell.edu (www.cs.cornell.edu)|132.236.207.36|:80... connected.
HTTP request sent, awaiting response... 200 OK
Length: 9916637 (9.5M) [application/zip]
Saving to: ‘cornell_movie_dialogs_corpus.zip’

cornell_movie_dialo  36%[======&gt;             ]   3.49M  37.2KB/s    in 70s     

2023-05-15 20:11:20 (51.4 KB/s) - Read error at byte 3659764/9916637 (Connection reset by peer). Retrying.

--2023-05-15 20:11:21--  (try: 2)  http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip
Connecting to www.cs.cornell.edu (www.cs.cornell.edu)|132.236.207.36|:80... connected.
HTTP request sent, awaiting response... 206 Partial Content
Length: 9916637 (9.5M), 6256873 (6.0M) remaining [application/zip]
Saving to: ‘cornell_movie_dialogs_corpus.zip’

cornell_movie_dialo 100%[+++++++============&gt;]   9.46M  3.06MB/s    in 1.9s    

2023-05-15 20:11:24 (3.06 MB/s) - ‘cornell_movie_dialogs_corpus.zip’ saved [9916637/9916637]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">transformers</span><span class="p">,</span> <span class="n">datasets</span>
<span class="kn">from</span> <span class="nn">tokenizers</span> <span class="kn">import</span> <span class="n">BertWordPieceTokenizer</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">BertTokenizer</span>
<span class="kn">import</span> <span class="nn">tqdm</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">DataLoader</span>
<span class="kn">import</span> <span class="nn">itertools</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="n">F</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>/home/ubuntu/miniconda3/envs/torch/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html
  from .autonotebook import tqdm as notebook_tqdm
</code></pre></div></div>

<h1 id="1--tokenization-word-piece-tokenizer">1 ) Tokenization (Word Piece Tokenizer)</h1>

<p>To begin our implementation of BERT, we first import the necessary libraries and preprocess the dataset by storing it into memory.</p>

<ul>
  <li>The data corpus is divided into two files, ‘movie_conversations.txt’ and ‘movie_lines.txt’.</li>
  <li>We then split the text in ‘movie_lines.txt’ using a special delimiter (‘+++ $ +++’) to separate the line’s ID, character ID, movie ID, and dialogue text, and store them in a dictionary called line_dic.</li>
  <li>Next, we generate question-answer pairs by iterating over each conversation in ‘movie_conversations.txt’ and pairing the current line’s text with the next line’s text for each conversation.</li>
  <li>Finally, we limit the maximum length of the input sequence to 64 tokens, which is a common length used in many NLP tasks, by splitting the text and taking only the first 64 tokens.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">### data processing
</span><span class="n">MAX_LEN</span> <span class="o">=</span> <span class="mi">64</span>

<span class="c1">### loading all data into memory
</span><span class="n">corpus_movie_conv</span> <span class="o">=</span> <span class="s">'./datasets/movie_conversations.txt'</span>
<span class="n">corpus_movie_lines</span> <span class="o">=</span> <span class="s">'./datasets/movie_lines.txt'</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">corpus_movie_conv</span><span class="p">,</span> <span class="s">'r'</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s">'iso-8859-1'</span><span class="p">)</span> <span class="k">as</span> <span class="n">c</span><span class="p">:</span>
    <span class="n">conv</span> <span class="o">=</span> <span class="n">c</span><span class="p">.</span><span class="n">readlines</span><span class="p">()</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">corpus_movie_lines</span><span class="p">,</span> <span class="s">'r'</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s">'iso-8859-1'</span><span class="p">)</span> <span class="k">as</span> <span class="n">l</span><span class="p">:</span>
    <span class="n">lines</span> <span class="o">=</span> <span class="n">l</span><span class="p">.</span><span class="n">readlines</span><span class="p">()</span>

<span class="c1">### splitting text using special lines
</span><span class="n">lines_dic</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">lines</span><span class="p">:</span>
    <span class="n">objects</span> <span class="o">=</span> <span class="n">line</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">" +++$+++ "</span><span class="p">)</span>
    <span class="n">lines_dic</span><span class="p">[</span><span class="n">objects</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">=</span> <span class="n">objects</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="c1">### generate question answer pairs
</span><span class="n">pairs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">con</span> <span class="ow">in</span> <span class="n">conv</span><span class="p">:</span>
    <span class="n">ids</span> <span class="o">=</span> <span class="nb">eval</span><span class="p">(</span><span class="n">con</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">" +++$+++ "</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ids</span><span class="p">)):</span>
        <span class="n">qa_pairs</span> <span class="o">=</span> <span class="p">[]</span>
        
        <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">ids</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">break</span>

        <span class="n">first</span> <span class="o">=</span> <span class="n">lines_dic</span><span class="p">[</span><span class="n">ids</span><span class="p">[</span><span class="n">i</span><span class="p">]].</span><span class="n">strip</span><span class="p">()</span>  
        <span class="n">second</span> <span class="o">=</span> <span class="n">lines_dic</span><span class="p">[</span><span class="n">ids</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]].</span><span class="n">strip</span><span class="p">()</span> 

        <span class="n">qa_pairs</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="s">' '</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">first</span><span class="p">.</span><span class="n">split</span><span class="p">()[:</span><span class="n">MAX_LEN</span><span class="p">]))</span>
        <span class="n">qa_pairs</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="s">' '</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">second</span><span class="p">.</span><span class="n">split</span><span class="p">()[:</span><span class="n">MAX_LEN</span><span class="p">]))</span>
        <span class="n">pairs</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">qa_pairs</span><span class="p">)</span>

<span class="c1"># sample
</span><span class="k">print</span><span class="p">(</span><span class="n">pairs</span><span class="p">[</span><span class="mi">20</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>["I really, really, really wanna go, but I can't. Not unless my sister goes.", "I'm workin' on it. But she doesn't seem to be goin' for him."]
</code></pre></div></div>

<p>WordPiece Tokenization
The initial stage of creating a fresh BERT model involves training a new tokenizer. Tokenization is the process of breaking down a text into smaller units called “tokens,” which are then converted into a numerical representation. An example of this would be splitting the sentence</p>

<p>“I like surfboarding!” → [‘[CLS]’, ‘i’, ‘like’, ‘surf’, ‘##board’, ‘##ing’, ‘!’, ‘[SEP]’] → [1, 48, 250, 4033, 3588, 154, 5, 2]
A tokenized BERT input always starts with a special [CLS] token and ends with a special [SEP] token, which are used for specific purposes that will be explained later. BERT employs a WordPiece tokenizer, which can split a single word into multiple tokens. For instance, in the example given earlier, the word “surfboarding” is broken down into [‘surf’, ‘##boarding’, ‘##ing’]. This technique helps the model to understand that words like surfboardand snowboardhave shared meaning through the common wordpiece ##board. By referring to the explanation from HuggingFace, WordPiece computes a score for each pair, using the following</p>

<p>score = (freq_of_pair) / (freq_of_first_element × freq_of_second_element)</p>

<p>By dividing the frequency of the pair by the product of the frequencies of each of its parts, the algorithm prioritizes the merging of pairs where the individual parts are less frequent in the vocabulary. For instance, it won’t necessarily merge (“un”, “##able”) even if that pair occurs very frequently in the vocabulary, because the two pairs “un” and “##able” will likely each appear in a lot of other words and have a high frequency. In contrast, a pair like (“hu”, “##gging”) will probably be merged faster (assuming the word “hugging” appears often in the vocabulary) since “hu” and “##gging” are likely to be less frequent individually.</p>

<p>To train the tokenizer, the BertWordPieceTokenizer from the transformer library was used with the steps below:</p>

<ul>
  <li>Saving the conversation text into multiple .txt files (with batch of N=10000)</li>
  <li>Define BertWordPieceTokenizer with some parameters likeclean_text to remove control characters, handle_chinese_chars to include spaces around Chinese characters, stripe_accents to remove accents and make é → e, ô → o, andlowercase to view capital and lowercase characters as equal.</li>
  <li>Train the tokenizer based on the file path to .txt files with parameters like vocab_size defines the total number of tokens, min_frequency for minimum frequency for a pair of tokens to be merged, special_tokens defines a list of the special tokens that BERT uses, limit_alphabet for a maximum number of different characters, workpieces_prefix the prefix added to pieces of words (like ##ing).</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># WordPiece tokenizer
</span>
<span class="c1">### save data as txt file
</span><span class="n">os</span><span class="p">.</span><span class="n">mkdir</span><span class="p">(</span><span class="s">'./data'</span><span class="p">)</span>
<span class="n">text_data</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">file_count</span> <span class="o">=</span> <span class="mi">0</span>

<span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">.</span><span class="n">tqdm</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">pairs</span><span class="p">]):</span>
    <span class="n">text_data</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>

    <span class="c1"># once we hit the 10K mark, save to file
</span>    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">text_data</span><span class="p">)</span> <span class="o">==</span> <span class="mi">10000</span><span class="p">:</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="sa">f</span><span class="s">'./data/text_</span><span class="si">{</span><span class="n">file_count</span><span class="si">}</span><span class="s">.txt'</span><span class="p">,</span> <span class="s">'w'</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s">'utf-8'</span><span class="p">)</span> <span class="k">as</span> <span class="n">fp</span><span class="p">:</span>
            <span class="n">fp</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="s">'</span><span class="se">\n</span><span class="s">'</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">text_data</span><span class="p">))</span>
        <span class="n">text_data</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">file_count</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="n">paths</span> <span class="o">=</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">Path</span><span class="p">(</span><span class="s">'./data'</span><span class="p">).</span><span class="n">glob</span><span class="p">(</span><span class="s">'**/*.txt'</span><span class="p">)]</span>
<span class="k">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">paths</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>100%|██████████| 221616/221616 [00:00&lt;00:00, 1797117.49it/s]

22
</code></pre></div></div>

<p>To specifically highlight these special tokens for BERT:</p>

<ul>
  <li>CLS stands for classification. It serves as the the Start of Sentence (SOS) and represent the meaning of the entire sentence.</li>
  <li>SEP serves as End of Sentence (EOS) and also the separation token between first and second sentences.</li>
  <li>PADto be added into sentences so that all of them would be in equal length. During the training process, please note that the [PAD] token with id of 0 will not contribute to the gradient .</li>
  <li>MASK for word replacement during masked language prediction</li>
  <li>UNK serves as a replacement for token if it’s not being found in the tokenizer’s vocab.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">### training own tokenizer
</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">BertWordPieceTokenizer</span><span class="p">(</span>
    <span class="n">clean_text</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">handle_chinese_chars</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
    <span class="n">strip_accents</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
    <span class="n">lowercase</span><span class="o">=</span><span class="bp">True</span>
<span class="p">)</span>

<span class="n">tokenizer</span><span class="p">.</span><span class="n">train</span><span class="p">(</span> 
    <span class="n">files</span><span class="o">=</span><span class="n">paths</span><span class="p">,</span>
    <span class="n">vocab_size</span><span class="o">=</span><span class="mi">30_000</span><span class="p">,</span> 
    <span class="n">min_frequency</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
    <span class="n">limit_alphabet</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> 
    <span class="n">wordpieces_prefix</span><span class="o">=</span><span class="s">'##'</span><span class="p">,</span>
    <span class="n">special_tokens</span><span class="o">=</span><span class="p">[</span><span class="s">'[PAD]'</span><span class="p">,</span> <span class="s">'[CLS]'</span><span class="p">,</span> <span class="s">'[SEP]'</span><span class="p">,</span> <span class="s">'[MASK]'</span><span class="p">,</span> <span class="s">'[UNK]'</span><span class="p">]</span>
    <span class="p">)</span>

<span class="n">os</span><span class="p">.</span><span class="n">mkdir</span><span class="p">(</span><span class="s">'./bert-it-1'</span><span class="p">)</span>
<span class="n">tokenizer</span><span class="p">.</span><span class="n">save_model</span><span class="p">(</span><span class="s">'./bert-it-1'</span><span class="p">,</span> <span class="s">'bert-it'</span><span class="p">)</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">BertTokenizer</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s">'./bert-it-1/bert-it-vocab.txt'</span><span class="p">,</span> <span class="n">local_files_only</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">token_ids</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="s">'I like surfboarding!'</span><span class="p">)[</span><span class="s">'input_ids'</span><span class="p">]</span>
<span class="k">print</span><span class="p">(</span><span class="n">token_ids</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">.</span><span class="n">convert_ids_to_tokens</span><span class="p">(</span><span class="n">token_ids</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[1, 48, 250, 4033, 3588, 154, 5, 2]
['[CLS]', 'i', 'like', 'surf', '##board', '##ing', '!', '[SEP]']


/home/ubuntu/miniconda3/envs/torch/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1714: FutureWarning: Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated and won't be possible anymore in v5. Use a model identifier or the path to a directory instead.
  warnings.warn(
</code></pre></div></div>

<h1 id="2-pre-processing">2) Pre-processing</h1>

<p>The code below defines a custom PyTorch Dataset class named BERTDataset, which is intended to be used for training a Bidirectional Encoder Representations from Transformers (BERT) model. The random_word method of the BERTDataset class performs the random replacement of tokens in each sentence using the given tokenizer object. The get_sent method returns a random sentence pair and corresponding is_next label. Finally, the get_corpus_line and get_random_line methods are used to retrieve individual sentences from the input pairs for negative sentence pairs.
It took multiple steps to prepare the data for the two training strategies</p>

<ul>
  <li>Step 1:
Select a random sentence pair, either positive or negative, and save the is_next indicating whether the two sentences are consecutive in the original text or not.</li>
  <li>Step 2:
Masking random words in first and second sentences based on predefined probabilities, at the same time recording the actual word as bert_label. After which, it converts the sequence string into integer (list of token ids).
<img src="2023-12-01-BERT-Pytorch-Scratch_files/0ae902d8-da32-4145-a744-989807b937d7.png" alt="image.png" /></li>
  <li>Step 3:
Add special [CLS] and [SEP] tokens to the start and end of each sentence.</li>
  <li>Step 4:
Combine first and second sentences as single output (but separated by SEPtoken) and then followed by padding with PAD token to the sentence pairs and labels to max length. At this step, a segment label is created by assigning 1 for first sentence and 2 for second, whereas 0 for padded tokens.</li>
</ul>

<p>By printing a sample output from the prepared dataset, we will see 4 keys output</p>

<ul>
  <li>bert_input for tokenized sentences</li>
  <li>bert_label stores original words of selected masking tokens</li>
  <li>segment_label as the identifier for sentence A or B, this allows the model to distinguish between sentences</li>
  <li>is_next as truth label for whether the two sentences are related</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">BERTDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_pair</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">seq_len</span><span class="o">=</span><span class="mi">64</span><span class="p">):</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">tokenizer</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">seq_len</span> <span class="o">=</span> <span class="n">seq_len</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">corpus_lines</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data_pair</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">lines</span> <span class="o">=</span> <span class="n">data_pair</span>

    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">corpus_lines</span>

    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">):</span>

        <span class="c1"># Step 1: get random sentence pair, either negative or positive (saved as is_next_label)
</span>        <span class="n">t1</span><span class="p">,</span> <span class="n">t2</span><span class="p">,</span> <span class="n">is_next_label</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">get_sent</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>

        <span class="c1"># Step 2: replace random words in sentence with mask / random words
</span>        <span class="n">t1_random</span><span class="p">,</span> <span class="n">t1_label</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">random_word</span><span class="p">(</span><span class="n">t1</span><span class="p">)</span>
        <span class="n">t2_random</span><span class="p">,</span> <span class="n">t2_label</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">random_word</span><span class="p">(</span><span class="n">t2</span><span class="p">)</span>

        <span class="c1"># Step 3: Adding CLS and SEP tokens to the start and end of sentences
</span>         <span class="c1"># Adding PAD token for labels
</span>        <span class="n">t1</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="p">.</span><span class="n">tokenizer</span><span class="p">.</span><span class="n">vocab</span><span class="p">[</span><span class="s">'[CLS]'</span><span class="p">]]</span> <span class="o">+</span> <span class="n">t1_random</span> <span class="o">+</span> <span class="p">[</span><span class="bp">self</span><span class="p">.</span><span class="n">tokenizer</span><span class="p">.</span><span class="n">vocab</span><span class="p">[</span><span class="s">'[SEP]'</span><span class="p">]]</span>
        <span class="n">t2</span> <span class="o">=</span> <span class="n">t2_random</span> <span class="o">+</span> <span class="p">[</span><span class="bp">self</span><span class="p">.</span><span class="n">tokenizer</span><span class="p">.</span><span class="n">vocab</span><span class="p">[</span><span class="s">'[SEP]'</span><span class="p">]]</span>
        <span class="n">t1_label</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="p">.</span><span class="n">tokenizer</span><span class="p">.</span><span class="n">vocab</span><span class="p">[</span><span class="s">'[PAD]'</span><span class="p">]]</span> <span class="o">+</span> <span class="n">t1_label</span> <span class="o">+</span> <span class="p">[</span><span class="bp">self</span><span class="p">.</span><span class="n">tokenizer</span><span class="p">.</span><span class="n">vocab</span><span class="p">[</span><span class="s">'[PAD]'</span><span class="p">]]</span>
        <span class="n">t2_label</span> <span class="o">=</span> <span class="n">t2_label</span> <span class="o">+</span> <span class="p">[</span><span class="bp">self</span><span class="p">.</span><span class="n">tokenizer</span><span class="p">.</span><span class="n">vocab</span><span class="p">[</span><span class="s">'[PAD]'</span><span class="p">]]</span>

        <span class="c1"># Step 4: combine sentence 1 and 2 as one input
</span>        <span class="c1"># adding PAD tokens to make the sentence same length as seq_len
</span>        <span class="n">segment_label</span> <span class="o">=</span> <span class="p">([</span><span class="mi">1</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">t1</span><span class="p">))]</span> <span class="o">+</span> <span class="p">[</span><span class="mi">2</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">t2</span><span class="p">))])[:</span><span class="bp">self</span><span class="p">.</span><span class="n">seq_len</span><span class="p">]</span>
        <span class="n">bert_input</span> <span class="o">=</span> <span class="p">(</span><span class="n">t1</span> <span class="o">+</span> <span class="n">t2</span><span class="p">)[:</span><span class="bp">self</span><span class="p">.</span><span class="n">seq_len</span><span class="p">]</span>
        <span class="n">bert_label</span> <span class="o">=</span> <span class="p">(</span><span class="n">t1_label</span> <span class="o">+</span> <span class="n">t2_label</span><span class="p">)[:</span><span class="bp">self</span><span class="p">.</span><span class="n">seq_len</span><span class="p">]</span>
        <span class="n">padding</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="p">.</span><span class="n">tokenizer</span><span class="p">.</span><span class="n">vocab</span><span class="p">[</span><span class="s">'[PAD]'</span><span class="p">]</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">seq_len</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">bert_input</span><span class="p">))]</span>
        <span class="n">bert_input</span><span class="p">.</span><span class="n">extend</span><span class="p">(</span><span class="n">padding</span><span class="p">),</span> <span class="n">bert_label</span><span class="p">.</span><span class="n">extend</span><span class="p">(</span><span class="n">padding</span><span class="p">),</span> <span class="n">segment_label</span><span class="p">.</span><span class="n">extend</span><span class="p">(</span><span class="n">padding</span><span class="p">)</span>

        <span class="n">output</span> <span class="o">=</span> <span class="p">{</span><span class="s">"bert_input"</span><span class="p">:</span> <span class="n">bert_input</span><span class="p">,</span>
                  <span class="s">"bert_label"</span><span class="p">:</span> <span class="n">bert_label</span><span class="p">,</span>
                  <span class="s">"segment_label"</span><span class="p">:</span> <span class="n">segment_label</span><span class="p">,</span>
                  <span class="s">"is_next"</span><span class="p">:</span> <span class="n">is_next_label</span><span class="p">}</span>

        <span class="k">return</span> <span class="p">{</span><span class="n">key</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">output</span><span class="p">.</span><span class="n">items</span><span class="p">()}</span>

    <span class="k">def</span> <span class="nf">random_word</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sentence</span><span class="p">):</span>
        <span class="n">tokens</span> <span class="o">=</span> <span class="n">sentence</span><span class="p">.</span><span class="n">split</span><span class="p">()</span>
        <span class="n">output_label</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">output</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># 15% of the tokens would be replaced
</span>        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">token</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">tokens</span><span class="p">):</span>
            <span class="n">prob</span> <span class="o">=</span> <span class="n">random</span><span class="p">.</span><span class="n">random</span><span class="p">()</span>

            <span class="c1"># remove cls and sep token
</span>            <span class="n">token_id</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">tokenizer</span><span class="p">(</span><span class="n">token</span><span class="p">)[</span><span class="s">'input_ids'</span><span class="p">][</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

            <span class="k">if</span> <span class="n">prob</span> <span class="o">&lt;</span> <span class="mf">0.15</span><span class="p">:</span>
                <span class="n">prob</span> <span class="o">/=</span> <span class="mf">0.15</span>

                <span class="c1"># 80% chance change token to mask token
</span>                <span class="k">if</span> <span class="n">prob</span> <span class="o">&lt;</span> <span class="mf">0.8</span><span class="p">:</span>
                    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">token_id</span><span class="p">)):</span>
                        <span class="n">output</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">tokenizer</span><span class="p">.</span><span class="n">vocab</span><span class="p">[</span><span class="s">'[MASK]'</span><span class="p">])</span>

                <span class="c1"># 10% chance change token to random token
</span>                <span class="k">elif</span> <span class="n">prob</span> <span class="o">&lt;</span> <span class="mf">0.9</span><span class="p">:</span>
                    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">token_id</span><span class="p">)):</span>
                        <span class="n">output</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">random</span><span class="p">.</span><span class="n">randrange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">tokenizer</span><span class="p">.</span><span class="n">vocab</span><span class="p">)))</span>

                <span class="c1"># 10% chance change token to current token
</span>                <span class="k">else</span><span class="p">:</span>
                    <span class="n">output</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">token_id</span><span class="p">)</span>

                <span class="n">output_label</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">token_id</span><span class="p">)</span>

            <span class="k">else</span><span class="p">:</span>
                <span class="n">output</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">token_id</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">token_id</span><span class="p">)):</span>
                    <span class="n">output_label</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="c1"># flattening
</span>        <span class="n">output</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">itertools</span><span class="p">.</span><span class="n">chain</span><span class="p">(</span><span class="o">*</span><span class="p">[[</span><span class="n">x</span><span class="p">]</span> <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="k">else</span> <span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">output</span><span class="p">]))</span>
        <span class="n">output_label</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">itertools</span><span class="p">.</span><span class="n">chain</span><span class="p">(</span><span class="o">*</span><span class="p">[[</span><span class="n">x</span><span class="p">]</span> <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="k">else</span> <span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">output_label</span><span class="p">]))</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">output</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">output_label</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">output_label</span>

    <span class="k">def</span> <span class="nf">get_sent</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="s">'''return random sentence pair'''</span>
        <span class="n">t1</span><span class="p">,</span> <span class="n">t2</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">get_corpus_line</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>

        <span class="c1"># negative or positive pair, for next sentence prediction
</span>        <span class="k">if</span> <span class="n">random</span><span class="p">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">t1</span><span class="p">,</span> <span class="n">t2</span><span class="p">,</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">t1</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">get_random_line</span><span class="p">(),</span> <span class="mi">0</span>

    <span class="k">def</span> <span class="nf">get_corpus_line</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">):</span>
        <span class="s">'''return sentence pair'''</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">lines</span><span class="p">[</span><span class="n">item</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="p">.</span><span class="n">lines</span><span class="p">[</span><span class="n">item</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">get_random_line</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="s">'''return random single sentence'''</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">lines</span><span class="p">[</span><span class="n">random</span><span class="p">.</span><span class="n">randrange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">lines</span><span class="p">))][</span><span class="mi">1</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># test
</span><span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">BERTDataset</span><span class="p">(</span><span class="n">pairs</span><span class="p">,</span> <span class="n">seq_len</span><span class="o">=</span><span class="n">MAX_LEN</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">)</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">pin_memory</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">sample_data</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">train_loader</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Batch Size'</span><span class="p">,</span> <span class="n">sample_data</span><span class="p">[</span><span class="s">'bert_input'</span><span class="p">].</span><span class="n">size</span><span class="p">())</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">train_data</span><span class="p">[</span><span class="n">random</span><span class="p">.</span><span class="n">randrange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_data</span><span class="p">))]</span>
<span class="n">result</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Batch Size torch.Size([32, 64])





{'bert_input': tensor([   1,  558,    3,    3,    2, 4039,   17, 6013,  162,   17,    2,    0,
            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
            0,    0,    0,    0]),
 'bert_label': tensor([  0,   0, 839,  17,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0,   0,   0,   0,   0]),
 'segment_label': tensor([1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),
 'is_next': tensor(1)}
</code></pre></div></div>

<h1 id="3-modeling">3) Modeling</h1>

<p>In NLP model, the order of the words and their position in a sentence matters and the meaning of the entire sentence can change if the words are re-ordered. As such, transformer model did a position embedding for each token in the input using the formula</p>

<p><img src="2023-12-01-BERT-Pytorch-Scratch_files/a8fb37fd-92a9-432b-8563-7dcd5ce74bfe.png" alt="image.png" />!</p>

<p>where</p>

<ul>
  <li>k: Position of an object in input sequence, 0 &lt; k &lt; L/2</li>
  <li>d: Dimension of the output embedding space</li>
  <li>n: User defined scalar. Default by 10,000</li>
  <li>i: Used for mapping to column indices 0 &lt; i &lt; d/2. A single value of i maps to both sine and cosine functions
For all three different type of embeddings, they must be in the similar output size (768 in this case), so that all three of them can be summed together to be a single embedded output. You may notice thepadding_idx is specified as 0, this is to make pad token remains as 0 and not being updated during training.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">### embedding
</span><span class="k">class</span> <span class="nc">PositionalEmbedding</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">max_len</span><span class="o">=</span><span class="mi">128</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>

        <span class="c1"># Compute the positional encodings once in log space.
</span>        <span class="n">pe</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">max_len</span><span class="p">,</span> <span class="n">d_model</span><span class="p">).</span><span class="nb">float</span><span class="p">()</span>
        <span class="n">pe</span><span class="p">.</span><span class="n">require_grad</span> <span class="o">=</span> <span class="bp">False</span>

        <span class="k">for</span> <span class="n">pos</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_len</span><span class="p">):</span>   
            <span class="c1"># for each dimension of the each position
</span>            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="mi">2</span><span class="p">):</span>   
                <span class="n">pe</span><span class="p">[</span><span class="n">pos</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">math</span><span class="p">.</span><span class="n">sin</span><span class="p">(</span><span class="n">pos</span> <span class="o">/</span> <span class="p">(</span><span class="mi">10000</span> <span class="o">**</span> <span class="p">((</span><span class="mi">2</span> <span class="o">*</span> <span class="n">i</span><span class="p">)</span><span class="o">/</span><span class="n">d_model</span><span class="p">)))</span>
                <span class="n">pe</span><span class="p">[</span><span class="n">pos</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">math</span><span class="p">.</span><span class="n">cos</span><span class="p">(</span><span class="n">pos</span> <span class="o">/</span> <span class="p">(</span><span class="mi">10000</span> <span class="o">**</span> <span class="p">((</span><span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span><span class="o">/</span><span class="n">d_model</span><span class="p">)))</span>

        <span class="c1"># include the batch size
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">pe</span> <span class="o">=</span> <span class="n">pe</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>   
        <span class="c1"># self.register_buffer('pe', pe)
</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">pe</span>

<span class="k">class</span> <span class="nc">BERTEmbedding</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="s">"""
    BERT Embedding which is consisted with under features
        1. TokenEmbedding : normal embedding matrix
        2. PositionalEmbedding : adding positional information using sin, cos
        2. SegmentEmbedding : adding sentence segment info, (sent_A:1, sent_B:2)
        sum of all these features are output of BERTEmbedding
    """</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">,</span> <span class="n">seq_len</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
        <span class="s">"""
        :param vocab_size: total vocab size
        :param embed_size: embedding size of token embedding
        :param dropout: dropout rate
        """</span>

        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">embed_size</span> <span class="o">=</span> <span class="n">embed_size</span>
        <span class="c1"># (m, seq_len) --&gt; (m, seq_len, embed_size)
</span>        <span class="c1"># padding_idx is not updated during training, remains as fixed pad (0)
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">token</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">,</span> <span class="n">padding_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">segment</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Embedding</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">,</span> <span class="n">padding_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">position</span> <span class="o">=</span> <span class="n">PositionalEmbedding</span><span class="p">(</span><span class="n">d_model</span><span class="o">=</span><span class="n">embed_size</span><span class="p">,</span> <span class="n">max_len</span><span class="o">=</span><span class="n">seq_len</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="n">dropout</span><span class="p">)</span>
       
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sequence</span><span class="p">,</span> <span class="n">segment_label</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">token</span><span class="p">(</span><span class="n">sequence</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="p">.</span><span class="n">position</span><span class="p">(</span><span class="n">sequence</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="p">.</span><span class="n">segment</span><span class="p">(</span><span class="n">segment_label</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="c1">### testing
</span><span class="n">embed_layer</span> <span class="o">=</span> <span class="n">BERTEmbedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">.</span><span class="n">vocab</span><span class="p">),</span> <span class="n">embed_size</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">seq_len</span><span class="o">=</span><span class="n">MAX_LEN</span><span class="p">)</span>
<span class="n">embed_result</span> <span class="o">=</span> <span class="n">embed_layer</span><span class="p">(</span><span class="n">sample_data</span><span class="p">[</span><span class="s">'bert_input'</span><span class="p">],</span> <span class="n">sample_data</span><span class="p">[</span><span class="s">'segment_label'</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="n">embed_result</span><span class="p">.</span><span class="n">size</span><span class="p">())</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>torch.Size([32, 64, 768])
</code></pre></div></div>

<h3 id="the-details-of-the-class-multiheadedattention">The details of the class MultiHeadedAttention</h3>

<ul>
  <li>It’s called multi-head attention because the hidden size: d_model(768) is split by heads(12), this allows the model to jointly attend to information at different positions from different representational spaces.</li>
  <li>It takes the query, key, and value as inputs, and the size is permuted from (batch_size, max_len, hidden_size) → (batch_size, num_heads, max_len, hidden_size / num_heads ). This indicates that all the 3 inpurs are linearly projected from the d_model dimensional space to heads sets of d_k dimensional vectors.</li>
  <li>Attention score matrix is computed using matrix multiplication between the query(Q) and key(K) tensors, followed by scaling by the square root of the key tensor’s dimension</li>
  <li>The mask is applied to the attention matrix and filled with -1e9 (close to negative infinity). This is done because the large negative inputs to softmax are near zero in the output.</li>
  <li>
    <p>The final output is a weighted sum of the value(V) tensors, where the weights are determined by the softmax of the scaled dot-product between the query and key vectors.
The EncoderLayer class contains 2 sublayers:.</p>
  </li>
  <li>MultiHeadedAttention: A multi-headed self-attention module that computes the attention weights between each element in the input sequence</li>
  <li>FeedForward: A feedforward network with one hidden layer that applies a non-linear activation function (GELU) to the output of the first linear layer and produces a d_model dimensional output.</li>
  <li>Each of these sublayers has a residual connection around it followed by a layer normalization LayerNorm(x + Sublayer(x)). Residual connections help in avoiding the vanishing gradient problem in deep networks.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">### attention layers
</span><span class="k">class</span> <span class="nc">MultiHeadedAttention</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">heads</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MultiHeadedAttention</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
        
        <span class="k">assert</span> <span class="n">d_model</span> <span class="o">%</span> <span class="n">heads</span> <span class="o">==</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">d_k</span> <span class="o">=</span> <span class="n">d_model</span> <span class="o">//</span> <span class="n">heads</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">heads</span> <span class="o">=</span> <span class="n">heads</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">query</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">key</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">value</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">output_linear</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">query</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">mask</span><span class="p">):</span>
        <span class="s">"""
        query, key, value of shape: (batch_size, max_len, d_model)
        mask of shape: (batch_size, 1, 1, max_words)
        """</span>
        <span class="c1"># (batch_size, max_len, d_model)
</span>        <span class="n">query</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">query</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
        <span class="n">key</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">key</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>        
        <span class="n">value</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">value</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>   
        
        <span class="c1"># (batch_size, max_len, d_model) --&gt; (batch_size, max_len, h, d_k) --&gt; (batch_size, h, max_len, d_k)
</span>        <span class="n">query</span> <span class="o">=</span> <span class="n">query</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="n">query</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">heads</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">d_k</span><span class="p">).</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>   
        <span class="n">key</span> <span class="o">=</span> <span class="n">key</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="n">key</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">heads</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">d_k</span><span class="p">).</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>  
        <span class="n">value</span> <span class="o">=</span> <span class="n">value</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="n">value</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">heads</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">d_k</span><span class="p">).</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>  
        
        <span class="c1"># (batch_size, h, max_len, d_k) matmul (batch_size, h, d_k, max_len) --&gt; (batch_size, h, max_len, max_len)
</span>        <span class="n">scores</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">key</span><span class="p">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span> <span class="o">/</span> <span class="n">math</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">query</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>

        <span class="c1"># fill 0 mask with super small number so it wont affect the softmax weight
</span>        <span class="c1"># (batch_size, h, max_len, max_len)
</span>        <span class="n">scores</span> <span class="o">=</span> <span class="n">scores</span><span class="p">.</span><span class="n">masked_fill</span><span class="p">(</span><span class="n">mask</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mf">1e9</span><span class="p">)</span>    

        <span class="c1"># (batch_size, h, max_len, max_len)
</span>        <span class="c1"># softmax to put attention weight for all non-pad tokens
</span>        <span class="c1"># max_len X max_len matrix of attention
</span>        <span class="n">weights</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>           
        <span class="n">weights</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>

        <span class="c1"># (batch_size, h, max_len, max_len) matmul (batch_size, h, max_len, d_k) --&gt; (batch_size, h, max_len, d_k)
</span>        <span class="n">context</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>

        <span class="c1"># (batch_size, h, max_len, d_k) --&gt; (batch_size, max_len, h, d_k) --&gt; (batch_size, max_len, d_model)
</span>        <span class="n">context</span> <span class="o">=</span> <span class="n">context</span><span class="p">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">).</span><span class="n">contiguous</span><span class="p">().</span><span class="n">view</span><span class="p">(</span><span class="n">context</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">heads</span> <span class="o">*</span> <span class="bp">self</span><span class="p">.</span><span class="n">d_k</span><span class="p">)</span>

        <span class="c1"># (batch_size, max_len, d_model)
</span>        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">output_linear</span><span class="p">(</span><span class="n">context</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">FeedForward</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="s">"Implements FFN equation."</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">middle_dim</span><span class="o">=</span><span class="mi">2048</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">FeedForward</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
        
        <span class="bp">self</span><span class="p">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">middle_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">middle_dim</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">GELU</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">activation</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">fc2</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">out</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">out</span>

<span class="k">class</span> <span class="nc">EncoderLayer</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> 
        <span class="n">d_model</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span>
        <span class="n">heads</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> 
        <span class="n">feed_forward_hidden</span><span class="o">=</span><span class="mi">768</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span> 
        <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span>
        <span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">EncoderLayer</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">layernorm</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">self_multihead</span> <span class="o">=</span> <span class="n">MultiHeadedAttention</span><span class="p">(</span><span class="n">heads</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">feed_forward</span> <span class="o">=</span> <span class="n">FeedForward</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">middle_dim</span><span class="o">=</span><span class="n">feed_forward_hidden</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">,</span> <span class="n">mask</span><span class="p">):</span>
        <span class="c1"># embeddings: (batch_size, max_len, d_model)
</span>        <span class="c1"># encoder mask: (batch_size, 1, 1, max_len)
</span>        <span class="c1"># result: (batch_size, max_len, d_model)
</span>        <span class="n">interacted</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">dropout</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">self_multihead</span><span class="p">(</span><span class="n">embeddings</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">,</span> <span class="n">mask</span><span class="p">))</span>
        <span class="c1"># residual layer
</span>        <span class="n">interacted</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">layernorm</span><span class="p">(</span><span class="n">interacted</span> <span class="o">+</span> <span class="n">embeddings</span><span class="p">)</span>
        <span class="c1"># bottleneck
</span>        <span class="n">feed_forward_out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">dropout</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">feed_forward</span><span class="p">(</span><span class="n">interacted</span><span class="p">))</span>
        <span class="n">encoded</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">layernorm</span><span class="p">(</span><span class="n">feed_forward_out</span> <span class="o">+</span> <span class="n">interacted</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">encoded</span>

<span class="c1">### testing
</span><span class="n">mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">sample_data</span><span class="p">[</span><span class="s">'bert_input'</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">).</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">).</span><span class="n">repeat</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">sample_data</span><span class="p">[</span><span class="s">'bert_input'</span><span class="p">].</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="mi">1</span><span class="p">).</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">transformer_block</span> <span class="o">=</span> <span class="n">EncoderLayer</span><span class="p">()</span>
<span class="n">transformer_result</span> <span class="o">=</span> <span class="n">transformer_block</span><span class="p">(</span><span class="n">embed_result</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>
<span class="n">transformer_result</span><span class="p">.</span><span class="n">size</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>torch.Size([32, 64, 768])
</code></pre></div></div>

<h3 id="the-details-of-the-class-multiheadedattention-1">The details of the class MultiHeadedAttention</h3>

<ul>
  <li>It’s called multi-head attention because the hidden size: <strong>d_model(768) is split by heads(12)</strong>, this allows the model to jointly attend to information at different positions from different representational spaces.</li>
  <li>It takes the query, key, and value as inputs, and the size is permuted from <strong>(batch_size, max_len, hidden_size) → (batch_size, num_heads, max_len, hidden_size / num_heads )</strong>. This indicates that all the 3 inpurs are linearly projected from the d_model dimensional space to heads sets of d_k dimensional vectors.</li>
  <li>Attention score matrix is computed using matrix multiplication between the query(Q) and key(K) tensors, followed by scaling by the square root of the key tensor’s dimension</li>
  <li><strong>The mask is applied to the attention matrix and filled with -1e9 (close to negative infinity)</strong>. This is done because the large negative inputs to softmax are near zero in the output. <br />
      ** per my understanding this means the mask for padding?? correct? not [mask] token… ..  “” def forward(self, query, key, value, mask): ““**</li>
  <li>The final output is a weighted sum of the value(V) tensors, where the weights are determined by the softmax of the scaled dot-product between the query and key vectors.</li>
</ul>

<p>The EncoderLayer class contains 2 sublayers:.</p>

<ul>
  <li>MultiHeadedAttention: A multi-headed self-attention module that computes the attention weights between each element in the input sequence</li>
  <li>FeedForward: A feedforward network with one hidden layer that applies a non-linear activation function (GELU) to the output of the first linear layer and produces a d_model dimensional output.
Each of these sublayers has a residual connection around it followed by a layer normalization LayerNorm(x + Sublayer(x)). Residual connections help in avoiding the vanishing gradient problem in deep networks.</li>
</ul>

<h3 id="final-bert-model">Final BERT Model</h3>
<p>Coming next, we are going to incorporate the encoder layer with attention mechanism into the final BERT’s construction.</p>
<ul>
  <li>The BERT class initializes the embedding layer for the input sequence, as well as multi layers of EncoderLayer blocks. The forward method of this class takes in the input sequence and a segment info tensor, applies attention masking to the input(for padded token), embeds the input sequence, and then passes it through the encoder blocks to obtain the output.</li>
  <li>The NextSentencePrediction class is a 2-class classification model that takes in the output of the BERT class and predicts whether the input sequence contains two consecutive sentences or not. The forward method applies applies linear transformation and log softmax function to obtain the predicted probabilities of the two classes.</li>
  <li>The MaskedLanguageModel class is a multi-class classification model that takes in the output of the BERT class and predicts the original tokens for the masked input sequence. The forward method applies a linear transformation and log softmax function to obtain the predicted probabilities of each token in the vocabulary.</li>
  <li>The BERTLM class combines the BERT, NextSentencePrediction, and MaskedLanguageModel classes to create a complete BERT language model.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">BERT</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="s">"""
    BERT model : Bidirectional Encoder Representations from Transformers.
    """</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">d_model</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">n_layers</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">heads</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
        <span class="s">"""
        :param vocab_size: vocab_size of total words
        :param hidden: BERT model hidden size
        :param n_layers: numbers of Transformer blocks(layers)
        :param attn_heads: number of attention heads
        :param dropout: dropout rate
        """</span>

        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">d_model</span> <span class="o">=</span> <span class="n">d_model</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">n_layers</span> <span class="o">=</span> <span class="n">n_layers</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">heads</span> <span class="o">=</span> <span class="n">heads</span>

        <span class="c1"># paper noted they used 4*hidden_size for ff_network_hidden_size
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">feed_forward_hidden</span> <span class="o">=</span> <span class="n">d_model</span> <span class="o">*</span> <span class="mi">4</span>

        <span class="c1"># embedding for BERT, sum of positional, segment, token embeddings
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">BERTEmbedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="o">=</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="o">=</span><span class="n">d_model</span><span class="p">)</span>

        <span class="c1"># multi-layers transformer blocks, deep network
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">encoder_blocks</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">ModuleList</span><span class="p">(</span>
            <span class="p">[</span><span class="n">EncoderLayer</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">heads</span><span class="p">,</span> <span class="n">d_model</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_layers</span><span class="p">)])</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">segment_info</span><span class="p">):</span>
        <span class="c1"># attention masking for padded token
</span>        <span class="c1"># (batch_size, 1, seq_len, seq_len)
</span>        <span class="n">mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">).</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">).</span><span class="n">repeat</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">x</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="mi">1</span><span class="p">).</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># embedding the indexed sequence to sequence of vectors
</span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">segment_info</span><span class="p">)</span>

        <span class="c1"># running over multiple transformer blocks
</span>        <span class="k">for</span> <span class="n">encoder</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">encoder_blocks</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="k">class</span> <span class="nc">NextSentencePrediction</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="s">"""
    2-class classification model : is_next, is_not_next
    """</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden</span><span class="p">):</span>
        <span class="s">"""
        :param hidden: BERT model output size
        """</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">softmax</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">LogSoftmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># use only the first token which is the [CLS]
</span>        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">softmax</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">linear</span><span class="p">(</span><span class="n">x</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]))</span>

<span class="k">class</span> <span class="nc">MaskedLanguageModel</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="s">"""
    predicting origin token from masked input sequence
    n-class classification problem, n-class = vocab_size
    """</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">):</span>
        <span class="s">"""
        :param hidden: output size of BERT model
        :param vocab_size: total vocab size
        """</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">softmax</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">LogSoftmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">softmax</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">linear</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>

<span class="k">class</span> <span class="nc">BERTLM</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="s">"""
    BERT Language Model
    Next Sentence Prediction Model + Masked Language Model
    """</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">bert</span><span class="p">:</span> <span class="n">BERT</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">):</span>
        <span class="s">"""
        :param bert: BERT model which should be trained
        :param vocab_size: total vocab size for masked_lm
        """</span>

        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">bert</span> <span class="o">=</span> <span class="n">bert</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">next_sentence</span> <span class="o">=</span> <span class="n">NextSentencePrediction</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">bert</span><span class="p">.</span><span class="n">d_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">mask_lm</span> <span class="o">=</span> <span class="n">MaskedLanguageModel</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">bert</span><span class="p">.</span><span class="n">d_model</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">segment_label</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">bert</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">segment_label</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">next_sentence</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="bp">self</span><span class="p">.</span><span class="n">mask_lm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="c1">### test
</span><span class="n">bert_model</span> <span class="o">=</span> <span class="n">BERT</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">.</span><span class="n">vocab</span><span class="p">))</span>
<span class="n">bert_result</span> <span class="o">=</span> <span class="n">bert_model</span><span class="p">(</span><span class="n">sample_data</span><span class="p">[</span><span class="s">'bert_input'</span><span class="p">],</span> <span class="n">sample_data</span><span class="p">[</span><span class="s">'segment_label'</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="n">bert_result</span><span class="p">.</span><span class="n">size</span><span class="p">())</span>

<span class="n">bert_lm</span> <span class="o">=</span> <span class="n">BERTLM</span><span class="p">(</span><span class="n">bert_model</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">.</span><span class="n">vocab</span><span class="p">))</span>
<span class="n">final_result</span> <span class="o">=</span> <span class="n">bert_lm</span><span class="p">(</span><span class="n">sample_data</span><span class="p">[</span><span class="s">'bert_input'</span><span class="p">],</span> <span class="n">sample_data</span><span class="p">[</span><span class="s">'segment_label'</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="n">final_result</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">size</span><span class="p">(),</span> <span class="n">final_result</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">size</span><span class="p">())</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>torch.Size([32, 64, 768])
torch.Size([32, 2]) torch.Size([32, 64, 21159])
</code></pre></div></div>

<h1 id="4-training">4) Training</h1>

<h3 id="optimizer">Optimizer</h3>
<p>The original BERT model was trained using Adam optimizer with a custom learning rate scheduler according to the formula in the <a href="https://arxiv.org/abs/1706.03762">paper</a>.
\(l r a t e=d_{\text {model }}^{-0.5} * \min \left(step\_num^{-0.5}, step\_num * warmup_steps^{-1.5}\right)\)</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">### optimizer
</span><span class="k">class</span> <span class="nc">ScheduledOptim</span><span class="p">():</span>
    <span class="s">'''A simple wrapper class for learning rate scheduling'''</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">n_warmup_steps</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">_optimizer</span> <span class="o">=</span> <span class="n">optimizer</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">n_warmup_steps</span> <span class="o">=</span> <span class="n">n_warmup_steps</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">n_current_steps</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">init_lr</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">power</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">step_and_update_lr</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="s">"Step with the inner optimizer"</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">_update_learning_rate</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">_optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">zero_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="s">"Zero out the gradients by the inner optimizer"</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">_optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_get_lr_scale</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nb">min</span><span class="p">([</span>
            <span class="n">np</span><span class="p">.</span><span class="n">power</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">n_current_steps</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">),</span>
            <span class="n">np</span><span class="p">.</span><span class="n">power</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">n_warmup_steps</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.5</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="p">.</span><span class="n">n_current_steps</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">_update_learning_rate</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="s">''' Learning rate scheduling per step '''</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">n_current_steps</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">lr</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">init_lr</span> <span class="o">*</span> <span class="bp">self</span><span class="p">.</span><span class="n">_get_lr_scale</span><span class="p">()</span>

        <span class="k">for</span> <span class="n">param_group</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">_optimizer</span><span class="p">.</span><span class="n">param_groups</span><span class="p">:</span>
            <span class="n">param_group</span><span class="p">[</span><span class="s">'lr'</span><span class="p">]</span> <span class="o">=</span> <span class="n">lr</span>
</code></pre></div></div>

<p>Trainer
We came a long way to finally combine what we have discussed above and start training a new BERT model</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">### trainer
</span><span class="k">class</span> <span class="nc">BERTTrainer</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> 
        <span class="n">model</span><span class="p">,</span> 
        <span class="n">train_dataloader</span><span class="p">,</span> 
        <span class="n">test_dataloader</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> 
        <span class="n">lr</span><span class="o">=</span> <span class="mf">1e-4</span><span class="p">,</span>
        <span class="n">weight_decay</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
        <span class="n">betas</span><span class="o">=</span><span class="p">(</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.999</span><span class="p">),</span>
        <span class="n">warmup_steps</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span>
        <span class="n">log_freq</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
        <span class="n">device</span><span class="o">=</span><span class="s">'cuda'</span>
        <span class="p">):</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">device</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">train_data</span> <span class="o">=</span> <span class="n">train_dataloader</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">test_data</span> <span class="o">=</span> <span class="n">test_dataloader</span>

        <span class="c1"># Setting the Adam optimizer with hyper-param
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">optim</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span> <span class="n">betas</span><span class="o">=</span><span class="n">betas</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="n">weight_decay</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">optim_schedule</span> <span class="o">=</span> <span class="n">ScheduledOptim</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">optim</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="n">bert</span><span class="p">.</span><span class="n">d_model</span><span class="p">,</span> <span class="n">n_warmup_steps</span><span class="o">=</span><span class="n">warmup_steps</span>
            <span class="p">)</span>

        <span class="c1"># Using Negative Log Likelihood Loss function for predicting the masked_token
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">criterion</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">NLLLoss</span><span class="p">(</span><span class="n">ignore_index</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">log_freq</span> <span class="o">=</span> <span class="n">log_freq</span>
        <span class="k">print</span><span class="p">(</span><span class="s">"Total Parameters:"</span><span class="p">,</span> <span class="nb">sum</span><span class="p">([</span><span class="n">p</span><span class="p">.</span><span class="n">nelement</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">()]))</span>
    
    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">iteration</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">train_data</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">test</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">iteration</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">test_data</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">iteration</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">data_loader</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
        
        <span class="n">avg_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="n">total_correct</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">total_element</span> <span class="o">=</span> <span class="mi">0</span>
        
        <span class="n">mode</span> <span class="o">=</span> <span class="s">"train"</span> <span class="k">if</span> <span class="n">train</span> <span class="k">else</span> <span class="s">"test"</span>

        <span class="c1"># progress bar
</span>        <span class="n">data_iter</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">.</span><span class="n">tqdm</span><span class="p">(</span>
            <span class="nb">enumerate</span><span class="p">(</span><span class="n">data_loader</span><span class="p">),</span>
            <span class="n">desc</span><span class="o">=</span><span class="s">"EP_%s:%d"</span> <span class="o">%</span> <span class="p">(</span><span class="n">mode</span><span class="p">,</span> <span class="n">epoch</span><span class="p">),</span>
            <span class="n">total</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">data_loader</span><span class="p">),</span>
            <span class="n">bar_format</span><span class="o">=</span><span class="s">"{l_bar}{r_bar}"</span>
        <span class="p">)</span>

        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">data_iter</span><span class="p">:</span>

            <span class="c1"># 0. batch_data will be sent into the device(GPU or cpu)
</span>            <span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="n">key</span><span class="p">:</span> <span class="n">value</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">data</span><span class="p">.</span><span class="n">items</span><span class="p">()}</span>

            <span class="c1"># 1. forward the next_sentence_prediction and masked_lm model
</span>            <span class="n">next_sent_output</span><span class="p">,</span> <span class="n">mask_lm_output</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="n">forward</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s">"bert_input"</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="s">"segment_label"</span><span class="p">])</span>

            <span class="c1"># 2-1. NLL(negative log likelihood) loss of is_next classification result
</span>            <span class="n">next_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">criterion</span><span class="p">(</span><span class="n">next_sent_output</span><span class="p">,</span> <span class="n">data</span><span class="p">[</span><span class="s">"is_next"</span><span class="p">])</span>

            <span class="c1"># 2-2. NLLLoss of predicting masked token word
</span>            <span class="c1"># transpose to (m, vocab_size, seq_len) vs (m, seq_len)
</span>            <span class="c1"># criterion(mask_lm_output.view(-1, mask_lm_output.size(-1)), data["bert_label"].view(-1))
</span>            <span class="n">mask_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">criterion</span><span class="p">(</span><span class="n">mask_lm_output</span><span class="p">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">data</span><span class="p">[</span><span class="s">"bert_label"</span><span class="p">])</span>

            <span class="c1"># 2-3. Adding next_loss and mask_loss : 3.4 Pre-training Procedure
</span>            <span class="n">loss</span> <span class="o">=</span> <span class="n">next_loss</span> <span class="o">+</span> <span class="n">mask_loss</span>

            <span class="c1"># 3. backward and optimization only in train
</span>            <span class="k">if</span> <span class="n">train</span><span class="p">:</span>
                <span class="bp">self</span><span class="p">.</span><span class="n">optim_schedule</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>
                <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
                <span class="bp">self</span><span class="p">.</span><span class="n">optim_schedule</span><span class="p">.</span><span class="n">step_and_update_lr</span><span class="p">()</span>

            <span class="c1"># next sentence prediction accuracy
</span>            <span class="n">correct</span> <span class="o">=</span> <span class="n">next_sent_output</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">).</span><span class="n">eq</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s">"is_next"</span><span class="p">]).</span><span class="nb">sum</span><span class="p">().</span><span class="n">item</span><span class="p">()</span>
            <span class="n">avg_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="p">.</span><span class="n">item</span><span class="p">()</span>
            <span class="n">total_correct</span> <span class="o">+=</span> <span class="n">correct</span>
            <span class="n">total_element</span> <span class="o">+=</span> <span class="n">data</span><span class="p">[</span><span class="s">"is_next"</span><span class="p">].</span><span class="n">nelement</span><span class="p">()</span>

            <span class="n">post_fix</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s">"epoch"</span><span class="p">:</span> <span class="n">epoch</span><span class="p">,</span>
                <span class="s">"iter"</span><span class="p">:</span> <span class="n">i</span><span class="p">,</span>
                <span class="s">"avg_loss"</span><span class="p">:</span> <span class="n">avg_loss</span> <span class="o">/</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span>
                <span class="s">"avg_acc"</span><span class="p">:</span> <span class="n">total_correct</span> <span class="o">/</span> <span class="n">total_element</span> <span class="o">*</span> <span class="mi">100</span><span class="p">,</span>
                <span class="s">"loss"</span><span class="p">:</span> <span class="n">loss</span><span class="p">.</span><span class="n">item</span><span class="p">()</span>
            <span class="p">}</span>

            <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="bp">self</span><span class="p">.</span><span class="n">log_freq</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">data_iter</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">post_fix</span><span class="p">))</span>
        <span class="k">print</span><span class="p">(</span>
            <span class="sa">f</span><span class="s">"EP</span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s">, </span><span class="si">{</span><span class="n">mode</span><span class="si">}</span><span class="s">: </span><span class="se">\
</span><span class="s">            avg_loss=</span><span class="si">{</span><span class="n">avg_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">data_iter</span><span class="p">)</span><span class="si">}</span><span class="s">, </span><span class="se">\
</span><span class="s">            total_acc=</span><span class="si">{</span><span class="n">total_correct</span> <span class="o">*</span> <span class="mf">100.0</span> <span class="o">/</span> <span class="n">total_element</span><span class="si">}</span><span class="s">"</span>
        <span class="p">)</span> 

<span class="c1">### test
</span><span class="n">train_data</span> <span class="o">=</span> <span class="n">BERTDataset</span><span class="p">(</span><span class="n">pairs</span><span class="p">,</span> <span class="n">seq_len</span><span class="o">=</span><span class="n">MAX_LEN</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">)</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">pin_memory</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">bert_model</span> <span class="o">=</span> <span class="n">BERT</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">.</span><span class="n">vocab</span><span class="p">))</span>
<span class="n">bert_lm</span> <span class="o">=</span> <span class="n">BERTLM</span><span class="p">(</span><span class="n">bert_model</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">.</span><span class="n">vocab</span><span class="p">))</span>
<span class="n">bert_trainer</span> <span class="o">=</span> <span class="n">BERTTrainer</span><span class="p">(</span><span class="n">bert_lm</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s">'cpu'</span><span class="p">)</span>   
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">2</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    <span class="n">bert_trainer</span><span class="p">.</span><span class="n">train</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Total Parameters: 117561257


EP_train:0:   0%|| 1/6926 [00:04&lt;9:01:10,  4.69s/it]

{'epoch': 0, 'iter': 0, 'avg_loss': 10.89798355102539, 'avg_acc': 53.125, 'loss': 10.89798355102539}


EP_train:0:   0%|| 11/6926 [00:39&lt;6:37:53,  3.45s/it]

{'epoch': 0, 'iter': 10, 'avg_loss': 10.867982777682217, 'avg_acc': 50.0, 'loss': 10.717849731445312}


EP_train:0:   0%|| 21/6926 [01:14&lt;6:35:39,  3.44s/it]

{'epoch': 0, 'iter': 20, 'avg_loss': 10.625354085649763, 'avg_acc': 50.0, 'loss': 10.077768325805664}


EP_train:0:   0%|| 31/6926 [01:48&lt;6:36:18,  3.45s/it]

{'epoch': 0, 'iter': 30, 'avg_loss': 10.422906321863975, 'avg_acc': 49.29435483870967, 'loss': 9.897195816040039}


EP_train:0:   1%|| 41/6926 [02:23&lt;6:41:40,  3.50s/it]

{'epoch': 0, 'iter': 40, 'avg_loss': 10.273156724325041, 'avg_acc': 49.84756097560975, 'loss': 9.698206901550293}


EP_train:0:   1%|| 51/6926 [02:57&lt;6:33:31,  3.43s/it]

{'epoch': 0, 'iter': 50, 'avg_loss': 10.160286865982355, 'avg_acc': 49.754901960784316, 'loss': 9.699801445007324}


EP_train:0:   1%|| 61/6926 [03:32&lt;6:38:19,  3.48s/it]

{'epoch': 0, 'iter': 60, 'avg_loss': 10.034004461569864, 'avg_acc': 50.25614754098361, 'loss': 9.232473373413086}


EP_train:0:   1%|| 71/6926 [04:06&lt;6:35:02,  3.46s/it]

{'epoch': 0, 'iter': 70, 'avg_loss': 9.914001276795293, 'avg_acc': 50.26408450704225, 'loss': 9.27730941772461}


EP_train:0:   1%|| 81/6926 [04:41&lt;6:33:04,  3.45s/it]

{'epoch': 0, 'iter': 80, 'avg_loss': 9.792469695762351, 'avg_acc': 50.1929012345679, 'loss': 8.917365074157715}


EP_train:0:   1%|| 91/6926 [05:15&lt;6:28:32,  3.41s/it]

{'epoch': 0, 'iter': 90, 'avg_loss': 9.684995368286804, 'avg_acc': 50.24038461538461, 'loss': 8.476027488708496}


EP_train:0:   1%|| 101/6926 [05:50&lt;6:35:22,  3.48s/it]

{'epoch': 0, 'iter': 100, 'avg_loss': 9.58456044149871, 'avg_acc': 49.93811881188119, 'loss': 8.499567985534668}


EP_train:0:   2%|| 111/6926 [06:24&lt;6:31:06,  3.44s/it]

{'epoch': 0, 'iter': 110, 'avg_loss': 9.4917702288241, 'avg_acc': 49.74662162162162, 'loss': 8.589751243591309}


EP_train:0:   2%|| 121/6926 [06:59&lt;6:29:42,  3.44s/it]

{'epoch': 0, 'iter': 120, 'avg_loss': 9.402804642669425, 'avg_acc': 49.43181818181818, 'loss': 8.433043479919434}


EP_train:0:   2%|| 131/6926 [07:33&lt;6:29:06,  3.44s/it]

{'epoch': 0, 'iter': 130, 'avg_loss': 9.320094690978072, 'avg_acc': 49.666030534351144, 'loss': 8.0137300491333}


EP_train:0:   2%|| 141/6926 [08:08&lt;6:28:28,  3.44s/it]

{'epoch': 0, 'iter': 140, 'avg_loss': 9.249869021963566, 'avg_acc': 49.933510638297875, 'loss': 8.34340763092041}


EP_train:0:   2%|| 151/6926 [08:42&lt;6:29:39,  3.45s/it]

{'epoch': 0, 'iter': 150, 'avg_loss': 9.182195328718779, 'avg_acc': 49.544701986754966, 'loss': 8.372312545776367}


EP_train:0:   2%|| 161/6926 [09:16&lt;6:28:02,  3.44s/it]

{'epoch': 0, 'iter': 160, 'avg_loss': 9.11899014881679, 'avg_acc': 49.631211180124225, 'loss': 8.272394180297852}


EP_train:0:   2%|| 171/6926 [09:51&lt;6:30:13,  3.47s/it]

{'epoch': 0, 'iter': 170, 'avg_loss': 9.060561514737314, 'avg_acc': 49.45175438596491, 'loss': 8.310636520385742}


EP_train:0:   3%|| 181/6926 [10:25&lt;6:27:49,  3.45s/it]

{'epoch': 0, 'iter': 180, 'avg_loss': 8.996443795894391, 'avg_acc': 49.51657458563536, 'loss': 8.046950340270996}


EP_train:0:   3%|| 191/6926 [11:00&lt;6:28:24,  3.46s/it]

{'epoch': 0, 'iter': 190, 'avg_loss': 8.946776854430194, 'avg_acc': 49.85274869109947, 'loss': 7.704115390777588}


EP_train:0:   3%|| 201/6926 [11:34&lt;6:25:56,  3.44s/it]

{'epoch': 0, 'iter': 200, 'avg_loss': 8.900923088415345, 'avg_acc': 49.98445273631841, 'loss': 7.938549518585205}


EP_train:0:   3%|| 211/6926 [12:09&lt;6:27:00,  3.46s/it]

{'epoch': 0, 'iter': 210, 'avg_loss': 8.856869426383792, 'avg_acc': 49.703791469194314, 'loss': 8.166866302490234}


EP_train:0:   3%|| 221/6926 [12:43&lt;6:23:55,  3.44s/it]

{'epoch': 0, 'iter': 220, 'avg_loss': 8.813115471628457, 'avg_acc': 49.872737556561084, 'loss': 8.149380683898926}


EP_train:0:   3%|| 231/6926 [13:18&lt;6:23:50,  3.44s/it]

{'epoch': 0, 'iter': 230, 'avg_loss': 8.776155362397562, 'avg_acc': 49.91883116883117, 'loss': 7.758193492889404}


EP_train:0:   3%|| 241/6926 [13:52&lt;6:28:36,  3.49s/it]

{'epoch': 0, 'iter': 240, 'avg_loss': 8.742853582152687, 'avg_acc': 49.7795643153527, 'loss': 8.106270790100098}


EP_train:0:   4%|| 251/6926 [14:27&lt;6:23:08,  3.44s/it]

{'epoch': 0, 'iter': 250, 'avg_loss': 8.702998539366096, 'avg_acc': 49.93774900398406, 'loss': 7.42200231552124}


EP_train:0:   4%|| 261/6926 [15:02&lt;6:21:51,  3.44s/it]

{'epoch': 0, 'iter': 260, 'avg_loss': 8.672737653228058, 'avg_acc': 49.724616858237546, 'loss': 7.538005352020264}


EP_train:0:   4%|| 271/6926 [15:36&lt;6:24:18,  3.46s/it]

{'epoch': 0, 'iter': 270, 'avg_loss': 8.637632560026162, 'avg_acc': 49.8270295202952, 'loss': 7.825370788574219}


EP_train:0:   4%|| 281/6926 [16:10&lt;6:20:35,  3.44s/it]

{'epoch': 0, 'iter': 280, 'avg_loss': 8.606602544886362, 'avg_acc': 50.011120996441285, 'loss': 7.539271354675293}


EP_train:0:   4%|| 291/6926 [16:45&lt;6:21:08,  3.45s/it]

{'epoch': 0, 'iter': 290, 'avg_loss': 8.573296895961171, 'avg_acc': 49.96778350515464, 'loss': 7.512895107269287}


EP_train:0:   4%|| 301/6926 [17:19&lt;6:17:24,  3.42s/it]

{'epoch': 0, 'iter': 300, 'avg_loss': 8.538208223260519, 'avg_acc': 49.91694352159469, 'loss': 7.337748050689697}


EP_train:0:   4%|| 311/6926 [17:54&lt;6:22:07,  3.47s/it]

{'epoch': 0, 'iter': 310, 'avg_loss': 8.508915681930983, 'avg_acc': 49.85932475884244, 'loss': 7.346322536468506}


EP_train:0:   5%|| 321/6926 [18:29&lt;6:22:02,  3.47s/it]

{'epoch': 0, 'iter': 320, 'avg_loss': 8.483167216042492, 'avg_acc': 49.84423676012461, 'loss': 7.777610778808594}


EP_train:0:   5%|| 331/6926 [19:04&lt;6:25:17,  3.51s/it]

{'epoch': 0, 'iter': 330, 'avg_loss': 8.454026497382772, 'avg_acc': 49.94335347432024, 'loss': 7.688755512237549}


EP_train:0:   5%|| 341/6926 [19:39&lt;6:25:37,  3.51s/it]

{'epoch': 0, 'iter': 340, 'avg_loss': 8.425729666287598, 'avg_acc': 50.0274926686217, 'loss': 7.76571798324585}


EP_train:0:   5%|| 351/6926 [20:13&lt;6:18:38,  3.46s/it]

{'epoch': 0, 'iter': 350, 'avg_loss': 8.397578780128066, 'avg_acc': 50.089031339031344, 'loss': 7.333456039428711}


EP_train:0:   5%|| 361/6926 [20:48&lt;6:15:35,  3.43s/it]

{'epoch': 0, 'iter': 360, 'avg_loss': 8.373832571869741, 'avg_acc': 50.181786703601105, 'loss': 7.28127384185791}


EP_train:0:   5%|| 371/6926 [21:23&lt;6:23:48,  3.51s/it]

{'epoch': 0, 'iter': 370, 'avg_loss': 8.34467096919962, 'avg_acc': 50.10950134770889, 'loss': 7.208791255950928}


EP_train:0:   6%|| 381/6926 [21:58&lt;6:23:20,  3.51s/it]

{'epoch': 0, 'iter': 380, 'avg_loss': 8.318920097951814, 'avg_acc': 50.14763779527559, 'loss': 7.3540472984313965}


EP_train:0:   6%|| 391/6926 [22:33&lt;6:16:44,  3.46s/it]

{'epoch': 0, 'iter': 390, 'avg_loss': 8.294580609597208, 'avg_acc': 50.22378516624041, 'loss': 7.1569037437438965}


EP_train:0:   6%|| 401/6926 [23:08&lt;6:16:49,  3.47s/it]

{'epoch': 0, 'iter': 400, 'avg_loss': 8.26598995522668, 'avg_acc': 50.194825436408976, 'loss': 7.342164993286133}


EP_train:0:   6%|| 411/6926 [23:42&lt;6:17:28,  3.48s/it]

{'epoch': 0, 'iter': 410, 'avg_loss': 8.244329189152033, 'avg_acc': 50.159671532846716, 'loss': 7.136423587799072}


EP_train:0:   6%|| 421/6926 [24:17&lt;6:15:41,  3.47s/it]

{'epoch': 0, 'iter': 420, 'avg_loss': 8.217572627894386, 'avg_acc': 50.24495249406176, 'loss': 6.9360151290893555}


EP_train:0:   6%|| 431/6926 [24:52&lt;6:17:11,  3.48s/it]

{'epoch': 0, 'iter': 430, 'avg_loss': 8.190027959385494, 'avg_acc': 50.16676334106729, 'loss': 6.8516340255737305}


EP_train:0:   6%|| 441/6926 [25:26&lt;6:16:11,  3.48s/it]

{'epoch': 0, 'iter': 440, 'avg_loss': 8.163161752445628, 'avg_acc': 50.09920634920635, 'loss': 6.856698036193848}


EP_train:0:   7%|| 451/6926 [26:01&lt;6:14:24,  3.47s/it]

{'epoch': 0, 'iter': 450, 'avg_loss': 8.137615378310041, 'avg_acc': 50.0, 'loss': 7.232318878173828}


EP_train:0:   7%|| 461/6926 [26:36&lt;6:09:12,  3.43s/it]

{'epoch': 0, 'iter': 460, 'avg_loss': 8.112295510712, 'avg_acc': 50.074566160520604, 'loss': 7.3403191566467285}


EP_train:0:   7%|| 471/6926 [27:10&lt;6:11:22,  3.45s/it]

{'epoch': 0, 'iter': 470, 'avg_loss': 8.08871301622654, 'avg_acc': 50.1526008492569, 'loss': 6.741003513336182}


EP_train:0:   7%|| 481/6926 [27:44&lt;6:10:50,  3.45s/it]

{'epoch': 0, 'iter': 480, 'avg_loss': 8.062562408169688, 'avg_acc': 50.11044698544699, 'loss': 7.173391819000244}


EP_train:0:   7%|| 491/6926 [28:19&lt;6:07:40,  3.43s/it]

{'epoch': 0, 'iter': 490, 'avg_loss': 8.039472820802521, 'avg_acc': 50.10819755600815, 'loss': 6.775766372680664}


EP_train:0:   7%|| 501/6926 [28:53&lt;6:10:09,  3.46s/it]

{'epoch': 0, 'iter': 500, 'avg_loss': 8.015938852123634, 'avg_acc': 50.1746506986028, 'loss': 6.762749195098877}


EP_train:0:   7%|| 511/6926 [29:28&lt;6:06:51,  3.43s/it]

{'epoch': 0, 'iter': 510, 'avg_loss': 7.990972069144949, 'avg_acc': 50.28131115459883, 'loss': 6.97685432434082}


EP_train:0:   8%|| 521/6926 [30:02&lt;6:05:00,  3.42s/it]

{'epoch': 0, 'iter': 520, 'avg_loss': 7.968726086753802, 'avg_acc': 50.38987523992322, 'loss': 6.717159748077393}


EP_train:0:   8%|| 531/6926 [30:37&lt;6:08:22,  3.46s/it]

{'epoch': 0, 'iter': 530, 'avg_loss': 7.9469300663403875, 'avg_acc': 50.32956685499058, 'loss': 6.882143020629883}


EP_train:0:   8%|| 541/6926 [31:11&lt;6:07:26,  3.45s/it]

{'epoch': 0, 'iter': 540, 'avg_loss': 7.923942721925689, 'avg_acc': 50.27148798521257, 'loss': 6.626901626586914}


EP_train:0:   8%|| 551/6926 [31:46&lt;6:07:35,  3.46s/it]

{'epoch': 0, 'iter': 550, 'avg_loss': 7.900415689672619, 'avg_acc': 50.25521778584392, 'loss': 6.582065105438232}


EP_train:0:   8%|| 561/6926 [32:20&lt;6:04:30,  3.44s/it]

{'epoch': 0, 'iter': 560, 'avg_loss': 7.878857596460298, 'avg_acc': 50.217245989304814, 'loss': 6.515105247497559}


EP_train:0:   8%|| 571/6926 [32:55&lt;6:05:31,  3.45s/it]

{'epoch': 0, 'iter': 570, 'avg_loss': 7.854935056482639, 'avg_acc': 50.333844133099824, 'loss': 6.567478179931641}


EP_train:0:   8%|| 581/6926 [33:29&lt;6:01:53,  3.42s/it]

{'epoch': 0, 'iter': 580, 'avg_loss': 7.830255449331156, 'avg_acc': 50.371127366609294, 'loss': 6.469046592712402}


EP_train:0:   9%|| 591/6926 [34:04&lt;6:06:36,  3.47s/it]

{'epoch': 0, 'iter': 590, 'avg_loss': 7.807632289763836, 'avg_acc': 50.34369712351946, 'loss': 6.447710037231445}


EP_train:0:   9%|| 601/6926 [34:38&lt;6:03:22,  3.45s/it]

{'epoch': 0, 'iter': 600, 'avg_loss': 7.785173703350759, 'avg_acc': 50.33797836938436, 'loss': 6.640997886657715}


EP_train:0:   9%|| 611/6926 [35:13&lt;6:02:34,  3.44s/it]

{'epoch': 0, 'iter': 610, 'avg_loss': 7.764555183448104, 'avg_acc': 50.32221767594108, 'loss': 6.900795936584473}


EP_train:0:   9%|| 621/6926 [35:47&lt;6:01:05,  3.44s/it]

{'epoch': 0, 'iter': 620, 'avg_loss': 7.744011157952645, 'avg_acc': 50.31702898550725, 'loss': 6.4761457443237305}


EP_train:0:   9%|| 631/6926 [36:22&lt;6:00:15,  3.43s/it]

{'epoch': 0, 'iter': 630, 'avg_loss': 7.723728686996194, 'avg_acc': 50.38629160063392, 'loss': 6.653886795043945}


EP_train:0:   9%|| 641/6926 [36:56&lt;6:02:31,  3.46s/it]

{'epoch': 0, 'iter': 640, 'avg_loss': 7.703406612884236, 'avg_acc': 50.35588923556942, 'loss': 6.2323832511901855}


EP_train:0:   9%|| 651/6926 [37:31&lt;6:02:14,  3.46s/it]

{'epoch': 0, 'iter': 650, 'avg_loss': 7.682767451999741, 'avg_acc': 50.360023041474655, 'loss': 6.42466402053833}


EP_train:0:  10%|| 661/6926 [38:06&lt;5:58:39,  3.43s/it]

{'epoch': 0, 'iter': 660, 'avg_loss': 7.663271325438899, 'avg_acc': 50.34512102874432, 'loss': 6.657591342926025}


EP_train:0:  10%|| 671/6926 [38:40&lt;6:00:59,  3.46s/it]

{'epoch': 0, 'iter': 670, 'avg_loss': 7.643598909704944, 'avg_acc': 50.293405365126674, 'loss': 6.493916034698486}


EP_train:0:  10%|| 681/6926 [39:15&lt;6:01:43,  3.48s/it]

{'epoch': 0, 'iter': 680, 'avg_loss': 7.625312284225934, 'avg_acc': 50.293685756240826, 'loss': 6.703272819519043}


EP_train:0:  10%|| 691/6926 [39:50&lt;5:57:29,  3.44s/it]

{'epoch': 0, 'iter': 690, 'avg_loss': 7.606728428179552, 'avg_acc': 50.23064399421129, 'loss': 6.424178600311279}


EP_train:0:  10%|| 701/6926 [40:24&lt;6:01:32,  3.48s/it]

{'epoch': 0, 'iter': 700, 'avg_loss': 7.587192697973973, 'avg_acc': 50.17831669044222, 'loss': 6.348569869995117}


EP_train:0:  10%|| 711/6926 [40:59&lt;5:56:46,  3.44s/it]

{'epoch': 0, 'iter': 710, 'avg_loss': 7.569472739465126, 'avg_acc': 50.210970464135016, 'loss': 6.120439052581787}


EP_train:0:  10%|| 721/6926 [41:33&lt;6:00:29,  3.49s/it]

{'epoch': 0, 'iter': 720, 'avg_loss': 7.552519568788526, 'avg_acc': 50.186373092926495, 'loss': 5.9562296867370605}


EP_train:0:  11%|| 731/6926 [42:08&lt;5:57:57,  3.47s/it]

{'epoch': 0, 'iter': 730, 'avg_loss': 7.534771291077871, 'avg_acc': 50.14962380300958, 'loss': 6.235836505889893}


EP_train:0:  11%|| 741/6926 [42:43&lt;5:58:59,  3.48s/it]

{'epoch': 0, 'iter': 740, 'avg_loss': 7.516607673222881, 'avg_acc': 50.10964912280702, 'loss': 5.814441204071045}


EP_train:0:  11%|| 751/6926 [43:18&lt;5:58:59,  3.49s/it]

{'epoch': 0, 'iter': 750, 'avg_loss': 7.499122726298204, 'avg_acc': 50.178928095872166, 'loss': 5.808696269989014}


EP_train:0:  11%|| 761/6926 [43:52&lt;5:54:51,  3.45s/it]

{'epoch': 0, 'iter': 760, 'avg_loss': 7.481864879698383, 'avg_acc': 50.193002628120894, 'loss': 6.158096790313721}


EP_train:0:  11%|| 771/6926 [44:27&lt;5:55:41,  3.47s/it]

{'epoch': 0, 'iter': 770, 'avg_loss': 7.4656713172774065, 'avg_acc': 50.15402075226978, 'loss': 6.347654819488525}


EP_train:0:  11%|| 781/6926 [45:01&lt;6:02:42,  3.54s/it]

{'epoch': 0, 'iter': 780, 'avg_loss': 7.4503515539034995, 'avg_acc': 50.11203585147247, 'loss': 6.144024848937988}


EP_train:0:  11%|| 791/6926 [45:36&lt;5:50:23,  3.43s/it]

{'epoch': 0, 'iter': 790, 'avg_loss': 7.433421123494994, 'avg_acc': 50.11061946902655, 'loss': 5.9156012535095215}


EP_train:0:  12%|| 801/6926 [46:10&lt;5:50:32,  3.43s/it]

{'epoch': 0, 'iter': 800, 'avg_loss': 7.416626945714676, 'avg_acc': 50.105337078651694, 'loss': 6.050990581512451}


EP_train:0:  12%|| 811/6926 [46:44&lt;5:48:55,  3.42s/it]

{'epoch': 0, 'iter': 810, 'avg_loss': 7.4007179522484945, 'avg_acc': 50.1040382244143, 'loss': 6.308589458465576}


EP_train:0:  12%|| 821/6926 [47:19&lt;5:50:34,  3.45s/it]

{'epoch': 0, 'iter': 820, 'avg_loss': 7.385387445628716, 'avg_acc': 50.106577344701584, 'loss': 5.797635078430176}


EP_train:0:  12%|| 831/6926 [47:54&lt;5:50:21,  3.45s/it]

{'epoch': 0, 'iter': 830, 'avg_loss': 7.3701629587028865, 'avg_acc': 50.157942238267154, 'loss': 6.100361347198486}


EP_train:0:  12%|| 841/6926 [48:28&lt;5:53:21,  3.48s/it]

{'epoch': 0, 'iter': 840, 'avg_loss': 7.355489640683822, 'avg_acc': 50.182074910820454, 'loss': 6.523128986358643}


EP_train:0:  12%|| 851/6926 [49:03&lt;5:51:57,  3.48s/it]

{'epoch': 0, 'iter': 850, 'avg_loss': 7.338581892634391, 'avg_acc': 50.146886016451234, 'loss': 5.890628814697266}


EP_train:0:  12%|| 861/6926 [49:38&lt;5:55:22,  3.52s/it]

{'epoch': 0, 'iter': 860, 'avg_loss': 7.3246063903649095, 'avg_acc': 50.13792102206737, 'loss': 5.798765659332275}


EP_train:0:  13%|| 871/6926 [50:13&lt;6:16:19,  3.73s/it]

{'epoch': 0, 'iter': 870, 'avg_loss': 7.309846629505179, 'avg_acc': 50.11839839265212, 'loss': 6.017465591430664}


EP_train:0:  13%|| 881/6926 [50:48&lt;5:49:03,  3.46s/it]

{'epoch': 0, 'iter': 880, 'avg_loss': 7.294576557756959, 'avg_acc': 50.152525539160045, 'loss': 6.191736698150635}


EP_train:0:  13%|| 891/6926 [51:22&lt;5:46:13,  3.44s/it]

{'epoch': 0, 'iter': 890, 'avg_loss': 7.280248526370887, 'avg_acc': 50.14029180695847, 'loss': 5.8434906005859375}


EP_train:0:  13%|| 901/6926 [51:57&lt;5:47:59,  3.47s/it]

{'epoch': 0, 'iter': 900, 'avg_loss': 7.267267483849901, 'avg_acc': 50.11098779134295, 'loss': 6.437450885772705}


EP_train:0:  13%|| 911/6926 [52:32&lt;5:49:36,  3.49s/it]

{'epoch': 0, 'iter': 910, 'avg_loss': 7.252066610149965, 'avg_acc': 50.12692096597146, 'loss': 5.577602863311768}


EP_train:0:  13%|| 921/6926 [53:07&lt;5:55:37,  3.55s/it]

{'epoch': 0, 'iter': 920, 'avg_loss': 7.2393625836160105, 'avg_acc': 50.139115092290986, 'loss': 6.020793914794922}


EP_train:0:  13%|| 931/6926 [53:42&lt;5:50:26,  3.51s/it]

{'epoch': 0, 'iter': 930, 'avg_loss': 7.2262739520579995, 'avg_acc': 50.137620837808804, 'loss': 6.0215888023376465}


EP_train:0:  14%|| 941/6926 [54:16&lt;5:43:23,  3.44s/it]

{'epoch': 0, 'iter': 940, 'avg_loss': 7.215727404250855, 'avg_acc': 50.13283740701382, 'loss': 6.280351161956787}


EP_train:0:  14%|| 951/6926 [54:51&lt;5:43:46,  3.45s/it]

{'epoch': 0, 'iter': 950, 'avg_loss': 7.203543867598572, 'avg_acc': 50.1215825446898, 'loss': 6.030501842498779}


EP_train:0:  14%|| 961/6926 [55:25&lt;5:49:09,  3.51s/it]

{'epoch': 0, 'iter': 960, 'avg_loss': 7.191026379985194, 'avg_acc': 50.11381373569199, 'loss': 6.155196189880371}


EP_train:0:  14%|| 971/6926 [56:00&lt;5:42:05,  3.45s/it]

{'epoch': 0, 'iter': 970, 'avg_loss': 7.177859566115941, 'avg_acc': 50.13838825952626, 'loss': 6.143617153167725}


EP_train:0:  14%|| 981/6926 [56:35&lt;5:48:32,  3.52s/it]

{'epoch': 0, 'iter': 980, 'avg_loss': 7.165363018179766, 'avg_acc': 50.11786442405708, 'loss': 6.266634464263916}


EP_train:0:  14%|| 991/6926 [57:09&lt;5:45:55,  3.50s/it]

{'epoch': 0, 'iter': 990, 'avg_loss': 7.1547578408427, 'avg_acc': 50.12613521695257, 'loss': 5.8587799072265625}


EP_train:0:  14%|| 1001/6926 [57:44&lt;5:40:42,  3.45s/it]

{'epoch': 0, 'iter': 1000, 'avg_loss': 7.143188433690028, 'avg_acc': 50.19043456543456, 'loss': 5.374644756317139}


EP_train:0:  15%|| 1011/6926 [58:19&lt;5:40:44,  3.46s/it]

{'epoch': 0, 'iter': 1010, 'avg_loss': 7.130960667758266, 'avg_acc': 50.09891196834817, 'loss': 5.900915622711182}


EP_train:0:  15%|| 1021/6926 [58:53&lt;5:41:47,  3.47s/it]

{'epoch': 0, 'iter': 1020, 'avg_loss': 7.118152967746298, 'avg_acc': 50.0765181194907, 'loss': 5.907759666442871}


EP_train:0:  15%|| 1031/6926 [59:28&lt;5:40:24,  3.46s/it]

{'epoch': 0, 'iter': 1030, 'avg_loss': 7.106619142537899, 'avg_acc': 50.054558680892335, 'loss': 5.74845552444458}


EP_train:0:  15%|| 1041/6926 [1:00:02&lt;5:35:59,  3.43s/it]

{'epoch': 0, 'iter': 1040, 'avg_loss': 7.0948704202855355, 'avg_acc': 50.03302113352546, 'loss': 6.052654266357422}


EP_train:0:  15%|| 1051/6926 [1:00:37&lt;5:40:52,  3.48s/it]

{'epoch': 0, 'iter': 1050, 'avg_loss': 7.082714090338216, 'avg_acc': 50.04757373929591, 'loss': 5.714799880981445}


EP_train:0:  15%|| 1061/6926 [1:01:12&lt;5:42:37,  3.51s/it]

{'epoch': 0, 'iter': 1060, 'avg_loss': 7.0725709513377515, 'avg_acc': 50.047125353440144, 'loss': 5.841132164001465}


EP_train:0:  15%|| 1071/6926 [1:01:47&lt;5:42:38,  3.51s/it]

{'epoch': 0, 'iter': 1070, 'avg_loss': 7.062578005839685, 'avg_acc': 50.04668534080299, 'loss': 6.043107986450195}


EP_train:0:  16%|| 1081/6926 [1:02:21&lt;5:36:16,  3.45s/it]

{'epoch': 0, 'iter': 1080, 'avg_loss': 7.052328350144774, 'avg_acc': 50.01156336725254, 'loss': 5.979182243347168}


EP_train:0:  16%|| 1091/6926 [1:02:56&lt;5:35:00,  3.44s/it]

{'epoch': 0, 'iter': 1090, 'avg_loss': 7.042487336341446, 'avg_acc': 50.01432172318974, 'loss': 5.883883953094482}


EP_train:0:  16%|| 1101/6926 [1:03:31&lt;5:37:29,  3.48s/it]

{'epoch': 0, 'iter': 1100, 'avg_loss': 7.031923555223429, 'avg_acc': 50.00851498637602, 'loss': 5.748727321624756}


EP_train:0:  16%|| 1111/6926 [1:04:05&lt;5:37:39,  3.48s/it]

{'epoch': 0, 'iter': 1110, 'avg_loss': 7.0224045612702595, 'avg_acc': 49.991561656165615, 'loss': 5.702943801879883}


EP_train:0:  16%|| 1121/6926 [1:04:40&lt;5:34:33,  3.46s/it]

{'epoch': 0, 'iter': 1120, 'avg_loss': 7.012452934598625, 'avg_acc': 49.99442462087422, 'loss': 5.645112991333008}


EP_train:0:  16%|| 1131/6926 [1:05:15&lt;5:37:45,  3.50s/it]

{'epoch': 0, 'iter': 1130, 'avg_loss': 7.002737390583959, 'avg_acc': 49.98065870910698, 'loss': 6.049877643585205}


EP_train:0:  16%|| 1141/6926 [1:05:50&lt;5:31:52,  3.44s/it]

{'epoch': 0, 'iter': 1140, 'avg_loss': 6.99303060660333, 'avg_acc': 49.98904469763366, 'loss': 5.958681106567383}


EP_train:0:  17%|| 1151/6926 [1:06:25&lt;5:33:18,  3.46s/it]

{'epoch': 0, 'iter': 1150, 'avg_loss': 6.98393302332516, 'avg_acc': 50.00271503040834, 'loss': 5.5045552253723145}


EP_train:0:  17%|| 1161/6926 [1:06:59&lt;5:33:59,  3.48s/it]

{'epoch': 0, 'iter': 1160, 'avg_loss': 6.974377678551621, 'avg_acc': 50.00538329026701, 'loss': 5.9710164070129395}


EP_train:0:  17%|| 1171/6926 [1:07:34&lt;5:30:32,  3.45s/it]

{'epoch': 0, 'iter': 1170, 'avg_loss': 6.963725277341196, 'avg_acc': 50.00266865926558, 'loss': 5.79750394821167}


EP_train:0:  17%|| 1181/6926 [1:08:08&lt;5:28:49,  3.43s/it]

{'epoch': 0, 'iter': 1180, 'avg_loss': 6.954753385167521, 'avg_acc': 50.04498306519899, 'loss': 5.537152290344238}


EP_train:0:  17%|| 1191/6926 [1:08:43&lt;5:30:47,  3.46s/it]

{'epoch': 0, 'iter': 1190, 'avg_loss': 6.94566969907554, 'avg_acc': 50.07871536523929, 'loss': 5.853878021240234}


EP_train:0:  17%|| 1201/6926 [1:09:17&lt;5:29:13,  3.45s/it]

{'epoch': 0, 'iter': 1200, 'avg_loss': 6.937208781532205, 'avg_acc': 50.07285595337218, 'loss': 6.008646488189697}


EP_train:0:  17%|| 1211/6926 [1:09:52&lt;5:32:25,  3.49s/it]

{'epoch': 0, 'iter': 1210, 'avg_loss': 6.928555098769095, 'avg_acc': 50.05677126341867, 'loss': 5.945259094238281}


EP_train:0:  18%|| 1221/6926 [1:10:26&lt;5:28:31,  3.46s/it]

{'epoch': 0, 'iter': 1220, 'avg_loss': 6.920036094487446, 'avg_acc': 50.05374692874693, 'loss': 6.105030536651611}


EP_train:0:  18%|| 1231/6926 [1:11:01&lt;5:31:22,  3.49s/it]

{'epoch': 0, 'iter': 1230, 'avg_loss': 6.91204860518368, 'avg_acc': 50.00507717303005, 'loss': 5.601499557495117}


EP_train:0:  18%|| 1241/6926 [1:11:36&lt;5:27:26,  3.46s/it]

{'epoch': 0, 'iter': 1240, 'avg_loss': 6.90380984136503, 'avg_acc': 49.97481869460113, 'loss': 5.824779987335205}


EP_train:0:  18%|| 1251/6926 [1:12:10&lt;5:26:24,  3.45s/it]

{'epoch': 0, 'iter': 1250, 'avg_loss': 6.8957438419381685, 'avg_acc': 49.95503597122302, 'loss': 5.898371696472168}


EP_train:0:  18%|| 1261/6926 [1:12:45&lt;5:27:33,  3.47s/it]

{'epoch': 0, 'iter': 1260, 'avg_loss': 6.8863400270974795, 'avg_acc': 49.960348929421095, 'loss': 5.912337779998779}


EP_train:0:  18%|| 1271/6926 [1:13:19&lt;5:23:54,  3.44s/it]

{'epoch': 0, 'iter': 1270, 'avg_loss': 6.878045447880035, 'avg_acc': 49.955743509048, 'loss': 5.8559770584106445}


EP_train:0:  18%|| 1281/6926 [1:13:54&lt;5:25:14,  3.46s/it]

{'epoch': 0, 'iter': 1280, 'avg_loss': 6.870755708189703, 'avg_acc': 49.98536299765808, 'loss': 5.950345993041992}


EP_train:0:  19%|| 1291/6926 [1:14:29&lt;5:24:31,  3.46s/it]

{'epoch': 0, 'iter': 1290, 'avg_loss': 6.863620923158275, 'avg_acc': 49.961270333075134, 'loss': 5.999393463134766}


EP_train:0:  19%|| 1301/6926 [1:15:03&lt;5:21:48,  3.43s/it]

{'epoch': 0, 'iter': 1300, 'avg_loss': 6.856247264178875, 'avg_acc': 50.00240199846272, 'loss': 5.7338080406188965}


EP_train:0:  19%|| 1311/6926 [1:15:38&lt;5:23:22,  3.46s/it]

{'epoch': 0, 'iter': 1310, 'avg_loss': 6.849443752105503, 'avg_acc': 50.030987795575896, 'loss': 6.524251937866211}


EP_train:0:  19%|| 1321/6926 [1:16:13&lt;5:25:18,  3.48s/it]

{'epoch': 0, 'iter': 1320, 'avg_loss': 6.8420479512413195, 'avg_acc': 50.021290688872064, 'loss': 6.1805219650268555}


EP_train:0:  19%|| 1331/6926 [1:16:47&lt;5:24:17,  3.48s/it]

{'epoch': 0, 'iter': 1330, 'avg_loss': 6.834033288246344, 'avg_acc': 50.02347858752817, 'loss': 5.730384826660156}


EP_train:0:  19%|| 1341/6926 [1:17:22&lt;5:22:45,  3.47s/it]

{'epoch': 0, 'iter': 1340, 'avg_loss': 6.826291152205954, 'avg_acc': 50.044276659209544, 'loss': 5.616055011749268}


EP_train:0:  20%|| 1351/6926 [1:17:56&lt;5:22:55,  3.48s/it]

{'epoch': 0, 'iter': 1350, 'avg_loss': 6.8185702647922835, 'avg_acc': 50.03932272390822, 'loss': 5.9452009201049805}


EP_train:0:  20%|| 1361/6926 [1:18:31&lt;5:22:40,  3.48s/it]

{'epoch': 0, 'iter': 1360, 'avg_loss': 6.811983755631625, 'avg_acc': 50.04362601028656, 'loss': 5.786157608032227}


EP_train:0:  20%|| 1371/6926 [1:19:06&lt;5:19:56,  3.46s/it]

{'epoch': 0, 'iter': 1370, 'avg_loss': 6.805471073181241, 'avg_acc': 50.0, 'loss': 5.986886024475098}


EP_train:0:  20%|| 1381/6926 [1:19:41&lt;5:18:20,  3.44s/it]

{'epoch': 0, 'iter': 1380, 'avg_loss': 6.8000097996423765, 'avg_acc': 49.97963432295438, 'loss': 6.026611328125}


EP_train:0:  20%|| 1391/6926 [1:20:15&lt;5:17:38,  3.44s/it]

{'epoch': 0, 'iter': 1390, 'avg_loss': 6.793595924212896, 'avg_acc': 49.96630122214235, 'loss': 6.366022109985352}


EP_train:0:  20%|| 1401/6926 [1:20:50&lt;5:18:58,  3.46s/it]

{'epoch': 0, 'iter': 1400, 'avg_loss': 6.786099822243821, 'avg_acc': 49.95538900785154, 'loss': 5.348405838012695}


EP_train:0:  20%|| 1411/6926 [1:21:24&lt;5:18:42,  3.47s/it]

{'epoch': 0, 'iter': 1410, 'avg_loss': 6.779374823174859, 'avg_acc': 49.96456413890857, 'loss': 6.062073707580566}


EP_train:0:  21%|| 1421/6926 [1:21:59&lt;5:15:47,  3.44s/it]

{'epoch': 0, 'iter': 1420, 'avg_loss': 6.772841719319332, 'avg_acc': 49.931826178747365, 'loss': 5.9784393310546875}


EP_train:0:  21%|| 1431/6926 [1:22:34&lt;5:17:28,  3.47s/it]

{'epoch': 0, 'iter': 1430, 'avg_loss': 6.76654654328928, 'avg_acc': 49.951956673654784, 'loss': 5.905849933624268}


EP_train:0:  21%|| 1441/6926 [1:23:08&lt;5:16:11,  3.46s/it]

{'epoch': 0, 'iter': 1440, 'avg_loss': 6.760677034204656, 'avg_acc': 49.97831367106176, 'loss': 6.101155757904053}


EP_train:0:  21%|| 1451/6926 [1:23:43&lt;5:13:33,  3.44s/it]

{'epoch': 0, 'iter': 1450, 'avg_loss': 6.754288878135235, 'avg_acc': 49.956926257753274, 'loss': 5.826649188995361}


EP_train:0:  21%|| 1461/6926 [1:24:18&lt;5:16:22,  3.47s/it]

{'epoch': 0, 'iter': 1460, 'avg_loss': 6.748312718080054, 'avg_acc': 49.9679158110883, 'loss': 5.891135215759277}


EP_train:0:  21%|| 1471/6926 [1:24:52&lt;5:17:34,  3.49s/it]

{'epoch': 0, 'iter': 1470, 'avg_loss': 6.743577530236571, 'avg_acc': 49.98725356900068, 'loss': 5.77427864074707}


EP_train:0:  21%|| 1481/6926 [1:25:27&lt;5:15:40,  3.48s/it]

{'epoch': 0, 'iter': 1480, 'avg_loss': 6.737167069591597, 'avg_acc': 49.99366981769075, 'loss': 5.330727577209473}


EP_train:0:  22%|| 1491/6926 [1:26:02&lt;5:13:14,  3.46s/it]

{'epoch': 0, 'iter': 1490, 'avg_loss': 6.7310639086543596, 'avg_acc': 50.046109993293086, 'loss': 6.10654878616333}


EP_train:0:  22%|| 1501/6926 [1:26:36&lt;5:12:21,  3.45s/it]

{'epoch': 0, 'iter': 1500, 'avg_loss': 6.724842217348163, 'avg_acc': 50.03331112591606, 'loss': 5.758561611175537}


EP_train:0:  22%|| 1511/6926 [1:27:11&lt;5:16:13,  3.50s/it]

{'epoch': 0, 'iter': 1510, 'avg_loss': 6.719215481743601, 'avg_acc': 50.018613500992714, 'loss': 5.708592414855957}


EP_train:0:  22%|| 1521/6926 [1:27:46&lt;5:11:33,  3.46s/it]

{'epoch': 0, 'iter': 1520, 'avg_loss': 6.712945926824265, 'avg_acc': 50.055473372781066, 'loss': 5.535630226135254}


EP_train:0:  22%|| 1531/6926 [1:28:20&lt;5:10:00,  3.45s/it]

{'epoch': 0, 'iter': 1530, 'avg_loss': 6.707054874151069, 'avg_acc': 50.03878184193338, 'loss': 5.712316036224365}


EP_train:0:  22%|| 1541/6926 [1:28:55&lt;5:12:20,  3.48s/it]

{'epoch': 0, 'iter': 1540, 'avg_loss': 6.701259867700951, 'avg_acc': 50.05069759896171, 'loss': 5.39851188659668}


EP_train:0:  22%|| 1551/6926 [1:29:30&lt;5:13:45,  3.50s/it]

{'epoch': 0, 'iter': 1550, 'avg_loss': 6.695485569445415, 'avg_acc': 50.04029658284978, 'loss': 5.813269138336182}


EP_train:0:  23%|| 1561/6926 [1:30:05&lt;5:15:53,  3.53s/it]

{'epoch': 0, 'iter': 1560, 'avg_loss': 6.690367103615761, 'avg_acc': 50.03002882767456, 'loss': 5.805647850036621}


EP_train:0:  23%|| 1571/6926 [1:30:40&lt;5:12:01,  3.50s/it]

{'epoch': 0, 'iter': 1570, 'avg_loss': 6.685033302865614, 'avg_acc': 50.08553469127944, 'loss': 6.341202735900879}


EP_train:0:  23%|| 1581/6926 [1:31:14&lt;5:06:20,  3.44s/it]

{'epoch': 0, 'iter': 1580, 'avg_loss': 6.679796560891892, 'avg_acc': 50.1166192283365, 'loss': 5.751227378845215}


EP_train:0:  23%|| 1591/6926 [1:31:49&lt;5:11:54,  3.51s/it]

{'epoch': 0, 'iter': 1590, 'avg_loss': 6.674660406945862, 'avg_acc': 50.133563796354494, 'loss': 5.759082317352295}


EP_train:0:  23%|| 1601/6926 [1:32:24&lt;5:08:01,  3.47s/it]

{'epoch': 0, 'iter': 1600, 'avg_loss': 6.668804914783046, 'avg_acc': 50.119066208619614, 'loss': 5.621526718139648}


EP_train:0:  23%|| 1611/6926 [1:32:58&lt;5:03:46,  3.43s/it]

{'epoch': 0, 'iter': 1610, 'avg_loss': 6.663902772575487, 'avg_acc': 50.11444754810677, 'loss': 5.824803829193115}


EP_train:0:  23%|| 1621/6926 [1:33:32&lt;5:03:55,  3.44s/it]

{'epoch': 0, 'iter': 1620, 'avg_loss': 6.659484281428135, 'avg_acc': 50.113741517581744, 'loss': 5.608224391937256}


EP_train:0:  24%|| 1631/6926 [1:34:07&lt;5:02:43,  3.43s/it]

{'epoch': 0, 'iter': 1630, 'avg_loss': 6.6549554376935465, 'avg_acc': 50.12837216431637, 'loss': 6.16309928894043}


EP_train:0:  24%|| 1641/6926 [1:34:41&lt;5:03:30,  3.45s/it]

{'epoch': 0, 'iter': 1640, 'avg_loss': 6.6503012007434945, 'avg_acc': 50.114259597806225, 'loss': 5.619045257568359}


EP_train:0:  24%|| 1651/6926 [1:35:16&lt;5:06:07,  3.48s/it]

{'epoch': 0, 'iter': 1650, 'avg_loss': 6.644976955843578, 'avg_acc': 50.111674742580256, 'loss': 5.851489067077637}


EP_train:0:  24%|| 1661/6926 [1:35:50&lt;5:01:16,  3.43s/it]

{'epoch': 0, 'iter': 1660, 'avg_loss': 6.640191291772336, 'avg_acc': 50.109121011438894, 'loss': 5.876086235046387}


EP_train:0:  24%|| 1671/6926 [1:36:25&lt;5:03:36,  3.47s/it]

{'epoch': 0, 'iter': 1670, 'avg_loss': 6.6346327164157435, 'avg_acc': 50.11407839616996, 'loss': 5.317509651184082}


EP_train:0:  24%|| 1681/6926 [1:36:59&lt;5:06:07,  3.50s/it]

{'epoch': 0, 'iter': 1680, 'avg_loss': 6.630361939100621, 'avg_acc': 50.10596371207614, 'loss': 6.142337322235107}


EP_train:0:  24%|| 1691/6926 [1:37:34&lt;4:59:59,  3.44s/it]

{'epoch': 0, 'iter': 1690, 'avg_loss': 6.625920400613867, 'avg_acc': 50.114577173270256, 'loss': 5.6801605224609375}


EP_train:0:  25%|| 1701/6926 [1:38:09&lt;5:01:27,  3.46s/it]

{'epoch': 0, 'iter': 1700, 'avg_loss': 6.62068870556768, 'avg_acc': 50.10288065843621, 'loss': 6.168246269226074}


EP_train:0:  25%|| 1711/6926 [1:38:43&lt;5:00:26,  3.46s/it]

{'epoch': 0, 'iter': 1710, 'avg_loss': 6.6155091547116, 'avg_acc': 50.08218877849211, 'loss': 5.276941299438477}


EP_train:0:  25%|| 1721/6926 [1:39:18&lt;4:58:53,  3.45s/it]

{'epoch': 0, 'iter': 1720, 'avg_loss': 6.61112783011969, 'avg_acc': 50.063553166763505, 'loss': 5.9864277839660645}


EP_train:0:  25%|| 1731/6926 [1:39:52&lt;4:58:41,  3.45s/it]

{'epoch': 0, 'iter': 1730, 'avg_loss': 6.607044134024318, 'avg_acc': 50.036106296938186, 'loss': 6.244937419891357}


EP_train:0:  25%|| 1741/6926 [1:40:27&lt;4:59:28,  3.47s/it]

{'epoch': 0, 'iter': 1740, 'avg_loss': 6.601897341023226, 'avg_acc': 50.05743825387709, 'loss': 5.8550496101379395}


EP_train:0:  25%|| 1751/6926 [1:41:01&lt;5:00:35,  3.49s/it]

{'epoch': 0, 'iter': 1750, 'avg_loss': 6.5980474860378155, 'avg_acc': 50.057110222729875, 'loss': 6.101003646850586}


EP_train:0:  25%|| 1761/6926 [1:41:36&lt;4:57:21,  3.45s/it]

{'epoch': 0, 'iter': 1760, 'avg_loss': 6.592984796856562, 'avg_acc': 50.03371663827371, 'loss': 5.774938106536865}


EP_train:0:  26%|| 1771/6926 [1:42:11&lt;5:00:09,  3.49s/it]

{'epoch': 0, 'iter': 1770, 'avg_loss': 6.589065146540465, 'avg_acc': 50.01588085827217, 'loss': 5.664983749389648}


EP_train:0:  26%|| 1781/6926 [1:42:46&lt;4:59:42,  3.50s/it]

{'epoch': 0, 'iter': 1780, 'avg_loss': 6.585036697312729, 'avg_acc': 50.00701852891633, 'loss': 5.618933200836182}


EP_train:0:  26%|| 1791/6926 [1:43:21&lt;4:57:17,  3.47s/it]

{'epoch': 0, 'iter': 1790, 'avg_loss': 6.581039176847201, 'avg_acc': 50.0034896705751, 'loss': 5.975118160247803}


EP_train:0:  26%|| 1801/6926 [1:43:55&lt;4:57:44,  3.49s/it]

{'epoch': 0, 'iter': 1800, 'avg_loss': 6.576796160745065, 'avg_acc': 50.01041088284287, 'loss': 5.964684009552002}


EP_train:0:  26%|| 1811/6926 [1:44:30&lt;4:56:40,  3.48s/it]

{'epoch': 0, 'iter': 1810, 'avg_loss': 6.572977085787574, 'avg_acc': 50.00690226394258, 'loss': 5.743773937225342}


EP_train:0:  26%|| 1821/6926 [1:45:05&lt;4:52:57,  3.44s/it]

{'epoch': 0, 'iter': 1820, 'avg_loss': 6.568574661870764, 'avg_acc': 49.98970345963756, 'loss': 5.717203617095947}


EP_train:0:  26%|| 1831/6926 [1:45:39&lt;4:51:06,  3.43s/it]

{'epoch': 0, 'iter': 1830, 'avg_loss': 6.564488740907478, 'avg_acc': 50.006826870562534, 'loss': 5.563779830932617}


EP_train:0:  27%|| 1841/6926 [1:46:14&lt;4:58:22,  3.52s/it]

{'epoch': 0, 'iter': 1840, 'avg_loss': 6.559978160309053, 'avg_acc': 50.025461705594786, 'loss': 5.8036932945251465}


EP_train:0:  27%|| 1851/6926 [1:46:49&lt;4:51:01,  3.44s/it]

{'epoch': 0, 'iter': 1850, 'avg_loss': 6.556545357263649, 'avg_acc': 50.047271745002696, 'loss': 5.616850852966309}


EP_train:0:  27%|| 1861/6926 [1:47:23&lt;4:50:29,  3.44s/it]

{'epoch': 0, 'iter': 1860, 'avg_loss': 6.553398664762486, 'avg_acc': 50.06380977968834, 'loss': 5.406038761138916}


EP_train:0:  27%|| 1871/6926 [1:47:58&lt;4:52:47,  3.48s/it]

{'epoch': 0, 'iter': 1870, 'avg_loss': 6.550090259182969, 'avg_acc': 50.058458043826825, 'loss': 5.88486385345459}


EP_train:0:  27%|| 1881/6926 [1:48:33&lt;4:52:38,  3.48s/it]

{'epoch': 0, 'iter': 1880, 'avg_loss': 6.546166201717735, 'avg_acc': 50.063131313131315, 'loss': 5.72655725479126}


EP_train:0:  27%|| 1891/6926 [1:49:07&lt;4:51:40,  3.48s/it]

{'epoch': 0, 'iter': 1890, 'avg_loss': 6.541274296676337, 'avg_acc': 50.0462718138551, 'loss': 5.617991924285889}


EP_train:0:  27%|| 1901/6926 [1:49:42&lt;4:50:29,  3.47s/it]

{'epoch': 0, 'iter': 1900, 'avg_loss': 6.537737650221614, 'avg_acc': 50.05589163598106, 'loss': 5.472006797790527}


EP_train:0:  28%|| 1911/6926 [1:50:17&lt;4:47:35,  3.44s/it]

{'epoch': 0, 'iter': 1910, 'avg_loss': 6.534674536926094, 'avg_acc': 50.05069335426479, 'loss': 6.121761798858643}


EP_train:0:  28%|| 1921/6926 [1:50:51&lt;4:48:22,  3.46s/it]

{'epoch': 0, 'iter': 1920, 'avg_loss': 6.531029757579622, 'avg_acc': 50.06832378969287, 'loss': 5.909574031829834}


EP_train:0:  28%|| 1931/6926 [1:51:26&lt;4:51:06,  3.50s/it]

{'epoch': 0, 'iter': 1930, 'avg_loss': 6.5268044886596455, 'avg_acc': 50.074443293630246, 'loss': 5.91326904296875}


EP_train:0:  28%|| 1941/6926 [1:52:01&lt;4:47:34,  3.46s/it]

{'epoch': 0, 'iter': 1940, 'avg_loss': 6.52398176969541, 'avg_acc': 50.08049974240082, 'loss': 5.717437744140625}


EP_train:0:  28%|| 1951/6926 [1:52:36&lt;4:44:04,  3.43s/it]

{'epoch': 0, 'iter': 1950, 'avg_loss': 6.520226235880966, 'avg_acc': 50.08489236289082, 'loss': 5.268540382385254}


EP_train:0:  28%|| 1961/6926 [1:53:10&lt;4:44:00,  3.43s/it]

{'epoch': 0, 'iter': 1960, 'avg_loss': 6.516827085564053, 'avg_acc': 50.08605303416624, 'loss': 5.840364933013916}


EP_train:0:  28%|| 1971/6926 [1:53:44&lt;4:42:27,  3.42s/it]

{'epoch': 0, 'iter': 1970, 'avg_loss': 6.513644299974059, 'avg_acc': 50.06817605276509, 'loss': 5.865345001220703}


EP_train:0:  29%|| 1981/6926 [1:54:19&lt;4:46:37,  3.48s/it]

{'epoch': 0, 'iter': 1980, 'avg_loss': 6.510300359961843, 'avg_acc': 50.075719333669866, 'loss': 5.67856502532959}


EP_train:0:  29%|| 1991/6926 [1:54:54&lt;4:44:53,  3.46s/it]

{'epoch': 0, 'iter': 1990, 'avg_loss': 6.50666828457283, 'avg_acc': 50.08632596685083, 'loss': 6.040983200073242}


EP_train:0:  29%|| 2001/6926 [1:55:28&lt;4:43:45,  3.46s/it]

{'epoch': 0, 'iter': 2000, 'avg_loss': 6.504097387112718, 'avg_acc': 50.08277111444278, 'loss': 6.24128532409668}


EP_train:0:  29%|| 2011/6926 [1:56:03&lt;4:45:20,  3.48s/it]

{'epoch': 0, 'iter': 2010, 'avg_loss': 6.501077034057284, 'avg_acc': 50.083913475882646, 'loss': 5.284446716308594}


EP_train:0:  29%|| 2021/6926 [1:56:38&lt;4:43:23,  3.47s/it]

{'epoch': 0, 'iter': 2020, 'avg_loss': 6.49810962945975, 'avg_acc': 50.07267441860465, 'loss': 5.207293510437012}


EP_train:0:  29%|| 2031/6926 [1:57:12&lt;4:39:20,  3.42s/it]

{'epoch': 0, 'iter': 2030, 'avg_loss': 6.495085201141342, 'avg_acc': 50.0492368291482, 'loss': 5.453665256500244}


EP_train:0:  29%|| 2041/6926 [1:57:47&lt;4:42:35,  3.47s/it]

{'epoch': 0, 'iter': 2040, 'avg_loss': 6.4921762126733835, 'avg_acc': 50.045933365997065, 'loss': 6.171324729919434}


EP_train:0:  30%|| 2051/6926 [1:58:22&lt;4:46:53,  3.53s/it]

{'epoch': 0, 'iter': 2050, 'avg_loss': 6.4887599893920545, 'avg_acc': 50.0365675280351, 'loss': 5.483743667602539}


EP_train:0:  30%|| 2061/6926 [1:58:56&lt;4:40:38,  3.46s/it]

{'epoch': 0, 'iter': 2060, 'avg_loss': 6.484664882981968, 'avg_acc': 50.06823144104804, 'loss': 5.602869033813477}


EP_train:0:  30%|| 2071/6926 [1:59:31&lt;4:39:56,  3.46s/it]

{'epoch': 0, 'iter': 2070, 'avg_loss': 6.482191278300154, 'avg_acc': 50.05733944954128, 'loss': 6.08825159072876}


EP_train:0:  30%|| 2081/6926 [2:00:05&lt;4:38:57,  3.45s/it]

{'epoch': 0, 'iter': 2080, 'avg_loss': 6.479258142257756, 'avg_acc': 50.066074002883234, 'loss': 6.080234050750732}


EP_train:0:  30%|| 2091/6926 [2:00:40&lt;4:36:59,  3.44s/it]

{'epoch': 0, 'iter': 2090, 'avg_loss': 6.47677060874782, 'avg_acc': 50.058285509325685, 'loss': 6.058839321136475}


EP_train:0:  30%|| 2101/6926 [2:01:14&lt;4:34:48,  3.42s/it]

{'epoch': 0, 'iter': 2100, 'avg_loss': 6.473212983368806, 'avg_acc': 50.068419800095185, 'loss': 5.553353309631348}


EP_train:0:  30%|| 2111/6926 [2:01:49&lt;4:39:11,  3.48s/it]

{'epoch': 0, 'iter': 2110, 'avg_loss': 6.470080981939001, 'avg_acc': 50.07549739459971, 'loss': 6.045713901519775}


EP_train:0:  31%|| 2121/6926 [2:02:23&lt;4:37:06,  3.46s/it]

{'epoch': 0, 'iter': 2120, 'avg_loss': 6.467039516769114, 'avg_acc': 50.079561527581326, 'loss': 6.144732475280762}


EP_train:0:  31%|| 2131/6926 [2:02:58&lt;4:35:43,  3.45s/it]

{'epoch': 0, 'iter': 2130, 'avg_loss': 6.464385775767934, 'avg_acc': 50.07625527921164, 'loss': 5.405893802642822}


EP_train:0:  31%|| 2141/6926 [2:03:33&lt;4:33:47,  3.43s/it]

{'epoch': 0, 'iter': 2140, 'avg_loss': 6.461514957816397, 'avg_acc': 50.086116300794025, 'loss': 6.083144187927246}


EP_train:0:  41%|| 2871/6926 [2:45:37&lt;3:52:44,  3.44s/it]

{'epoch': 0, 'iter': 2870, 'avg_loss': 6.30501551480295, 'avg_acc': 50.143678160919535, 'loss': 6.170657634735107}


EP_train:0:  42%|| 2881/6926 [2:46:13&lt;3:55:59,  3.50s/it]

{'epoch': 0, 'iter': 2880, 'avg_loss': 6.303754466724495, 'avg_acc': 50.14209475876432, 'loss': 5.637953758239746}


EP_train:0:  42%|| 2891/6926 [2:46:47&lt;3:53:27,  3.47s/it]

{'epoch': 0, 'iter': 2890, 'avg_loss': 6.302581706454456, 'avg_acc': 50.12971290211, 'loss': 6.26906156539917}


EP_train:0:  42%|| 2901/6926 [2:47:22&lt;3:54:26,  3.49s/it]

{'epoch': 0, 'iter': 2900, 'avg_loss': 6.301098016162282, 'avg_acc': 50.13249741468459, 'loss': 5.8243937492370605}


EP_train:0:  42%|| 2911/6926 [2:47:57&lt;3:51:17,  3.46s/it]

{'epoch': 0, 'iter': 2910, 'avg_loss': 6.29952759531428, 'avg_acc': 50.12667468223978, 'loss': 5.761030197143555}


EP_train:0:  42%|| 2921/6926 [2:48:31&lt;3:49:00,  3.43s/it]

{'epoch': 0, 'iter': 2920, 'avg_loss': 6.298045401130788, 'avg_acc': 50.11875213967819, 'loss': 6.2981743812561035}


EP_train:0:  42%|| 2931/6926 [2:49:06&lt;3:50:01,  3.45s/it]

{'epoch': 0, 'iter': 2930, 'avg_loss': 6.296928513298178, 'avg_acc': 50.12474411463664, 'loss': 5.463428497314453}


EP_train:0:  42%|| 2941/6926 [2:49:40&lt;3:47:51,  3.43s/it]

{'epoch': 0, 'iter': 2940, 'avg_loss': 6.295126533151605, 'avg_acc': 50.113694321659295, 'loss': 5.533849716186523}


EP_train:0:  43%|| 2951/6926 [2:50:15&lt;3:49:19,  3.46s/it]

{'epoch': 0, 'iter': 2950, 'avg_loss': 6.293472126030348, 'avg_acc': 50.101660454083365, 'loss': 5.400457859039307}


EP_train:0:  43%|| 2961/6926 [2:50:49&lt;3:48:26,  3.46s/it]

{'epoch': 0, 'iter': 2960, 'avg_loss': 6.2923729253032645, 'avg_acc': 50.11292637622425, 'loss': 6.580233097076416}


EP_train:0:  43%|| 2971/6926 [2:51:24&lt;3:47:24,  3.45s/it]

{'epoch': 0, 'iter': 2970, 'avg_loss': 6.291031072052269, 'avg_acc': 50.115701783911135, 'loss': 5.922897815704346}


EP_train:0:  43%|| 2981/6926 [2:51:58&lt;3:47:07,  3.45s/it]

{'epoch': 0, 'iter': 2980, 'avg_loss': 6.289031018510196, 'avg_acc': 50.121603488762155, 'loss': 6.050359725952148}


EP_train:0:  43%|| 2991/6926 [2:52:33&lt;3:48:34,  3.49s/it]

{'epoch': 0, 'iter': 2990, 'avg_loss': 6.287773423591851, 'avg_acc': 50.118062520896025, 'loss': 6.4279704093933105}


EP_train:0:  43%|| 3001/6926 [2:53:08&lt;3:45:44,  3.45s/it]

{'epoch': 0, 'iter': 3000, 'avg_loss': 6.286346402020504, 'avg_acc': 50.11037987337554, 'loss': 5.731723785400391}


EP_train:0:  43%|| 3011/6926 [2:53:43&lt;3:47:59,  3.49s/it]

{'epoch': 0, 'iter': 3010, 'avg_loss': 6.284757147909042, 'avg_acc': 50.122467618731314, 'loss': 5.829910755157471}


EP_train:0:  44%|| 3021/6926 [2:54:18&lt;3:45:44,  3.47s/it]

{'epoch': 0, 'iter': 3020, 'avg_loss': 6.282995776126259, 'avg_acc': 50.13137206223105, 'loss': 5.287047386169434}


EP_train:0:  44%|| 3031/6926 [2:54:52&lt;3:46:00,  3.48s/it]

{'epoch': 0, 'iter': 3030, 'avg_loss': 6.281364510610763, 'avg_acc': 50.122690531177824, 'loss': 5.5934367179870605}


EP_train:0:  44%|| 3041/6926 [2:55:27&lt;3:44:25,  3.47s/it]

{'epoch': 0, 'iter': 3040, 'avg_loss': 6.279620425084122, 'avg_acc': 50.10790036172311, 'loss': 5.831112861633301}


EP_train:0:  44%|| 3051/6926 [2:56:01&lt;3:41:25,  3.43s/it]

{'epoch': 0, 'iter': 3050, 'avg_loss': 6.278026736161624, 'avg_acc': 50.11266797771222, 'loss': 5.961607933044434}


EP_train:0:  44%|| 3061/6926 [2:56:36&lt;3:41:55,  3.45s/it]

{'epoch': 0, 'iter': 3060, 'avg_loss': 6.276269334159385, 'avg_acc': 50.12046716759229, 'loss': 5.718508720397949}


EP_train:0:  44%|| 3071/6926 [2:57:10&lt;3:40:21,  3.43s/it]

{'epoch': 0, 'iter': 3070, 'avg_loss': 6.274964790629937, 'avg_acc': 50.117022142624556, 'loss': 5.907179355621338}


EP_train:0:  44%|| 3081/6926 [2:57:45&lt;3:45:56,  3.53s/it]

{'epoch': 0, 'iter': 3080, 'avg_loss': 6.273098578046027, 'avg_acc': 50.12272801038624, 'loss': 5.667904376983643}


EP_train:0:  45%|| 3091/6926 [2:58:20&lt;3:43:04,  3.49s/it]

{'epoch': 0, 'iter': 3090, 'avg_loss': 6.271562425884295, 'avg_acc': 50.11424296344226, 'loss': 5.675585746765137}


EP_train:0:  45%|| 3101/6926 [2:58:55&lt;3:40:41,  3.46s/it]

{'epoch': 0, 'iter': 3100, 'avg_loss': 6.269683937379061, 'avg_acc': 50.12193647210578, 'loss': 6.055880069732666}


EP_train:0:  45%|| 3111/6926 [2:59:30&lt;3:40:51,  3.47s/it]

{'epoch': 0, 'iter': 3110, 'avg_loss': 6.268129614226422, 'avg_acc': 50.12455801992929, 'loss': 5.9486918449401855}


EP_train:0:  45%|| 3121/6926 [3:00:04&lt;3:39:49,  3.47s/it]

{'epoch': 0, 'iter': 3120, 'avg_loss': 6.266449210048677, 'avg_acc': 50.11815123357898, 'loss': 6.4969987869262695}


EP_train:0:  45%|| 3131/6926 [3:00:39&lt;3:40:10,  3.48s/it]

{'epoch': 0, 'iter': 3130, 'avg_loss': 6.264453706860124, 'avg_acc': 50.1287527946343, 'loss': 5.43622350692749}


EP_train:0:  45%|| 3141/6926 [3:01:14&lt;3:38:18,  3.46s/it]

{'epoch': 0, 'iter': 3140, 'avg_loss': 6.26304022956904, 'avg_acc': 50.13033269659344, 'loss': 5.587998390197754}


EP_train:0:  45%|| 3151/6926 [3:01:48&lt;3:37:03,  3.45s/it]

{'epoch': 0, 'iter': 3150, 'avg_loss': 6.2617480554341585, 'avg_acc': 50.13289431926372, 'loss': 6.050402641296387}


EP_train:0:  46%|| 3161/6926 [3:02:23&lt;3:34:28,  3.42s/it]

{'epoch': 0, 'iter': 3160, 'avg_loss': 6.260293862820426, 'avg_acc': 50.12654223347042, 'loss': 5.674601078033447}


EP_train:0:  46%|| 3171/6926 [3:02:58&lt;3:36:37,  3.46s/it]

{'epoch': 0, 'iter': 3170, 'avg_loss': 6.258769833676937, 'avg_acc': 50.13599810785241, 'loss': 5.690023899078369}


EP_train:0:  46%|| 3181/6926 [3:03:32&lt;3:38:46,  3.50s/it]

{'epoch': 0, 'iter': 3180, 'avg_loss': 6.257336515182596, 'avg_acc': 50.141464948129524, 'loss': 6.035431861877441}


EP_train:0:  46%|| 3191/6926 [3:04:07&lt;3:36:37,  3.48s/it]

{'epoch': 0, 'iter': 3190, 'avg_loss': 6.255578008052213, 'avg_acc': 50.140042306487, 'loss': 6.241879940032959}


EP_train:0:  46%|| 3201/6926 [3:04:42&lt;3:32:27,  3.42s/it]

{'epoch': 0, 'iter': 3200, 'avg_loss': 6.254713234697346, 'avg_acc': 50.131794751640115, 'loss': 5.585864067077637}


EP_train:0:  46%|| 3211/6926 [3:05:16&lt;3:33:26,  3.45s/it]

{'epoch': 0, 'iter': 3210, 'avg_loss': 6.253378930473506, 'avg_acc': 50.13138430395515, 'loss': 5.481635570526123}


EP_train:0:  47%|| 3221/6926 [3:05:50&lt;3:31:02,  3.42s/it]

{'epoch': 0, 'iter': 3220, 'avg_loss': 6.25171201090678, 'avg_acc': 50.1397081651661, 'loss': 5.6242523193359375}


EP_train:0:  47%|| 3231/6926 [3:06:25&lt;3:31:05,  3.43s/it]

{'epoch': 0, 'iter': 3230, 'avg_loss': 6.250507676317315, 'avg_acc': 50.125735066542866, 'loss': 5.807900428771973}


EP_train:0:  47%|| 3241/6926 [3:07:00&lt;3:32:40,  3.46s/it]

{'epoch': 0, 'iter': 3240, 'avg_loss': 6.248571161354298, 'avg_acc': 50.121490280777536, 'loss': 6.13726806640625}


EP_train:0:  47%|| 3251/6926 [3:07:34&lt;3:30:37,  3.44s/it]

{'epoch': 0, 'iter': 3250, 'avg_loss': 6.247323126691703, 'avg_acc': 50.10285296831745, 'loss': 6.156318187713623}


EP_train:0:  47%|| 3261/6926 [3:08:09&lt;3:30:17,  3.44s/it]

{'epoch': 0, 'iter': 3260, 'avg_loss': 6.245429852885434, 'avg_acc': 50.10732904017172, 'loss': 5.416029930114746}


EP_train:0:  47%|| 3271/6926 [3:08:44&lt;3:30:44,  3.46s/it]

{'epoch': 0, 'iter': 3270, 'avg_loss': 6.244244876238812, 'avg_acc': 50.108911647814125, 'loss': 6.065566062927246}


EP_train:0:  47%|| 3281/6926 [3:09:18&lt;3:29:30,  3.45s/it]

{'epoch': 0, 'iter': 3280, 'avg_loss': 6.242680059123134, 'avg_acc': 50.106674794270035, 'loss': 5.227103233337402}


EP_train:0:  48%|| 3291/6926 [3:09:53&lt;3:28:19,  3.44s/it]

{'epoch': 0, 'iter': 3290, 'avg_loss': 6.241573854624337, 'avg_acc': 50.10445153448799, 'loss': 6.120715618133545}


EP_train:0:  48%|| 3301/6926 [3:10:27&lt;3:28:53,  3.46s/it]

{'epoch': 0, 'iter': 3300, 'avg_loss': 6.240098802438832, 'avg_acc': 50.11360193880642, 'loss': 5.652524948120117}


EP_train:0:  48%|| 3311/6926 [3:11:02&lt;3:28:46,  3.47s/it]

{'epoch': 0, 'iter': 3310, 'avg_loss': 6.23900456429968, 'avg_acc': 50.110427363334345, 'loss': 5.927626132965088}


EP_train:0:  48%|| 3321/6926 [3:11:36&lt;3:25:19,  3.42s/it]

{'epoch': 0, 'iter': 3320, 'avg_loss': 6.237606107309187, 'avg_acc': 50.11385877747666, 'loss': 5.536543846130371}


EP_train:0:  48%|| 3331/6926 [3:12:11&lt;3:28:12,  3.47s/it]

{'epoch': 0, 'iter': 3330, 'avg_loss': 6.23606965564028, 'avg_acc': 50.116331432002404, 'loss': 6.248320579528809}


EP_train:0:  48%|| 3341/6926 [3:12:46&lt;3:28:05,  3.48s/it]

{'epoch': 0, 'iter': 3340, 'avg_loss': 6.234930654586842, 'avg_acc': 50.11691858724932, 'loss': 5.643083572387695}


EP_train:0:  48%|| 3351/6926 [3:13:20&lt;3:26:52,  3.47s/it]

{'epoch': 0, 'iter': 3350, 'avg_loss': 6.23354035183694, 'avg_acc': 50.11750223813787, 'loss': 6.102465629577637}


EP_train:0:  49%|| 3361/6926 [3:13:55&lt;3:24:27,  3.44s/it]

{'epoch': 0, 'iter': 3360, 'avg_loss': 6.232676638694294, 'avg_acc': 50.109714370723005, 'loss': 5.754641056060791}


EP_train:0:  49%|| 3371/6926 [3:14:30&lt;3:23:22,  3.43s/it]

{'epoch': 0, 'iter': 3370, 'avg_loss': 6.231407767267264, 'avg_acc': 50.09919163452982, 'loss': 6.043362140655518}


EP_train:0:  49%|| 3381/6926 [3:15:05&lt;3:25:20,  3.48s/it]

{'epoch': 0, 'iter': 3380, 'avg_loss': 6.23005606654973, 'avg_acc': 50.09612540668441, 'loss': 5.88515567779541}


EP_train:0:  49%|| 3391/6926 [3:15:40&lt;3:23:18,  3.45s/it]

{'epoch': 0, 'iter': 3390, 'avg_loss': 6.228594171652855, 'avg_acc': 50.104135948097905, 'loss': 5.32595682144165}


EP_train:0:  49%|| 3401/6926 [3:16:14&lt;3:22:35,  3.45s/it]

{'epoch': 0, 'iter': 3400, 'avg_loss': 6.226963288852026, 'avg_acc': 50.10566745074978, 'loss': 6.132233142852783}


EP_train:0:  49%|| 3411/6926 [3:16:49&lt;3:24:39,  3.49s/it]

{'epoch': 0, 'iter': 3410, 'avg_loss': 6.225550739201099, 'avg_acc': 50.08886690120199, 'loss': 5.387300968170166}


EP_train:0:  49%|| 3421/6926 [3:17:23&lt;3:21:58,  3.46s/it]

{'epoch': 0, 'iter': 3420, 'avg_loss': 6.224329726105718, 'avg_acc': 50.083126278865834, 'loss': 5.836758136749268}


EP_train:0:  50%|| 3431/6926 [3:17:58&lt;3:22:44,  3.48s/it]

{'epoch': 0, 'iter': 3430, 'avg_loss': 6.22317759673125, 'avg_acc': 50.08197318566015, 'loss': 5.096984386444092}


EP_train:0:  50%|| 3441/6926 [3:18:33&lt;3:19:53,  3.44s/it]

{'epoch': 0, 'iter': 3440, 'avg_loss': 6.222500560797082, 'avg_acc': 50.08264312699796, 'loss': 5.920487880706787}


EP_train:0:  50%|| 3451/6926 [3:19:08&lt;3:21:19,  3.48s/it]

{'epoch': 0, 'iter': 3450, 'avg_loss': 6.221058753496389, 'avg_acc': 50.08783685888149, 'loss': 5.709464073181152}


EP_train:0:  50%|| 3461/6926 [3:19:43&lt;3:19:30,  3.45s/it]

{'epoch': 0, 'iter': 3460, 'avg_loss': 6.219895183609524, 'avg_acc': 50.09480641433112, 'loss': 5.588047504425049}


EP_train:0:  50%|| 3471/6926 [3:20:18&lt;3:21:18,  3.50s/it]

{'epoch': 0, 'iter': 3470, 'avg_loss': 6.2184577888042565, 'avg_acc': 50.101735811005476, 'loss': 5.708352565765381}


EP_train:0:  50%|| 3481/6926 [3:20:53&lt;3:20:55,  3.50s/it]

{'epoch': 0, 'iter': 3480, 'avg_loss': 6.217134620087888, 'avg_acc': 50.10144355070382, 'loss': 5.452094554901123}


EP_train:0:  50%|| 3491/6926 [3:21:27&lt;3:17:30,  3.45s/it]

{'epoch': 0, 'iter': 3490, 'avg_loss': 6.216033760984318, 'avg_acc': 50.11189487252936, 'loss': 5.774087429046631}


EP_train:0:  51%|| 3501/6926 [3:22:02&lt;3:17:42,  3.46s/it]

{'epoch': 0, 'iter': 3500, 'avg_loss': 6.214568872514435, 'avg_acc': 50.11514567266495, 'loss': 5.287735462188721}


EP_train:0:  51%|| 3511/6926 [3:22:36&lt;3:16:18,  3.45s/it]

{'epoch': 0, 'iter': 3510, 'avg_loss': 6.2134798007010055, 'avg_acc': 50.11570777556251, 'loss': 6.348851680755615}


EP_train:0:  51%|| 3521/6926 [3:23:11&lt;3:16:45,  3.47s/it]

{'epoch': 0, 'iter': 3520, 'avg_loss': 6.21255720721426, 'avg_acc': 50.10916642999148, 'loss': 6.2176971435546875}


EP_train:0:  51%|| 3531/6926 [3:23:45&lt;3:15:46,  3.46s/it]

{'epoch': 0, 'iter': 3530, 'avg_loss': 6.212049034829519, 'avg_acc': 50.10974228263948, 'loss': 5.880690574645996}


EP_train:0:  51%|| 3541/6926 [3:24:20&lt;3:15:22,  3.46s/it]

{'epoch': 0, 'iter': 3540, 'avg_loss': 6.211238995880368, 'avg_acc': 50.10413724936459, 'loss': 5.573653221130371}


EP_train:0:  51%|| 3551/6926 [3:24:55&lt;3:15:41,  3.48s/it]

{'epoch': 0, 'iter': 3550, 'avg_loss': 6.209664390846495, 'avg_acc': 50.095923683469444, 'loss': 5.674375057220459}


EP_train:0:  51%|| 3561/6926 [3:25:29&lt;3:13:05,  3.44s/it]

{'epoch': 0, 'iter': 3560, 'avg_loss': 6.208728829383582, 'avg_acc': 50.099164560516705, 'loss': 5.379258632659912}


EP_train:0:  52%|| 3571/6926 [3:26:04&lt;3:13:15,  3.46s/it]

{'epoch': 0, 'iter': 3570, 'avg_loss': 6.207470196029846, 'avg_acc': 50.086635396247544, 'loss': 5.845820903778076}


EP_train:0:  52%|| 3581/6926 [3:26:38&lt;3:12:16,  3.45s/it]

{'epoch': 0, 'iter': 3580, 'avg_loss': 6.206407408380069, 'avg_acc': 50.09337475565484, 'loss': 5.866831302642822}


EP_train:0:  52%|| 3591/6926 [3:27:13&lt;3:11:23,  3.44s/it]

{'epoch': 0, 'iter': 3590, 'avg_loss': 6.205047326843508, 'avg_acc': 50.09224450013924, 'loss': 5.758725166320801}


EP_train:0:  52%|| 3601/6926 [3:27:48&lt;3:12:51,  3.48s/it]

{'epoch': 0, 'iter': 3600, 'avg_loss': 6.204162875866433, 'avg_acc': 50.098063038044984, 'loss': 6.484498500823975}


EP_train:0:  52%|| 3611/6926 [3:28:23&lt;3:12:40,  3.49s/it]

{'epoch': 0, 'iter': 3610, 'avg_loss': 6.203004776028443, 'avg_acc': 50.09000276931598, 'loss': 6.100214004516602}


EP_train:0:  52%|| 3621/6926 [3:28:58&lt;3:12:27,  3.49s/it]

{'epoch': 0, 'iter': 3620, 'avg_loss': 6.201920005242096, 'avg_acc': 50.08716514774923, 'loss': 5.938502311706543}


EP_train:0:  52%|| 3631/6926 [3:29:32&lt;3:11:30,  3.49s/it]

{'epoch': 0, 'iter': 3630, 'avg_loss': 6.200789731844369, 'avg_acc': 50.07659735610025, 'loss': 5.771533489227295}


EP_train:0:  53%|| 3641/6926 [3:30:07&lt;3:09:35,  3.46s/it]

{'epoch': 0, 'iter': 3640, 'avg_loss': 6.199535256327917, 'avg_acc': 50.0781035429827, 'loss': 5.855103492736816}


EP_train:0:  53%|| 3651/6926 [3:30:42&lt;3:08:25,  3.45s/it]

{'epoch': 0, 'iter': 3650, 'avg_loss': 6.198270769257704, 'avg_acc': 50.06676253081348, 'loss': 5.2879838943481445}


EP_train:0:  53%|| 3661/6926 [3:31:17&lt;3:08:31,  3.46s/it]

{'epoch': 0, 'iter': 3660, 'avg_loss': 6.196909987968814, 'avg_acc': 50.07084812892653, 'loss': 5.845424652099609}


EP_train:0:  53%|| 3671/6926 [3:31:52&lt;3:10:26,  3.51s/it]

{'epoch': 0, 'iter': 3670, 'avg_loss': 6.195943700036507, 'avg_acc': 50.07065513484065, 'loss': 5.753200531005859}


EP_train:0:  53%|| 3681/6926 [3:32:26&lt;3:09:28,  3.50s/it]

{'epoch': 0, 'iter': 3680, 'avg_loss': 6.194556915704986, 'avg_acc': 50.06791632708503, 'loss': 5.695070743560791}


EP_train:0:  53%|| 3691/6926 [3:33:01&lt;3:07:07,  3.47s/it]

{'epoch': 0, 'iter': 3690, 'avg_loss': 6.193383834123676, 'avg_acc': 50.071965591980494, 'loss': 5.697078704833984}


EP_train:0:  53%|| 3701/6926 [3:33:36&lt;3:06:18,  3.47s/it]

{'epoch': 0, 'iter': 3700, 'avg_loss': 6.192638800228586, 'avg_acc': 50.075148608484184, 'loss': 6.033320903778076}


EP_train:0:  54%|| 3711/6926 [3:34:11&lt;3:07:59,  3.51s/it]

{'epoch': 0, 'iter': 3710, 'avg_loss': 6.191417550565226, 'avg_acc': 50.077472379412555, 'loss': 5.891236305236816}


EP_train:0:  54%|| 3721/6926 [3:34:46&lt;3:08:51,  3.54s/it]

{'epoch': 0, 'iter': 3720, 'avg_loss': 6.190265684991522, 'avg_acc': 50.06298710024188, 'loss': 5.223845958709717}


EP_train:0:  54%|| 3731/6926 [3:35:21&lt;3:07:19,  3.52s/it]

{'epoch': 0, 'iter': 3730, 'avg_loss': 6.189020359685484, 'avg_acc': 50.06030554811043, 'loss': 5.904521465301514}


EP_train:0:  54%|| 3741/6926 [3:35:56&lt;3:04:07,  3.47s/it]

{'epoch': 0, 'iter': 3740, 'avg_loss': 6.187715866896469, 'avg_acc': 50.05095562683775, 'loss': 5.292939186096191}


EP_train:0:  54%|| 3751/6926 [3:36:31&lt;3:06:14,  3.52s/it]

{'epoch': 0, 'iter': 3750, 'avg_loss': 6.186928363394273, 'avg_acc': 50.05165289256198, 'loss': 6.4447832107543945}


EP_train:0:  54%|| 3761/6926 [3:37:06&lt;3:05:05,  3.51s/it]

{'epoch': 0, 'iter': 3760, 'avg_loss': 6.185825161273351, 'avg_acc': 50.04819197022069, 'loss': 5.809656620025635}


EP_train:0:  54%|| 3771/6926 [3:37:41&lt;3:04:04,  3.50s/it]

{'epoch': 0, 'iter': 3770, 'avg_loss': 6.184727871711992, 'avg_acc': 50.05137894457704, 'loss': 5.74653434753418}


EP_train:0:  55%|| 3781/6926 [3:38:17&lt;3:09:17,  3.61s/it]

{'epoch': 0, 'iter': 3780, 'avg_loss': 6.1832064308523655, 'avg_acc': 50.04959005554086, 'loss': 5.981086254119873}


EP_train:0:  55%|| 3791/6926 [3:38:53&lt;3:06:29,  3.57s/it]

{'epoch': 0, 'iter': 3790, 'avg_loss': 6.182036062244123, 'avg_acc': 50.052756528620414, 'loss': 5.522501468658447}


EP_train:0:  55%|| 3801/6926 [3:39:29&lt;3:06:51,  3.59s/it]

{'epoch': 0, 'iter': 3800, 'avg_loss': 6.180774577069803, 'avg_acc': 50.056728492501975, 'loss': 5.973437786102295}


EP_train:0:  55%|| 3811/6926 [3:40:05&lt;3:09:11,  3.64s/it]

{'epoch': 0, 'iter': 3810, 'avg_loss': 6.179361567601104, 'avg_acc': 50.064779585410655, 'loss': 6.320959568023682}


EP_train:0:  55%|| 3821/6926 [3:40:42&lt;3:06:18,  3.60s/it]

{'epoch': 0, 'iter': 3820, 'avg_loss': 6.1784018083755585, 'avg_acc': 50.0711528395708, 'loss': 5.407601356506348}


EP_train:0:  55%|| 3831/6926 [3:41:19&lt;3:12:49,  3.74s/it]

{'epoch': 0, 'iter': 3830, 'avg_loss': 6.1772821021123585, 'avg_acc': 50.0693356825894, 'loss': 6.021275043487549}


EP_train:0:  55%|| 3841/6926 [3:41:57&lt;3:17:26,  3.84s/it]

{'epoch': 0, 'iter': 3840, 'avg_loss': 6.176352686138396, 'avg_acc': 50.0561377245509, 'loss': 5.442045211791992}


EP_train:0:  56%|| 3851/6926 [3:42:35&lt;3:14:48,  3.80s/it]

{'epoch': 0, 'iter': 3850, 'avg_loss': 6.175828560765023, 'avg_acc': 50.05355751752791, 'loss': 5.861415386199951}


EP_train:0:  56%|| 3861/6926 [3:43:13&lt;3:12:28,  3.77s/it]

{'epoch': 0, 'iter': 3860, 'avg_loss': 6.174891271420755, 'avg_acc': 50.03965941465941, 'loss': 5.797309875488281}


EP_train:0:  56%|| 3871/6926 [3:43:52&lt;3:23:00,  3.99s/it]

{'epoch': 0, 'iter': 3870, 'avg_loss': 6.174061799474355, 'avg_acc': 50.04036424696461, 'loss': 5.4632720947265625}


EP_train:0:  56%|| 3881/6926 [3:44:33&lt;3:31:56,  4.18s/it]

{'epoch': 0, 'iter': 3880, 'avg_loss': 6.172991682223148, 'avg_acc': 50.03703942282917, 'loss': 6.058238506317139}


EP_train:0:  56%|| 3891/6926 [3:45:14&lt;3:25:46,  4.07s/it]

{'epoch': 0, 'iter': 3890, 'avg_loss': 6.1719814577252174, 'avg_acc': 50.028912875867384, 'loss': 6.011285305023193}


EP_train:0:  56%|| 3901/6926 [3:45:56&lt;3:37:35,  4.32s/it]

{'epoch': 0, 'iter': 3900, 'avg_loss': 6.170856231727591, 'avg_acc': 50.02483337605742, 'loss': 5.179987907409668}


EP_train:0:  56%|| 3911/6926 [3:46:41&lt;3:45:07,  4.48s/it]

{'epoch': 0, 'iter': 3910, 'avg_loss': 6.169618224097896, 'avg_acc': 50.02556890820762, 'loss': 5.848067283630371}


EP_train:0:  57%|| 3921/6926 [3:47:25&lt;3:42:56,  4.45s/it]

{'epoch': 0, 'iter': 3920, 'avg_loss': 6.168895365844664, 'avg_acc': 50.018330782963524, 'loss': 5.656007766723633}


EP_train:0:  57%|| 3931/6926 [3:48:12&lt;3:52:49,  4.66s/it]

{'epoch': 0, 'iter': 3930, 'avg_loss': 6.167847494107414, 'avg_acc': 50.025438819638765, 'loss': 6.014158248901367}


EP_train:0:  57%|| 3941/6926 [3:48:59&lt;3:55:27,  4.73s/it]

{'epoch': 0, 'iter': 3940, 'avg_loss': 6.166905548934917, 'avg_acc': 50.016651865008875, 'loss': 5.993920803070068}


EP_train:0:  57%|| 3951/6926 [3:49:49&lt;4:15:00,  5.14s/it]

{'epoch': 0, 'iter': 3950, 'avg_loss': 6.165852081078694, 'avg_acc': 50.00237281700836, 'loss': 5.804994583129883}


EP_train:0:  57%|| 3961/6926 [3:50:41&lt;4:22:36,  5.31s/it]

{'epoch': 0, 'iter': 3960, 'avg_loss': 6.164667328028208, 'avg_acc': 50.00157788437263, 'loss': 5.279772758483887}


EP_train:0:  57%|| 3971/6926 [3:51:34&lt;4:23:10,  5.34s/it]

{'epoch': 0, 'iter': 3970, 'avg_loss': 6.163366601617833, 'avg_acc': 50.00944346512214, 'loss': 5.7298736572265625}


EP_train:0:  57%|| 3981/6926 [3:52:29&lt;4:27:33,  5.45s/it]

{'epoch': 0, 'iter': 3980, 'avg_loss': 6.162418046509073, 'avg_acc': 50.00549485054007, 'loss': 5.988441467285156}


EP_train:0:  58%|| 3991/6926 [3:53:27&lt;4:50:22,  5.94s/it]

{'epoch': 0, 'iter': 3990, 'avg_loss': 6.161358871068073, 'avg_acc': 50.007830117764975, 'loss': 5.854517936706543}


EP_train:0:  58%|| 4001/6926 [3:54:24&lt;4:42:07,  5.79s/it]

{'epoch': 0, 'iter': 4000, 'avg_loss': 6.160307237905909, 'avg_acc': 50.007810547363164, 'loss': 5.7460832595825195}


EP_train:0:  58%|| 4011/6926 [3:55:26&lt;5:18:21,  6.55s/it]

{'epoch': 0, 'iter': 4010, 'avg_loss': 6.159289666049589, 'avg_acc': 50.0, 'loss': 5.876718044281006}


EP_train:0:  58%|| 4021/6926 [3:56:29&lt;5:02:01,  6.24s/it]

{'epoch': 0, 'iter': 4020, 'avg_loss': 6.158182346473965, 'avg_acc': 50.00466301914946, 'loss': 5.27029275894165}


EP_train:0:  58%|| 4031/6926 [3:57:34&lt;5:20:27,  6.64s/it]

{'epoch': 0, 'iter': 4030, 'avg_loss': 6.15733044462741, 'avg_acc': 50.01162862813197, 'loss': 5.8875732421875}


EP_train:0:  58%|| 4041/6926 [3:58:39&lt;5:16:20,  6.58s/it]

{'epoch': 0, 'iter': 4040, 'avg_loss': 6.1566401381092595, 'avg_acc': 50.02242637960901, 'loss': 5.774832725524902}


EP_train:0:  58%|| 4051/6926 [3:59:46&lt;5:20:28,  6.69s/it]

{'epoch': 0, 'iter': 4050, 'avg_loss': 6.155588622741774, 'avg_acc': 50.035485065415955, 'loss': 6.138017177581787}


EP_train:0:  59%|| 4061/6926 [4:00:55&lt;5:34:05,  7.00s/it]

{'epoch': 0, 'iter': 4060, 'avg_loss': 6.154778440372605, 'avg_acc': 50.032319625707956, 'loss': 5.674389362335205}


EP_train:0:  59%|| 4071/6926 [4:02:08&lt;5:44:06,  7.23s/it]

{'epoch': 0, 'iter': 4070, 'avg_loss': 6.153988276322097, 'avg_acc': 50.02609923851633, 'loss': 5.415286064147949}


EP_train:0:  59%|| 4081/6926 [4:03:24&lt;5:55:47,  7.50s/it]

{'epoch': 0, 'iter': 4080, 'avg_loss': 6.153260077719769, 'avg_acc': 50.01454913011517, 'loss': 5.970011234283447}


EP_train:0:  59%|| 4091/6926 [4:04:36&lt;5:45:08,  7.30s/it]

{'epoch': 0, 'iter': 4090, 'avg_loss': 6.152195111197558, 'avg_acc': 50.013749694451235, 'loss': 5.845784664154053}


EP_train:0:  59%|| 4101/6926 [4:05:53&lt;6:02:36,  7.70s/it]

{'epoch': 0, 'iter': 4100, 'avg_loss': 6.151107918544677, 'avg_acc': 50.023622287247015, 'loss': 5.969123363494873}


EP_train:0:  59%|| 4111/6926 [4:07:07&lt;5:53:23,  7.53s/it]

{'epoch': 0, 'iter': 4110, 'avg_loss': 6.149992354273999, 'avg_acc': 50.02204451471661, 'loss': 5.289840221405029}


EP_train:0:  60%|| 4121/6926 [4:08:27&lt;6:13:04,  7.98s/it]

{'epoch': 0, 'iter': 4120, 'avg_loss': 6.148857050166492, 'avg_acc': 50.03109075467119, 'loss': 5.793868541717529}


EP_train:0:  60%|| 4131/6926 [4:09:44&lt;6:00:25,  7.74s/it]

{'epoch': 0, 'iter': 4130, 'avg_loss': 6.1480596452785505, 'avg_acc': 50.03631082062454, 'loss': 5.535717010498047}


EP_train:0:  60%|| 4141/6926 [4:11:07&lt;6:19:39,  8.18s/it]

{'epoch': 0, 'iter': 4140, 'avg_loss': 6.147115438751943, 'avg_acc': 50.02943129678822, 'loss': 5.722696304321289}


EP_train:0:  60%|| 4151/6926 [4:12:24&lt;5:52:41,  7.63s/it]

{'epoch': 0, 'iter': 4150, 'avg_loss': 6.146216990085603, 'avg_acc': 50.02484341122621, 'loss': 5.767571449279785}


EP_train:0:  60%|| 4161/6926 [4:13:46&lt;6:18:56,  8.22s/it]

{'epoch': 0, 'iter': 4160, 'avg_loss': 6.145457845443546, 'avg_acc': 50.03304494111992, 'loss': 5.451801300048828}


EP_train:0:  60%|| 4171/6926 [4:15:07&lt;6:13:32,  8.14s/it]

{'epoch': 0, 'iter': 4170, 'avg_loss': 6.14477330882096, 'avg_acc': 50.03521337808679, 'loss': 5.747236251831055}


EP_train:0:  60%|| 4181/6926 [4:16:33&lt;6:16:33,  8.23s/it]

{'epoch': 0, 'iter': 4180, 'avg_loss': 6.143900096202632, 'avg_acc': 50.036624013393926, 'loss': 5.488006591796875}


EP_train:0:  61%|| 4191/6926 [4:17:56&lt;6:14:32,  8.22s/it]

{'epoch': 0, 'iter': 4190, 'avg_loss': 6.142865265277598, 'avg_acc': 50.03802791696492, 'loss': 5.668560981750488}


EP_train:0:  61%|| 4201/6926 [4:19:20&lt;6:25:45,  8.49s/it]

{'epoch': 0, 'iter': 4200, 'avg_loss': 6.1420037670948195, 'avg_acc': 50.026779338252794, 'loss': 5.94446325302124}


EP_train:0:  61%|| 4211/6926 [4:20:46&lt;6:26:24,  8.54s/it]

{'epoch': 0, 'iter': 4210, 'avg_loss': 6.141215065204454, 'avg_acc': 50.02226312039896, 'loss': 5.621335506439209}


EP_train:0:  61%|| 4221/6926 [4:22:11&lt;6:23:34,  8.51s/it]

{'epoch': 0, 'iter': 4220, 'avg_loss': 6.140289033371475, 'avg_acc': 50.01406657190239, 'loss': 5.930065631866455}


EP_train:0:  61%|| 4231/6926 [4:23:40&lt;6:42:31,  8.96s/it]

{'epoch': 0, 'iter': 4230, 'avg_loss': 6.139495749080246, 'avg_acc': 50.02068069014417, 'loss': 6.0438127517700195}


EP_train:0:  61%|| 4241/6926 [4:25:07&lt;6:25:31,  8.62s/it]

{'epoch': 0, 'iter': 4240, 'avg_loss': 6.138515166926007, 'avg_acc': 50.01252652676256, 'loss': 6.2702460289001465}


EP_train:0:  61%|| 4251/6926 [4:26:37&lt;6:36:09,  8.89s/it]

{'epoch': 0, 'iter': 4250, 'avg_loss': 6.137436031538075, 'avg_acc': 50.02131851329099, 'loss': 5.432215690612793}


EP_train:0:  62%|| 4261/6926 [4:28:08&lt;6:50:01,  9.23s/it]

{'epoch': 0, 'iter': 4260, 'avg_loss': 6.136874010461621, 'avg_acc': 50.023468669326455, 'loss': 5.911162376403809}


EP_train:0:  62%|| 4271/6926 [4:29:40&lt;6:59:10,  9.47s/it]

{'epoch': 0, 'iter': 4270, 'avg_loss': 6.13604357348089, 'avg_acc': 50.02048700538515, 'loss': 5.512773036956787}


EP_train:0:  62%|| 4281/6926 [4:31:09&lt;6:40:25,  9.08s/it]

{'epoch': 0, 'iter': 4280, 'avg_loss': 6.135322889249142, 'avg_acc': 50.01459939266526, 'loss': 5.481927871704102}


EP_train:0:  62%|| 4291/6926 [4:32:35&lt;6:29:58,  8.88s/it]

{'epoch': 0, 'iter': 4290, 'avg_loss': 6.134688405383859, 'avg_acc': 50.023304591004425, 'loss': 5.839148044586182}


EP_train:0:  62%|| 4301/6926 [4:34:03&lt;6:17:36,  8.63s/it]

{'epoch': 0, 'iter': 4300, 'avg_loss': 6.133672989404249, 'avg_acc': 50.01307835387119, 'loss': 5.7530717849731445}


EP_train:0:  62%|| 4311/6926 [4:35:32&lt;6:29:21,  8.93s/it]

{'epoch': 0, 'iter': 4310, 'avg_loss': 6.133218464954246, 'avg_acc': 50.0152226861517, 'loss': 6.094731330871582}


EP_train:0:  62%|| 4321/6926 [4:37:04&lt;6:54:45,  9.55s/it]

{'epoch': 0, 'iter': 4320, 'avg_loss': 6.132279896730627, 'avg_acc': 50.02314279102059, 'loss': 5.431138038635254}


EP_train:0:  63%|| 4331/6926 [4:38:31&lt;6:33:19,  9.09s/it]

{'epoch': 0, 'iter': 4330, 'avg_loss': 6.131346632222661, 'avg_acc': 50.04112791503117, 'loss': 5.826376914978027}


EP_train:0:  63%|| 4341/6926 [4:40:00&lt;6:34:02,  9.15s/it]

{'epoch': 0, 'iter': 4340, 'avg_loss': 6.130246740858337, 'avg_acc': 50.04247293250403, 'loss': 5.552226543426514}


EP_train:0:  63%|| 4351/6926 [4:41:29&lt;6:26:04,  9.00s/it]

{'epoch': 0, 'iter': 4350, 'avg_loss': 6.129379989305766, 'avg_acc': 50.0423753160193, 'loss': 5.709573745727539}


EP_train:0:  63%|| 4361/6926 [4:42:56&lt;6:18:54,  8.86s/it]

{'epoch': 0, 'iter': 4360, 'avg_loss': 6.128431880454956, 'avg_acc': 50.03654551708324, 'loss': 5.882369041442871}


EP_train:0:  63%|| 4371/6926 [4:44:20&lt;6:04:57,  8.57s/it]

{'epoch': 0, 'iter': 4370, 'avg_loss': 6.127559314082837, 'avg_acc': 50.03932166552276, 'loss': 5.3647308349609375}


EP_train:0:  63%|| 4381/6926 [4:45:44&lt;5:52:51,  8.32s/it]

{'epoch': 0, 'iter': 4380, 'avg_loss': 6.126560695093534, 'avg_acc': 50.02781899109793, 'loss': 5.55737829208374}


EP_train:0:  63%|| 4391/6926 [4:47:11&lt;6:10:30,  8.77s/it]

{'epoch': 0, 'iter': 4390, 'avg_loss': 6.125727731148276, 'avg_acc': 50.02775563652927, 'loss': 5.657538890838623}


EP_train:0:  64%|| 4401/6926 [4:48:37&lt;6:02:49,  8.62s/it]

{'epoch': 0, 'iter': 4400, 'avg_loss': 6.1247635921330055, 'avg_acc': 50.018461713246985, 'loss': 5.667081832885742}


EP_train:0:  64%|| 4411/6926 [4:50:03&lt;6:07:42,  8.77s/it]

{'epoch': 0, 'iter': 4410, 'avg_loss': 6.123572657206139, 'avg_acc': 50.0184198594423, 'loss': 5.8721442222595215}


EP_train:0:  64%|| 4421/6926 [4:51:33&lt;6:21:36,  9.14s/it]

{'epoch': 0, 'iter': 4420, 'avg_loss': 6.123023362214736, 'avg_acc': 50.02261931689663, 'loss': 5.535576820373535}


EP_train:0:  64%|| 4431/6926 [4:53:00&lt;6:02:01,  8.71s/it]

{'epoch': 0, 'iter': 4430, 'avg_loss': 6.122202802635267, 'avg_acc': 50.03244188670729, 'loss': 5.904573440551758}


EP_train:0:  64%|| 4441/6926 [4:54:28&lt;6:11:12,  8.96s/it]

{'epoch': 0, 'iter': 4440, 'avg_loss': 6.120835080390523, 'avg_acc': 50.03166516550327, 'loss': 5.762210845947266}


EP_train:0:  64%|| 4451/6926 [4:55:56&lt;5:57:42,  8.67s/it]

{'epoch': 0, 'iter': 4450, 'avg_loss': 6.120343457176776, 'avg_acc': 50.03089193439676, 'loss': 5.757116794586182}


EP_train:0:  64%|| 4461/6926 [4:57:24&lt;6:08:39,  8.97s/it]

{'epoch': 0, 'iter': 4460, 'avg_loss': 6.119431651619298, 'avg_acc': 50.01891392064559, 'loss': 5.837987899780273}


EP_train:0:  65%|| 4471/6926 [4:58:54&lt;6:08:38,  9.01s/it]

{'epoch': 0, 'iter': 4470, 'avg_loss': 6.1184872946358455, 'avg_acc': 50.01328002683964, 'loss': 5.809126377105713}


EP_train:0:  65%|| 4481/6926 [5:00:20&lt;5:46:45,  8.51s/it]

{'epoch': 0, 'iter': 4480, 'avg_loss': 6.117713194291418, 'avg_acc': 50.0251060031243, 'loss': 5.521522521972656}


EP_train:0:  65%|| 4491/6926 [5:01:50&lt;5:50:37,  8.64s/it]

{'epoch': 0, 'iter': 4490, 'avg_loss': 6.116802253268711, 'avg_acc': 50.02017924738366, 'loss': 6.110646724700928}


EP_train:0:  65%|| 4501/6926 [5:03:23&lt;6:00:07,  8.91s/it]

{'epoch': 0, 'iter': 4500, 'avg_loss': 6.116173224458692, 'avg_acc': 50.01805154410132, 'loss': 6.085875034332275}


EP_train:0:  65%|| 4511/6926 [5:05:00&lt;6:19:40,  9.43s/it]

{'epoch': 0, 'iter': 4510, 'avg_loss': 6.1152781693905265, 'avg_acc': 50.01246951895367, 'loss': 6.162149906158447}


EP_train:0:  65%|| 4521/6926 [5:06:35&lt;6:15:37,  9.37s/it]

{'epoch': 0, 'iter': 4520, 'avg_loss': 6.114330110864232, 'avg_acc': 50.01520681265207, 'loss': 6.03239107131958}


EP_train:0:  65%|| 4531/6926 [5:08:17&lt;6:49:36, 10.26s/it]

{'epoch': 0, 'iter': 4530, 'avg_loss': 6.113296936269207, 'avg_acc': 50.02069079673361, 'loss': 5.511043548583984}


EP_train:0:  66%|| 4541/6926 [5:10:00&lt;6:42:09, 10.12s/it]

{'epoch': 0, 'iter': 4540, 'avg_loss': 6.112421222994229, 'avg_acc': 50.01926888350584, 'loss': 5.17509126663208}


EP_train:0:  66%|| 4551/6926 [5:11:43&lt;6:58:53, 10.58s/it]

{'epoch': 0, 'iter': 4550, 'avg_loss': 6.111743990705972, 'avg_acc': 50.02471984179301, 'loss': 5.924271583557129}


EP_train:0:  66%|| 4561/6926 [5:13:32&lt;7:05:25, 10.79s/it]

{'epoch': 0, 'iter': 4560, 'avg_loss': 6.11097088029473, 'avg_acc': 50.030832054374045, 'loss': 5.890345573425293}


EP_train:0:  66%|| 4571/6926 [5:15:17&lt;6:53:51, 10.54s/it]

{'epoch': 0, 'iter': 4570, 'avg_loss': 6.110327378687987, 'avg_acc': 50.039652154889524, 'loss': 5.677709579467773}


EP_train:0:  66%|| 4581/6926 [5:17:07&lt;7:03:23, 10.83s/it]

{'epoch': 0, 'iter': 4580, 'avg_loss': 6.109236018154408, 'avg_acc': 50.04502292075966, 'loss': 5.508075714111328}


EP_train:0:  66%|| 4591/6926 [5:19:01&lt;7:37:03, 11.74s/it]

{'epoch': 0, 'iter': 4590, 'avg_loss': 6.108820357890826, 'avg_acc': 50.041521455020685, 'loss': 6.13588285446167}


EP_train:0:  66%|| 4601/6926 [5:20:52&lt;7:10:36, 11.11s/it]

{'epoch': 0, 'iter': 4600, 'avg_loss': 6.1080951874112595, 'avg_acc': 50.042789610954145, 'loss': 5.552509784698486}


EP_train:0:  67%|| 4611/6926 [5:22:48&lt;7:14:30, 11.26s/it]

{'epoch': 0, 'iter': 4610, 'avg_loss': 6.107930664487734, 'avg_acc': 50.05150726523531, 'loss': 6.015118598937988}


EP_train:0:  67%|| 4621/6926 [5:24:45&lt;7:33:41, 11.81s/it]

{'epoch': 0, 'iter': 4620, 'avg_loss': 6.107511350226799, 'avg_acc': 50.05207206232417, 'loss': 5.898167610168457}


EP_train:0:  67%|| 4631/6926 [5:26:44&lt;7:20:35, 11.52s/it]

{'epoch': 0, 'iter': 4630, 'avg_loss': 6.106834995646221, 'avg_acc': 50.0580328222846, 'loss': 5.948448657989502}


EP_train:0:  67%|| 4641/6926 [5:28:51&lt;8:11:31, 12.91s/it]

{'epoch': 0, 'iter': 4640, 'avg_loss': 6.105808212951811, 'avg_acc': 50.05992781728076, 'loss': 5.264282703399658}


EP_train:0:  67%|| 4651/6926 [5:30:57&lt;8:10:50, 12.95s/it]

{'epoch': 0, 'iter': 4650, 'avg_loss': 6.105038179169161, 'avg_acc': 50.05240808428295, 'loss': 5.927124500274658}


EP_train:0:  67%|| 4661/6926 [5:33:06&lt;8:04:19, 12.83s/it]

{'epoch': 0, 'iter': 4660, 'avg_loss': 6.104328574348585, 'avg_acc': 50.06436387041408, 'loss': 6.021064758300781}


EP_train:0:  67%|| 4671/6926 [5:35:09&lt;7:41:16, 12.27s/it]

{'epoch': 0, 'iter': 4670, 'avg_loss': 6.103573122822838, 'avg_acc': 50.06355705416399, 'loss': 5.581331729888916}


EP_train:0:  68%|| 4681/6926 [5:37:11&lt;7:33:17, 12.11s/it]

{'epoch': 0, 'iter': 4680, 'avg_loss': 6.102721853608684, 'avg_acc': 50.06809442426832, 'loss': 5.77381706237793}


EP_train:0:  68%|| 4691/6926 [5:39:22&lt;7:59:51, 12.88s/it]

{'epoch': 0, 'iter': 4690, 'avg_loss': 6.102065182829991, 'avg_acc': 50.06861543380943, 'loss': 5.896530628204346}


EP_train:0:  68%|| 4701/6926 [5:41:28&lt;7:48:29, 12.63s/it]

{'epoch': 0, 'iter': 4700, 'avg_loss': 6.101369438767813, 'avg_acc': 50.07312273984259, 'loss': 5.971706390380859}


EP_train:0:  68%|| 4711/6926 [5:43:36&lt;7:43:28, 12.55s/it]

{'epoch': 0, 'iter': 4710, 'avg_loss': 6.100448183890893, 'avg_acc': 50.07495754616854, 'loss': 5.855482578277588}


EP_train:0:  68%|| 4721/6926 [5:45:46&lt;8:19:06, 13.58s/it]

{'epoch': 0, 'iter': 4720, 'avg_loss': 6.0997356430147445, 'avg_acc': 50.07347489938573, 'loss': 5.568177223205566}


EP_train:0:  68%|| 4731/6926 [5:47:59&lt;8:01:24, 13.16s/it]

{'epoch': 0, 'iter': 4730, 'avg_loss': 6.0991575538016, 'avg_acc': 50.06407207778483, 'loss': 5.6837592124938965}


EP_train:0:  68%|| 4741/6926 [5:50:17&lt;8:27:48, 13.94s/it]

{'epoch': 0, 'iter': 4740, 'avg_loss': 6.098652768653044, 'avg_acc': 50.06195950221473, 'loss': 5.796774387359619}


EP_train:0:  69%|| 4751/6926 [5:52:35&lt;8:25:23, 13.94s/it]

{'epoch': 0, 'iter': 4750, 'avg_loss': 6.098018825694, 'avg_acc': 50.069722163755, 'loss': 5.777691841125488}


EP_train:0:  69%|| 4761/6926 [5:55:04&lt;9:06:08, 15.14s/it]

{'epoch': 0, 'iter': 4760, 'avg_loss': 6.097104172425169, 'avg_acc': 50.0676065952531, 'loss': 5.552586078643799}


EP_train:0:  69%|| 4771/6926 [5:57:44&lt;9:37:48, 16.09s/it]

{'epoch': 0, 'iter': 4770, 'avg_loss': 6.096467465680742, 'avg_acc': 50.070084887864176, 'loss': 5.810379505157471}


EP_train:0:  69%|| 4781/6926 [6:00:38&lt;10:15:23, 17.21s/it]

{'epoch': 0, 'iter': 4780, 'avg_loss': 6.09603063971945, 'avg_acc': 50.06405563689604, 'loss': 5.595292091369629}


EP_train:0:  69%|| 4791/6926 [6:03:43&lt;11:05:09, 18.69s/it]

{'epoch': 0, 'iter': 4790, 'avg_loss': 6.095529262170093, 'avg_acc': 50.070444583594245, 'loss': 5.8601884841918945}


EP_train:0:  69%|| 4801/6926 [6:07:02&lt;11:54:08, 20.16s/it]

{'epoch': 0, 'iter': 4800, 'avg_loss': 6.094917712919763, 'avg_acc': 50.06964694855238, 'loss': 5.623406410217285}


EP_train:0:  69%|| 4811/6926 [6:10:34&lt;12:47:40, 21.78s/it]

{'epoch': 0, 'iter': 4810, 'avg_loss': 6.0942052355726455, 'avg_acc': 50.07664726668052, 'loss': 6.030642986297607}


EP_train:0:  70%|| 4821/6926 [6:14:13&lt;12:45:07, 21.81s/it]

{'epoch': 0, 'iter': 4820, 'avg_loss': 6.093401744884466, 'avg_acc': 50.079081103505494, 'loss': 5.665616035461426}


EP_train:0:  70%|| 4831/6926 [6:18:04&lt;13:35:32, 23.36s/it]

{'epoch': 0, 'iter': 4830, 'avg_loss': 6.092756156767409, 'avg_acc': 50.08344545642724, 'loss': 5.4798479080200195}


EP_train:0:  70%|| 4841/6926 [6:21:59&lt;13:43:32, 23.70s/it]

{'epoch': 0, 'iter': 4840, 'avg_loss': 6.092291939137914, 'avg_acc': 50.08262755629003, 'loss': 5.376607894897461}


EP_train:0:  70%|| 4851/6926 [6:25:57&lt;13:38:42, 23.67s/it]

{'epoch': 0, 'iter': 4850, 'avg_loss': 6.09143973773004, 'avg_acc': 50.07923623995053, 'loss': 5.781012058258057}


EP_train:0:  70%|| 4861/6926 [6:29:55&lt;13:35:57, 23.71s/it]

{'epoch': 0, 'iter': 4860, 'avg_loss': 6.090944552269524, 'avg_acc': 50.07521600493725, 'loss': 6.19387674331665}


EP_train:0:  70%|| 4871/6926 [6:33:57&lt;13:52:03, 24.29s/it]

{'epoch': 0, 'iter': 4870, 'avg_loss': 6.090154030611323, 'avg_acc': 50.075703141038794, 'loss': 5.867021083831787}


EP_train:0:  70%|| 4881/6926 [6:37:55&lt;13:23:16, 23.57s/it]

{'epoch': 0, 'iter': 4880, 'avg_loss': 6.089595957726539, 'avg_acc': 50.08002970702725, 'loss': 5.85502815246582}


EP_train:0:  71%|| 4891/6926 [6:41:47&lt;13:09:13, 23.27s/it]

{'epoch': 0, 'iter': 4890, 'avg_loss': 6.0889315922990015, 'avg_acc': 50.06708750766714, 'loss': 5.50833797454834}


EP_train:0:  71%|| 4901/6926 [6:45:43&lt;13:12:40, 23.49s/it]

{'epoch': 0, 'iter': 4900, 'avg_loss': 6.0882990747003065, 'avg_acc': 50.07268924709243, 'loss': 5.293552398681641}


EP_train:0:  71%|| 4911/6926 [6:49:39&lt;13:06:28, 23.42s/it]

{'epoch': 0, 'iter': 4910, 'avg_loss': 6.0876276060511, 'avg_acc': 50.06681429444105, 'loss': 6.01899528503418}


EP_train:0:  71%|| 4921/6926 [6:53:30&lt;12:36:35, 22.64s/it]

{'epoch': 0, 'iter': 4920, 'avg_loss': 6.087292747947167, 'avg_acc': 50.066043487096124, 'loss': 5.781203269958496}


EP_train:0:  71%|| 4931/6926 [6:57:16&lt;12:33:19, 22.66s/it]

{'epoch': 0, 'iter': 4930, 'avg_loss': 6.086437698794388, 'avg_acc': 50.06527580612452, 'loss': 6.0631184577941895}


EP_train:0:  71%|| 4941/6926 [7:00:58&lt;12:13:23, 22.17s/it]

{'epoch': 0, 'iter': 4940, 'avg_loss': 6.085821283464368, 'avg_acc': 50.06640862173649, 'loss': 5.635220050811768}


EP_train:0:  71%|| 4951/6926 [7:04:38&lt;12:05:48, 22.05s/it]

{'epoch': 0, 'iter': 4950, 'avg_loss': 6.0850673654156004, 'avg_acc': 50.074479903049884, 'loss': 5.9276885986328125}


EP_train:0:  72%|| 4961/6926 [7:08:18&lt;11:56:45, 21.89s/it]

{'epoch': 0, 'iter': 4960, 'avg_loss': 6.084530617291589, 'avg_acc': 50.084408385406164, 'loss': 5.963618278503418}


EP_train:0:  72%|| 4971/6926 [7:11:52&lt;11:40:34, 21.50s/it]

{'epoch': 0, 'iter': 4970, 'avg_loss': 6.083843590243917, 'avg_acc': 50.0779521223094, 'loss': 5.6765336990356445}


EP_train:0:  72%|| 4981/6926 [7:15:29&lt;11:42:25, 21.67s/it]

{'epoch': 0, 'iter': 4980, 'avg_loss': 6.0829357622235065, 'avg_acc': 50.07340393495282, 'loss': 5.715503215789795}


EP_train:0:  72%|| 4991/6926 [7:19:05&lt;11:33:31, 21.50s/it]

{'epoch': 0, 'iter': 4990, 'avg_loss': 6.082450271297662, 'avg_acc': 50.08014425966741, 'loss': 5.585351943969727}


EP_train:0:  72%|| 5001/6926 [7:22:38&lt;11:20:36, 21.21s/it]

{'epoch': 0, 'iter': 5000, 'avg_loss': 6.081787624160806, 'avg_acc': 50.084983003399316, 'loss': 5.853309631347656}


EP_train:0:  72%|| 5011/6926 [7:26:09&lt;11:10:31, 21.01s/it]

{'epoch': 0, 'iter': 5010, 'avg_loss': 6.081495600578386, 'avg_acc': 50.08980243464378, 'loss': 5.8602190017700195}


EP_train:0:  72%|| 5021/6926 [7:29:41&lt;11:10:15, 21.11s/it]

{'epoch': 0, 'iter': 5020, 'avg_loss': 6.080860076399824, 'avg_acc': 50.09086835291775, 'loss': 5.634836673736572}


EP_train:0:  73%|| 5031/6926 [7:33:12&lt;11:02:16, 20.97s/it]

{'epoch': 0, 'iter': 5030, 'avg_loss': 6.080404411748872, 'avg_acc': 50.09006658715961, 'loss': 5.9641618728637695}


EP_train:0:  73%|| 5041/6926 [7:36:41&lt;10:53:40, 20.81s/it]

{'epoch': 0, 'iter': 5040, 'avg_loss': 6.0797398177859945, 'avg_acc': 50.09918666931165, 'loss': 5.676470756530762}


EP_train:0:  73%|| 5051/6926 [7:40:07&lt;10:41:11, 20.52s/it]

{'epoch': 0, 'iter': 5050, 'avg_loss': 6.079021374368828, 'avg_acc': 50.09465947337161, 'loss': 5.772432804107666}


EP_train:0:  73%|| 5061/6926 [7:43:33&lt;10:38:00, 20.53s/it]

{'epoch': 0, 'iter': 5060, 'avg_loss': 6.078650245598667, 'avg_acc': 50.09262003556609, 'loss': 5.78647518157959}


EP_train:0:  73%|| 5071/6926 [7:47:00&lt;10:40:41, 20.72s/it]

{'epoch': 0, 'iter': 5070, 'avg_loss': 6.078217857524832, 'avg_acc': 50.09428613685664, 'loss': 6.273963928222656}


EP_train:0:  73%|| 5081/6926 [7:50:26&lt;10:32:48, 20.58s/it]

{'epoch': 0, 'iter': 5080, 'avg_loss': 6.07775627827696, 'avg_acc': 50.09717575280457, 'loss': 5.673422336578369}


EP_train:0:  74%|| 5091/6926 [7:53:53&lt;10:35:43, 20.79s/it]

{'epoch': 0, 'iter': 5090, 'avg_loss': 6.077203060784056, 'avg_acc': 50.102509330190536, 'loss': 5.872105121612549}


EP_train:0:  74%|| 5101/6926 [7:57:19&lt;10:25:31, 20.57s/it]

{'epoch': 0, 'iter': 5100, 'avg_loss': 6.0764456864689596, 'avg_acc': 50.10047049598118, 'loss': 5.70937442779541}


EP_train:0:  74%|| 5111/6926 [8:00:44&lt;10:17:25, 20.41s/it]

{'epoch': 0, 'iter': 5110, 'avg_loss': 6.075798931244977, 'avg_acc': 50.10271962433966, 'loss': 5.772765159606934}


EP_train:0:  74%|| 5121/6926 [8:04:07&lt;10:16:09, 20.48s/it]

{'epoch': 0, 'iter': 5120, 'avg_loss': 6.075373151623116, 'avg_acc': 50.0994678773677, 'loss': 5.413810729980469}


EP_train:0:  74%|| 5131/6926 [8:07:30&lt;10:03:30, 20.17s/it]

{'epoch': 0, 'iter': 5130, 'avg_loss': 6.074517063731177, 'avg_acc': 50.101101149873315, 'loss': 5.70771598815918}


EP_train:0:  74%|| 5141/6926 [8:10:53&lt;10:02:44, 20.26s/it]

{'epoch': 0, 'iter': 5140, 'avg_loss': 6.073841538695458, 'avg_acc': 50.09847305971601, 'loss': 5.845581531524658}


EP_train:0:  74%|| 5151/6926 [8:14:14&lt;9:51:51, 20.01s/it] 

{'epoch': 0, 'iter': 5150, 'avg_loss': 6.073580761692682, 'avg_acc': 50.09828188701223, 'loss': 5.733440399169922}


EP_train:0:  75%|| 5161/6926 [8:17:36&lt;9:50:40, 20.08s/it]

{'epoch': 0, 'iter': 5160, 'avg_loss': 6.072867002766207, 'avg_acc': 50.087192404572754, 'loss': 5.919801235198975}


EP_train:0:  75%|| 5171/6926 [8:20:58&lt;9:53:42, 20.30s/it]

{'epoch': 0, 'iter': 5170, 'avg_loss': 6.072219424357476, 'avg_acc': 50.085815122800234, 'loss': 5.778360366821289}


EP_train:0:  75%|| 5181/6926 [8:24:19&lt;9:45:01, 20.12s/it]

{'epoch': 0, 'iter': 5180, 'avg_loss': 6.071556362998092, 'avg_acc': 50.09349063887281, 'loss': 5.578665256500244}


EP_train:0:  75%|| 5191/6926 [8:27:38&lt;9:38:07, 19.99s/it]

{'epoch': 0, 'iter': 5190, 'avg_loss': 6.0709186734732485, 'avg_acc': 50.0993305721441, 'loss': 6.053485870361328}


EP_train:0:  75%|| 5201/6926 [8:30:58&lt;9:32:31, 19.91s/it]

{'epoch': 0, 'iter': 5200, 'avg_loss': 6.070428849733511, 'avg_acc': 50.10634974043453, 'loss': 5.696314811706543}


EP_train:0:  75%|| 5211/6926 [8:34:17&lt;9:27:50, 19.87s/it]

{'epoch': 0, 'iter': 5210, 'avg_loss': 6.069478024083945, 'avg_acc': 50.10614565342545, 'loss': 5.324738025665283}


EP_train:0:  75%|| 5221/6926 [8:37:36&lt;9:25:46, 19.91s/it]

{'epoch': 0, 'iter': 5220, 'avg_loss': 6.069184598007597, 'avg_acc': 50.10235108216816, 'loss': 5.764991283416748}


EP_train:0:  76%|| 5231/6926 [8:40:55&lt;9:22:40, 19.92s/it]

{'epoch': 0, 'iter': 5230, 'avg_loss': 6.069119955608708, 'avg_acc': 50.10096061938444, 'loss': 6.385601997375488}


EP_train:0:  76%|| 5241/6926 [8:44:14&lt;9:14:32, 19.75s/it]

{'epoch': 0, 'iter': 5240, 'avg_loss': 6.068350166338269, 'avg_acc': 50.100767983209316, 'loss': 5.714400768280029}


EP_train:0:  76%|| 5251/6926 [8:47:32&lt;9:11:35, 19.76s/it]

{'epoch': 0, 'iter': 5250, 'avg_loss': 6.067922578269335, 'avg_acc': 50.09581508284137, 'loss': 5.966418266296387}


EP_train:0:  76%|| 5261/6926 [8:50:49&lt;9:07:37, 19.73s/it]

{'epoch': 0, 'iter': 5260, 'avg_loss': 6.067496065630293, 'avg_acc': 50.087911043527846, 'loss': 5.884022235870361}


EP_train:0:  76%|| 5271/6926 [8:54:06&lt;9:02:55, 19.68s/it]

{'epoch': 0, 'iter': 5270, 'avg_loss': 6.066774628642297, 'avg_acc': 50.0818155947638, 'loss': 5.430381774902344}


EP_train:0:  76%|| 5281/6926 [8:57:23&lt;8:58:15, 19.63s/it]

{'epoch': 0, 'iter': 5280, 'avg_loss': 6.066137432578025, 'avg_acc': 50.089945086157925, 'loss': 5.879445552825928}


EP_train:0:  76%|| 5291/6926 [9:00:38&lt;8:53:16, 19.57s/it]

{'epoch': 0, 'iter': 5290, 'avg_loss': 6.065570325712652, 'avg_acc': 50.08918446418447, 'loss': 5.868078231811523}


EP_train:0:  77%|| 5301/6926 [9:03:55&lt;8:52:29, 19.66s/it]

{'epoch': 0, 'iter': 5300, 'avg_loss': 6.0650617345462, 'avg_acc': 50.08547915487643, 'loss': 5.8117451667785645}


EP_train:0:  77%|| 5311/6926 [9:07:12&lt;8:49:28, 19.67s/it]

{'epoch': 0, 'iter': 5310, 'avg_loss': 6.064686179497758, 'avg_acc': 50.08708341178686, 'loss': 5.709105014801025}


EP_train:0:  77%|| 5321/6926 [9:10:27&lt;8:42:24, 19.53s/it]

{'epoch': 0, 'iter': 5320, 'avg_loss': 6.064325973114289, 'avg_acc': 50.08339597819958, 'loss': 5.776423931121826}


EP_train:0:  77%|| 5331/6926 [9:13:42&lt;8:40:33, 19.58s/it]

{'epoch': 0, 'iter': 5330, 'avg_loss': 6.0636539949393145, 'avg_acc': 50.079722378540616, 'loss': 5.148025989532471}


EP_train:0:  77%|| 5341/6926 [9:16:58&lt;8:40:46, 19.71s/it]

{'epoch': 0, 'iter': 5340, 'avg_loss': 6.062986289354505, 'avg_acc': 50.07430724583411, 'loss': 6.282643795013428}


EP_train:0:  77%|| 5351/6926 [9:20:15&lt;8:35:25, 19.63s/it]

{'epoch': 0, 'iter': 5350, 'avg_loss': 6.062770438225464, 'avg_acc': 50.07008035881144, 'loss': 6.184378147125244}


EP_train:0:  77%|| 5361/6926 [9:23:30&lt;8:28:24, 19.49s/it]

{'epoch': 0, 'iter': 5360, 'avg_loss': 6.062225062863592, 'avg_acc': 50.061205931729155, 'loss': 5.738152503967285}


EP_train:0:  78%|| 5371/6926 [9:26:45&lt;8:27:35, 19.59s/it]

{'epoch': 0, 'iter': 5370, 'avg_loss': 6.061937043174555, 'avg_acc': 50.063419288773034, 'loss': 5.628539085388184}


EP_train:0:  78%|| 5381/6926 [9:30:02&lt;8:26:10, 19.66s/it]

{'epoch': 0, 'iter': 5380, 'avg_loss': 6.061433275754823, 'avg_acc': 50.05400947779223, 'loss': 5.4939422607421875}


EP_train:0:  78%|| 5391/6926 [9:33:17&lt;8:20:35, 19.57s/it]

{'epoch': 0, 'iter': 5390, 'avg_loss': 6.0608886586251005, 'avg_acc': 50.059126321647184, 'loss': 6.1512346267700195}


EP_train:0:  78%|| 5401/6926 [9:36:33&lt;8:15:32, 19.50s/it]

{'epoch': 0, 'iter': 5400, 'avg_loss': 6.060428837894665, 'avg_acc': 50.061909831512686, 'loss': 6.008522987365723}


EP_train:0:  78%|| 5411/6926 [9:39:47&lt;8:11:39, 19.47s/it]

{'epoch': 0, 'iter': 5410, 'avg_loss': 6.060002618566544, 'avg_acc': 50.06237294400295, 'loss': 5.748854160308838}


EP_train:0:  78%|| 5421/6926 [9:43:02&lt;8:09:10, 19.50s/it]

{'epoch': 0, 'iter': 5420, 'avg_loss': 6.05946754243756, 'avg_acc': 50.05706972883232, 'loss': 6.189664840698242}


EP_train:0:  78%|| 5431/6926 [9:46:17&lt;8:06:19, 19.52s/it]

{'epoch': 0, 'iter': 5430, 'avg_loss': 6.0591200932330835, 'avg_acc': 50.058115448352055, 'loss': 5.9671311378479}


EP_train:0:  79%|| 5441/6926 [9:49:31&lt;8:00:03, 19.40s/it]

{'epoch': 0, 'iter': 5440, 'avg_loss': 6.058608655521174, 'avg_acc': 50.064900753537955, 'loss': 5.550085067749023}


EP_train:0:  79%|| 5451/6926 [9:52:44&lt;7:54:18, 19.29s/it]

{'epoch': 0, 'iter': 5450, 'avg_loss': 6.058155152365125, 'avg_acc': 50.05790221977618, 'loss': 6.0328145027160645}


EP_train:0:  79%|| 5461/6926 [9:55:58&lt;7:53:11, 19.38s/it]

{'epoch': 0, 'iter': 5460, 'avg_loss': 6.057945248234121, 'avg_acc': 50.05836843069035, 'loss': 6.305117130279541}


EP_train:0:  79%|| 5471/6926 [9:59:12&lt;7:48:24, 19.32s/it]

{'epoch': 0, 'iter': 5470, 'avg_loss': 6.057664112512208, 'avg_acc': 50.05312100164504, 'loss': 5.615352630615234}


EP_train:0:  79%|| 5481/6926 [10:02:24&lt;7:45:19, 19.32s/it]

{'epoch': 0, 'iter': 5480, 'avg_loss': 6.057026087683149, 'avg_acc': 50.05416438606094, 'loss': 5.559899806976318}


EP_train:0:  79%|| 5491/6926 [10:05:37&lt;7:39:49, 19.23s/it]

{'epoch': 0, 'iter': 5490, 'avg_loss': 6.05657900966727, 'avg_acc': 50.04894372609725, 'loss': 5.771035671234131}


EP_train:0:  79%|| 5501/6926 [10:08:49&lt;7:36:18, 19.21s/it]

{'epoch': 0, 'iter': 5500, 'avg_loss': 6.0561153448791725, 'avg_acc': 50.05908016724232, 'loss': 5.7838664054870605}


EP_train:0:  80%|| 5511/6926 [10:12:01&lt;7:32:20, 19.18s/it]

{'epoch': 0, 'iter': 5510, 'avg_loss': 6.055715451632496, 'avg_acc': 50.06010705861005, 'loss': 5.436075687408447}


EP_train:0:  80%|| 5521/6926 [10:15:13&lt;7:29:45, 19.21s/it]

{'epoch': 0, 'iter': 5520, 'avg_loss': 6.055223534923817, 'avg_acc': 50.05377196160116, 'loss': 6.087020397186279}


EP_train:0:  80%|| 5531/6926 [10:18:25&lt;7:25:30, 19.16s/it]

{'epoch': 0, 'iter': 5530, 'avg_loss': 6.054754813440323, 'avg_acc': 50.05367474236123, 'loss': 5.598529815673828}


EP_train:0:  80%|| 5541/6926 [10:21:37&lt;7:22:04, 19.15s/it]

{'epoch': 0, 'iter': 5540, 'avg_loss': 6.054398222577161, 'avg_acc': 50.05132196354448, 'loss': 5.5578155517578125}


EP_train:0:  80%|| 5551/6926 [10:24:48&lt;7:18:26, 19.13s/it]

{'epoch': 0, 'iter': 5550, 'avg_loss': 6.053861262669028, 'avg_acc': 50.0444739686543, 'loss': 5.696660041809082}


EP_train:0:  80%|| 5561/6926 [10:28:00&lt;7:15:21, 19.14s/it]

{'epoch': 0, 'iter': 5560, 'avg_loss': 6.053380429583945, 'avg_acc': 50.04495594317569, 'loss': 5.97573184967041}


EP_train:0:  80%|| 5571/6926 [10:31:10&lt;7:10:42, 19.07s/it]

{'epoch': 0, 'iter': 5570, 'avg_loss': 6.052962116483854, 'avg_acc': 50.047679949739724, 'loss': 6.062566757202148}


EP_train:0:  81%|| 5581/6926 [10:34:21&lt;7:06:29, 19.03s/it]

{'epoch': 0, 'iter': 5580, 'avg_loss': 6.052793034941593, 'avg_acc': 50.04927432359793, 'loss': 6.089478492736816}


EP_train:0:  81%|| 5591/6926 [10:37:31&lt;7:02:17, 18.98s/it]

{'epoch': 0, 'iter': 5590, 'avg_loss': 6.05223103350805, 'avg_acc': 50.04471472008585, 'loss': 5.812742710113525}


EP_train:0:  81%|| 5601/6926 [10:40:44&lt;7:04:37, 19.23s/it]

{'epoch': 0, 'iter': 5600, 'avg_loss': 6.051796140723559, 'avg_acc': 50.05579360828424, 'loss': 6.247024059295654}


EP_train:0:  81%|| 5611/6926 [10:43:55&lt;7:01:27, 19.23s/it]

{'epoch': 0, 'iter': 5610, 'avg_loss': 6.051140494576922, 'avg_acc': 50.04956781322403, 'loss': 5.793033599853516}


EP_train:0:  81%|| 5621/6926 [10:47:05&lt;6:54:00, 19.03s/it]

{'epoch': 0, 'iter': 5620, 'avg_loss': 6.050951790330334, 'avg_acc': 50.05059153175592, 'loss': 6.803011417388916}


EP_train:0:  81%|| 5631/6926 [10:50:16&lt;6:50:25, 19.02s/it]

{'epoch': 0, 'iter': 5630, 'avg_loss': 6.0504347828814415, 'avg_acc': 50.05771621381637, 'loss': 5.808588981628418}


EP_train:0:  81%|| 5641/6926 [10:53:27&lt;6:50:41, 19.18s/it]

{'epoch': 0, 'iter': 5640, 'avg_loss': 6.050119936962834, 'avg_acc': 50.05484399929091, 'loss': 5.763957977294922}


EP_train:0:  82%|| 5651/6926 [10:56:36&lt;6:42:50, 18.96s/it]

{'epoch': 0, 'iter': 5650, 'avg_loss': 6.049732971984588, 'avg_acc': 50.05474694744293, 'loss': 5.428714275360107}


EP_train:0:  82%|| 5661/6926 [10:59:47&lt;6:42:56, 19.11s/it]

{'epoch': 0, 'iter': 5660, 'avg_loss': 6.049299944291539, 'avg_acc': 50.05796237413884, 'loss': 6.474251747131348}


EP_train:0:  82%|| 5671/6926 [11:02:57&lt;6:38:57, 19.07s/it]

{'epoch': 0, 'iter': 5670, 'avg_loss': 6.04898352682685, 'avg_acc': 50.05345177217422, 'loss': 5.9161858558654785}


EP_train:0:  82%|| 5681/6926 [11:06:07&lt;6:33:51, 18.98s/it]

{'epoch': 0, 'iter': 5680, 'avg_loss': 6.048277414258444, 'avg_acc': 50.05335768350643, 'loss': 5.432251930236816}


EP_train:0:  82%|| 5691/6926 [11:09:17&lt;6:31:56, 19.04s/it]

{'epoch': 0, 'iter': 5690, 'avg_loss': 6.047640271774182, 'avg_acc': 50.05436215076436, 'loss': 6.023947715759277}


EP_train:0:  82%|| 5701/6926 [11:12:27&lt;6:28:32, 19.03s/it]

{'epoch': 0, 'iter': 5700, 'avg_loss': 6.047283367239954, 'avg_acc': 50.051526048061746, 'loss': 6.204166412353516}


EP_train:0:  82%|| 5711/6926 [11:15:37&lt;6:24:31, 18.99s/it]

{'epoch': 0, 'iter': 5710, 'avg_loss': 6.046686040063055, 'avg_acc': 50.05636053230608, 'loss': 5.616063594818115}


EP_train:0:  83%|| 5721/6926 [11:18:47&lt;6:21:48, 19.01s/it]

{'epoch': 0, 'iter': 5720, 'avg_loss': 6.046054969194823, 'avg_acc': 50.051892151721724, 'loss': 5.643561840057373}


EP_train:0:  83%|| 5731/6926 [11:21:57&lt;6:18:18, 18.99s/it]

{'epoch': 0, 'iter': 5730, 'avg_loss': 6.045337284033553, 'avg_acc': 50.05779968591869, 'loss': 5.545201301574707}


EP_train:0:  83%|| 5741/6926 [11:25:08&lt;6:16:15, 19.05s/it]

{'epoch': 0, 'iter': 5740, 'avg_loss': 6.045013471589107, 'avg_acc': 50.05606601637346, 'loss': 5.711957931518555}


EP_train:0:  83%|| 5751/6926 [11:28:18&lt;6:11:46, 18.98s/it]

{'epoch': 0, 'iter': 5750, 'avg_loss': 6.044551691248653, 'avg_acc': 50.04781777082247, 'loss': 5.949689865112305}


EP_train:0:  83%|| 5761/6926 [11:31:28&lt;6:09:32, 19.03s/it]

{'epoch': 0, 'iter': 5760, 'avg_loss': 6.043848627372203, 'avg_acc': 50.049904530463465, 'loss': 5.838766098022461}


EP_train:0:  83%|| 5771/6926 [11:34:39&lt;6:06:35, 19.04s/it]

{'epoch': 0, 'iter': 5770, 'avg_loss': 6.043492621430242, 'avg_acc': 50.04873505458326, 'loss': 5.7118821144104}


EP_train:0:  83%|| 5781/6926 [11:37:49&lt;6:05:26, 19.15s/it]

{'epoch': 0, 'iter': 5780, 'avg_loss': 6.043258738092971, 'avg_acc': 50.045947932883585, 'loss': 6.598991870880127}


EP_train:0:  84%|| 5791/6926 [11:41:00&lt;6:00:30, 19.06s/it]

{'epoch': 0, 'iter': 5790, 'avg_loss': 6.042884248214113, 'avg_acc': 50.04263080642376, 'loss': 6.095027446746826}


EP_train:0:  84%|| 5801/6926 [11:44:10&lt;5:56:30, 19.01s/it]

{'epoch': 0, 'iter': 5800, 'avg_loss': 6.042668266884933, 'avg_acc': 50.03663161523875, 'loss': 6.164670467376709}


EP_train:0:  84%|| 5811/6926 [11:47:20&lt;5:53:52, 19.04s/it]

{'epoch': 0, 'iter': 5810, 'avg_loss': 6.042545654875874, 'avg_acc': 50.02796420581655, 'loss': 6.297694683074951}


EP_train:0:  84%|| 5821/6926 [11:50:30&lt;5:49:56, 19.00s/it]

{'epoch': 0, 'iter': 5820, 'avg_loss': 6.0420319640417315, 'avg_acc': 50.0327478096547, 'loss': 5.990520000457764}


EP_train:0:  84%|| 5831/6926 [11:53:40&lt;5:47:46, 19.06s/it]

{'epoch': 0, 'iter': 5830, 'avg_loss': 6.041855342840784, 'avg_acc': 50.030547933459104, 'loss': 6.198580741882324}


EP_train:0:  84%|| 5841/6926 [11:56:51&lt;5:44:20, 19.04s/it]

{'epoch': 0, 'iter': 5840, 'avg_loss': 6.041508391098992, 'avg_acc': 50.026215545283335, 'loss': 5.53244161605835}


EP_train:0:  84%|| 5851/6926 [12:00:01&lt;5:41:38, 19.07s/it]

{'epoch': 0, 'iter': 5850, 'avg_loss': 6.041253163577797, 'avg_acc': 50.02082977268842, 'loss': 5.799931526184082}


EP_train:0:  85%|| 5861/6926 [12:03:12&lt;5:37:18, 19.00s/it]

{'epoch': 0, 'iter': 5860, 'avg_loss': 6.040680655154163, 'avg_acc': 50.0170619348234, 'loss': 4.953822612762451}


EP_train:0:  85%|| 5871/6926 [12:06:22&lt;5:34:07, 19.00s/it]

{'epoch': 0, 'iter': 5870, 'avg_loss': 6.040281329807158, 'avg_acc': 50.02288792369273, 'loss': 6.154869556427002}


EP_train:0:  85%|| 5881/6926 [12:09:33&lt;5:30:49, 18.99s/it]

{'epoch': 0, 'iter': 5880, 'avg_loss': 6.039676517232951, 'avg_acc': 50.02072351640877, 'loss': 5.802964687347412}


EP_train:0:  85%|| 5891/6926 [12:12:44&lt;5:28:52, 19.07s/it]

{'epoch': 0, 'iter': 5890, 'avg_loss': 6.039148722373251, 'avg_acc': 50.018566457307756, 'loss': 5.647651195526123}


EP_train:0:  85%|| 5901/6926 [12:15:54&lt;5:25:20, 19.04s/it]

{'epoch': 0, 'iter': 5900, 'avg_loss': 6.038776549620661, 'avg_acc': 50.01429842399593, 'loss': 5.790339469909668}


EP_train:0:  85%|| 5911/6926 [12:19:04&lt;5:22:08, 19.04s/it]

{'epoch': 0, 'iter': 5910, 'avg_loss': 6.038495293286342, 'avg_acc': 50.00634410421249, 'loss': 6.066430568695068}


EP_train:0:  85%|| 5921/6926 [12:22:14&lt;5:18:34, 19.02s/it]

{'epoch': 0, 'iter': 5920, 'avg_loss': 6.03806191846902, 'avg_acc': 50.013194561729435, 'loss': 5.983713626861572}


EP_train:0:  86%|| 5931/6926 [12:25:24&lt;5:14:44, 18.98s/it]

{'epoch': 0, 'iter': 5930, 'avg_loss': 6.0374118405838795, 'avg_acc': 50.01317231495533, 'loss': 5.995700359344482}


EP_train:0:  86%|| 5941/6926 [12:28:34&lt;5:12:03, 19.01s/it]

{'epoch': 0, 'iter': 5940, 'avg_loss': 6.037050577310415, 'avg_acc': 50.00841609156708, 'loss': 5.815313339233398}


EP_train:0:  86%|| 5951/6926 [12:31:45&lt;5:09:58, 19.08s/it]

{'epoch': 0, 'iter': 5950, 'avg_loss': 6.036335761638033, 'avg_acc': 50.01417828936313, 'loss': 5.6513352394104}


EP_train:0:  86%|| 5961/6926 [12:34:57&lt;5:09:24, 19.24s/it]

{'epoch': 0, 'iter': 5960, 'avg_loss': 6.035792850404153, 'avg_acc': 50.01310602247945, 'loss': 5.454611778259277}


EP_train:0:  86%|| 5971/6926 [12:38:09&lt;5:03:42, 19.08s/it]

{'epoch': 0, 'iter': 5970, 'avg_loss': 6.035440462674952, 'avg_acc': 50.017270976385866, 'loss': 5.517047882080078}


EP_train:0:  86%|| 5981/6926 [12:41:19&lt;5:00:04, 19.05s/it]

{'epoch': 0, 'iter': 5980, 'avg_loss': 6.035089520701715, 'avg_acc': 50.012017221200466, 'loss': 5.950679779052734}


EP_train:0:  87%|| 5991/6926 [12:44:29&lt;4:55:27, 18.96s/it]

{'epoch': 0, 'iter': 5990, 'avg_loss': 6.034344943213236, 'avg_acc': 50.014605241195135, 'loss': 5.059428691864014}


EP_train:0:  87%|| 6001/6926 [12:47:40&lt;4:54:13, 19.09s/it]

{'epoch': 0, 'iter': 6000, 'avg_loss': 6.0341623494116945, 'avg_acc': 50.01406015664056, 'loss': 6.380976676940918}


EP_train:0:  87%|| 6011/6926 [12:50:51&lt;4:50:01, 19.02s/it]

{'epoch': 0, 'iter': 6010, 'avg_loss': 6.033997507465003, 'avg_acc': 50.01923556812511, 'loss': 5.880812168121338}


EP_train:0:  87%|| 6021/6926 [12:54:01&lt;4:48:12, 19.11s/it]

{'epoch': 0, 'iter': 6020, 'avg_loss': 6.033575561271912, 'avg_acc': 50.02179870453413, 'loss': 5.8794379234313965}


EP_train:0:  87%|| 6031/6926 [12:57:12&lt;4:45:13, 19.12s/it]

{'epoch': 0, 'iter': 6030, 'avg_loss': 6.03301862554751, 'avg_acc': 50.03005305919417, 'loss': 5.894796371459961}


EP_train:0:  87%|| 6041/6926 [13:00:23&lt;4:41:16, 19.07s/it]

{'epoch': 0, 'iter': 6040, 'avg_loss': 6.032567908207009, 'avg_acc': 50.01500165535507, 'loss': 5.722947597503662}


EP_train:0:  87%|| 6051/6926 [13:03:33&lt;4:37:25, 19.02s/it]

{'epoch': 0, 'iter': 6050, 'avg_loss': 6.032233718051888, 'avg_acc': 50.013427532639234, 'loss': 5.412944316864014}


EP_train:0:  88%|| 6061/6926 [13:06:44&lt;4:34:27, 19.04s/it]

{'epoch': 0, 'iter': 6060, 'avg_loss': 6.032118993906116, 'avg_acc': 50.01082742121762, 'loss': 5.759841442108154}


EP_train:0:  88%|| 6071/6926 [13:09:54&lt;4:31:13, 19.03s/it]

{'epoch': 0, 'iter': 6070, 'avg_loss': 6.031723793835955, 'avg_acc': 50.01029484434195, 'loss': 5.889526844024658}


EP_train:0:  88%|| 6081/6926 [13:13:06&lt;4:30:01, 19.17s/it]

{'epoch': 0, 'iter': 6080, 'avg_loss': 6.031357279891854, 'avg_acc': 50.0128473935208, 'loss': 5.590921401977539}


EP_train:0:  88%|| 6091/6926 [13:16:16&lt;4:25:44, 19.10s/it]

{'epoch': 0, 'iter': 6090, 'avg_loss': 6.030790824840034, 'avg_acc': 50.00923493679199, 'loss': 5.659143924713135}


EP_train:0:  88%|| 6101/6926 [13:19:27&lt;4:21:50, 19.04s/it]

{'epoch': 0, 'iter': 6100, 'avg_loss': 6.030299226254093, 'avg_acc': 50.0158785445009, 'loss': 5.879879474639893}


EP_train:0:  88%|| 6111/6926 [13:22:39&lt;4:21:44, 19.27s/it]

{'epoch': 0, 'iter': 6110, 'avg_loss': 6.030024196098526, 'avg_acc': 50.014829815087545, 'loss': 5.886487007141113}


EP_train:0:  88%|| 6121/6926 [13:25:51&lt;4:17:06, 19.16s/it]

{'epoch': 0, 'iter': 6120, 'avg_loss': 6.029531428946757, 'avg_acc': 50.01327397484071, 'loss': 5.961380481719971}


EP_train:0:  89%|| 6131/6926 [13:29:02&lt;4:12:34, 19.06s/it]

{'epoch': 0, 'iter': 6130, 'avg_loss': 6.029220996605321, 'avg_acc': 50.01529114336976, 'loss': 5.741018295288086}


EP_train:0:  89%|| 6141/6926 [13:32:13&lt;4:09:38, 19.08s/it]

{'epoch': 0, 'iter': 6140, 'avg_loss': 6.0290389252765, 'avg_acc': 50.01424849373066, 'loss': 5.700308322906494}


EP_train:0:  89%|| 6151/6926 [13:35:24&lt;4:05:52, 19.04s/it]

{'epoch': 0, 'iter': 6150, 'avg_loss': 6.028690724038745, 'avg_acc': 50.010668996911065, 'loss': 6.073245525360107}


EP_train:0:  89%|| 6161/6926 [13:38:35&lt;4:03:32, 19.10s/it]

{'epoch': 0, 'iter': 6160, 'avg_loss': 6.028311000050633, 'avg_acc': 50.01166612562896, 'loss': 5.587075710296631}


EP_train:0:  89%|| 6171/6926 [13:41:47&lt;4:00:30, 19.11s/it]

{'epoch': 0, 'iter': 6170, 'avg_loss': 6.028168549087171, 'avg_acc': 50.00962161724194, 'loss': 5.567011833190918}


EP_train:0:  89%|| 6181/6926 [13:44:57&lt;3:56:41, 19.06s/it]

{'epoch': 0, 'iter': 6180, 'avg_loss': 6.027922423559762, 'avg_acc': 50.012133958906325, 'loss': 6.1278181076049805}


EP_train:0:  89%|| 6191/6926 [13:48:09&lt;3:55:01, 19.19s/it]

{'epoch': 0, 'iter': 6190, 'avg_loss': 6.027708585727121, 'avg_acc': 50.006057179777095, 'loss': 5.852789878845215}


EP_train:0:  90%|| 6201/6926 [13:51:21&lt;3:50:49, 19.10s/it]

{'epoch': 0, 'iter': 6200, 'avg_loss': 6.027192727190278, 'avg_acc': 50.016630382196425, 'loss': 5.914374351501465}


EP_train:0:  90%|| 6211/6926 [13:54:33&lt;3:48:46, 19.20s/it]

{'epoch': 0, 'iter': 6210, 'avg_loss': 6.026688819806024, 'avg_acc': 50.01710674609564, 'loss': 5.38663911819458}


EP_train:0:  90%|| 6221/6926 [13:57:44&lt;3:44:51, 19.14s/it]

{'epoch': 0, 'iter': 6220, 'avg_loss': 6.026326997125672, 'avg_acc': 50.025618871564056, 'loss': 5.984750270843506}


EP_train:0:  90%|| 6231/6926 [14:00:56&lt;3:41:50, 19.15s/it]

{'epoch': 0, 'iter': 6230, 'avg_loss': 6.025808269149935, 'avg_acc': 50.02357165783984, 'loss': 6.185163974761963}


EP_train:0:  90%|| 6241/6926 [14:04:07&lt;3:38:55, 19.18s/it]

{'epoch': 0, 'iter': 6240, 'avg_loss': 6.025444647265329, 'avg_acc': 50.02403460983816, 'loss': 5.641790866851807}


EP_train:0:  90%|| 6251/6926 [14:07:20&lt;3:36:25, 19.24s/it]

{'epoch': 0, 'iter': 6250, 'avg_loss': 6.0252187642988595, 'avg_acc': 50.012997920332744, 'loss': 5.41579008102417}


EP_train:0:  90%|| 6261/6926 [14:10:31&lt;3:32:02, 19.13s/it]

{'epoch': 0, 'iter': 6260, 'avg_loss': 6.024968230063648, 'avg_acc': 50.017469254112754, 'loss': 5.893710136413574}


EP_train:0:  91%|| 6271/6926 [14:13:43&lt;3:29:27, 19.19s/it]

{'epoch': 0, 'iter': 6270, 'avg_loss': 6.024743533176282, 'avg_acc': 50.019434699409985, 'loss': 5.925285816192627}


EP_train:0:  91%|| 6281/6926 [14:16:54&lt;3:26:03, 19.17s/it]

{'epoch': 0, 'iter': 6280, 'avg_loss': 6.024407376986441, 'avg_acc': 50.01940375736348, 'loss': 5.84910249710083}


EP_train:0:  91%|| 6291/6926 [14:20:05&lt;3:21:53, 19.08s/it]

{'epoch': 0, 'iter': 6290, 'avg_loss': 6.024231166533381, 'avg_acc': 50.013908758543955, 'loss': 5.5846381187438965}


EP_train:0:  91%|| 6301/6926 [14:23:16&lt;3:19:10, 19.12s/it]

{'epoch': 0, 'iter': 6300, 'avg_loss': 6.023935518611369, 'avg_acc': 50.01289477860658, 'loss': 6.034008979797363}


EP_train:0:  91%|| 6311/6926 [14:26:28&lt;3:15:59, 19.12s/it]

{'epoch': 0, 'iter': 6310, 'avg_loss': 6.023718788513875, 'avg_acc': 50.00891300903185, 'loss': 6.074720859527588}


EP_train:0:  91%|| 6321/6926 [14:29:39&lt;3:12:45, 19.12s/it]

{'epoch': 0, 'iter': 6320, 'avg_loss': 6.02339181890972, 'avg_acc': 50.00593260560038, 'loss': 6.016669273376465}


EP_train:0:  91%|| 6331/6926 [14:32:50&lt;3:09:16, 19.09s/it]

{'epoch': 0, 'iter': 6330, 'avg_loss': 6.022894253532688, 'avg_acc': 50.01579529300268, 'loss': 5.54511022567749}


EP_train:0:  92%|| 6341/6926 [14:36:02&lt;3:07:13, 19.20s/it]

{'epoch': 0, 'iter': 6340, 'avg_loss': 6.022788465220438, 'avg_acc': 50.0241483993061, 'loss': 6.032009124755859}


EP_train:0:  92%|| 6351/6926 [14:39:13&lt;3:03:30, 19.15s/it]

{'epoch': 0, 'iter': 6350, 'avg_loss': 6.022524105021567, 'avg_acc': 50.022142182333496, 'loss': 5.417093276977539}


EP_train:0:  92%|| 6361/6926 [14:42:24&lt;2:59:32, 19.07s/it]

{'epoch': 0, 'iter': 6360, 'avg_loss': 6.022403193652077, 'avg_acc': 50.018668448357175, 'loss': 5.7805705070495605}


EP_train:0:  92%|| 6371/6926 [14:45:36&lt;2:57:37, 19.20s/it]

{'epoch': 0, 'iter': 6370, 'avg_loss': 6.022453367307822, 'avg_acc': 50.014715115366506, 'loss': 5.773720741271973}


EP_train:0:  92%|| 6381/6926 [14:48:47&lt;2:53:45, 19.13s/it]

{'epoch': 0, 'iter': 6380, 'avg_loss': 6.022148494529156, 'avg_acc': 50.01812020059552, 'loss': 5.828519344329834}


EP_train:0:  92%|| 6391/6926 [14:51:59&lt;2:50:43, 19.15s/it]

{'epoch': 0, 'iter': 6390, 'avg_loss': 6.021771567283037, 'avg_acc': 50.02151462994836, 'loss': 6.139357566833496}


EP_train:0:  92%|| 6401/6926 [14:55:10&lt;2:48:02, 19.20s/it]

{'epoch': 0, 'iter': 6400, 'avg_loss': 6.021559764958605, 'avg_acc': 50.02099281362287, 'loss': 6.213183403015137}


EP_train:0:  93%|| 6411/6926 [14:58:22&lt;2:44:22, 19.15s/it]

{'epoch': 0, 'iter': 6410, 'avg_loss': 6.021199776701986, 'avg_acc': 50.025347059741065, 'loss': 6.391252040863037}


EP_train:0:  93%|| 6421/6926 [15:01:33&lt;2:41:03, 19.14s/it]

{'epoch': 0, 'iter': 6420, 'avg_loss': 6.020786032166516, 'avg_acc': 50.02287416290297, 'loss': 5.490016937255859}


EP_train:0:  93%|| 6431/6926 [15:04:44&lt;2:37:48, 19.13s/it]

{'epoch': 0, 'iter': 6430, 'avg_loss': 6.020458819280051, 'avg_acc': 50.02235266677033, 'loss': 5.519053936004639}


EP_train:0:  93%|| 6441/6926 [15:07:55&lt;2:34:36, 19.13s/it]

{'epoch': 0, 'iter': 6440, 'avg_loss': 6.020114336338052, 'avg_acc': 50.01698105884179, 'loss': 5.88951301574707}


EP_train:0:  93%|| 6451/6926 [15:11:07&lt;2:31:29, 19.14s/it]

{'epoch': 0, 'iter': 6450, 'avg_loss': 6.019951528032664, 'avg_acc': 50.01259494651992, 'loss': 6.402599334716797}


EP_train:0:  93%|| 6461/6926 [15:14:18&lt;2:28:34, 19.17s/it]

{'epoch': 0, 'iter': 6460, 'avg_loss': 6.019697615318375, 'avg_acc': 50.01354279523294, 'loss': 6.159534454345703}


EP_train:0:  93%|| 6471/6926 [15:17:30&lt;2:25:04, 19.13s/it]

{'epoch': 0, 'iter': 6470, 'avg_loss': 6.019480395991326, 'avg_acc': 50.00193169525575, 'loss': 5.5013275146484375}


EP_train:0:  94%|| 6481/6926 [15:20:41&lt;2:21:50, 19.12s/it]

{'epoch': 0, 'iter': 6480, 'avg_loss': 6.019170306270054, 'avg_acc': 50.002410893380656, 'loss': 5.37006139755249}


EP_train:0:  94%|| 6491/6926 [15:23:53&lt;2:19:25, 19.23s/it]

{'epoch': 0, 'iter': 6490, 'avg_loss': 6.018963563425701, 'avg_acc': 50.001925743336926, 'loss': 6.374922275543213}


EP_train:0:  94%|| 6501/6926 [15:27:06&lt;2:16:49, 19.32s/it]

{'epoch': 0, 'iter': 6500, 'avg_loss': 6.018632433667878, 'avg_acc': 50.002403476388245, 'loss': 5.702291011810303}


EP_train:0:  94%|| 6511/6926 [15:30:19&lt;2:13:16, 19.27s/it]

{'epoch': 0, 'iter': 6510, 'avg_loss': 6.018304113784413, 'avg_acc': 50.00047995699586, 'loss': 5.912711143493652}


EP_train:0:  94%|| 6521/6926 [15:33:31&lt;2:09:32, 19.19s/it]

{'epoch': 0, 'iter': 6520, 'avg_loss': 6.017902231677107, 'avg_acc': 50.0129389664162, 'loss': 6.289568901062012}


EP_train:0:  94%|| 6531/6926 [15:36:44&lt;2:07:07, 19.31s/it]

{'epoch': 0, 'iter': 6530, 'avg_loss': 6.0176445086760575, 'avg_acc': 50.01291915480019, 'loss': 5.743828296661377}


EP_train:0:  94%|| 6541/6926 [15:39:56&lt;2:03:06, 19.19s/it]

{'epoch': 0, 'iter': 6540, 'avg_loss': 6.017163850174568, 'avg_acc': 50.008121846812415, 'loss': 5.398609161376953}


EP_train:0:  95%|| 6551/6926 [15:43:14&lt;2:06:39, 20.26s/it]

{'epoch': 0, 'iter': 6550, 'avg_loss': 6.017079152218023, 'avg_acc': 50.004293237673636, 'loss': 5.756030082702637}


EP_train:0:  95%|| 6561/6926 [15:48:33&lt;3:15:52, 32.20s/it]

{'epoch': 0, 'iter': 6560, 'avg_loss': 6.016903623613783, 'avg_acc': 50.002857796067666, 'loss': 6.09950590133667}


EP_train:0:  95%|| 6571/6926 [15:53:55&lt;3:12:46, 32.58s/it]

{'epoch': 0, 'iter': 6570, 'avg_loss': 6.01651362657293, 'avg_acc': 50.00095114898798, 'loss': 5.890357494354248}


EP_train:0:  95%|| 6581/6926 [15:59:16&lt;3:05:18, 32.23s/it]

{'epoch': 0, 'iter': 6580, 'avg_loss': 6.016133970736806, 'avg_acc': 50.00047485184622, 'loss': 5.606696128845215}


EP_train:0:  95%|| 6591/6926 [16:04:38&lt;2:58:55, 32.05s/it]

{'epoch': 0, 'iter': 6590, 'avg_loss': 6.015973757872757, 'avg_acc': 50.00379305113033, 'loss': 6.242420196533203}


EP_train:0:  95%|| 6601/6926 [16:10:02&lt;2:56:25, 32.57s/it]

{'epoch': 0, 'iter': 6600, 'avg_loss': 6.01564334201336, 'avg_acc': 50.00047341311923, 'loss': 5.982399940490723}


EP_train:0:  95%|| 6611/6926 [16:15:23&lt;2:47:34, 31.92s/it]

{'epoch': 0, 'iter': 6610, 'avg_loss': 6.015625978053527, 'avg_acc': 50.000945394040244, 'loss': 6.09565544128418}


EP_train:0:  96%|| 6621/6926 [16:20:51&lt;2:46:23, 32.73s/it]

{'epoch': 0, 'iter': 6620, 'avg_loss': 6.01537481828536, 'avg_acc': 49.99386421990636, 'loss': 5.418523788452148}


EP_train:0:  96%|| 6631/6926 [16:24:03&lt;1:36:19, 19.59s/it]

{'epoch': 0, 'iter': 6630, 'avg_loss': 6.015127572407821, 'avg_acc': 49.99387347308099, 'loss': 5.733451843261719}


EP_train:0:  96%|| 6641/6926 [16:27:15&lt;1:31:34, 19.28s/it]

{'epoch': 0, 'iter': 6640, 'avg_loss': 6.014838525355356, 'avg_acc': 49.993882698388795, 'loss': 5.605808734893799}


EP_train:0:  96%|| 6651/6926 [16:30:28&lt;1:28:27, 19.30s/it]

{'epoch': 0, 'iter': 6650, 'avg_loss': 6.014767191173833, 'avg_acc': 49.99718087505639, 'loss': 5.6949782371521}


EP_train:0:  96%|| 6661/6926 [16:33:41&lt;1:24:59, 19.24s/it]

{'epoch': 0, 'iter': 6660, 'avg_loss': 6.014458387504019, 'avg_acc': 49.99014787569434, 'loss': 6.062519550323486}


EP_train:0:  96%|| 6671/6926 [16:36:53&lt;1:21:47, 19.25s/it]

{'epoch': 0, 'iter': 6670, 'avg_loss': 6.014176159636976, 'avg_acc': 49.98688352570829, 'loss': 5.965818405151367}


EP_train:0:  96%|| 6681/6926 [16:40:06&lt;1:18:49, 19.30s/it]

{'epoch': 0, 'iter': 6680, 'avg_loss': 6.014068628852729, 'avg_acc': 49.9864354138602, 'loss': 6.070623397827148}


EP_train:0:  97%|| 6691/6926 [16:43:18&lt;1:15:06, 19.18s/it]

{'epoch': 0, 'iter': 6690, 'avg_loss': 6.013976595252463, 'avg_acc': 49.982719324465705, 'loss': 5.54081916809082}


EP_train:0:  97%|| 6701/6926 [16:46:30&lt;1:11:46, 19.14s/it]

{'epoch': 0, 'iter': 6700, 'avg_loss': 6.01353130815919, 'avg_acc': 49.98461050589464, 'loss': 5.863101005554199}


EP_train:0:  97%|| 6711/6926 [16:49:42&lt;1:08:45, 19.19s/it]

{'epoch': 0, 'iter': 6710, 'avg_loss': 6.0132572604369665, 'avg_acc': 49.9878930114737, 'loss': 5.598949432373047}


EP_train:0:  97%|| 6721/6926 [16:52:53&lt;1:05:14, 19.09s/it]

{'epoch': 0, 'iter': 6720, 'avg_loss': 6.013212072017416, 'avg_acc': 49.98279645886029, 'loss': 5.909557342529297}


EP_train:0:  97%|| 6731/6926 [16:56:05&lt;1:02:20, 19.18s/it]

{'epoch': 0, 'iter': 6730, 'avg_loss': 6.012646399959734, 'avg_acc': 49.98096493834497, 'loss': 5.427638053894043}


EP_train:0:  97%|| 6741/6926 [16:59:17&lt;58:58, 19.13s/it]  

{'epoch': 0, 'iter': 6740, 'avg_loss': 6.012475981625335, 'avg_acc': 49.97821168966029, 'loss': 5.700652122497559}


EP_train:0:  97%|| 6751/6926 [17:02:28&lt;55:46, 19.12s/it]

{'epoch': 0, 'iter': 6750, 'avg_loss': 6.012365468677424, 'avg_acc': 49.97963264701526, 'loss': 6.176610946655273}


EP_train:0:  98%|| 6761/6926 [17:05:40&lt;52:38, 19.14s/it]

{'epoch': 0, 'iter': 6760, 'avg_loss': 6.0121523709431886, 'avg_acc': 49.97550288418873, 'loss': 5.579730033874512}


EP_train:0:  98%|| 6771/6926 [17:08:52&lt;49:36, 19.20s/it]

{'epoch': 0, 'iter': 6770, 'avg_loss': 6.011860047392366, 'avg_acc': 49.983846551469505, 'loss': 5.901065826416016}


EP_train:0:  98%|| 6781/6926 [17:12:04&lt;46:35, 19.28s/it]

{'epoch': 0, 'iter': 6780, 'avg_loss': 6.011770728133348, 'avg_acc': 49.98018360123876, 'loss': 5.47562313079834}


EP_train:0:  98%|| 6791/6926 [17:15:16&lt;43:03, 19.14s/it]

{'epoch': 0, 'iter': 6790, 'avg_loss': 6.011512113941065, 'avg_acc': 49.97883227801502, 'loss': 6.059812545776367}


EP_train:0:  98%|| 6801/6926 [17:18:29&lt;40:03, 19.23s/it]

{'epoch': 0, 'iter': 6800, 'avg_loss': 6.011380450407594, 'avg_acc': 49.982998823702395, 'loss': 6.518869876861572}


EP_train:0:  98%|| 6811/6926 [17:21:41&lt;36:53, 19.25s/it]

{'epoch': 0, 'iter': 6810, 'avg_loss': 6.011360747438576, 'avg_acc': 49.98210615181324, 'loss': 6.399105548858643}


EP_train:0:  98%|| 6821/6926 [17:24:53&lt;33:36, 19.21s/it]

{'epoch': 0, 'iter': 6820, 'avg_loss': 6.01107167086107, 'avg_acc': 49.98946268875532, 'loss': 5.806404113769531}


EP_train:0:  99%|| 6831/6926 [17:28:05&lt;30:33, 19.30s/it]

{'epoch': 0, 'iter': 6830, 'avg_loss': 6.0108459484104255, 'avg_acc': 49.99039306104523, 'loss': 5.857755661010742}


EP_train:0:  99%|| 6841/6926 [17:31:17&lt;27:16, 19.25s/it]

{'epoch': 0, 'iter': 6840, 'avg_loss': 6.010873877362643, 'avg_acc': 49.98172781757053, 'loss': 5.758935928344727}


EP_train:0:  99%|| 6851/6926 [17:34:29&lt;23:59, 19.19s/it]

{'epoch': 0, 'iter': 6850, 'avg_loss': 6.010545881068405, 'avg_acc': 49.986772004086994, 'loss': 5.64037561416626}


EP_train:0:  99%|| 6861/6926 [17:37:42&lt;20:47, 19.20s/it]

{'epoch': 0, 'iter': 6860, 'avg_loss': 6.010220855200817, 'avg_acc': 49.983147500364375, 'loss': 5.707495212554932}


EP_train:0:  99%|| 6871/6926 [17:40:55&lt;17:38, 19.25s/it]

{'epoch': 0, 'iter': 6870, 'avg_loss': 6.010123378757548, 'avg_acc': 49.98317202736137, 'loss': 5.717169284820557}


EP_train:0:  99%|| 6881/6926 [17:44:08&lt;14:31, 19.37s/it]

{'epoch': 0, 'iter': 6880, 'avg_loss': 6.009998554997, 'avg_acc': 49.98728382502543, 'loss': 5.7754130363464355}


EP_train:0:  99%|| 6891/6926 [17:47:20&lt;11:12, 19.21s/it]

{'epoch': 0, 'iter': 6890, 'avg_loss': 6.009924337179217, 'avg_acc': 49.99093019881004, 'loss': 6.444478988647461}


EP_train:0: 100%|| 6901/6926 [17:50:32&lt;07:58, 19.14s/it]

{'epoch': 0, 'iter': 6900, 'avg_loss': 6.009942910305367, 'avg_acc': 49.985056513548756, 'loss': 6.345350742340088}


EP_train:0: 100%|| 6911/6926 [17:53:44&lt;04:49, 19.29s/it]

{'epoch': 0, 'iter': 6910, 'avg_loss': 6.009896017090316, 'avg_acc': 49.982817247865725, 'loss': 5.79774808883667}


EP_train:0: 100%|| 6921/6926 [17:56:57&lt;01:36, 19.38s/it]

{'epoch': 0, 'iter': 6920, 'avg_loss': 6.009602792241329, 'avg_acc': 49.977875307036555, 'loss': 5.463503837585449}


EP_train:0: 100%|| 6926/6926 [17:58:24&lt;00:00,  9.34s/it]


EP0, train:             avg_loss=6.009420036340153,             total_acc=49.97337737347484


EP_train:1:   0%|| 1/6926 [00:19&lt;36:46:00, 19.11s/it]

{'epoch': 1, 'iter': 0, 'avg_loss': 5.7898664474487305, 'avg_acc': 50.0, 'loss': 5.7898664474487305}


EP_train:1:   0%|| 11/6926 [03:30&lt;36:52:25, 19.20s/it]

{'epoch': 1, 'iter': 10, 'avg_loss': 5.765929655595259, 'avg_acc': 48.57954545454545, 'loss': 5.726385116577148}


EP_train:1:   0%|| 21/6926 [06:43&lt;36:49:29, 19.20s/it]

{'epoch': 1, 'iter': 20, 'avg_loss': 5.850452173323858, 'avg_acc': 49.107142857142854, 'loss': 6.110977649688721}


EP_train:1:   0%|| 31/6926 [09:55&lt;36:45:52, 19.20s/it]

{'epoch': 1, 'iter': 30, 'avg_loss': 5.828610743245771, 'avg_acc': 49.79838709677419, 'loss': 5.774191379547119}


EP_train:1:   1%|| 41/6926 [13:08&lt;36:47:37, 19.24s/it]

{'epoch': 1, 'iter': 40, 'avg_loss': 5.866406952462545, 'avg_acc': 49.390243902439025, 'loss': 6.16168737411499}


EP_train:1:   1%|| 51/6926 [16:20&lt;36:43:34, 19.23s/it]

{'epoch': 1, 'iter': 50, 'avg_loss': 5.8676528650171615, 'avg_acc': 50.18382352941176, 'loss': 6.630732536315918}


EP_train:1:   1%|| 61/6926 [19:33&lt;36:41:51, 19.24s/it]

{'epoch': 1, 'iter': 60, 'avg_loss': 5.888651972911397, 'avg_acc': 49.795081967213115, 'loss': 6.124413013458252}


EP_train:1:   1%|| 71/6926 [22:45&lt;36:27:43, 19.15s/it]

{'epoch': 1, 'iter': 70, 'avg_loss': 5.882588467127841, 'avg_acc': 49.603873239436616, 'loss': 6.333876132965088}


EP_train:1:   1%|| 81/6926 [25:57&lt;36:28:39, 19.18s/it]

{'epoch': 1, 'iter': 80, 'avg_loss': 5.870515434830277, 'avg_acc': 49.57561728395062, 'loss': 5.677712440490723}


EP_train:1:   1%|| 91/6926 [29:09&lt;36:19:29, 19.13s/it]

{'epoch': 1, 'iter': 90, 'avg_loss': 5.8840242218185255, 'avg_acc': 49.38186813186813, 'loss': 6.505983829498291}


EP_train:1:   1%|| 101/6926 [32:21&lt;36:33:20, 19.28s/it]

{'epoch': 1, 'iter': 100, 'avg_loss': 5.885297610027956, 'avg_acc': 49.597772277227726, 'loss': 5.711908340454102}


EP_train:1:   2%|| 111/6926 [35:34&lt;36:20:00, 19.19s/it]

{'epoch': 1, 'iter': 110, 'avg_loss': 5.881839593251546, 'avg_acc': 49.971846846846844, 'loss': 6.196578025817871}


EP_train:1:   2%|| 121/6926 [38:46&lt;36:19:01, 19.21s/it]

{'epoch': 1, 'iter': 120, 'avg_loss': 5.888786520839723, 'avg_acc': 50.15495867768595, 'loss': 6.299873352050781}


EP_train:1:   2%|| 131/6926 [41:59&lt;36:29:14, 19.33s/it]

{'epoch': 1, 'iter': 130, 'avg_loss': 5.88999764245885, 'avg_acc': 49.833015267175576, 'loss': 5.836378574371338}


EP_train:1:   2%|| 141/6926 [45:11&lt;36:15:45, 19.24s/it]

{'epoch': 1, 'iter': 140, 'avg_loss': 5.884459282489533, 'avg_acc': 49.75620567375886, 'loss': 5.787635326385498}


EP_train:1:   2%|| 151/6926 [48:25&lt;37:37:42, 19.99s/it]

{'epoch': 1, 'iter': 150, 'avg_loss': 5.880914773372625, 'avg_acc': 49.71026490066225, 'loss': 6.034032821655273}


EP_train:1:   2%|| 161/6926 [51:43&lt;36:35:31, 19.47s/it]

{'epoch': 1, 'iter': 160, 'avg_loss': 5.874822672849857, 'avg_acc': 49.767080745341616, 'loss': 5.685953140258789}


EP_train:1:   2%|| 171/6926 [54:55&lt;36:01:50, 19.20s/it]

{'epoch': 1, 'iter': 170, 'avg_loss': 5.86680287366722, 'avg_acc': 49.56140350877193, 'loss': 5.6062517166137695}


EP_train:1:   3%|| 181/6926 [58:06&lt;35:48:39, 19.11s/it]

{'epoch': 1, 'iter': 180, 'avg_loss': 5.8650890134316125, 'avg_acc': 49.568370165745854, 'loss': 5.928098201751709}


EP_train:1:   3%|| 191/6926 [1:01:18&lt;35:49:32, 19.15s/it]

{'epoch': 1, 'iter': 190, 'avg_loss': 5.858440072124541, 'avg_acc': 49.721858638743456, 'loss': 5.673971176147461}


EP_train:1:   3%|| 201/6926 [1:04:30&lt;35:50:35, 19.19s/it]

{'epoch': 1, 'iter': 200, 'avg_loss': 5.862566321643431, 'avg_acc': 49.93781094527363, 'loss': 5.701019763946533}


EP_train:1:   3%|| 211/6926 [1:07:42&lt;35:44:34, 19.16s/it]

{'epoch': 1, 'iter': 210, 'avg_loss': 5.860975496011887, 'avg_acc': 50.133293838862556, 'loss': 5.544591903686523}


EP_train:1:   3%|| 221/6926 [1:10:53&lt;35:38:59, 19.14s/it]

{'epoch': 1, 'iter': 220, 'avg_loss': 5.857743077688088, 'avg_acc': 50.04242081447964, 'loss': 5.729083061218262}


EP_train:1:   3%|| 231/6926 [1:14:05&lt;35:36:27, 19.15s/it]

{'epoch': 1, 'iter': 230, 'avg_loss': 5.858985324958702, 'avg_acc': 49.8241341991342, 'loss': 5.8883867263793945}


EP_train:1:   3%|| 241/6926 [1:17:17&lt;35:31:52, 19.13s/it]

{'epoch': 1, 'iter': 240, 'avg_loss': 5.85954476985694, 'avg_acc': 49.71473029045643, 'loss': 5.887384414672852}


EP_train:1:   4%|| 251/6926 [1:20:28&lt;35:27:21, 19.12s/it]

{'epoch': 1, 'iter': 250, 'avg_loss': 5.858979394236409, 'avg_acc': 49.813247011952186, 'loss': 5.831138610839844}


EP_train:1:   4%|| 261/6926 [1:23:39&lt;35:22:47, 19.11s/it]

{'epoch': 1, 'iter': 260, 'avg_loss': 5.859414310747637, 'avg_acc': 49.9161877394636, 'loss': 5.701999187469482}


EP_train:1:   4%|| 271/6926 [1:26:50&lt;35:19:55, 19.11s/it]

{'epoch': 1, 'iter': 270, 'avg_loss': 5.854931660683833, 'avg_acc': 50.04612546125461, 'loss': 6.198373794555664}


EP_train:1:   4%|| 281/6926 [1:30:02&lt;35:16:02, 19.11s/it]

{'epoch': 1, 'iter': 280, 'avg_loss': 5.85461603449757, 'avg_acc': 50.055604982206404, 'loss': 5.955772876739502}


EP_train:1:   4%|| 291/6926 [1:33:13&lt;35:13:11, 19.11s/it]

{'epoch': 1, 'iter': 290, 'avg_loss': 5.856383528496392, 'avg_acc': 50.2147766323024, 'loss': 6.128197193145752}


EP_train:1:   4%|| 301/6926 [1:36:24&lt;35:09:50, 19.11s/it]

{'epoch': 1, 'iter': 300, 'avg_loss': 5.856983832742685, 'avg_acc': 50.36337209302325, 'loss': 5.785074710845947}


EP_train:1:   4%|| 311/6926 [1:40:00&lt;36:27:03, 19.84s/it]

{'epoch': 1, 'iter': 310, 'avg_loss': 5.856134589462035, 'avg_acc': 50.34163987138264, 'loss': 6.169585704803467}


EP_train:1:   5%|| 321/6926 [1:43:12&lt;35:13:36, 19.20s/it]

{'epoch': 1, 'iter': 320, 'avg_loss': 5.855534742183032, 'avg_acc': 50.28232087227414, 'loss': 5.786722660064697}


EP_train:1:   5%|| 331/6926 [1:46:24&lt;35:08:30, 19.18s/it]

{'epoch': 1, 'iter': 330, 'avg_loss': 5.855514389510601, 'avg_acc': 50.16993957703928, 'loss': 5.721573352813721}


EP_train:1:   5%|| 341/6926 [1:49:36&lt;35:01:51, 19.15s/it]

{'epoch': 1, 'iter': 340, 'avg_loss': 5.854255662286037, 'avg_acc': 50.1741202346041, 'loss': 6.028651714324951}


EP_train:1:   5%|| 351/6926 [1:52:48&lt;35:03:42, 19.20s/it]

{'epoch': 1, 'iter': 350, 'avg_loss': 5.858589369347293, 'avg_acc': 50.32941595441596, 'loss': 5.835811138153076}


EP_train:1:   5%|| 361/6926 [1:56:01&lt;35:11:13, 19.30s/it]

{'epoch': 1, 'iter': 360, 'avg_loss': 5.859188112855948, 'avg_acc': 50.3722299168975, 'loss': 5.411815166473389}


EP_train:1:   5%|| 371/6926 [1:59:13&lt;34:54:57, 19.18s/it]

{'epoch': 1, 'iter': 370, 'avg_loss': 5.860896775022028, 'avg_acc': 50.19373315363881, 'loss': 6.040600776672363}


EP_train:1:   6%|| 381/6926 [2:02:25&lt;34:55:23, 19.21s/it]

{'epoch': 1, 'iter': 380, 'avg_loss': 5.861102593539581, 'avg_acc': 50.22145669291339, 'loss': 5.881434440612793}


EP_train:1:   6%|| 391/6926 [2:05:36&lt;34:45:56, 19.15s/it]

{'epoch': 1, 'iter': 390, 'avg_loss': 5.863249294593206, 'avg_acc': 50.1358695652174, 'loss': 5.768378257751465}


EP_train:1:   6%|| 401/6926 [2:08:48&lt;34:51:26, 19.23s/it]

{'epoch': 1, 'iter': 400, 'avg_loss': 5.861934682080276, 'avg_acc': 50.093516209476306, 'loss': 6.008617401123047}


EP_train:1:   6%|| 411/6926 [2:12:01&lt;34:48:24, 19.23s/it]

{'epoch': 1, 'iter': 410, 'avg_loss': 5.8630056404429345, 'avg_acc': 50.04562043795621, 'loss': 5.907751083374023}


EP_train:1:   6%|| 421/6926 [2:15:14&lt;34:50:33, 19.28s/it]

{'epoch': 1, 'iter': 420, 'avg_loss': 5.867002961754515, 'avg_acc': 50.0, 'loss': 5.6928911209106445}


EP_train:1:   6%|| 431/6926 [2:18:27&lt;34:44:33, 19.26s/it]

{'epoch': 1, 'iter': 430, 'avg_loss': 5.86686744048258, 'avg_acc': 50.050754060324834, 'loss': 5.937226295471191}


EP_train:1:   6%|| 441/6926 [2:21:39&lt;34:33:30, 19.18s/it]

{'epoch': 1, 'iter': 440, 'avg_loss': 5.867215950202509, 'avg_acc': 50.05668934240363, 'loss': 5.970946311950684}


EP_train:1:   7%|| 451/6926 [2:24:50&lt;34:21:58, 19.11s/it]

{'epoch': 1, 'iter': 450, 'avg_loss': 5.867052065559607, 'avg_acc': 50.0069290465632, 'loss': 6.138850688934326}


EP_train:1:   7%|| 461/6926 [2:28:02&lt;34:31:22, 19.22s/it]

{'epoch': 1, 'iter': 460, 'avg_loss': 5.865982198404904, 'avg_acc': 49.97966377440347, 'loss': 5.222504138946533}


EP_train:1:   7%|| 471/6926 [2:31:15&lt;34:41:26, 19.35s/it]

{'epoch': 1, 'iter': 470, 'avg_loss': 5.867836634318034, 'avg_acc': 49.90047770700637, 'loss': 5.999167442321777}


EP_train:1:   7%|| 481/6926 [2:34:27&lt;34:24:09, 19.22s/it]

{'epoch': 1, 'iter': 480, 'avg_loss': 5.866187658726302, 'avg_acc': 49.95452182952183, 'loss': 5.776668071746826}


EP_train:1:   7%|| 491/6926 [2:37:40&lt;34:26:38, 19.27s/it]

{'epoch': 1, 'iter': 490, 'avg_loss': 5.867664511966122, 'avg_acc': 49.980906313645626, 'loss': 5.901947498321533}


EP_train:1:   7%|| 501/6926 [2:40:52&lt;34:19:01, 19.23s/it]

{'epoch': 1, 'iter': 500, 'avg_loss': 5.86596357893801, 'avg_acc': 49.962574850299404, 'loss': 5.214600086212158}


EP_train:1:   7%|| 511/6926 [2:44:04&lt;34:05:07, 19.13s/it]

{'epoch': 1, 'iter': 510, 'avg_loss': 5.864071903863298, 'avg_acc': 49.97553816046967, 'loss': 5.491891860961914}


EP_train:1:   8%|| 521/6926 [2:47:16&lt;34:13:17, 19.23s/it]

{'epoch': 1, 'iter': 520, 'avg_loss': 5.865162833867283, 'avg_acc': 50.03598848368522, 'loss': 6.381423473358154}


EP_train:1:   8%|| 531/6926 [2:50:28&lt;34:06:15, 19.20s/it]

{'epoch': 1, 'iter': 530, 'avg_loss': 5.864204099622824, 'avg_acc': 50.02354048964218, 'loss': 5.515666961669922}


EP_train:1:   8%|| 541/6926 [2:53:40&lt;33:57:02, 19.14s/it]

{'epoch': 1, 'iter': 540, 'avg_loss': 5.861967081503595, 'avg_acc': 49.98844731977819, 'loss': 5.428747177124023}


EP_train:1:   8%|| 551/6926 [2:56:52&lt;34:08:43, 19.28s/it]

{'epoch': 1, 'iter': 550, 'avg_loss': 5.862547218475065, 'avg_acc': 49.96029945553539, 'loss': 6.113502502441406}


EP_train:1:   8%|| 561/6926 [3:00:05&lt;33:59:46, 19.23s/it]

{'epoch': 1, 'iter': 560, 'avg_loss': 5.861968838594814, 'avg_acc': 49.94986631016043, 'loss': 5.945765972137451}


EP_train:1:   8%|| 571/6926 [3:03:18&lt;34:13:21, 19.39s/it]

{'epoch': 1, 'iter': 570, 'avg_loss': 5.860212508099718, 'avg_acc': 49.91243432574431, 'loss': 5.618706226348877}


EP_train:1:   8%|| 581/6926 [3:06:31&lt;34:11:43, 19.40s/it]

{'epoch': 1, 'iter': 580, 'avg_loss': 5.860705601368837, 'avg_acc': 49.87091222030981, 'loss': 5.72037935256958}


EP_train:1:   9%|| 591/6926 [3:09:42&lt;33:43:02, 19.16s/it]

{'epoch': 1, 'iter': 590, 'avg_loss': 5.861424665564006, 'avg_acc': 49.84137055837564, 'loss': 6.172145366668701}


EP_train:1:   9%|| 601/6926 [3:12:54&lt;33:43:10, 19.19s/it]

{'epoch': 1, 'iter': 600, 'avg_loss': 5.8617067448113005, 'avg_acc': 49.802412645590685, 'loss': 5.886046886444092}


EP_train:1:   9%|| 611/6926 [3:16:05&lt;33:27:18, 19.07s/it]

{'epoch': 1, 'iter': 610, 'avg_loss': 5.859487274469603, 'avg_acc': 49.86190671031097, 'loss': 5.65408182144165}


EP_train:1:   9%|| 621/6926 [3:19:18&lt;33:41:21, 19.24s/it]

{'epoch': 1, 'iter': 620, 'avg_loss': 5.857120867128725, 'avg_acc': 49.81884057971014, 'loss': 5.547512054443359}


EP_train:1:   9%|| 631/6926 [3:22:30&lt;33:32:23, 19.18s/it]

{'epoch': 1, 'iter': 630, 'avg_loss': 5.8560241882094495, 'avg_acc': 49.74247226624406, 'loss': 5.398869037628174}


EP_train:1:   9%|| 641/6926 [3:25:42&lt;33:37:38, 19.26s/it]

{'epoch': 1, 'iter': 640, 'avg_loss': 5.856239571772202, 'avg_acc': 49.765990639625585, 'loss': 5.919886112213135}


EP_train:1:   9%|| 651/6926 [3:28:54&lt;33:31:15, 19.23s/it]

{'epoch': 1, 'iter': 650, 'avg_loss': 5.854985670743083, 'avg_acc': 49.78878648233487, 'loss': 5.877474784851074}


EP_train:1:  10%|| 661/6926 [3:32:06&lt;33:25:43, 19.21s/it]

{'epoch': 1, 'iter': 660, 'avg_loss': 5.854530731235799, 'avg_acc': 49.787254160363084, 'loss': 5.628725051879883}


EP_train:1:  10%|| 671/6926 [3:35:20&lt;33:41:36, 19.39s/it]

{'epoch': 1, 'iter': 670, 'avg_loss': 5.853959171676067, 'avg_acc': 49.72056631892697, 'loss': 5.894036293029785}


EP_train:1:  10%|| 681/6926 [3:38:34&lt;33:38:06, 19.39s/it]

{'epoch': 1, 'iter': 680, 'avg_loss': 5.852304049000341, 'avg_acc': 49.70172540381792, 'loss': 5.862987041473389}


EP_train:1:  10%|| 691/6926 [3:41:47&lt;33:26:31, 19.31s/it]

{'epoch': 1, 'iter': 690, 'avg_loss': 5.85155159623164, 'avg_acc': 49.696997105643995, 'loss': 5.2892937660217285}


EP_train:1:  10%|| 701/6926 [3:45:01&lt;33:45:03, 19.52s/it]

{'epoch': 1, 'iter': 700, 'avg_loss': 5.851237080066588, 'avg_acc': 49.67011412268189, 'loss': 6.079766750335693}


EP_train:1:  10%|| 711/6926 [3:48:13&lt;33:09:23, 19.21s/it]

{'epoch': 1, 'iter': 710, 'avg_loss': 5.850454349222733, 'avg_acc': 49.67475386779184, 'loss': 5.564901351928711}


EP_train:1:  10%|| 721/6926 [3:51:26&lt;33:13:57, 19.28s/it]

{'epoch': 1, 'iter': 720, 'avg_loss': 5.852251948992852, 'avg_acc': 49.71393897364771, 'loss': 5.800187110900879}


EP_train:1:  11%|| 731/6926 [3:54:38&lt;32:59:39, 19.17s/it]

{'epoch': 1, 'iter': 730, 'avg_loss': 5.850966430069158, 'avg_acc': 49.64517783857729, 'loss': 5.609173774719238}


EP_train:1:  11%|| 741/6926 [3:57:50&lt;32:54:25, 19.15s/it]

{'epoch': 1, 'iter': 740, 'avg_loss': 5.850172593043401, 'avg_acc': 49.61201079622132, 'loss': 6.199341773986816}


EP_train:1:  11%|| 751/6926 [4:01:02&lt;32:54:09, 19.18s/it]

{'epoch': 1, 'iter': 750, 'avg_loss': 5.850118440889646, 'avg_acc': 49.604693741677764, 'loss': 5.561918258666992}


EP_train:1:  11%|| 761/6926 [4:04:14&lt;32:55:36, 19.23s/it]

{'epoch': 1, 'iter': 760, 'avg_loss': 5.848167900656902, 'avg_acc': 49.5811432325887, 'loss': 5.6837334632873535}


EP_train:1:  11%|| 771/6926 [4:07:26&lt;32:47:00, 19.17s/it]

{'epoch': 1, 'iter': 770, 'avg_loss': 5.847578158174508, 'avg_acc': 49.54199092088197, 'loss': 5.642725944519043}


EP_train:1:  11%|| 781/6926 [4:10:39&lt;33:14:22, 19.47s/it]

{'epoch': 1, 'iter': 780, 'avg_loss': 5.848220976610953, 'avg_acc': 49.51984635083227, 'loss': 5.483386039733887}


EP_train:1:  11%|| 791/6926 [4:13:52&lt;33:04:24, 19.41s/it]

{'epoch': 1, 'iter': 790, 'avg_loss': 5.848804213455142, 'avg_acc': 49.48245891276864, 'loss': 5.911666393280029}


EP_train:1:  12%|| 801/6926 [4:17:04&lt;32:46:01, 19.26s/it]

{'epoch': 1, 'iter': 800, 'avg_loss': 5.849996216734697, 'avg_acc': 49.51622971285893, 'loss': 5.937110424041748}


EP_train:1:  12%|| 811/6926 [4:20:17&lt;32:40:29, 19.24s/it]

{'epoch': 1, 'iter': 810, 'avg_loss': 5.850373899598598, 'avg_acc': 49.533754623921084, 'loss': 5.817855358123779}


EP_train:1:  12%|| 821/6926 [4:23:28&lt;32:27:11, 19.14s/it]

{'epoch': 1, 'iter': 820, 'avg_loss': 5.85045076839526, 'avg_acc': 49.57369062119367, 'loss': 6.1385698318481445}


EP_train:1:  12%|| 831/6926 [4:26:40&lt;32:26:16, 19.16s/it]

{'epoch': 1, 'iter': 830, 'avg_loss': 5.850518212278254, 'avg_acc': 49.575060168471715, 'loss': 5.991103649139404}


EP_train:1:  12%|| 841/6926 [4:29:51&lt;32:25:23, 19.18s/it]

{'epoch': 1, 'iter': 840, 'avg_loss': 5.849334524587842, 'avg_acc': 49.60240784780024, 'loss': 5.678135871887207}


EP_train:1:  12%|| 851/6926 [4:33:03&lt;32:18:04, 19.14s/it]

{'epoch': 1, 'iter': 850, 'avg_loss': 5.850284370216164, 'avg_acc': 49.61075205640423, 'loss': 6.211353302001953}


EP_train:1:  12%|| 861/6926 [4:36:15&lt;32:28:07, 19.27s/it]

{'epoch': 1, 'iter': 860, 'avg_loss': 5.849237011700142, 'avg_acc': 49.60075493612079, 'loss': 5.670510768890381}


EP_train:1:  13%|| 871/6926 [4:39:27&lt;32:17:37, 19.20s/it]

{'epoch': 1, 'iter': 870, 'avg_loss': 5.849724954086111, 'avg_acc': 49.60533869115958, 'loss': 5.823276519775391}


EP_train:1:  13%|| 881/6926 [4:42:40&lt;32:22:11, 19.28s/it]

{'epoch': 1, 'iter': 880, 'avg_loss': 5.848760309338434, 'avg_acc': 49.5849886492622, 'loss': 5.7896904945373535}


EP_train:1:  13%|| 891/6926 [4:45:53&lt;32:20:24, 19.29s/it]

{'epoch': 1, 'iter': 890, 'avg_loss': 5.848237068698596, 'avg_acc': 49.56509539842873, 'loss': 5.874814510345459}


EP_train:1:  13%|| 901/6926 [4:49:05&lt;32:04:59, 19.17s/it]

{'epoch': 1, 'iter': 900, 'avg_loss': 5.847013555541552, 'avg_acc': 49.55951720310765, 'loss': 5.768845558166504}


EP_train:1:  13%|| 911/6926 [4:52:17&lt;32:02:40, 19.18s/it]

{'epoch': 1, 'iter': 910, 'avg_loss': 5.846529427265624, 'avg_acc': 49.58493413830955, 'loss': 5.537152290344238}


EP_train:1:  13%|| 921/6926 [4:55:28&lt;31:56:22, 19.15s/it]

{'epoch': 1, 'iter': 920, 'avg_loss': 5.845628834184943, 'avg_acc': 49.582654723127035, 'loss': 5.630972385406494}


EP_train:1:  13%|| 931/6926 [4:58:40&lt;31:58:08, 19.20s/it]

{'epoch': 1, 'iter': 930, 'avg_loss': 5.845260304103732, 'avg_acc': 49.57706766917293, 'loss': 5.698583126068115}


EP_train:1:  14%|| 941/6926 [5:01:52&lt;31:54:49, 19.20s/it]

{'epoch': 1, 'iter': 940, 'avg_loss': 5.846199887465215, 'avg_acc': 49.58488310308183, 'loss': 5.645341396331787}


EP_train:1:  14%|| 951/6926 [5:05:05&lt;31:50:53, 19.19s/it]

{'epoch': 1, 'iter': 950, 'avg_loss': 5.845864964333744, 'avg_acc': 49.66811251314406, 'loss': 5.785149574279785}


EP_train:1:  14%|| 961/6926 [5:08:17&lt;31:49:16, 19.20s/it]

{'epoch': 1, 'iter': 960, 'avg_loss': 5.844765096499694, 'avg_acc': 49.69107700312175, 'loss': 5.350743293762207}


EP_train:1:  14%|| 971/6926 [5:11:30&lt;31:49:19, 19.24s/it]

{'epoch': 1, 'iter': 970, 'avg_loss': 5.844221463777992, 'avg_acc': 49.70391349124614, 'loss': 6.132320404052734}


EP_train:1:  14%|| 981/6926 [5:14:42&lt;31:50:05, 19.28s/it]

{'epoch': 1, 'iter': 980, 'avg_loss': 5.84315927799081, 'avg_acc': 49.691004077471966, 'loss': 5.966439723968506}


EP_train:1:  14%|| 991/6926 [5:17:54&lt;31:34:07, 19.15s/it]

{'epoch': 1, 'iter': 990, 'avg_loss': 5.8421003638074085, 'avg_acc': 49.70358224016145, 'loss': 5.977272033691406}


EP_train:1:  14%|| 1001/6926 [5:21:06&lt;31:38:48, 19.23s/it]

{'epoch': 1, 'iter': 1000, 'avg_loss': 5.842337221532435, 'avg_acc': 49.72215284715284, 'loss': 5.648003101348877}


EP_train:1:  15%|| 1011/6926 [5:24:19&lt;31:33:44, 19.21s/it]

{'epoch': 1, 'iter': 1010, 'avg_loss': 5.842143786531292, 'avg_acc': 49.78363006923838, 'loss': 5.270914554595947}


EP_train:1:  15%|| 1021/6926 [5:27:30&lt;31:27:52, 19.18s/it]

{'epoch': 1, 'iter': 1020, 'avg_loss': 5.842267990579335, 'avg_acc': 49.767384916748284, 'loss': 5.850009918212891}


EP_train:1:  15%|| 1031/6926 [5:30:43&lt;31:43:02, 19.37s/it]

{'epoch': 1, 'iter': 1030, 'avg_loss': 5.8431478721441055, 'avg_acc': 49.73326867119302, 'loss': 6.137674331665039}


EP_train:1:  15%|| 1041/6926 [5:33:55&lt;31:20:01, 19.17s/it]

{'epoch': 1, 'iter': 1040, 'avg_loss': 5.843129161226417, 'avg_acc': 49.74183477425552, 'loss': 5.970772743225098}


EP_train:1:  15%|| 1051/6926 [5:37:07&lt;31:25:16, 19.25s/it]

{'epoch': 1, 'iter': 1050, 'avg_loss': 5.8425049609393875, 'avg_acc': 49.72942435775452, 'loss': 5.395400047302246}


EP_train:1:  15%|| 1061/6926 [5:40:20&lt;31:27:50, 19.31s/it]

{'epoch': 1, 'iter': 1060, 'avg_loss': 5.841531728372385, 'avg_acc': 49.7496465598492, 'loss': 6.239808082580566}


EP_train:1:  15%|| 1071/6926 [5:43:32&lt;31:13:34, 19.20s/it]

{'epoch': 1, 'iter': 1070, 'avg_loss': 5.840466057664317, 'avg_acc': 49.78699813258637, 'loss': 6.059412002563477}


EP_train:1:  16%|| 1081/6926 [5:46:45&lt;31:21:29, 19.31s/it]

{'epoch': 1, 'iter': 1080, 'avg_loss': 5.840707620573088, 'avg_acc': 49.77740518038853, 'loss': 5.7304911613464355}


EP_train:1:  16%|| 1091/6926 [5:49:57&lt;31:07:16, 19.20s/it]

{'epoch': 1, 'iter': 1090, 'avg_loss': 5.839890107662715, 'avg_acc': 49.785174152153985, 'loss': 6.10009241104126}


EP_train:1:  16%|| 1101/6926 [5:53:09&lt;31:07:11, 19.23s/it]

{'epoch': 1, 'iter': 1100, 'avg_loss': 5.841028182318166, 'avg_acc': 49.77861035422343, 'loss': 5.7616424560546875}


EP_train:1:  16%|| 1111/6926 [5:56:22&lt;31:19:14, 19.39s/it]

{'epoch': 1, 'iter': 1110, 'avg_loss': 5.839225487060959, 'avg_acc': 49.78622862286229, 'loss': 5.515673637390137}


EP_train:1:  16%|| 1121/6926 [5:59:34&lt;30:58:29, 19.21s/it]

{'epoch': 1, 'iter': 1120, 'avg_loss': 5.8397217451941215, 'avg_acc': 49.79371097234612, 'loss': 6.025796890258789}


EP_train:1:  16%|| 1131/6926 [6:02:47&lt;31:00:03, 19.26s/it]

{'epoch': 1, 'iter': 1130, 'avg_loss': 5.837902028195948, 'avg_acc': 49.798297966401414, 'loss': 5.794040679931641}


EP_train:1:  16%|| 1141/6926 [6:06:00&lt;30:55:24, 19.24s/it]

{'epoch': 1, 'iter': 1140, 'avg_loss': 5.837508106733184, 'avg_acc': 49.772677475898334, 'loss': 6.092175006866455}


EP_train:1:  17%|| 1151/6926 [6:09:12&lt;30:51:07, 19.23s/it]

{'epoch': 1, 'iter': 1150, 'avg_loss': 5.837949460739679, 'avg_acc': 49.80180278019114, 'loss': 6.035767555236816}


EP_train:1:  17%|| 1161/6926 [6:12:25&lt;30:54:28, 19.30s/it]

{'epoch': 1, 'iter': 1160, 'avg_loss': 5.8369841148481605, 'avg_acc': 49.822351421188635, 'loss': 5.83712100982666}


EP_train:1:  17%|| 1171/6926 [6:15:38&lt;30:57:23, 19.36s/it]

{'epoch': 1, 'iter': 1170, 'avg_loss': 5.837335775083807, 'avg_acc': 49.82386848847139, 'loss': 5.484726428985596}


EP_train:1:  17%|| 1181/6926 [6:18:51&lt;30:41:29, 19.23s/it]

{'epoch': 1, 'iter': 1180, 'avg_loss': 5.8367451983523715, 'avg_acc': 49.8174216765453, 'loss': 5.847054958343506}


EP_train:1:  17%|| 1191/6926 [6:22:03&lt;30:35:54, 19.21s/it]

{'epoch': 1, 'iter': 1190, 'avg_loss': 5.836948211006914, 'avg_acc': 49.78222082283795, 'loss': 5.790893077850342}


EP_train:1:  17%|| 1201/6926 [6:25:16&lt;30:32:44, 19.21s/it]

{'epoch': 1, 'iter': 1200, 'avg_loss': 5.837502387441465, 'avg_acc': 49.76842214820982, 'loss': 5.365159511566162}


EP_train:1:  17%|| 1211/6926 [6:28:28&lt;30:27:13, 19.18s/it]

{'epoch': 1, 'iter': 1210, 'avg_loss': 5.83753428707233, 'avg_acc': 49.744529314616024, 'loss': 6.047626972198486}


EP_train:1:  18%|| 1221/6926 [6:31:40&lt;30:25:00, 19.19s/it]

{'epoch': 1, 'iter': 1220, 'avg_loss': 5.836108738042408, 'avg_acc': 49.74662162162162, 'loss': 5.518049240112305}


EP_train:1:  18%|| 1231/6926 [6:34:52&lt;30:21:39, 19.19s/it]

{'epoch': 1, 'iter': 1230, 'avg_loss': 5.836604392208964, 'avg_acc': 49.77406580016247, 'loss': 5.829573154449463}


EP_train:1:  18%|| 1241/6926 [6:38:06&lt;30:44:37, 19.47s/it]

{'epoch': 1, 'iter': 1240, 'avg_loss': 5.83546933505345, 'avg_acc': 49.77840451248993, 'loss': 5.50302267074585}


EP_train:1:  18%|| 1251/6926 [6:41:20&lt;30:47:25, 19.53s/it]

{'epoch': 1, 'iter': 1250, 'avg_loss': 5.836626249156315, 'avg_acc': 49.80515587529976, 'loss': 6.165284156799316}


EP_train:1:  18%|| 1261/6926 [6:44:34&lt;30:22:26, 19.30s/it]

{'epoch': 1, 'iter': 1260, 'avg_loss': 5.835903795818598, 'avg_acc': 49.79926645519429, 'loss': 6.05486536026001}


EP_train:1:  18%|| 1271/6926 [6:47:47&lt;30:15:58, 19.27s/it]

{'epoch': 1, 'iter': 1270, 'avg_loss': 5.837218529215767, 'avg_acc': 49.795928402832416, 'loss': 5.663443088531494}


EP_train:1:  18%|| 1281/6926 [6:51:00&lt;30:19:22, 19.34s/it]

{'epoch': 1, 'iter': 1280, 'avg_loss': 5.838011113672309, 'avg_acc': 49.799960967993755, 'loss': 5.5717453956604}


EP_train:1:  19%|| 1291/6926 [6:54:13&lt;30:18:35, 19.36s/it]

{'epoch': 1, 'iter': 1290, 'avg_loss': 5.8368172656649495, 'avg_acc': 49.80877226955848, 'loss': 5.385322093963623}


EP_train:1:  19%|| 1301/6926 [6:57:27&lt;30:20:54, 19.42s/it]

{'epoch': 1, 'iter': 1300, 'avg_loss': 5.835430765042023, 'avg_acc': 49.80784012298232, 'loss': 5.272273540496826}


EP_train:1:  19%|| 1311/6926 [7:00:41&lt;30:13:15, 19.38s/it]

{'epoch': 1, 'iter': 1310, 'avg_loss': 5.834374673306533, 'avg_acc': 49.82360793287567, 'loss': 5.6404571533203125}


EP_train:1:  19%|| 1321/6926 [7:03:56&lt;30:15:11, 19.43s/it]

{'epoch': 1, 'iter': 1320, 'avg_loss': 5.834086731471048, 'avg_acc': 49.81311506434519, 'loss': 6.042065620422363}


EP_train:1:  19%|| 1331/6926 [7:07:10&lt;30:05:33, 19.36s/it]

{'epoch': 1, 'iter': 1330, 'avg_loss': 5.833662637456927, 'avg_acc': 49.7980841472577, 'loss': 5.997086524963379}


EP_train:1:  19%|| 1341/6926 [7:10:25&lt;30:11:19, 19.46s/it]

{'epoch': 1, 'iter': 1340, 'avg_loss': 5.831286788075651, 'avg_acc': 49.79026845637584, 'loss': 5.13810396194458}


EP_train:1:  20%|| 1351/6926 [7:13:38&lt;30:01:40, 19.39s/it]

{'epoch': 1, 'iter': 1350, 'avg_loss': 5.830443996045433, 'avg_acc': 49.78025536639527, 'loss': 6.180279731750488}


EP_train:1:  20%|| 1361/6926 [7:16:53&lt;30:06:20, 19.48s/it]

{'epoch': 1, 'iter': 1360, 'avg_loss': 5.831139720423444, 'avg_acc': 49.81171932402645, 'loss': 5.738363742828369}


EP_train:1:  20%|| 1371/6926 [7:20:14&lt;33:19:54, 21.60s/it]

{'epoch': 1, 'iter': 1370, 'avg_loss': 5.831161075052251, 'avg_acc': 49.80625455871627, 'loss': 5.848499298095703}


EP_train:1:  20%|| 1381/6926 [7:24:08&lt;31:00:36, 20.13s/it]

{'epoch': 1, 'iter': 1380, 'avg_loss': 5.831336831114242, 'avg_acc': 49.82349746560463, 'loss': 5.313791275024414}


EP_train:1:  20%|| 1391/6926 [7:27:23&lt;29:51:22, 19.42s/it]

{'epoch': 1, 'iter': 1390, 'avg_loss': 5.830504140092862, 'avg_acc': 49.800053918044576, 'loss': 5.489503860473633}


EP_train:1:  20%|| 1401/6926 [7:30:36&lt;29:45:56, 19.39s/it]

{'epoch': 1, 'iter': 1400, 'avg_loss': 5.8311854865532275, 'avg_acc': 49.81486438258387, 'loss': 5.570352077484131}


EP_train:1:  20%|| 1411/6926 [7:33:50&lt;29:44:40, 19.42s/it]

{'epoch': 1, 'iter': 1410, 'avg_loss': 5.831230178105755, 'avg_acc': 49.81839121190645, 'loss': 5.9099040031433105}


EP_train:1:  21%|| 1421/6926 [7:37:04&lt;29:36:52, 19.37s/it]

{'epoch': 1, 'iter': 1420, 'avg_loss': 5.830774644157737, 'avg_acc': 49.80207600281492, 'loss': 5.86726188659668}


EP_train:1:  21%|| 1431/6926 [7:40:19&lt;29:42:58, 19.47s/it]

{'epoch': 1, 'iter': 1430, 'avg_loss': 5.8307352695824965, 'avg_acc': 49.79472396925227, 'loss': 5.561969757080078}


EP_train:1:  21%|| 1441/6926 [7:43:34&lt;29:48:26, 19.56s/it]

{'epoch': 1, 'iter': 1440, 'avg_loss': 5.83044555797749, 'avg_acc': 49.8265093684941, 'loss': 5.945946216583252}


EP_train:1:  21%|| 1451/6926 [7:46:49&lt;29:32:47, 19.43s/it]

{'epoch': 1, 'iter': 1450, 'avg_loss': 5.830807990488885, 'avg_acc': 49.825551343900756, 'loss': 5.711259365081787}


EP_train:1:  21%|| 1461/6926 [7:50:03&lt;29:25:33, 19.38s/it]

{'epoch': 1, 'iter': 1460, 'avg_loss': 5.8303068593134215, 'avg_acc': 49.841718001368925, 'loss': 5.9310078620910645}


EP_train:1:  21%|| 1471/6926 [7:53:23&lt;29:56:43, 19.76s/it]

{'epoch': 1, 'iter': 1470, 'avg_loss': 5.829525811100071, 'avg_acc': 49.83642080217539, 'loss': 5.824807167053223}


EP_train:1:  21%|| 1481/6926 [7:58:23&lt;48:14:59, 31.90s/it]

{'epoch': 1, 'iter': 1480, 'avg_loss': 5.828599950093663, 'avg_acc': 49.80376434841323, 'loss': 5.627674102783203}


EP_train:1:  22%|| 1491/6926 [8:03:48&lt;48:43:50, 32.28s/it]

{'epoch': 1, 'iter': 1490, 'avg_loss': 5.828133173711663, 'avg_acc': 49.80508048289739, 'loss': 5.458308219909668}


EP_train:1:  22%|| 1501/6926 [8:09:13&lt;49:11:50, 32.65s/it]

{'epoch': 1, 'iter': 1500, 'avg_loss': 5.827345010362253, 'avg_acc': 49.81054297135243, 'loss': 6.186519145965576}


EP_train:1:  22%|| 1511/6926 [8:14:37&lt;48:40:35, 32.36s/it]

{'epoch': 1, 'iter': 1510, 'avg_loss': 5.828246969958949, 'avg_acc': 49.82834215751158, 'loss': 5.6483941078186035}


EP_train:1:  22%|| 1521/6926 [8:18:31&lt;30:54:09, 20.58s/it]

{'epoch': 1, 'iter': 1520, 'avg_loss': 5.827747987650634, 'avg_acc': 49.80481591058514, 'loss': 5.682420253753662}


EP_train:1:  22%|| 1531/6926 [8:21:45&lt;29:04:30, 19.40s/it]

{'epoch': 1, 'iter': 1530, 'avg_loss': 5.8276047756436755, 'avg_acc': 49.781596995427826, 'loss': 5.823483943939209}


EP_train:1:  22%|| 1541/6926 [8:25:00&lt;29:08:31, 19.48s/it]

{'epoch': 1, 'iter': 1540, 'avg_loss': 5.827125796863276, 'avg_acc': 49.748539909149905, 'loss': 5.908112049102783}


EP_train:1:  22%|| 1551/6926 [8:28:13&lt;28:53:38, 19.35s/it]

{'epoch': 1, 'iter': 1550, 'avg_loss': 5.826776943538821, 'avg_acc': 49.715909090909086, 'loss': 5.829923629760742}


EP_train:1:  23%|| 1561/6926 [8:31:29&lt;28:59:51, 19.46s/it]

{'epoch': 1, 'iter': 1560, 'avg_loss': 5.825906138936348, 'avg_acc': 49.70771941063421, 'loss': 5.758691787719727}


EP_train:1:  23%|| 1571/6926 [8:34:44&lt;28:56:01, 19.45s/it]

{'epoch': 1, 'iter': 1570, 'avg_loss': 5.824675731185438, 'avg_acc': 49.699633991088476, 'loss': 5.4692864418029785}


EP_train:1:  23%|| 1581/6926 [8:37:59&lt;28:52:12, 19.44s/it]

{'epoch': 1, 'iter': 1580, 'avg_loss': 5.823218187601185, 'avg_acc': 49.68967425679949, 'loss': 5.819296360015869}


EP_train:1:  23%|| 1591/6926 [8:41:14&lt;28:57:14, 19.54s/it]

{'epoch': 1, 'iter': 1590, 'avg_loss': 5.822140803657786, 'avg_acc': 49.679839723444374, 'loss': 5.727397441864014}


EP_train:1:  23%|| 1601/6926 [8:44:29&lt;28:46:20, 19.45s/it]

{'epoch': 1, 'iter': 1600, 'avg_loss': 5.822034669026667, 'avg_acc': 49.691599000624606, 'loss': 5.708556175231934}


EP_train:1:  23%|| 1611/6926 [8:47:43&lt;28:40:23, 19.42s/it]

{'epoch': 1, 'iter': 1610, 'avg_loss': 5.82130381041325, 'avg_acc': 49.72454996896338, 'loss': 5.713103294372559}


EP_train:1:  23%|| 1621/6926 [8:50:58&lt;28:45:25, 19.51s/it]

{'epoch': 1, 'iter': 1620, 'avg_loss': 5.820537564785373, 'avg_acc': 49.747455274521904, 'loss': 5.773373126983643}


EP_train:1:  24%|| 1631/6926 [8:54:14&lt;28:42:51, 19.52s/it]

{'epoch': 1, 'iter': 1630, 'avg_loss': 5.820567112916237, 'avg_acc': 49.77582771305947, 'loss': 6.175393104553223}


EP_train:1:  24%|| 1641/6926 [8:57:28&lt;28:35:08, 19.47s/it]

{'epoch': 1, 'iter': 1640, 'avg_loss': 5.820892861381963, 'avg_acc': 49.79433272394881, 'loss': 6.086596965789795}


EP_train:1:  24%|| 1651/6926 [9:00:43&lt;28:27:31, 19.42s/it]

{'epoch': 1, 'iter': 1650, 'avg_loss': 5.82148897048562, 'avg_acc': 49.77475772259237, 'loss': 5.665853500366211}


EP_train:1:  24%|| 1661/6926 [9:03:58&lt;28:42:11, 19.63s/it]

{'epoch': 1, 'iter': 1660, 'avg_loss': 5.821362611976178, 'avg_acc': 49.772350993377486, 'loss': 6.048189640045166}


EP_train:1:  24%|| 1671/6926 [9:07:12&lt;28:19:47, 19.41s/it]

{'epoch': 1, 'iter': 1670, 'avg_loss': 5.821244932376718, 'avg_acc': 49.741921005386, 'loss': 5.851042747497559}


EP_train:1:  24%|| 1681/6926 [9:10:26&lt;28:13:33, 19.37s/it]

{'epoch': 1, 'iter': 1680, 'avg_loss': 5.821554210056938, 'avg_acc': 49.7267251635931, 'loss': 5.589755058288574}


EP_train:1:  24%|| 1691/6926 [9:13:40&lt;28:08:00, 19.35s/it]

{'epoch': 1, 'iter': 1690, 'avg_loss': 5.82084716106575, 'avg_acc': 49.74312536960379, 'loss': 6.045618057250977}


EP_train:1:  25%|| 1701/6926 [9:16:54&lt;28:12:40, 19.44s/it]

{'epoch': 1, 'iter': 1700, 'avg_loss': 5.8202199764913285, 'avg_acc': 49.76300705467372, 'loss': 5.553305625915527}


EP_train:1:  25%|| 1711/6926 [9:20:08&lt;28:06:45, 19.41s/it]

{'epoch': 1, 'iter': 1710, 'avg_loss': 5.820620152770532, 'avg_acc': 49.77535067212157, 'loss': 5.491093635559082}


EP_train:1:  25%|| 1721/6926 [9:23:23&lt;28:16:31, 19.56s/it]

{'epoch': 1, 'iter': 1720, 'avg_loss': 5.820222318484158, 'avg_acc': 49.756682161533995, 'loss': 5.753364086151123}


EP_train:1:  25%|| 1731/6926 [9:26:38&lt;28:10:18, 19.52s/it]

{'epoch': 1, 'iter': 1730, 'avg_loss': 5.819994436392958, 'avg_acc': 49.76530906990179, 'loss': 5.770174026489258}


EP_train:1:  25%|| 1741/6926 [9:29:54&lt;28:17:53, 19.65s/it]

{'epoch': 1, 'iter': 1740, 'avg_loss': 5.820441535257321, 'avg_acc': 49.763067202757036, 'loss': 6.412217617034912}


EP_train:1:  25%|| 1751/6926 [9:33:10&lt;28:08:19, 19.57s/it]

{'epoch': 1, 'iter': 1750, 'avg_loss': 5.8209615562521755, 'avg_acc': 49.77155910908053, 'loss': 6.034691333770752}


EP_train:1:  25%|| 1761/6926 [9:36:25&lt;27:53:42, 19.44s/it]

{'epoch': 1, 'iter': 1760, 'avg_loss': 5.820453921073814, 'avg_acc': 49.755110732538334, 'loss': 5.652312278747559}


EP_train:1:  26%|| 1771/6926 [9:39:41&lt;28:07:38, 19.64s/it]

{'epoch': 1, 'iter': 1770, 'avg_loss': 5.8203765439960256, 'avg_acc': 49.76002258610954, 'loss': 5.796370506286621}


EP_train:1:  26%|| 1781/6926 [9:42:57&lt;27:58:54, 19.58s/it]

{'epoch': 1, 'iter': 1780, 'avg_loss': 5.820226957395062, 'avg_acc': 49.74908759124087, 'loss': 5.988513469696045}


EP_train:1:  26%|| 1791/6926 [9:46:12&lt;27:40:50, 19.41s/it]

{'epoch': 1, 'iter': 1790, 'avg_loss': 5.820003282418137, 'avg_acc': 49.75223338916806, 'loss': 5.468523979187012}


EP_train:1:  26%|| 1801/6926 [9:49:26&lt;27:32:35, 19.35s/it]

{'epoch': 1, 'iter': 1800, 'avg_loss': 5.819864340585712, 'avg_acc': 49.74840366463076, 'loss': 5.617454528808594}


EP_train:1:  26%|| 1811/6926 [9:52:41&lt;27:41:44, 19.49s/it]

{'epoch': 1, 'iter': 1810, 'avg_loss': 5.819467352872919, 'avg_acc': 49.76532302595251, 'loss': 5.4071149826049805}


EP_train:1:  26%|| 1821/6926 [9:55:55&lt;27:38:52, 19.50s/it]

{'epoch': 1, 'iter': 1820, 'avg_loss': 5.819182623748528, 'avg_acc': 49.75288303130148, 'loss': 5.931480884552002}


EP_train:1:  27%|| 1881/6926 [10:15:31&lt;27:26:32, 19.58s/it]

{'epoch': 1, 'iter': 1880, 'avg_loss': 5.818567064326853, 'avg_acc': 49.76408825093036, 'loss': 6.084392070770264}


EP_train:1:  27%|| 1891/6926 [10:18:46&lt;27:18:08, 19.52s/it]

{'epoch': 1, 'iter': 1890, 'avg_loss': 5.818359741138315, 'avg_acc': 49.75542041248017, 'loss': 5.704246520996094}


EP_train:1:  27%|| 1901/6926 [10:22:03&lt;27:25:51, 19.65s/it]

{'epoch': 1, 'iter': 1900, 'avg_loss': 5.817869842836319, 'avg_acc': 49.753419253024724, 'loss': 5.708099842071533}


EP_train:1:  28%|| 1911/6926 [10:25:20&lt;27:34:19, 19.79s/it]

{'epoch': 1, 'iter': 1910, 'avg_loss': 5.817352183634919, 'avg_acc': 49.739992150706435, 'loss': 5.804592132568359}


EP_train:1:  28%|| 1921/6926 [10:28:37&lt;27:22:08, 19.69s/it]

{'epoch': 1, 'iter': 1920, 'avg_loss': 5.817291461819475, 'avg_acc': 49.73971889640812, 'loss': 5.680202960968018}


EP_train:1:  28%|| 1931/6926 [10:31:53&lt;27:12:45, 19.61s/it]

{'epoch': 1, 'iter': 1930, 'avg_loss': 5.816651209471202, 'avg_acc': 49.73944847229414, 'loss': 5.508451461791992}


EP_train:1:  28%|| 1941/6926 [10:35:11&lt;27:18:43, 19.72s/it]

{'epoch': 1, 'iter': 1940, 'avg_loss': 5.816490153195255, 'avg_acc': 49.75367078825348, 'loss': 5.697039604187012}


EP_train:1:  28%|| 1951/6926 [10:38:28&lt;27:18:48, 19.76s/it]

{'epoch': 1, 'iter': 1950, 'avg_loss': 5.816306221002435, 'avg_acc': 49.754933367503845, 'loss': 5.570111274719238}


EP_train:1:  28%|| 1961/6926 [10:41:45&lt;27:20:12, 19.82s/it]

{'epoch': 1, 'iter': 1960, 'avg_loss': 5.816004560773072, 'avg_acc': 49.76255736868944, 'loss': 5.424126625061035}


EP_train:1:  28%|| 1971/6926 [10:45:04&lt;27:20:51, 19.87s/it]

{'epoch': 1, 'iter': 1970, 'avg_loss': 5.815267153042697, 'avg_acc': 49.75266362252664, 'loss': 5.304238319396973}


EP_train:1:  29%|| 1981/6926 [10:48:55&lt;29:40:40, 21.61s/it]

{'epoch': 1, 'iter': 1980, 'avg_loss': 5.815337210457352, 'avg_acc': 49.7649545683998, 'loss': 6.371850967407227}


EP_train:1:  29%|| 1991/6926 [10:52:24&lt;27:34:43, 20.12s/it]

{'epoch': 1, 'iter': 1990, 'avg_loss': 5.815152885086389, 'avg_acc': 49.75985685585133, 'loss': 5.692751884460449}


EP_train:1:  29%|| 2001/6926 [10:55:41&lt;26:57:10, 19.70s/it]

{'epoch': 1, 'iter': 2000, 'avg_loss': 5.815084245310969, 'avg_acc': 49.7641804097951, 'loss': 5.7164435386657715}


EP_train:1:  29%|| 2011/6926 [10:58:58&lt;26:57:53, 19.75s/it]

{'epoch': 1, 'iter': 2010, 'avg_loss': 5.815105802203102, 'avg_acc': 49.77156887120835, 'loss': 5.837700843811035}


EP_train:1:  29%|| 2021/6926 [11:02:17&lt;27:02:48, 19.85s/it]

{'epoch': 1, 'iter': 2020, 'avg_loss': 5.815062510619241, 'avg_acc': 49.75105145967343, 'loss': 5.568780422210693}


EP_train:1:  29%|| 2031/6926 [11:05:53&lt;29:32:35, 21.73s/it]

{'epoch': 1, 'iter': 2030, 'avg_loss': 5.81544689801102, 'avg_acc': 49.7445839487937, 'loss': 5.928976058959961}


EP_train:1:  29%|| 2041/6926 [11:09:45&lt;28:09:58, 20.76s/it]

{'epoch': 1, 'iter': 2040, 'avg_loss': 5.815306768179057, 'avg_acc': 49.74583537481627, 'loss': 5.518974304199219}


EP_train:1:  30%|| 2051/6926 [11:13:02&lt;26:42:20, 19.72s/it]

{'epoch': 1, 'iter': 2050, 'avg_loss': 5.814903688919015, 'avg_acc': 49.71964895173086, 'loss': 5.489553928375244}


EP_train:1:  30%|| 2061/6926 [11:16:20&lt;26:50:07, 19.86s/it]

{'epoch': 1, 'iter': 2060, 'avg_loss': 5.814639778405587, 'avg_acc': 49.725557981562346, 'loss': 5.28331995010376}


EP_train:1:  30%|| 2071/6926 [11:19:37&lt;26:39:10, 19.76s/it]

{'epoch': 1, 'iter': 2070, 'avg_loss': 5.813812052783386, 'avg_acc': 49.73744567841622, 'loss': 6.101926803588867}


EP_train:1:  30%|| 2081/6926 [11:22:55&lt;26:40:25, 19.82s/it]

{'epoch': 1, 'iter': 2080, 'avg_loss': 5.8142264005027675, 'avg_acc': 49.758229216722725, 'loss': 5.813886642456055}


EP_train:1:  30%|| 2091/6926 [11:26:12&lt;26:35:24, 19.80s/it]

{'epoch': 1, 'iter': 2090, 'avg_loss': 5.8136649193346415, 'avg_acc': 49.757890961262554, 'loss': 5.670198917388916}


EP_train:1:  30%|| 2101/6926 [11:29:30&lt;26:22:43, 19.68s/it]

{'epoch': 1, 'iter': 2100, 'avg_loss': 5.814033971293548, 'avg_acc': 49.756068538791055, 'loss': 5.676214694976807}


EP_train:1:  30%|| 2111/6926 [11:32:47&lt;26:20:32, 19.70s/it]

{'epoch': 1, 'iter': 2110, 'avg_loss': 5.813995209761222, 'avg_acc': 49.74982235907153, 'loss': 5.68745231628418}


EP_train:1:  31%|| 2121/6926 [11:36:05&lt;26:20:38, 19.74s/it]

{'epoch': 1, 'iter': 2120, 'avg_loss': 5.813585028227968, 'avg_acc': 49.75247524752475, 'loss': 5.451981544494629}


EP_train:1:  31%|| 2131/6926 [11:39:21&lt;26:12:21, 19.67s/it]

{'epoch': 1, 'iter': 2130, 'avg_loss': 5.8135437112859245, 'avg_acc': 49.75217034256218, 'loss': 5.650767803192139}


EP_train:1:  31%|| 2141/6926 [11:42:39&lt;26:16:27, 19.77s/it]

{'epoch': 1, 'iter': 2140, 'avg_loss': 5.813377936718231, 'avg_acc': 49.769383465670245, 'loss': 5.65677547454834}


EP_train:1:  31%|| 2151/6926 [11:45:55&lt;26:06:23, 19.68s/it]

{'epoch': 1, 'iter': 2150, 'avg_loss': 5.813167368296078, 'avg_acc': 49.73994653649466, 'loss': 5.920616149902344}


EP_train:1:  31%|| 2161/6926 [11:49:12&lt;26:02:14, 19.67s/it]

{'epoch': 1, 'iter': 2160, 'avg_loss': 5.812986291376102, 'avg_acc': 49.731027302174915, 'loss': 5.761153697967529}


EP_train:1:  31%|| 2171/6926 [11:52:30&lt;26:12:51, 19.85s/it]

{'epoch': 1, 'iter': 2170, 'avg_loss': 5.812540080678018, 'avg_acc': 49.725069092584064, 'loss': 5.7599263191223145}


EP_train:1:  31%|| 2181/6926 [11:55:48&lt;26:05:08, 19.79s/it]

{'epoch': 1, 'iter': 2180, 'avg_loss': 5.812452738244618, 'avg_acc': 49.74352361302155, 'loss': 5.98489236831665}


EP_train:1:  32%|| 2191/6926 [11:59:06&lt;26:01:10, 19.78s/it]

{'epoch': 1, 'iter': 2190, 'avg_loss': 5.812447594921647, 'avg_acc': 49.74184162482885, 'loss': 5.562654495239258}


EP_train:1:  32%|| 2201/6926 [12:02:24&lt;26:04:17, 19.86s/it]

{'epoch': 1, 'iter': 2200, 'avg_loss': 5.812213972231195, 'avg_acc': 49.744434348023624, 'loss': 5.945650577545166}


EP_train:1:  32%|| 2211/6926 [12:05:43&lt;26:02:51, 19.89s/it]

{'epoch': 1, 'iter': 2210, 'avg_loss': 5.812122378398907, 'avg_acc': 49.75124378109453, 'loss': 5.539562702178955}


EP_train:1:  32%|| 2221/6926 [12:09:02&lt;25:59:40, 19.89s/it]

{'epoch': 1, 'iter': 2220, 'avg_loss': 5.812053891894303, 'avg_acc': 49.76502701485817, 'loss': 5.630687713623047}


EP_train:1:  32%|| 2231/6926 [12:12:20&lt;25:50:03, 19.81s/it]

{'epoch': 1, 'iter': 2230, 'avg_loss': 5.811385647804948, 'avg_acc': 49.75487449574182, 'loss': 5.983824729919434}


EP_train:1:  32%|| 2241/6926 [12:15:38&lt;25:50:48, 19.86s/it]

{'epoch': 1, 'iter': 2240, 'avg_loss': 5.810250847640712, 'avg_acc': 49.76851851851852, 'loss': 6.013811111450195}


EP_train:1:  33%|| 2251/6926 [12:18:57&lt;25:46:48, 19.85s/it]

{'epoch': 1, 'iter': 2250, 'avg_loss': 5.810296357763655, 'avg_acc': 49.776488227454465, 'loss': 5.763908863067627}


EP_train:1:  33%|| 2261/6926 [12:22:16&lt;25:53:24, 19.98s/it]

{'epoch': 1, 'iter': 2260, 'avg_loss': 5.810534973895323, 'avg_acc': 49.780241043785935, 'loss': 5.905952453613281}


EP_train:1:  33%|| 2271/6926 [12:25:35&lt;25:41:41, 19.87s/it]

{'epoch': 1, 'iter': 2270, 'avg_loss': 5.810524367068319, 'avg_acc': 49.785336856010574, 'loss': 5.680035591125488}


EP_train:1:  33%|| 2281/6926 [12:28:54&lt;25:39:13, 19.88s/it]

{'epoch': 1, 'iter': 2280, 'avg_loss': 5.81014431489763, 'avg_acc': 49.77942788250767, 'loss': 5.456300258636475}


EP_train:1:  33%|| 2291/6926 [12:32:14&lt;25:43:00, 19.97s/it]

{'epoch': 1, 'iter': 2290, 'avg_loss': 5.809880057259555, 'avg_acc': 49.774934526407684, 'loss': 5.729395866394043}


EP_train:1:  33%|| 2301/6926 [12:35:34&lt;25:29:41, 19.84s/it]

{'epoch': 1, 'iter': 2300, 'avg_loss': 5.809157367376388, 'avg_acc': 49.76233159495872, 'loss': 5.143627166748047}


EP_train:1:  33%|| 2311/6926 [12:38:51&lt;25:21:23, 19.78s/it]

{'epoch': 1, 'iter': 2310, 'avg_loss': 5.808825852911176, 'avg_acc': 49.768768931198615, 'loss': 5.558385848999023}


EP_train:1:  34%|| 2321/6926 [12:42:10&lt;25:14:51, 19.74s/it]

{'epoch': 1, 'iter': 2320, 'avg_loss': 5.808508661788684, 'avg_acc': 49.758993968117196, 'loss': 6.150199890136719}


EP_train:1:  34%|| 2331/6926 [12:45:29&lt;25:30:12, 19.98s/it]

{'epoch': 1, 'iter': 2330, 'avg_loss': 5.808087570684655, 'avg_acc': 49.73589661089661, 'loss': 5.794741630554199}


EP_train:1:  34%|| 2341/6926 [12:48:49&lt;25:24:44, 19.95s/it]

{'epoch': 1, 'iter': 2340, 'avg_loss': 5.807202406389904, 'avg_acc': 49.75571337035455, 'loss': 5.584786891937256}


EP_train:1:  34%|| 2351/6926 [12:52:09&lt;25:24:53, 20.00s/it]

{'epoch': 1, 'iter': 2350, 'avg_loss': 5.806677556656513, 'avg_acc': 49.75409400255211, 'loss': 5.515694618225098}


EP_train:1:  34%|| 2361/6926 [12:55:30&lt;25:25:39, 20.05s/it]

{'epoch': 1, 'iter': 2360, 'avg_loss': 5.805700262741031, 'avg_acc': 49.75248835239305, 'loss': 5.311631679534912}


EP_train:1:  34%|| 2371/6926 [12:58:50&lt;25:19:21, 20.01s/it]

{'epoch': 1, 'iter': 2370, 'avg_loss': 5.805741113834068, 'avg_acc': 49.76539434837621, 'loss': 6.047265529632568}


EP_train:1:  34%|| 2381/6926 [13:02:12&lt;25:24:44, 20.13s/it]

{'epoch': 1, 'iter': 2380, 'avg_loss': 5.805614596602798, 'avg_acc': 49.77687946241075, 'loss': 5.547722816467285}


EP_train:1:  35%|| 2391/6926 [13:05:32&lt;25:06:58, 19.94s/it]

{'epoch': 1, 'iter': 2390, 'avg_loss': 5.805619691914965, 'avg_acc': 49.77519866164785, 'loss': 5.432829856872559}


EP_train:1:  35%|| 2401/6926 [13:08:53&lt;25:12:20, 20.05s/it]

{'epoch': 1, 'iter': 2400, 'avg_loss': 5.805759970717806, 'avg_acc': 49.780039566847144, 'loss': 5.861325263977051}


EP_train:1:  35%|| 2411/6926 [13:12:14&lt;25:10:20, 20.07s/it]

{'epoch': 1, 'iter': 2410, 'avg_loss': 5.806004341486231, 'avg_acc': 49.80428245541269, 'loss': 5.867797374725342}


EP_train:1:  35%|| 2421/6926 [13:15:36&lt;25:16:42, 20.20s/it]

{'epoch': 1, 'iter': 2420, 'avg_loss': 5.805987544810166, 'avg_acc': 49.79476456009913, 'loss': 5.692656517028809}


EP_train:1:  35%|| 2431/6926 [13:18:57&lt;24:58:30, 20.00s/it]

{'epoch': 1, 'iter': 2430, 'avg_loss': 5.806068894501235, 'avg_acc': 49.80075071986837, 'loss': 5.708716869354248}


EP_train:1:  35%|| 2441/6926 [13:22:19&lt;25:11:32, 20.22s/it]

{'epoch': 1, 'iter': 2440, 'avg_loss': 5.805675500536101, 'avg_acc': 49.80028676771815, 'loss': 5.948583126068115}


EP_train:1:  35%|| 2451/6926 [13:25:43&lt;25:10:30, 20.25s/it]

{'epoch': 1, 'iter': 2450, 'avg_loss': 5.80541812930969, 'avg_acc': 49.78452672378621, 'loss': 5.5749430656433105}


EP_train:1:  36%|| 2461/6926 [13:29:05&lt;25:02:48, 20.19s/it]

{'epoch': 1, 'iter': 2460, 'avg_loss': 5.805113396185387, 'avg_acc': 49.812068264932954, 'loss': 5.6128315925598145}


EP_train:1:  36%|| 2471/6926 [13:32:28&lt;24:57:45, 20.17s/it]

{'epoch': 1, 'iter': 2470, 'avg_loss': 5.804539583608333, 'avg_acc': 49.81282881424525, 'loss': 5.324734210968018}


EP_train:1:  36%|| 2481/6926 [13:35:50&lt;25:05:24, 20.32s/it]

{'epoch': 1, 'iter': 2480, 'avg_loss': 5.804087520846913, 'avg_acc': 49.819881096332125, 'loss': 5.382660865783691}


EP_train:1:  36%|| 2491/6926 [13:39:12&lt;24:54:25, 20.22s/it]

{'epoch': 1, 'iter': 2490, 'avg_loss': 5.804366817535621, 'avg_acc': 49.84443998394219, 'loss': 6.087839126586914}


EP_train:1:  36%|| 2501/6926 [13:42:35&lt;24:53:42, 20.25s/it]

{'epoch': 1, 'iter': 2500, 'avg_loss': 5.8043414020195145, 'avg_acc': 49.84756097560975, 'loss': 5.833101749420166}


EP_train:1:  36%|| 2511/6926 [13:45:57&lt;24:44:28, 20.17s/it]

{'epoch': 1, 'iter': 2510, 'avg_loss': 5.803561097262438, 'avg_acc': 49.83945639187575, 'loss': 5.380828857421875}


EP_train:1:  36%|| 2521/6926 [13:49:19&lt;24:35:44, 20.10s/it]

{'epoch': 1, 'iter': 2520, 'avg_loss': 5.803822430766135, 'avg_acc': 49.84257239190797, 'loss': 6.243338108062744}


EP_train:1:  37%|| 2531/6926 [13:52:41&lt;24:39:04, 20.19s/it]

{'epoch': 1, 'iter': 2530, 'avg_loss': 5.803207256915493, 'avg_acc': 49.83949032003161, 'loss': 6.056561470031738}


EP_train:1:  37%|| 2541/6926 [13:56:04&lt;24:48:26, 20.37s/it]

{'epoch': 1, 'iter': 2540, 'avg_loss': 5.803235923619966, 'avg_acc': 49.86471861471862, 'loss': 5.26930046081543}


EP_train:1:  37%|| 2551/6926 [13:59:30&lt;25:20:51, 20.86s/it]

{'epoch': 1, 'iter': 2550, 'avg_loss': 5.803682241660387, 'avg_acc': 49.90444923559389, 'loss': 5.970859527587891}


EP_train:1:  37%|| 2561/6926 [14:02:54&lt;24:46:13, 20.43s/it]

{'epoch': 1, 'iter': 2560, 'avg_loss': 5.803817744741027, 'avg_acc': 49.90726278797345, 'loss': 5.6861090660095215}


EP_train:1:  37%|| 2571/6926 [14:06:18&lt;24:37:49, 20.36s/it]

{'epoch': 1, 'iter': 2570, 'avg_loss': 5.803871367516475, 'avg_acc': 49.886960326721116, 'loss': 5.429114818572998}


EP_train:1:  37%|| 2581/6926 [14:09:40&lt;24:22:00, 20.19s/it]

{'epoch': 1, 'iter': 2580, 'avg_loss': 5.803580724560258, 'avg_acc': 49.88134444013948, 'loss': 5.6898698806762695}


EP_train:1:  37%|| 2591/6926 [14:13:04&lt;24:28:55, 20.33s/it]

{'epoch': 1, 'iter': 2590, 'avg_loss': 5.8033536022485155, 'avg_acc': 49.875771902740254, 'loss': 5.311685562133789}


EP_train:1:  38%|| 2601/6926 [14:16:29&lt;24:31:04, 20.41s/it]

{'epoch': 1, 'iter': 2600, 'avg_loss': 5.803310167509883, 'avg_acc': 49.88586120722799, 'loss': 5.9250898361206055}


EP_train:1:  38%|| 2611/6926 [14:19:53&lt;24:28:04, 20.41s/it]

{'epoch': 1, 'iter': 2610, 'avg_loss': 5.803713341592053, 'avg_acc': 49.90185752585216, 'loss': 6.0624098777771}


EP_train:1:  38%|| 2621/6926 [14:23:17&lt;24:29:41, 20.48s/it]

{'epoch': 1, 'iter': 2620, 'avg_loss': 5.803969218593569, 'avg_acc': 49.905808851583366, 'loss': 5.931776523590088}


EP_train:1:  38%|| 2631/6926 [14:26:41&lt;24:09:23, 20.25s/it]

{'epoch': 1, 'iter': 2630, 'avg_loss': 5.804032856409471, 'avg_acc': 49.89310148232612, 'loss': 5.649225234985352}


EP_train:1:  38%|| 2641/6926 [14:30:05&lt;24:16:44, 20.40s/it]

{'epoch': 1, 'iter': 2640, 'avg_loss': 5.804332307413283, 'avg_acc': 49.88877319197273, 'loss': 5.363492488861084}


EP_train:1:  38%|| 2651/6926 [14:33:28&lt;24:06:14, 20.30s/it]

{'epoch': 1, 'iter': 2650, 'avg_loss': 5.80409545459553, 'avg_acc': 49.88211995473406, 'loss': 5.785643100738525}


EP_train:1:  38%|| 2661/6926 [14:36:53&lt;24:05:45, 20.34s/it]

{'epoch': 1, 'iter': 2660, 'avg_loss': 5.8036675842038585, 'avg_acc': 49.8837373167982, 'loss': 5.403915882110596}


EP_train:1:  39%|| 2671/6926 [14:40:16&lt;24:08:42, 20.43s/it]

{'epoch': 1, 'iter': 2670, 'avg_loss': 5.803600825784984, 'avg_acc': 49.878322725570946, 'loss': 5.855526447296143}


EP_train:1:  39%|| 2681/6926 [14:43:41&lt;24:10:25, 20.50s/it]

{'epoch': 1, 'iter': 2680, 'avg_loss': 5.803370747002414, 'avg_acc': 49.88693584483402, 'loss': 5.916980266571045}


EP_train:1:  39%|| 2691/6926 [14:47:07&lt;24:04:11, 20.46s/it]

{'epoch': 1, 'iter': 2690, 'avg_loss': 5.803192461170436, 'avg_acc': 49.882710888145674, 'loss': 5.771810054779053}


EP_train:1:  39%|| 2701/6926 [14:50:32&lt;24:03:29, 20.50s/it]

{'epoch': 1, 'iter': 2700, 'avg_loss': 5.803469681554439, 'avg_acc': 49.872732321362456, 'loss': 6.208793640136719}


EP_train:1:  39%|| 2711/6926 [14:53:58&lt;24:10:04, 20.64s/it]

{'epoch': 1, 'iter': 2710, 'avg_loss': 5.803627242289184, 'avg_acc': 49.87435448174106, 'loss': 6.089566707611084}


EP_train:1:  39%|| 2721/6926 [14:57:22&lt;23:49:14, 20.39s/it]

{'epoch': 1, 'iter': 2720, 'avg_loss': 5.803495487716433, 'avg_acc': 49.88400404263139, 'loss': 5.7707648277282715}


EP_train:1:  39%|| 2731/6926 [15:00:47&lt;23:56:46, 20.55s/it]

{'epoch': 1, 'iter': 2730, 'avg_loss': 5.803271200228243, 'avg_acc': 49.89015012815818, 'loss': 5.9853196144104}


EP_train:1:  40%|| 2741/6926 [15:04:12&lt;23:54:24, 20.56s/it]

{'epoch': 1, 'iter': 2740, 'avg_loss': 5.802916974231563, 'avg_acc': 49.88827070412258, 'loss': 6.10043478012085}


EP_train:1:  40%|| 2751/6926 [15:07:36&lt;23:42:31, 20.44s/it]

{'epoch': 1, 'iter': 2750, 'avg_loss': 5.802925791405886, 'avg_acc': 49.89208469647401, 'loss': 5.7196044921875}


EP_train:1:  40%|| 2761/6926 [15:11:03&lt;23:50:10, 20.60s/it]

{'epoch': 1, 'iter': 2760, 'avg_loss': 5.803030003157701, 'avg_acc': 49.88568453458891, 'loss': 5.646425247192383}


EP_train:1:  40%|| 2771/6926 [15:14:28&lt;23:44:25, 20.57s/it]

{'epoch': 1, 'iter': 2770, 'avg_loss': 5.802530446666881, 'avg_acc': 49.86692529772645, 'loss': 5.583689212799072}


EP_train:1:  40%|| 2781/6926 [15:17:54&lt;23:43:20, 20.60s/it]

{'epoch': 1, 'iter': 2780, 'avg_loss': 5.80263057161432, 'avg_acc': 49.8584142394822, 'loss': 5.739715576171875}


EP_train:1:  40%|| 2791/6926 [15:21:20&lt;23:33:52, 20.52s/it]

{'epoch': 1, 'iter': 2790, 'avg_loss': 5.802805198387876, 'avg_acc': 49.856682192762456, 'loss': 5.3376030921936035}


EP_train:1:  40%|| 2801/6926 [15:24:45&lt;23:45:00, 20.73s/it]

{'epoch': 1, 'iter': 2800, 'avg_loss': 5.802788054334483, 'avg_acc': 49.846037129596574, 'loss': 5.699147701263428}


EP_train:1:  41%|| 2811/6926 [15:28:10&lt;23:24:40, 20.48s/it]

{'epoch': 1, 'iter': 2810, 'avg_loss': 5.802020575897586, 'avg_acc': 49.85103166133049, 'loss': 5.489011764526367}


EP_train:1:  41%|| 2821/6926 [15:31:35&lt;23:27:22, 20.57s/it]

{'epoch': 1, 'iter': 2820, 'avg_loss': 5.80217228963501, 'avg_acc': 49.86485288904643, 'loss': 6.136548042297363}


EP_train:1:  41%|| 2831/6926 [15:35:00&lt;23:13:04, 20.41s/it]

{'epoch': 1, 'iter': 2830, 'avg_loss': 5.801999372208089, 'avg_acc': 49.8675379724479, 'loss': 5.894773006439209}


EP_train:1:  41%|| 2841/6926 [15:38:25&lt;23:16:41, 20.51s/it]

{'epoch': 1, 'iter': 2840, 'avg_loss': 5.801592723620857, 'avg_acc': 49.86360436466033, 'loss': 5.720633506774902}


EP_train:1:  41%|| 2851/6926 [15:41:51&lt;23:11:01, 20.48s/it]

{'epoch': 1, 'iter': 2850, 'avg_loss': 5.801943971833945, 'avg_acc': 49.87504384426517, 'loss': 5.807015419006348}


EP_train:1:  41%|| 2861/6926 [15:45:16&lt;23:16:56, 20.62s/it]

{'epoch': 1, 'iter': 2860, 'avg_loss': 5.801992543882859, 'avg_acc': 49.86674239776302, 'loss': 6.230549335479736}


EP_train:1:  41%|| 2871/6926 [15:48:41&lt;23:04:49, 20.49s/it]

{'epoch': 1, 'iter': 2870, 'avg_loss': 5.801884959940709, 'avg_acc': 49.86067572274469, 'loss': 5.754544258117676}


EP_train:1:  42%|| 2881/6926 [15:52:06&lt;22:59:33, 20.46s/it]

{'epoch': 1, 'iter': 2880, 'avg_loss': 5.801832714994431, 'avg_acc': 49.86332870531066, 'loss': 5.754513263702393}


EP_train:1:  42%|| 2891/6926 [15:55:29&lt;22:47:39, 20.34s/it]

{'epoch': 1, 'iter': 2890, 'avg_loss': 5.801836648642172, 'avg_acc': 49.87244897959184, 'loss': 5.542731761932373}


EP_train:1:  42%|| 2901/6926 [15:58:55&lt;23:05:01, 20.65s/it]

{'epoch': 1, 'iter': 2900, 'avg_loss': 5.801939054671258, 'avg_acc': 49.886892450879, 'loss': 6.0265045166015625}


EP_train:1:  42%|| 2911/6926 [16:02:23&lt;23:16:36, 20.87s/it]

{'epoch': 1, 'iter': 2910, 'avg_loss': 5.8020411515637225, 'avg_acc': 49.89694263139815, 'loss': 5.593013286590576}


EP_train:1:  42%|| 2921/6926 [16:05:50&lt;22:51:02, 20.54s/it]

{'epoch': 1, 'iter': 2920, 'avg_loss': 5.802139006343372, 'avg_acc': 49.88873673399521, 'loss': 5.587180137634277}


EP_train:1:  42%|| 2931/6926 [16:09:16&lt;22:58:59, 20.71s/it]

{'epoch': 1, 'iter': 2930, 'avg_loss': 5.801907398480273, 'avg_acc': 49.88911634254521, 'loss': 5.605075836181641}


EP_train:1:  42%|| 2941/6926 [16:12:42&lt;22:51:57, 20.66s/it]

{'epoch': 1, 'iter': 2940, 'avg_loss': 5.802057036977364, 'avg_acc': 49.904369262155726, 'loss': 5.779245376586914}


EP_train:1:  43%|| 2951/6926 [16:16:05&lt;22:31:04, 20.39s/it]

{'epoch': 1, 'iter': 2950, 'avg_loss': 5.801865979074745, 'avg_acc': 49.90681125042358, 'loss': 5.421384334564209}


EP_train:1:  43%|| 2961/6926 [16:19:31&lt;22:31:31, 20.45s/it]

{'epoch': 1, 'iter': 2960, 'avg_loss': 5.801866229906633, 'avg_acc': 49.91451367781155, 'loss': 6.421411991119385}


EP_train:1:  43%|| 2971/6926 [16:22:55&lt;22:24:54, 20.40s/it]

{'epoch': 1, 'iter': 2970, 'avg_loss': 5.801617084870391, 'avg_acc': 49.89692022887917, 'loss': 5.8181610107421875}


EP_train:1:  43%|| 2981/6926 [16:26:20&lt;22:23:48, 20.44s/it]

{'epoch': 1, 'iter': 2980, 'avg_loss': 5.801531334204867, 'avg_acc': 49.90250754780275, 'loss': 6.25356388092041}


EP_train:1:  43%|| 2991/6926 [16:29:43&lt;22:11:19, 20.30s/it]

{'epoch': 1, 'iter': 2990, 'avg_loss': 5.801264963114951, 'avg_acc': 49.89447509194249, 'loss': 5.840907573699951}


EP_train:1:  43%|| 3001/6926 [16:33:07&lt;22:16:55, 20.44s/it]

{'epoch': 1, 'iter': 3000, 'avg_loss': 5.8012425353709, 'avg_acc': 49.88337220926358, 'loss': 5.5747480392456055}


EP_train:1:  43%|| 3011/6926 [16:36:32&lt;22:16:53, 20.49s/it]

{'epoch': 1, 'iter': 3010, 'avg_loss': 5.80091211083956, 'avg_acc': 49.87441879774161, 'loss': 5.703753471374512}


EP_train:1:  44%|| 3021/6926 [16:39:56&lt;22:07:26, 20.40s/it]

{'epoch': 1, 'iter': 3020, 'avg_loss': 5.801163221186891, 'avg_acc': 49.86966236345581, 'loss': 5.810041427612305}


EP_train:1:  44%|| 3031/6926 [16:43:21&lt;22:08:17, 20.46s/it]

{'epoch': 1, 'iter': 3030, 'avg_loss': 5.80099582404675, 'avg_acc': 49.87834048168921, 'loss': 6.274641990661621}


EP_train:1:  44%|| 3041/6926 [16:46:44&lt;22:00:07, 20.39s/it]

{'epoch': 1, 'iter': 3040, 'avg_loss': 5.800807579376713, 'avg_acc': 49.874630055902664, 'loss': 5.624147415161133}


EP_train:1:  44%|| 3051/6926 [16:50:07&lt;21:53:55, 20.34s/it]

{'epoch': 1, 'iter': 3050, 'avg_loss': 5.800946569958502, 'avg_acc': 49.87299246148804, 'loss': 5.570043563842773}


EP_train:1:  44%|| 3061/6926 [16:53:29&lt;21:41:34, 20.21s/it]

{'epoch': 1, 'iter': 3060, 'avg_loss': 5.800996650788021, 'avg_acc': 49.86830284220843, 'loss': 6.268154144287109}


EP_train:1:  44%|| 3071/6926 [16:56:53&lt;21:52:58, 20.44s/it]

{'epoch': 1, 'iter': 3070, 'avg_loss': 5.801088010632072, 'avg_acc': 49.8666965157929, 'loss': 5.92355489730835}


EP_train:1:  44%|| 3081/6926 [17:00:15&lt;21:31:36, 20.16s/it]

{'epoch': 1, 'iter': 3080, 'avg_loss': 5.800997397451577, 'avg_acc': 49.875243427458614, 'loss': 5.917311668395996}


EP_train:1:  45%|| 3091/6926 [17:03:38&lt;21:37:46, 20.30s/it]

{'epoch': 1, 'iter': 3090, 'avg_loss': 5.80108144714469, 'avg_acc': 49.888790035587185, 'loss': 5.845328330993652}


EP_train:1:  45%|| 3101/6926 [17:07:00&lt;21:31:30, 20.26s/it]

{'epoch': 1, 'iter': 3100, 'avg_loss': 5.8006915970795845, 'avg_acc': 49.890156401160915, 'loss': 5.792585849761963}


EP_train:1:  45%|| 3111/6926 [17:10:23&lt;21:32:38, 20.33s/it]

{'epoch': 1, 'iter': 3110, 'avg_loss': 5.800643468431934, 'avg_acc': 49.88347798135648, 'loss': 5.319636344909668}


EP_train:1:  45%|| 3121/6926 [17:13:46&lt;21:26:54, 20.29s/it]

{'epoch': 1, 'iter': 3120, 'avg_loss': 5.800560562857371, 'avg_acc': 49.90487824415252, 'loss': 5.848810195922852}


EP_train:1:  45%|| 3131/6926 [17:17:08&lt;21:16:29, 20.18s/it]

{'epoch': 1, 'iter': 3130, 'avg_loss': 5.799761191453084, 'avg_acc': 49.906180134142446, 'loss': 5.522349834442139}


EP_train:1:  45%|| 3141/6926 [17:20:30&lt;21:20:26, 20.30s/it]

{'epoch': 1, 'iter': 3140, 'avg_loss': 5.799490795056556, 'avg_acc': 49.90846864056033, 'loss': 5.382495880126953}


EP_train:1:  45%|| 3151/6926 [17:23:51&lt;21:02:39, 20.07s/it]

{'epoch': 1, 'iter': 3150, 'avg_loss': 5.799324041243698, 'avg_acc': 49.8998333862266, 'loss': 5.682802200317383}


EP_train:1:  46%|| 3161/6926 [17:27:13&lt;21:05:27, 20.17s/it]

{'epoch': 1, 'iter': 3160, 'avg_loss': 5.799414351860657, 'avg_acc': 49.903116102499204, 'loss': 5.818331718444824}


EP_train:1:  46%|| 3171/6926 [17:30:34&lt;20:57:38, 20.10s/it]

{'epoch': 1, 'iter': 3170, 'avg_loss': 5.798695234950128, 'avg_acc': 49.9083491012299, 'loss': 6.04541540145874}


EP_train:1:  46%|| 3181/6926 [17:33:55&lt;20:55:41, 20.12s/it]

{'epoch': 1, 'iter': 3180, 'avg_loss': 5.798833204867217, 'avg_acc': 49.91747878025778, 'loss': 5.4481658935546875}


EP_train:1:  46%|| 3191/6926 [17:37:16&lt;20:44:59, 20.00s/it]

{'epoch': 1, 'iter': 3190, 'avg_loss': 5.798147868004311, 'avg_acc': 49.90696490128486, 'loss': 5.371510028839111}


EP_train:1:  46%|| 3201/6926 [17:40:35&lt;20:37:30, 19.93s/it]

{'epoch': 1, 'iter': 3200, 'avg_loss': 5.798515476982358, 'avg_acc': 49.91213683223992, 'loss': 5.820341110229492}


EP_train:1:  46%|| 3211/6926 [17:43:56&lt;20:36:00, 19.96s/it]

{'epoch': 1, 'iter': 3210, 'avg_loss': 5.798679115689829, 'avg_acc': 49.916303332295236, 'loss': 6.057877063751221}


EP_train:1:  47%|| 3221/6926 [17:47:14&lt;20:21:11, 19.78s/it]

{'epoch': 1, 'iter': 3220, 'avg_loss': 5.798803051744548, 'avg_acc': 49.910742005588325, 'loss': 5.672614097595215}


EP_train:1:  47%|| 3231/6926 [17:50:35&lt;20:35:24, 20.06s/it]

{'epoch': 1, 'iter': 3230, 'avg_loss': 5.798637440609733, 'avg_acc': 49.90521510368307, 'loss': 5.771320819854736}


EP_train:1:  47%|| 3241/6926 [17:53:55&lt;20:29:09, 20.01s/it]

{'epoch': 1, 'iter': 3240, 'avg_loss': 5.7986973548001695, 'avg_acc': 49.90261493366245, 'loss': 6.0871100425720215}


EP_train:1:  47%|| 3251/6926 [17:57:15&lt;20:18:36, 19.90s/it]

{'epoch': 1, 'iter': 3250, 'avg_loss': 5.798550034625388, 'avg_acc': 49.90579821593356, 'loss': 5.959145545959473}


EP_train:1:  47%|| 3261/6926 [18:00:34&lt;20:12:48, 19.86s/it]

{'epoch': 1, 'iter': 3260, 'avg_loss': 5.798477939358887, 'avg_acc': 49.91567003986507, 'loss': 6.048858165740967}


EP_train:1:  47%|| 3271/6926 [18:03:52&lt;20:02:53, 19.75s/it]

{'epoch': 1, 'iter': 3270, 'avg_loss': 5.798104361852205, 'avg_acc': 49.92930296545399, 'loss': 5.471917152404785}


EP_train:1:  47%|| 3281/6926 [18:07:10&lt;20:05:53, 19.85s/it]

{'epoch': 1, 'iter': 3280, 'avg_loss': 5.797959458933339, 'avg_acc': 49.923803718378544, 'loss': 5.832575798034668}


EP_train:1:  48%|| 3291/6926 [18:10:30&lt;19:59:10, 19.79s/it]

{'epoch': 1, 'iter': 3290, 'avg_loss': 5.797657301707748, 'avg_acc': 49.92783348526284, 'loss': 5.882083415985107}


EP_train:1:  48%|| 3301/6926 [18:13:47&lt;19:55:06, 19.78s/it]

{'epoch': 1, 'iter': 3300, 'avg_loss': 5.797738103280101, 'avg_acc': 49.942252347773405, 'loss': 5.842111587524414}


EP_train:1:  48%|| 3311/6926 [18:17:06&lt;19:55:55, 19.85s/it]

{'epoch': 1, 'iter': 3310, 'avg_loss': 5.797788564548936, 'avg_acc': 49.93204469948656, 'loss': 5.644682884216309}


EP_train:1:  48%|| 3321/6926 [18:20:24&lt;19:46:51, 19.75s/it]

{'epoch': 1, 'iter': 3320, 'avg_loss': 5.797738609957214, 'avg_acc': 49.93977717554953, 'loss': 5.707881927490234}


EP_train:1:  48%|| 3331/6926 [18:23:42&lt;19:48:14, 19.83s/it]

{'epoch': 1, 'iter': 3330, 'avg_loss': 5.79758222823886, 'avg_acc': 49.935267187030924, 'loss': 6.302088260650635}


EP_train:1:  48%|| 3341/6926 [18:27:00&lt;19:35:10, 19.67s/it]

{'epoch': 1, 'iter': 3340, 'avg_loss': 5.797448237760807, 'avg_acc': 49.919560011972465, 'loss': 5.805854320526123}


EP_train:1:  48%|| 3351/6926 [18:30:16&lt;19:31:35, 19.66s/it]

{'epoch': 1, 'iter': 3350, 'avg_loss': 5.797970459305397, 'avg_acc': 49.92073261712922, 'loss': 6.262275218963623}


EP_train:1:  49%|| 3361/6926 [18:33:33&lt;19:24:11, 19.59s/it]

{'epoch': 1, 'iter': 3360, 'avg_loss': 5.797864862865935, 'avg_acc': 49.91724933055639, 'loss': 6.109804153442383}


EP_train:1:  49%|| 3371/6926 [18:36:50&lt;19:33:27, 19.81s/it]

{'epoch': 1, 'iter': 3370, 'avg_loss': 5.797793220320854, 'avg_acc': 49.9147137347968, 'loss': 5.812377452850342}


EP_train:1:  49%|| 3381/6926 [18:40:06&lt;19:17:50, 19.60s/it]

{'epoch': 1, 'iter': 3380, 'avg_loss': 5.797807161640888, 'avg_acc': 49.91404170363798, 'loss': 5.877485752105713}


EP_train:1:  49%|| 3391/6926 [18:43:30&lt;19:27:50, 19.82s/it]

{'epoch': 1, 'iter': 3390, 'avg_loss': 5.797511611776484, 'avg_acc': 49.92074609259806, 'loss': 5.540976047515869}


EP_train:1:  49%|| 3401/6926 [18:46:46&lt;19:03:32, 19.46s/it]

{'epoch': 1, 'iter': 3400, 'avg_loss': 5.797180272522691, 'avg_acc': 49.923735665980594, 'loss': 5.785827159881592}


EP_train:1:  49%|| 3411/6926 [18:50:02&lt;19:07:56, 19.60s/it]

{'epoch': 1, 'iter': 3410, 'avg_loss': 5.797631775238967, 'avg_acc': 49.92304309586631, 'loss': 5.969135761260986}


EP_train:1:  49%|| 3421/6926 [18:53:15&lt;18:49:32, 19.34s/it]

{'epoch': 1, 'iter': 3420, 'avg_loss': 5.797375422686521, 'avg_acc': 49.90225811166326, 'loss': 5.652700901031494}


EP_train:1:  50%|| 3431/6926 [18:56:29&lt;18:44:42, 19.31s/it]

{'epoch': 1, 'iter': 3430, 'avg_loss': 5.797165639822284, 'avg_acc': 49.89070241911979, 'loss': 5.90446662902832}


EP_train:1:  50%|| 3441/6926 [18:59:42&lt;18:41:07, 19.30s/it]

{'epoch': 1, 'iter': 3440, 'avg_loss': 5.7970707328539195, 'avg_acc': 49.88012205754141, 'loss': 5.610228538513184}


EP_train:1:  50%|| 3451/6926 [19:02:56&lt;18:52:37, 19.56s/it]

{'epoch': 1, 'iter': 3450, 'avg_loss': 5.796945811492469, 'avg_acc': 49.88590263691683, 'loss': 5.920961856842041}


EP_train:1:  50%|| 3461/6926 [19:06:10&lt;18:36:27, 19.33s/it]

{'epoch': 1, 'iter': 3460, 'avg_loss': 5.79697771232206, 'avg_acc': 49.88984397572956, 'loss': 5.862846374511719}


EP_train:1:  50%|| 3471/6926 [19:09:23&lt;18:29:37, 19.27s/it]

{'epoch': 1, 'iter': 3470, 'avg_loss': 5.797259839595617, 'avg_acc': 49.89736387208297, 'loss': 5.542323112487793}


EP_train:1:  50%|| 3481/6926 [19:12:34&lt;18:17:58, 19.12s/it]

{'epoch': 1, 'iter': 3480, 'avg_loss': 5.797178803213503, 'avg_acc': 49.89855644929618, 'loss': 5.552881717681885}


EP_train:1:  50%|| 3491/6926 [19:15:44&lt;18:08:34, 19.01s/it]

{'epoch': 1, 'iter': 3490, 'avg_loss': 5.797389878956236, 'avg_acc': 49.89168576339158, 'loss': 5.8328142166137695}


EP_train:1:  51%|| 3501/6926 [19:18:53&lt;17:59:26, 18.91s/it]

{'epoch': 1, 'iter': 3500, 'avg_loss': 5.797299477414587, 'avg_acc': 49.88396172522137, 'loss': 5.669032573699951}


EP_train:1:  51%|| 3511/6926 [19:22:03&lt;17:58:31, 18.95s/it]

{'epoch': 1, 'iter': 3510, 'avg_loss': 5.79730965805271, 'avg_acc': 49.86916120763315, 'loss': 6.08472204208374}


EP_train:1:  51%|| 3521/6926 [19:25:12&lt;17:53:36, 18.92s/it]

{'epoch': 1, 'iter': 3520, 'avg_loss': 5.797139988064732, 'avg_acc': 49.861545015620564, 'loss': 5.721656799316406}


EP_train:1:  51%|| 3531/6926 [19:28:22&lt;17:49:56, 18.91s/it]

{'epoch': 1, 'iter': 3530, 'avg_loss': 5.796997390229585, 'avg_acc': 49.8548569810252, 'loss': 5.389169692993164}


EP_train:1:  51%|| 3541/6926 [19:31:30&lt;17:42:49, 18.84s/it]

{'epoch': 1, 'iter': 3540, 'avg_loss': 5.796650430571053, 'avg_acc': 49.8570319118893, 'loss': 5.669034481048584}


EP_train:1:  51%|| 3551/6926 [19:34:39&lt;17:44:43, 18.93s/it]

{'epoch': 1, 'iter': 3550, 'avg_loss': 5.796759259361711, 'avg_acc': 49.85479442410588, 'loss': 5.946142196655273}


EP_train:1:  51%|| 3561/6926 [19:37:47&lt;17:30:43, 18.73s/it]

{'epoch': 1, 'iter': 3560, 'avg_loss': 5.796634467456221, 'avg_acc': 49.85520219039596, 'loss': 5.647500514984131}


EP_train:1:  52%|| 3571/6926 [19:40:53&lt;17:20:25, 18.61s/it]

{'epoch': 1, 'iter': 3570, 'avg_loss': 5.7965164471660735, 'avg_acc': 49.85385746289555, 'loss': 5.817470073699951}


EP_train:1:  52%|| 3581/6926 [19:44:00&lt;17:23:51, 18.72s/it]

{'epoch': 1, 'iter': 3580, 'avg_loss': 5.796583670872079, 'avg_acc': 49.86211951968723, 'loss': 6.430782318115234}


EP_train:1:  52%|| 3591/6926 [19:47:06&lt;17:17:14, 18.66s/it]

{'epoch': 1, 'iter': 3590, 'avg_loss': 5.796288941637515, 'avg_acc': 49.87207602339181, 'loss': 5.8473734855651855}


EP_train:1:  52%|| 3601/6926 [19:50:12&lt;17:06:33, 18.52s/it]

{'epoch': 1, 'iter': 3600, 'avg_loss': 5.7958874981855555, 'avg_acc': 49.87590252707581, 'loss': 5.566928386688232}


EP_train:1:  52%|| 3611/6926 [19:53:17&lt;17:06:04, 18.57s/it]

{'epoch': 1, 'iter': 3610, 'avg_loss': 5.796095670342479, 'avg_acc': 49.87711160343395, 'loss': 5.474966526031494}


EP_train:1:  52%|| 3621/6926 [19:57:09&lt;20:14:31, 22.05s/it]

{'epoch': 1, 'iter': 3620, 'avg_loss': 5.796189312248789, 'avg_acc': 49.883492129246065, 'loss': 5.988002777099609}


EP_train:1:  52%|| 3631/6926 [20:00:59&lt;23:19:53, 25.49s/it]

{'epoch': 1, 'iter': 3630, 'avg_loss': 5.796312926131416, 'avg_acc': 49.88897686587717, 'loss': 5.757579803466797}


EP_train:1:  53%|| 3641/6926 [20:04:05&lt;17:04:46, 18.72s/it]

{'epoch': 1, 'iter': 3640, 'avg_loss': 5.796070382412369, 'avg_acc': 49.88842351002472, 'loss': 5.555129051208496}


EP_train:1:  53%|| 3651/6926 [20:07:25&lt;17:51:29, 19.63s/it]

{'epoch': 1, 'iter': 3650, 'avg_loss': 5.795582013664361, 'avg_acc': 49.89044097507532, 'loss': 5.464755535125732}


EP_train:1:  53%|| 3661/6926 [20:10:35&lt;17:00:01, 18.74s/it]

{'epoch': 1, 'iter': 3660, 'avg_loss': 5.795854019617259, 'avg_acc': 49.88903305107894, 'loss': 5.79459285736084}


EP_train:1:  53%|| 3671/6926 [20:13:38&lt;16:34:25, 18.33s/it]

{'epoch': 1, 'iter': 3670, 'avg_loss': 5.795935146557281, 'avg_acc': 49.88763279760283, 'loss': 6.025897979736328}


EP_train:1:  53%|| 3681/6926 [20:16:41&lt;16:28:18, 18.27s/it]

{'epoch': 1, 'iter': 3680, 'avg_loss': 5.7961370896399265, 'avg_acc': 49.894729693018206, 'loss': 6.070523262023926}


EP_train:1:  53%|| 3691/6926 [20:19:42&lt;16:11:59, 18.03s/it]

{'epoch': 1, 'iter': 3690, 'avg_loss': 5.796098995260416, 'avg_acc': 49.894168247087514, 'loss': 5.607734680175781}


EP_train:1:  53%|| 3701/6926 [20:22:42&lt;16:06:22, 17.98s/it]

{'epoch': 1, 'iter': 3700, 'avg_loss': 5.796049712252469, 'avg_acc': 49.896987300729535, 'loss': 6.21684455871582}


EP_train:1:  54%|| 3711/6926 [20:25:42&lt;16:00:13, 17.92s/it]

{'epoch': 1, 'iter': 3710, 'avg_loss': 5.795763020244322, 'avg_acc': 49.89389652384802, 'loss': 5.917003154754639}


EP_train:1:  54%|| 3721/6926 [20:28:39&lt;15:49:20, 17.77s/it]

{'epoch': 1, 'iter': 3720, 'avg_loss': 5.795843896478839, 'avg_acc': 49.909298575651704, 'loss': 6.046869277954102}


EP_train:1:  54%|| 3731/6926 [20:31:36&lt;15:42:15, 17.69s/it]

{'epoch': 1, 'iter': 3730, 'avg_loss': 5.795734848486646, 'avg_acc': 49.91037925489145, 'loss': 6.020778179168701}


EP_train:1:  54%|| 3741/6926 [20:34:32&lt;15:29:33, 17.51s/it]

{'epoch': 1, 'iter': 3740, 'avg_loss': 5.795458523164743, 'avg_acc': 49.92147821438118, 'loss': 5.970174312591553}


EP_train:1:  54%|| 3751/6926 [20:37:25&lt;15:12:40, 17.25s/it]

{'epoch': 1, 'iter': 3750, 'avg_loss': 5.795276692313405, 'avg_acc': 49.915855771794185, 'loss': 6.3066253662109375}


EP_train:1:  54%|| 3761/6926 [20:40:17&lt;15:01:38, 17.09s/it]

{'epoch': 1, 'iter': 3760, 'avg_loss': 5.795042146871902, 'avg_acc': 49.91358681201808, 'loss': 5.656373023986816}


EP_train:1:  54%|| 3771/6926 [20:43:08&lt;14:58:57, 17.10s/it]

{'epoch': 1, 'iter': 3770, 'avg_loss': 5.795108221848679, 'avg_acc': 49.90801511535402, 'loss': 5.706948280334473}


EP_train:1:  55%|| 3781/6926 [20:45:59&lt;14:57:48, 17.13s/it]

{'epoch': 1, 'iter': 3780, 'avg_loss': 5.795098736562983, 'avg_acc': 49.908258397249405, 'loss': 6.0315070152282715}


EP_train:1:  55%|| 3791/6926 [20:48:50&lt;14:49:26, 17.02s/it]

{'epoch': 1, 'iter': 3790, 'avg_loss': 5.795354385547039, 'avg_acc': 49.91427064099182, 'loss': 6.394899368286133}


EP_train:1:  55%|| 3801/6926 [20:51:39&lt;14:40:22, 16.90s/it]

{'epoch': 1, 'iter': 3800, 'avg_loss': 5.795517491905415, 'avg_acc': 49.903808208366215, 'loss': 5.58576774597168}


EP_train:1:  55%|| 3811/6926 [20:54:28&lt;14:37:55, 16.91s/it]

{'epoch': 1, 'iter': 3810, 'avg_loss': 5.795274944700803, 'avg_acc': 49.9048806087641, 'loss': 5.320634365081787}


EP_train:1:  55%|| 3821/6926 [20:57:17&lt;14:35:43, 16.92s/it]

{'epoch': 1, 'iter': 3820, 'avg_loss': 5.7953101960316715, 'avg_acc': 49.91249018581524, 'loss': 5.8170318603515625}


EP_train:1:  55%|| 3831/6926 [21:00:05&lt;14:21:10, 16.69s/it]

{'epoch': 1, 'iter': 3830, 'avg_loss': 5.795442255941703, 'avg_acc': 49.92332289219525, 'loss': 5.72982120513916}


EP_train:1:  55%|| 3841/6926 [21:02:51&lt;14:13:10, 16.59s/it]

{'epoch': 1, 'iter': 3840, 'avg_loss': 5.7952990185559585, 'avg_acc': 49.93409919291851, 'loss': 5.5230255126953125}


EP_train:1:  56%|| 3851/6926 [21:05:36&lt;14:06:31, 16.52s/it]

{'epoch': 1, 'iter': 3850, 'avg_loss': 5.7952710199715165, 'avg_acc': 49.93264736432096, 'loss': 5.660543441772461}


EP_train:1:  56%|| 3861/6926 [21:08:20&lt;13:54:19, 16.33s/it]

{'epoch': 1, 'iter': 3860, 'avg_loss': 5.794991210531429, 'avg_acc': 49.921490546490546, 'loss': 5.702726364135742}


EP_train:1:  56%|| 3871/6926 [21:11:03&lt;13:45:22, 16.21s/it]

{'epoch': 1, 'iter': 3870, 'avg_loss': 5.795202156457135, 'avg_acc': 49.92492250064583, 'loss': 5.88737154006958}


EP_train:1:  56%|| 3881/6926 [21:13:44&lt;13:38:04, 16.12s/it]

{'epoch': 1, 'iter': 3880, 'avg_loss': 5.795012125370583, 'avg_acc': 49.93236279309456, 'loss': 5.569786548614502}


EP_train:1:  56%|| 3891/6926 [21:16:24&lt;13:28:15, 15.98s/it]

{'epoch': 1, 'iter': 3890, 'avg_loss': 5.79500720912097, 'avg_acc': 49.92852094577229, 'loss': 5.793521404266357}


EP_train:1:  56%|| 3901/6926 [21:19:03&lt;13:20:24, 15.88s/it]

{'epoch': 1, 'iter': 3900, 'avg_loss': 5.79471958615602, 'avg_acc': 49.930306331709815, 'loss': 5.839369297027588}


EP_train:1:  56%|| 3911/6926 [21:21:41&lt;13:07:56, 15.68s/it]

{'epoch': 1, 'iter': 3910, 'avg_loss': 5.794606451791926, 'avg_acc': 49.933680644336484, 'loss': 5.522931098937988}


EP_train:1:  57%|| 3921/6926 [21:24:18&lt;13:00:51, 15.59s/it]

{'epoch': 1, 'iter': 3920, 'avg_loss': 5.7943557105907155, 'avg_acc': 49.923488905891354, 'loss': 5.36496114730835}


EP_train:1:  57%|| 3931/6926 [21:26:53&lt;12:52:24, 15.47s/it]

{'epoch': 1, 'iter': 3930, 'avg_loss': 5.794669412468808, 'avg_acc': 49.93560798778937, 'loss': 5.800092697143555}


EP_train:1:  57%|| 3941/6926 [21:29:27&lt;12:45:45, 15.39s/it]

{'epoch': 1, 'iter': 3940, 'avg_loss': 5.794817465448464, 'avg_acc': 49.92704897234205, 'loss': 6.14797306060791}


EP_train:1:  57%|| 3951/6926 [21:32:01&lt;12:41:35, 15.36s/it]

{'epoch': 1, 'iter': 3950, 'avg_loss': 5.794826054385993, 'avg_acc': 49.92802455074665, 'loss': 5.839995384216309}


EP_train:1:  57%|| 3961/6926 [21:34:34&lt;12:39:14, 15.36s/it]

{'epoch': 1, 'iter': 3960, 'avg_loss': 5.794849992490604, 'avg_acc': 49.92899520323151, 'loss': 5.774095058441162}


EP_train:1:  57%|| 3971/6926 [21:37:06&lt;12:25:51, 15.14s/it]

{'epoch': 1, 'iter': 3970, 'avg_loss': 5.794746690239543, 'avg_acc': 49.92917401158398, 'loss': 5.460506439208984}


EP_train:1:  57%|| 3981/6926 [21:39:38&lt;12:23:54, 15.16s/it]

{'epoch': 1, 'iter': 3980, 'avg_loss': 5.794556604082097, 'avg_acc': 49.9222871137905, 'loss': 5.621820449829102}


EP_train:1:  58%|| 3991/6926 [21:42:08&lt;12:13:49, 15.00s/it]

{'epoch': 1, 'iter': 3990, 'avg_loss': 5.794708291380903, 'avg_acc': 49.926396893009276, 'loss': 5.9321208000183105}


EP_train:1:  58%|| 4001/6926 [21:44:38&lt;12:02:50, 14.83s/it]

{'epoch': 1, 'iter': 4000, 'avg_loss': 5.794589236091894, 'avg_acc': 49.9265808547863, 'loss': 5.453184604644775}


EP_train:1:  58%|| 4011/6926 [21:47:05&lt;11:53:06, 14.68s/it]

{'epoch': 1, 'iter': 4010, 'avg_loss': 5.794481540314725, 'avg_acc': 49.926763899276985, 'loss': 5.48418664932251}


EP_train:1:  58%|| 4021/6926 [21:49:31&lt;11:47:59, 14.62s/it]

{'epoch': 1, 'iter': 4020, 'avg_loss': 5.794357808660258, 'avg_acc': 49.92539169360855, 'loss': 5.723490238189697}


EP_train:1:  58%|| 4031/6926 [21:51:57&lt;11:46:30, 14.64s/it]

{'epoch': 1, 'iter': 4030, 'avg_loss': 5.794494402967532, 'avg_acc': 49.92325105432895, 'loss': 5.922822952270508}


EP_train:1:  58%|| 4041/6926 [21:54:21&lt;11:25:22, 14.25s/it]

{'epoch': 1, 'iter': 4040, 'avg_loss': 5.794372910469129, 'avg_acc': 49.929627567433805, 'loss': 5.785887241363525}


EP_train:1:  58%|| 4051/6926 [21:56:42&lt;11:19:09, 14.17s/it]

{'epoch': 1, 'iter': 4050, 'avg_loss': 5.794430562402843, 'avg_acc': 49.929029869168104, 'loss': 5.535454273223877}


EP_train:1:  59%|| 4061/6926 [21:59:02&lt;11:07:50, 13.99s/it]

{'epoch': 1, 'iter': 4060, 'avg_loss': 5.794532713059926, 'avg_acc': 49.921509480423545, 'loss': 5.970178604125977}


EP_train:1:  59%|| 4071/6926 [22:01:22&lt;11:01:04, 13.89s/it]

{'epoch': 1, 'iter': 4070, 'avg_loss': 5.794323054791317, 'avg_acc': 49.91939941046426, 'loss': 5.706122875213623}


EP_train:1:  59%|| 4081/6926 [22:03:39&lt;10:46:51, 13.64s/it]

{'epoch': 1, 'iter': 4080, 'avg_loss': 5.79427270204581, 'avg_acc': 49.91883116883117, 'loss': 5.926842212677002}


EP_train:1:  59%|| 4091/6926 [22:05:55&lt;10:42:52, 13.61s/it]

{'epoch': 1, 'iter': 4090, 'avg_loss': 5.794327908173018, 'avg_acc': 49.924376680518215, 'loss': 5.8620381355285645}


EP_train:1:  59%|| 4101/6926 [22:08:10&lt;10:34:33, 13.48s/it]

{'epoch': 1, 'iter': 4100, 'avg_loss': 5.794293555013438, 'avg_acc': 49.925323091928796, 'loss': 6.033656120300293}


EP_train:1:  59%|| 4111/6926 [22:10:23&lt;10:24:16, 13.31s/it]

{'epoch': 1, 'iter': 4110, 'avg_loss': 5.794242945415671, 'avg_acc': 49.92018365361226, 'loss': 5.560708522796631}


EP_train:1:  60%|| 4121/6926 [22:12:34&lt;10:12:20, 13.10s/it]

{'epoch': 1, 'iter': 4120, 'avg_loss': 5.794160013724172, 'avg_acc': 49.91582746906091, 'loss': 6.027267932891846}


EP_train:1:  60%|| 4131/6926 [22:14:44&lt;10:08:10, 13.06s/it]

{'epoch': 1, 'iter': 4130, 'avg_loss': 5.793972036042649, 'avg_acc': 49.90846647300896, 'loss': 5.352296352386475}


EP_train:1:  60%|| 4141/6926 [22:16:53&lt;9:58:12, 12.89s/it] 

{'epoch': 1, 'iter': 4140, 'avg_loss': 5.79385355399214, 'avg_acc': 49.901895677372615, 'loss': 5.622790813446045}


EP_train:1:  60%|| 4151/6926 [22:19:02&lt;9:59:10, 12.96s/it]

{'epoch': 1, 'iter': 4150, 'avg_loss': 5.793552322291202, 'avg_acc': 49.90137918573838, 'loss': 5.768672943115234}


EP_train:1:  60%|| 4161/6926 [22:21:10&lt;9:45:22, 12.70s/it]

{'epoch': 1, 'iter': 4160, 'avg_loss': 5.793569183555883, 'avg_acc': 49.895608026916605, 'loss': 5.898829460144043}


EP_train:1:  60%|| 4171/6926 [22:23:16&lt;9:38:30, 12.60s/it]

{'epoch': 1, 'iter': 4170, 'avg_loss': 5.793333467777557, 'avg_acc': 49.89585830736035, 'loss': 5.702149391174316}


EP_train:1:  60%|| 4181/6926 [22:25:22&lt;9:30:18, 12.47s/it]

{'epoch': 1, 'iter': 4180, 'avg_loss': 5.793202239399006, 'avg_acc': 49.89237024635255, 'loss': 6.27134895324707}


EP_train:1:  61%|| 4191/6926 [22:27:26&lt;9:24:02, 12.37s/it]

{'epoch': 1, 'iter': 4190, 'avg_loss': 5.793524647805777, 'avg_acc': 49.89784657599618, 'loss': 6.174899101257324}


EP_train:1:  61%|| 4201/6926 [22:29:29&lt;9:16:32, 12.25s/it]

{'epoch': 1, 'iter': 4200, 'avg_loss': 5.793787608229526, 'avg_acc': 49.89808974053796, 'loss': 5.691822052001953}


EP_train:1:  61%|| 4211/6926 [22:31:31&lt;9:13:11, 12.23s/it]

{'epoch': 1, 'iter': 4210, 'avg_loss': 5.7935389137358655, 'avg_acc': 49.89016860603182, 'loss': 5.811758041381836}


EP_train:1:  61%|| 4221/6926 [22:33:31&lt;8:58:32, 11.95s/it]

{'epoch': 1, 'iter': 4220, 'avg_loss': 5.793146554227972, 'avg_acc': 49.895611229566455, 'loss': 5.675384998321533}


EP_train:1:  61%|| 4231/6926 [22:35:30&lt;8:57:14, 11.96s/it]

{'epoch': 1, 'iter': 4230, 'avg_loss': 5.793019925750646, 'avg_acc': 49.88994918458993, 'loss': 5.687623977661133}


EP_train:1:  61%|| 4241/6926 [22:37:28&lt;8:43:06, 11.69s/it]

{'epoch': 1, 'iter': 4240, 'avg_loss': 5.792919600130786, 'avg_acc': 49.901261494930445, 'loss': 6.263227462768555}


EP_train:1:  61%|| 4251/6926 [22:39:23&lt;8:31:24, 11.47s/it]

{'epoch': 1, 'iter': 4250, 'avg_loss': 5.792667934962425, 'avg_acc': 49.90810985650435, 'loss': 5.616147041320801}


EP_train:1:  62%|| 4261/6926 [22:41:17&lt;8:19:48, 11.25s/it]

{'epoch': 1, 'iter': 4260, 'avg_loss': 5.7923400158670635, 'avg_acc': 49.90832551044356, 'loss': 5.353346824645996}


EP_train:1:  62%|| 4271/6926 [22:43:09&lt;8:12:14, 11.12s/it]

{'epoch': 1, 'iter': 4270, 'avg_loss': 5.7925298052631256, 'avg_acc': 49.91000351205807, 'loss': 6.090911865234375}


EP_train:1:  62%|| 4281/6926 [22:44:59&lt;8:06:40, 11.04s/it]

{'epoch': 1, 'iter': 4280, 'avg_loss': 5.792039564796988, 'avg_acc': 49.9145935529082, 'loss': 5.736459255218506}


EP_train:1:  62%|| 4291/6926 [22:46:48&lt;7:57:58, 10.88s/it]

{'epoch': 1, 'iter': 4290, 'avg_loss': 5.792303221344087, 'avg_acc': 49.91115124679562, 'loss': 5.262261867523193}


EP_train:1:  62%|| 4301/6926 [22:48:38&lt;7:59:20, 10.96s/it]

{'epoch': 1, 'iter': 4300, 'avg_loss': 5.792396713151291, 'avg_acc': 49.90263892118112, 'loss': 5.961178302764893}


EP_train:1:  62%|| 4311/6926 [22:50:27&lt;7:52:27, 10.84s/it]

{'epoch': 1, 'iter': 4310, 'avg_loss': 5.792013904551181, 'avg_acc': 49.90866388308977, 'loss': 5.368079662322998}


EP_train:1:  62%|| 4321/6926 [22:52:15&lt;7:47:57, 10.78s/it]

{'epoch': 1, 'iter': 4320, 'avg_loss': 5.791845591800463, 'avg_acc': 49.919000231427916, 'loss': 5.8557209968566895}


EP_train:1:  63%|| 4331/6926 [22:54:02&lt;7:44:36, 10.74s/it]

{'epoch': 1, 'iter': 4330, 'avg_loss': 5.791850880865301, 'avg_acc': 49.922794966520435, 'loss': 5.736635684967041}


EP_train:1:  63%|| 4341/6926 [22:55:49&lt;7:42:25, 10.73s/it]

{'epoch': 1, 'iter': 4340, 'avg_loss': 5.791390453937058, 'avg_acc': 49.93305114029026, 'loss': 5.70697021484375}


EP_train:1:  63%|| 4351/6926 [22:57:35&lt;7:33:16, 10.56s/it]

{'epoch': 1, 'iter': 4350, 'avg_loss': 5.791365481003814, 'avg_acc': 49.92817743047575, 'loss': 5.999698638916016}


EP_train:1:  63%|| 4361/6926 [22:59:19&lt;7:25:05, 10.41s/it]

{'epoch': 1, 'iter': 4360, 'avg_loss': 5.791415565195939, 'avg_acc': 49.93264159596423, 'loss': 5.592486381530762}


EP_train:1:  63%|| 4371/6926 [23:01:02&lt;7:13:48, 10.19s/it]

{'epoch': 1, 'iter': 4370, 'avg_loss': 5.791266237126693, 'avg_acc': 49.928506062685884, 'loss': 5.677746772766113}


EP_train:1:  63%|| 4381/6926 [23:02:43&lt;7:11:54, 10.18s/it]

{'epoch': 1, 'iter': 4380, 'avg_loss': 5.791361003236612, 'avg_acc': 49.94150878794796, 'loss': 5.427810192108154}


EP_train:1:  63%|| 4391/6926 [23:04:26&lt;7:11:05, 10.20s/it]

{'epoch': 1, 'iter': 4390, 'avg_loss': 5.791563838089118, 'avg_acc': 49.93737189706217, 'loss': 6.359541893005371}


EP_train:1:  64%|| 4401/6926 [23:06:08&lt;7:10:25, 10.23s/it]

{'epoch': 1, 'iter': 4400, 'avg_loss': 5.791609601577935, 'avg_acc': 49.928283344694385, 'loss': 6.141855716705322}


EP_train:1:  64%|| 4411/6926 [23:07:47&lt;6:54:27,  9.89s/it]

{'epoch': 1, 'iter': 4410, 'avg_loss': 5.791563305933711, 'avg_acc': 49.93127975515756, 'loss': 5.503215789794922}


EP_train:1:  64%|| 4421/6926 [23:09:25&lt;6:48:06,  9.77s/it]

{'epoch': 1, 'iter': 4420, 'avg_loss': 5.791686383018503, 'avg_acc': 49.93779687853427, 'loss': 5.017365455627441}


EP_train:1:  64%|| 4431/6926 [23:11:03&lt;6:42:23,  9.68s/it]

{'epoch': 1, 'iter': 4430, 'avg_loss': 5.791787002781287, 'avg_acc': 49.929474159331974, 'loss': 5.570000648498535}


EP_train:1:  64%|| 4441/6926 [23:12:39&lt;6:32:18,  9.47s/it]

{'epoch': 1, 'iter': 4440, 'avg_loss': 5.79137702472466, 'avg_acc': 49.933151317270884, 'loss': 5.4280686378479}


EP_train:1:  64%|| 4451/6926 [23:14:13&lt;6:26:55,  9.38s/it]

{'epoch': 1, 'iter': 4450, 'avg_loss': 5.791135346265461, 'avg_acc': 49.93119523702539, 'loss': 5.561283111572266}


EP_train:1:  64%|| 4461/6926 [23:15:48&lt;6:32:12,  9.55s/it]

{'epoch': 1, 'iter': 4460, 'avg_loss': 5.790786760480274, 'avg_acc': 49.932750504371214, 'loss': 5.831860065460205}


EP_train:1:  65%|| 4471/6926 [23:17:21&lt;6:19:34,  9.28s/it]

{'epoch': 1, 'iter': 4470, 'avg_loss': 5.7904958413554315, 'avg_acc': 49.93220196823977, 'loss': 5.783606052398682}


EP_train:1:  65%|| 4481/6926 [23:18:54&lt;6:15:03,  9.20s/it]

{'epoch': 1, 'iter': 4480, 'avg_loss': 5.790014457234419, 'avg_acc': 49.92537937960277, 'loss': 5.5710649490356445}


EP_train:1:  65%|| 4491/6926 [23:20:24&lt;6:09:03,  9.09s/it]

{'epoch': 1, 'iter': 4490, 'avg_loss': 5.789725657959766, 'avg_acc': 49.92624137163215, 'loss': 5.569758892059326}


EP_train:1:  65%|| 4501/6926 [23:21:54&lt;6:00:42,  8.92s/it]

{'epoch': 1, 'iter': 4500, 'avg_loss': 5.78943614423659, 'avg_acc': 49.929876694067985, 'loss': 5.799868106842041}


EP_train:1:  65%|| 4511/6926 [23:23:24&lt;5:59:54,  8.94s/it]

{'epoch': 1, 'iter': 4510, 'avg_loss': 5.789443961481539, 'avg_acc': 49.93280314786078, 'loss': 6.369606971740723}


EP_train:1:  65%|| 4521/6926 [23:24:52&lt;5:55:48,  8.88s/it]

{'epoch': 1, 'iter': 4520, 'avg_loss': 5.789692890430493, 'avg_acc': 49.930878124308784, 'loss': 6.097248554229736}


EP_train:1:  65%|| 4531/6926 [23:26:18&lt;5:46:32,  8.68s/it]

{'epoch': 1, 'iter': 4530, 'avg_loss': 5.789552313948382, 'avg_acc': 49.93447914367689, 'loss': 6.212596416473389}


EP_train:1:  66%|| 4541/6926 [23:27:43&lt;5:36:53,  8.48s/it]

{'epoch': 1, 'iter': 4540, 'avg_loss': 5.789276582032829, 'avg_acc': 49.94081700066065, 'loss': 5.68822717666626}


EP_train:1:  66%|| 4551/6926 [23:29:07&lt;5:32:37,  8.40s/it]

{'epoch': 1, 'iter': 4550, 'avg_loss': 5.788956431445643, 'avg_acc': 49.92790046143705, 'loss': 5.529911994934082}


EP_train:1:  66%|| 4561/6926 [23:30:32&lt;5:35:45,  8.52s/it]

{'epoch': 1, 'iter': 4560, 'avg_loss': 5.788553897917885, 'avg_acc': 49.94244683183513, 'loss': 5.255894660949707}


EP_train:1:  66%|| 4571/6926 [23:31:55&lt;5:26:48,  8.33s/it]

{'epoch': 1, 'iter': 4570, 'avg_loss': 5.788283214034984, 'avg_acc': 49.952143950995406, 'loss': 5.589775085449219}


EP_train:1:  66%|| 4581/6926 [23:33:18&lt;5:22:50,  8.26s/it]

{'epoch': 1, 'iter': 4580, 'avg_loss': 5.78847688016244, 'avg_acc': 49.95361274830823, 'loss': 5.636112213134766}


EP_train:1:  66%|| 4591/6926 [23:34:40&lt;5:19:28,  8.21s/it]

{'epoch': 1, 'iter': 4590, 'avg_loss': 5.788426787680308, 'avg_acc': 49.949629710302766, 'loss': 6.208221912384033}


EP_train:1:  66%|| 4601/6926 [23:36:01&lt;5:13:15,  8.08s/it]

{'epoch': 1, 'iter': 4600, 'avg_loss': 5.788588617553247, 'avg_acc': 49.93819278417735, 'loss': 5.983859539031982}


EP_train:1:  67%|| 4611/6926 [23:37:20&lt;5:05:21,  7.91s/it]

{'epoch': 1, 'iter': 4610, 'avg_loss': 5.788734662406125, 'avg_acc': 49.93697137280416, 'loss': 6.003018856048584}


EP_train:1:  67%|| 4621/6926 [23:38:39&lt;5:02:50,  7.88s/it]

{'epoch': 1, 'iter': 4620, 'avg_loss': 5.788934172605751, 'avg_acc': 49.939812811079854, 'loss': 6.00796365737915}


EP_train:1:  67%|| 4631/6926 [23:39:58&lt;5:02:32,  7.91s/it]

{'epoch': 1, 'iter': 4630, 'avg_loss': 5.789179396459439, 'avg_acc': 49.93589397538329, 'loss': 6.413631916046143}


EP_train:1:  67%|| 4641/6926 [23:41:17&lt;5:02:06,  7.93s/it]

{'epoch': 1, 'iter': 4640, 'avg_loss': 5.789161979882426, 'avg_acc': 49.9306453350571, 'loss': 5.865474224090576}


EP_train:1:  67%|| 4651/6926 [23:42:37&lt;5:01:00,  7.94s/it]

{'epoch': 1, 'iter': 4650, 'avg_loss': 5.788921422226355, 'avg_acc': 49.92945065577295, 'loss': 5.805312156677246}


EP_train:1:  67%|| 4661/6926 [23:43:55&lt;4:53:35,  7.78s/it]

{'epoch': 1, 'iter': 4660, 'avg_loss': 5.788980215257188, 'avg_acc': 49.932283844668525, 'loss': 5.606457710266113}


EP_train:1:  67%|| 4671/6926 [23:45:12&lt;4:49:20,  7.70s/it]

{'epoch': 1, 'iter': 4670, 'avg_loss': 5.789101604424102, 'avg_acc': 49.93242881609934, 'loss': 5.404266357421875}


EP_train:1:  68%|| 4681/6926 [23:46:29&lt;4:48:08,  7.70s/it]

{'epoch': 1, 'iter': 4680, 'avg_loss': 5.789283708944404, 'avg_acc': 49.94125186925871, 'loss': 5.393746852874756}


EP_train:1:  68%|| 4691/6926 [23:47:45&lt;4:39:49,  7.51s/it]

{'epoch': 1, 'iter': 4690, 'avg_loss': 5.789118626610198, 'avg_acc': 49.934715412492004, 'loss': 5.847562789916992}


EP_train:1:  68%|| 4701/6926 [23:49:00&lt;4:41:44,  7.60s/it]

{'epoch': 1, 'iter': 4700, 'avg_loss': 5.78872311822761, 'avg_acc': 49.93418953414167, 'loss': 5.54182767868042}


EP_train:1:  68%|| 4711/6926 [23:50:15&lt;4:36:25,  7.49s/it]

{'epoch': 1, 'iter': 4710, 'avg_loss': 5.788682299544922, 'avg_acc': 49.93432922946296, 'loss': 5.763123035430908}


EP_train:1:  68%|| 4721/6926 [23:51:30&lt;4:35:43,  7.50s/it]

{'epoch': 1, 'iter': 4720, 'avg_loss': 5.7887042617676645, 'avg_acc': 49.93579220504131, 'loss': 5.008922100067139}


EP_train:1:  68%|| 4731/6926 [23:52:43&lt;4:24:42,  7.24s/it]

{'epoch': 1, 'iter': 4730, 'avg_loss': 5.788827963143468, 'avg_acc': 49.9385700697527, 'loss': 6.348005294799805}


EP_train:1:  68%|| 4741/6926 [23:53:56&lt;4:24:02,  7.25s/it]

{'epoch': 1, 'iter': 4740, 'avg_loss': 5.788779858973579, 'avg_acc': 49.936063066863525, 'loss': 5.833249568939209}


EP_train:1:  69%|| 4751/6926 [23:55:08&lt;4:19:19,  7.15s/it]

{'epoch': 1, 'iter': 4750, 'avg_loss': 5.7885240177635495, 'avg_acc': 49.93882866764891, 'loss': 5.320862770080566}


EP_train:1:  69%|| 4761/6926 [23:56:20&lt;4:18:29,  7.16s/it]

{'epoch': 1, 'iter': 4760, 'avg_loss': 5.788583486777748, 'avg_acc': 49.930424280613316, 'loss': 6.05222749710083}


EP_train:1:  69%|| 4771/6926 [23:57:31&lt;4:16:08,  7.13s/it]

{'epoch': 1, 'iter': 4770, 'avg_loss': 5.788538340226931, 'avg_acc': 49.922055124711804, 'loss': 5.370018482208252}


EP_train:1:  69%|| 4781/6926 [23:58:43&lt;4:16:44,  7.18s/it]

{'epoch': 1, 'iter': 4780, 'avg_loss': 5.788333303084111, 'avg_acc': 49.92156452624974, 'loss': 6.177128314971924}


EP_train:1:  69%|| 4791/6926 [23:59:54&lt;4:11:23,  7.06s/it]

{'epoch': 1, 'iter': 4790, 'avg_loss': 5.788014187889441, 'avg_acc': 49.91846691713629, 'loss': 5.8995232582092285}


EP_train:1:  69%|| 4801/6926 [24:01:04&lt;4:08:19,  7.01s/it]

{'epoch': 1, 'iter': 4800, 'avg_loss': 5.788256717209914, 'avg_acc': 49.92254217871277, 'loss': 5.670840263366699}


EP_train:1:  69%|| 4811/6926 [24:02:13&lt;4:02:50,  6.89s/it]

{'epoch': 1, 'iter': 4810, 'avg_loss': 5.788121572330771, 'avg_acc': 49.910361671170236, 'loss': 5.873446941375732}


EP_train:1:  70%|| 4821/6926 [24:03:23&lt;4:03:00,  6.93s/it]

{'epoch': 1, 'iter': 4820, 'avg_loss': 5.787842813059394, 'avg_acc': 49.912492221530805, 'loss': 5.583961009979248}


EP_train:1:  70%|| 4831/6926 [24:04:30&lt;3:54:22,  6.71s/it]

{'epoch': 1, 'iter': 4830, 'avg_loss': 5.787578386836999, 'avg_acc': 49.912026495549576, 'loss': 5.802366733551025}


EP_train:1:  70%|| 4841/6926 [24:05:37&lt;3:51:06,  6.65s/it]

{'epoch': 1, 'iter': 4840, 'avg_loss': 5.787446636080963, 'avg_acc': 49.906398471390204, 'loss': 6.0409369468688965}


EP_train:1:  70%|| 4851/6926 [24:06:43&lt;3:50:05,  6.65s/it]

{'epoch': 1, 'iter': 4850, 'avg_loss': 5.787142503730933, 'avg_acc': 49.904658833230265, 'loss': 5.501993179321289}


EP_train:1:  70%|| 4861/6926 [24:07:48&lt;3:45:09,  6.54s/it]

{'epoch': 1, 'iter': 4860, 'avg_loss': 5.787131439092056, 'avg_acc': 49.90871219913598, 'loss': 5.414707183837891}


EP_train:1:  70%|| 4871/6926 [24:08:54&lt;3:46:09,  6.60s/it]

{'epoch': 1, 'iter': 4870, 'avg_loss': 5.787226953390956, 'avg_acc': 49.91146581810717, 'loss': 5.188268661499023}


EP_train:1:  70%|| 4881/6926 [24:09:59&lt;3:41:48,  6.51s/it]

{'epoch': 1, 'iter': 4880, 'avg_loss': 5.787362124875441, 'avg_acc': 49.9039643515673, 'loss': 5.624892234802246}


EP_train:1:  71%|| 4891/6926 [24:11:03&lt;3:35:34,  6.36s/it]

{'epoch': 1, 'iter': 4890, 'avg_loss': 5.787320288820175, 'avg_acc': 49.91821713351053, 'loss': 5.858331680297852}


EP_train:1:  71%|| 4901/6926 [24:12:07&lt;3:35:56,  6.40s/it]

{'epoch': 1, 'iter': 4900, 'avg_loss': 5.787399033871604, 'avg_acc': 49.92093450316262, 'loss': 5.9390363693237305}


EP_train:1:  71%|| 4911/6926 [24:13:10&lt;3:33:10,  6.35s/it]

{'epoch': 1, 'iter': 4910, 'avg_loss': 5.787554553219705, 'avg_acc': 49.92236815312563, 'loss': 6.048376083374023}


EP_train:1:  71%|| 4921/6926 [24:14:13&lt;3:29:15,  6.26s/it]

{'epoch': 1, 'iter': 4920, 'avg_loss': 5.787447882483486, 'avg_acc': 49.92697114407641, 'loss': 5.413477897644043}


EP_train:1:  71%|| 4931/6926 [24:15:16&lt;3:28:16,  6.26s/it]

{'epoch': 1, 'iter': 4930, 'avg_loss': 5.787312490513155, 'avg_acc': 49.92521800851754, 'loss': 5.5958638191223145}


EP_train:1:  71%|| 4941/6926 [24:16:18&lt;3:26:48,  6.25s/it]

{'epoch': 1, 'iter': 4940, 'avg_loss': 5.787154680899439, 'avg_acc': 49.92663428455778, 'loss': 5.397399425506592}


EP_train:1:  71%|| 4951/6926 [24:17:21&lt;3:24:41,  6.22s/it]

{'epoch': 1, 'iter': 4950, 'avg_loss': 5.787053776519319, 'avg_acc': 49.917945869521304, 'loss': 5.379844665527344}


EP_train:1:  72%|| 4961/6926 [24:18:23&lt;3:23:33,  6.22s/it]

{'epoch': 1, 'iter': 4960, 'avg_loss': 5.787061457046696, 'avg_acc': 49.91874118121346, 'loss': 5.6148505210876465}


EP_train:1:  72%|| 4971/6926 [24:19:24&lt;3:19:40,  6.13s/it]

{'epoch': 1, 'iter': 4970, 'avg_loss': 5.786740227931223, 'avg_acc': 49.920161939247635, 'loss': 5.569698333740234}


EP_train:1:  72%|| 4981/6926 [24:20:26&lt;3:20:32,  6.19s/it]

{'epoch': 1, 'iter': 4980, 'avg_loss': 5.78702146129612, 'avg_acc': 49.92659606504718, 'loss': 5.415506839752197}


EP_train:1:  72%|| 4991/6926 [24:21:27&lt;3:16:27,  6.09s/it]

{'epoch': 1, 'iter': 4990, 'avg_loss': 5.786872534731828, 'avg_acc': 49.92987377279102, 'loss': 5.665578842163086}


EP_train:1:  72%|| 5001/6926 [24:22:27&lt;3:14:32,  6.06s/it]

{'epoch': 1, 'iter': 5000, 'avg_loss': 5.786735336057331, 'avg_acc': 49.92314037192562, 'loss': 5.924252510070801}


EP_train:1:  72%|| 5011/6926 [24:23:28&lt;3:11:49,  6.01s/it]

{'epoch': 1, 'iter': 5010, 'avg_loss': 5.786793859151042, 'avg_acc': 49.9351426860906, 'loss': 6.492675304412842}


EP_train:1:  72%|| 5021/6926 [24:24:28&lt;3:10:16,  5.99s/it]

{'epoch': 1, 'iter': 5020, 'avg_loss': 5.786595426501328, 'avg_acc': 49.937761402111136, 'loss': 5.4357686042785645}


EP_train:1:  73%|| 5031/6926 [24:25:27&lt;3:07:46,  5.95s/it]

{'epoch': 1, 'iter': 5030, 'avg_loss': 5.7865324396661535, 'avg_acc': 49.939127410057644, 'loss': 5.767693519592285}


EP_train:1:  73%|| 5041/6926 [24:26:26&lt;3:04:39,  5.88s/it]

{'epoch': 1, 'iter': 5040, 'avg_loss': 5.786570438055073, 'avg_acc': 49.93304899821464, 'loss': 5.453466415405273}


EP_train:1:  73%|| 5051/6926 [24:27:24&lt;3:02:07,  5.83s/it]

{'epoch': 1, 'iter': 5050, 'avg_loss': 5.7864458643547545, 'avg_acc': 49.933181548208275, 'loss': 5.8941731452941895}


EP_train:1:  73%|| 5061/6926 [24:28:23&lt;3:02:16,  5.86s/it]

{'epoch': 1, 'iter': 5060, 'avg_loss': 5.786396266678722, 'avg_acc': 49.93146117368109, 'loss': 5.800904750823975}


EP_train:1:  73%|| 5071/6926 [24:29:21&lt;2:59:03,  5.79s/it]

{'epoch': 1, 'iter': 5070, 'avg_loss': 5.786205190945555, 'avg_acc': 49.9346775783869, 'loss': 5.469834327697754}


EP_train:1:  73%|| 5081/6926 [24:30:18&lt;2:56:08,  5.73s/it]

{'epoch': 1, 'iter': 5080, 'avg_loss': 5.785916267054167, 'avg_acc': 49.93542117693367, 'loss': 5.56289529800415}


EP_train:1:  74%|| 5091/6926 [24:31:15&lt;2:54:03,  5.69s/it]

{'epoch': 1, 'iter': 5090, 'avg_loss': 5.7859456138745715, 'avg_acc': 49.93677568257709, 'loss': 5.786680221557617}


EP_train:1:  74%|| 5101/6926 [24:32:12&lt;2:52:22,  5.67s/it]

{'epoch': 1, 'iter': 5100, 'avg_loss': 5.785936889917657, 'avg_acc': 49.9387375024505, 'loss': 5.944669723510742}


EP_train:1:  74%|| 5111/6926 [24:33:09&lt;2:52:03,  5.69s/it]

{'epoch': 1, 'iter': 5110, 'avg_loss': 5.785903461104012, 'avg_acc': 49.92968597143416, 'loss': 5.812314510345459}


EP_train:1:  74%|| 5121/6926 [24:34:06&lt;2:49:20,  5.63s/it]

{'epoch': 1, 'iter': 5120, 'avg_loss': 5.785528050947645, 'avg_acc': 49.91944932630346, 'loss': 5.632965564727783}


EP_train:1:  74%|| 5131/6926 [24:35:02&lt;2:47:46,  5.61s/it]

{'epoch': 1, 'iter': 5130, 'avg_loss': 5.785435689678203, 'avg_acc': 49.93117813291756, 'loss': 5.793095588684082}


EP_train:1:  74%|| 5141/6926 [24:35:59&lt;2:48:35,  5.67s/it]

{'epoch': 1, 'iter': 5140, 'avg_loss': 5.785562406553645, 'avg_acc': 49.94103773584906, 'loss': 6.014484882354736}


EP_train:1:  74%|| 5151/6926 [24:36:55&lt;2:46:17,  5.62s/it]

{'epoch': 1, 'iter': 5150, 'avg_loss': 5.785854521965986, 'avg_acc': 49.95328576975345, 'loss': 6.094200611114502}


EP_train:1:  75%|| 5161/6926 [24:37:50&lt;2:42:45,  5.53s/it]

{'epoch': 1, 'iter': 5160, 'avg_loss': 5.78595069091788, 'avg_acc': 49.95216527804689, 'loss': 5.796298503875732}


EP_train:1:  75%|| 5171/6926 [24:38:46&lt;2:42:56,  5.57s/it]

{'epoch': 1, 'iter': 5170, 'avg_loss': 5.785935990977762, 'avg_acc': 49.95165345194353, 'loss': 5.894540309906006}


EP_train:1:  75%|| 5181/6926 [24:39:41&lt;2:40:25,  5.52s/it]

{'epoch': 1, 'iter': 5180, 'avg_loss': 5.785864553817841, 'avg_acc': 49.95295309785755, 'loss': 5.792293548583984}


EP_train:1:  75%|| 5191/6926 [24:40:35&lt;2:36:49,  5.42s/it]

{'epoch': 1, 'iter': 5190, 'avg_loss': 5.785756077065539, 'avg_acc': 49.9488297052591, 'loss': 5.8627824783325195}


EP_train:1:  75%|| 5201/6926 [24:41:29&lt;2:34:54,  5.39s/it]

{'epoch': 1, 'iter': 5200, 'avg_loss': 5.785612379810118, 'avg_acc': 49.94952893674293, 'loss': 5.686365127563477}


EP_train:1:  75%|| 5211/6926 [24:42:23&lt;2:33:07,  5.36s/it]

{'epoch': 1, 'iter': 5210, 'avg_loss': 5.785322140741431, 'avg_acc': 49.95082517750912, 'loss': 5.074163436889648}


EP_train:1:  75%|| 5221/6926 [24:43:17&lt;2:32:20,  5.36s/it]

{'epoch': 1, 'iter': 5220, 'avg_loss': 5.785333730141977, 'avg_acc': 49.94493392070485, 'loss': 6.03475284576416}


EP_train:1:  76%|| 5231/6926 [24:44:10&lt;2:29:47,  5.30s/it]

{'epoch': 1, 'iter': 5230, 'avg_loss': 5.7852302342339925, 'avg_acc': 49.94503918944753, 'loss': 5.761468410491943}


EP_train:1:  76%|| 5241/6926 [24:45:04&lt;2:30:22,  5.35s/it]

{'epoch': 1, 'iter': 5240, 'avg_loss': 5.785118418098338, 'avg_acc': 49.94037397443236, 'loss': 5.688961982727051}


EP_train:1:  76%|| 5251/6926 [24:45:57&lt;2:27:52,  5.30s/it]

{'epoch': 1, 'iter': 5250, 'avg_loss': 5.78509274066641, 'avg_acc': 49.936321653018474, 'loss': 5.434635162353516}


EP_train:1:  76%|| 5261/6926 [24:46:50&lt;2:27:38,  5.32s/it]

{'epoch': 1, 'iter': 5260, 'avg_loss': 5.7850141297771644, 'avg_acc': 49.935254704428814, 'loss': 5.639525413513184}


EP_train:1:  76%|| 5271/6926 [24:47:44&lt;2:27:15,  5.34s/it]

{'epoch': 1, 'iter': 5270, 'avg_loss': 5.785223968384999, 'avg_acc': 49.92944887118193, 'loss': 5.607095241546631}


EP_train:1:  76%|| 5281/6926 [24:48:37&lt;2:24:16,  5.26s/it]

{'epoch': 1, 'iter': 5280, 'avg_loss': 5.785083117301752, 'avg_acc': 49.92780723347851, 'loss': 5.321253299713135}


EP_train:1:  76%|| 5291/6926 [24:49:29&lt;2:23:46,  5.28s/it]

{'epoch': 1, 'iter': 5290, 'avg_loss': 5.785107800154397, 'avg_acc': 49.92026554526554, 'loss': 5.930552959442139}


EP_train:1:  77%|| 5301/6926 [24:50:23&lt;2:23:56,  5.32s/it]

{'epoch': 1, 'iter': 5300, 'avg_loss': 5.785208872097255, 'avg_acc': 49.91687889077532, 'loss': 5.997699737548828}


EP_train:1:  77%|| 5311/6926 [24:51:16&lt;2:22:08,  5.28s/it]

{'epoch': 1, 'iter': 5310, 'avg_loss': 5.7851737416906115, 'avg_acc': 49.92056580681604, 'loss': 5.9337663650512695}


EP_train:1:  77%|| 5321/6926 [24:52:08&lt;2:18:40,  5.18s/it]

{'epoch': 1, 'iter': 5320, 'avg_loss': 5.785334258302668, 'avg_acc': 49.923064273632775, 'loss': 5.717741966247559}


EP_train:1:  77%|| 5331/6926 [24:52:59&lt;2:16:15,  5.13s/it]

{'epoch': 1, 'iter': 5330, 'avg_loss': 5.785141843811161, 'avg_acc': 49.926139561057965, 'loss': 6.1371846199035645}


EP_train:1:  77%|| 5341/6926 [24:53:51&lt;2:17:27,  5.20s/it]

{'epoch': 1, 'iter': 5340, 'avg_loss': 5.784899124155507, 'avg_acc': 49.921597079198655, 'loss': 5.609897613525391}


EP_train:1:  77%|| 5351/6926 [24:54:42&lt;2:14:15,  5.11s/it]

{'epoch': 1, 'iter': 5350, 'avg_loss': 5.784700462916614, 'avg_acc': 49.91707157540647, 'loss': 5.650408744812012}


EP_train:1:  77%|| 5361/6926 [24:55:33&lt;2:13:07,  5.10s/it]

{'epoch': 1, 'iter': 5360, 'avg_loss': 5.784607118511573, 'avg_acc': 49.91722626375677, 'loss': 5.6946563720703125}


EP_train:1:  78%|| 5371/6926 [24:56:24&lt;2:11:34,  5.08s/it]

{'epoch': 1, 'iter': 5370, 'avg_loss': 5.784720784746453, 'avg_acc': 49.916216719419104, 'loss': 6.1461615562438965}


EP_train:1:  78%|| 5381/6926 [24:57:14&lt;2:10:16,  5.06s/it]

{'epoch': 1, 'iter': 5380, 'avg_loss': 5.784454568215317, 'avg_acc': 49.917533915629065, 'loss': 5.918368816375732}


EP_train:1:  78%|| 5391/6926 [24:58:05&lt;2:09:56,  5.08s/it]

{'epoch': 1, 'iter': 5390, 'avg_loss': 5.784659076546323, 'avg_acc': 49.911890187349286, 'loss': 6.016552925109863}


EP_train:1:  78%|| 5401/6926 [24:58:56&lt;2:08:24,  5.05s/it]

{'epoch': 1, 'iter': 5400, 'avg_loss': 5.784735913145125, 'avg_acc': 49.91089613034623, 'loss': 6.018709182739258}


EP_train:1:  78%|| 5411/6926 [24:59:47&lt;2:08:12,  5.08s/it]

{'epoch': 1, 'iter': 5410, 'avg_loss': 5.784527376605323, 'avg_acc': 49.909328220292, 'loss': 5.77882719039917}


EP_train:1:  78%|| 5421/6926 [25:00:38&lt;2:08:26,  5.12s/it]

{'epoch': 1, 'iter': 5420, 'avg_loss': 5.784672113037532, 'avg_acc': 49.91698948533481, 'loss': 5.923573970794678}


EP_train:1:  78%|| 5431/6926 [25:01:29&lt;2:06:12,  5.07s/it]

{'epoch': 1, 'iter': 5430, 'avg_loss': 5.784611293699307, 'avg_acc': 49.92174553489229, 'loss': 6.211486339569092}


EP_train:1:  79%|| 5441/6926 [25:02:20&lt;2:05:04,  5.05s/it]

{'epoch': 1, 'iter': 5440, 'avg_loss': 5.7847099865081, 'avg_acc': 49.91442290020217, 'loss': 6.249625205993652}


EP_train:1:  79%|| 5451/6926 [25:03:10&lt;2:03:36,  5.03s/it]

{'epoch': 1, 'iter': 5450, 'avg_loss': 5.7844880132407495, 'avg_acc': 49.90942028985507, 'loss': 6.039062023162842}


EP_train:1:  79%|| 5461/6926 [25:04:00&lt;2:03:24,  5.05s/it]

{'epoch': 1, 'iter': 5460, 'avg_loss': 5.784443095105403, 'avg_acc': 49.90844167734847, 'loss': 5.641089916229248}


EP_train:1:  79%|| 5471/6926 [25:04:51&lt;2:00:24,  4.97s/it]

{'epoch': 1, 'iter': 5470, 'avg_loss': 5.784420987845469, 'avg_acc': 49.91603454578687, 'loss': 5.327508926391602}


EP_train:1:  79%|| 5481/6926 [25:05:41&lt;2:00:36,  5.01s/it]

{'epoch': 1, 'iter': 5480, 'avg_loss': 5.784344418078003, 'avg_acc': 49.91162652800584, 'loss': 5.988985061645508}


EP_train:1:  79%|| 5491/6926 [25:06:31&lt;1:59:13,  4.99s/it]

{'epoch': 1, 'iter': 5490, 'avg_loss': 5.7845592009003015, 'avg_acc': 49.91634037515935, 'loss': 5.780298233032227}


EP_train:1:  79%|| 5501/6926 [25:07:21&lt;1:58:58,  5.01s/it]

{'epoch': 1, 'iter': 5500, 'avg_loss': 5.784604727799319, 'avg_acc': 49.927285948009455, 'loss': 5.699859142303467}


EP_train:1:  80%|| 5511/6926 [25:08:10&lt;1:57:29,  4.98s/it]

{'epoch': 1, 'iter': 5510, 'avg_loss': 5.784727857368565, 'avg_acc': 49.93875884594448, 'loss': 5.810672760009766}


EP_train:1:  80%|| 5521/6926 [25:09:00&lt;1:55:16,  4.92s/it]

{'epoch': 1, 'iter': 5520, 'avg_loss': 5.78466478540206, 'avg_acc': 49.94509599710197, 'loss': 5.763308525085449}


EP_train:1:  80%|| 5531/6926 [25:09:49&lt;1:53:46,  4.89s/it]

{'epoch': 1, 'iter': 5530, 'avg_loss': 5.784506014211982, 'avg_acc': 49.94406526848671, 'loss': 5.884986400604248}


EP_train:1:  80%|| 5541/6926 [25:10:38&lt;1:53:32,  4.92s/it]

{'epoch': 1, 'iter': 5540, 'avg_loss': 5.784547121983921, 'avg_acc': 49.93063075257174, 'loss': 5.656123161315918}


EP_train:1:  80%|| 5551/6926 [25:11:28&lt;1:53:49,  4.97s/it]

{'epoch': 1, 'iter': 5550, 'avg_loss': 5.7843577021243355, 'avg_acc': 49.929066834804544, 'loss': 5.350888252258301}


EP_train:1:  80%|| 5561/6926 [25:12:17&lt;1:52:25,  4.94s/it]

{'epoch': 1, 'iter': 5560, 'avg_loss': 5.784318096323465, 'avg_acc': 49.926946592339505, 'loss': 5.604388236999512}


EP_train:1:  80%|| 5571/6926 [25:13:07&lt;1:51:44,  4.95s/it]

{'epoch': 1, 'iter': 5570, 'avg_loss': 5.7842132499542815, 'avg_acc': 49.92315113983127, 'loss': 5.612821578979492}


EP_train:1:  81%|| 5581/6926 [25:13:56&lt;1:50:24,  4.93s/it]

{'epoch': 1, 'iter': 5580, 'avg_loss': 5.78414215458014, 'avg_acc': 49.930008063071135, 'loss': 5.800327301025391}


EP_train:1:  81%|| 5591/6926 [25:14:45&lt;1:48:47,  4.89s/it]

{'epoch': 1, 'iter': 5590, 'avg_loss': 5.7843216540582745, 'avg_acc': 49.929015381863714, 'loss': 5.423799991607666}


EP_train:1:  81%|| 5601/6926 [25:15:34&lt;1:48:39,  4.92s/it]

{'epoch': 1, 'iter': 5600, 'avg_loss': 5.784348123564377, 'avg_acc': 49.93081592572755, 'loss': 5.427426338195801}


EP_train:1:  81%|| 5611/6926 [25:16:23&lt;1:48:28,  4.95s/it]

{'epoch': 1, 'iter': 5610, 'avg_loss': 5.78420087824189, 'avg_acc': 49.93650864373552, 'loss': 5.6833176612854}


EP_train:1:  81%|| 5621/6926 [25:17:13&lt;1:47:30,  4.94s/it]

{'epoch': 1, 'iter': 5620, 'avg_loss': 5.78432444766034, 'avg_acc': 49.93550969578367, 'loss': 5.740802764892578}


EP_train:1:  81%|| 5631/6926 [25:18:02&lt;1:45:13,  4.88s/it]

{'epoch': 1, 'iter': 5630, 'avg_loss': 5.784201818299196, 'avg_acc': 49.927299769135146, 'loss': 5.6963396072387695}


EP_train:1:  81%|| 5641/6926 [25:18:51&lt;1:45:29,  4.93s/it]

{'epoch': 1, 'iter': 5640, 'avg_loss': 5.784294325205224, 'avg_acc': 49.93019854635703, 'loss': 5.713461875915527}


EP_train:1:  82%|| 5651/6926 [25:19:40&lt;1:42:47,  4.84s/it]

{'epoch': 1, 'iter': 5650, 'avg_loss': 5.784053106853085, 'avg_acc': 49.93364006370554, 'loss': 5.680525302886963}


EP_train:1:  82%|| 5661/6926 [25:20:29&lt;1:43:21,  4.90s/it]

{'epoch': 1, 'iter': 5660, 'avg_loss': 5.783927380333223, 'avg_acc': 49.926580992757465, 'loss': 5.957330703735352}


EP_train:1:  82%|| 5671/6926 [25:21:17&lt;1:41:19,  4.84s/it]

{'epoch': 1, 'iter': 5670, 'avg_loss': 5.783729803875375, 'avg_acc': 49.9283636043026, 'loss': 5.475937843322754}


EP_train:1:  82%|| 5681/6926 [25:22:06&lt;1:40:05,  4.82s/it]

{'epoch': 1, 'iter': 5680, 'avg_loss': 5.783408293567101, 'avg_acc': 49.926839464882946, 'loss': 5.761279582977295}


EP_train:1:  82%|| 5691/6926 [25:22:55&lt;1:39:54,  4.85s/it]

{'epoch': 1, 'iter': 5690, 'avg_loss': 5.783462573513795, 'avg_acc': 49.92641890704621, 'loss': 5.531265735626221}


EP_train:1:  82%|| 5701/6926 [25:23:43&lt;1:39:27,  4.87s/it]

{'epoch': 1, 'iter': 5700, 'avg_loss': 5.783237645885773, 'avg_acc': 49.92325907735485, 'loss': 5.559386730194092}


EP_train:1:  82%|| 5711/6926 [25:24:32&lt;1:39:24,  4.91s/it]

{'epoch': 1, 'iter': 5710, 'avg_loss': 5.783113932738974, 'avg_acc': 49.93050691647697, 'loss': 5.662935733795166}


EP_train:1:  83%|| 5721/6926 [25:25:21&lt;1:38:12,  4.89s/it]

{'epoch': 1, 'iter': 5720, 'avg_loss': 5.78305008452665, 'avg_acc': 49.932267086173745, 'loss': 5.837520599365234}


EP_train:1:  83%|| 5731/6926 [25:26:10&lt;1:36:28,  4.84s/it]

{'epoch': 1, 'iter': 5730, 'avg_loss': 5.783110486048717, 'avg_acc': 49.93402111324376, 'loss': 5.914923191070557}


EP_train:1:  83%|| 5741/6926 [25:26:58&lt;1:35:05,  4.81s/it]

{'epoch': 1, 'iter': 5740, 'avg_loss': 5.782980721454923, 'avg_acc': 49.93359170876154, 'loss': 6.288550853729248}


EP_train:1:  83%|| 5751/6926 [25:27:46&lt;1:33:55,  4.80s/it]

{'epoch': 1, 'iter': 5750, 'avg_loss': 5.78316503208713, 'avg_acc': 49.93914101895322, 'loss': 5.9080986976623535}


EP_train:1:  83%|| 5761/6926 [25:28:35&lt;1:34:06,  4.85s/it]

{'epoch': 1, 'iter': 5760, 'avg_loss': 5.782785179755316, 'avg_acc': 49.94738326679396, 'loss': 5.55677604675293}


EP_train:1:  83%|| 5771/6926 [25:29:23&lt;1:34:51,  4.93s/it]

{'epoch': 1, 'iter': 5770, 'avg_loss': 5.78283761176012, 'avg_acc': 49.95126494541674, 'loss': 5.984116554260254}


EP_train:1:  83%|| 5781/6926 [25:30:12&lt;1:32:41,  4.86s/it]

{'epoch': 1, 'iter': 5780, 'avg_loss': 5.782416016806824, 'avg_acc': 49.95351150320014, 'loss': 5.6232075691223145}


EP_train:1:  84%|| 5791/6926 [25:31:00&lt;1:31:07,  4.82s/it]

{'epoch': 1, 'iter': 5790, 'avg_loss': 5.782243973273025, 'avg_acc': 49.94819547573822, 'loss': 5.683053016662598}


EP_train:1:  84%|| 5801/6926 [25:31:48&lt;1:30:01,  4.80s/it]

{'epoch': 1, 'iter': 5800, 'avg_loss': 5.782278052446576, 'avg_acc': 49.93912687467678, 'loss': 6.064216136932373}


EP_train:1:  84%|| 5811/6926 [25:32:37&lt;1:29:20,  4.81s/it]

{'epoch': 1, 'iter': 5810, 'avg_loss': 5.782294087269655, 'avg_acc': 49.938156083290316, 'loss': 5.709198951721191}


EP_train:1:  84%|| 5821/6926 [25:33:25&lt;1:28:47,  4.82s/it]

{'epoch': 1, 'iter': 5820, 'avg_loss': 5.782214635918792, 'avg_acc': 49.931283284658996, 'loss': 5.346830368041992}


EP_train:1:  84%|| 5831/6926 [25:34:13&lt;1:27:29,  4.79s/it]

{'epoch': 1, 'iter': 5830, 'avg_loss': 5.782174025201773, 'avg_acc': 49.92389813068085, 'loss': 5.908675193786621}


EP_train:1:  84%|| 5841/6926 [25:35:01&lt;1:26:51,  4.80s/it]

{'epoch': 1, 'iter': 5840, 'avg_loss': 5.781947762238369, 'avg_acc': 49.92884351994522, 'loss': 5.71120023727417}


EP_train:1:  84%|| 5851/6926 [25:35:49&lt;1:27:01,  4.86s/it]

{'epoch': 1, 'iter': 5850, 'avg_loss': 5.781698381201953, 'avg_acc': 49.92736284395829, 'loss': 5.3460693359375}


EP_train:1:  85%|| 5861/6926 [25:36:37&lt;1:25:10,  4.80s/it]

{'epoch': 1, 'iter': 5860, 'avg_loss': 5.781845590356795, 'avg_acc': 49.91788943866234, 'loss': 5.871155261993408}


EP_train:1:  85%|| 5871/6926 [25:37:25&lt;1:24:24,  4.80s/it]

{'epoch': 1, 'iter': 5870, 'avg_loss': 5.781756310259092, 'avg_acc': 49.919093851132686, 'loss': 5.670632362365723}


EP_train:1:  85%|| 5881/6926 [25:38:13&lt;1:23:59,  4.82s/it]

{'epoch': 1, 'iter': 5880, 'avg_loss': 5.781726860833845, 'avg_acc': 49.92188828430539, 'loss': 5.868326187133789}


EP_train:1:  85%|| 5891/6926 [25:39:01&lt;1:21:48,  4.74s/it]

{'epoch': 1, 'iter': 5890, 'avg_loss': 5.781478759368679, 'avg_acc': 49.9156552368019, 'loss': 5.818526744842529}


EP_train:1:  85%|| 5901/6926 [25:39:48&lt;1:20:41,  4.72s/it]

{'epoch': 1, 'iter': 5900, 'avg_loss': 5.7811871450081895, 'avg_acc': 49.90467717336045, 'loss': 5.347582817077637}


EP_train:1:  85%|| 5911/6926 [25:40:35&lt;1:19:07,  4.68s/it]

{'epoch': 1, 'iter': 5910, 'avg_loss': 5.781136796793504, 'avg_acc': 49.90378108611064, 'loss': 6.000991344451904}


EP_train:1:  85%|| 5921/6926 [25:41:22&lt;1:19:11,  4.73s/it]

{'epoch': 1, 'iter': 5920, 'avg_loss': 5.781358487661214, 'avg_acc': 49.90763806789394, 'loss': 5.775269985198975}


EP_train:1:  86%|| 5931/6926 [25:42:09&lt;1:17:40,  4.68s/it]

{'epoch': 1, 'iter': 5930, 'avg_loss': 5.781212314026209, 'avg_acc': 49.90674001011634, 'loss': 5.669227600097656}


EP_train:1:  86%|| 5941/6926 [25:42:55&lt;1:16:33,  4.66s/it]

{'epoch': 1, 'iter': 5940, 'avg_loss': 5.781081504401204, 'avg_acc': 49.90900100993099, 'loss': 6.182577610015869}


EP_train:1:  86%|| 5951/6926 [25:43:42&lt;1:16:03,  4.68s/it]

{'epoch': 1, 'iter': 5950, 'avg_loss': 5.78110646159884, 'avg_acc': 49.90810368005377, 'loss': 5.681771278381348}


EP_train:1:  86%|| 5961/6926 [25:44:29&lt;1:14:51,  4.65s/it]

{'epoch': 1, 'iter': 5960, 'avg_loss': 5.7811979621153835, 'avg_acc': 49.907733601744674, 'loss': 5.719395160675049}


EP_train:1:  86%|| 5971/6926 [25:45:15&lt;1:14:02,  4.65s/it]

{'epoch': 1, 'iter': 5970, 'avg_loss': 5.780883351995046, 'avg_acc': 49.90893485178362, 'loss': 5.446839809417725}


EP_train:1:  86%|| 5981/6926 [25:46:02&lt;1:13:12,  4.65s/it]

{'epoch': 1, 'iter': 5980, 'avg_loss': 5.780823045940109, 'avg_acc': 49.91169954857047, 'loss': 5.8073954582214355}


EP_train:1:  87%|| 5991/6926 [25:46:48&lt;1:13:27,  4.71s/it]

{'epoch': 1, 'iter': 5990, 'avg_loss': 5.7807477352675285, 'avg_acc': 49.90923885828743, 'loss': 5.797297477722168}


EP_train:1:  87%|| 6001/6926 [25:47:35&lt;1:11:38,  4.65s/it]

{'epoch': 1, 'iter': 6000, 'avg_loss': 5.780810562178922, 'avg_acc': 49.912514580903185, 'loss': 5.653048992156982}


EP_train:1:  87%|| 6011/6926 [25:48:21&lt;1:10:25,  4.62s/it]

{'epoch': 1, 'iter': 6010, 'avg_loss': 5.780854975596142, 'avg_acc': 49.91889868574281, 'loss': 5.777438640594482}


EP_train:1:  87%|| 6021/6926 [25:49:08&lt;1:09:43,  4.62s/it]

{'epoch': 1, 'iter': 6020, 'avg_loss': 5.780711438999958, 'avg_acc': 49.9179953496097, 'loss': 5.75351095199585}


EP_train:1:  87%|| 6031/6926 [25:49:54&lt;1:09:18,  4.65s/it]

{'epoch': 1, 'iter': 6030, 'avg_loss': 5.780518743296481, 'avg_acc': 49.926939976786606, 'loss': 5.70479679107666}


EP_train:1:  87%|| 6041/6926 [25:50:41&lt;1:08:30,  4.64s/it]

{'epoch': 1, 'iter': 6040, 'avg_loss': 5.7802501204708046, 'avg_acc': 49.92861281244827, 'loss': 5.732730865478516}


EP_train:1:  87%|| 6051/6926 [25:51:28&lt;1:08:24,  4.69s/it]

{'epoch': 1, 'iter': 6050, 'avg_loss': 5.780145037254998, 'avg_acc': 49.926665014047266, 'loss': 6.207437992095947}


EP_train:1:  88%|| 6061/6926 [25:52:14&lt;1:06:47,  4.63s/it]

{'epoch': 1, 'iter': 6060, 'avg_loss': 5.780249950536071, 'avg_acc': 49.92523923444976, 'loss': 6.00528621673584}


EP_train:1:  88%|| 6071/6926 [25:53:01&lt;1:06:21,  4.66s/it]

{'epoch': 1, 'iter': 6070, 'avg_loss': 5.780045858935182, 'avg_acc': 49.92072969856696, 'loss': 5.68556547164917}


EP_train:1:  88%|| 6081/6926 [25:53:47&lt;1:05:29,  4.65s/it]

{'epoch': 1, 'iter': 6080, 'avg_loss': 5.779607152178224, 'avg_acc': 49.92137395165269, 'loss': 5.5342278480529785}


EP_train:1:  88%|| 6091/6926 [25:54:33&lt;1:04:26,  4.63s/it]

{'epoch': 1, 'iter': 6090, 'avg_loss': 5.779395503023931, 'avg_acc': 49.9173986209161, 'loss': 5.9122514724731445}


EP_train:1:  88%|| 6101/6926 [25:55:19&lt;1:03:46,  4.64s/it]

{'epoch': 1, 'iter': 6100, 'avg_loss': 5.779381259780031, 'avg_acc': 49.924704966398956, 'loss': 5.792469501495361}


EP_train:1:  88%|| 6111/6926 [25:56:06&lt;1:03:35,  4.68s/it]

{'epoch': 1, 'iter': 6110, 'avg_loss': 5.779114612638024, 'avg_acc': 49.92380543282605, 'loss': 5.879085063934326}


EP_train:1:  88%|| 6121/6926 [25:56:52&lt;1:02:13,  4.64s/it]

{'epoch': 1, 'iter': 6120, 'avg_loss': 5.7791698663341045, 'avg_acc': 49.92750367586996, 'loss': 5.887377738952637}


EP_train:1:  89%|| 6131/6926 [25:57:38&lt;1:00:48,  4.59s/it]

{'epoch': 1, 'iter': 6130, 'avg_loss': 5.7788901533588195, 'avg_acc': 49.930680150057086, 'loss': 5.180190563201904}


EP_train:1:  89%|| 6141/6926 [25:58:24&lt;1:00:01,  4.59s/it]

{'epoch': 1, 'iter': 6140, 'avg_loss': 5.77883395844301, 'avg_acc': 49.931810780003254, 'loss': 6.083118915557861}


EP_train:1:  89%|| 6151/6926 [25:59:10&lt;59:26,  4.60s/it]  

{'epoch': 1, 'iter': 6150, 'avg_loss': 5.7788775052855295, 'avg_acc': 49.93039749634206, 'loss': 5.849542140960693}


EP_train:1:  89%|| 6161/6926 [25:59:56&lt;58:46,  4.61s/it]

{'epoch': 1, 'iter': 6160, 'avg_loss': 5.778919962353761, 'avg_acc': 49.93304658334686, 'loss': 5.840837478637695}


EP_train:1:  89%|| 6171/6926 [26:00:42&lt;57:56,  4.60s/it]

{'epoch': 1, 'iter': 6170, 'avg_loss': 5.778584497903352, 'avg_acc': 49.93011667476908, 'loss': 5.556150913238525}


EP_train:1:  89%|| 6181/6926 [26:01:28&lt;57:28,  4.63s/it]

{'epoch': 1, 'iter': 6180, 'avg_loss': 5.778414422843549, 'avg_acc': 49.92972415466753, 'loss': 5.839237213134766}


EP_train:1:  89%|| 6191/6926 [26:02:14&lt;56:13,  4.59s/it]

{'epoch': 1, 'iter': 6190, 'avg_loss': 5.778344067247132, 'avg_acc': 49.935390082377644, 'loss': 5.642001628875732}


EP_train:1:  90%|| 6201/6926 [26:03:02&lt;58:27,  4.84s/it]

{'epoch': 1, 'iter': 6200, 'avg_loss': 5.778295888225602, 'avg_acc': 49.9435574907273, 'loss': 6.1009368896484375}


EP_train:1:  90%|| 6211/6926 [26:03:48&lt;54:59,  4.61s/it]

{'epoch': 1, 'iter': 6210, 'avg_loss': 5.778387287737494, 'avg_acc': 49.94817662212204, 'loss': 5.893352031707764}


EP_train:1:  90%|| 6221/6926 [26:04:33&lt;53:29,  4.55s/it]

{'epoch': 1, 'iter': 6220, 'avg_loss': 5.7782907649992055, 'avg_acc': 49.94876225687189, 'loss': 5.663171768188477}


EP_train:1:  90%|| 6231/6926 [26:05:19&lt;52:31,  4.53s/it]

{'epoch': 1, 'iter': 6230, 'avg_loss': 5.778239460248584, 'avg_acc': 49.95335820895522, 'loss': 5.583588600158691}


EP_train:1:  90%|| 6241/6926 [26:06:04&lt;52:02,  4.56s/it]

{'epoch': 1, 'iter': 6240, 'avg_loss': 5.7781203764597775, 'avg_acc': 49.95793943278321, 'loss': 6.1364006996154785}


EP_train:1:  90%|| 6251/6926 [26:06:49&lt;50:47,  4.51s/it]

{'epoch': 1, 'iter': 6250, 'avg_loss': 5.778017304188117, 'avg_acc': 49.96050631898896, 'loss': 5.472578048706055}


EP_train:1:  90%|| 6261/6926 [26:07:35&lt;50:26,  4.55s/it]

{'epoch': 1, 'iter': 6260, 'avg_loss': 5.77785077823882, 'avg_acc': 49.956576425491136, 'loss': 5.628420829772949}


EP_train:1:  91%|| 6271/6926 [26:08:20&lt;49:10,  4.50s/it]

{'epoch': 1, 'iter': 6270, 'avg_loss': 5.777695393566119, 'avg_acc': 49.962625578057725, 'loss': 6.0225067138671875}


EP_train:1:  91%|| 6281/6926 [26:09:05&lt;48:10,  4.48s/it]

{'epoch': 1, 'iter': 6280, 'avg_loss': 5.777665248173017, 'avg_acc': 49.957709759592426, 'loss': 5.661037445068359}


EP_train:1:  91%|| 6291/6926 [26:09:49&lt;46:48,  4.42s/it]

{'epoch': 1, 'iter': 6290, 'avg_loss': 5.7775033164187315, 'avg_acc': 49.95330631060245, 'loss': 5.781978607177734}


EP_train:1:  91%|| 6301/6926 [26:10:34&lt;46:17,  4.44s/it]

{'epoch': 1, 'iter': 6300, 'avg_loss': 5.777581789440209, 'avg_acc': 49.94594112045707, 'loss': 5.737508296966553}


EP_train:1:  91%|| 6311/6926 [26:11:18&lt;45:21,  4.43s/it]

{'epoch': 1, 'iter': 6310, 'avg_loss': 5.777420561507432, 'avg_acc': 49.941075106956106, 'loss': 5.739945888519287}


EP_train:1:  91%|| 6321/6926 [26:12:02&lt;44:53,  4.45s/it]

{'epoch': 1, 'iter': 6320, 'avg_loss': 5.777400415393677, 'avg_acc': 49.93919079259611, 'loss': 5.752358436584473}


EP_train:1:  91%|| 6331/6926 [26:12:46&lt;43:51,  4.42s/it]

{'epoch': 1, 'iter': 6330, 'avg_loss': 5.777687952842706, 'avg_acc': 49.936325225082925, 'loss': 5.815260410308838}


EP_train:1:  92%|| 6341/6926 [26:13:30&lt;42:52,  4.40s/it]

{'epoch': 1, 'iter': 6340, 'avg_loss': 5.7778140435627146, 'avg_acc': 49.93346869578931, 'loss': 6.343088626861572}


EP_train:1:  92%|| 6351/6926 [26:14:15&lt;42:49,  4.47s/it]

{'epoch': 1, 'iter': 6350, 'avg_loss': 5.77768568301122, 'avg_acc': 49.93455754999213, 'loss': 5.540189743041992}


EP_train:1:  92%|| 6361/6926 [26:14:59&lt;41:47,  4.44s/it]

{'epoch': 1, 'iter': 6360, 'avg_loss': 5.7775874545675014, 'avg_acc': 49.93564298066342, 'loss': 6.135932445526123}


EP_train:1:  92%|| 6371/6926 [26:15:43&lt;40:47,  4.41s/it]

{'epoch': 1, 'iter': 6370, 'avg_loss': 5.777595979642352, 'avg_acc': 49.93034845393188, 'loss': 5.408830165863037}


EP_train:1:  92%|| 6381/6926 [26:16:27&lt;40:30,  4.46s/it]

{'epoch': 1, 'iter': 6380, 'avg_loss': 5.77757071253088, 'avg_acc': 49.944170192759756, 'loss': 5.634832859039307}


EP_train:1:  92%|| 6391/6926 [26:17:12&lt;39:21,  4.41s/it]

{'epoch': 1, 'iter': 6390, 'avg_loss': 5.777440669260158, 'avg_acc': 49.94670239399155, 'loss': 5.383371829986572}


EP_train:1:  92%|| 6401/6926 [26:17:56&lt;38:19,  4.38s/it]

{'epoch': 1, 'iter': 6400, 'avg_loss': 5.777283759251961, 'avg_acc': 49.94580924855491, 'loss': 5.011127948760986}


EP_train:1:  93%|| 6411/6926 [26:18:41&lt;38:11,  4.45s/it]

{'epoch': 1, 'iter': 6410, 'avg_loss': 5.777359984851148, 'avg_acc': 49.946868663235065, 'loss': 5.4994916915893555}


EP_train:1:  93%|| 6421/6926 [26:19:25&lt;37:21,  4.44s/it]

{'epoch': 1, 'iter': 6420, 'avg_loss': 5.777320318960212, 'avg_acc': 49.94549135648653, 'loss': 5.719225883483887}


EP_train:1:  93%|| 6431/6926 [26:20:09&lt;36:02,  4.37s/it]

{'epoch': 1, 'iter': 6430, 'avg_loss': 5.77764610160919, 'avg_acc': 49.94071684030477, 'loss': 6.161487579345703}


EP_train:1:  93%|| 6441/6926 [26:20:53&lt;35:16,  4.36s/it]

{'epoch': 1, 'iter': 6440, 'avg_loss': 5.777708658278497, 'avg_acc': 49.94469026548673, 'loss': 6.02605676651001}


EP_train:1:  93%|| 6451/6926 [26:21:36&lt;34:38,  4.38s/it]

{'epoch': 1, 'iter': 6450, 'avg_loss': 5.777484106659021, 'avg_acc': 49.94186947760037, 'loss': 5.899960517883301}


EP_train:1:  93%|| 6461/6926 [26:22:20&lt;33:36,  4.34s/it]

{'epoch': 1, 'iter': 6460, 'avg_loss': 5.77741036040922, 'avg_acc': 49.95018186039313, 'loss': 5.4888787269592285}


EP_train:1:  93%|| 6471/6926 [26:23:04&lt;33:04,  4.36s/it]

{'epoch': 1, 'iter': 6470, 'avg_loss': 5.77723308531399, 'avg_acc': 49.94591253283882, 'loss': 5.877783298492432}


EP_train:1:  94%|| 6481/6926 [26:23:48&lt;32:49,  4.43s/it]

{'epoch': 1, 'iter': 6480, 'avg_loss': 5.7769616072127485, 'avg_acc': 49.94647816694954, 'loss': 5.616131782531738}


EP_train:1:  94%|| 6491/6926 [26:24:31&lt;31:47,  4.39s/it]

{'epoch': 1, 'iter': 6490, 'avg_loss': 5.777087825892097, 'avg_acc': 49.941264828223694, 'loss': 5.8958916664123535}


EP_train:1:  94%|| 6501/6926 [26:25:15&lt;30:39,  4.33s/it]

{'epoch': 1, 'iter': 6500, 'avg_loss': 5.7769701031607275, 'avg_acc': 49.94616212890325, 'loss': 5.841654300689697}


EP_train:1:  94%|| 6511/6926 [26:25:58&lt;30:04,  4.35s/it]

{'epoch': 1, 'iter': 6510, 'avg_loss': 5.777001203543725, 'avg_acc': 49.949124558439564, 'loss': 5.653926849365234}


EP_train:1:  94%|| 6521/6926 [26:26:42&lt;29:17,  4.34s/it]

{'epoch': 1, 'iter': 6520, 'avg_loss': 5.77680205348225, 'avg_acc': 49.94584802944333, 'loss': 5.291003704071045}


EP_train:1:  94%|| 6531/6926 [26:27:25&lt;28:23,  4.31s/it]

{'epoch': 1, 'iter': 6530, 'avg_loss': 5.776695243944674, 'avg_acc': 49.95693615066605, 'loss': 6.052003860473633}


EP_train:1:  94%|| 6541/6926 [26:28:08&lt;27:32,  4.29s/it]

{'epoch': 1, 'iter': 6540, 'avg_loss': 5.776760118376897, 'avg_acc': 49.95317994190491, 'loss': 5.720389366149902}


EP_train:1:  95%|| 6551/6926 [26:28:52&lt;27:18,  4.37s/it]

{'epoch': 1, 'iter': 6550, 'avg_loss': 5.776665815159194, 'avg_acc': 49.954205464814535, 'loss': 5.827826023101807}


EP_train:1:  95%|| 6561/6926 [26:29:35&lt;26:18,  4.32s/it]

{'epoch': 1, 'iter': 6560, 'avg_loss': 5.776401111763836, 'avg_acc': 49.95379896357262, 'loss': 5.450952529907227}


EP_train:1:  95%|| 6571/6926 [26:30:18&lt;25:25,  4.30s/it]

{'epoch': 1, 'iter': 6570, 'avg_loss': 5.776434445341253, 'avg_acc': 49.94768680566124, 'loss': 5.8960280418396}


EP_train:1:  95%|| 6581/6926 [26:31:01&lt;24:43,  4.30s/it]

{'epoch': 1, 'iter': 6580, 'avg_loss': 5.776199127435503, 'avg_acc': 49.944442333991795, 'loss': 5.734650611877441}


EP_train:1:  95%|| 6591/6926 [26:31:44&lt;24:03,  4.31s/it]

{'epoch': 1, 'iter': 6590, 'avg_loss': 5.776165728684062, 'avg_acc': 49.93741465634957, 'loss': 5.232611656188965}


EP_train:1:  95%|| 6601/6926 [26:32:28&lt;23:25,  4.32s/it]

{'epoch': 1, 'iter': 6600, 'avg_loss': 5.775830157542478, 'avg_acc': 49.94034994697773, 'loss': 5.430495738983154}


EP_train:1:  95%|| 6611/6926 [26:33:11&lt;22:40,  4.32s/it]

{'epoch': 1, 'iter': 6610, 'avg_loss': 5.775653046786992, 'avg_acc': 49.937603993344425, 'loss': 5.380129337310791}


EP_train:1:  96%|| 6621/6926 [26:33:54&lt;21:50,  4.30s/it]

{'epoch': 1, 'iter': 6620, 'avg_loss': 5.775762736878354, 'avg_acc': 49.94053013140009, 'loss': 5.624420642852783}


EP_train:1:  96%|| 6631/6926 [26:34:37&lt;21:21,  4.34s/it]

{'epoch': 1, 'iter': 6630, 'avg_loss': 5.77552282100097, 'avg_acc': 49.93873473080983, 'loss': 5.898670196533203}


EP_train:1:  96%|| 6641/6926 [26:35:20&lt;20:19,  4.28s/it]

{'epoch': 1, 'iter': 6640, 'avg_loss': 5.775653746702139, 'avg_acc': 49.93788586056317, 'loss': 5.747555732727051}


EP_train:1:  96%|| 6651/6926 [26:36:03&lt;19:29,  4.25s/it]

{'epoch': 1, 'iter': 6650, 'avg_loss': 5.775573407056869, 'avg_acc': 49.94549691775673, 'loss': 5.552094459533691}


EP_train:1:  96%|| 6661/6926 [26:36:45&lt;18:49,  4.26s/it]

{'epoch': 1, 'iter': 6660, 'avg_loss': 5.775592314733469, 'avg_acc': 49.94464044437772, 'loss': 5.8559770584106445}


EP_train:1:  96%|| 6671/6926 [26:37:28&lt;18:12,  4.28s/it]

{'epoch': 1, 'iter': 6670, 'avg_loss': 5.77529502804893, 'avg_acc': 49.946597211812325, 'loss': 5.930022239685059}


EP_train:1:  96%|| 6681/6926 [26:38:11&lt;17:18,  4.24s/it]

{'epoch': 1, 'iter': 6680, 'avg_loss': 5.775084311332982, 'avg_acc': 49.94293518934291, 'loss': 5.836806774139404}


EP_train:1:  97%|| 6691/6926 [26:38:53&lt;16:33,  4.23s/it]

{'epoch': 1, 'iter': 6690, 'avg_loss': 5.775097164546868, 'avg_acc': 49.93694888656404, 'loss': 5.301206111907959}


EP_train:1:  97%|| 6701/6926 [26:39:35&lt;15:51,  4.23s/it]

{'epoch': 1, 'iter': 6700, 'avg_loss': 5.775078065109652, 'avg_acc': 49.93331219221012, 'loss': 5.591684341430664}


EP_train:1:  97%|| 6711/6926 [26:40:18&lt;15:10,  4.24s/it]

{'epoch': 1, 'iter': 6710, 'avg_loss': 5.774972334648454, 'avg_acc': 49.94132767098793, 'loss': 5.595386981964111}


EP_train:1:  97%|| 6721/6926 [26:41:00&lt;14:25,  4.22s/it]

{'epoch': 1, 'iter': 6720, 'avg_loss': 5.774984706886608, 'avg_acc': 49.94048504686803, 'loss': 5.732786178588867}


EP_train:1:  97%|| 6731/6926 [26:41:42&lt;13:37,  4.19s/it]

{'epoch': 1, 'iter': 6730, 'avg_loss': 5.7750621846518815, 'avg_acc': 49.93732357747734, 'loss': 5.633825302124023}


EP_train:1:  97%|| 6741/6926 [26:42:24&lt;12:47,  4.15s/it]

{'epoch': 1, 'iter': 6740, 'avg_loss': 5.77519698136639, 'avg_acc': 49.93324432576769, 'loss': 6.02584171295166}


EP_train:1:  97%|| 6751/6926 [26:43:05&lt;12:04,  4.14s/it]

{'epoch': 1, 'iter': 6750, 'avg_loss': 5.775010837305742, 'avg_acc': 49.93473189157162, 'loss': 5.970997333526611}


EP_train:1:  98%|| 6761/6926 [26:43:46&lt;11:19,  4.12s/it]

{'epoch': 1, 'iter': 6760, 'avg_loss': 5.774941228088799, 'avg_acc': 49.93297958881822, 'loss': 5.925961494445801}


EP_train:1:  98%|| 6771/6926 [26:44:28&lt;10:38,  4.12s/it]

{'epoch': 1, 'iter': 6770, 'avg_loss': 5.775033120231533, 'avg_acc': 49.93446315167627, 'loss': 5.306178092956543}


EP_train:1:  98%|| 6781/6926 [26:45:09&lt;10:05,  4.18s/it]

{'epoch': 1, 'iter': 6780, 'avg_loss': 5.775017764360534, 'avg_acc': 49.932255567025514, 'loss': 5.493859767913818}


EP_train:1:  98%|| 6791/6926 [26:45:51&lt;09:13,  4.10s/it]

{'epoch': 1, 'iter': 6790, 'avg_loss': 5.774907826850699, 'avg_acc': 49.933735826829626, 'loss': 5.780702114105225}


EP_train:1:  98%|| 6801/6926 [26:46:32&lt;08:49,  4.24s/it]

{'epoch': 1, 'iter': 6800, 'avg_loss': 5.774968336792733, 'avg_acc': 49.9347522423173, 'loss': 5.785495281219482}


EP_train:1:  98%|| 6811/6926 [26:47:13&lt;07:51,  4.10s/it]

{'epoch': 1, 'iter': 6810, 'avg_loss': 5.774826055895545, 'avg_acc': 49.93622448979592, 'loss': 5.582895755767822}


EP_train:1:  98%|| 6821/6926 [26:47:54&lt;07:06,  4.06s/it]

{'epoch': 1, 'iter': 6820, 'avg_loss': 5.774791732069999, 'avg_acc': 49.93815056443337, 'loss': 5.51682186126709}


EP_train:1:  99%|| 6831/6926 [26:48:34&lt;06:25,  4.06s/it]

{'epoch': 1, 'iter': 6830, 'avg_loss': 5.7745794972813576, 'avg_acc': 49.94556067925633, 'loss': 5.5028533935546875}


EP_train:1:  99%|| 6841/6926 [26:49:15&lt;05:43,  4.04s/it]

{'epoch': 1, 'iter': 6840, 'avg_loss': 5.774490070872759, 'avg_acc': 49.947467475515275, 'loss': 5.823716640472412}


EP_train:1:  99%|| 6851/6926 [26:49:55&lt;05:00,  4.01s/it]

{'epoch': 1, 'iter': 6850, 'avg_loss': 5.774343690286151, 'avg_acc': 49.947088016347976, 'loss': 5.5767927169799805}


EP_train:1:  99%|| 6861/6926 [26:50:35&lt;04:20,  4.00s/it]

{'epoch': 1, 'iter': 6860, 'avg_loss': 5.774208201800503, 'avg_acc': 49.95080891998251, 'loss': 5.940675258636475}


EP_train:1:  99%|| 6871/6926 [26:51:16&lt;03:40,  4.02s/it]

{'epoch': 1, 'iter': 6870, 'avg_loss': 5.774142305501561, 'avg_acc': 49.9549738029399, 'loss': 5.632803916931152}


EP_train:1:  99%|| 6881/6926 [26:51:56&lt;02:59,  3.99s/it]

{'epoch': 1, 'iter': 6880, 'avg_loss': 5.774009880051504, 'avg_acc': 49.95367679116408, 'loss': 5.485649108886719}


EP_train:1:  99%|| 6891/6926 [26:52:35&lt;02:18,  3.97s/it]

{'epoch': 1, 'iter': 6890, 'avg_loss': 5.773817592289257, 'avg_acc': 49.953290523871715, 'loss': 6.408249378204346}


EP_train:1: 100%|| 6901/6926 [26:53:15&lt;01:39,  3.97s/it]

{'epoch': 1, 'iter': 6900, 'avg_loss': 5.773691588494246, 'avg_acc': 49.94928271265034, 'loss': 5.580688953399658}


EP_train:1: 100%|| 6911/6926 [26:53:55&lt;00:59,  3.95s/it]

{'epoch': 1, 'iter': 6910, 'avg_loss': 5.773572737876353, 'avg_acc': 49.94890392128491, 'loss': 5.805022716522217}


EP_train:1: 100%|| 6921/6926 [26:54:35&lt;00:19,  3.97s/it]

{'epoch': 1, 'iter': 6920, 'avg_loss': 5.773589925844534, 'avg_acc': 49.94581707845687, 'loss': 5.892418384552002}


EP_train:1: 100%|| 6926/6926 [26:54:53&lt;00:00, 13.99s/it]

EP1, train:             avg_loss=5.773454445757137,             total_acc=49.949010901739946
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">bert_lm</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>BERTLM(
  (bert): BERT(
    (embedding): BERTEmbedding(
      (token): Embedding(21159, 768, padding_idx=0)
      (segment): Embedding(3, 768, padding_idx=0)
      (position): PositionalEmbedding()
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder_blocks): ModuleList(
      (0-11): 12 x EncoderLayer(
        (layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (self_multihead): MultiHeadedAttention(
          (dropout): Dropout(p=0.1, inplace=False)
          (query): Linear(in_features=768, out_features=768, bias=True)
          (key): Linear(in_features=768, out_features=768, bias=True)
          (value): Linear(in_features=768, out_features=768, bias=True)
          (output_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): FeedForward(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): GELU(approximate='none')
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (next_sentence): NextSentencePrediction(
    (linear): Linear(in_features=768, out_features=2, bias=True)
    (softmax): LogSoftmax(dim=-1)
  )
  (mask_lm): MaskedLanguageModel(
    (linear): Linear(in_features=768, out_features=21159, bias=True)
    (softmax): LogSoftmax(dim=-1)
  )
)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">os</span>

<span class="c1"># Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()
</span>
<span class="n">output_dir</span> <span class="o">=</span> <span class="s">'./model_save/'</span>

<span class="c1"># Create output directory if needed
</span><span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">exists</span><span class="p">(</span><span class="n">output_dir</span><span class="p">):</span>
    <span class="n">os</span><span class="p">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">output_dir</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Saving model to %s"</span> <span class="o">%</span> <span class="n">output_dir</span><span class="p">)</span>

<span class="c1"># Save a trained model, configuration and tokenizer using `save_pretrained()`.
# They can then be reloaded using `from_pretrained()`
#model_to_save = model.module if hasattr(model, 'nanoGPT-module') else model  # Take care of distributed/parallel training
</span><span class="n">torch</span><span class="p">.</span><span class="n">save</span><span class="p">(</span><span class="n">bert_lm</span><span class="p">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">output_dir</span><span class="o">+</span><span class="s">"mybert.path"</span><span class="p">)</span>

<span class="c1"># Good practice: save your training arguments together with the trained model
# torch.save(args, os.path.join(output_dir, 'training_args.bin'))
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Saving model to ./model_save/
</code></pre></div></div>

<h1 id="5-reference">5) Reference</h1>

<p>BERT vs Roberta vs XLM : https://towardsdatascience.com/bert-roberta-distilbert-xlnet-which-one-to-use-3d5ab82ba5f8</p>

<p>StructBert vs Albert vs LongForm: https://towardsdatascience.com/advancing-over-bert-bigbird-convbert-dynabert-bca78a45629c</p>

<p>BART: https://medium.com/analytics-vidhya/revealing-bart-a-denoising-objective-for-pretraining-c6e8f8009564</p>

<p>BLOOM: https://www.infoq.com/news/2022/07/bigscience-bloom-nlp-ai/</p>

<p>PaLM: https://www.infoq.com/news/2022/04/google-palm-ai/</p>]]></content><author><name>Zhu Tianda</name></author><category term="coding" /><category term="AI" /><category term="BERT" /><category term="Pytorch" /><summary type="html"><![CDATA[!pip install transformers datasets tokenizers !wget http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip !unzip -qq cornell_movie_dialogs_corpus.zip !rm cornell_movie_dialogs_corpus.zip !mkdir datasets !mv cornell\ movie-dialogs\ corpus/movie_conversations.txt ./datasets !mv cornell\ movie-dialogs\ corpus/movie_lines.txt ./datasets]]></summary></entry><entry><title type="html">Convolutional Neural Networks: Application</title><link href="http://0.0.0.0:8855/coding/2023/12/01/Convolution-model-Application-v1a.html" rel="alternate" type="text/html" title="Convolutional Neural Networks: Application" /><published>2023-12-01T00:00:00+08:00</published><updated>2023-12-01T00:00:00+08:00</updated><id>http://0.0.0.0:8855/coding/2023/12/01/Convolution-model-Application-v1a</id><content type="html" xml:base="http://0.0.0.0:8855/coding/2023/12/01/Convolution-model-Application-v1a.html"><![CDATA[<h1 id="convolutional-neural-networks-application">Convolutional Neural Networks: Application</h1>

<p>Welcome to Course 4’s second assignment! In this notebook, you will:</p>

<ul>
  <li>Implement helper functions that you will use when implementing a TensorFlow model</li>
  <li>Implement a fully functioning ConvNet using TensorFlow</li>
</ul>

<p><strong>After this assignment you will be able to:</strong></p>

<ul>
  <li>Build and train a ConvNet in TensorFlow for a classification problem</li>
</ul>

<p>We assume here that you are already familiar with TensorFlow. If you are not, please refer the <em>TensorFlow Tutorial</em> of the third week of Course 2 (“<em>Improving deep neural networks</em>”).</p>

<h3 id="-updates-to-assignment-"><font color="darkblue"> Updates to Assignment <font></font></font></h3>

<h4 id="if-you-were-working-on-a-previous-version">If you were working on a previous version</h4>
<ul>
  <li>The current notebook filename is version “1a”.</li>
  <li>You can find your work in the file directory as version “1”.</li>
  <li>To view the file directory, go to the menu “File-&gt;Open”, and this will open a new tab that shows the file directory.</li>
</ul>

<h4 id="list-of-updates">List of Updates</h4>
<ul>
  <li><code class="language-plaintext highlighter-rouge">initialize_parameters</code>: added details about tf.get_variable, <code class="language-plaintext highlighter-rouge">eval</code>. Clarified test case.</li>
  <li>Added explanations for the kernel (filter) stride values, max pooling, and flatten functions.</li>
  <li>Added details about softmax cross entropy with logits.</li>
  <li>Added instructions for creating the Adam Optimizer.</li>
  <li>Added explanation of how to evaluate tensors (optimizer and cost).</li>
  <li><code class="language-plaintext highlighter-rouge">forward_propagation</code>: clarified instructions, use “F” to store “flatten” layer.</li>
  <li>Updated print statements and ‘expected output’ for easier visual comparisons.</li>
  <li>Many thanks to Kevin P. Brown (mentor for the deep learning specialization) for his suggestions on the assignments in this course!</li>
</ul>

<h2 id="10---tensorflow-model">1.0 - TensorFlow model</h2>

<p>In the previous assignment, you built helper functions using numpy to understand the mechanics behind convolutional neural networks. Most practical applications of deep learning today are built using programming frameworks, which have many built-in functions you can simply call.</p>

<p>As usual, we will start by loading in the packages.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">h5py</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">scipy</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">ndimage</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.framework</span> <span class="kn">import</span> <span class="n">ops</span>
<span class="kn">from</span> <span class="nn">cnn_utils</span> <span class="kn">import</span> <span class="o">*</span>

<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<p>Run the next cell to load the “SIGNS” dataset you are going to use.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Loading the data (signs)
</span><span class="n">X_train_orig</span><span class="p">,</span> <span class="n">Y_train_orig</span><span class="p">,</span> <span class="n">X_test_orig</span><span class="p">,</span> <span class="n">Y_test_orig</span><span class="p">,</span> <span class="n">classes</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">()</span>
</code></pre></div></div>

<p>As a reminder, the SIGNS dataset is a collection of 6 signs representing numbers from 0 to 5.</p>

<p><img src="/assets/2023-12-01-Convolution-model-Application-v1a_files/SIGNS.png" style="width:800px;height:300px;" /></p>

<p>The next cell will show you an example of a labelled image in the dataset. Feel free to change the value of <code class="language-plaintext highlighter-rouge">index</code> below and re-run to see different examples.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Example of a picture
</span><span class="n">index</span> <span class="o">=</span> <span class="mi">6</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">X_train_orig</span><span class="p">[</span><span class="n">index</span><span class="p">])</span>
<span class="k">print</span> <span class="p">(</span><span class="s">"y = "</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">Y_train_orig</span><span class="p">[:,</span> <span class="n">index</span><span class="p">])))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>y = 2
</code></pre></div></div>

<p><img src="/assets/2023-12-01-Convolution-model-Application-v1a_files/2023-12-01-Convolution-model-Application-v1a_7_1.png" alt="png" /></p>

<p>In Course 2, you had built a fully-connected network for this dataset. But since this is an image dataset, it is more natural to apply a ConvNet to it.</p>

<p>To get started, let’s examine the shapes of your data.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X_train</span> <span class="o">=</span> <span class="n">X_train_orig</span><span class="o">/</span><span class="mf">255.</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">X_test_orig</span><span class="o">/</span><span class="mf">255.</span>
<span class="n">Y_train</span> <span class="o">=</span> <span class="n">convert_to_one_hot</span><span class="p">(</span><span class="n">Y_train_orig</span><span class="p">,</span> <span class="mi">6</span><span class="p">).</span><span class="n">T</span>
<span class="n">Y_test</span> <span class="o">=</span> <span class="n">convert_to_one_hot</span><span class="p">(</span><span class="n">Y_test_orig</span><span class="p">,</span> <span class="mi">6</span><span class="p">).</span><span class="n">T</span>
<span class="k">print</span> <span class="p">(</span><span class="s">"number of training examples = "</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">X_train</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
<span class="k">print</span> <span class="p">(</span><span class="s">"number of test examples = "</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">X_test</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
<span class="k">print</span> <span class="p">(</span><span class="s">"X_train shape: "</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">X_train</span><span class="p">.</span><span class="n">shape</span><span class="p">))</span>
<span class="k">print</span> <span class="p">(</span><span class="s">"Y_train shape: "</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">Y_train</span><span class="p">.</span><span class="n">shape</span><span class="p">))</span>
<span class="k">print</span> <span class="p">(</span><span class="s">"X_test shape: "</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">X_test</span><span class="p">.</span><span class="n">shape</span><span class="p">))</span>
<span class="k">print</span> <span class="p">(</span><span class="s">"Y_test shape: "</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">Y_test</span><span class="p">.</span><span class="n">shape</span><span class="p">))</span>
<span class="n">conv_layers</span> <span class="o">=</span> <span class="p">{}</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>number of training examples = 1080
number of test examples = 120
X_train shape: (1080, 64, 64, 3)
Y_train shape: (1080, 6)
X_test shape: (120, 64, 64, 3)
Y_test shape: (120, 6)
</code></pre></div></div>

<h3 id="11---create-placeholders">1.1 - Create placeholders</h3>

<p>TensorFlow requires that you create placeholders for the input data that will be fed into the model when running the session.</p>

<p><strong>Exercise</strong>: Implement the function below to create placeholders for the input image X and the output Y. You should not define the number of training examples for the moment. To do so, you could use “None” as the batch size, it will give you the flexibility to choose it later. Hence X should be of dimension <strong>[None, n_H0, n_W0, n_C0]</strong> and Y should be of dimension <strong>[None, n_y]</strong>.  <a href="https://www.tensorflow.org/api_docs/python/tf/placeholder">Hint: search for the tf.placeholder documentation”</a>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># GRADED FUNCTION: create_placeholders
</span>
<span class="k">def</span> <span class="nf">create_placeholders</span><span class="p">(</span><span class="n">n_H0</span><span class="p">,</span> <span class="n">n_W0</span><span class="p">,</span> <span class="n">n_C0</span><span class="p">,</span> <span class="n">n_y</span><span class="p">):</span>
    <span class="s">"""
    Creates the placeholders for the tensorflow session.
    
    Arguments:
    n_H0 -- scalar, height of an input image
    n_W0 -- scalar, width of an input image
    n_C0 -- scalar, number of channels of the input
    n_y -- scalar, number of classes
        
    Returns:
    X -- placeholder for the data input, of shape [None, n_H0, n_W0, n_C0] and dtype "float"
    Y -- placeholder for the input labels, of shape [None, n_y] and dtype "float"
    """</span>

    <span class="c1">### START CODE HERE ### (≈2 lines)
</span>    <span class="n">X</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="n">n_H0</span><span class="p">,</span> <span class="n">n_W0</span><span class="p">,</span> <span class="n">n_C0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="s">"float"</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s">"X"</span><span class="p">)</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="n">n_y</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="s">"float"</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s">"Y"</span><span class="p">)</span>
    <span class="c1">### END CODE HERE ###
</span>    
    <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">create_placeholders</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
<span class="k">print</span> <span class="p">(</span><span class="s">"X = "</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
<span class="k">print</span> <span class="p">(</span><span class="s">"Y = "</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">Y</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>X = Tensor("X:0", shape=(?, 64, 64, 3), dtype=float32)
Y = Tensor("Y:0", shape=(?, 6), dtype=float32)
</code></pre></div></div>

<p><strong>Expected Output</strong></p>

<table> 
<tr>
<td>
    X = Tensor("Placeholder:0", shape=(?, 64, 64, 3), dtype=float32)

</td>
</tr>
<tr>
<td>
    Y = Tensor("Placeholder_1:0", shape=(?, 6), dtype=float32)

</td>
</tr>
</table>

<h3 id="12---initialize-parameters">1.2 - Initialize parameters</h3>

<p>You will initialize weights/filters $W1$ and $W2$ using <code class="language-plaintext highlighter-rouge">tf.contrib.layers.xavier_initializer(seed = 0)</code>. You don’t need to worry about bias variables as you will soon see that TensorFlow functions take care of the bias. Note also that you will only initialize the weights/filters for the conv2d functions. TensorFlow initializes the layers for the fully connected part automatically. We will talk more about that later in this assignment.</p>

<p><strong>Exercise:</strong> Implement initialize_parameters(). The dimensions for each group of filters are provided below. Reminder - to initialize a parameter $W$ of shape [1,2,3,4] in Tensorflow, use:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">W</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">get_variable</span><span class="p">(</span><span class="s">"W"</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">],</span> <span class="n">initializer</span> <span class="o">=</span> <span class="p">...)</span>
</code></pre></div></div>
<h4 id="tfget_variable">tf.get_variable()</h4>
<p><a href="https://www.tensorflow.org/api_docs/python/tf/get_variable">Search for the tf.get_variable documentation</a>.  Notice that the documentation says:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Gets an existing variable with these parameters or create a new one.
</code></pre></div></div>
<p>So we can use this function to create a tensorflow variable with the specified name, but if the variables already exist, it will get the existing variable with that same name.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># GRADED FUNCTION: initialize_parameters
</span>
<span class="k">def</span> <span class="nf">initialize_parameters</span><span class="p">():</span>
    <span class="s">"""
    Initializes weight parameters to build a neural network with tensorflow. The shapes are:
                        W1 : [4, 4, 3, 8]
                        W2 : [2, 2, 8, 16]
    Note that we will hard code the shape values in the function to make the grading simpler.
    Normally, functions should take values as inputs rather than hard coding.
    Returns:
    parameters -- a dictionary of tensors containing W1, W2
    """</span>
    
    <span class="n">tf</span><span class="p">.</span><span class="n">set_random_seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>                              <span class="c1"># so that your "random" numbers match ours
</span>        
    <span class="c1">### START CODE HERE ### (approx. 2 lines of code)
</span>    <span class="n">W1</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">get_variable</span><span class="p">(</span><span class="s">"W1"</span><span class="p">,</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span> <span class="n">initializer</span> <span class="o">=</span>  <span class="n">tf</span><span class="p">.</span><span class="n">contrib</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">xavier_initializer</span><span class="p">(</span><span class="n">seed</span> <span class="o">=</span> <span class="mi">0</span><span class="p">))</span>
    <span class="n">W2</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">get_variable</span><span class="p">(</span><span class="s">"W2"</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">16</span><span class="p">],</span> <span class="n">initializer</span> <span class="o">=</span>  <span class="n">tf</span><span class="p">.</span><span class="n">contrib</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">xavier_initializer</span><span class="p">(</span><span class="n">seed</span> <span class="o">=</span> <span class="mi">0</span><span class="p">))</span>
    <span class="c1">### END CODE HERE ###
</span>
    <span class="n">parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s">"W1"</span><span class="p">:</span> <span class="n">W1</span><span class="p">,</span>
                  <span class="s">"W2"</span><span class="p">:</span> <span class="n">W2</span><span class="p">}</span>
    
    <span class="k">return</span> <span class="n">parameters</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">tf</span><span class="p">.</span><span class="n">reset_default_graph</span><span class="p">()</span>
<span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess_test</span><span class="p">:</span>
    <span class="n">parameters</span> <span class="o">=</span> <span class="n">initialize_parameters</span><span class="p">()</span>
    <span class="n">init</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">global_variables_initializer</span><span class="p">()</span>
    <span class="n">sess_test</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">init</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"W1[1,1,1] = </span><span class="se">\n</span><span class="s">"</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">parameters</span><span class="p">[</span><span class="s">"W1"</span><span class="p">].</span><span class="nb">eval</span><span class="p">()[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]))</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"W1.shape: "</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">parameters</span><span class="p">[</span><span class="s">"W1"</span><span class="p">].</span><span class="n">shape</span><span class="p">))</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"W2[1,1,1] = </span><span class="se">\n</span><span class="s">"</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">parameters</span><span class="p">[</span><span class="s">"W2"</span><span class="p">].</span><span class="nb">eval</span><span class="p">()[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]))</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"W2.shape: "</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">parameters</span><span class="p">[</span><span class="s">"W2"</span><span class="p">].</span><span class="n">shape</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>W1[1,1,1] = 
[ 0.00131723  0.14176141 -0.04434952  0.09197326  0.14984085 -0.03514394
 -0.06847463  0.05245192]
W1.shape: (4, 4, 3, 8)


W2[1,1,1] = 
[-0.08566415  0.17750949  0.11974221  0.16773748 -0.0830943  -0.08058
 -0.00577033 -0.14643836  0.24162132 -0.05857408 -0.19055021  0.1345228
 -0.22779644 -0.1601823  -0.16117483 -0.10286498]
W2.shape: (2, 2, 8, 16)
</code></pre></div></div>

<p>** Expected Output:**</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>W1[1,1,1] = 
[ 0.00131723  0.14176141 -0.04434952  0.09197326  0.14984085 -0.03514394
 -0.06847463  0.05245192]
W1.shape: (4, 4, 3, 8)


W2[1,1,1] = 
[-0.08566415  0.17750949  0.11974221  0.16773748 -0.0830943  -0.08058
 -0.00577033 -0.14643836  0.24162132 -0.05857408 -0.19055021  0.1345228
 -0.22779644 -0.1601823  -0.16117483 -0.10286498]
W2.shape: (2, 2, 8, 16)
</code></pre></div></div>

<h3 id="13---forward-propagation">1.3 - Forward propagation</h3>

<p>In TensorFlow, there are built-in functions that implement the convolution steps for you.</p>

<ul>
  <li>
    <p><strong>tf.nn.conv2d(X,W, strides = [1,s,s,1], padding = ‘SAME’):</strong> given an input $X$ and a group of filters $W$, this function convolves $W$’s filters on X. The third parameter ([1,s,s,1]) represents the strides for each dimension of the input (m, n_H_prev, n_W_prev, n_C_prev). Normally, you’ll choose a stride of 1 for the number of examples (the first value) and for the channels (the fourth value), which is why we wrote the value as <code class="language-plaintext highlighter-rouge">[1,s,s,1]</code>. You can read the full documentation on <a href="https://www.tensorflow.org/api_docs/python/tf/nn/conv2d">conv2d</a>.</p>
  </li>
  <li>
    <p><strong>tf.nn.max_pool(A, ksize = [1,f,f,1], strides = [1,s,s,1], padding = ‘SAME’):</strong> given an input A, this function uses a window of size (f, f) and strides of size (s, s) to carry out max pooling over each window.  For max pooling, we usually operate on a single example at a time and a single channel at a time.  So the first and fourth value in <code class="language-plaintext highlighter-rouge">[1,f,f,1]</code> are both 1.  You can read the full documentation on <a href="https://www.tensorflow.org/api_docs/python/tf/nn/max_pool">max_pool</a>.</p>
  </li>
  <li>
    <p><strong>tf.nn.relu(Z):</strong> computes the elementwise ReLU of Z (which can be any shape). You can read the full documentation on <a href="https://www.tensorflow.org/api_docs/python/tf/nn/relu">relu</a>.</p>
  </li>
  <li><strong>tf.contrib.layers.flatten(P)</strong>: given a tensor “P”, this function takes each training (or test) example in the batch and flattens it into a 1D vector.
    <ul>
      <li>If a tensor P has the shape (m,h,w,c), where m is the number of examples (the batch size), it returns a flattened tensor with shape (batch_size, k), where $k=h \times w \times c$.  “k” equals the product of all the dimension sizes other than the first dimension.</li>
      <li>For example, given a tensor with dimensions [100,2,3,4], it flattens the tensor to be of shape [100, 24], where 24 = 2 * 3 * 4.  You can read the full documentation on <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/layers/flatten">flatten</a>.</li>
    </ul>
  </li>
  <li><strong>tf.contrib.layers.fully_connected(F, num_outputs):</strong> given the flattened input F, it returns the output computed using a fully connected layer. You can read the full documentation on <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/layers/fully_connected">full_connected</a>.</li>
</ul>

<p>In the last function above (<code class="language-plaintext highlighter-rouge">tf.contrib.layers.fully_connected</code>), the fully connected layer automatically initializes weights in the graph and keeps on training them as you train the model. Hence, you did not need to initialize those weights when initializing the parameters.</p>

<h4 id="window-kernel-filter">Window, kernel, filter</h4>
<p>The words “window”, “kernel”, and “filter” are used to refer to the same thing.  This is why the parameter <code class="language-plaintext highlighter-rouge">ksize</code> refers to “kernel size”, and we use <code class="language-plaintext highlighter-rouge">(f,f)</code> to refer to the filter size.  Both “kernel” and “filter” refer to the “window.”</p>

<p><strong>Exercise</strong></p>

<p>Implement the <code class="language-plaintext highlighter-rouge">forward_propagation</code> function below to build the following model: <code class="language-plaintext highlighter-rouge">CONV2D -&gt; RELU -&gt; MAXPOOL -&gt; CONV2D -&gt; RELU -&gt; MAXPOOL -&gt; FLATTEN -&gt; FULLYCONNECTED</code>. You should use the functions above.</p>

<p>In detail, we will use the following parameters for all the steps:</p>
<ul>
  <li>Conv2D: stride 1, padding is “SAME”</li>
  <li>ReLU</li>
  <li>Max pool: Use an 8 by 8 filter size and an 8 by 8 stride, padding is “SAME”</li>
  <li>Conv2D: stride 1, padding is “SAME”</li>
  <li>ReLU</li>
  <li>Max pool: Use a 4 by 4 filter size and a 4 by 4 stride, padding is “SAME”</li>
  <li>Flatten the previous output.</li>
  <li>FULLYCONNECTED (FC) layer: Apply a fully connected layer without an non-linear activation function. Do not call the softmax here. This will result in 6 neurons in the output layer, which then get passed later to a softmax. In TensorFlow, the softmax and cost function are lumped together into a single function, which you’ll call in a different function when computing the cost.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># GRADED FUNCTION: forward_propagation
</span>
<span class="k">def</span> <span class="nf">forward_propagation</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">parameters</span><span class="p">):</span>
    <span class="s">"""
    Implements the forward propagation for the model:
    CONV2D -&gt; RELU -&gt; MAXPOOL -&gt; CONV2D -&gt; RELU -&gt; MAXPOOL -&gt; FLATTEN -&gt; FULLYCONNECTED
    
    Note that for simplicity and grading purposes, we'll hard-code some values
    such as the stride and kernel (filter) sizes. 
    Normally, functions should take these values as function parameters.
    
    Arguments:
    X -- input dataset placeholder, of shape (input size, number of examples)
    parameters -- python dictionary containing your parameters "W1", "W2"
                  the shapes are given in initialize_parameters

    Returns:
    Z3 -- the output of the last LINEAR unit
    """</span>
    
    <span class="c1"># Retrieve the parameters from the dictionary "parameters" 
</span>    <span class="n">W1</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="s">'W1'</span><span class="p">]</span>
    <span class="n">W2</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="s">'W2'</span><span class="p">]</span>
    
    <span class="c1">### START CODE HERE ###
</span>    <span class="c1"># CONV2D: stride of 1, padding 'SAME'
</span>    <span class="n">s</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">Z1</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">conv2d</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">W1</span><span class="p">,</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="n">s</span><span class="p">,</span><span class="n">s</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="n">padding</span> <span class="o">=</span> <span class="s">'SAME'</span><span class="p">)</span>
    <span class="c1"># RELU
</span>    <span class="n">A1</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">relu</span><span class="p">(</span><span class="n">Z1</span><span class="p">)</span>
    <span class="c1"># MAXPOOL: window 8x8, stride 8, padding 'SAME'
</span>    <span class="n">f</span> <span class="o">=</span> <span class="mi">8</span>
    <span class="n">s</span> <span class="o">=</span> <span class="mi">8</span>
    <span class="n">P1</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">max_pool</span><span class="p">(</span><span class="n">A1</span><span class="p">,</span> <span class="n">ksize</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="n">f</span><span class="p">,</span><span class="n">f</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="n">s</span><span class="p">,</span><span class="n">s</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="n">padding</span> <span class="o">=</span> <span class="s">'SAME'</span><span class="p">)</span>
    <span class="c1"># CONV2D: filters W2, stride 1, padding 'SAME'
</span>    <span class="n">s</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">Z2</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">conv2d</span><span class="p">(</span><span class="n">P1</span><span class="p">,</span> <span class="n">W2</span><span class="p">,</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="n">s</span><span class="p">,</span><span class="n">s</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="n">padding</span> <span class="o">=</span> <span class="s">'SAME'</span><span class="p">)</span>
    <span class="c1"># RELU
</span>    <span class="n">A2</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">relu</span><span class="p">(</span><span class="n">Z2</span><span class="p">)</span>
    <span class="c1"># MAXPOOL: window 4x4, stride 4, padding 'SAME'
</span>    <span class="n">f</span> <span class="o">=</span> <span class="mi">4</span>
    <span class="n">s</span> <span class="o">=</span> <span class="mi">4</span>
    <span class="n">P2</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">max_pool</span><span class="p">(</span><span class="n">A2</span><span class="p">,</span> <span class="n">ksize</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="n">f</span><span class="p">,</span><span class="n">f</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="n">s</span><span class="p">,</span><span class="n">s</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="n">padding</span> <span class="o">=</span> <span class="s">'SAME'</span><span class="p">)</span>
    <span class="c1"># FLATTEN
</span>    <span class="n">F</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">contrib</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">P2</span><span class="p">)</span>
    <span class="c1"># FULLY-CONNECTED without non-linear activation function (not not call softmax).
</span>    <span class="c1"># 6 neurons in output layer. Hint: one of the arguments should be "activation_fn=None" 
</span>    <span class="n">num_outputs</span> <span class="o">=</span> <span class="mi">6</span>
    <span class="n">Z3</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">contrib</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">fully_connected</span><span class="p">(</span><span class="n">F</span><span class="p">,</span> <span class="n">num_outputs</span><span class="p">,</span> <span class="n">activation_fn</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
    <span class="c1">### END CODE HERE ###
</span>
    <span class="k">return</span> <span class="n">Z3</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">tf</span><span class="p">.</span><span class="n">reset_default_graph</span><span class="p">()</span>

<span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">create_placeholders</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
    <span class="n">parameters</span> <span class="o">=</span> <span class="n">initialize_parameters</span><span class="p">()</span>
    <span class="n">Z3</span> <span class="o">=</span> <span class="n">forward_propagation</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">parameters</span><span class="p">)</span>
    <span class="n">init</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">global_variables_initializer</span><span class="p">()</span>
    <span class="n">sess</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">init</span><span class="p">)</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">sess</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">Z3</span><span class="p">,</span> <span class="p">{</span><span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">64</span><span class="p">,</span><span class="mi">64</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">Y</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">6</span><span class="p">)})</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"Z3 = </span><span class="se">\n</span><span class="s">"</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">a</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Z3 = 
[[-0.44670227 -1.57208765 -1.53049231 -2.31013036 -1.29104376  0.46852064]
 [-0.17601591 -1.57972014 -1.4737016  -2.61672091 -1.00810647  0.5747785 ]]
</code></pre></div></div>

<p><strong>Expected Output</strong>:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Z3 = 
[[-0.44670227 -1.57208765 -1.53049231 -2.31013036 -1.29104376  0.46852064]
 [-0.17601591 -1.57972014 -1.4737016  -2.61672091 -1.00810647  0.5747785 ]]
</code></pre></div></div>

<h3 id="14---compute-cost">1.4 - Compute cost</h3>

<p>Implement the compute cost function below. Remember that the cost function helps the neural network see how much the model’s predictions differ from the correct labels.  By adjusting the weights of the network to reduce the cost, the neural network can improve its predictions.</p>

<p>You might find these two functions helpful:</p>

<ul>
  <li><strong>tf.nn.softmax_cross_entropy_with_logits(logits = Z, labels = Y):</strong> computes the softmax entropy loss. This function both computes the softmax activation function as well as the resulting loss. You can check the full documentation  <a href="https://www.tensorflow.org/api_docs/python/tf/nn/softmax_cross_entropy_with_logits">softmax_cross_entropy_with_logits</a>.</li>
  <li><strong>tf.reduce_mean:</strong> computes the mean of elements across dimensions of a tensor. Use this to calculate the sum of the losses over all the examples to get the overall cost. You can check the full documentation <a href="https://www.tensorflow.org/api_docs/python/tf/reduce_mean">reduce_mean</a>.</li>
</ul>

<h4 id="details-on-softmax_cross_entropy_with_logits-optional-reading">Details on softmax_cross_entropy_with_logits (optional reading)</h4>
<ul>
  <li>Softmax is used to format outputs so that they can be used for classification.  It assigns a value between 0 and 1 for each category, where the sum of all prediction values (across all possible categories) equals 1.</li>
  <li>Cross Entropy is compares the model’s predicted classifications with the actual labels and results in a numerical value representing the “loss” of the model’s predictions.</li>
  <li>“Logits” are the result of multiplying the weights and adding the biases.  Logits are passed through an activation function (such as a relu), and the result is called the “activation.”</li>
  <li>The function is named <code class="language-plaintext highlighter-rouge">softmax_cross_entropy_with_logits</code> takes logits as input (and not activations); then uses the model to predict using softmax, and then compares the predictions with the true labels using cross entropy.  These are done with a single function to optimize the calculations.</li>
</ul>

<p>** Exercise**: Compute the cost below using the function above.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># GRADED FUNCTION: compute_cost 
</span>
<span class="k">def</span> <span class="nf">compute_cost</span><span class="p">(</span><span class="n">Z3</span><span class="p">,</span> <span class="n">Y</span><span class="p">):</span>
    <span class="s">"""
    Computes the cost
    
    Arguments:
    Z3 -- output of forward propagation (output of the last LINEAR unit), of shape (number of examples, 6)
    Y -- "true" labels vector placeholder, same shape as Z3
    
    Returns:
    cost - Tensor of the cost function
    """</span>
    
    <span class="c1">### START CODE HERE ### (1 line of code)
</span>    <span class="n">cost</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">softmax_cross_entropy_with_logits</span><span class="p">(</span><span class="n">logits</span> <span class="o">=</span> <span class="n">Z3</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">Y</span><span class="p">))</span>
    <span class="c1">### END CODE HERE ###
</span>    
    <span class="k">return</span> <span class="n">cost</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">tf</span><span class="p">.</span><span class="n">reset_default_graph</span><span class="p">()</span>

<span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">create_placeholders</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
    <span class="n">parameters</span> <span class="o">=</span> <span class="n">initialize_parameters</span><span class="p">()</span>
    <span class="n">Z3</span> <span class="o">=</span> <span class="n">forward_propagation</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">parameters</span><span class="p">)</span>
    <span class="n">cost</span> <span class="o">=</span> <span class="n">compute_cost</span><span class="p">(</span><span class="n">Z3</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
    <span class="n">init</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">global_variables_initializer</span><span class="p">()</span>
    <span class="n">sess</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">init</span><span class="p">)</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">sess</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">cost</span><span class="p">,</span> <span class="p">{</span><span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">64</span><span class="p">,</span><span class="mi">64</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">Y</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">6</span><span class="p">)})</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"cost = "</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">a</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cost = 2.91034
</code></pre></div></div>

<p><strong>Expected Output</strong>:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cost = 2.91034
</code></pre></div></div>

<h2 id="15-model">1.5 Model</h2>

<p>Finally you will merge the helper functions you implemented above to build a model. You will train it on the SIGNS dataset.</p>

<p><strong>Exercise</strong>: Complete the function below.</p>

<p>The model below should:</p>

<ul>
  <li>create placeholders</li>
  <li>initialize parameters</li>
  <li>forward propagate</li>
  <li>compute the cost</li>
  <li>create an optimizer</li>
</ul>

<p>Finally you will create a session and run a for loop  for num_epochs, get the mini-batches, and then for each mini-batch you will optimize the function. <a href="https://www.tensorflow.org/api_docs/python/tf/global_variables_initializer">Hint for initializing the variables</a></p>

<h4 id="adam-optimizer">Adam Optimizer</h4>
<p>You can use <code class="language-plaintext highlighter-rouge">tf.train.AdamOptimizer(learning_rate = ...)</code> to create the optimizer.  The optimizer has a <code class="language-plaintext highlighter-rouge">minimize(loss=...)</code> function that you’ll call to set the cost function that the optimizer will minimize.</p>

<p>For details, check out the documentation for <a href="https://www.tensorflow.org/api_docs/python/tf/train/AdamOptimizer">Adam Optimizer</a></p>

<h4 id="random-mini-batches">Random mini batches</h4>
<p>If you took course 2 of the deep learning specialization, you implemented <code class="language-plaintext highlighter-rouge">random_mini_batches()</code> in the “Optimization” programming assignment. This function returns a list of mini-batches. It is already implemented in the <code class="language-plaintext highlighter-rouge">cnn_utils.py</code> file and imported here, so you can call it like this:</p>
<pre><code class="language-Python">minibatches = random_mini_batches(X, Y, mini_batch_size = 64, seed = 0)
</code></pre>
<p>(You will want to choose the correct variable names when you use it in your code).</p>

<h4 id="evaluating-the-optimizer-and-cost">Evaluating the optimizer and cost</h4>

<p>Within a loop, for each mini-batch, you’ll use the <code class="language-plaintext highlighter-rouge">tf.Session</code> object (named <code class="language-plaintext highlighter-rouge">sess</code>) to feed a mini-batch of inputs and labels into the neural network and evaluate the tensors for the optimizer as well as the cost.  Remember that we built a graph data structure and need to feed it inputs and labels and use <code class="language-plaintext highlighter-rouge">sess.run()</code> in order to get values for the optimizer and cost.</p>

<p>You’ll use this kind of syntax:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>output_for_var1, output_for_var2 = sess.run(
                                                fetches=[var1, var2],
                                                feed_dict={var_inputs: the_batch_of_inputs,
                                                           var_labels: the_batch_of_labels}
                                                )
</code></pre></div></div>
<ul>
  <li>Notice that <code class="language-plaintext highlighter-rouge">sess.run</code> takes its first argument <code class="language-plaintext highlighter-rouge">fetches</code> as a list of objects that you want it to evaluate (in this case, we want to evaluate the optimizer and the cost).</li>
  <li>It also takes a dictionary for the <code class="language-plaintext highlighter-rouge">feed_dict</code> parameter.</li>
  <li>The keys are the <code class="language-plaintext highlighter-rouge">tf.placeholder</code> variables that we created in the <code class="language-plaintext highlighter-rouge">create_placeholders</code> function above.</li>
  <li>The values are the variables holding the actual numpy arrays for each mini-batch.</li>
  <li>The sess.run outputs a tuple of the evaluated tensors, in the same order as the list given to <code class="language-plaintext highlighter-rouge">fetches</code>.</li>
</ul>

<p>For more information on how to use sess.run, see the documentation <a href="https://www.tensorflow.org/api_docs/python/tf/Session#run">tf.Sesssion#run</a> documentation.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># GRADED FUNCTION: model
</span>
<span class="k">def</span> <span class="nf">model</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">,</span> <span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.009</span><span class="p">,</span>
          <span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n">minibatch_size</span> <span class="o">=</span> <span class="mi">64</span><span class="p">,</span> <span class="n">print_cost</span> <span class="o">=</span> <span class="bp">True</span><span class="p">):</span>
    <span class="s">"""
    Implements a three-layer ConvNet in Tensorflow:
    CONV2D -&gt; RELU -&gt; MAXPOOL -&gt; CONV2D -&gt; RELU -&gt; MAXPOOL -&gt; FLATTEN -&gt; FULLYCONNECTED
    
    Arguments:
    X_train -- training set, of shape (None, 64, 64, 3)
    Y_train -- test set, of shape (None, n_y = 6)
    X_test -- training set, of shape (None, 64, 64, 3)
    Y_test -- test set, of shape (None, n_y = 6)
    learning_rate -- learning rate of the optimization
    num_epochs -- number of epochs of the optimization loop
    minibatch_size -- size of a minibatch
    print_cost -- True to print the cost every 100 epochs
    
    Returns:
    train_accuracy -- real number, accuracy on the train set (X_train)
    test_accuracy -- real number, testing accuracy on the test set (X_test)
    parameters -- parameters learnt by the model. They can then be used to predict.
    """</span>
    
    <span class="n">ops</span><span class="p">.</span><span class="n">reset_default_graph</span><span class="p">()</span>                         <span class="c1"># to be able to rerun the model without overwriting tf variables
</span>    <span class="n">tf</span><span class="p">.</span><span class="n">set_random_seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>                             <span class="c1"># to keep results consistent (tensorflow seed)
</span>    <span class="n">seed</span> <span class="o">=</span> <span class="mi">3</span>                                          <span class="c1"># to keep results consistent (numpy seed)
</span>    <span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">n_H0</span><span class="p">,</span> <span class="n">n_W0</span><span class="p">,</span> <span class="n">n_C0</span><span class="p">)</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">.</span><span class="n">shape</span>             
    <span class="n">n_y</span> <span class="o">=</span> <span class="n">Y_train</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>                            
    <span class="n">costs</span> <span class="o">=</span> <span class="p">[]</span>                                        <span class="c1"># To keep track of the cost
</span>    
    <span class="c1"># Create Placeholders of the correct shape
</span>    <span class="c1">### START CODE HERE ### (1 line)
</span>    <span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">create_placeholders</span><span class="p">(</span><span class="n">n_H0</span><span class="p">,</span> <span class="n">n_W0</span><span class="p">,</span> <span class="n">n_C0</span><span class="p">,</span> <span class="n">n_y</span><span class="p">)</span>
    <span class="c1">### END CODE HERE ###
</span>
    <span class="c1"># Initialize parameters
</span>    <span class="c1">### START CODE HERE ### (1 line)
</span>    <span class="n">parameters</span> <span class="o">=</span> <span class="n">initialize_parameters</span><span class="p">()</span>
    <span class="c1">### END CODE HERE ###
</span>    
    <span class="c1"># Forward propagation: Build the forward propagation in the tensorflow graph
</span>    <span class="c1">### START CODE HERE ### (1 line)
</span>    <span class="n">Z3</span> <span class="o">=</span> <span class="n">forward_propagation</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">parameters</span><span class="p">)</span>
    <span class="c1">### END CODE HERE ###
</span>    
    <span class="c1"># Cost function: Add cost function to tensorflow graph
</span>    <span class="c1">### START CODE HERE ### (1 line)
</span>    <span class="n">cost</span> <span class="o">=</span> <span class="n">compute_cost</span><span class="p">(</span><span class="n">Z3</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
    <span class="c1">### END CODE HERE ###
</span>    
    <span class="c1"># Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer that minimizes the cost.
</span>    <span class="c1">### START CODE HERE ### (1 line)
</span>    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">train</span><span class="p">.</span><span class="n">AdamOptimizer</span><span class="p">(</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">learning_rate</span><span class="p">).</span><span class="n">minimize</span><span class="p">(</span><span class="n">loss</span> <span class="o">=</span> <span class="n">cost</span><span class="p">)</span>
    <span class="c1">### END CODE HERE ###
</span>    
    <span class="c1"># Initialize all the variables globally
</span>    <span class="n">init</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">global_variables_initializer</span><span class="p">()</span>
     
    <span class="c1"># Start the session to compute the tensorflow graph
</span>    <span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
        
        <span class="c1"># Run the initialization
</span>        <span class="n">sess</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">init</span><span class="p">)</span>
        
        <span class="c1"># Do the training loop
</span>        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>

            <span class="n">minibatch_cost</span> <span class="o">=</span> <span class="mf">0.</span>
            <span class="n">num_minibatches</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">m</span> <span class="o">/</span> <span class="n">minibatch_size</span><span class="p">)</span> <span class="c1"># number of minibatches of size minibatch_size in the train set
</span>            <span class="n">seed</span> <span class="o">=</span> <span class="n">seed</span> <span class="o">+</span> <span class="mi">1</span>
            <span class="n">minibatches</span> <span class="o">=</span> <span class="n">random_mini_batches</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">minibatch_size</span><span class="p">,</span> <span class="n">seed</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">minibatch</span> <span class="ow">in</span> <span class="n">minibatches</span><span class="p">:</span>

                <span class="c1"># Select a minibatch
</span>                <span class="p">(</span><span class="n">minibatch_X</span><span class="p">,</span> <span class="n">minibatch_Y</span><span class="p">)</span> <span class="o">=</span> <span class="n">minibatch</span>
                <span class="s">"""
                # IMPORTANT: The line that runs the graph on a minibatch.
                # Run the session to execute the optimizer and the cost.
                # The feedict should contain a minibatch for (X,Y).
                """</span>
                <span class="c1">### START CODE HERE ### (1 line)
</span>                <span class="n">_</span> <span class="p">,</span> <span class="n">temp_cost</span> <span class="o">=</span> <span class="n">sess</span><span class="p">.</span><span class="n">run</span><span class="p">([</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">cost</span><span class="p">],</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">X</span><span class="p">:</span><span class="n">minibatch_X</span><span class="p">,</span> <span class="n">Y</span><span class="p">:</span><span class="n">minibatch_Y</span><span class="p">})</span>
                <span class="c1">### END CODE HERE ###
</span>                
                <span class="n">minibatch_cost</span> <span class="o">+=</span> <span class="n">temp_cost</span> <span class="o">/</span> <span class="n">num_minibatches</span>
                

            <span class="c1"># Print the cost every epoch
</span>            <span class="k">if</span> <span class="n">print_cost</span> <span class="o">==</span> <span class="bp">True</span> <span class="ow">and</span> <span class="n">epoch</span> <span class="o">%</span> <span class="mi">5</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">print</span> <span class="p">(</span><span class="s">"Cost after epoch %i: %f"</span> <span class="o">%</span> <span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">minibatch_cost</span><span class="p">))</span>
            <span class="k">if</span> <span class="n">print_cost</span> <span class="o">==</span> <span class="bp">True</span> <span class="ow">and</span> <span class="n">epoch</span> <span class="o">%</span> <span class="mi">1</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">costs</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">minibatch_cost</span><span class="p">)</span>
        
        
        <span class="c1"># plot the cost
</span>        <span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">costs</span><span class="p">))</span>
        <span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'cost'</span><span class="p">)</span>
        <span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'iterations (per tens)'</span><span class="p">)</span>
        <span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Learning rate ="</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">learning_rate</span><span class="p">))</span>
        <span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>

        <span class="c1"># Calculate the correct predictions
</span>        <span class="n">predict_op</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">Z3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">correct_prediction</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">equal</span><span class="p">(</span><span class="n">predict_op</span><span class="p">,</span> <span class="n">tf</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        
        <span class="c1"># Calculate accuracy on the test set
</span>        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">cast</span><span class="p">(</span><span class="n">correct_prediction</span><span class="p">,</span> <span class="s">"float"</span><span class="p">))</span>
        <span class="k">print</span><span class="p">(</span><span class="n">accuracy</span><span class="p">)</span>
        <span class="n">train_accuracy</span> <span class="o">=</span> <span class="n">accuracy</span><span class="p">.</span><span class="nb">eval</span><span class="p">({</span><span class="n">X</span><span class="p">:</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">Y</span><span class="p">:</span> <span class="n">Y_train</span><span class="p">})</span>
        <span class="n">test_accuracy</span> <span class="o">=</span> <span class="n">accuracy</span><span class="p">.</span><span class="nb">eval</span><span class="p">({</span><span class="n">X</span><span class="p">:</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">Y</span><span class="p">:</span> <span class="n">Y_test</span><span class="p">})</span>
        <span class="k">print</span><span class="p">(</span><span class="s">"Train Accuracy:"</span><span class="p">,</span> <span class="n">train_accuracy</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s">"Test Accuracy:"</span><span class="p">,</span> <span class="n">test_accuracy</span><span class="p">)</span>
                
        <span class="k">return</span> <span class="n">train_accuracy</span><span class="p">,</span> <span class="n">test_accuracy</span><span class="p">,</span> <span class="n">parameters</span>
</code></pre></div></div>

<p>Run the following cell to train your model for 100 epochs. Check if your cost after epoch 0 and 5 matches our output. If not, stop the cell and go back to your code!</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">parameters</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Cost after epoch 0: 1.917929
Cost after epoch 5: 1.506757
Cost after epoch 10: 0.955359
Cost after epoch 15: 0.845802
Cost after epoch 20: 0.701174
Cost after epoch 25: 0.571977
Cost after epoch 30: 0.518435
Cost after epoch 35: 0.495806
Cost after epoch 40: 0.429827
Cost after epoch 45: 0.407291
Cost after epoch 50: 0.366394
Cost after epoch 55: 0.376922
Cost after epoch 60: 0.299491
Cost after epoch 65: 0.338870
Cost after epoch 70: 0.316400
Cost after epoch 75: 0.310413
Cost after epoch 80: 0.249549
Cost after epoch 85: 0.243457
Cost after epoch 90: 0.200031
Cost after epoch 95: 0.175452
</code></pre></div></div>

<p><img src="/assets/2023-12-01-Convolution-model-Application-v1a_files/2023-12-01-Convolution-model-Application-v1a_33_1.png" alt="png" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Tensor("Mean_1:0", shape=(), dtype=float32)
Train Accuracy: 0.940741
Test Accuracy: 0.783333
</code></pre></div></div>

<p><strong>Expected output</strong>: although it may not match perfectly, your expected output should be close to ours and your cost value should decrease.</p>

<table> 
<tr>
    <td> 
    **Cost after epoch 0 =**
    </td>

    <td> 
      1.917929
    </td> 
</tr>
<tr>
    <td> 
    **Cost after epoch 5 =**
    </td>

    <td> 
      1.506757
    </td> 
</tr>
<tr>
    <td> 
    **Train Accuracy   =**
    </td>

    <td> 
      0.940741
    </td> 
</tr> 

<tr>
    <td> 
    **Test Accuracy   =**
    </td>

    <td> 
      0.783333
    </td> 
</tr> 
</table>

<p>Congratulations! You have finished the assignment and built a model that recognizes SIGN language with almost 80% accuracy on the test set. If you wish, feel free to play around with this dataset further. You can actually improve its accuracy by spending more time tuning the hyperparameters, or using regularization (as this model clearly has a high variance).</p>

<p>Once again, here’s a thumbs up for your work!</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fname</span> <span class="o">=</span> <span class="s">"/assets/2023-12-01-Convolution-model-Application-v1a_files/thumbs_up.jpg"</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">ndimage</span><span class="p">.</span><span class="n">imread</span><span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="n">flatten</span><span class="o">=</span><span class="bp">False</span><span class="p">))</span>
<span class="n">my_image</span> <span class="o">=</span> <span class="n">scipy</span><span class="p">.</span><span class="n">misc</span><span class="p">.</span><span class="n">imresize</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span><span class="mi">64</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">my_image</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;matplotlib.image.AxesImage at 0x7fd681a816a0&gt;
</code></pre></div></div>

<p><img src="/assets/2023-12-01-Convolution-model-Application-v1a_files/2023-12-01-Convolution-model-Application-v1a_36_1.png" alt="png" /></p>]]></content><author><name>Zhu Tianda</name></author><category term="coding" /><category term="AI" /><category term="CNN" /><summary type="html"><![CDATA[Convolutional Neural Networks: Application]]></summary></entry><entry><title type="html">Convolutional Neural Networks: Step by Step</title><link href="http://0.0.0.0:8855/coding/2023/12/01/convolutional-neural-networks-step-by-step.html" rel="alternate" type="text/html" title="Convolutional Neural Networks: Step by Step" /><published>2023-12-01T00:00:00+08:00</published><updated>2023-12-01T00:00:00+08:00</updated><id>http://0.0.0.0:8855/coding/2023/12/01/convolutional-neural-networks-step-by-step</id><content type="html" xml:base="http://0.0.0.0:8855/coding/2023/12/01/convolutional-neural-networks-step-by-step.html"><![CDATA[<p>卷积的数学表示
\(f∗g(n)=∫_{−∞}^{+∞}​f(τ)g(n−τ)dτ\)
上面公式是连续的定义，再看看离散的定义：</p>

\[f∗g(n)=τ=∑_{−∞}^{+∞}​f(τ)g(n−τ)\]

<p>互相关与卷积
一些深度学习教程都使用这种互相关运算来解释卷积的计算过程。但实际上，计算过程并非学术上严格意义上的卷积。
我们将这种互相关的矩阵乘法转换成公式，如果输入矩阵为I，核矩阵为K，核矩阵K形状为m×n。我们想要得到输出矩阵O中(i,j)位置的元素，其实就是对矩阵中各个数字做乘法，最后累加到一起。
\(O(i,j)=(K∗I)(i,j)=\sum_m\sum_n​I(i+m,j+n)K(m,n)\)</p>

<p>上面公式中，$I(i+m,j+n)K(m,n)$表示输入矩阵的某个元素I(i+m,j+n)与核矩阵的元素K(m,n)相乘。$\sum_m$和$\sum_n$​分别在矩阵的横向和纵向做累加。
但这个公式依然与最初看到的卷积公式有些区别，我们将输入矩阵的加号改为减号：\(O(i,j)=(K∗I)(i,j)=\sum_m\sum_n​I(i−m,j−n)K(m,n)\)</p>

<p>这就出现了卷积公式中的减号，那么这两个矩阵实际的计算类似于：</p>

<p><img src="/assets/2023-12-01-convolutional-neural-networks-step-by-step_files/j1ni4qxh.png" style="width:700px;height:400px;" /></p>

<p>图4 两个矩阵之间进行卷积运算</p>

<p>也就是说，输入矩阵深色区域的最后一个元素与核矩阵的第一个元素相乘，输入矩阵深色区域的倒数第二个元素与核矩阵的第二个元素相乘，以此类推…又或者说，<strong>把核矩阵旋转180度，再与输入矩阵相乘。</strong></p>

<p>卷积数学公式中的减号，在二维矩阵的场景下，可以被解释为：先旋转、再相乘。<strong>由于在深度学习中，核矩阵是一个需要训练的参数，卷积神经网络都是针对图像，图像即使旋转180度，对于计算机来说区别不大</strong>。旋转与否，或者说是否使用减号，对于深度学习来说关系不大，反而不旋转的互相关运算计算起来更方便。因此，很多深度学习框架直接使用互相关运算来表示卷积的过程。</p>

<h1 id="convolutional-neural-networks-step-by-step">Convolutional Neural Networks: Step by Step</h1>

<p>Welcome to Course 4’s first assignment! In this assignment, you will implement convolutional (CONV) and pooling (POOL) layers in numpy, including both forward propagation and (optionally) backward propagation.</p>

<p><strong>Notation</strong>:</p>
<ul>
  <li>Superscript $[l]$ denotes an object of the $l^{th}$ layer.
    <ul>
      <li>Example: $a^{[4]}$ is the $4^{th}$ layer activation. $W^{[5]}$ and $b^{[5]}$ are the $5^{th}$ layer parameters.</li>
    </ul>
  </li>
  <li>Superscript $(i)$ denotes an object from the $i^{th}$ example.
    <ul>
      <li>Example: $x^{(i)}$ is the $i^{th}$ training example input.</li>
    </ul>
  </li>
  <li>Lowerscript $i$ denotes the $i^{th}$ entry of a vector.
    <ul>
      <li>Example: $a^{[l]}_i$ denotes the $i^{th}$ entry of the activations in layer $l$, assuming this is a fully connected (FC) layer.</li>
    </ul>
  </li>
  <li>$n_H$, $n_W$ and $n_C$ denote respectively the height, width and number of channels of a given layer. If you want to reference a specific layer $l$, you can also write $n_H^{[l]}$, $n_W^{[l]}$, $n_C^{[l]}$.</li>
  <li>$n_{H_{prev}}$, $n_{W_{prev}}$ and $n_{C_{prev}}$ denote respectively the height, width and number of channels of the previous layer. If referencing a specific layer $l$, this could also be denoted $n_H^{[l-1]}$, $n_W^{[l-1]}$, $n_C^{[l-1]}$.</li>
</ul>

<p>We assume that you are already familiar with <code class="language-plaintext highlighter-rouge">numpy</code> and/or have completed the previous courses of the specialization. Let’s get started!</p>

<h2 id="1---packages">1 - Packages</h2>

<p>Let’s first import all the packages that you will need during this assignment.</p>
<ul>
  <li><a href="www.numpy.org">numpy</a> is the fundamental package for scientific computing with Python.</li>
  <li><a href="http://matplotlib.org">matplotlib</a> is a library to plot graphs in Python.</li>
  <li>np.random.seed(1) is used to keep all the random function calls consistent. It will help us grade your work.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">h5py</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="n">plt</span><span class="p">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s">'figure.figsize'</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mf">5.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">)</span> <span class="c1"># set default size of plots
</span><span class="n">plt</span><span class="p">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s">'image.interpolation'</span><span class="p">]</span> <span class="o">=</span> <span class="s">'nearest'</span>
<span class="n">plt</span><span class="p">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s">'image.cmap'</span><span class="p">]</span> <span class="o">=</span> <span class="s">'gray'</span>

<span class="o">%</span><span class="n">load_ext</span> <span class="n">autoreload</span>
<span class="o">%</span><span class="n">autoreload</span> <span class="mi">2</span>

<span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="2---outline-of-the-assignment">2 - Outline of the Assignment</h2>

<p>You will be implementing the building blocks of a convolutional neural network! Each function you will implement will have detailed instructions that will walk you through the steps needed:</p>

<ul>
  <li>Convolution functions, including:
    <ul>
      <li>Zero Padding</li>
      <li>Convolve window</li>
      <li>Convolution forward</li>
      <li>Convolution backward (optional)</li>
    </ul>
  </li>
  <li>Pooling functions, including:
    <ul>
      <li>Pooling forward</li>
      <li>Create mask</li>
      <li>Distribute value</li>
      <li>Pooling backward (optional)</li>
    </ul>
  </li>
</ul>

<p>This notebook will ask you to implement these functions from scratch in <code class="language-plaintext highlighter-rouge">numpy</code>. In the next notebook, you will use the TensorFlow equivalents of these functions to build the following model:</p>

<p><img src="/assets/2023-12-01-convolutional-neural-networks-step-by-step_files/da1b0164-5374-428a-b22e-f6449c637892.png" alt="model.png" /><br />
<strong>Note</strong> that for every forward function, there is its corresponding backward equivalent. Hence, at every step of your forward module you will store some parameters in a cache. These parameters are used to compute gradients during backpropagation.</p>

<h2 id="3---convolutional-neural-networks">3 - Convolutional Neural Networks</h2>

<p>Although programming frameworks make convolutions easy to use, they remain one of the hardest concepts to understand in Deep Learning. A convolution layer transforms an input volume into an output volume of different size, as shown below.</p>

<p><img src="/assets/2023-12-01-convolutional-neural-networks-step-by-step_files/ba23f49b-6548-40e9-afc6-7f5d5953554d.png" style="width:350px;height:200px;" /></p>

<p><img src="/assets/2023-12-01-convolutional-neural-networks-step-by-step_files/ba23f49b-6548-40e9-afc6-7f5d5953554d.png" alt="conv_nn.png" /></p>

<p>In this part, you will build every step of the convolution layer. You will first implement two helper functions: one for zero padding and the other for computing the convolution function itself.</p>

<h3 id="31---zero-padding">3.1 - Zero-Padding</h3>

<p>Zero-padding adds zeros around the border of an image:</p>

<p><img src="/assets/2023-12-01-convolutional-neural-networks-step-by-step_files/aee3a50b-9668-4d72-9897-74c140a78058.png" style="width:600px;height:400px;" /></p>
<caption><center> <u>  **Figure 1** </u>&gt;  : **Zero-Padding** Image (3 channels, RGB) with a padding of 2. </center></caption>

<p><img src="/assets/2023-12-01-convolutional-neural-networks-step-by-step_files/aee3a50b-9668-4d72-9897-74c140a78058.png" alt="PAD.png" /></p>

<p><strong>The main benefits of padding are the following:</strong></p>

<ul>
  <li>
    <p><strong>It allows you to use a CONV layer without necessarily shrinking the height and width of the volumes.</strong> This is important for building deeper networks, since otherwise the height/width would shrink as you go to deeper layers. An important special case is the “same” convolution, in which the height/width is exactly preserved after one layer.</p>
  </li>
  <li>
    <p><strong>It helps us keep more of the information at the border of an image</strong>. Without padding, very few values at the next layer would be affected by pixels as the edges of an image.</p>
  </li>
</ul>

<p><strong>Exercise</strong>: Implement the following function, which pads all the images of a batch of examples X with zeros. <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.pad.html">Use np.pad</a>. Note if you want to pad the array “a” of shape $(5,5,5,5,5)$ with <code class="language-plaintext highlighter-rouge">pad = 1</code> for the 2nd dimension, <code class="language-plaintext highlighter-rouge">pad = 3</code> for the 4th dimension and <code class="language-plaintext highlighter-rouge">pad = 0</code> for the rest, you would do:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">pad</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="p">((</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">)),</span> <span class="s">'constant'</span><span class="p">,</span> <span class="n">constant_values</span> <span class="o">=</span> <span class="p">(..,..))</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># GRADED FUNCTION: zero_pad
</span>
<span class="k">def</span> <span class="nf">zero_pad</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">pad</span><span class="p">):</span>
    <span class="s">"""
    Pad with zeros all images of the dataset X. The padding is applied to the height and width of an image, 
    as illustrated in Figure 1.
    
    Argument:
    X -- python numpy array of shape (m, n_H, n_W, n_C) representing a batch of m images
    pad -- integer, amount of padding around each image on vertical and horizontal dimensions
    
    Returns:
    X_pad -- padded image of shape (m, n_H + 2*pad, n_W + 2*pad, n_C)
    """</span>
    
    <span class="c1">### START CODE HERE ### (≈ 1 line)
</span>    <span class="n">X_pad</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">pad</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="p">((</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">),(</span><span class="n">pad</span><span class="p">,</span><span class="n">pad</span><span class="p">),(</span><span class="n">pad</span><span class="p">,</span><span class="n">pad</span><span class="p">),(</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">)),</span><span class="s">'constant'</span><span class="p">,</span> <span class="n">constant_values</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">))</span>
    <span class="c1">### END CODE HERE ###
</span>    
    <span class="k">return</span> <span class="n">X_pad</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">x_pad</span> <span class="o">=</span> <span class="n">zero_pad</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="k">print</span> <span class="p">(</span><span class="s">"x.shape ="</span><span class="p">,</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
<span class="k">print</span> <span class="p">(</span><span class="s">"x_pad.shape ="</span><span class="p">,</span> <span class="n">x_pad</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
<span class="k">print</span> <span class="p">(</span><span class="s">"x[1,1] ="</span><span class="p">,</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>  <span class="c1">#the first 3x2 
</span><span class="k">print</span> <span class="p">(</span><span class="s">"x_pad[1,1] ="</span><span class="p">,</span> <span class="n">x_pad</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axarr</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">axarr</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">'x'</span><span class="p">)</span>
<span class="n">axarr</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">imshow</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">,:,:,</span><span class="mi">0</span><span class="p">])</span>
<span class="n">axarr</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">'x_pad'</span><span class="p">)</span>
<span class="n">axarr</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">imshow</span><span class="p">(</span><span class="n">x_pad</span><span class="p">[</span><span class="mi">0</span><span class="p">,:,:,</span><span class="mi">0</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>x.shape = (4, 3, 3, 2)
x_pad.shape = (4, 7, 7, 2)
x[1,1] = [[ 0.90085595 -0.68372786]
 [-0.12289023 -0.93576943]
 [-0.26788808  0.53035547]]
x_pad[1,1] = [[0. 0.]
 [0. 0.]
 [0. 0.]
 [0. 0.]
 [0. 0.]
 [0. 0.]
 [0. 0.]]





&lt;matplotlib.image.AxesImage at 0x7f4ddd522dd0&gt;
</code></pre></div></div>

<p><img src="/assets/2023-12-01-convolutional-neural-networks-step-by-step_files/2023-12-01-convolutional-neural-networks-step-by-step_8_2.png" alt="png" /></p>

<p><strong>Expected Output</strong>:</p>

<table>
    <tr>
        <td>
            **x.shape**:
        </td>
        <td>
           (4, 3, 3, 2)
        </td>
    </tr>
        <tr>
        <td>
            **x_pad.shape**:
        </td>
        <td>
           (4, 7, 7, 2)
        </td>
    </tr>
        <tr>
        <td>
            **x[1,1]**:
        </td>
        <td>
           [[ 0.90085595 -0.68372786]
 [-0.12289023 -0.93576943]
 [-0.26788808  0.53035547]]
        </td>
    </tr>
        <tr>
        <td>
            **x_pad[1,1]**:
        </td>
        <td>
           [[ 0.  0.]
 [ 0.  0.]
 [ 0.  0.]
 [ 0.  0.]
 [ 0.  0.]
 [ 0.  0.]
 [ 0.  0.]]
        </td>
    </tr>

</table>

<h3 id="32---single-step-of-convolution">3.2 - Single step of convolution</h3>

<p>In this part, <strong>implement a single step of convolution</strong>, in which you apply the filter to a single position of the input. This will be used to build a convolutional unit, which:</p>

<ul>
  <li>Takes an input volume</li>
  <li>Applies a filter at every position of the input</li>
  <li>Outputs another volume (usually of different size)</li>
</ul>

<p><img src="/assets/2023-12-01-convolutional-neural-networks-step-by-step_files/23c61b52-6461-4a00-8a7f-07945136cd78.gif" style="width:500px;height:300px;" /></p>
<caption><center> <u>  **Figure 2** </u> : **Convolution operation** with a filter of 2x2 and a stride of 1 (stride = amount you move the window each time you slide) </center></caption>

<p><img src="/assets/2023-12-01-convolutional-neural-networks-step-by-step_files/23c61b52-6461-4a00-8a7f-07945136cd78.gif" alt="Convolution_schematic.gif" /></p>

<p>In a computer vision application, each value in the matrix on the left corresponds to a single pixel value, and we convolve a 3x3 filter with the image by multiplying its values element-wise with the original matrix, then summing them up and adding a bias. In this first step of the exercise, you will implement a single step of convolution, corresponding to applying a filter to just one of the positions to get a single real-valued output.</p>

<p>Later in this notebook, you’ll apply this function to multiple positions of the input to implement the full convolutional operation.</p>

<p><strong>Exercise</strong>: Implement conv_single_step(). <a href="https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.sum.html">Hint</a>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># GRADED FUNCTION: conv_single_step
</span>
<span class="k">def</span> <span class="nf">conv_single_step</span><span class="p">(</span><span class="n">a_slice_prev</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
    <span class="s">"""
    Apply one filter defined by parameters W on a single slice (a_slice_prev) of the output activation 
    of the previous layer.
    
    Arguments:
    a_slice_prev -- slice of input data of shape (f, f, n_C_prev)
    W -- Weight parameters contained in a window - matrix of shape (f, f, n_C_prev)
    b -- Bias parameters contained in a window - matrix of shape (1, 1, 1)
    
    Returns:
    Z -- a scalar value, result of convolving the sliding window (W, b) on a slice x of the input data
    """</span>

    <span class="c1">### START CODE HERE ### (≈ 2 lines of code)
</span>    <span class="c1"># Element-wise product between a_slice and W. Do not add the bias yet.
</span>    <span class="n">s</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">a_slice_prev</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span>
    <span class="c1"># Sum over all entries of the volume s.
</span>    <span class="n">Z</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
    <span class="c1"># Add bias b to Z. Cast b to a float() so that Z results in a scalar value.
</span>    <span class="n">Z</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">squeeze</span><span class="p">(</span> <span class="n">Z</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span>
    <span class="c1">### END CODE HERE ###
</span>
    <span class="k">return</span> <span class="n">Z</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">a_slice_prev</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">b</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">conv_single_step</span><span class="p">(</span><span class="n">a_slice_prev</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Z ="</span><span class="p">,</span> <span class="n">Z</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(1, 1, 1)
Z = -6.999089450680221
</code></pre></div></div>

<p><strong>Expected Output</strong>:</p>
<table>
    <tr>
        <td>
            **Z**
        </td>
        <td>
            -6.99908945068
        </td>
    </tr>

</table>

<h3 id="33---convolutional-neural-networks---forward-pass">3.3 - Convolutional Neural Networks - Forward pass</h3>

<p>In the forward pass, you will take many filters and convolve them on the input. Each ‘convolution’ gives you a 2D matrix output. You will then stack these outputs to get a 3D volume:</p>

<p><img src="/assets/2023-12-01-convolutional-neural-networks-step-by-step_files/738f8421-f255-4656-9e6a-22bd2537e5a5.png" style="width:600px;height:400px;" /></p>

<p><img src="/assets/2023-12-01-convolutional-neural-networks-step-by-step_files/738f8421-f255-4656-9e6a-22bd2537e5a5.png" alt="image.png" /></p>

<p><strong>Exercise</strong>: Implement the function below to convolve the filters W on an input activation A_prev. This function takes as input A_prev, the activations output by the previous layer (for a batch of m inputs), F filters/weights denoted by W, and a bias vector denoted by b, where each filter has its own (single) bias. Finally you also have access to the hyperparameters dictionary which contains the stride and the padding.</p>

<p><strong>Hint</strong>:</p>
<ol>
  <li>To select a 2x2 slice at the upper left corner of a matrix “a_prev” (shape (5,5,3)), you would do:
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">a_slice_prev</span> <span class="o">=</span> <span class="n">a_prev</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">,:]</span>
</code></pre></div>    </div>
    <p>This will be useful when you will define <code class="language-plaintext highlighter-rouge">a_slice_prev</code> below, using the <code class="language-plaintext highlighter-rouge">start/end</code> indexes you will define.</p>
  </li>
  <li>To define a_slice you will need to first define its corners <code class="language-plaintext highlighter-rouge">vert_start</code>, <code class="language-plaintext highlighter-rouge">vert_end</code>, <code class="language-plaintext highlighter-rouge">horiz_start</code> and <code class="language-plaintext highlighter-rouge">horiz_end</code>. This figure may be helpful for you to find how each of the corner can be defined using h, w, f and s in the code below.</li>
</ol>

<p><img src="/assets/2023-12-01-convolutional-neural-networks-step-by-step_files/85771fb2-5211-4c2f-a587-b75842931ce4.png" style="width:400px;height:300px;" /></p>
<caption><center> <u> **Figure 3** </u>:

![vert_horiz_kiank.png](/assets/2023-12-01-convolutional-neural-networks-step-by-step_files/85771fb2-5211-4c2f-a587-b75842931ce4.png)
**Definition of a slice using vertical and horizontal start/end (with a 2x2 filter)** <br /> This figure shows only a single channel.  </center></caption>

<p><strong>Reminder</strong>:
The formulas relating the output shape of the convolution to the input shape is:
\(n_H = \lfloor \frac{n_{H_{prev}} - f + 2 \times pad}{stride} \rfloor +1\)
\(n_W = \lfloor \frac{n_{W_{prev}} - f + 2 \times pad}{stride} \rfloor +1\)
\(n_C = \text{number of filters used in the convolution}\)</p>

<p>For this exercise, we won’t worry about vectorization, and will just implement everything with for-loops.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># GRADED FUNCTION: conv_forward
</span>
<span class="k">def</span> <span class="nf">conv_forward</span><span class="p">(</span><span class="n">A_prev</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">hparameters</span><span class="p">):</span>
    <span class="s">"""
    Implements the forward propagation for a convolution function
    
    Arguments:
    A_prev -- output activations of the previous layer, numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)
    W -- Weights, numpy array of shape (f, f, n_C_prev, n_C)
    b -- Biases, numpy array of shape (1, 1, 1, n_C)
    hparameters -- python dictionary containing "stride" and "pad"
        
    Returns:
    Z -- conv output, numpy array of shape (m, n_H, n_W, n_C)
    cache -- cache of values needed for the conv_backward() function
    """</span>
    
    <span class="c1">### START CODE HERE ###
</span>    <span class="c1"># Retrieve dimensions from A_prev's shape (≈1 line)  
</span>    <span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">n_H_prev</span><span class="p">,</span> <span class="n">n_W_prev</span><span class="p">,</span> <span class="n">n_C_prev</span><span class="p">)</span> <span class="o">=</span> <span class="n">A_prev</span><span class="p">.</span><span class="n">shape</span>
    
    <span class="c1"># Retrieve dimensions from W's shape (≈1 line)
</span>    <span class="c1"># n_c is the filter number 
</span>    <span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">n_C_prev</span><span class="p">,</span> <span class="n">n_C</span><span class="p">)</span> <span class="o">=</span> <span class="n">W</span><span class="p">.</span><span class="n">shape</span>  
    
    <span class="c1"># Retrieve information from "hparameters" (≈2 lines)
</span>    <span class="n">stride</span> <span class="o">=</span> <span class="n">hparameters</span><span class="p">[</span><span class="s">'stride'</span><span class="p">]</span>
    <span class="n">pad</span> <span class="o">=</span> <span class="n">hparameters</span><span class="p">[</span><span class="s">'pad'</span><span class="p">]</span>
    
    <span class="c1"># Compute the dimensions of the CONV output volume using the formula given above. Hint: use int() to floor. (≈2 lines)
</span>    <span class="n">n_H</span> <span class="o">=</span> <span class="nb">int</span><span class="p">((</span><span class="n">n_H_prev</span> <span class="o">-</span> <span class="n">f</span> <span class="o">+</span> <span class="mi">2</span><span class="o">*</span><span class="n">pad</span><span class="p">)</span><span class="o">/</span><span class="n">stride</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">n_W</span> <span class="o">=</span> <span class="nb">int</span><span class="p">((</span><span class="n">n_W_prev</span> <span class="o">-</span> <span class="n">f</span> <span class="o">+</span> <span class="mi">2</span><span class="o">*</span><span class="n">pad</span><span class="p">)</span><span class="o">/</span><span class="n">stride</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
    
    <span class="c1"># Initialize the output volume Z with zeros. (≈1 line)
</span>    <span class="n">Z</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">m</span><span class="p">,</span> <span class="n">n_H</span><span class="p">,</span> <span class="n">n_W</span><span class="p">,</span> <span class="n">n_C</span><span class="p">))</span>
    
    <span class="c1"># Create A_prev_pad by padding A_prev
</span>    <span class="n">A_prev_pad</span> <span class="o">=</span> <span class="n">zero_pad</span><span class="p">(</span><span class="n">A_prev</span><span class="p">,</span> <span class="n">pad</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>                               <span class="c1"># loop over the batch of training examples
</span>        <span class="n">a_prev_pad</span> <span class="o">=</span> <span class="n">A_prev_pad</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>                               <span class="c1"># Select ith training example's padded activation
</span>        <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_H</span><span class="p">):</span>                           <span class="c1"># loop over vertical axis of the output volume
</span>            <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_W</span><span class="p">):</span>                       <span class="c1"># loop over horizontal axis of the output volume
</span>                <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_C</span><span class="p">):</span>                   <span class="c1"># loop over channels (= #filters) of the output volume
</span>                    
                    <span class="c1"># Find the corners of the current "slice" (≈4 lines)
</span>                    <span class="n">vert_start</span> <span class="o">=</span> <span class="n">h</span> <span class="o">*</span> <span class="n">stride</span>
                    <span class="n">vert_end</span> <span class="o">=</span> <span class="n">vert_start</span> <span class="o">+</span> <span class="n">f</span>
                    <span class="n">horiz_start</span> <span class="o">=</span> <span class="n">w</span> <span class="o">*</span> <span class="n">stride</span>
                    <span class="n">horiz_end</span> <span class="o">=</span> <span class="n">horiz_start</span> <span class="o">+</span> <span class="n">f</span>
                    
                    <span class="c1"># Use the corners to define the (3D) slice of a_prev_pad (See Hint above the cell). (≈1 line)
</span>                    <span class="n">a_slice_prev</span> <span class="o">=</span> <span class="n">a_prev_pad</span><span class="p">[</span><span class="n">vert_start</span><span class="p">:</span><span class="n">vert_end</span><span class="p">,</span> <span class="n">horiz_start</span><span class="p">:</span><span class="n">horiz_end</span><span class="p">,</span> <span class="p">:]</span>
                    
                    <span class="c1"># Convolve the (3D) slice with the correct filter W and bias b, to get back one output neuron. (≈1 line)
</span>                    <span class="n">Z</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="n">conv_single_step</span><span class="p">(</span><span class="n">a_slice_prev</span><span class="p">,</span> <span class="n">W</span><span class="p">[:,:,:,</span><span class="n">c</span><span class="p">],</span> <span class="n">b</span><span class="p">[:,:,:,</span><span class="n">c</span><span class="p">])</span>
                                        
    <span class="c1">### END CODE HERE ###
</span>    
    <span class="c1"># Making sure your output shape is correct
</span>    <span class="k">assert</span><span class="p">(</span><span class="n">Z</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">n_H</span><span class="p">,</span> <span class="n">n_W</span><span class="p">,</span> <span class="n">n_C</span><span class="p">))</span>
    
    <span class="c1"># Save information in "cache" for the backprop
</span>    <span class="n">cache</span> <span class="o">=</span> <span class="p">(</span><span class="n">A_prev</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">hparameters</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">Z</span><span class="p">,</span> <span class="n">cache</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#the im2col function copied from internet for reference
</span><span class="k">def</span> <span class="nf">im2col</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">ksize</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">N</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">C</span> <span class="o">=</span> <span class="n">img</span><span class="p">.</span><span class="n">shape</span>
    <span class="n">out_h</span> <span class="o">=</span> <span class="p">(</span><span class="n">H</span> <span class="o">-</span> <span class="n">ksize</span><span class="p">)</span> <span class="o">//</span> <span class="n">stride</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">out_w</span> <span class="o">=</span> <span class="p">(</span><span class="n">W</span> <span class="o">-</span> <span class="n">ksize</span><span class="p">)</span> <span class="o">//</span> <span class="n">stride</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">col</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">empty</span><span class="p">((</span><span class="n">N</span> <span class="o">*</span> <span class="n">out_h</span> <span class="o">*</span> <span class="n">out_w</span><span class="p">,</span> <span class="n">ksize</span> <span class="o">*</span> <span class="n">ksize</span> <span class="o">*</span> <span class="n">C</span><span class="p">))</span>
    <span class="n">outsize</span> <span class="o">=</span> <span class="n">out_w</span> <span class="o">*</span> <span class="n">out_h</span>
    <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">out_h</span><span class="p">):</span>
        <span class="n">y_min</span> <span class="o">=</span> <span class="n">y</span> <span class="o">*</span> <span class="n">stride</span>
        <span class="n">y_max</span> <span class="o">=</span> <span class="n">y_min</span> <span class="o">+</span> <span class="n">ksize</span>
        <span class="n">y_start</span> <span class="o">=</span> <span class="n">y</span> <span class="o">*</span> <span class="n">out_w</span>
        <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">out_w</span><span class="p">):</span>
            <span class="n">x_min</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="n">stride</span>
            <span class="n">x_max</span> <span class="o">=</span> <span class="n">x_min</span> <span class="o">+</span> <span class="n">ksize</span>
            <span class="n">col</span><span class="p">[</span><span class="n">y_start</span><span class="o">+</span><span class="n">x</span><span class="p">::</span><span class="n">outsize</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">img</span><span class="p">[:,</span> <span class="n">y_min</span><span class="p">:</span><span class="n">y_max</span><span class="p">,</span> <span class="n">x_min</span><span class="p">:</span><span class="n">x_max</span><span class="p">,</span> <span class="p">:].</span><span class="n">reshape</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">col</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">A_prev</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">8</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">8</span><span class="p">)</span>
<span class="n">hparameters</span> <span class="o">=</span> <span class="p">{</span><span class="s">"pad"</span> <span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
               <span class="s">"stride"</span><span class="p">:</span> <span class="mi">2</span><span class="p">}</span>

<span class="n">Z</span><span class="p">,</span> <span class="n">cache_conv</span> <span class="o">=</span> <span class="n">conv_forward</span><span class="p">(</span><span class="n">A_prev</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">hparameters</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Z's mean ="</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">Z</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Z[3,2,1] ="</span><span class="p">,</span> <span class="n">Z</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="s">"cache_conv[0][1][2][3] ="</span><span class="p">,</span> <span class="n">cache_conv</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">][</span><span class="mi">2</span><span class="p">][</span><span class="mi">3</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Z's mean = 0.048995203528855794
Z[3,2,1] = [-0.61490741 -6.7439236  -2.55153897  1.75698377  3.56208902  0.53036437
  5.18531798  8.75898442]
cache_conv[0][1][2][3] = [-0.20075807  0.18656139  0.41005165]
</code></pre></div></div>

<p><strong>Expected Output</strong>:</p>

<table>
    <tr>
        <td>
            **Z's mean**
        </td>
        <td>
            0.0489952035289
        </td>
    </tr>
    <tr>
        <td>
            **Z[3,2,1]**
        </td>
        <td>
            [-0.61490741 -6.7439236  -2.55153897  1.75698377  3.56208902  0.53036437
  5.18531798  8.75898442]
        </td>
    </tr>
    <tr>
        <td>
            **cache_conv[0][1][2][3]**
        </td>
        <td>
            [-0.20075807  0.18656139  0.41005165]
        </td>
    </tr>

</table>

<h1 id="finally-conv-layer-should-also-contain-an-activation-in-which-case-we-would-add-the-following-line-of-code"><strong>Finally, CONV layer should also contain an activation, in which case we would add the following line of code:</strong></h1>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Convolve the window to get back one output neuron
</span><span class="n">Z</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="p">...</span>
<span class="c1"># Apply activation
</span><span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="n">activation</span><span class="p">(</span><span class="n">Z</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">c</span><span class="p">])</span>
</code></pre></div></div>

<p>You don’t need to do it here.</p>

<h2 id="4---pooling-layer">4 - Pooling layer</h2>

<p>The pooling (POOL) layer reduces the height and width of the input. It helps reduce computation, as well as helps make feature detectors more invariant to its position in the input. The two types of pooling layers are:</p>

<ul>
  <li>
    <p>Max-pooling layer: slides an ($f, f$) window over the input and stores the max value of the window in the output.</p>
  </li>
  <li>
    <p>Average-pooling layer: slides an ($f, f$) window over the input and stores the average value of the window in the output.</p>
  </li>
</ul>

<table>
<td>
<img src="/assets/2023-12-01-convolutional-neural-networks-step-by-step_files/67cccc08-1d30-457c-867b-f685ea713011.png" style="width:500px;height:300px;" />
</td>

<td>
<img src="/assets/2023-12-01-convolutional-neural-networks-step-by-step_files/c68d5db2-b26d-417b-9f69-dad7f2a2293a.png" style="width:500px;height:300px;" />
</td>
</table>

<p><img src="/assets/2023-12-01-convolutional-neural-networks-step-by-step_files/67cccc08-1d30-457c-867b-f685ea713011.png" alt="max_pool1.png" /><img src="/assets/2023-12-01-convolutional-neural-networks-step-by-step_files/c68d5db2-b26d-417b-9f69-dad7f2a2293a.png" alt="ave_pool1.png" /></p>

<p>These pooling layers have no parameters for backpropagation to train. However, they have hyperparameters such as the window size $f$. This specifies the height and width of the fxf window you would compute a max or average over.</p>

<h3 id="41---forward-pooling">4.1 - Forward Pooling</h3>
<p>Now, you are going to implement MAX-POOL and AVG-POOL, in the same function.</p>

<p><strong>Exercise</strong>: Implement the forward pass of the pooling layer. Follow the hints in the comments below.</p>

<p><strong>Reminder</strong>:
As there’s no padding, the formulas binding the output shape of the pooling to the input shape is:
\(n_H = \lfloor \frac{n_{H_{prev}} - f}{stride} \rfloor +1\)
\(n_W = \lfloor \frac{n_{W_{prev}} - f}{stride} \rfloor +1\)
\(n_C = n_{C_{prev}}\)</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># GRADED FUNCTION: pool_forward
</span>
<span class="k">def</span> <span class="nf">pool_forward</span><span class="p">(</span><span class="n">A_prev</span><span class="p">,</span> <span class="n">hparameters</span><span class="p">,</span> <span class="n">mode</span> <span class="o">=</span> <span class="s">"max"</span><span class="p">):</span>
    <span class="s">"""
    Implements the forward pass of the pooling layer
    
    Arguments:
    A_prev -- Input data, numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)
    hparameters -- python dictionary containing "f" and "stride"
    mode -- the pooling mode you would like to use, defined as a string ("max" or "average")
    
    Returns:
    A -- output of the pool layer, a numpy array of shape (m, n_H, n_W, n_C)
    cache -- cache used in the backward pass of the pooling layer, contains the input and hparameters 
    """</span>
    
    <span class="c1"># Retrieve dimensions from the input shape
</span>    <span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">n_H_prev</span><span class="p">,</span> <span class="n">n_W_prev</span><span class="p">,</span> <span class="n">n_C_prev</span><span class="p">)</span> <span class="o">=</span> <span class="n">A_prev</span><span class="p">.</span><span class="n">shape</span>
    
    <span class="c1"># Retrieve hyperparameters from "hparameters"
</span>    <span class="n">f</span> <span class="o">=</span> <span class="n">hparameters</span><span class="p">[</span><span class="s">"f"</span><span class="p">]</span>
    <span class="n">stride</span> <span class="o">=</span> <span class="n">hparameters</span><span class="p">[</span><span class="s">"stride"</span><span class="p">]</span>
    
    <span class="c1"># Define the dimensions of the output
</span>    <span class="n">n_H</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="p">(</span><span class="n">n_H_prev</span> <span class="o">-</span> <span class="n">f</span><span class="p">)</span> <span class="o">/</span> <span class="n">stride</span><span class="p">)</span>
    <span class="n">n_W</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="p">(</span><span class="n">n_W_prev</span> <span class="o">-</span> <span class="n">f</span><span class="p">)</span> <span class="o">/</span> <span class="n">stride</span><span class="p">)</span>
    <span class="n">n_C</span> <span class="o">=</span> <span class="n">n_C_prev</span>
    
    <span class="c1"># Initialize output matrix A
</span>    <span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">m</span><span class="p">,</span> <span class="n">n_H</span><span class="p">,</span> <span class="n">n_W</span><span class="p">,</span> <span class="n">n_C</span><span class="p">))</span>              
    
    <span class="c1">### START CODE HERE ###
</span>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>                         <span class="c1"># loop over the training examples
</span>        <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_H</span><span class="p">):</span>                     <span class="c1"># loop on the vertical axis of the output volume
</span>            <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_W</span><span class="p">):</span>                 <span class="c1"># loop on the horizontal axis of the output volume
</span>                <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">range</span> <span class="p">(</span><span class="n">n_C</span><span class="p">):</span>            <span class="c1"># loop over the channels of the output volume
</span>                    
                    <span class="c1"># Find the corners of the current "slice" (≈4 lines)
</span>                    <span class="n">vert_start</span> <span class="o">=</span> <span class="n">h</span> <span class="o">*</span> <span class="n">stride</span>
                    <span class="n">vert_end</span> <span class="o">=</span> <span class="n">vert_start</span> <span class="o">+</span> <span class="n">f</span>
                    <span class="n">horiz_start</span> <span class="o">=</span> <span class="n">w</span> <span class="o">*</span> <span class="n">stride</span>
                    <span class="n">horiz_end</span> <span class="o">=</span> <span class="n">horiz_start</span> <span class="o">+</span> <span class="n">f</span>
                    
                    <span class="c1"># Use the corners to define the current slice on the ith training example of A_prev, channel c. (≈1 line)
</span>                    <span class="n">a_prev_slice</span> <span class="o">=</span> <span class="n">A_prev</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">vert_start</span><span class="p">:</span><span class="n">vert_end</span><span class="p">,</span> <span class="n">horiz_start</span><span class="p">:</span><span class="n">horiz_end</span><span class="p">,</span> <span class="n">c</span><span class="p">]</span>
                    
                    <span class="c1"># Compute the pooling operation on the slice. Use an if statment to differentiate the modes. Use np.max/np.mean.
</span>                    <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s">"max"</span><span class="p">:</span>
                        <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">max</span><span class="p">(</span><span class="n">a_prev_slice</span><span class="p">)</span>
                    <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s">"average"</span><span class="p">:</span>
                        <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">a_prev_slice</span><span class="p">)</span>
    
    <span class="c1">### END CODE HERE ###
</span>    
    <span class="c1"># Store the input and hparameters in "cache" for pool_backward()
</span>    <span class="n">cache</span> <span class="o">=</span> <span class="p">(</span><span class="n">A_prev</span><span class="p">,</span> <span class="n">hparameters</span><span class="p">)</span>
    
    <span class="c1"># Making sure your output shape is correct
</span>    <span class="k">assert</span><span class="p">(</span><span class="n">A</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">n_H</span><span class="p">,</span> <span class="n">n_W</span><span class="p">,</span> <span class="n">n_C</span><span class="p">))</span>
    
    <span class="k">return</span> <span class="n">A</span><span class="p">,</span> <span class="n">cache</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">A_prev</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">hparameters</span> <span class="o">=</span> <span class="p">{</span><span class="s">"stride"</span> <span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s">"f"</span><span class="p">:</span> <span class="mi">3</span><span class="p">}</span>

<span class="n">A</span><span class="p">,</span> <span class="n">cache</span> <span class="o">=</span> <span class="n">pool_forward</span><span class="p">(</span><span class="n">A_prev</span><span class="p">,</span> <span class="n">hparameters</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"mode = max"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"A ="</span><span class="p">,</span> <span class="n">A</span><span class="p">)</span>
<span class="k">print</span><span class="p">()</span>
<span class="n">A</span><span class="p">,</span> <span class="n">cache</span> <span class="o">=</span> <span class="n">pool_forward</span><span class="p">(</span><span class="n">A_prev</span><span class="p">,</span> <span class="n">hparameters</span><span class="p">,</span> <span class="n">mode</span> <span class="o">=</span> <span class="s">"average"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"mode = average"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"A ="</span><span class="p">,</span> <span class="n">A</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>mode = max
A = [[[[1.74481176 0.86540763 1.13376944]]]


 [[[1.13162939 1.51981682 2.18557541]]]]

mode = average
A = [[[[ 0.02105773 -0.20328806 -0.40389855]]]


 [[[-0.22154621  0.51716526  0.48155844]]]]
</code></pre></div></div>

<p><strong>Expected Output:</strong></p>
<table>
    <tr>
    <td>
    A  =
    </td>
    <td>
         [[[[ 1.74481176  0.86540763  1.13376944]]]
         [[[ 1.13162939  1.51981682  2.18557541]]]]
    </td>
    </tr>
    <tr>
    <td>
    A  =
    </td>
    <td>
         [[[[ 0.02105773 -0.20328806 -0.40389855]]]
         [[[-0.22154621  0.51716526  0.48155844]]]]
    </td>
    </tr>
</table>

<p>Congratulations! You have now implemented the forward passes of all the layers of a convolutional network.</p>

<p>The remainer of this notebook is optional, and will not be graded.</p>

<h2 id="5---backpropagation-in-convolutional-neural-networks-optional--ungraded">5 - Backpropagation in convolutional neural networks (OPTIONAL / UNGRADED)</h2>

<p>In modern deep learning frameworks, you only have to implement the forward pass, and the framework takes care of the backward pass, so most deep learning engineers don’t need to bother with the details of the backward pass. The backward pass for convolutional networks is complicated. If you wish however, you can work through this optional portion of the notebook to get a sense of what backprop in a convolutional network looks like.</p>

<p>When in an earlier course you implemented a simple (fully connected) neural network, you used backpropagation to compute the derivatives with respect to the cost to update the parameters. Similarly, in convolutional neural networks you can to calculate the derivatives with respect to the cost in order to update the parameters. The backprop equations are not trivial and we did not derive them in lecture, but we briefly presented them below.</p>

<h3 id="51---convolutional-layer-backward-pass">5.1 - Convolutional layer backward pass</h3>

<p>Let’s start by implementing the backward pass for a CONV layer.</p>

<p><img src="/assets/2023-12-01-convolutional-neural-networks-step-by-step_files/401809ec-dbb3-47a2-8cc1-972d4d089531.png" alt="image.png" />
<img src="/assets/2023-12-01-convolutional-neural-networks-step-by-step_files/03129698-2f26-478b-9ccf-29663bcc6675.png" alt="image.png" /></p>

<h4 id="511---computing-da--the-previouse-a-the-x-above">5.1.1 - Computing dA – the previouse A, the X above:</h4>
<p>Activation formula like such: 
\(A[m, h, w, c] = activation(Z[m, h, w, c])=activation(conv(X[m, h, w, c],W[f, f, c])+b)\) 
\(Z[m, h, w, c]= \sum_m\sum_n​X(i−m,j−n,c)W(f,f,c)+b,   i,j [0, m-1]\)
This is the formula for computing $dA$ with respect to the cost for a certain filter $W_c$ and a given training example:</p>

\[dA += \sum _{h=0} ^{n_H} \sum_{w=0} ^{n_W} W_c \times dZ_{hw} \tag{1}\]

<p>Where $W_c$ is a filter and $dZ_{hw}$ is a scalar corresponding to the gradient of the cost with respect to the output of the conv layer Z at the hth row and wth column (corresponding to the dot product taken at the ith stride left and jth stride down). <font color="red">**Note that at each time, we multiply the the same filter $W_c$ by a different dZ when updating dA**. We do so mainly because when computing the forward propagation, each filter is dotted and summed by a different a_slice. Therefore when computing the backprop for dA, we are just adding the gradients of all the a_slices. </font></p>

<p>In code, inside the appropriate for-loops, this formula translates into:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">da_prev_pad</span><span class="p">[</span><span class="n">vert_start</span><span class="p">:</span><span class="n">vert_end</span><span class="p">,</span> <span class="n">horiz_start</span><span class="p">:</span><span class="n">horiz_end</span><span class="p">,</span> <span class="p">:]</span> <span class="o">+=</span> <span class="n">W</span><span class="p">[:,:,:,</span><span class="n">c</span><span class="p">]</span> <span class="o">*</span> <span class="n">dZ</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">c</span><span class="p">]</span>
</code></pre></div></div>

<h4 id="512---computing-dw">5.1.2 - Computing dW:</h4>
<p>This is the formula for computing $dW_c$ ($dW_c$ is the derivative of one filter) with respect to the loss:</p>

\[dW_c  += \sum _{h=0} ^{n_H} \sum_{w=0} ^ {n_W} a_{slice} \times dZ_{hw}  \tag{2}\]

<p>Where $a_{slice}$ corresponds to the slice which was used to generate the acitivation $Z_{ij}$. Hence, this ends up giving us the gradient for $W$ with respect to that slice. Since it is the same $W$, we will just add up all such gradients to get $dW$.</p>

<p>In code, inside the appropriate for-loops, this formula translates into:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">dW</span><span class="p">[:,:,:,</span><span class="n">c</span><span class="p">]</span> <span class="o">+=</span> <span class="n">a_slice</span> <span class="o">*</span> <span class="n">dZ</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">c</span><span class="p">]</span>
</code></pre></div></div>

<h4 id="513---computing-db">5.1.3 - Computing db:</h4>

<p>This is the formula for computing $db$ with respect to the cost for a certain filter $W_c$:</p>

\[db = \sum_h \sum_w dZ_{hw} \tag{3}\]

<p>As you have previously seen in basic neural networks, db is computed by summing $dZ$. In this case, you are just summing over all the gradients of the conv output (Z) with respect to the cost.</p>

<p>In code, inside the appropriate for-loops, this formula translates into:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">db</span><span class="p">[:,:,:,</span><span class="n">c</span><span class="p">]</span> <span class="o">+=</span> <span class="n">dZ</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">c</span><span class="p">]</span>
</code></pre></div></div>

<p><strong>Exercise</strong>: Implement the <code class="language-plaintext highlighter-rouge">conv_backward</code> function below. You should sum over all the training examples, filters, heights, and widths. You should then compute the derivatives using formulas 1, 2 and 3 above.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">conv_backward</span><span class="p">(</span><span class="n">dZ</span><span class="p">,</span> <span class="n">cache</span><span class="p">):</span>
    <span class="s">"""
    Implement the backward propagation for a convolution function
    
    Arguments:
    dZ -- gradient of the cost with respect to the output of the conv layer (Z), numpy array of shape (m, n_H, n_W, n_C)
    cache -- cache of values needed for the conv_backward(), output of conv_forward()
    
    Returns:
    dA_prev -- gradient of the cost with respect to the input of the conv layer (A_prev),
               numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)
    dW -- gradient of the cost with respect to the weights of the conv layer (W)
          numpy array of shape (f, f, n_C_prev, n_C)
    db -- gradient of the cost with respect to the biases of the conv layer (b)
          numpy array of shape (1, 1, 1, n_C)
    """</span>
    
    <span class="c1">### START CODE HERE ###
</span>    <span class="c1"># Retrieve information from "cache"
</span>    <span class="p">(</span><span class="n">A_prev</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">hparameters</span><span class="p">)</span> <span class="o">=</span> <span class="n">cache</span>
    
    <span class="c1"># Retrieve dimensions from A_prev's shape
</span>    <span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">n_H_prev</span><span class="p">,</span> <span class="n">n_W_prev</span><span class="p">,</span> <span class="n">n_C_prev</span><span class="p">)</span> <span class="o">=</span> <span class="n">A_prev</span><span class="p">.</span><span class="n">shape</span>
    
    <span class="c1"># Retrieve dimensions from W's shape
</span>    <span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">n_C_prev</span><span class="p">,</span> <span class="n">n_C</span><span class="p">)</span> <span class="o">=</span> <span class="n">W</span><span class="p">.</span><span class="n">shape</span>
    
    <span class="c1"># Retrieve information from "hparameters"
</span>    <span class="n">stride</span> <span class="o">=</span> <span class="n">hparameters</span><span class="p">[</span><span class="s">'stride'</span><span class="p">]</span>
    <span class="n">pad</span> <span class="o">=</span> <span class="n">hparameters</span><span class="p">[</span><span class="s">'pad'</span><span class="p">]</span>
    
    <span class="c1"># Retrieve dimensions from dZ's shape
</span>    <span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">n_H</span><span class="p">,</span> <span class="n">n_W</span><span class="p">,</span> <span class="n">n_C</span><span class="p">)</span> <span class="o">=</span> <span class="n">dZ</span><span class="p">.</span><span class="n">shape</span>
    
    <span class="c1"># Initialize dA_prev, dW, db with the correct shapes
</span>    <span class="n">dA_prev</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">m</span><span class="p">,</span> <span class="n">n_H_prev</span><span class="p">,</span> <span class="n">n_W_prev</span><span class="p">,</span> <span class="n">n_C_prev</span><span class="p">))</span>         
    <span class="n">dW</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">f</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">n_C_prev</span><span class="p">,</span> <span class="n">n_C</span><span class="p">))</span>
    <span class="n">db</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n_C</span><span class="p">))</span>

    <span class="c1"># Pad A_prev and dA_prev
</span>    <span class="n">A_prev_pad</span> <span class="o">=</span> <span class="n">zero_pad</span><span class="p">(</span><span class="n">A_prev</span><span class="p">,</span> <span class="n">pad</span><span class="p">)</span>
    <span class="n">dA_prev_pad</span> <span class="o">=</span> <span class="n">zero_pad</span><span class="p">(</span><span class="n">dA_prev</span><span class="p">,</span> <span class="n">pad</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>                       <span class="c1"># loop over the training examples #how to elimiated this loop???
</span>        
        <span class="c1"># select ith training example from A_prev_pad and dA_prev_pad
</span>        <span class="n">a_prev_pad</span> <span class="o">=</span> <span class="n">A_prev_pad</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">da_prev_pad</span> <span class="o">=</span> <span class="n">dA_prev_pad</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        
        <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_H</span><span class="p">):</span>                   <span class="c1"># loop over vertical axis of the output volume
</span>            <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_W</span><span class="p">):</span>               <span class="c1"># loop over horizontal axis of the output volume
</span>                <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_C</span><span class="p">):</span>           <span class="c1"># loop over the channels of the output volume
</span>                    
                    <span class="c1"># Find the corners of the current "slice"
</span>                    <span class="n">vert_start</span> <span class="o">=</span> <span class="n">h</span> <span class="o">*</span> <span class="n">stride</span>
                    <span class="n">vert_end</span> <span class="o">=</span> <span class="n">vert_start</span> <span class="o">+</span> <span class="n">f</span>
                    <span class="n">horiz_start</span> <span class="o">=</span> <span class="n">w</span> <span class="o">*</span> <span class="n">stride</span>
                    <span class="n">horiz_end</span> <span class="o">=</span> <span class="n">horiz_start</span> <span class="o">+</span> <span class="n">f</span>
                    
                    <span class="c1"># Use the corners to define the slice from a_prev_pad
</span>                    <span class="n">a_slice</span> <span class="o">=</span> <span class="n">a_prev_pad</span><span class="p">[</span><span class="n">vert_start</span><span class="p">:</span><span class="n">vert_end</span><span class="p">,</span> <span class="n">horiz_start</span><span class="p">:</span><span class="n">horiz_end</span><span class="p">,</span> <span class="p">:]</span>

                    <span class="c1"># Update gradients for the window and the filter's parameters using the code formulas given above
</span>                    <span class="n">da_prev_pad</span><span class="p">[</span><span class="n">vert_start</span><span class="p">:</span><span class="n">vert_end</span><span class="p">,</span> <span class="n">horiz_start</span><span class="p">:</span><span class="n">horiz_end</span><span class="p">,</span> <span class="p">:]</span> <span class="o">+=</span> <span class="n">W</span><span class="p">[:,:,:,</span><span class="n">c</span><span class="p">]</span> <span class="o">*</span> <span class="n">dZ</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">h</span><span class="p">,</span><span class="n">w</span><span class="p">,</span><span class="n">c</span><span class="p">]</span>
                    <span class="n">dW</span><span class="p">[:,:,:,</span><span class="n">c</span><span class="p">]</span> <span class="o">+=</span> <span class="n">a_slice</span> <span class="o">*</span> <span class="n">dZ</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">h</span><span class="p">,</span><span class="n">w</span><span class="p">,</span><span class="n">c</span><span class="p">]</span>
                    <span class="n">db</span><span class="p">[:,:,:,</span><span class="n">c</span><span class="p">]</span> <span class="o">+=</span> <span class="n">dZ</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">h</span><span class="p">,</span><span class="n">w</span><span class="p">,</span><span class="n">c</span><span class="p">]</span>
                    
        <span class="c1"># Set the ith training example's dA_prev to the unpaded da_prev_pad (Hint: use X[pad:-pad, pad:-pad, :])
</span>        <span class="n">dA_prev</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">da_prev_pad</span><span class="p">[</span><span class="n">pad</span><span class="p">:</span><span class="o">-</span><span class="n">pad</span><span class="p">,</span> <span class="n">pad</span><span class="p">:</span><span class="o">-</span><span class="n">pad</span><span class="p">,</span> <span class="p">:]</span>
    <span class="c1">### END CODE HERE ###
</span>    
    <span class="c1"># Making sure your output shape is correct
</span>    <span class="k">assert</span><span class="p">(</span><span class="n">dA_prev</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">n_H_prev</span><span class="p">,</span> <span class="n">n_W_prev</span><span class="p">,</span> <span class="n">n_C_prev</span><span class="p">))</span>
    
    <span class="k">return</span> <span class="n">dA_prev</span><span class="p">,</span> <span class="n">dW</span><span class="p">,</span> <span class="n">db</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">dA</span><span class="p">,</span> <span class="n">dW</span><span class="p">,</span> <span class="n">db</span> <span class="o">=</span> <span class="n">conv_backward</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">cache_conv</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"dA_mean ="</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dA</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">"dW_mean ="</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dW</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">"db_mean ="</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">db</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>dA_mean = 1.4524377775388075
dW_mean = 1.7269914583139097
db_mean = 7.839232564616838
</code></pre></div></div>

<p>** Expected Output: **</p>
<table>
    <tr>
        <td>
            **dA_mean**
        </td>
        <td>
            1.45243777754
        </td>
    </tr>
    <tr>
        <td>
            **dW_mean**
        </td>
        <td>
            1.72699145831
        </td>
    </tr>
    <tr>
        <td>
            **db_mean**
        </td>
        <td>
            7.83923256462
        </td>
    </tr>

</table>

<h2 id="52-pooling-layer---backward-pass">5.2 Pooling layer - backward pass</h2>

<p>Next, let’s implement the backward pass for the pooling layer, starting with the MAX-POOL layer. Even though a pooling layer has no parameters for backprop to update, you still need to backpropagation the gradient through the pooling layer in order to compute gradients for layers that came before the pooling layer.</p>

<h3 id="521-max-pooling---backward-pass">5.2.1 Max pooling - backward pass</h3>

<p>Before jumping into the backpropagation of the pooling layer, you are going to build a helper function called <code class="language-plaintext highlighter-rouge">create_mask_from_window()</code> which does the following:</p>

\[X = \begin{bmatrix}
1 &amp;&amp; 3 \\
4 &amp;&amp; 2
\end{bmatrix} \quad \rightarrow  \quad M =\begin{bmatrix}
0 &amp;&amp; 0 \\
1 &amp;&amp; 0
\end{bmatrix}\tag{4}\]

<p>As you can see, this function creates a “mask” matrix which keeps track of where the maximum of the matrix is. True (1) indicates the position of the maximum in X, the other entries are False (0). You’ll see later that the backward pass for average pooling will be similar to this but using a different mask.</p>

<p><strong>Exercise</strong>: Implement <code class="language-plaintext highlighter-rouge">create_mask_from_window()</code>. This function will be helpful for pooling backward. 
Hints:</p>
<ul>
  <li><a href="">np.max()</a> may be helpful. It computes the maximum of an array.</li>
  <li>If you have a matrix X and a scalar x: <code class="language-plaintext highlighter-rouge">A = (X == x)</code> will return a matrix A of the same size as X such that:
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>A[i,j] = True if X[i,j] = x
A[i,j] = False if X[i,j] != x
</code></pre></div>    </div>
  </li>
  <li>Here, you don’t need to consider cases where there are several maxima in a matrix.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">create_mask_from_window</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="s">"""
    Creates a mask from an input matrix x, to identify the max entry of x.
    
    Arguments:
    x -- Array of shape (f, f)
    
    Returns:
    mask -- Array of the same shape as window, contains a True at the position corresponding to the max entry of x.
    """</span>
    
    <span class="c1">### START CODE HERE ### (≈1 line)
</span>    <span class="n">mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">==</span> <span class="n">np</span><span class="p">.</span><span class="nb">max</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    <span class="c1">### END CODE HERE ###
</span>    
    <span class="k">return</span> <span class="n">mask</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="n">mask</span> <span class="o">=</span> <span class="n">create_mask_from_window</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'x = '</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"mask = "</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>x =  [[ 1.62434536 -0.61175641 -0.52817175]
 [-1.07296862  0.86540763 -2.3015387 ]]
mask =  [[ True False False]
 [False False False]]
</code></pre></div></div>

<p><strong>Expected Output:</strong></p>

<table> 
<tr> 
<td>

**x =**
</td>

<td>

[[ 1.62434536 -0.61175641 -0.52817175] <br />
 [-1.07296862  0.86540763 -2.3015387 ]]

  </td>
</tr>

<tr> 
<td>
**mask =**
</td>
<td>
[[ True False False] <br />
 [False False False]]
</td>
</tr>


</table>

<font size="3">**Why do we keep track of the position of the max? It's because this is the input value that ultimately influenced the output, and therefore the cost. Backprop is computing gradients with respect to the cost, so anything that influences the ultimate cost should have a non-zero gradient. So, backprop will "propagate" the gradient back to this particular input value that had influenced the cost**. </font>

<h3 id="522---average-pooling---backward-pass">5.2.2 - Average pooling - backward pass</h3>

<p>In max pooling, for each input window, all the “influence” on the output came from a single input value–the max. In average pooling, every element of the input window has equal influence on the output. So to implement backprop, you will now implement a helper function that reflects this.</p>

<p>For example if we did average pooling in the forward pass using a 2x2 filter, then the mask you’ll use for the backward pass will look like: 
\(dZ = 1 \quad \rightarrow  \quad dZ =\begin{bmatrix}
1/4 &amp;&amp; 1/4 \\
1/4 &amp;&amp; 1/4
\end{bmatrix}\tag{5}\)</p>

<p>This implies that each position in the $dZ$ matrix contributes equally to output because in the forward pass, we took an average.</p>

<p><strong>Exercise</strong>: Implement the function below to equally distribute a value dz through a matrix of dimension shape. <a href="https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.ones.html">Hint</a></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">distribute_value</span><span class="p">(</span><span class="n">dz</span><span class="p">,</span> <span class="n">shape</span><span class="p">):</span>
    <span class="s">"""
    Distributes the input value in the matrix of dimension shape
    
    Arguments:
    dz -- input scalar
    shape -- the shape (n_H, n_W) of the output matrix for which we want to distribute the value of dz
    
    Returns:
    a -- Array of size (n_H, n_W) for which we distributed the value of dz
    """</span>
    
    <span class="c1">### START CODE HERE ###
</span>    <span class="c1"># Retrieve dimensions from shape (≈1 line)
</span>    <span class="p">(</span><span class="n">n_H</span><span class="p">,</span> <span class="n">n_W</span><span class="p">)</span> <span class="o">=</span> <span class="n">shape</span>
    
    <span class="c1"># Compute the value to distribute on the matrix (≈1 line)
</span>    <span class="c1"># I think it should be n_h*n_w instead of n_h+nw, right?2
</span>    <span class="n">average</span> <span class="o">=</span> <span class="n">dz</span> <span class="o">/</span> <span class="p">(</span><span class="n">n_H</span> <span class="o">*</span> <span class="n">n_W</span><span class="p">)</span>
    
    <span class="c1"># Create a matrix where every entry is the "average" value (≈1 line)
</span>    <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="o">*</span> <span class="n">average</span>
    <span class="c1">### END CODE HERE ###
</span>    
    <span class="k">return</span> <span class="n">a</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">a</span> <span class="o">=</span> <span class="n">distribute_value</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'distributed value ='</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>distributed value = [[0.5 0.5]
 [0.5 0.5]]
</code></pre></div></div>

<p><strong>Expected Output</strong>:</p>

<table> 
<tr> 
<td>
distributed_value =
</td>
<td>
[[ 0.5  0.5]
&lt;br\&gt; 
[ 0.5  0.5]]
</td>
</tr>
</table>

<h3 id="523-putting-it-together-pooling-backward">5.2.3 Putting it together: Pooling backward</h3>

<p>You now have everything you need to compute backward propagation on a pooling layer.</p>

<p><strong>Exercise</strong>: Implement the <code class="language-plaintext highlighter-rouge">pool_backward</code> function in both modes (<code class="language-plaintext highlighter-rouge">"max"</code> and <code class="language-plaintext highlighter-rouge">"average"</code>). You will once again use 4 for-loops (iterating over training examples, height, width, and channels). You should use an <code class="language-plaintext highlighter-rouge">if/elif</code> statement to see if the mode is equal to <code class="language-plaintext highlighter-rouge">'max'</code> or <code class="language-plaintext highlighter-rouge">'average'</code>. If it is equal to ‘average’ you should use the <code class="language-plaintext highlighter-rouge">distribute_value()</code> function you implemented above to create a matrix of the same shape as <code class="language-plaintext highlighter-rouge">a_slice</code>. Otherwise, the mode is equal to ‘<code class="language-plaintext highlighter-rouge">max</code>’, and you will create a mask with <code class="language-plaintext highlighter-rouge">create_mask_from_window()</code> and multiply it by the corresponding value of dZ.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">pool_backward</span><span class="p">(</span><span class="n">dA</span><span class="p">,</span> <span class="n">cache</span><span class="p">,</span> <span class="n">mode</span> <span class="o">=</span> <span class="s">"max"</span><span class="p">):</span>
    <span class="s">"""
    Implements the backward pass of the pooling layer
    
    Arguments:
    dA -- gradient of cost with respect to the output of the pooling layer, same shape as A
    cache -- cache output from the forward pass of the pooling layer, contains the layer's input and hparameters 
    mode -- the pooling mode you would like to use, defined as a string ("max" or "average")
    
    Returns:
    dA_prev -- gradient of cost with respect to the input of the pooling layer, same shape as A_prev
    """</span>
    
    <span class="c1">### START CODE HERE ###
</span>    
    <span class="c1"># Retrieve information from cache (≈1 line)
</span>    <span class="p">(</span><span class="n">A_prev</span><span class="p">,</span> <span class="n">hparameters</span><span class="p">)</span> <span class="o">=</span> <span class="n">cache</span>
    
    <span class="c1"># Retrieve hyperparameters from "hparameters" (≈2 lines)
</span>    <span class="n">stride</span> <span class="o">=</span> <span class="n">hparameters</span><span class="p">[</span><span class="s">'stride'</span><span class="p">]</span>
    <span class="n">f</span> <span class="o">=</span> <span class="n">hparameters</span><span class="p">[</span><span class="s">'f'</span><span class="p">]</span>
    
    <span class="c1"># Retrieve dimensions from A_prev's shape and dA's shape (≈2 lines)
</span>    <span class="n">m</span><span class="p">,</span> <span class="n">n_H_prev</span><span class="p">,</span> <span class="n">n_W_prev</span><span class="p">,</span> <span class="n">n_C_prev</span> <span class="o">=</span> <span class="n">A_prev</span><span class="p">.</span><span class="n">shape</span>
    <span class="n">m</span><span class="p">,</span> <span class="n">n_H</span><span class="p">,</span> <span class="n">n_W</span><span class="p">,</span> <span class="n">n_C</span> <span class="o">=</span> <span class="n">dA</span><span class="p">.</span><span class="n">shape</span>
    
    <span class="c1"># Initialize dA_prev with zeros (≈1 line)
</span>    <span class="n">dA_prev</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span> <span class="o">=</span> <span class="n">A_prev</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>                       <span class="c1"># loop over the training examples
</span>        
        <span class="c1"># select training example from A_prev (≈1 line)
</span>        <span class="n">a_prev</span> <span class="o">=</span> <span class="n">A_prev</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        
        <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_H</span><span class="p">):</span>                   <span class="c1"># loop on the vertical axis
</span>            <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_W</span><span class="p">):</span>               <span class="c1"># loop on the horizontal axis
</span>                <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_C</span><span class="p">):</span>           <span class="c1"># loop over the channels (depth)
</span>                    
                    <span class="c1"># Find the corners of the current "slice" (≈4 lines)
</span>                    <span class="n">vert_start</span> <span class="o">=</span> <span class="n">h</span> <span class="o">*</span> <span class="n">stride</span>
                    <span class="n">vert_end</span> <span class="o">=</span> <span class="n">vert_start</span> <span class="o">+</span> <span class="n">f</span>
                    <span class="n">horiz_start</span> <span class="o">=</span> <span class="n">w</span> <span class="o">*</span> <span class="n">stride</span>
                    <span class="n">horiz_end</span> <span class="o">=</span> <span class="n">horiz_start</span> <span class="o">+</span> <span class="n">f</span>
                    
                    <span class="c1"># Compute the backward propagation in both modes.
</span>                    <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s">"max"</span><span class="p">:</span>
                        
                        <span class="c1"># Use the corners and "c" to define the current slice from a_prev (≈1 line)
</span>                        <span class="n">a_prev_slice</span> <span class="o">=</span> <span class="n">a_prev</span><span class="p">[</span><span class="n">vert_start</span><span class="p">:</span><span class="n">vert_end</span><span class="p">,</span> <span class="n">horiz_start</span><span class="p">:</span><span class="n">horiz_end</span><span class="p">,</span> <span class="n">c</span><span class="p">]</span>
                        <span class="c1"># Create the mask from a_prev_slice (≈1 line)
</span>                        <span class="n">mask</span> <span class="o">=</span> <span class="n">create_mask_from_window</span><span class="p">(</span><span class="n">a_prev_slice</span><span class="p">)</span>
                        <span class="c1"># Set dA_prev to be dA_prev + (the mask multiplied by the correct entry of dA) (≈1 line)
</span>                        <span class="n">dA_prev</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">vert_start</span><span class="p">:</span> <span class="n">vert_end</span><span class="p">,</span> <span class="n">horiz_start</span><span class="p">:</span> <span class="n">horiz_end</span><span class="p">,</span> <span class="n">c</span><span class="p">]</span> <span class="o">+=</span> <span class="n">np</span><span class="p">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">dA</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">h</span><span class="p">,</span><span class="n">w</span><span class="p">,</span><span class="n">c</span><span class="p">])</span>
                        
                    <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s">"average"</span><span class="p">:</span>
                        
                        <span class="c1"># Get the value a from dA (≈1 line)
</span>                        <span class="n">da</span> <span class="o">=</span> <span class="n">dA</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">h</span><span class="p">,</span><span class="n">w</span><span class="p">,</span><span class="n">c</span><span class="p">]</span>
                        <span class="c1"># Define the shape of the filter as fxf (≈1 line)
</span>                        <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">f</span><span class="p">,</span><span class="n">f</span><span class="p">)</span>
                        <span class="c1"># Distribute it to get the correct slice of dA_prev. i.e. Add the distributed value of da. (≈1 line)
</span>                        <span class="n">dA_prev</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">vert_start</span><span class="p">:</span> <span class="n">vert_end</span><span class="p">,</span> <span class="n">horiz_start</span><span class="p">:</span> <span class="n">horiz_end</span><span class="p">,</span> <span class="n">c</span><span class="p">]</span> <span class="o">+=</span> <span class="n">distribute_value</span><span class="p">(</span><span class="n">da</span><span class="p">,</span> <span class="n">shape</span><span class="p">)</span>
                        
    <span class="c1">### END CODE ###
</span>    
    <span class="c1"># Making sure your output shape is correct
</span>    <span class="k">assert</span><span class="p">(</span><span class="n">dA_prev</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">A_prev</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">dA_prev</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">A_prev</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">hparameters</span> <span class="o">=</span> <span class="p">{</span><span class="s">"stride"</span> <span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s">"f"</span><span class="p">:</span> <span class="mi">2</span><span class="p">}</span>
<span class="n">A</span><span class="p">,</span> <span class="n">cache</span> <span class="o">=</span> <span class="n">pool_forward</span><span class="p">(</span><span class="n">A_prev</span><span class="p">,</span> <span class="n">hparameters</span><span class="p">)</span>
<span class="n">dA</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

<span class="n">dA_prev</span> <span class="o">=</span> <span class="n">pool_backward</span><span class="p">(</span><span class="n">dA</span><span class="p">,</span> <span class="n">cache</span><span class="p">,</span> <span class="n">mode</span> <span class="o">=</span> <span class="s">"max"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"mode = max"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'mean of dA = '</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dA</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'dA_prev[1,1] = '</span><span class="p">,</span> <span class="n">dA_prev</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>  
<span class="k">print</span><span class="p">()</span>
<span class="n">dA_prev</span> <span class="o">=</span> <span class="n">pool_backward</span><span class="p">(</span><span class="n">dA</span><span class="p">,</span> <span class="n">cache</span><span class="p">,</span> <span class="n">mode</span> <span class="o">=</span> <span class="s">"average"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"mode = average"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'mean of dA = '</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dA</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'dA_prev[1,1] = '</span><span class="p">,</span> <span class="n">dA_prev</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span> 
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>mode = max
mean of dA =  0.14571390272918056
dA_prev[1,1] =  [[ 0.          0.        ]
 [ 5.05844394 -1.68282702]
 [ 0.          0.        ]]

mode = average
mean of dA =  0.14571390272918056
dA_prev[1,1] =  [[ 0.08485462  0.2787552 ]
 [ 1.26461098 -0.25749373]
 [ 1.17975636 -0.53624893]]
</code></pre></div></div>

<p><strong>Expected Output</strong>:</p>

<p>mode = max:</p>
<table> 
<tr> 
<td>

**mean of dA =**
</td>

<td>

0.145713902729

  </td>
</tr>

<tr> 
<td>
**dA_prev[1,1] =** 
</td>
<td>
[[ 0.          0.        ] <br />
 [ 5.05844394 -1.68282702] <br />
 [ 0.          0.        ]]
</td>
</tr>
</table>

<p>mode = average</p>
<table> 
<tr> 
<td>

**mean of dA =**
</td>

<td>

0.145713902729

  </td>
</tr>

<tr> 
<td>
**dA_prev[1,1] =** 
</td>
<td>
[[ 0.08485462  0.2787552 ] <br />
 [ 1.26461098 -0.25749373] <br />
 [ 1.17975636 -0.53624893]]
</td>
</tr>
</table>

<h3 id="congratulations-">Congratulations !</h3>

<p>Congratulation on completing this assignment. You now understand how convolutional neural networks work. You have implemented all the building blocks of a neural network. In the next assignment you will implement a ConvNet using TensorFlow.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
</code></pre></div></div>]]></content><author><name>Zhu Tianda</name></author><category term="coding" /><category term="AI" /><category term="CNN" /><summary type="html"><![CDATA[卷积的数学表示 \(f∗g(n)=∫_{−∞}^{+∞}​f(τ)g(n−τ)dτ\) 上面公式是连续的定义，再看看离散的定义：]]></summary></entry><entry><title type="html">working todo</title><link href="http://0.0.0.0:8855/working/2023/12/01/My-Tasks-and-Notes.html" rel="alternate" type="text/html" title="working todo" /><published>2023-12-01T00:00:00+08:00</published><updated>2023-12-01T00:00:00+08:00</updated><id>http://0.0.0.0:8855/working/2023/12/01/My-Tasks-and-Notes</id><content type="html" xml:base="http://0.0.0.0:8855/working/2023/12/01/My-Tasks-and-Notes.html"><![CDATA[<p>#todo</p>
<ul class="task-list">
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" checked="checked" />#task compare the nougat small model and code with the nougat big model what’s the different between them.  🔼 🛫 2024-01-09 : ✅ 2024-01-21</li>
  <li class="task-list-item">transformer version change to  4.34.1, then it work (static saving safe is in newer version)</li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" />#task based work output of above task let’s partially loading the Chinese Bart pre-trained model data 🔼 🛫 2024-01-09</li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" checked="checked" />prepare one small set dataset include Chinese data for training 🔼 🛫 2024-01-09 ✅ 2024-01-21</li>
  <li class="task-list-item">small set dataset — nougat-dataset-test include - ocrpadded, ocrset</li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" />adding authentication function to android and pc side client. let’s start this after Chinese supporting in server side.</li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" />adding authentication and security function to server side. let’s start this after Chinese supporting in server side.</li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" />today’s work 📅 2024-01-11 , ⏫  try to modify the ocr padding method to scale the ocr png to size fit  swin-transformer , then padding.  I suspect the training error is caused by too small png 🛫 padding.  current size is 672(w)x896(h)x8.. arxiv size is 816x1056x24.. something wrong.</li>
  <li class="task-list-item">notice that the orignal code has the resize function to make the small picture to fit the 886*672 size , so using the original un-padding figure (latex ocr dataset image) to feed the current training. but still have the “repetition error”</li>
  <li class="task-list-item">put the original un-padding figure  and the padded figure together into the training , it seems that the training have no “repetition error” still unclear why it is so????
    <ul>
      <li>this have the repetition error… while using bigger dataset from arXiv orignal data</li>
      <li>I am think the VIT how to train the all blank image… it is lead to some error , or how it is treated , get some test ???</li>
      <li>how about using all back or white image as training data</li>
      <li>how the voice to text treat the white noise? how the blank image is treated</li>
      <li>in normal ViT , the fixed size image is always required…,   how about reserve the SWIN transformer architecture, change from low level resolution to high resolution</li>
    </ul>
  </li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" checked="checked" />bleu score ✅ 2024-01-12, the bleu score is noted at [[Transformer_learning#3.2 Bleu Score]]</li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" />Pytorch-view的用法</li>
  <li class="task-list-item">在pytorch中view函数的作用为重构张量的维度，相当于numpy中resize（）的功能，但是用法可能不太一样。如下例所示</li>
</ul>

<div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt;&gt; import torch
&gt;&gt;&gt; tt1=torch.tensor([-0.3623, -0.6115,  0.7283,  0.4699,  2.3261,  0.1599])
&gt;&gt;&gt; result=tt1.view(3,2)
&gt;&gt;&gt; result
tensor([[-0.3623, -0.6115],
        [ 0.7283,  0.4699],
        [ 2.3261,  0.1599]])
</code></pre></div></div>

<ol>
  <li>torch.view(参数a，参数b，…)</li>
</ol>

<p>在上面例子中参数a=3和参数b=2决定了将一维的tt1重构成3x2维的张量。</p>

<ol>
  <li>有的时候会出现torch.view(-1)或者torch.view(参数a，-1)这种情况。
    <div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt;&gt; import torch
&gt;&gt;&gt; tt2=torch.tensor([[-0.3623, -0.6115],
...         [ 0.7283,  0.4699],
...         [ 2.3261,  0.1599]])
&gt;&gt;&gt; result=tt2.view(-1)
&gt;&gt;&gt; result
tensor([-0.3623, -0.6115,  0.7283,  0.4699,  2.3261,  0.1599])
</code></pre></div>    </div>
    <p>由上面的案例可以看到，如果是torch.view(-1)，则原张量会变成一维的结构。</p>
    <div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt;&gt; import torch
&gt;&gt;&gt; tt3=torch.tensor([[-0.3623, -0.6115],
...         [ 0.7283,  0.4699],
...         [ 2.3261,  0.1599]])
&gt;&gt;&gt; result=tt3.view(2,-1)
&gt;&gt;&gt; result
tensor([[-0.3623, -0.6115,  0.7283],
     [ 0.4699,  2.3261,  0.1599]])
</code></pre></div>    </div>
  </li>
</ol>

<p>由上面的案例可以看到，如果是torch.view(参数a，-1)，则表示在参数b未知，参数a已知的情况下自动补齐列向量长度，在这个例子中a=2，tt3总共由6个元素，则b=6/2=3。</p>]]></content><author><name>Zhu Tianda</name></author><category term="working" /><category term="AI" /><summary type="html"><![CDATA[#todo #task compare the nougat small model and code with the nougat big model what’s the different between them. 🔼 🛫 2024-01-09 : ✅ 2024-01-21 transformer version change to 4.34.1, then it work (static saving safe is in newer version) #task based work output of above task let’s partially loading the Chinese Bart pre-trained model data 🔼 🛫 2024-01-09 prepare one small set dataset include Chinese data for training 🔼 🛫 2024-01-09 ✅ 2024-01-21 small set dataset — nougat-dataset-test include - ocrpadded, ocrset adding authentication function to android and pc side client. let’s start this after Chinese supporting in server side. adding authentication and security function to server side. let’s start this after Chinese supporting in server side. today’s work 📅 2024-01-11 , ⏫ try to modify the ocr padding method to scale the ocr png to size fit swin-transformer , then padding. I suspect the training error is caused by too small png 🛫 padding. current size is 672(w)x896(h)x8.. arxiv size is 816x1056x24.. something wrong. notice that the orignal code has the resize function to make the small picture to fit the 886*672 size , so using the original un-padding figure (latex ocr dataset image) to feed the current training. but still have the “repetition error” put the original un-padding figure and the padded figure together into the training , it seems that the training have no “repetition error” still unclear why it is so???? this have the repetition error… while using bigger dataset from arXiv orignal data I am think the VIT how to train the all blank image… it is lead to some error , or how it is treated , get some test ??? how about using all back or white image as training data how the voice to text treat the white noise? how the blank image is treated in normal ViT , the fixed size image is always required…, how about reserve the SWIN transformer architecture, change from low level resolution to high resolution bleu score ✅ 2024-01-12, the bleu score is noted at [[Transformer_learning#3.2 Bleu Score]] Pytorch-view的用法 在pytorch中view函数的作用为重构张量的维度，相当于numpy中resize（）的功能，但是用法可能不太一样。如下例所示]]></summary></entry><entry><title type="html">Transformer Network</title><link href="http://0.0.0.0:8855/coding/2023/11/26/Transformer-learning-C5W4A1SubclassV1.html" rel="alternate" type="text/html" title="Transformer Network" /><published>2023-11-26T00:00:00+08:00</published><updated>2023-11-26T00:00:00+08:00</updated><id>http://0.0.0.0:8855/coding/2023/11/26/Transformer-learning-C5W4A1SubclassV1</id><content type="html" xml:base="http://0.0.0.0:8855/coding/2023/11/26/Transformer-learning-C5W4A1SubclassV1.html"><![CDATA[<p>I update this document also refere to</p>
<ol>
  <li>https://www.tensorflow.org/tutorials/text/transformer?hl=zh-cn</li>
  <li>https://nlp.seas.harvard.edu/2018/04/03/attention.html#positional-encoding</li>
</ol>

<h1 id="transformer-network">Transformer Network</h1>

<p>Welcome to Week 4’s assignment, the last assignment of Course 5 of the Deep Learning Specialization! And congratulations on making it to the last assignment of the entire Deep Learning Specialization - you’re almost done!</p>

<p>Ealier in the course, you’ve implemented sequential neural networks such as RNNs, GRUs, and LSTMs. In this notebook you’ll explore the Transformer architecture, a neural network that takes advantage of parallel processing and allows you to substantially speed up the training process.</p>

<p><strong>After this assignment you’ll be able to</strong>:</p>

<ul>
  <li>Create positional encodings to capture sequential relationships in data</li>
  <li>Calculate scaled dot-product self-attention with word embeddings</li>
  <li>Implement masked multi-head attention</li>
  <li>Build and train a Transformer model</li>
</ul>

<p>For the last time, let’s get started!</p>

<h2 id="table-of-contents">Table of Contents</h2>

<ul>
  <li><a href="#0">Packages</a></li>
  <li><a href="#1">1 - Positional Encoding</a>
    <ul>
      <li><a href="#1-1">1.1 - Sine and Cosine Angles</a>
        <ul>
          <li><a href="#ex-1">Exercise 1 - get_angles</a></li>
        </ul>
      </li>
      <li><a href="#1-2">1.2 - Sine and Cosine Positional Encodings</a>
        <ul>
          <li><a href="#ex-2">Exercise 2 - positional_encoding</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#2">2 - Masking</a>
    <ul>
      <li><a href="#2-1">2.1 - Padding Mask</a></li>
      <li><a href="#2-2">2.2 - Look-ahead Mask</a></li>
    </ul>
  </li>
  <li><a href="#3">3 - Self-Attention</a>
    <ul>
      <li><a href="#ex-3">Exercise 3 - scaled_dot_product_attention</a></li>
    </ul>
  </li>
  <li><a href="#4">4 - Encoder</a>
    <ul>
      <li><a href="#4-1">4.1 Encoder Layer</a>
        <ul>
          <li><a href="#ex-4">Exercise 4 - EncoderLayer</a></li>
        </ul>
      </li>
      <li><a href="#4-2">4.2 - Full Encoder</a>
        <ul>
          <li><a href="#ex-5">Exercise 5 - Encoder</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#5">5 - Decoder</a>
    <ul>
      <li><a href="#5-1">5.1 - Decoder Layer</a>
        <ul>
          <li><a href="#ex-6">Exercise 6 - DecoderLayer</a></li>
        </ul>
      </li>
      <li><a href="#5-2">5.2 - Full Decoder</a>
        <ul>
          <li><a href="#ex-7">Exercise 7 - Decoder</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#6">6 - Transformer</a>
    <ul>
      <li><a href="#ex-8">Exercise 8 - Transformer</a></li>
    </ul>
  </li>
  <li><a href="#7">7 - References</a></li>
</ul>

<p><a name="0"></a></p>
<h2 id="packages">Packages</h2>

<p>Run the following cell to load the packages you’ll need.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Embedding</span><span class="p">,</span> <span class="n">MultiHeadAttention</span><span class="p">,</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Input</span><span class="p">,</span> <span class="n">Dropout</span><span class="p">,</span> <span class="n">LayerNormalization</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">DistilBertTokenizerFast</span> <span class="c1">#, TFDistilBertModel
</span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">TFDistilBertForTokenClassification</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm_notebook</span> <span class="k">as</span> <span class="n">tqdm</span>

<span class="kn">import</span> <span class="nn">seaborn</span>
<span class="n">seaborn</span><span class="p">.</span><span class="n">set_context</span><span class="p">(</span><span class="n">context</span><span class="o">=</span><span class="s">"talk"</span><span class="p">)</span>
</code></pre></div></div>

<p><a name="1"></a></p>
<h2 id="1---positional-encoding">1 - Positional Encoding</h2>

<p>In sequence to sequence tasks, the relative order of your data is extremely important to its meaning. When you were training sequential neural networks such as RNNs, you fed your inputs into the network in order. Information about the order of your data was automatically fed into your model.  However, when you train a Transformer network, you feed your data into the model all at once. While this dramatically reduces training time, there is no information about the order of your data. This is where positional encoding is useful - you can specifically encode the positions of your inputs and pass them into the network using these sine and cosine formulas:</p>

<p><img src="/assets/2023-12-03-Transformer-learning-C5W4A1SubclassV1_files/fafd0dfa-961d-416d-8159-678f0d903421.png" alt="image.png" />
\(PE_{(pos, 2i)}= sin\left(\frac{pos}{10000^{\frac{2i}{d}}}\right)
\tag{1}\)</p>

\[PE_{(pos, 2i+1)}= cos\left(\frac{pos}{10000^{\frac{2i}{d}}}\right)
\tag{2}\]

<font size="5" color="red">**it is like FFT, I should check it later!!**</font>
<ul>
  <li>$d$ is the dimension of the word embedding and positional encoding</li>
  <li>$pos$ is the position of the word.</li>
  <li>$i$ refers to each of the different dimensions of the positional encoding.</li>
</ul>

<p>The values of the sine and cosine equations are small enough (between -1 and 1) that when you add the positional encoding to a word embedding, the word embedding is not significantly distorted. The sum of the positional encoding and word embeding is ultimately what is fed into the model. Using a combination of these two equations helps your Transformer network attend to the relative positions of your input data. Note that while in the lectures Andrew uses vertical vectors but in this assignment, all vectors are horizontal. All matrix multiplications should be adjusted accordingly.</p>

<p><a name="1-1"></a></p>
<h3 id="11---sine-and-cosine-angles">1.1 - Sine and Cosine Angles</h3>

<p>Get the possible angles used to compute the positional encodings by calculating the inner term of the sine and cosine equations:</p>

\[\frac{pos}{10000^{\frac{2i}{d}}} \tag{3}\]

<p><a name="ex-1"></a></p>
<h3 id="exercise-1---get_angles">Exercise 1 - get_angles</h3>

<p>Implement the function <code class="language-plaintext highlighter-rouge">get_angles()</code> to calculate the possible angles for the sine and cosine  positional encodings</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># UNQ_C1 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)
# GRADED FUNCTION get_angles
</span><span class="k">def</span> <span class="nf">get_angles</span><span class="p">(</span><span class="n">pos</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">d</span><span class="p">):</span>
    <span class="s">"""
    Get the angles for the positional encoding
    
    Arguments:
        pos -- Column vector containing the positions [[0], [1], ...,[N-1]]
        i --   Row vector containing the dimension span [[0, 1, 2, ..., M-1]]
        d(integer) -- Encoding size
    
    Returns:
        angles -- (pos, d) numpy array 
    """</span>
    <span class="c1"># START CODE HERE
</span>    <span class="n">angles</span> <span class="o">=</span> <span class="n">pos</span><span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">power</span><span class="p">(</span><span class="mi">10000</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">i</span><span class="o">//</span><span class="mi">2</span><span class="p">))</span> <span class="o">/</span> <span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">(</span><span class="n">d</span><span class="p">)))</span>
    <span class="c1"># END CODE HERE
</span>    
    <span class="k">return</span> <span class="n">angles</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># UNIT TEST
</span><span class="k">def</span> <span class="nf">get_angles_test</span><span class="p">(</span><span class="n">target</span><span class="p">):</span>
    <span class="n">position</span> <span class="o">=</span> <span class="mi">4</span>
    <span class="n">d_model</span> <span class="o">=</span> <span class="mi">16</span>
    <span class="n">pos_m</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="n">position</span><span class="p">)[:,</span> <span class="n">np</span><span class="p">.</span><span class="n">newaxis</span><span class="p">]</span>
    <span class="n">dims</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="n">d_model</span><span class="p">)[</span><span class="n">np</span><span class="p">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="p">:]</span>

    <span class="n">result</span> <span class="o">=</span> <span class="n">target</span><span class="p">(</span><span class="n">pos_m</span><span class="p">,</span> <span class="n">dims</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>

    <span class="k">assert</span> <span class="nb">type</span><span class="p">(</span><span class="n">result</span><span class="p">)</span> <span class="o">==</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="s">"You must return a numpy ndarray"</span>
    <span class="k">assert</span> <span class="n">result</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">position</span><span class="p">,</span> <span class="n">d_model</span><span class="p">),</span> <span class="sa">f</span><span class="s">"Wrong shape. We expected: (</span><span class="si">{</span><span class="n">position</span><span class="si">}</span><span class="s">, </span><span class="si">{</span><span class="n">d_model</span><span class="si">}</span><span class="s">)"</span>
    <span class="k">assert</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:])</span> <span class="o">==</span> <span class="mi">0</span>
    <span class="k">assert</span> <span class="n">np</span><span class="p">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">result</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]),</span> <span class="n">position</span> <span class="o">*</span> <span class="p">(</span><span class="n">position</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">even_cols</span> <span class="o">=</span>  <span class="n">result</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span>
    <span class="n">odd_cols</span> <span class="o">=</span> <span class="n">result</span><span class="p">[:,</span>  <span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span>
    <span class="k">assert</span> <span class="n">np</span><span class="p">.</span><span class="nb">all</span><span class="p">(</span><span class="n">even_cols</span> <span class="o">==</span> <span class="n">odd_cols</span><span class="p">),</span> <span class="s">"Submatrices of odd and even columns must be equal"</span>
    <span class="c1"># edge value of the angle (d_model =16)
</span>    <span class="n">limit</span> <span class="o">=</span> <span class="p">(</span><span class="n">position</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="p">.</span><span class="n">power</span><span class="p">(</span><span class="mi">10000</span><span class="p">,</span><span class="mf">14.0</span><span class="o">/</span><span class="mf">16.0</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">np</span><span class="p">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="n">position</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">d_model</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">limit</span> <span class="p">),</span> <span class="sa">f</span><span class="s">"Last value must be </span><span class="si">{</span><span class="n">limit</span><span class="si">}</span><span class="s">"</span>

    <span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\033</span><span class="s">[92mAll tests passed"</span><span class="p">)</span>

<span class="n">get_angles_test</span><span class="p">(</span><span class="n">get_angles</span><span class="p">)</span>

<span class="c1"># Example
</span><span class="n">position</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">d_model</span> <span class="o">=</span> <span class="mi">8</span>
<span class="c1"># add new dimension to column so it will be (4, 1)
</span><span class="n">pos_m</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="n">position</span><span class="p">)[:,</span> <span class="n">np</span><span class="p">.</span><span class="n">newaxis</span><span class="p">]</span>
<span class="c1"># add new dimension to row so it will be (1, 4)
</span><span class="n">dims</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="n">d_model</span><span class="p">)[</span><span class="n">np</span><span class="p">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="p">:]</span>
<span class="n">angles</span><span class="o">=</span> <span class="n">get_angles</span><span class="p">(</span><span class="n">pos_m</span><span class="p">,</span> <span class="n">dims</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[92mAll tests passed
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pos_m</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([[0],
       [1],
       [2],
       [3]])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">dims</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([[0, 1, 2, 3, 4, 5, 6, 7]])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">angles</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([[0.e+00, 0.e+00, 0.e+00, 0.e+00, 0.e+00, 0.e+00, 0.e+00, 0.e+00],
       [1.e+00, 1.e+00, 1.e-01, 1.e-01, 1.e-02, 1.e-02, 1.e-03, 1.e-03],
       [2.e+00, 2.e+00, 2.e-01, 2.e-01, 2.e-02, 2.e-02, 2.e-03, 2.e-03],
       [3.e+00, 3.e+00, 3.e-01, 3.e-01, 3.e-02, 3.e-02, 3.e-03, 3.e-03]])
</code></pre></div></div>

<p><a name="1-2"></a></p>
<h3 id="12---sine-and-cosine-positional-encodings">1.2 - Sine and Cosine Positional Encodings</h3>

<p>Now you can use the angles you computed to calculate the sine and cosine positional encodings.</p>

\[PE_{(pos, 2i)}= sin\left(\frac{pos}{10000^{\frac{2i}{d}}}\right)\]

\[PE_{(pos, 2i+1)}= cos\left(\frac{pos}{10000^{\frac{2i}{d}}}\right)\]

<p><a name="ex-2"></a></p>
<h3 id="exercise-2---positional_encoding">Exercise 2 - positional_encoding</h3>

<p>Implement the function <code class="language-plaintext highlighter-rouge">positional_encoding()</code> to calculate the sine and cosine  positional encodings</p>

<p><strong>Reminder:</strong> Use the sine equation when $i$ is an even number and the cosine equation when $i$ is an odd number.</p>

<h4 id="additional-hints">Additional Hints</h4>
<ul>
  <li>You may find 
<a href="https://numpy.org/doc/stable/reference/arrays.indexing.html">np.newaxis</a> useful depending on the implementation you choose.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># UNQ_C2 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)
# GRADED FUNCTION positional_encoding
</span><span class="k">def</span> <span class="nf">positional_encoding</span><span class="p">(</span><span class="n">positions</span><span class="p">,</span> <span class="n">d</span><span class="p">):</span>
    <span class="s">"""
    Precomputes a matrix with all the positional encodings 
    
    Arguments:
        positions (int) -- Maximum number of positions to be encoded 
        d (int) -- Encoding size 
    
    Returns:
        pos_encoding -- (1, position, d_model) A matrix with the positional encodings
    """</span>
    <span class="c1"># START CODE HERE
</span>    <span class="c1"># initialize a matrix angle_rads of all the angles 
</span>    <span class="n">angle_rads</span> <span class="o">=</span> <span class="n">get_angles</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="n">positions</span><span class="p">)[:,</span> <span class="n">np</span><span class="p">.</span><span class="n">newaxis</span><span class="p">],</span>
                            <span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="n">d</span><span class="p">)[</span> <span class="n">np</span><span class="p">.</span><span class="n">newaxis</span><span class="p">,:],</span>
                            <span class="n">d</span><span class="p">)</span>
  
    <span class="c1"># -&gt; angle_rads has dim (positions,d)
</span>    <span class="c1"># apply sin to even indices in the array; 2i
</span>    <span class="n">angle_rads</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">sin</span><span class="p">(</span><span class="n">angle_rads</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">::</span><span class="mi">2</span><span class="p">])</span>
  
    <span class="c1"># apply cos to odd indices in the array; 2i+1
</span>    <span class="n">angle_rads</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">cos</span><span class="p">(</span><span class="n">angle_rads</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">])</span>
    <span class="c1"># END CODE HERE
</span>    
    <span class="n">pos_encoding</span> <span class="o">=</span> <span class="n">angle_rads</span><span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="p">...]</span>
    
    <span class="k">return</span> <span class="n">tf</span><span class="p">.</span><span class="n">cast</span><span class="p">(</span><span class="n">pos_encoding</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>

</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># UNIT TEST
</span><span class="k">def</span> <span class="nf">positional_encoding_test</span><span class="p">(</span><span class="n">target</span><span class="p">):</span>
    <span class="n">position</span> <span class="o">=</span> <span class="mi">8</span>
    <span class="n">d_model</span> <span class="o">=</span> <span class="mi">16</span>

    <span class="n">pos_encoding</span> <span class="o">=</span> <span class="n">target</span><span class="p">(</span><span class="n">position</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
    <span class="n">sin_part</span> <span class="o">=</span> <span class="n">pos_encoding</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span>
    <span class="n">cos_part</span> <span class="o">=</span> <span class="n">pos_encoding</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span>

    <span class="k">assert</span> <span class="n">tf</span><span class="p">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">pos_encoding</span><span class="p">),</span> <span class="s">"Output is not a tensor"</span>
    <span class="k">assert</span> <span class="n">pos_encoding</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">position</span><span class="p">,</span> <span class="n">d_model</span><span class="p">),</span> <span class="sa">f</span><span class="s">"Wrong shape. We expected: (1, </span><span class="si">{</span><span class="n">position</span><span class="si">}</span><span class="s">, </span><span class="si">{</span><span class="n">d_model</span><span class="si">}</span><span class="s">)"</span>

    <span class="n">ones</span> <span class="o">=</span> <span class="n">sin_part</span> <span class="o">**</span> <span class="mi">2</span>  <span class="o">+</span>  <span class="n">cos_part</span> <span class="o">**</span> <span class="mi">2</span>
    <span class="k">assert</span> <span class="n">np</span><span class="p">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">ones</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">position</span><span class="p">,</span> <span class="n">d_model</span> <span class="o">//</span> <span class="mi">2</span><span class="p">))),</span> <span class="s">"Sum of square pairs must be 1 = sin(a)**2 + cos(a)**2"</span>
    
    <span class="n">angs</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">arctan</span><span class="p">(</span><span class="n">sin_part</span> <span class="o">/</span> <span class="n">cos_part</span><span class="p">)</span>
    <span class="n">angs</span><span class="p">[</span><span class="n">angs</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">]</span> <span class="o">+=</span> <span class="n">np</span><span class="p">.</span><span class="n">pi</span>
    <span class="n">angs</span><span class="p">[</span><span class="n">sin_part</span><span class="p">.</span><span class="n">numpy</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">]</span> <span class="o">+=</span> <span class="n">np</span><span class="p">.</span><span class="n">pi</span>
    <span class="n">angs</span> <span class="o">=</span> <span class="n">angs</span> <span class="o">%</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">pi</span><span class="p">)</span>
    
    <span class="n">pos_m</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="n">position</span><span class="p">)[:,</span> <span class="n">np</span><span class="p">.</span><span class="n">newaxis</span><span class="p">]</span>
    <span class="n">dims</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="n">d_model</span><span class="p">)[</span><span class="n">np</span><span class="p">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="p">:]</span>

    <span class="n">trueAngs</span> <span class="o">=</span> <span class="n">get_angles</span><span class="p">(</span><span class="n">pos_m</span><span class="p">,</span> <span class="n">dims</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)[:,</span> <span class="mi">0</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span> <span class="o">%</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">pi</span><span class="p">)</span>
    
    <span class="k">assert</span> <span class="n">np</span><span class="p">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">angs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">trueAngs</span><span class="p">),</span> <span class="s">"Did you apply sin and cos to even and odd parts respectively?"</span>
 
    <span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\033</span><span class="s">[92mAll tests passed"</span><span class="p">)</span>
    
    
<span class="n">positional_encoding_test</span><span class="p">(</span><span class="n">positional_encoding</span><span class="p">)</span>

</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[92mAll tests passed


2023-05-09 10:37:45.354620: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-09 10:37:45.355316: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
</code></pre></div></div>

<p>another example implementation in torch https://nlp.seas.harvard.edu/2018/04/03/attention.html#positional-encoding</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="n">F</span>
<span class="kn">import</span> <span class="nn">math</span><span class="p">,</span> <span class="n">copy</span><span class="p">,</span> <span class="n">time</span>
<span class="kn">from</span> <span class="nn">torch.autograd</span> <span class="kn">import</span> <span class="n">Variable</span>

<span class="k">class</span> <span class="nc">PositionalEncoding</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="s">"Implement the PE function."</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">max_len</span><span class="o">=</span><span class="mi">5000</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">PositionalEncoding</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="n">dropout</span><span class="p">)</span>
        
        <span class="c1"># Compute the positional encodings once in log space.
</span>        <span class="n">pe</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">max_len</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
        <span class="n">position</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_len</span><span class="p">).</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">div_term</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span>
                             <span class="o">-</span><span class="p">(</span><span class="n">math</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="mf">10000.0</span><span class="p">)</span> <span class="o">/</span> <span class="n">d_model</span><span class="p">))</span>
        <span class="n">pe</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">sin</span><span class="p">(</span><span class="n">position</span> <span class="o">*</span> <span class="n">div_term</span><span class="p">)</span>
        <span class="n">pe</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cos</span><span class="p">(</span><span class="n">position</span> <span class="o">*</span> <span class="n">div_term</span><span class="p">)</span>
        <span class="n">pe</span> <span class="o">=</span> <span class="n">pe</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s">'pe'</span><span class="p">,</span> <span class="n">pe</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">Variable</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">pe</span><span class="p">[:,</span> <span class="p">:</span><span class="n">x</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)],</span> 
                         <span class="n">requires_grad</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</code></pre></div></div>

<p>Nice work calculating the positional encodings! Now you can visualize them.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pos_encoding</span> <span class="o">=</span> <span class="n">positional_encoding</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="mi">512</span><span class="p">)</span>

<span class="k">print</span> <span class="p">(</span><span class="n">pos_encoding</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">pcolormesh</span><span class="p">(</span><span class="n">pos_encoding</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s">'RdBu'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'d'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlim</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">512</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'Position'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">colorbar</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(1, 50, 512)
</code></pre></div></div>

<p><img src="/assets/2023-12-03-Transformer-learning-C5W4A1SubclassV1_files/2023-12-03-Transformer-learning-C5W4A1SubclassV1_17_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#forward acctually just adding the pos_endcoding to x, and adding one dropout which is ingored here
#this is just for corss check the pos_endcoding 
</span><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">x</span> <span class="p">,</span> <span class="n">pos_encoding</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">tf</span><span class="p">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">pos_encoding</span><span class="p">[:,</span> <span class="p">:</span><span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
    <span class="k">return</span> <span class="n">x</span>

<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">position</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">d_model</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">pos_encoding</span> <span class="o">=</span> <span class="n">positional_encoding</span><span class="p">(</span><span class="n">position</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">forward</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">20</span><span class="p">])),</span><span class="n">pos_encoding</span><span class="p">)</span>
<span class="n">tf</span><span class="p">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">20</span><span class="p">]))</span>
<span class="c1">#you will see the different value added
</span><span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">100</span><span class="p">),</span> <span class="n">y</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="mi">4</span><span class="p">:</span><span class="mi">8</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">([</span><span class="s">"dim %d"</span><span class="o">%</span><span class="n">p</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">7</span><span class="p">]])</span>
<span class="bp">None</span>
</code></pre></div></div>

<p><img src="/assets/2023-12-03-Transformer-learning-C5W4A1SubclassV1_files/2023-12-03-Transformer-learning-C5W4A1SubclassV1_18_0.png" alt="png" /></p>

<p>Each row represents a positional encoding - <font size="5" color="red">notice how none of the rows are identical! </font> You have created a unique positional encoding for each of the words.</p>

<p><a name="2"></a></p>
<h2 id="2---masking">2 - Masking</h2>

<p>There are two types of masks that are useful when building your Transformer network: the <em>padding mask</em> and the <em>look-ahead mask</em>. Both help the softmax computation give the appropriate weights to the words in your input sentence.</p>

<p><a name="2-1"></a></p>
<h3 id="21---padding-mask">2.1 - Padding Mask</h3>

<p>Oftentimes your input sequence will exceed the maximum length of a sequence your network can process. Let’s say the maximum length of your model is five, it is fed the following sequences:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[["Do", "you", "know", "when", "Jane", "is", "going", "to", "visit", "Africa"], 
 ["Jane", "visits", "Africa", "in", "September" ],
 ["Exciting", "!"]
]
</code></pre></div></div>

<p>which might get vectorized as:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[[ 71, 121, 4, 56, 99, 2344, 345, 1284, 15],
 [ 56, 1285, 15, 181, 545],
 [ 87, 600]
]
</code></pre></div></div>

<p>When passing sequences into a transformer model, it is important that they are of uniform length. You can achieve this by padding the sequence with zeros, and truncating sentences that exceed the maximum length of your model:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[[ 71, 121, 4, 56, 99],
 [ 2344, 345, 1284, 15, 0],
 [ 56, 1285, 15, 181, 545],
 [ 87, 600, 0, 0, 0],
]
</code></pre></div></div>

<font color="red">Sequences longer than the maximum length of five will be truncated, and zeros will be added to the truncated sequence to achieve uniform length.</font>
<p>Similarly, for sequences shorter than the maximum length, they zeros will also be added for padding. However, these zeros will affect the softmax calculation - this is when a padding mask comes in handy! By multiplying a padding mask by -1e9 and adding it to your sequence, you mask out the zeros by setting them to close to negative infinity. We’ll implement this for you so you can get to the fun of building the Transformer network! 😇 Just make sure you go through the code so you can correctly implement padding when building your model.</p>

<p>After masking, your input should go from <code class="language-plaintext highlighter-rouge">[87, 600, 0, 0, 0]</code> to <code class="language-plaintext highlighter-rouge">[87, 600, -1e9, -1e9, -1e9]</code>, so that when you take the softmax, the zeros don’t affect the score.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">create_padding_mask</span><span class="p">(</span><span class="n">seq</span><span class="p">):</span>
    <span class="s">"""
    Creates a matrix mask for the padding cells
    
    Arguments:
        seq -- (n, m) matrix
    
    Returns:
        mask -- (n, 1, 1, m) binary tensor
    """</span>
    <span class="n">seq</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">cast</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">math</span><span class="p">.</span><span class="n">equal</span><span class="p">(</span><span class="n">seq</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
  
    <span class="c1"># add extra dimensions to add the padding
</span>    <span class="c1"># to the attention logits.
</span>    <span class="k">return</span> <span class="n">seq</span><span class="p">[:,</span> <span class="n">tf</span><span class="p">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="n">tf</span><span class="p">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="p">:]</span> 
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">constant</span><span class="p">([[</span><span class="mf">7.</span><span class="p">,</span> <span class="mf">6.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">]])</span>
<span class="k">print</span><span class="p">(</span><span class="n">create_padding_mask</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tf.Tensor(
[[[[0. 0. 1. 1. 0.]]]


 [[[0. 0. 0. 1. 1.]]]


 [[[1. 1. 1. 0. 0.]]]], shape=(3, 1, 1, 5), dtype=float32)
</code></pre></div></div>

<p>If we multiply this mask by -1e9 and add it to the sample input sequences, the zeros are essentially set to negative infinity. Notice the difference when taking the softmax of the original sequence and the masked sequence:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">activations</span><span class="p">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">activations</span><span class="p">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="n">create_padding_mask</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">*</span> <span class="o">-</span><span class="mf">1.0e9</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tf.Tensor(
[[7.2876638e-01 2.6809818e-01 6.6454895e-04 6.6454895e-04 1.8064313e-03]
 [8.4437370e-02 2.2952457e-01 6.2391245e-01 3.1062772e-02 3.1062772e-02]
 [4.8541026e-03 4.8541026e-03 4.8541026e-03 2.6502505e-01 7.2041273e-01]], shape=(3, 5), dtype=float32)
tf.Tensor(
[[[[7.2973627e-01 2.6845497e-01 0.0000000e+00 0.0000000e+00
    1.8088354e-03]
   [2.4472848e-01 6.6524094e-01 0.0000000e+00 0.0000000e+00
    9.0030573e-02]
   [6.6483542e-03 6.6483542e-03 0.0000000e+00 0.0000000e+00
    9.8670328e-01]]]


 [[[7.3057157e-01 2.6876226e-01 6.6619506e-04 0.0000000e+00
    0.0000000e+00]
   [9.0030566e-02 2.4472845e-01 6.6524088e-01 0.0000000e+00
    0.0000000e+00]
   [3.3333334e-01 3.3333334e-01 3.3333334e-01 0.0000000e+00
    0.0000000e+00]]]


 [[[0.0000000e+00 0.0000000e+00 0.0000000e+00 2.6894143e-01
    7.3105860e-01]
   [0.0000000e+00 0.0000000e+00 0.0000000e+00 5.0000000e-01
    5.0000000e-01]
   [0.0000000e+00 0.0000000e+00 0.0000000e+00 2.6894143e-01
    7.3105860e-01]]]], shape=(3, 1, 3, 5), dtype=float32)
</code></pre></div></div>

<p><a name="2-2"></a></p>
<h3 id="22---look-ahead-mask--it-looks-like-the-mask-m-in-importedimplementing-transformersipynb---no-it-is-not-same-the-m-is-used-in-softmax">2.2 - Look-ahead Mask – it looks like the mask M in “imported/implementing-transformers.ipynb”  – no, it is not same, the M is used in softmax</h3>

<p>The look-ahead mask follows similar intuition. In training, you will have access to the complete correct output of your training example. The look-ahead mask helps your model pretend that it correctly predicted a part of the output and see if, <em>without looking ahead</em>, it can correctly predict the next output.</p>

<p>For example, if the expected correct output is <code class="language-plaintext highlighter-rouge">[1, 2, 3]</code> and you wanted to see if given that the model correctly predicted the first value it could predict the second value, you would mask out the second and third values. So you would input the masked sequence <code class="language-plaintext highlighter-rouge">[1, -1e9, -1e9]</code> and see if it could generate <code class="language-plaintext highlighter-rouge">[1, 2, -1e9]</code>.</p>

<p>Just because you’ve worked so hard, we’ll also implement this mask for you 😇😇. Again, take a close look at the code so you can effictively implement it later.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">create_look_ahead_mask</span><span class="p">(</span><span class="n">size</span><span class="p">):</span>
    <span class="s">"""
    Returns an upper triangular matrix filled with ones
    
    Arguments:
        size -- matrix size
    
    Returns:
        mask -- (size, size) tensor
    """</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="n">band_part</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">ones</span><span class="p">((</span><span class="n">size</span><span class="p">,</span> <span class="n">size</span><span class="p">)),</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">mask</span> 
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">temp</span> <span class="o">=</span> <span class="n">create_look_ahead_mask</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">temp</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tf.Tensor([[0.8312781  0.24044645 0.17191601]], shape=(1, 3), dtype=float32)





&lt;tf.Tensor: shape=(3, 3), dtype=float32, numpy=
array([[1., 0., 0.],
       [1., 1., 0.],
       [1., 1., 1.]], dtype=float32)&gt;
</code></pre></div></div>

<p><a name="3"></a></p>
<h2 id="3---self-attention">3 - Self-Attention</h2>

<p>As the authors of the Transformers paper state, “Attention is All You Need”.</p>

<center><img src="/assets//assets/2023-12-03-Transformer-learning-C5W4A1SubclassV1_files/self-attention.png" alt="Encoder" width="600" /></center>
<caption><center><font color="purple">Figure 1: Self-Attention calculation visualization</font></center></caption>

<p>The use of self-attention paired with traditional convolutional networks allows for the parallization which speeds up training. You will implement <strong>scaled dot product attention</strong> which takes in a query, key, value, and a mask as inputs to returns rich, attention-based vector representations of the words in your sequence. This type of self-attention can be mathematically expressed as:
\(\text { Attention }(Q, K, V)=\operatorname{softmax}\left(\frac{Q K^{T}}{\sqrt{d_{k}}}+{M}\right) V\tag{4}\)</p>

<ul>
  <li>$Q$ is the matrix of queries</li>
  <li>$K$ is the matrix of keys</li>
  <li>$V$ is the matrix of values</li>
  <li>$M$ is the optional mask you choose to apply</li>
  <li>${d_k}$ is the dimension of the keys, which is used to scale everything down so the softmax doesn’t explode</li>
</ul>

<p><a name="ex-3"></a></p>
<h3 id="exercise-3---scaled_dot_product_attention">Exercise 3 - scaled_dot_product_attention</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Implement the function `scaled_dot_product_attention()` to create attention-based representations **Reminder**: The boolean mask parameter can be passed in as `none` or as either padding or look-ahead. Multiply it by -1e9 before applying the softmax. 
</code></pre></div></div>

<p><strong>Additional Hints</strong></p>
<ul>
  <li>You may find <a href="https://www.tensorflow.org/api_docs/python/tf/linalg/matmul">tf.matmul</a> useful for matrix multiplication.</li>
</ul>

<p>Q，K和V是经过卷积后得到的特征，其形状为（batch_size，seq_length，num_features）。</p>

<p>将查询（Q）和键（K）相乘会得到（batch_size，seq_length，seq_length）特征，这大致告诉我们序列中每个元素的重要性，确定我们“注意”哪些元素。 注意数组使用softmax标准化，因此所有权重之和为1。 最后，注意力将通过矩阵乘法应用于值（V）数组。
请注意，MatMul操作在PyTorch中对应为torch.bmm。 这是因为Q，K和V（查询，键和值数组）都是矩阵，每个矩阵的形状均为（batch_size，sequence_length，num_features），矩阵乘法仅在最后两个维度上执行。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># UNQ_C3 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)
# GRADED FUNCTION scaled_dot_product_attention
</span><span class="k">def</span> <span class="nf">scaled_dot_product_attention</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">mask</span><span class="p">):</span>
    <span class="s">"""
    Calculate the attention weights.
      q, k, v must have matching leading dimensions.
      k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.
      The mask has different shapes depending on its type(padding or look ahead) 
      but it must be broadcastable for addition.

    Arguments:
        q -- query shape == (..., seq_len_q, depth)
        k -- key shape == (..., seq_len_k, depth)
        v -- value shape == (..., seq_len_v, depth_v)
        mask: Float tensor with shape broadcastable 
              to (..., seq_len_q, seq_len_k). Defaults to None.

    Returns:
        output -- attention_weights
    """</span>
    <span class="c1"># START CODE HERE
</span>    
    <span class="c1"># Q*K'
</span>    <span class="n">matmul_qk</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">transpose_b</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

    <span class="c1"># scale matmul_qk
</span>    <span class="n">dk</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">cast</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">shape</span><span class="p">(</span><span class="n">k</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">scaled_attention_logits</span> <span class="o">=</span> <span class="n">matmul_qk</span> <span class="o">/</span> <span class="n">tf</span><span class="p">.</span><span class="n">math</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">dk</span><span class="p">)</span>

    <span class="c1"># add the mask to the scaled tensor.
</span>    <span class="k">if</span> <span class="n">mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">scaled_attention_logits</span> <span class="o">+=</span> <span class="p">(</span><span class="n">mask</span> <span class="o">*</span> <span class="o">-</span><span class="mf">1e9</span><span class="p">)</span>

    <span class="c1"># softmax is normalized on the last axis (seq_len_k) so that the scores
</span>    <span class="c1"># add up to 1.
</span>    <span class="n">attention_weights</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">scaled_attention_logits</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># (..., seq_len_q, seq_len_k)
</span>    <span class="c1"># attention_weights * V
</span>    <span class="n">output</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">attention_weights</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>   <span class="c1"># (..., seq_len_q, depth_v)
</span>    
    <span class="c1"># END CODE HERE
</span>
    <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">attention_weights</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># UNIT TEST
</span><span class="k">def</span> <span class="nf">scaled_dot_product_attention_test</span><span class="p">(</span><span class="n">target</span><span class="p">):</span>
    <span class="n">q</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]).</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>  <span class="c1">#accoridng to vector is horizontal, so here means q is 4 feature vector but 
</span>                                                                                 <span class="c1">#3 is the seq_len， so here 3x4 matrix
</span>    <span class="n">k</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span> <span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]).</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span> <span class="c1">#k shape (4,4), still 4 is the seq_len but lenth is also 4
</span>                                                                                               <span class="c1">#q , v should have the same feature number , but it could be different 
</span>                                                                                               <span class="c1">#lenght?? -- it seems not reasonable ?
</span>    <span class="n">v</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]).</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>    <span class="c1">#q lenth is  should be 4, feature bumber is 2
</span>
    <span class="n">attention</span><span class="p">,</span> <span class="n">weights</span> <span class="o">=</span> <span class="n">target</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="bp">None</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">tf</span><span class="p">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">weights</span><span class="p">),</span> <span class="s">"Weights must be a tensor"</span>
    <span class="c1">#so here the weight shape is 3x4, shape should be (q.shape[0], k.shape[0]) instead of  (q.shape[0], k.shape[1]), k is transpose
</span>    <span class="c1">#assert tuple(tf.shape(weights).numpy()) == (q.shape[0], k.shape[1]), f"Wrong shape. We expected ({q.shape[0]}, {k.shape[1]})"
</span>    <span class="k">assert</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">shape</span><span class="p">(</span><span class="n">weights</span><span class="p">).</span><span class="n">numpy</span><span class="p">())</span> <span class="o">==</span> <span class="p">(</span><span class="n">q</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">k</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="sa">f</span><span class="s">"Wrong shape. We expected (</span><span class="si">{</span><span class="n">q</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s">, </span><span class="si">{</span><span class="n">k</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s">)"</span>
    
    <span class="k">assert</span> <span class="n">np</span><span class="p">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="p">[[</span><span class="mf">0.2589478</span><span class="p">,</span>  <span class="mf">0.42693272</span><span class="p">,</span> <span class="mf">0.15705977</span><span class="p">,</span> <span class="mf">0.15705977</span><span class="p">],</span>
                                   <span class="p">[</span><span class="mf">0.2772748</span><span class="p">,</span>  <span class="mf">0.2772748</span><span class="p">,</span>  <span class="mf">0.2772748</span><span class="p">,</span>  <span class="mf">0.16817567</span><span class="p">],</span>
                                   <span class="p">[</span><span class="mf">0.33620113</span><span class="p">,</span> <span class="mf">0.33620113</span><span class="p">,</span> <span class="mf">0.12368149</span><span class="p">,</span> <span class="mf">0.2039163</span> <span class="p">]])</span>

    <span class="k">assert</span> <span class="n">tf</span><span class="p">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">attention</span><span class="p">),</span> <span class="s">"Output must be a tensor"</span>
    <span class="k">assert</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">shape</span><span class="p">(</span><span class="n">attention</span><span class="p">).</span><span class="n">numpy</span><span class="p">())</span> <span class="o">==</span> <span class="p">(</span><span class="n">q</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">v</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="sa">f</span><span class="s">"Wrong shape. We expected (</span><span class="si">{</span><span class="n">q</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s">, </span><span class="si">{</span><span class="n">v</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s">)"</span>
    <span class="k">assert</span> <span class="n">np</span><span class="p">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">attention</span><span class="p">,</span> <span class="p">[[</span><span class="mf">0.74105227</span><span class="p">,</span> <span class="mf">0.15705977</span><span class="p">],</span>
                                   <span class="p">[</span><span class="mf">0.7227253</span><span class="p">,</span>  <span class="mf">0.16817567</span><span class="p">],</span>
                                   <span class="p">[</span><span class="mf">0.6637989</span><span class="p">,</span>  <span class="mf">0.2039163</span> <span class="p">]])</span>

    <span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
    <span class="n">attention</span><span class="p">,</span> <span class="n">weights</span> <span class="o">=</span> <span class="n">target</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>

    <span class="k">assert</span> <span class="n">np</span><span class="p">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="p">[[</span><span class="mf">0.30719590187072754</span><span class="p">,</span> <span class="mf">0.5064803957939148</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.18632373213768005</span><span class="p">],</span>
                                 <span class="p">[</span><span class="mf">0.3836517333984375</span><span class="p">,</span> <span class="mf">0.3836517333984375</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.2326965481042862</span><span class="p">],</span>
                                 <span class="p">[</span><span class="mf">0.3836517333984375</span><span class="p">,</span> <span class="mf">0.3836517333984375</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.2326965481042862</span><span class="p">]]),</span> <span class="s">"Wrong masked weights"</span>
    <span class="k">assert</span> <span class="n">np</span><span class="p">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">attention</span><span class="p">,</span> <span class="p">[[</span><span class="mf">0.6928040981292725</span><span class="p">,</span> <span class="mf">0.18632373213768005</span><span class="p">],</span>
                                   <span class="p">[</span><span class="mf">0.6163482666015625</span><span class="p">,</span> <span class="mf">0.2326965481042862</span><span class="p">],</span> 
                                   <span class="p">[</span><span class="mf">0.6163482666015625</span><span class="p">,</span> <span class="mf">0.2326965481042862</span><span class="p">]]),</span> <span class="s">"Wrong masked attention"</span>
    
    <span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\033</span><span class="s">[92mAll tests passed"</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">attention</span><span class="p">,</span> <span class="n">weights</span> 
    
<span class="n">attention</span><span class="p">,</span> <span class="n">weights</span> <span class="o">=</span> <span class="n">scaled_dot_product_attention_test</span><span class="p">(</span><span class="n">scaled_dot_product_attention</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">attention</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[92mAll tests passed
tf.Tensor(
[[0.6928041  0.18632373]
 [0.61634827 0.23269655]
 [0.61634827 0.23269655]], shape=(3, 2), dtype=float32)
tf.Tensor(
[[0.3071959  0.5064804  0.         0.18632373]
 [0.38365173 0.38365173 0.         0.23269655]
 [0.38365173 0.38365173 0.         0.23269655]], shape=(3, 4), dtype=float32)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">q</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]).</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">k</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span> <span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]).</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">v</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]).</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">k</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">matmul_qk</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">transpose_b</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">matmul_qk</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(4, 4)
tf.Tensor(
[[2. 3. 1. 1.]
 [2. 2. 2. 1.]
 [2. 2. 0. 1.]], shape=(3, 4), dtype=float32)
</code></pre></div></div>

<p>another sample to Obtaining Query, Key and Value matrix</p>

<p><img src="/assets/2023-12-03-Transformer-learning-C5W4A1SubclassV1_files/ce597e22-7e6c-4e60-86f9-1d7af9a71b6b.png" alt="image.png" />!</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#generate the emdedding the word vector for "this is book", each vector have 5 features
</span><span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Shape is :- </span><span class="si">{</span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">5</span><span class="p">).</span><span class="n">shape</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
<span class="n">X</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>
<span class="n">X</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Shape is :- (3, 5)





array([[ 0.47858264, -1.74327212, -0.82029071, -0.21163698,  1.31543753],
       [-0.09012238, -0.48729982,  0.84112528,  1.85078928,  0.32633046],
       [-1.62962921,  0.17127885, -0.49912593,  0.09966805, -0.55323133]])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">weight_of_query</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="n">weight_of_query</span>
<span class="n">Query</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">weight_of_query</span><span class="p">)</span>
<span class="n">Query</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([[-2.28215318, -0.37214572,  0.97116363],
       [-0.04802642,  1.48761478, -0.61758178],
       [-2.79664269, -3.07753598, -0.81546614]])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">weight_of_key</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="n">weight_of_key</span>
<span class="n">Key</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">weight_of_key</span><span class="p">)</span>
<span class="n">Key</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([[-2.03322686,  1.9992987 ,  2.09889272],
       [ 0.1997882 ,  0.12002915, -3.34110812],
       [ 3.23284659, -0.30207486, -0.76657696]])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">weight_of_values</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="n">weight_of_values</span>
<span class="n">Values</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">weight_of_values</span><span class="p">)</span>
<span class="n">Values</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([[-2.60174708, -1.75190164, -1.32735991],
       [-2.93463348,  0.28382245, -1.42966431],
       [ 1.57416533,  3.9202751 , -0.21375642]])
</code></pre></div></div>

<p><strong>so most cases the W_q, W_k, W_v are same shape, so the q, k, v also have the same shape</strong><br />
<img src="/assets/2023-12-03-Transformer-learning-C5W4A1SubclassV1_files/18755036-dc11-421e-917c-7d2aec49f7fb.png" alt="image.png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">dimension</span><span class="o">=</span><span class="mi">5</span>
<span class="n">Scores</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">Query</span><span class="p">,</span><span class="n">Key</span><span class="p">.</span><span class="n">T</span><span class="p">)</span><span class="o">/</span><span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">dimension</span><span class="p">)</span> <span class="c1">#score is the weights
</span><span class="n">Scores</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([[ 2.653977  , -1.6749841 , -3.58213928],
       [ 0.79407112,  0.998346  , -0.0586785 ],
       [-0.97415669,  0.80338804, -3.34799884]])
</code></pre></div></div>

<p>Excellent work! You can now implement self-attention. With that, you can start building the encoder block!</p>

<p><a name="4"></a></p>
<h2 id="4---encoder">4 - Encoder</h2>

<p>The Transformer Encoder layer pairs self-attention and convolutional neural network style of processing to improve the speed of training and passes K and V matrices to the Decoder, which you’ll build later in the assignment. In this section of the assignment, you will implement the Encoder by pairing multi-head attention and a feed forward neural network (Figure 2a).</p>
<center><img src="/assets//assets/2023-12-03-Transformer-learning-C5W4A1SubclassV1_files/encoder_layer.png" alt="Encoder" width="250" /></center>
<caption><center><font color="purple"><b>Figure 2a: Transformer encoder layer</b></font></center></caption>

<ul>
  <li><code class="language-plaintext highlighter-rouge">MultiHeadAttention</code> you can think of as computing the self-attention several times to detect different features.</li>
  <li>Feed forward neural network contains two Dense layers which we’ll implement as the function <code class="language-plaintext highlighter-rouge">FullyConnected</code></li>
</ul>

<p>Your input sentence first passes through a <em>multi-head attention layer</em>, where the encoder looks at other words in the input sentence as it encodes a specific word. The outputs of the multi-head attention layer are then fed to a <em>feed forward neural network</em>. The exact same feed forward network is independently applied to each position.</p>

<ul>
  <li>For the <code class="language-plaintext highlighter-rouge">MultiHeadAttention</code> layer, you will use the <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/MultiHeadAttention">Keras implementation</a>. If you’re curious about how to split the query matrix Q, key matrix K, and value matrix V into different heads, you can look through the implementation.</li>
  <li>You will also use the <a href="https://keras.io/api/models/sequential/">Sequential API</a> with two dense layers to built the feed forward neural network layers.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">FullyConnected</span><span class="p">(</span><span class="n">embedding_dim</span><span class="p">,</span> <span class="n">fully_connected_dim</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">Sequential</span><span class="p">([</span>
        <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">fully_connected_dim</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">),</span>  <span class="c1"># (batch_size, seq_len, dff)
</span>        <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">embedding_dim</span><span class="p">)</span>  <span class="c1"># (batch_size, seq_len, d_model)
</span>    <span class="p">])</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sample_ffn</span> <span class="o">=</span> <span class="n">FullyConnected</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">2048</span><span class="p">)</span>
<span class="n">sample_ffn</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">64</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">512</span><span class="p">))).</span><span class="n">shape</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>TensorShape([64, 50, 512])
</code></pre></div></div>

<p><a name="4-1"></a></p>
<h3 id="41-encoder-layer">4.1 Encoder Layer</h3>

<p>Now you can pair multi-head attention and feed forward neural network together in an encoder layer! You will also use residual connections and layer normalization to help speed up training (Figure 2a).</p>

<p><a name="ex-4"></a></p>
<h3 id="exercise-4---encoderlayer">Exercise 4 - EncoderLayer</h3>

<p>Implement <code class="language-plaintext highlighter-rouge">EncoderLayer()</code> using the <code class="language-plaintext highlighter-rouge">call()</code> method</p>

<p>In this exercise, you will implement one encoder block (Figure 2) using the <code class="language-plaintext highlighter-rouge">call()</code> method. The function should perform the following steps:</p>
<ol>
  <li>You will pass the Q, V, K matrices and a boolean mask to a multi-head attention layer. Remember that to compute <em>self</em>-attention Q, V and K should be the same.</li>
  <li>Next, you will pass the output of the multi-head attention layer to a dropout layer. Don’t forget to use the <code class="language-plaintext highlighter-rouge">training</code> parameter to set the mode of your model.</li>
  <li>Now add a skip connection by adding your original input <code class="language-plaintext highlighter-rouge">x</code> and the output of the dropout layer.</li>
  <li>After adding the skip connection, pass the output through the first layer normalization.</li>
  <li>Finally, repeat steps 1-4 but with the feed forward neural network instead of the multi-head attention layer.</li>
</ol>

<p><strong>Additional Hints</strong>:</p>
<ul>
  <li>The <code class="language-plaintext highlighter-rouge">__init__</code> method creates all the layers that will be accesed by the the <code class="language-plaintext highlighter-rouge">call</code> method. Wherever you want to use a layer defined inside  the <code class="language-plaintext highlighter-rouge">__init__</code>  method you will have to use the syntax <code class="language-plaintext highlighter-rouge">self.[insert layer name]</code>.</li>
  <li>You will find the documentation of <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/MultiHeadAttention">MultiHeadAttention</a> helpful. <em>Note that if query, key and value are the same, then this function performs self-attention.</em></li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># I borrow the another implemenation of the MultiHeadAttention to cross check 
</span><span class="k">def</span> <span class="nf">multihead_attention</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">heads</span><span class="p">,</span> <span class="n">W_KQV</span><span class="p">,</span> <span class="n">W_out</span><span class="p">):</span>
    <span class="n">N</span><span class="p">,</span><span class="n">T</span><span class="p">,</span><span class="n">d</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">shape</span>
    <span class="n">K</span><span class="p">,</span><span class="n">Q</span><span class="p">,</span><span class="n">V</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="o">@</span><span class="n">W_KQV</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">K</span><span class="p">,</span><span class="n">Q</span><span class="p">,</span><span class="n">V</span> <span class="o">=</span> <span class="p">[</span><span class="n">a</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="n">T</span><span class="p">,</span><span class="n">heads</span><span class="p">,</span><span class="n">d</span><span class="o">//</span><span class="n">heads</span><span class="p">).</span><span class="n">swapaxes</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="p">(</span><span class="n">K</span><span class="p">,</span><span class="n">Q</span><span class="p">,</span><span class="n">V</span><span class="p">)]</span>
    
    <span class="n">attn</span> <span class="o">=</span> <span class="n">softmax</span><span class="p">(</span><span class="n">K</span><span class="o">@</span><span class="n">Q</span><span class="p">.</span><span class="n">swapaxes</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">d</span><span class="o">//</span><span class="n">heads</span><span class="p">)</span> <span class="o">+</span> <span class="n">mask</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">attn</span><span class="o">@</span><span class="n">V</span><span class="p">).</span><span class="n">swapaxes</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">).</span><span class="n">reshape</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="n">T</span><span class="p">,</span><span class="n">d</span><span class="p">)</span> <span class="o">@</span> <span class="n">W_out</span><span class="p">,</span> <span class="n">attn</span>
</code></pre></div></div>

<p>多头注意力由四部分组成：</p>

<p>线性层并分拆成多头。
按比缩放的点积注意力。
多头及联。
最后一层线性层。
每个多头注意力块有三个输入：Q（请求）、K（主键）、V（数值）。这些输入经过线性（Dense）层，并分拆成多头。– <font size="4" color="red">先经过dense 层,然后再分拆层多头matrix 喂给多个head ，经过学习后这些dense网络的W_q, W_k, W_v, 其实和前面实现中的W_q, W_k, W_v是相同的作用</font></p>

<p>将上面定义的 scaled_dot_product_attention 函数应用于每个头（进行了广播（broadcasted）以提高效率）。注意力这步必须使用一个恰当的 mask。然后将每个头的注意力输出连接起来（用tf.transpose 和 tf.reshape），并放入最后的 Dense 层。</p>

<p>Q、K、和 V 被拆分到了多个头，而非单个的注意力头，因为多头允许模型共同注意来自不同表示空间的不同位置的信息。在分拆后，每个头部的维度减少，因此总的计算成本与有着全部维度的单个注意力头相同。</p>

<p><img src="/assets/2023-12-03-Transformer-learning-C5W4A1SubclassV1_files/d777e331-2ae4-48d6-8725-1975e945b192.png" alt="image.png" /></p>

<p><img src="/assets/2023-12-03-Transformer-learning-C5W4A1SubclassV1_files/23a76e89-6143-4f1b-86c1-9e5f8a52e641.png" alt="image.png" />
<img src="/assets/2023-12-03-Transformer-learning-C5W4A1SubclassV1_files/a407995b-56d9-4c42-a6d9-f1fc11c53c76.png" alt="image.png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># borrow the clip implemenation of the MultiHeadAttention to cross check 
</span><span class="k">class</span> <span class="nc">MultiheadAttention</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_ctx</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">heads</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">n_ctx</span> <span class="o">=</span> <span class="n">n_ctx</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">width</span> <span class="o">=</span> <span class="n">width</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">heads</span> <span class="o">=</span> <span class="n">heads</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">c_qkv</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">width</span><span class="p">,</span> <span class="n">width</span> <span class="o">*</span> <span class="mi">3</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">c_proj</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">width</span><span class="p">,</span> <span class="n">width</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">attention</span> <span class="o">=</span> <span class="n">QKVMultiheadAttention</span><span class="p">(</span><span class="n">heads</span><span class="p">,</span> <span class="n">n_ctx</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">c_qkv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">attention</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">c_proj</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>


<span class="k">class</span> <span class="nc">MLP</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">width</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">width</span> <span class="o">=</span> <span class="n">width</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">c_fc</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">width</span><span class="p">,</span> <span class="n">width</span> <span class="o">*</span> <span class="mi">4</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">c_proj</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">width</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span> <span class="n">width</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">gelu</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">GELU</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">c_proj</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">gelu</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">c_fc</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>


<span class="k">class</span> <span class="nc">QKVMultiheadAttention</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_heads</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">n_ctx</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">n_heads</span> <span class="o">=</span> <span class="n">n_heads</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">n_ctx</span> <span class="o">=</span> <span class="n">n_ctx</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">qkv</span><span class="p">):</span>
        <span class="c1">#get bachsize , 
</span>        <span class="n">bs</span><span class="p">,</span> <span class="n">n_ctx</span><span class="p">,</span> <span class="n">width</span> <span class="o">=</span> <span class="n">qkv</span><span class="p">.</span><span class="n">shape</span>
        <span class="n">attn_ch</span> <span class="o">=</span> <span class="n">width</span> <span class="o">//</span> <span class="bp">self</span><span class="p">.</span><span class="n">n_heads</span> <span class="o">//</span> <span class="mi">3</span>
        <span class="n">scale</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">math</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">math</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">attn_ch</span><span class="p">))</span>
        <span class="n">qkv</span> <span class="o">=</span> <span class="n">qkv</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="n">n_ctx</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">n_heads</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        
        <span class="c1">### 分拆最后q,k,v维度到 (num_heads, depth).
</span>        <span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="n">th</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="n">qkv</span><span class="p">,</span> <span class="n">attn_ch</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">weight</span> <span class="o">=</span> <span class="n">th</span><span class="p">.</span><span class="n">einsum</span><span class="p">(</span>
            <span class="s">"bthc,bshc-&gt;bhts"</span><span class="p">,</span> <span class="n">q</span> <span class="o">*</span> <span class="n">scale</span><span class="p">,</span> <span class="n">k</span> <span class="o">*</span> <span class="n">scale</span>
        <span class="p">)</span>  <span class="c1"># More stable with f16 than dividing afterwards
</span>        <span class="n">wdtype</span> <span class="o">=</span> <span class="n">weight</span><span class="p">.</span><span class="n">dtype</span>

        <span class="c1">### calucate the softmax attention
</span>        <span class="n">weight</span> <span class="o">=</span> <span class="n">th</span><span class="p">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">weight</span><span class="p">.</span><span class="nb">float</span><span class="p">(),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">).</span><span class="nb">type</span><span class="p">(</span><span class="n">wdtype</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">th</span><span class="p">.</span><span class="n">einsum</span><span class="p">(</span><span class="s">"bhts,bshc-&gt;bthc"</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">v</span><span class="p">).</span><span class="n">reshape</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="n">n_ctx</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># I borrow the another implemenation of the MultiHeadAttention to cross check 
</span><span class="k">class</span> <span class="nc">MultiHeadAttention</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Layer</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MultiHeadAttention</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">num_heads</span> <span class="o">=</span> <span class="n">num_heads</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">d_model</span> <span class="o">=</span> <span class="n">d_model</span>
        <span class="k">assert</span> <span class="n">d_model</span> <span class="o">%</span> <span class="bp">self</span><span class="p">.</span><span class="n">num_heads</span> <span class="o">==</span> <span class="mi">0</span>

        <span class="c1">## numbers heads will collapse the feature depth into heads.. such as feed features parallel to different heads so that improve the efficiency
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">depth</span> <span class="o">=</span> <span class="n">d_model</span> <span class="o">//</span> <span class="bp">self</span><span class="p">.</span><span class="n">num_heads</span> 
        
        <span class="bp">self</span><span class="p">.</span><span class="n">wq</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">wk</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">wv</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">dense</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">split_heads</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
        <span class="s">"""分拆最后一个维度到 (num_heads, depth).
        转置结果使得形状为 (batch_size, num_heads, seq_len, depth)
        """</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">depth</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">tf</span><span class="p">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">perm</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">return_attention_scores</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">shape</span><span class="p">(</span><span class="n">q</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

        <span class="n">q</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">wq</span><span class="p">(</span><span class="n">q</span><span class="p">)</span>  <span class="c1"># (batch_size, seq_len, d_model)
</span>        <span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">wk</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>  <span class="c1"># (batch_size, seq_len, d_model)
</span>        <span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">wv</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>  <span class="c1"># (batch_size, seq_len, d_model)
</span>
        <span class="n">q</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">split_heads</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>  <span class="c1"># (batch_size, num_heads, seq_len_q, depth)
</span>        <span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">split_heads</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>  <span class="c1"># (batch_size, num_heads, seq_len_k, depth)
</span>        <span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">split_heads</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>  <span class="c1"># (batch_size, num_heads, seq_len_v, depth)
</span>
        <span class="c1"># scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)
</span>        <span class="c1"># attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)
</span>        <span class="n">scaled_attention</span><span class="p">,</span> <span class="n">attention_weights</span> <span class="o">=</span> <span class="n">scaled_dot_product_attention</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>
        
        <span class="c1">#reverse the split head procedure 
</span>        <span class="n">scaled_attention</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">scaled_attention</span><span class="p">,</span> <span class="n">perm</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>  <span class="c1"># (batch_size, seq_len_q, num_heads, depth)
</span>    
        <span class="n">concat_attention</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">scaled_attention</span><span class="p">,</span> 
                                      <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">d_model</span><span class="p">))</span>  <span class="c1"># (batch_size, seq_len_q, d_model)
</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">dense</span><span class="p">(</span><span class="n">concat_attention</span><span class="p">)</span>  <span class="c1"># (batch_size, seq_len_q, d_model)
</span>        <span class="k">if</span> <span class="n">return_attention_scores</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">attention_weights</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">output</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">temp_mha</span> <span class="o">=</span> <span class="n">MultiHeadAttention</span><span class="p">(</span><span class="n">d_model</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">num_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">512</span><span class="p">))</span>  <span class="c1"># (batch_size, encoder_sequence, d_model)
</span><span class="n">out</span><span class="p">,</span> <span class="n">attn</span> <span class="o">=</span> <span class="n">temp_mha</span><span class="p">(</span><span class="n">q</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">v</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span><span class="n">return_attention_scores</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">out</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">attn</span><span class="p">.</span><span class="n">shape</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(TensorShape([1, 60, 512]), TensorShape([1, 8, 60, 60]))
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">temp_mha</span><span class="p">.</span><span class="n">num_heads</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>8
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">## if for tf , give the number_heads &gt; key_dim , how the output could be?
</span><span class="n">layer</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">MultiHeadAttention</span><span class="p">(</span><span class="n">num_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">key_dim</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="n">source</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="n">output_tensor</span><span class="p">,</span> <span class="n">weights</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">source</span><span class="p">,</span>
                               <span class="n">return_attention_scores</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">output_tensor</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">weights</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>

</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(None, 8, 4)
(None, 8, 8, 4)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#check the matrix split heads
</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">shape</span><span class="p">(</span><span class="n">y</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">depth</span> <span class="o">=</span> <span class="mi">512</span> <span class="o">//</span> <span class="mi">8</span>  <span class="c1"># numbers heads will collapse the feature depth into heads.. such as feed features parallel to different heads so that improve the efficiency
</span><span class="n">num_heads</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">wq</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">512</span><span class="p">)</span>
<span class="n">q</span> <span class="o">=</span> <span class="n">wq</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="c1">#check split heads
</span><span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">depth</span><span class="p">))</span> <span class="c1"># (batch_size, seq_len_q ,num_heads, depth)
</span><span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">perm</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span> <span class="c1"># (batch_size, num_heads, seq_len_q, depth)
</span><span class="n">x</span><span class="p">.</span><span class="n">shape</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>TensorShape([1, 8, 60, 64])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># UNQ_C4 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)
# GRADED FUNCTION EncoderLayer
</span><span class="k">class</span> <span class="nc">EncoderLayer</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Layer</span><span class="p">):</span>
    <span class="s">"""
    The encoder layer is composed by a multi-head self-attention mechanism,
    followed by a simple, positionwise fully connected feed-forward network. 
    This archirecture includes a residual connection around each of the two 
    sub-layers, followed by layer normalization.
    """</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">fully_connected_dim</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">layernorm_eps</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">EncoderLayer</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">ownMultiHead</span> <span class="o">=</span> <span class="n">ownMultiHead</span>
        
        <span class="k">if</span> <span class="p">(</span><span class="n">ownMultiHead</span><span class="o">==</span><span class="bp">False</span><span class="p">):</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">mha</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">MultiHeadAttention</span><span class="p">(</span><span class="n">num_heads</span><span class="o">=</span><span class="n">num_heads</span><span class="p">,</span>
                                          <span class="n">key_dim</span><span class="o">=</span><span class="n">embedding_dim</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">mha</span> <span class="o">=</span> <span class="n">MultiHeadAttention</span><span class="p">(</span><span class="n">embedding_dim</span><span class="p">,</span><span class="n">num_heads</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="p">.</span><span class="n">ffn</span> <span class="o">=</span> <span class="n">FullyConnected</span><span class="p">(</span><span class="n">embedding_dim</span><span class="o">=</span><span class="n">embedding_dim</span><span class="p">,</span>
                                  <span class="n">fully_connected_dim</span><span class="o">=</span><span class="n">fully_connected_dim</span><span class="p">)</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">layernorm1</span> <span class="o">=</span> <span class="n">LayerNormalization</span><span class="p">(</span><span class="n">epsilon</span><span class="o">=</span><span class="n">layernorm_eps</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">layernorm2</span> <span class="o">=</span> <span class="n">LayerNormalization</span><span class="p">(</span><span class="n">epsilon</span><span class="o">=</span><span class="n">layernorm_eps</span><span class="p">)</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">dropout1</span> <span class="o">=</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_rate</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">dropout2</span> <span class="o">=</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_rate</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="p">,</span> <span class="n">mask</span><span class="p">):</span>
        <span class="s">"""
        Forward pass for the Encoder Layer
        
        Arguments:
            x -- Tensor of shape (batch_size, input_seq_len, embedding_dim)
            training -- Boolean, set to true to activate
                        the training mode for dropout layers
            mask -- Boolean mask to ensure that the padding is not 
                    treated as part of the input
        Returns:
            out2 -- Tensor of shape (batch_size, input_seq_len, embedding_dim)
        """</span>
        <span class="c1"># START CODE HERE
</span>        <span class="c1"># calculate self-attention using mha(~1 line)
</span>        <span class="c1">#-&gt; To compute self-attention Q, V and K should be the same (x)
</span>        <span class="c1">#ztd, namely it should be different q, v and k, but it seems merged with  EmbeddingParamtersMatrix*(Embedding matrix *X)
</span>        <span class="n">self_attn_output</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">mha</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span> <span class="c1"># Self attention (batch_size, input_seq_len, embedding_dim)
</span>        
        <span class="c1"># apply dropout layer to the self-attention output (~1 line)
</span>        <span class="n">self_attn_output</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">dropout1</span><span class="p">(</span><span class="n">self_attn_output</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>
        
        <span class="c1"># apply layer normalization on sum of the input and the attention output to get the  
</span>        <span class="c1"># output of the multi-head attention layer (~1 line)
</span>        <span class="n">mult_attn_out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">layernorm1</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="n">self_attn_output</span><span class="p">)</span>  <span class="c1"># (batch_size, input_seq_len, embedding_dim)
</span>
        <span class="c1"># pass the output of the multi-head attention layer through a ffn (~1 line)
</span>        <span class="n">ffn_output</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">ffn</span><span class="p">(</span><span class="n">mult_attn_out</span><span class="p">)</span>  <span class="c1"># (batch_size, input_seq_len, embedding_dim)
</span>        
        <span class="c1"># apply dropout layer to ffn output (~1 line)
</span>        <span class="n">ffn_output</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">dropout2</span><span class="p">(</span><span class="n">ffn_output</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>
        
        <span class="c1"># apply layer normalization on sum of the output from multi-head attention and ffn output to get the
</span>        <span class="c1"># output of the encoder layer (~1 line)
</span>        <span class="n">encoder_layer_out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">layernorm2</span><span class="p">(</span><span class="n">ffn_output</span> <span class="o">+</span> <span class="n">mult_attn_out</span><span class="p">)</span>  <span class="c1"># (batch_size, input_seq_len, embedding_dim)
</span>        <span class="c1"># END CODE HERE
</span>        
        <span class="k">return</span> <span class="n">encoder_layer_out</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># UNIT TEST
</span><span class="n">ownMultiHead</span><span class="o">=</span><span class="bp">True</span>
<span class="k">def</span> <span class="nf">EncoderLayer_test</span><span class="p">(</span><span class="n">target</span><span class="p">):</span>
    <span class="n">q</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]]).</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">encoder_layer1</span> <span class="o">=</span> <span class="n">EncoderLayer</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>
    <span class="n">tf</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">encoded</span> <span class="o">=</span> <span class="n">encoder_layer1</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="bp">True</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]))</span>
    
    <span class="k">assert</span> <span class="n">tf</span><span class="p">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">encoded</span><span class="p">),</span> <span class="s">"Wrong type. Output must be a tensor"</span>
    <span class="k">assert</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">shape</span><span class="p">(</span><span class="n">encoded</span><span class="p">).</span><span class="n">numpy</span><span class="p">())</span> <span class="o">==</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">q</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">q</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]),</span> <span class="sa">f</span><span class="s">"Wrong shape. We expected ((1, </span><span class="si">{</span><span class="n">q</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s">, </span><span class="si">{</span><span class="n">q</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="si">}</span><span class="s">))"</span>
    <span class="k">print</span><span class="p">(</span><span class="n">encoded</span><span class="p">.</span><span class="n">numpy</span><span class="p">())</span>
    <span class="k">assert</span> <span class="n">np</span><span class="p">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">encoded</span><span class="p">.</span><span class="n">numpy</span><span class="p">(),</span> 
                       <span class="p">[[</span><span class="o">-</span><span class="mf">0.5214877</span> <span class="p">,</span> <span class="o">-</span><span class="mf">1.001476</span>  <span class="p">,</span> <span class="o">-</span><span class="mf">0.12321664</span><span class="p">,</span>  <span class="mf">1.6461804</span> <span class="p">],</span>
                       <span class="p">[</span><span class="o">-</span><span class="mf">1.3114998</span> <span class="p">,</span>  <span class="mf">1.2167752</span> <span class="p">,</span> <span class="o">-</span><span class="mf">0.5830886</span> <span class="p">,</span>  <span class="mf">0.6778133</span> <span class="p">],</span>
                       <span class="p">[</span> <span class="mf">0.25485858</span><span class="p">,</span>  <span class="mf">0.3776546</span> <span class="p">,</span> <span class="o">-</span><span class="mf">1.6564771</span> <span class="p">,</span>  <span class="mf">1.023964</span>  <span class="p">]],),</span> <span class="s">"Wrong values"</span>
    
    <span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\033</span><span class="s">[92mAll tests passed"</span><span class="p">)</span>
    

<span class="n">EncoderLayer_test</span><span class="p">(</span><span class="n">EncoderLayer</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[[[-0.12410855 -1.4025799   0.1106668   1.4160216 ]
  [-1.4312509  -0.02727069  0.06325354  1.3952682 ]
  [-0.0983822  -0.7909938  -0.7737439   1.6631199 ]]]



---------------------------------------------------------------------------

AssertionError                            Traceback (most recent call last)

/var/tmp/ipykernel_27065/4238340319.py in &lt;module&gt;
     18 
     19 
---&gt; 20 EncoderLayer_test(EncoderLayer)


/var/tmp/ipykernel_27065/4238340319.py in EncoderLayer_test(target)
     13                        [[-0.5214877 , -1.001476  , -0.12321664,  1.6461804 ],
     14                        [-1.3114998 ,  1.2167752 , -0.5830886 ,  0.6778133 ],
---&gt; 15                        [ 0.25485858,  0.3776546 , -1.6564771 ,  1.023964  ]],), "Wrong values"
     16 
     17     print("\033[92mAll tests passed")


AssertionError: Wrong values
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sample_encoder_layer</span> <span class="o">=</span> <span class="n">EncoderLayer</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">2048</span><span class="p">)</span> <span class="c1">#embedding_dim, num_heads, fully_connected_dim
</span><span class="n">sample_encoder_layer_output</span> <span class="o">=</span> <span class="n">sample_encoder_layer</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">64</span><span class="p">,</span> <span class="mi">43</span><span class="p">,</span> <span class="mi">512</span><span class="p">)),</span> <span class="bp">False</span><span class="p">,</span> <span class="bp">None</span><span class="p">)</span> <span class="c1">#(batch_size, input_seq_len, embedding_dim)
</span>
<span class="n">sample_encoder_layer_output</span><span class="p">.</span><span class="n">shape</span>  <span class="c1"># (batch_size, input_seq_len, d_model)
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>TensorShape([64, 43, 512])
</code></pre></div></div>

<p>不太明白这个矩阵检查的根据是什么， ingore this error firstly</p>

<p>assert np.allclose(encoded.numpy(), 
                       [[-0.5214877 , -1.001476  , -0.12321664,  1.6461804 ],
                       [-1.3114998 ,  1.2167752 , -0.5830886 ,  0.6778133 ],
                       [ 0.25485858,  0.3776546 , -1.6564771 ,  1.023964  ]],), “Wrong values”</p>

<p><a name="4-2"></a></p>
<h3 id="42---full-encoder">4.2 - Full Encoder</h3>

<p>Awesome job! You have now successfully implemented positional encoding, self-attention, and an encoder layer - give yourself a pat on the back. Now you’re ready to build the full Transformer Encoder (Figure 2b), where you will embedd your input and add the positional encodings you calculated. You will then feed your encoded embeddings to a stack of Encoder layers.</p>

<center><img src="/assets//assets/2023-12-03-Transformer-learning-C5W4A1SubclassV1_files/encoder.png" alt="Encoder" width="330" /></center>
<caption><center><font color="purple">Figure 2b: Transformer Encoder</font></center></caption>

<p><a name="ex-5"></a></p>
<h3 id="exercise-5---encoder">Exercise 5 - Encoder</h3>

<p>Complete the <code class="language-plaintext highlighter-rouge">Encoder()</code> function using the <code class="language-plaintext highlighter-rouge">call()</code> method to embed your input, add positional encoding, and implement multiple encoder layers</p>

<p>In this exercise, you will initialize your Encoder with an Embedding layer, positional encoding, and multiple EncoderLayers. Your <code class="language-plaintext highlighter-rouge">call()</code> method will perform the following steps:</p>
<ol>
  <li>Pass your input through the Embedding layer.</li>
  <li>Scale your embedding by multiplying it by the square root of your embedding dimension. Remember to cast the embedding dimension to data type <code class="language-plaintext highlighter-rouge">tf.float32</code> before computing the square root.</li>
</ol>

<p>** some dicussion about this scal square root of your embedding dimension **
    This is specified in the original Transformer paper, at the end of section 3.4:
    <img src="/assets/2023-12-03-Transformer-learning-C5W4A1SubclassV1_files/7612d8b6-3931-45a4-901e-5765642e5458.png" alt="image.png" /><br />
    <font color="red">Transcription：
    **3.4 Embeddings and Softmax**
    Similarly to other sequence transduction models, we use learned embeddings to convert the input tokens and output tokens to vectors of dimension 𝑑model. We also use the usual learned linear transformation and softmax function to convert the decoder output to predicted next-token probabilities. In our model, we share the same weight matrix between the two embedding layers and the pre-softmax linear transformation, similar to [24]. In the embedding layers, we multiply those weights by $\sqrt{𝑑_model}$</font></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>This aspect is not justified by the authors, either on the paper or anywhere else. It was specifically asked as an issue in the original implementation by Google with no response.      
    
Other implementations of the Transformer have also wondered if this was actually needed (see this, this and this).   
Some hypothesithed arguments (source) are:   
    
    It is for the sharing weight between the decoder embedding and the decoder pre-softmax linear weights.  
    It is not actually needed.  
    It is to make the positional encoding relatively smaller. This means the original meaning in the embedding vector won’t be lost when we add them together.  
    For reference, there are other StackExchange questions discussing this (see this and this).
Thank-you!! I'd also missed that multiply in my (fairseq transformer) code study, and it helps clear up a mystery that I'd noted: the (sinusoidal, non-learned) **positional embeddings are initialized with a range of -1.0 to +1.0, but the word-embeddings are initialized with a mean of 0.0 and s.d. of embedding_dim ** -0.5 (0.044 for 512, 0.03125 for 1024).**

So, on the face of it, the positional embeddings would overwhelm any signal coming from the word embeddings.

But now I can see word embeddings are scaled by math.sqrt(embed_dim) (22.6 for 512, 32 for 1024), it makes sense again.
Following the links in the other answer, it seems it is done this way &lt;font color=red&gt;**because the same embeddings can be used in other parts of the transformer model**, and that has decided the initialization values.&lt;\font&gt;
</code></pre></div></div>

<ol>
  <li>Add the position encoding: self.pos_encoding <code class="language-plaintext highlighter-rouge">[:, :seq_len, :]</code> to your embedding.</li>
  <li>
    <p>Pass the encoded embedding through a dropout layer, remembering to use the <code class="language-plaintext highlighter-rouge">training</code> parameter to set the model training mode.</p>

    <p>https://discuss.pytorch.org/t/why-use-dropout-in-positional-encoding-layer/159923/6    <br />
Dropout is a type of regularization. The final embedding for each token that you use (for the transformer) is a sum of positional and standard embeddings and then they apply dropout to that sum. So dropout is applied to the sum of the standard embedding and the positional embedding, not just the (constant) positional embedding. This sum is then an embedding, a bunch of parameters, and dropout is used to regularize as is usual. 
usually the “embedding” of a word is the embedding that’s used for that token. In this case, <font color="red">**the embedding is the parametric embedding + the constant positional encoding**</font>. When you apply dropout to a neuron, you kill the entire neuron. So if you have a sequence of length 10 and each token has 512 dimensional vectors, you kill on average 60% of the neurons in the 10 by 512 matrix that represents the data. If you only did this to the parametric embeddings and not the positional ones, you would not kill a neuron, you’d leave in its positional information, so it’s not really dropout.</p>
  </li>
  <li>Pass the output of the dropout layer through the stack of encoding layers using a for loop.</li>
</ol>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="mi">1024</span><span class="o">**</span><span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0.03125
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="c1"># UNQ_C5 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)
# GRADED FUNCTION
</span><span class="k">class</span> <span class="nc">Encoder</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Layer</span><span class="p">):</span>
    <span class="s">"""
    The entire Encoder starts by passing the input to an embedding layer 
    and using positional encoding to then pass the output through a stack of
    encoder Layers
        
    """</span>   
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">fully_connected_dim</span><span class="p">,</span> <span class="n">input_vocab_size</span><span class="p">,</span>
               <span class="n">maximum_position_encoding</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">layernorm_eps</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Encoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">embedding_dim</span> <span class="o">=</span> <span class="n">embedding_dim</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">num_layers</span> <span class="o">=</span> <span class="n">num_layers</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">Embedding</span><span class="p">(</span><span class="n">input_vocab_size</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">embedding_dim</span><span class="p">)</span> <span class="c1">#tensorflow Embedding function generate embedding matrix
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">pos_encoding</span> <span class="o">=</span> <span class="n">positional_encoding</span><span class="p">(</span><span class="n">maximum_position_encoding</span><span class="p">,</span>  <span class="c1">#generate the postion encoding matrix
</span>                                                <span class="bp">self</span><span class="p">.</span><span class="n">embedding_dim</span><span class="p">)</span>

        <span class="c1">#init EncoderLayer 
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">enc_layers</span> <span class="o">=</span> <span class="p">[</span><span class="n">EncoderLayer</span><span class="p">(</span><span class="n">embedding_dim</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">embedding_dim</span><span class="p">,</span>
                                        <span class="n">num_heads</span><span class="o">=</span><span class="n">num_heads</span><span class="p">,</span>
                                        <span class="n">fully_connected_dim</span><span class="o">=</span><span class="n">fully_connected_dim</span><span class="p">,</span>
                                        <span class="n">dropout_rate</span><span class="o">=</span><span class="n">dropout_rate</span><span class="p">,</span>
                                        <span class="n">layernorm_eps</span><span class="o">=</span><span class="n">layernorm_eps</span><span class="p">)</span> 
                           <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">num_layers</span><span class="p">)]</span>
    
        <span class="bp">self</span><span class="p">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_rate</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="p">,</span> <span class="n">mask</span><span class="p">):</span>
        <span class="s">"""
        Forward pass for the Encoder
        
        Arguments:
            x -- Tensor of shape (batch_size, input_seq_len)
            training -- Boolean, set to true to activate
                        the training mode for dropout layers
            mask -- Boolean mask to ensure that the padding is not 
                    treated as part of the input
        Returns:
            out2 -- Tensor of shape (batch_size, input_seq_len, embedding_dim)
        """</span>

        <span class="n">seq_len</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
        
        <span class="c1"># START CODE HERE
</span>        <span class="c1"># Pass input through the Embedding layer
</span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># (batch_size, input_seq_len, embedding_dim)
</span>        <span class="c1"># Scale embedding by multiplying it by the square root of the embedding dimension
</span>        <span class="n">x</span> <span class="o">*=</span> <span class="n">tf</span><span class="p">.</span><span class="n">math</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">cast</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">embedding_dim</span><span class="p">,</span><span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">))</span>
        <span class="c1"># Add the position encoding to embedding
</span>        <span class="n">x</span> <span class="o">+=</span> <span class="bp">self</span><span class="p">.</span><span class="n">pos_encoding</span><span class="p">[:,</span> <span class="p">:</span><span class="n">seq_len</span><span class="p">,</span> <span class="p">:]</span>
        <span class="c1"># Pass the encoded embedding through a dropout layer
</span>        <span class="c1"># why we first have one dropout layer ???
</span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>
        <span class="c1"># Pass the output through the stack of encoding layers 
</span>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">num_layers</span><span class="p">):</span>
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">enc_layers</span><span class="p">[</span><span class="n">i</span><span class="p">](</span><span class="n">x</span><span class="p">,</span><span class="n">training</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>
        <span class="c1"># END CODE HERE
</span>        <span class="c1">#Embedding layer also include FFN (feed forward network) +  dropout layer + normalize layer
</span>        <span class="c1">#the output is (batch_size, input_seq_len, embedding_dim) same as input
</span>
        <span class="k">return</span> <span class="n">x</span>  <span class="c1"># (batch_size, input_seq_len, embedding_dim)
</span></code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># UNIT TEST
</span><span class="k">def</span> <span class="nf">Encoder_test</span><span class="p">(</span><span class="n">target</span><span class="p">):</span>
    <span class="n">tf</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
    
    <span class="n">embedding_dim</span><span class="o">=</span><span class="mi">4</span>
    
    <span class="n">encoderq</span> <span class="o">=</span> <span class="n">target</span><span class="p">(</span><span class="n">num_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                      <span class="n">embedding_dim</span><span class="o">=</span><span class="n">embedding_dim</span><span class="p">,</span>
                      <span class="n">num_heads</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                      <span class="n">fully_connected_dim</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
                      <span class="n">input_vocab_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
                      <span class="n">maximum_position_encoding</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
    
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
    
    <span class="n">encoderq_output</span> <span class="o">=</span> <span class="n">encoderq</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">True</span><span class="p">,</span> <span class="bp">None</span><span class="p">)</span>
    
    <span class="k">assert</span> <span class="n">tf</span><span class="p">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">encoderq_output</span><span class="p">),</span> <span class="s">"Wrong type. Output must be a tensor"</span>
    <span class="k">assert</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">shape</span><span class="p">(</span><span class="n">encoderq_output</span><span class="p">).</span><span class="n">numpy</span><span class="p">())</span> <span class="o">==</span> <span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">embedding_dim</span><span class="p">),</span> <span class="sa">f</span><span class="s">"Wrong shape. We expected (</span><span class="si">{</span><span class="n">eshape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s">, </span><span class="si">{</span><span class="n">eshape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s">, </span><span class="si">{</span><span class="n">embedding_dim</span><span class="si">}</span><span class="s">)"</span>
    <span class="k">assert</span> <span class="n">np</span><span class="p">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">encoderq_output</span><span class="p">.</span><span class="n">numpy</span><span class="p">(),</span> 
                       <span class="p">[[[</span><span class="o">-</span><span class="mf">0.40172306</span><span class="p">,</span>  <span class="mf">0.11519244</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.2322885</span><span class="p">,</span>   <span class="mf">1.5188192</span> <span class="p">],</span>
                         <span class="p">[</span> <span class="mf">0.4017268</span><span class="p">,</span>   <span class="mf">0.33922842</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.6836855</span><span class="p">,</span>   <span class="mf">0.9427304</span> <span class="p">],</span>
                         <span class="p">[</span> <span class="mf">0.4685002</span><span class="p">,</span>  <span class="o">-</span><span class="mf">1.6252842</span><span class="p">,</span>   <span class="mf">0.09368491</span><span class="p">,</span>  <span class="mf">1.063099</span>  <span class="p">]],</span>
                        <span class="p">[[</span><span class="o">-</span><span class="mf">0.3489219</span><span class="p">,</span>   <span class="mf">0.31335592</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.3568854</span><span class="p">,</span>   <span class="mf">1.3924513</span> <span class="p">],</span>
                         <span class="p">[</span><span class="o">-</span><span class="mf">0.08761203</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1680029</span><span class="p">,</span>  <span class="o">-</span><span class="mf">1.2742313</span><span class="p">,</span>   <span class="mf">1.5298463</span> <span class="p">],</span>
                         <span class="p">[</span> <span class="mf">0.2627198</span><span class="p">,</span>  <span class="o">-</span><span class="mf">1.6140151</span><span class="p">,</span>   <span class="mf">0.2212624</span> <span class="p">,</span>  <span class="mf">1.130033</span>  <span class="p">]]]),</span> <span class="s">"Wrong values"</span>
    
    <span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\033</span><span class="s">[92mAll tests passed"</span><span class="p">)</span>
    
<span class="n">Encoder_test</span><span class="p">(</span><span class="n">Encoder</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>---------------------------------------------------------------------------

AssertionError                            Traceback (most recent call last)

/var/tmp/ipykernel_27065/2836601725.py in &lt;module&gt;
     28     print("\033[92mAll tests passed")
     29 
---&gt; 30 Encoder_test(Encoder)


/var/tmp/ipykernel_27065/2836601725.py in Encoder_test(target)
     24                         [[-0.3489219,   0.31335592, -1.3568854,   1.3924513 ],
     25                          [-0.08761203, -0.1680029,  -1.2742313,   1.5298463 ],
---&gt; 26                          [ 0.2627198,  -1.6140151,   0.2212624 ,  1.130033  ]]]), "Wrong values"
     27 
     28     print("\033[92mAll tests passed")


AssertionError: Wrong values
</code></pre></div></div>

<p><a name="5"></a></p>
<h2 id="5---decoder">5 - Decoder</h2>

<p>The Decoder layer takes the K and V matrices generated by the Encoder and in computes the second multi-head attention layer with the Q matrix from the output (Figure 3a).</p>

<center><img src="/assets//assets/2023-12-03-Transformer-learning-C5W4A1SubclassV1_files/decoder_layer.png" alt="Encoder" width="250" class="centerImage" /></center>
<caption><center><font color="purple">Figure 3a: Transformer Decoder layer</font></center></caption>

<p><a name="5-1"></a></p>
<h3 id="51---decoder-layer">5.1 - Decoder Layer</h3>
<p>Again, you’ll pair multi-head attention with a feed forward neural network, but this time you’ll implement two multi-head attention layers. You will also use residual connections and layer normalization to help speed up training (Figure 3a).</p>

<p><a name="ex-6"></a></p>
<h3 id="exercise-6---decoderlayer-include-ffndropoutnormlize-layer">Exercise 6 - DecoderLayer (include FFN+dropout+normlize layer)</h3>

<p>Implement <code class="language-plaintext highlighter-rouge">DecoderLayer()</code> using the <code class="language-plaintext highlighter-rouge">call()</code> method</p>

<ol>
  <li>Block 1 is a multi-head attention layer with a residual connection, dropout layer, and look-ahead mask.</li>
  <li>Block 2 will take into account the output of the Encoder, so the multi-head attention layer will receive K and V from the encoder, and Q from the Block 1. You will then apply a dropout layer, layer normalization and a residual connection, just like you’ve done before.</li>
  <li>Finally, Block 3 is a feed forward neural network with dropout and normalization layers and a residual connection.</li>
</ol>

<p><strong>Additional Hints:</strong></p>
<ul>
  <li>The first two blocks are fairly similar to the EncoderLayer except you will return <code class="language-plaintext highlighter-rouge">attention_scores</code> when computing self-attention</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># UNQ_C6 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)
# GRADED FUNCTION DecoderLayer
</span><span class="k">class</span> <span class="nc">DecoderLayer</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Layer</span><span class="p">):</span>
    <span class="s">"""
    The decoder layer is composed by two multi-head attention blocks, 
    one that takes the new input and uses self-attention, and the other 
    one that combines it with the output of the encoder, followed by a
    fully connected block. 
    """</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">fully_connected_dim</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">layernorm_eps</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">DecoderLayer</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>

        <span class="k">if</span> <span class="p">(</span><span class="n">ownMultiHead</span><span class="o">==</span><span class="bp">False</span><span class="p">):</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">mha1</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">MultiHeadAttention</span><span class="p">(</span><span class="n">num_heads</span><span class="o">=</span><span class="n">num_heads</span><span class="p">,</span>
                                          <span class="n">key_dim</span><span class="o">=</span><span class="n">embedding_dim</span><span class="p">)</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">mha2</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">MultiHeadAttention</span><span class="p">(</span><span class="n">num_heads</span><span class="o">=</span><span class="n">num_heads</span><span class="p">,</span>
                                          <span class="n">key_dim</span><span class="o">=</span><span class="n">embedding_dim</span><span class="p">)</span>            
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">mha1</span> <span class="o">=</span> <span class="n">MultiHeadAttention</span><span class="p">(</span><span class="n">embedding_dim</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">)</span> <span class="c1"># there are own wq1, wk1, wv1 for multihead 1
</span>            <span class="bp">self</span><span class="p">.</span><span class="n">mha2</span> <span class="o">=</span> <span class="n">MultiHeadAttention</span><span class="p">(</span><span class="n">embedding_dim</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">)</span> <span class="c1"># there are own wq2, wk2, wv2 for multihead 2
</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">ffn</span> <span class="o">=</span> <span class="n">FullyConnected</span><span class="p">(</span><span class="n">embedding_dim</span><span class="o">=</span><span class="n">embedding_dim</span><span class="p">,</span>
                                  <span class="n">fully_connected_dim</span><span class="o">=</span><span class="n">fully_connected_dim</span><span class="p">)</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">layernorm1</span> <span class="o">=</span> <span class="n">LayerNormalization</span><span class="p">(</span><span class="n">epsilon</span><span class="o">=</span><span class="n">layernorm_eps</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">layernorm2</span> <span class="o">=</span> <span class="n">LayerNormalization</span><span class="p">(</span><span class="n">epsilon</span><span class="o">=</span><span class="n">layernorm_eps</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">layernorm3</span> <span class="o">=</span> <span class="n">LayerNormalization</span><span class="p">(</span><span class="n">epsilon</span><span class="o">=</span><span class="n">layernorm_eps</span><span class="p">)</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">dropout1</span> <span class="o">=</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_rate</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">dropout2</span> <span class="o">=</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_rate</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">dropout3</span> <span class="o">=</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_rate</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">enc_output</span><span class="p">,</span> <span class="n">training</span><span class="p">,</span> <span class="n">look_ahead_mask</span><span class="p">,</span> <span class="n">padding_mask</span><span class="p">):</span>
        <span class="s">"""
        Forward pass for the Decoder Layer
        
        Arguments:
            x -- Tensor of shape (batch_size, target_seq_len, embedding_dim)
            enc_output --  Tensor of shape(batch_size, input_seq_len, embedding_dim)
            training -- Boolean, set to true to activate
                        the training mode for dropout layers
            look_ahead_mask -- Boolean mask for the target_input
            padding_mask -- Boolean mask for the second multihead attention layer
        Returns:
            out3 -- Tensor of shape (batch_size, target_seq_len, embedding_dim)
            attn_weights_block1 -- Tensor of shape(batch_size, num_heads, target_seq_len, input_seq_len)
            attn_weights_block2 -- Tensor of shape(batch_size, num_heads, target_seq_len, input_seq_len)
        """</span>
        
        <span class="c1"># START CODE HERE
</span>        <span class="c1"># enc_output.shape == (batch_size, input_seq_len, embedding_dim)
</span>        
        <span class="c1"># BLOCK 1
</span>        <span class="c1"># calculate self-attention and return attention scores as attn_weights_block1 (~1 line)
</span>        <span class="c1"># decode first mh use x as input + look_ahead_mask
</span>        <span class="n">attn1</span><span class="p">,</span> <span class="n">attn_weights_block1</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">mha1</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span><span class="n">look_ahead_mask</span><span class="p">,</span> <span class="n">return_attention_scores</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>  <span class="c1"># (batch_size, target_seq_len, d_model)
</span>        
        <span class="c1"># apply dropout layer on the attention output (~1 line)
</span>        <span class="n">attn1</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">dropout1</span><span class="p">(</span><span class="n">attn1</span><span class="p">,</span> <span class="n">training</span> <span class="o">=</span> <span class="n">training</span><span class="p">)</span>
        
        <span class="c1"># apply layer normalization to the sum of the attention output and the input (~1 line)
</span>        <span class="n">out1</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">layernorm1</span><span class="p">(</span><span class="n">attn1</span> <span class="o">+</span> <span class="n">x</span><span class="p">)</span>

        <span class="c1"># BLOCK 2
</span>        <span class="c1"># calculate self-attention using the Q from the first block and K and V from the encoder output.  so , K V is same from the output??
</span>        <span class="c1"># MultiHeadAttention's call takes input (Query, Value, Key, attention_mask, return_attention_scores, training)
</span>        <span class="c1"># Return attention scores as attn_weights_block2 (~1 line)
</span>        <span class="n">attn2</span><span class="p">,</span> <span class="n">attn_weights_block2</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">mha2</span><span class="p">(</span> <span class="n">out1</span><span class="p">,</span><span class="n">enc_output</span><span class="p">,</span> <span class="n">enc_output</span><span class="p">,</span> <span class="n">padding_mask</span><span class="p">,</span> <span class="n">return_attention_scores</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>  <span class="c1"># (batch_size, target_seq_len, d_model)
</span>        
        <span class="c1"># apply dropout layer on the attention output (~1 line)
</span>        <span class="n">attn2</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">dropout2</span><span class="p">(</span><span class="n">attn2</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>
        
        <span class="c1"># apply layer normalization to the sum of the attention output and the output of the first block (~1 line)
</span>        <span class="n">out2</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">layernorm2</span><span class="p">(</span><span class="n">attn2</span> <span class="o">+</span> <span class="n">out1</span><span class="p">)</span>  <span class="c1"># (batch_size, target_seq_len, embedding_dim)
</span>        
        <span class="c1">#BLOCK 3
</span>        <span class="c1"># pass the output of the second block through a ffn
</span>        <span class="n">ffn_output</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">ffn</span><span class="p">(</span><span class="n">out2</span><span class="p">)</span> <span class="c1"># (batch_size, target_seq_len, embedding_dim)
</span>        
        <span class="c1"># apply a dropout layer to the ffn output
</span>        <span class="n">ffn_output</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">dropout3</span><span class="p">(</span><span class="n">ffn_output</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>
        
        <span class="c1"># apply layer normalization to the sum of the ffn output and the output of the second block
</span>        <span class="n">out3</span> <span class="o">=</span>  <span class="bp">self</span><span class="p">.</span><span class="n">layernorm3</span><span class="p">(</span><span class="n">ffn_output</span> <span class="o">+</span> <span class="n">out2</span><span class="p">)</span> <span class="c1"># (batch_size, target_seq_len, embedding_dim)
</span>        <span class="c1"># END CODE HERE
</span>
        <span class="k">return</span> <span class="n">out3</span><span class="p">,</span> <span class="n">attn_weights_block1</span><span class="p">,</span> <span class="n">attn_weights_block2</span>
    
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># UNIT TEST
</span><span class="n">ownMultiHead</span><span class="o">=</span><span class="bp">True</span>
<span class="k">def</span> <span class="nf">DecoderLayer_test</span><span class="p">(</span><span class="n">target</span><span class="p">):</span>
    
    <span class="n">num_heads</span><span class="o">=</span><span class="mi">2</span>  <span class="c1"># change to smaller number than embedding_dim
</span>    <span class="n">tf</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
    
    <span class="n">decoderLayerq</span> <span class="o">=</span> <span class="n">target</span><span class="p">(</span>
        <span class="n">embedding_dim</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> 
        <span class="n">num_heads</span><span class="o">=</span><span class="n">num_heads</span><span class="p">,</span>
        <span class="n">fully_connected_dim</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> 
        <span class="n">dropout_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> 
        <span class="n">layernorm_eps</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">)</span>
    
    <span class="n">encoderq_output</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">constant</span><span class="p">([[[</span><span class="o">-</span><span class="mf">0.40172306</span><span class="p">,</span>  <span class="mf">0.11519244</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.2322885</span><span class="p">,</span>   <span class="mf">1.5188192</span> <span class="p">],</span>
                                   <span class="p">[</span> <span class="mf">0.4017268</span><span class="p">,</span>   <span class="mf">0.33922842</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.6836855</span><span class="p">,</span>   <span class="mf">0.9427304</span> <span class="p">],</span>
                                   <span class="p">[</span> <span class="mf">0.4685002</span><span class="p">,</span>  <span class="o">-</span><span class="mf">1.6252842</span><span class="p">,</span>   <span class="mf">0.09368491</span><span class="p">,</span>  <span class="mf">1.063099</span>  <span class="p">]]])</span>
    
    <span class="n">q</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]]).</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
    
    <span class="n">look_ahead_mask</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">constant</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
                       <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
                       <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]])</span>
    
    <span class="n">padding_mask</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="n">out</span><span class="p">,</span> <span class="n">attn_w_b1</span><span class="p">,</span> <span class="n">attn_w_b2</span> <span class="o">=</span> <span class="n">decoderLayerq</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">encoderq_output</span><span class="p">,</span> <span class="bp">True</span><span class="p">,</span> <span class="n">look_ahead_mask</span><span class="p">,</span> <span class="n">padding_mask</span><span class="p">)</span>
    
    <span class="k">assert</span> <span class="n">tf</span><span class="p">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">attn_w_b1</span><span class="p">),</span> <span class="s">"Wrong type for attn_w_b1. Output must be a tensor"</span>
    <span class="k">assert</span> <span class="n">tf</span><span class="p">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">attn_w_b2</span><span class="p">),</span> <span class="s">"Wrong type for attn_w_b2. Output must be a tensor"</span>
    <span class="k">assert</span> <span class="n">tf</span><span class="p">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">out</span><span class="p">),</span> <span class="s">"Wrong type for out. Output must be a tensor"</span>
    
    <span class="n">shape1</span> <span class="o">=</span> <span class="p">(</span><span class="n">q</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">q</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">q</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">assert</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">shape</span><span class="p">(</span><span class="n">attn_w_b1</span><span class="p">).</span><span class="n">numpy</span><span class="p">())</span> <span class="o">==</span> <span class="n">shape1</span><span class="p">,</span> <span class="sa">f</span><span class="s">"Wrong shape. We expected </span><span class="si">{</span><span class="n">shape1</span><span class="si">}</span><span class="s">"</span>
    <span class="k">assert</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">shape</span><span class="p">(</span><span class="n">attn_w_b2</span><span class="p">).</span><span class="n">numpy</span><span class="p">())</span> <span class="o">==</span> <span class="n">shape1</span><span class="p">,</span> <span class="sa">f</span><span class="s">"Wrong shape. We expected </span><span class="si">{</span><span class="n">shape1</span><span class="si">}</span><span class="s">"</span>
    <span class="k">assert</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">shape</span><span class="p">(</span><span class="n">out</span><span class="p">).</span><span class="n">numpy</span><span class="p">())</span> <span class="o">==</span> <span class="n">q</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="sa">f</span><span class="s">"Wrong shape. We expected </span><span class="si">{</span><span class="n">q</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="s">"</span>

    <span class="k">assert</span> <span class="n">np</span><span class="p">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">attn_w_b1</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.5271505</span><span class="p">,</span>  <span class="mf">0.47284946</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span> <span class="n">atol</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">),</span> <span class="s">"Wrong values in attn_w_b1. Check the call to self.mha1"</span>
    <span class="k">assert</span> <span class="n">np</span><span class="p">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">attn_w_b2</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.33365652</span><span class="p">,</span> <span class="mf">0.32598493</span><span class="p">,</span> <span class="mf">0.34035856</span><span class="p">]),</span>  <span class="s">"Wrong values in attn_w_b2. Check the call to self.mha2"</span>
    <span class="k">assert</span> <span class="n">np</span><span class="p">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.04726627</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.6235218</span><span class="p">,</span> <span class="mf">1.0327158</span><span class="p">,</span> <span class="mf">0.54353976</span><span class="p">]),</span> <span class="s">"Wrong values in out"</span>
    

    <span class="c1"># Now let's try a example with padding mask
</span>    <span class="n">padding_mask</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
    <span class="n">out</span><span class="p">,</span> <span class="n">attn_w_b1</span><span class="p">,</span> <span class="n">attn_w_b2</span> <span class="o">=</span> <span class="n">decoderLayerq</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">encoderq_output</span><span class="p">,</span> <span class="bp">True</span><span class="p">,</span> <span class="n">look_ahead_mask</span><span class="p">,</span> <span class="n">padding_mask</span><span class="p">)</span>

    <span class="k">assert</span> <span class="n">np</span><span class="p">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mf">0.34323323</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.4689083</span><span class="p">,</span> <span class="mf">1.1092525</span><span class="p">,</span> <span class="mf">0.7028891</span><span class="p">]),</span> <span class="s">"Wrong values in out when we mask the last word. Are you passing the padding_mask to the inner functions?"</span>

    <span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\033</span><span class="s">[92mAll tests passed"</span><span class="p">)</span>
    
<span class="n">DecoderLayer_test</span><span class="p">(</span><span class="n">DecoderLayer</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>---------------------------------------------------------------------------

AssertionError                            Traceback (most recent call last)

/var/tmp/ipykernel_27065/3323492748.py in &lt;module&gt;
     48     print("\033[92mAll tests passed")
     49 
---&gt; 50 DecoderLayer_test(DecoderLayer)


/var/tmp/ipykernel_27065/3323492748.py in DecoderLayer_test(target)
     35     assert tuple(tf.shape(out).numpy()) == q.shape, f"Wrong shape. We expected {q.shape}"
     36 
---&gt; 37     assert np.allclose(attn_w_b1[0, 0, 1], [0.5271505,  0.47284946, 0.], atol=1e-2), "Wrong values in attn_w_b1. Check the call to self.mha1"
     38     assert np.allclose(attn_w_b2[0, 0, 1], [0.33365652, 0.32598493, 0.34035856]),  "Wrong values in attn_w_b2. Check the call to self.mha2"
     39     assert np.allclose(out[0, 0], [0.04726627, -1.6235218, 1.0327158, 0.54353976]), "Wrong values in out"


AssertionError: Wrong values in attn_w_b1. Check the call to self.mha1
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sample_encoder_layer_output</span><span class="p">.</span><span class="n">shape</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>TensorShape([64, 43, 512])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sample_decoder_layer</span> <span class="o">=</span> <span class="n">DecoderLayer</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">2048</span><span class="p">)</span>
<span class="n">sample_decoder_layer_output</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">sample_decoder_layer</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">64</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">512</span><span class="p">)),</span> <span class="n">sample_encoder_layer_output</span><span class="p">,</span> 
    <span class="bp">False</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">)</span>

<span class="n">sample_decoder_layer_output</span><span class="p">.</span><span class="n">shape</span>  <span class="c1"># (batch_size, target_seq_len, d_model)
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>TensorShape([64, 50, 512])
</code></pre></div></div>

<p><a name="5-2"></a></p>
<h3 id="52---full-decoder">5.2 - Full Decoder</h3>
<p>You’re almost there! Time to use your Decoder layer to build a full Transformer Decoder (Figure 3b). You will embedd your output and add positional encodings. You will then feed your encoded embeddings to a stack of Decoder layers.</p>

<p><img src="/assets/2023-12-03-Transformer-learning-C5W4A1SubclassV1_files/4733f7c9-6d0c-4872-a73e-d0b4e937639d.png" alt="image.png" /></p>
<center><img src="/assets//assets/2023-12-03-Transformer-learning-C5W4A1SubclassV1_files/decoder.png" alt="Encoder" width="300" /></center>
<caption><center><font color="purple">Figure 3b: Transformer Decoder&lt;/b&gt;</font></center></caption>

<p><a name="ex-7"></a></p>
<h3 id="exercise-7---decoder">Exercise 7 - Decoder</h3>

<p>Implement <code class="language-plaintext highlighter-rouge">Decoder()</code> using the <code class="language-plaintext highlighter-rouge">call()</code> method to embed your output, add positional encoding, and implement multiple decoder layers</p>

<p>In this exercise, you will initialize your Decoder with an Embedding layer, positional encoding, and multiple DecoderLayers. Your <code class="language-plaintext highlighter-rouge">call()</code> method will perform the following steps:</p>
<ol>
  <li>Pass your generated output through the Embedding layer.</li>
  <li>Scale your embedding by multiplying it by the square root of your embedding dimension. Remember to cast the embedding dimension to data type <code class="language-plaintext highlighter-rouge">tf.float32</code> before computing the square root.</li>
  <li>Add the position encoding: self.pos_encoding <code class="language-plaintext highlighter-rouge">[:, :seq_len, :]</code> to your embedding.</li>
  <li>Pass the encoded embedding through a dropout layer, remembering to use the <code class="language-plaintext highlighter-rouge">training</code> parameter to set the model training mode.</li>
  <li>Pass the output of the dropout layer through the stack of Decoding layers using a for loop.</li>
</ol>

<p>解码器包括：</p>

<ul>
  <li>输出嵌入（Output Embedding）</li>
  <li>位置编码（Positional Encoding）</li>
  <li>N 个解码器层（decoder layers）
目标（target）经过一个嵌入后，该嵌入和位置编码相加。该加法结果是解码器层的输入。解码器的输出是最后的线性层的输入。</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># UNQ_C7 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)
# GRADED FUNCTION Decoder
</span><span class="k">class</span> <span class="nc">Decoder</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Layer</span><span class="p">):</span>
    <span class="s">"""
    The entire Encoder is starts by passing the target input to an embedding layer 
    and using positional encoding to then pass the output through a stack of
    decoder Layers
        
    """</span> 
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">fully_connected_dim</span><span class="p">,</span> <span class="n">target_vocab_size</span><span class="p">,</span>
               <span class="n">maximum_position_encoding</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">layernorm_eps</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Decoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">embedding_dim</span> <span class="o">=</span> <span class="n">embedding_dim</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">num_layers</span> <span class="o">=</span> <span class="n">num_layers</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">Embedding</span><span class="p">(</span><span class="n">target_vocab_size</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">embedding_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">pos_encoding</span> <span class="o">=</span> <span class="n">positional_encoding</span><span class="p">(</span><span class="n">maximum_position_encoding</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">embedding_dim</span><span class="p">)</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">dec_layers</span> <span class="o">=</span> <span class="p">[</span><span class="n">DecoderLayer</span><span class="p">(</span><span class="n">embedding_dim</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">embedding_dim</span><span class="p">,</span>
                                        <span class="n">num_heads</span><span class="o">=</span><span class="n">num_heads</span><span class="p">,</span>
                                        <span class="n">fully_connected_dim</span><span class="o">=</span><span class="n">fully_connected_dim</span><span class="p">,</span>
                                        <span class="n">dropout_rate</span><span class="o">=</span><span class="n">dropout_rate</span><span class="p">,</span>
                                        <span class="n">layernorm_eps</span><span class="o">=</span><span class="n">layernorm_eps</span><span class="p">)</span> 
                           <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">num_layers</span><span class="p">)]</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">dropout_rate</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">enc_output</span><span class="p">,</span> <span class="n">training</span><span class="p">,</span> 
           <span class="n">look_ahead_mask</span><span class="p">,</span> <span class="n">padding_mask</span><span class="p">):</span>
        <span class="s">"""
        Forward  pass for the Decoder
        
        Arguments:
            x -- Tensor of shape (batch_size, target_seq_len, embedding_dim)
            enc_output --  Tensor of shape(batch_size, input_seq_len, embedding_dim)
            training -- Boolean, set to true to activate
                        the training mode for dropout layers
            look_ahead_mask -- Boolean mask for the target_input
            padding_mask -- Boolean mask for the second multihead attention layer
        Returns:
            x -- Tensor of shape (batch_size, target_seq_len, embedding_dim)
            attention_weights - Dictionary of tensors containing all the attention weights
                                each of shape Tensor of shape (batch_size, num_heads, target_seq_len, input_seq_len)
        """</span>

        <span class="n">seq_len</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">attention_weights</span> <span class="o">=</span> <span class="p">{}</span>
        
        <span class="c1"># START CODE HERE
</span>        <span class="c1"># create word embeddings 
</span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># (batch_size, target_seq_len, embedding_dim)
</span>        
        <span class="c1"># scale embeddings by multiplying by the square root of their dimension
</span>        <span class="n">x</span> <span class="o">*=</span> <span class="n">tf</span><span class="p">.</span><span class="n">math</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">cast</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">embedding_dim</span><span class="p">,</span> <span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">))</span>
        
        <span class="c1"># calculate positional encodings and add to word embedding
</span>        <span class="n">x</span> <span class="o">+=</span> <span class="bp">self</span><span class="p">.</span><span class="n">pos_encoding</span><span class="p">[:,</span> <span class="p">:</span><span class="n">seq_len</span><span class="p">,</span> <span class="p">:]</span>
        
        <span class="c1"># apply a dropout layer to x
</span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>

        <span class="c1"># use a for loop to pass x through a stack of decoder layers and update attention_weights (~4 lines total)
</span>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">num_layers</span><span class="p">):</span>
            <span class="c1"># pass x and the encoder output through a stack of decoder layers and save the attention weights
</span>            <span class="c1"># of block 1 and 2 (~1 line)
</span>            <span class="c1">#the layer(i) mh2's output will be the layer(i+1)'s input x
</span>            <span class="n">x</span><span class="p">,</span> <span class="n">block1</span><span class="p">,</span> <span class="n">block2</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">dec_layers</span><span class="p">[</span><span class="n">i</span><span class="p">](</span><span class="n">x</span><span class="p">,</span> <span class="n">enc_output</span><span class="p">,</span> <span class="n">training</span><span class="p">,</span> <span class="n">look_ahead_mask</span><span class="p">,</span> <span class="n">padding_mask</span><span class="p">)</span>

            <span class="c1">#update/store attention_weights dictionary with the attention weights of block 1 and block 2
</span>            <span class="n">attention_weights</span><span class="p">[</span><span class="s">'decoder_layer{}_block1_self_att'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span> <span class="o">=</span> <span class="n">block1</span>
            <span class="n">attention_weights</span><span class="p">[</span><span class="s">'decoder_layer{}_block2_decenc_att'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span> <span class="o">=</span> <span class="n">block2</span>
        <span class="c1"># END CODE HERE
</span>        
        <span class="c1"># x.shape == (batch_size, target_seq_len, embedding_dim)
</span>        <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">attention_weights</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># UNIT TEST
</span><span class="k">def</span> <span class="nf">Decoder_test</span><span class="p">(</span><span class="n">target</span><span class="p">):</span>
    
    <span class="n">tf</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
        
    <span class="n">num_layers</span><span class="o">=</span><span class="mi">7</span>
    <span class="n">embedding_dim</span><span class="o">=</span><span class="mi">4</span> 
    <span class="n">num_heads</span><span class="o">=</span><span class="mi">2</span>
    <span class="n">fully_connected_dim</span><span class="o">=</span><span class="mi">8</span>
    <span class="n">target_vocab_size</span><span class="o">=</span><span class="mi">33</span>
    <span class="n">maximum_position_encoding</span><span class="o">=</span><span class="mi">6</span>
    
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>

    
    <span class="n">encoderq_output</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">constant</span><span class="p">([[[</span><span class="o">-</span><span class="mf">0.40172306</span><span class="p">,</span>  <span class="mf">0.11519244</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.2322885</span><span class="p">,</span>   <span class="mf">1.5188192</span> <span class="p">],</span>
                         <span class="p">[</span> <span class="mf">0.4017268</span><span class="p">,</span>   <span class="mf">0.33922842</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.6836855</span><span class="p">,</span>   <span class="mf">0.9427304</span> <span class="p">],</span>
                         <span class="p">[</span> <span class="mf">0.4685002</span><span class="p">,</span>  <span class="o">-</span><span class="mf">1.6252842</span><span class="p">,</span>   <span class="mf">0.09368491</span><span class="p">,</span>  <span class="mf">1.063099</span>  <span class="p">]],</span>
                        <span class="p">[[</span><span class="o">-</span><span class="mf">0.3489219</span><span class="p">,</span>   <span class="mf">0.31335592</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.3568854</span><span class="p">,</span>   <span class="mf">1.3924513</span> <span class="p">],</span>
                         <span class="p">[</span><span class="o">-</span><span class="mf">0.08761203</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1680029</span><span class="p">,</span>  <span class="o">-</span><span class="mf">1.2742313</span><span class="p">,</span>   <span class="mf">1.5298463</span> <span class="p">],</span>
                         <span class="p">[</span> <span class="mf">0.2627198</span><span class="p">,</span>  <span class="o">-</span><span class="mf">1.6140151</span><span class="p">,</span>   <span class="mf">0.2212624</span> <span class="p">,</span>  <span class="mf">1.130033</span>  <span class="p">]]])</span>
    
    <span class="n">look_ahead_mask</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">constant</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
                       <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
                       <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]])</span>
    
    <span class="n">decoderk</span> <span class="o">=</span> <span class="n">Decoder</span><span class="p">(</span><span class="n">num_layers</span><span class="p">,</span>
                    <span class="n">embedding_dim</span><span class="p">,</span> 
                    <span class="n">num_heads</span><span class="p">,</span> 
                    <span class="n">fully_connected_dim</span><span class="p">,</span>
                    <span class="n">target_vocab_size</span><span class="p">,</span>
                    <span class="n">maximum_position_encoding</span><span class="p">)</span>
    <span class="n">outd</span><span class="p">,</span> <span class="n">att_weights</span> <span class="o">=</span> <span class="n">decoderk</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">encoderq_output</span><span class="p">,</span> <span class="bp">False</span><span class="p">,</span> <span class="n">look_ahead_mask</span><span class="p">,</span> <span class="bp">None</span><span class="p">)</span>
    
    <span class="k">assert</span> <span class="n">tf</span><span class="p">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">outd</span><span class="p">),</span> <span class="s">"Wrong type for outd. It must be a dict"</span>
    <span class="k">assert</span> <span class="n">np</span><span class="p">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">shape</span><span class="p">(</span><span class="n">outd</span><span class="p">),</span> <span class="n">tf</span><span class="p">.</span><span class="n">shape</span><span class="p">(</span><span class="n">encoderq_output</span><span class="p">)),</span> <span class="sa">f</span><span class="s">"Wrong shape. We expected </span><span class="si">{</span> <span class="n">tf</span><span class="p">.</span><span class="n">shape</span><span class="p">(</span><span class="n">encoderq_output</span><span class="p">)</span><span class="si">}</span><span class="s">"</span>
    <span class="k">print</span><span class="p">(</span><span class="n">outd</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="k">assert</span> <span class="n">np</span><span class="p">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">outd</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mf">0.2715261</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5606001</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.861783</span><span class="p">,</span> <span class="mf">1.69390933</span><span class="p">]),</span> <span class="s">"Wrong values in outd"</span>
    
    <span class="n">keys</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">att_weights</span><span class="p">.</span><span class="n">keys</span><span class="p">())</span>
    <span class="k">assert</span> <span class="nb">type</span><span class="p">(</span><span class="n">att_weights</span><span class="p">)</span> <span class="o">==</span> <span class="nb">dict</span><span class="p">,</span> <span class="s">"Wrong type for att_weights[0]. Output must be a tensor"</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">keys</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">num_layers</span><span class="p">,</span> <span class="sa">f</span><span class="s">"Wrong length for attention weights. It must be 2 x num_layers = </span><span class="si">{</span><span class="mi">2</span><span class="o">*</span><span class="n">num_layers</span><span class="si">}</span><span class="s">"</span>
    <span class="k">assert</span> <span class="n">tf</span><span class="p">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">att_weights</span><span class="p">[</span><span class="n">keys</span><span class="p">[</span><span class="mi">0</span><span class="p">]]),</span> <span class="sa">f</span><span class="s">"Wrong type for att_weights[</span><span class="si">{</span><span class="n">keys</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s">]. Output must be a tensor"</span>
    <span class="n">shape1</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">assert</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">shape</span><span class="p">(</span><span class="n">att_weights</span><span class="p">[</span><span class="n">keys</span><span class="p">[</span><span class="mi">1</span><span class="p">]]).</span><span class="n">numpy</span><span class="p">())</span> <span class="o">==</span> <span class="n">shape1</span><span class="p">,</span> <span class="sa">f</span><span class="s">"Wrong shape. We expected </span><span class="si">{</span><span class="n">shape1</span><span class="si">}</span><span class="s">"</span> 
    <span class="k">assert</span> <span class="n">np</span><span class="p">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">att_weights</span><span class="p">[</span><span class="n">keys</span><span class="p">[</span><span class="mi">0</span><span class="p">]][</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.52145624</span><span class="p">,</span> <span class="mf">0.47854376</span><span class="p">,</span> <span class="mf">0.</span><span class="p">]),</span> <span class="sa">f</span><span class="s">"Wrong values in att_weights[</span><span class="si">{</span><span class="n">keys</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s">]"</span>
    
    <span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\033</span><span class="s">[92mAll tests passed"</span><span class="p">)</span>
    
<span class="n">Decoder_test</span><span class="p">(</span><span class="n">Decoder</span><span class="p">)</span>
</code></pre></div></div>

<p><a name="6"></a></p>
<h2 id="6---transformer">6 - Transformer</h2>

<p>Phew! This has been quite the assignment, and now you’ve made it to your last exercise of the Deep Learning Specialization. Congratulations! You’ve done all the hard work, now it’s time to put it all together.</p>

<center><img src="/assets//assets/2023-12-03-Transformer-learning-C5W4A1SubclassV1_files/transformer.png" alt="Transformer" width="550" /></center>
<caption><center><font color="purple">Figure 4: Transformer</font></center></caption>

<p>The flow of data through the Transformer Architecture is as follows:</p>
<ul>
  <li>First your input passes through an Encoder, which is just repeated Encoder layers that you implemented:
    <ul>
      <li>embedding and positional encoding of your input</li>
      <li>multi-head attention on your input</li>
      <li>feed forward neural network to help detect features</li>
    </ul>
  </li>
  <li>Then the predicted output passes through a Decoder, consisting of the decoder layers that you implemented:
    <ul>
      <li>embedding and positional encoding of the output</li>
      <li>multi-head attention on your generated output</li>
      <li>multi-head attention with the Q from the first multi-head attention layer and the K and V from the Encoder</li>
      <li><strong>the decode input:tar is the target stenece? —  the encodeing input’s shifted right???</strong></li>
      <li>a feed forward neural network to help detect features</li>
    </ul>
  </li>
  <li>Finally, after the Nth Decoder layer, two dense layers and a softmax are applied to generate prediction for the next output in your sequence.</li>
</ul>

<p><a name="ex-8"></a></p>
<h3 id="exercise-8---transformer">Exercise 8 - Transformer</h3>

<p>Implement <code class="language-plaintext highlighter-rouge">Transformer()</code> using the <code class="language-plaintext highlighter-rouge">call()</code> method</p>
<ol>
  <li>Pass the input through the Encoder with the appropiate mask.</li>
  <li>Pass the encoder output and the target through the Decoder with the appropiate mask.</li>
  <li>Apply a linear transformation and a softmax to get a prediction.</li>
</ol>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># UNQ_C8 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)
# GRADED FUNCTION Transformer
# max_positional_encoding_target is used for decoder maximum_position_encoding
# max_positional_encoding_input is used for encoder maximum_position_encoding
# tar as the decoder X
</span><span class="k">class</span> <span class="nc">Transformer</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">Model</span><span class="p">):</span>
    <span class="s">"""
    Complete transformer with an Encoder and a Decoder
    """</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">fully_connected_dim</span><span class="p">,</span> <span class="n">input_vocab_size</span><span class="p">,</span> 
               <span class="n">target_vocab_size</span><span class="p">,</span> <span class="n">max_positional_encoding_input</span><span class="p">,</span>
               <span class="n">max_positional_encoding_target</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">layernorm_eps</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Transformer</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">Encoder</span><span class="p">(</span><span class="n">num_layers</span><span class="o">=</span><span class="n">num_layers</span><span class="p">,</span>
                               <span class="n">embedding_dim</span><span class="o">=</span><span class="n">embedding_dim</span><span class="p">,</span>
                               <span class="n">num_heads</span><span class="o">=</span><span class="n">num_heads</span><span class="p">,</span>
                               <span class="n">fully_connected_dim</span><span class="o">=</span><span class="n">fully_connected_dim</span><span class="p">,</span>
                               <span class="n">input_vocab_size</span><span class="o">=</span><span class="n">input_vocab_size</span><span class="p">,</span>
                               <span class="n">maximum_position_encoding</span><span class="o">=</span><span class="n">max_positional_encoding_input</span><span class="p">,</span>
                               <span class="n">dropout_rate</span><span class="o">=</span><span class="n">dropout_rate</span><span class="p">,</span>
                               <span class="n">layernorm_eps</span><span class="o">=</span><span class="n">layernorm_eps</span><span class="p">)</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">Decoder</span><span class="p">(</span><span class="n">num_layers</span><span class="o">=</span><span class="n">num_layers</span><span class="p">,</span> 
                               <span class="n">embedding_dim</span><span class="o">=</span><span class="n">embedding_dim</span><span class="p">,</span>
                               <span class="n">num_heads</span><span class="o">=</span><span class="n">num_heads</span><span class="p">,</span>
                               <span class="n">fully_connected_dim</span><span class="o">=</span><span class="n">fully_connected_dim</span><span class="p">,</span>
                               <span class="n">target_vocab_size</span><span class="o">=</span><span class="n">target_vocab_size</span><span class="p">,</span> 
                               <span class="n">maximum_position_encoding</span><span class="o">=</span><span class="n">max_positional_encoding_target</span><span class="p">,</span>
                               <span class="n">dropout_rate</span><span class="o">=</span><span class="n">dropout_rate</span><span class="p">,</span>
                               <span class="n">layernorm_eps</span><span class="o">=</span><span class="n">layernorm_eps</span><span class="p">)</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">final_layer</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">target_vocab_size</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'softmax'</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inp</span><span class="p">,</span> <span class="n">tar</span><span class="p">,</span> <span class="n">training</span><span class="p">,</span> <span class="n">enc_padding_mask</span><span class="p">,</span> <span class="n">look_ahead_mask</span><span class="p">,</span> <span class="n">dec_padding_mask</span><span class="p">):</span>
        <span class="s">"""
        Forward pass for the entire Transformer
        Arguments:
            inp -- Tensor of shape (batch_size, input_seq_len, fully_connected_dim)
            tar -- Tensor of shape (batch_size, target_seq_len, fully_connected_dim)
            training -- Boolean, set to true to activate
                        the training mode for dropout layers
            enc_padding_mask -- Boolean mask to ensure that the padding is not 
                    treated as part of the input
            look_ahead_mask -- Boolean mask for the target_input
            padding_mask -- Boolean mask for the second multihead attention layer
        Returns:
            final_output -- Describe me
            attention_weights - Dictionary of tensors containing all the attention weights for the decoder
                                each of shape Tensor of shape (batch_size, num_heads, target_seq_len, input_seq_len)
        
        """</span>
        <span class="c1"># START CODE HERE
</span>        <span class="c1"># call self.encoder with the appropriate arguments to get the encoder output
</span>        <span class="n">enc_output</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span><span class="n">training</span><span class="p">,</span><span class="n">enc_padding_mask</span><span class="p">)</span> <span class="c1"># (batch_size, inp_seq_len, fully_connected_dim)
</span>        
        <span class="c1"># call self.decoder with the appropriate arguments to get the decoder output
</span>        <span class="c1"># dec_output.shape == (batch_size, tar_seq_len, fully_connected_dim)
</span>        <span class="c1"># so the tar is the target stenece? ---  the encodeing input's shifted right???
</span>        <span class="n">dec_output</span><span class="p">,</span> <span class="n">attention_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">tar</span><span class="p">,</span> <span class="n">enc_output</span><span class="p">,</span> <span class="n">training</span><span class="p">,</span> <span class="n">look_ahead_mask</span><span class="p">,</span> <span class="n">dec_padding_mask</span><span class="p">)</span>
        
        <span class="c1"># pass decoder output through a linear layer and softmax (~2 lines)
</span>        <span class="n">final_output</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">final_layer</span><span class="p">(</span><span class="n">dec_output</span><span class="p">)</span>  <span class="c1"># (batch_size, tar_seq_len, target_vocab_size)
</span>        <span class="c1"># START CODE HERE
</span>
        <span class="k">return</span> <span class="n">final_output</span><span class="p">,</span> <span class="n">attention_weights</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># UNIT TEST
</span><span class="n">ownMultiHead</span><span class="o">=</span><span class="bp">False</span>
<span class="k">def</span> <span class="nf">Transformer_test</span><span class="p">(</span><span class="n">target</span><span class="p">):</span>
    
    <span class="n">tf</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>


    <span class="n">num_layers</span> <span class="o">=</span> <span class="mi">6</span>
    <span class="n">embedding_dim</span> <span class="o">=</span> <span class="mi">4</span>
    <span class="n">num_heads</span> <span class="o">=</span> <span class="mi">4</span>
    <span class="n">fully_connected_dim</span> <span class="o">=</span> <span class="mi">8</span>
    <span class="n">input_vocab_size</span> <span class="o">=</span> <span class="mi">30</span>
    <span class="n">target_vocab_size</span> <span class="o">=</span> <span class="mi">35</span>
    <span class="n">max_positional_encoding_input</span> <span class="o">=</span> <span class="mi">5</span>
    <span class="n">max_positional_encoding_target</span> <span class="o">=</span> <span class="mi">6</span>

    <span class="n">trans</span> <span class="o">=</span> <span class="n">Transformer</span><span class="p">(</span><span class="n">num_layers</span><span class="p">,</span> 
                        <span class="n">embedding_dim</span><span class="p">,</span> 
                        <span class="n">num_heads</span><span class="p">,</span> 
                        <span class="n">fully_connected_dim</span><span class="p">,</span> 
                        <span class="n">input_vocab_size</span><span class="p">,</span> 
                        <span class="n">target_vocab_size</span><span class="p">,</span> 
                        <span class="n">max_positional_encoding_input</span><span class="p">,</span>
                        <span class="n">max_positional_encoding_target</span><span class="p">)</span>
    <span class="c1"># 0 is the padding value
</span>    <span class="n">sentence_lang_a</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
    <span class="n">sentence_lang_b</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>

    <span class="n">enc_padding_mask</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
    <span class="n">dec_padding_mask</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>

    <span class="n">look_ahead_mask</span> <span class="o">=</span> <span class="n">create_look_ahead_mask</span><span class="p">(</span><span class="n">sentence_lang_a</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

    <span class="n">translation</span><span class="p">,</span> <span class="n">weights</span> <span class="o">=</span> <span class="n">trans</span><span class="p">(</span>
        <span class="n">sentence_lang_a</span><span class="p">,</span>
        <span class="n">sentence_lang_b</span><span class="p">,</span>
        <span class="bp">True</span><span class="p">,</span>
        <span class="n">enc_padding_mask</span><span class="p">,</span>
        <span class="n">look_ahead_mask</span><span class="p">,</span>
        <span class="n">dec_padding_mask</span>
    <span class="p">)</span>
    
    
    <span class="k">assert</span> <span class="n">tf</span><span class="p">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">translation</span><span class="p">),</span> <span class="s">"Wrong type for translation. Output must be a tensor"</span>
    <span class="n">shape1</span> <span class="o">=</span> <span class="p">(</span><span class="n">sentence_lang_a</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">max_positional_encoding_input</span><span class="p">,</span> <span class="n">target_vocab_size</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">shape</span><span class="p">(</span><span class="n">translation</span><span class="p">).</span><span class="n">numpy</span><span class="p">())</span> <span class="o">==</span> <span class="n">shape1</span><span class="p">,</span> <span class="sa">f</span><span class="s">"Wrong shape. We expected </span><span class="si">{</span><span class="n">shape1</span><span class="si">}</span><span class="s">"</span>
        
    <span class="k">print</span><span class="p">(</span><span class="n">translation</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">:</span><span class="mi">8</span><span class="p">])</span>
    <span class="k">assert</span> <span class="n">np</span><span class="p">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">translation</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">:</span><span class="mi">8</span><span class="p">],</span>
                       <span class="p">[[</span><span class="mf">0.02616475</span><span class="p">,</span> <span class="mf">0.02074359</span><span class="p">,</span> <span class="mf">0.01675757</span><span class="p">,</span> 
                         <span class="mf">0.025527</span><span class="p">,</span> <span class="mf">0.04473696</span><span class="p">,</span> <span class="mf">0.02171909</span><span class="p">,</span> 
                         <span class="mf">0.01542725</span><span class="p">,</span> <span class="mf">0.03658631</span><span class="p">]]),</span> <span class="s">"Wrong values in outd"</span>
    
    <span class="n">keys</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">weights</span><span class="p">.</span><span class="n">keys</span><span class="p">())</span>
    <span class="k">assert</span> <span class="nb">type</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span> <span class="o">==</span> <span class="nb">dict</span><span class="p">,</span> <span class="s">"Wrong type for weights. It must be a dict"</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">keys</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">num_layers</span><span class="p">,</span> <span class="sa">f</span><span class="s">"Wrong length for attention weights. It must be 2 x num_layers = </span><span class="si">{</span><span class="mi">2</span><span class="o">*</span><span class="n">num_layers</span><span class="si">}</span><span class="s">"</span>
    <span class="k">assert</span> <span class="n">tf</span><span class="p">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">weights</span><span class="p">[</span><span class="n">keys</span><span class="p">[</span><span class="mi">0</span><span class="p">]]),</span> <span class="sa">f</span><span class="s">"Wrong type for att_weights[</span><span class="si">{</span><span class="n">keys</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s">]. Output must be a tensor"</span>

    <span class="n">shape1</span> <span class="o">=</span> <span class="p">(</span><span class="n">sentence_lang_a</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">sentence_lang_a</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">sentence_lang_a</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">assert</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">shape</span><span class="p">(</span><span class="n">weights</span><span class="p">[</span><span class="n">keys</span><span class="p">[</span><span class="mi">1</span><span class="p">]]).</span><span class="n">numpy</span><span class="p">())</span> <span class="o">==</span> <span class="n">shape1</span><span class="p">,</span> <span class="sa">f</span><span class="s">"Wrong shape. We expected </span><span class="si">{</span><span class="n">shape1</span><span class="si">}</span><span class="s">"</span> 
    <span class="k">assert</span> <span class="n">np</span><span class="p">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">weights</span><span class="p">[</span><span class="n">keys</span><span class="p">[</span><span class="mi">0</span><span class="p">]][</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.4992985</span><span class="p">,</span> <span class="mf">0.5007015</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">]),</span> <span class="sa">f</span><span class="s">"Wrong values in weights[</span><span class="si">{</span><span class="n">keys</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s">]"</span>
    
    <span class="k">print</span><span class="p">(</span><span class="n">translation</span><span class="p">)</span>
    
    <span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\033</span><span class="s">[92mAll tests passed"</span><span class="p">)</span>

    
<span class="n">Transformer_test</span><span class="p">(</span><span class="n">Transformer</span><span class="p">)</span>

</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tf.Tensor(
[0.02616475 0.02074359 0.01675757 0.025527   0.04473695 0.02171909
 0.01542725 0.0365863 ], shape=(8,), dtype=float32)
tf.Tensor(
[[[0.02616475 0.02074359 0.01675757 0.025527   0.04473695 0.02171909
   0.01542725 0.0365863  0.02433536 0.02948791 0.01698964 0.02147779
   0.05749574 0.02669398 0.01277918 0.03276358 0.0253941  0.01698772
   0.02758246 0.02529753 0.04394253 0.06258808 0.03667333 0.03009711
   0.05011231 0.01414333 0.01601289 0.01800467 0.02506283 0.01607273
   0.06204056 0.02099288 0.03005534 0.03070701 0.01854689]
  [0.02490053 0.017258   0.01794803 0.02998916 0.05038005 0.01997477
   0.01526351 0.03385608 0.03138068 0.02608407 0.01852771 0.01744511
   0.05923333 0.03287778 0.01450072 0.02815487 0.02676623 0.01684978
   0.02482791 0.02307897 0.04122656 0.05552058 0.03742857 0.03390088
   0.04666695 0.01667501 0.01400229 0.01981527 0.02202851 0.01818
   0.05918451 0.02173372 0.03040997 0.03337187 0.02055808]
  [0.01867789 0.01225462 0.02509719 0.04180384 0.06244645 0.02000666
   0.01934388 0.03032456 0.05771376 0.02616111 0.01742368 0.01100331
   0.05456048 0.04248188 0.02078063 0.02245298 0.03337655 0.02052129
   0.0239658  0.02193134 0.04068131 0.03323278 0.04556258 0.03676546
   0.04394966 0.01574801 0.01223158 0.02734469 0.01154951 0.02240609
   0.03563077 0.02169302 0.02025472 0.02886864 0.02175329]
  [0.02305287 0.01215192 0.02248081 0.0418811  0.05324595 0.016529
   0.01626855 0.02452858 0.05319852 0.01741914 0.02720063 0.01175192
   0.04887011 0.05262585 0.02324445 0.01787254 0.02867536 0.01768711
   0.01800392 0.01797924 0.02830286 0.03332606 0.0324963  0.04277937
   0.03038614 0.0323176  0.01166379 0.02618811 0.01842924 0.02784598
   0.04346567 0.02524558 0.03285819 0.0404315  0.02959607]
  [0.01859851 0.01163484 0.02560123 0.04363471 0.06270956 0.01928385
   0.01924486 0.02882556 0.06161031 0.02436098 0.01855855 0.01041807
   0.05321557 0.04556077 0.0220504  0.02093103 0.03341144 0.02041205
   0.02265851 0.02099104 0.03823084 0.03121315 0.04416506 0.03813418
   0.04104865 0.01757099 0.01183266 0.0281889  0.0114538  0.02377767
   0.03464996 0.02217591 0.02084129 0.03000083 0.02300425]]], shape=(1, 5, 35), dtype=float32)
[92mAll tests passed
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># UNIT TEST
</span><span class="n">ownMultiHead</span><span class="o">=</span><span class="bp">True</span>
<span class="k">def</span> <span class="nf">Transformer_test</span><span class="p">(</span><span class="n">target</span><span class="p">):</span>
    
    <span class="n">tf</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>


    <span class="n">num_layers</span> <span class="o">=</span> <span class="mi">6</span>
    <span class="n">embedding_dim</span> <span class="o">=</span> <span class="mi">4</span>
    <span class="n">num_heads</span> <span class="o">=</span> <span class="mi">4</span>
    <span class="n">fully_connected_dim</span> <span class="o">=</span> <span class="mi">8</span>
    <span class="n">input_vocab_size</span> <span class="o">=</span> <span class="mi">30</span>
    <span class="n">target_vocab_size</span> <span class="o">=</span> <span class="mi">35</span>
    <span class="n">max_positional_encoding_input</span> <span class="o">=</span> <span class="mi">5</span>
    <span class="n">max_positional_encoding_target</span> <span class="o">=</span> <span class="mi">6</span>

    <span class="n">trans</span> <span class="o">=</span> <span class="n">Transformer</span><span class="p">(</span><span class="n">num_layers</span><span class="p">,</span> 
                        <span class="n">embedding_dim</span><span class="p">,</span> 
                        <span class="n">num_heads</span><span class="p">,</span> 
                        <span class="n">fully_connected_dim</span><span class="p">,</span> 
                        <span class="n">input_vocab_size</span><span class="p">,</span> 
                        <span class="n">target_vocab_size</span><span class="p">,</span> 
                        <span class="n">max_positional_encoding_input</span><span class="p">,</span>
                        <span class="n">max_positional_encoding_target</span><span class="p">)</span>
    <span class="c1"># 0 is the padding value
</span>    <span class="n">sentence_lang_a</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
    <span class="n">sentence_lang_b</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>

    <span class="n">enc_padding_mask</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
    <span class="n">dec_padding_mask</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>

    <span class="n">look_ahead_mask</span> <span class="o">=</span> <span class="n">create_look_ahead_mask</span><span class="p">(</span><span class="n">sentence_lang_a</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

    <span class="n">translation</span><span class="p">,</span> <span class="n">weights</span> <span class="o">=</span> <span class="n">trans</span><span class="p">(</span>
        <span class="n">sentence_lang_a</span><span class="p">,</span>
        <span class="n">sentence_lang_b</span><span class="p">,</span>
        <span class="bp">True</span><span class="p">,</span>
        <span class="n">enc_padding_mask</span><span class="p">,</span>
        <span class="n">look_ahead_mask</span><span class="p">,</span>
        <span class="n">dec_padding_mask</span>
    <span class="p">)</span>
    
    
    <span class="k">assert</span> <span class="n">tf</span><span class="p">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">translation</span><span class="p">),</span> <span class="s">"Wrong type for translation. Output must be a tensor"</span>
    <span class="n">shape1</span> <span class="o">=</span> <span class="p">(</span><span class="n">sentence_lang_a</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">max_positional_encoding_input</span><span class="p">,</span> <span class="n">target_vocab_size</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">shape</span><span class="p">(</span><span class="n">translation</span><span class="p">).</span><span class="n">numpy</span><span class="p">())</span> <span class="o">==</span> <span class="n">shape1</span><span class="p">,</span> <span class="sa">f</span><span class="s">"Wrong shape. We expected </span><span class="si">{</span><span class="n">shape1</span><span class="si">}</span><span class="s">"</span>
        
    <span class="k">print</span><span class="p">(</span><span class="n">translation</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">:</span><span class="mi">8</span><span class="p">])</span>
    
    <span class="n">keys</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">weights</span><span class="p">.</span><span class="n">keys</span><span class="p">())</span>
    <span class="k">assert</span> <span class="nb">type</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span> <span class="o">==</span> <span class="nb">dict</span><span class="p">,</span> <span class="s">"Wrong type for weights. It must be a dict"</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">keys</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">num_layers</span><span class="p">,</span> <span class="sa">f</span><span class="s">"Wrong length for attention weights. It must be 2 x num_layers = </span><span class="si">{</span><span class="mi">2</span><span class="o">*</span><span class="n">num_layers</span><span class="si">}</span><span class="s">"</span>
    <span class="k">assert</span> <span class="n">tf</span><span class="p">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">weights</span><span class="p">[</span><span class="n">keys</span><span class="p">[</span><span class="mi">0</span><span class="p">]]),</span> <span class="sa">f</span><span class="s">"Wrong type for att_weights[</span><span class="si">{</span><span class="n">keys</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s">]. Output must be a tensor"</span>

    <span class="n">shape1</span> <span class="o">=</span> <span class="p">(</span><span class="n">sentence_lang_a</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">sentence_lang_a</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">sentence_lang_a</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">assert</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">shape</span><span class="p">(</span><span class="n">weights</span><span class="p">[</span><span class="n">keys</span><span class="p">[</span><span class="mi">1</span><span class="p">]]).</span><span class="n">numpy</span><span class="p">())</span> <span class="o">==</span> <span class="n">shape1</span><span class="p">,</span> <span class="sa">f</span><span class="s">"Wrong shape. We expected </span><span class="si">{</span><span class="n">shape1</span><span class="si">}</span><span class="s">"</span> 
    <span class="c1">#assert np.allclose(weights[keys[0]][0, 0, 1], [0.4992985, 0.5007015, 0., 0., 0.]), f"Wrong values in weights[{keys[0]}]"
</span>    
    <span class="k">print</span><span class="p">(</span><span class="n">translation</span><span class="p">)</span>
    
    <span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\033</span><span class="s">[92mAll tests passed"</span><span class="p">)</span>
<span class="n">Transformer_test</span><span class="p">(</span><span class="n">Transformer</span><span class="p">)</span>    
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tf.Tensor(
[0.0138899  0.03013041 0.0194122  0.02183245 0.0163418  0.03393482
 0.05421878 0.04387819], shape=(8,), dtype=float32)
tf.Tensor(
[[[0.0138899  0.03013041 0.0194122  0.02183245 0.0163418  0.03393482
   0.05421878 0.04387819 0.0329827  0.01397073 0.03924095 0.01440488
   0.03002763 0.0154879  0.0176722  0.01628551 0.01585947 0.01415133
   0.03792994 0.02771122 0.02725577 0.02476936 0.04830182 0.07570544
   0.02002317 0.02237192 0.02127243 0.02123942 0.01698944 0.02112064
   0.043529   0.03428836 0.04166754 0.04055457 0.03154815]
  [0.01227451 0.02959899 0.0166487  0.02353616 0.01820176 0.03310344
   0.05079214 0.05486127 0.03501931 0.01502464 0.03344036 0.01418775
   0.03232233 0.01766093 0.01824826 0.01715104 0.01604581 0.01408619
   0.04389434 0.02434369 0.03227949 0.02387203 0.03963812 0.07077137
   0.01703417 0.01782698 0.02154371 0.02032982 0.01434441 0.02211295
   0.05294901 0.03850862 0.03668781 0.04071193 0.03094796]
  [0.01763018 0.03471405 0.01863351 0.02474838 0.02410761 0.03263579
   0.03585017 0.06357922 0.0360616  0.02341402 0.02914601 0.01382798
   0.03207213 0.02026083 0.02584696 0.01884262 0.01772998 0.01937712
   0.04135303 0.02141738 0.04634167 0.02295651 0.02191478 0.03458349
   0.01216602 0.01243537 0.03257969 0.0191417  0.01196113 0.02268301
   0.06083624 0.05173917 0.02795435 0.0412199  0.03023846]
  [0.01262886 0.02906489 0.01768985 0.02290371 0.01714453 0.03321528
   0.05317392 0.04823885 0.03380431 0.01412825 0.03580388 0.01471408
   0.03130832 0.01684265 0.01749932 0.01695023 0.01611957 0.01388939
   0.04119689 0.02608779 0.02872973 0.02446639 0.04545375 0.07689973
   0.01928073 0.02068552 0.02047833 0.02108692 0.01605351 0.02187557
   0.04714353 0.03499512 0.03939003 0.03994213 0.03111436]
  [0.01367486 0.02952728 0.01929193 0.02200459 0.01632005 0.03364716
   0.0543959  0.04299618 0.03275498 0.01379251 0.03886067 0.01478795
   0.03005839 0.01573534 0.01740936 0.01650989 0.01605004 0.01407218
   0.03796678 0.02783582 0.02657028 0.02490305 0.04947045 0.07766728
   0.02074305 0.02304619 0.0206537  0.02151686 0.01744339 0.02133087
   0.04263789 0.03324496 0.04177879 0.03989565 0.03140577]]], shape=(1, 5, 35), dtype=float32)
[92mAll tests passed
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ownMultiHead</span><span class="o">=</span><span class="bp">True</span>
<span class="n">sample_transformer</span> <span class="o">=</span> <span class="n">Transformer</span><span class="p">(</span>
    <span class="n">num_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">num_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">fully_connected_dim</span><span class="o">=</span><span class="mi">2048</span><span class="p">,</span> 
    <span class="n">input_vocab_size</span><span class="o">=</span><span class="mi">8500</span><span class="p">,</span> <span class="n">target_vocab_size</span><span class="o">=</span><span class="mi">8000</span><span class="p">,</span> 
    <span class="n">max_positional_encoding_input</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> 
    <span class="n">max_positional_encoding_target</span><span class="o">=</span><span class="mi">6000</span><span class="p">)</span>

<span class="n">temp_input</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">64</span><span class="p">,</span> <span class="mi">62</span><span class="p">))</span>
<span class="n">temp_target</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">64</span><span class="p">,</span> <span class="mi">26</span><span class="p">))</span>

<span class="n">fn_out</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">sample_transformer</span><span class="p">(</span><span class="n">temp_input</span><span class="p">,</span> <span class="n">temp_target</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> 
                               <span class="n">enc_padding_mask</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> 
                               <span class="n">look_ahead_mask</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
                               <span class="n">dec_padding_mask</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>

<span class="n">fn_out</span><span class="p">.</span><span class="n">shape</span>  <span class="c1"># (batch_size, tar_seq_len, target_vocab_size)
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>TensorShape([64, 26, 8000])
</code></pre></div></div>

<p>配置超参数（hyperparameters）
为了让本示例小且相对较快，已经减小了num_layers、 d_model 和 dff 的值。</p>

<p>Transformer 的基础模型使用的数值为：num_layers=6，d_model = 512，dff = 2048。关于所有其他版本的 Transformer，请查阅论文。</p>

<p>Note：通过改变以下数值，您可以获得在许多任务上达到最先进水平的模型。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">tensorflow_datasets</span> <span class="k">as</span> <span class="n">tfds</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="n">examples</span><span class="p">,</span> <span class="n">metadata</span> <span class="o">=</span> <span class="n">tfds</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="s">'ted_hrlr_translate/pt_to_en'</span><span class="p">,</span> <span class="n">with_info</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                               <span class="n">as_supervised</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">train_examples</span><span class="p">,</span> <span class="n">val_examples</span> <span class="o">=</span> <span class="n">examples</span><span class="p">[</span><span class="s">'train'</span><span class="p">],</span> <span class="n">examples</span><span class="p">[</span><span class="s">'validation'</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[1mDownloading and preparing dataset ted_hrlr_translate (124.94 MiB) to /home/jupyter/tensorflow_datasets/ted_hrlr_translate/pt_to_en/0.0.1...[0m


Dl Completed...: 0 url [00:00, ? url/s]
Dl Size...: 0 MiB [00:00, ? MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:00&lt;?, ? url/s]
Dl Size...: 0 MiB [00:00, ? MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:00&lt;?, ? url/s]
Dl Size...:   0%|          | 0/124 [00:00&lt;?, ? MiB/s][A

Extraction completed...: 0 file [00:00, ? file/s][A[A
Dl Completed...:   0%|          | 0/1 [00:00&lt;?, ? url/s]iB/s][A
Dl Size...:   1%|          | 1/124 [00:00&lt;01:27,  1.41 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:00&lt;?, ? url/s]
Dl Size...:   2%|▏         | 2/124 [00:00&lt;01:26,  1.41 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:00&lt;?, ? url/s]
Dl Size...:   2%|▏         | 3/124 [00:00&lt;01:25,  1.41 MiB/s][A

Extraction completed...: 0 file [00:00, ? file/s][A[A
Dl Completed...:   0%|          | 0/1 [00:00&lt;?, ? url/s]iB/s][A
Dl Size...:   3%|▎         | 4/124 [00:00&lt;00:20,  5.82 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:00&lt;?, ? url/s]
Dl Size...:   4%|▍         | 5/124 [00:00&lt;00:20,  5.82 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:00&lt;?, ? url/s]
Dl Size...:   5%|▍         | 6/124 [00:00&lt;00:20,  5.82 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:00&lt;?, ? url/s]
Dl Size...:   6%|▌         | 7/124 [00:00&lt;00:20,  5.82 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:00&lt;?, ? url/s]
Dl Size...:   6%|▋         | 8/124 [00:00&lt;00:19,  5.82 MiB/s][A

Extraction completed...: 0 file [00:00, ? file/s][A[A
Dl Completed...:   0%|          | 0/1 [00:00&lt;?, ? url/s]iB/s][A
Dl Size...:   7%|▋         | 9/124 [00:00&lt;00:08, 13.05 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]
Dl Size...:   8%|▊         | 10/124 [00:01&lt;00:08, 13.05 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]
Dl Size...:   9%|▉         | 11/124 [00:01&lt;00:08, 13.05 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]
Dl Size...:  10%|▉         | 12/124 [00:01&lt;00:08, 13.05 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]
Dl Size...:  10%|█         | 13/124 [00:01&lt;00:08, 13.05 MiB/s][A

Extraction completed...: 0 file [00:01, ? file/s][A[A
Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]MiB/s][A
Dl Size...:  11%|█▏        | 14/124 [00:01&lt;00:05, 19.04 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]
Dl Size...:  12%|█▏        | 15/124 [00:01&lt;00:05, 19.04 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]
Dl Size...:  13%|█▎        | 16/124 [00:01&lt;00:05, 19.04 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]
Dl Size...:  14%|█▎        | 17/124 [00:01&lt;00:05, 19.04 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]
Dl Size...:  15%|█▍        | 18/124 [00:01&lt;00:05, 19.04 MiB/s][A

Extraction completed...: 0 file [00:01, ? file/s][A[A
Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]MiB/s][A
Dl Size...:  15%|█▌        | 19/124 [00:01&lt;00:04, 24.24 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]
Dl Size...:  16%|█▌        | 20/124 [00:01&lt;00:04, 24.24 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]
Dl Size...:  17%|█▋        | 21/124 [00:01&lt;00:04, 24.24 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]
Dl Size...:  18%|█▊        | 22/124 [00:01&lt;00:04, 24.24 MiB/s][A

Extraction completed...: 0 file [00:01, ? file/s][A[A
Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]MiB/s][A
Dl Size...:  19%|█▊        | 23/124 [00:01&lt;00:03, 27.63 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]
Dl Size...:  19%|█▉        | 24/124 [00:01&lt;00:03, 27.63 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]
Dl Size...:  20%|██        | 25/124 [00:01&lt;00:03, 27.63 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]
Dl Size...:  21%|██        | 26/124 [00:01&lt;00:03, 27.63 MiB/s][A

Extraction completed...: 0 file [00:01, ? file/s][A[A
Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]MiB/s][A
Dl Size...:  22%|██▏       | 27/124 [00:01&lt;00:03, 30.56 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]
Dl Size...:  23%|██▎       | 28/124 [00:01&lt;00:03, 30.56 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]
Dl Size...:  23%|██▎       | 29/124 [00:01&lt;00:03, 30.56 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]
Dl Size...:  24%|██▍       | 30/124 [00:01&lt;00:03, 30.56 MiB/s][A

Extraction completed...: 0 file [00:01, ? file/s][A[A
Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]MiB/s][A
Dl Size...:  25%|██▌       | 31/124 [00:01&lt;00:02, 32.46 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]
Dl Size...:  26%|██▌       | 32/124 [00:01&lt;00:02, 32.46 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]
Dl Size...:  27%|██▋       | 33/124 [00:01&lt;00:02, 32.46 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]
Dl Size...:  27%|██▋       | 34/124 [00:01&lt;00:02, 32.46 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]
Dl Size...:  28%|██▊       | 35/124 [00:01&lt;00:02, 32.46 MiB/s][A

Extraction completed...: 0 file [00:01, ? file/s][A[A
Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]MiB/s][A
Dl Size...:  29%|██▉       | 36/124 [00:01&lt;00:02, 35.21 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]
Dl Size...:  30%|██▉       | 37/124 [00:01&lt;00:02, 35.21 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]
Dl Size...:  31%|███       | 38/124 [00:01&lt;00:02, 35.21 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]
Dl Size...:  31%|███▏      | 39/124 [00:01&lt;00:02, 35.21 MiB/s][A

Extraction completed...: 0 file [00:01, ? file/s][A[A
Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]MiB/s][A
Dl Size...:  32%|███▏      | 40/124 [00:01&lt;00:02, 35.71 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]
Dl Size...:  33%|███▎      | 41/124 [00:01&lt;00:02, 35.71 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]
Dl Size...:  34%|███▍      | 42/124 [00:01&lt;00:02, 35.71 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]
Dl Size...:  35%|███▍      | 43/124 [00:01&lt;00:02, 35.71 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]
Dl Size...:  35%|███▌      | 44/124 [00:01&lt;00:02, 35.71 MiB/s][A

Extraction completed...: 0 file [00:01, ? file/s][A[A
Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]MiB/s][A
Dl Size...:  36%|███▋      | 45/124 [00:01&lt;00:02, 37.55 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]
Dl Size...:  37%|███▋      | 46/124 [00:01&lt;00:02, 37.55 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]
Dl Size...:  38%|███▊      | 47/124 [00:01&lt;00:02, 37.55 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:01&lt;?, ? url/s]
Dl Size...:  39%|███▊      | 48/124 [00:01&lt;00:02, 37.55 MiB/s][A

Extraction completed...: 0 file [00:01, ? file/s][A[A
Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]MiB/s][A
Dl Size...:  40%|███▉      | 49/124 [00:02&lt;00:02, 37.24 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]
Dl Size...:  40%|████      | 50/124 [00:02&lt;00:01, 37.24 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]
Dl Size...:  41%|████      | 51/124 [00:02&lt;00:01, 37.24 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]
Dl Size...:  42%|████▏     | 52/124 [00:02&lt;00:01, 37.24 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]
Dl Size...:  43%|████▎     | 53/124 [00:02&lt;00:01, 37.24 MiB/s][A

Extraction completed...: 0 file [00:02, ? file/s][A[A
Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]MiB/s][A
Dl Size...:  44%|████▎     | 54/124 [00:02&lt;00:01, 39.37 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]
Dl Size...:  44%|████▍     | 55/124 [00:02&lt;00:01, 39.37 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]
Dl Size...:  45%|████▌     | 56/124 [00:02&lt;00:01, 39.37 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]
Dl Size...:  46%|████▌     | 57/124 [00:02&lt;00:01, 39.37 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]
Dl Size...:  47%|████▋     | 58/124 [00:02&lt;00:01, 39.37 MiB/s][A

Extraction completed...: 0 file [00:02, ? file/s][A[A
Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]MiB/s][A
Dl Size...:  48%|████▊     | 59/124 [00:02&lt;00:01, 38.63 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]
Dl Size...:  48%|████▊     | 60/124 [00:02&lt;00:01, 38.63 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]
Dl Size...:  49%|████▉     | 61/124 [00:02&lt;00:01, 38.63 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]
Dl Size...:  50%|█████     | 62/124 [00:02&lt;00:01, 38.63 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]
Dl Size...:  51%|█████     | 63/124 [00:02&lt;00:01, 38.63 MiB/s][A

Extraction completed...: 0 file [00:02, ? file/s][A[A
Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]MiB/s][A
Dl Size...:  52%|█████▏    | 64/124 [00:02&lt;00:01, 38.13 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]
Dl Size...:  52%|█████▏    | 65/124 [00:02&lt;00:01, 38.13 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]
Dl Size...:  53%|█████▎    | 66/124 [00:02&lt;00:01, 38.13 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]
Dl Size...:  54%|█████▍    | 67/124 [00:02&lt;00:01, 38.13 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]
Dl Size...:  55%|█████▍    | 68/124 [00:02&lt;00:01, 38.13 MiB/s][A

Extraction completed...: 0 file [00:02, ? file/s][A[A
Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]MiB/s][A
Dl Size...:  56%|█████▌    | 69/124 [00:02&lt;00:01, 39.58 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]
Dl Size...:  56%|█████▋    | 70/124 [00:02&lt;00:01, 39.58 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]
Dl Size...:  57%|█████▋    | 71/124 [00:02&lt;00:01, 39.58 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]
Dl Size...:  58%|█████▊    | 72/124 [00:02&lt;00:01, 39.58 MiB/s][A

Extraction completed...: 0 file [00:02, ? file/s][A[A
Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]MiB/s][A
Dl Size...:  59%|█████▉    | 73/124 [00:02&lt;00:01, 38.34 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]
Dl Size...:  60%|█████▉    | 74/124 [00:02&lt;00:01, 38.34 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]
Dl Size...:  60%|██████    | 75/124 [00:02&lt;00:01, 38.34 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]
Dl Size...:  61%|██████▏   | 76/124 [00:02&lt;00:01, 38.34 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]
Dl Size...:  62%|██████▏   | 77/124 [00:02&lt;00:01, 38.34 MiB/s][A

Extraction completed...: 0 file [00:02, ? file/s][A[A
Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]MiB/s][A
Dl Size...:  63%|██████▎   | 78/124 [00:02&lt;00:01, 39.90 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]
Dl Size...:  64%|██████▎   | 79/124 [00:02&lt;00:01, 39.90 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]
Dl Size...:  65%|██████▍   | 80/124 [00:02&lt;00:01, 39.90 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]
Dl Size...:  65%|██████▌   | 81/124 [00:02&lt;00:01, 39.90 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]
Dl Size...:  66%|██████▌   | 82/124 [00:02&lt;00:01, 39.90 MiB/s][A

Extraction completed...: 0 file [00:02, ? file/s][A[A
Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]MiB/s][A
Dl Size...:  67%|██████▋   | 83/124 [00:02&lt;00:01, 39.35 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]
Dl Size...:  68%|██████▊   | 84/124 [00:02&lt;00:01, 39.35 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]
Dl Size...:  69%|██████▊   | 85/124 [00:02&lt;00:00, 39.35 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]
Dl Size...:  69%|██████▉   | 86/124 [00:02&lt;00:00, 39.35 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:02&lt;?, ? url/s]
Dl Size...:  70%|███████   | 87/124 [00:02&lt;00:00, 39.35 MiB/s][A

Extraction completed...: 0 file [00:02, ? file/s][A[A
Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s]MiB/s][A
Dl Size...:  71%|███████   | 88/124 [00:03&lt;00:00, 38.82 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s]
Dl Size...:  72%|███████▏  | 89/124 [00:03&lt;00:00, 38.82 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s]
Dl Size...:  73%|███████▎  | 90/124 [00:03&lt;00:00, 38.82 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s]
Dl Size...:  73%|███████▎  | 91/124 [00:03&lt;00:00, 38.82 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s]
Dl Size...:  74%|███████▍  | 92/124 [00:03&lt;00:00, 38.82 MiB/s][A

Extraction completed...: 0 file [00:03, ? file/s][A[A
Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s]MiB/s][A
Dl Size...:  75%|███████▌  | 93/124 [00:03&lt;00:00, 40.16 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s]
Dl Size...:  76%|███████▌  | 94/124 [00:03&lt;00:00, 40.16 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s]
Dl Size...:  77%|███████▋  | 95/124 [00:03&lt;00:00, 40.16 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s]
Dl Size...:  77%|███████▋  | 96/124 [00:03&lt;00:00, 40.16 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s]
Dl Size...:  78%|███████▊  | 97/124 [00:03&lt;00:00, 40.16 MiB/s][A

Extraction completed...: 0 file [00:03, ? file/s][A[A
Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s]MiB/s][A
Dl Size...:  79%|███████▉  | 98/124 [00:03&lt;00:00, 39.51 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s]
Dl Size...:  80%|███████▉  | 99/124 [00:03&lt;00:00, 39.51 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s]
Dl Size...:  81%|████████  | 100/124 [00:03&lt;00:00, 39.51 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s]
Dl Size...:  81%|████████▏ | 101/124 [00:03&lt;00:00, 39.51 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s]
Dl Size...:  82%|████████▏ | 102/124 [00:03&lt;00:00, 39.51 MiB/s][A

Extraction completed...: 0 file [00:03, ? file/s][A[A
Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s] MiB/s][A
Dl Size...:  83%|████████▎ | 103/124 [00:03&lt;00:00, 40.34 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s]
Dl Size...:  84%|████████▍ | 104/124 [00:03&lt;00:00, 40.34 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s]
Dl Size...:  85%|████████▍ | 105/124 [00:03&lt;00:00, 40.34 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s]
Dl Size...:  85%|████████▌ | 106/124 [00:03&lt;00:00, 40.34 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s]
Dl Size...:  86%|████████▋ | 107/124 [00:03&lt;00:00, 40.34 MiB/s][A

Extraction completed...: 0 file [00:03, ? file/s][A[A
Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s] MiB/s][A
Dl Size...:  87%|████████▋ | 108/124 [00:03&lt;00:00, 39.83 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s]
Dl Size...:  88%|████████▊ | 109/124 [00:03&lt;00:00, 39.83 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s]
Dl Size...:  89%|████████▊ | 110/124 [00:03&lt;00:00, 39.83 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s]
Dl Size...:  90%|████████▉ | 111/124 [00:03&lt;00:00, 39.83 MiB/s][A

Extraction completed...: 0 file [00:03, ? file/s][A[A
Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s] MiB/s][A
Dl Size...:  90%|█████████ | 112/124 [00:03&lt;00:00, 39.72 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s]
Dl Size...:  91%|█████████ | 113/124 [00:03&lt;00:00, 39.72 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s]
Dl Size...:  92%|█████████▏| 114/124 [00:03&lt;00:00, 39.72 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s]
Dl Size...:  93%|█████████▎| 115/124 [00:03&lt;00:00, 39.72 MiB/s][A

Extraction completed...: 0 file [00:03, ? file/s][A[A
Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s] MiB/s][A
Dl Size...:  94%|█████████▎| 116/124 [00:03&lt;00:00, 38.85 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s]
Dl Size...:  94%|█████████▍| 117/124 [00:03&lt;00:00, 38.85 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s]
Dl Size...:  95%|█████████▌| 118/124 [00:03&lt;00:00, 38.85 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s]
Dl Size...:  96%|█████████▌| 119/124 [00:03&lt;00:00, 38.85 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s]
Dl Size...:  97%|█████████▋| 120/124 [00:03&lt;00:00, 38.85 MiB/s][A

Extraction completed...: 0 file [00:03, ? file/s][A[A
Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s] MiB/s][A
Dl Size...:  98%|█████████▊| 121/124 [00:03&lt;00:00, 39.96 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s]
Dl Size...:  98%|█████████▊| 122/124 [00:03&lt;00:00, 39.96 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s]
Dl Size...:  99%|█████████▉| 123/124 [00:03&lt;00:00, 39.96 MiB/s][A

Dl Completed...:   0%|          | 0/1 [00:03&lt;?, ? url/s]
Dl Size...: 100%|██████████| 124/124 [00:03&lt;00:00, 39.96 MiB/s][A

Dl Completed...: 100%|██████████| 1/1 [00:03&lt;00:00,  3.93s/ url]
Dl Size...: 100%|██████████| 124/124 [00:03&lt;00:00, 39.96 MiB/s][A

Dl Completed...: 100%|██████████| 1/1 [00:03&lt;00:00,  3.93s/ url]
Dl Size...: 100%|██████████| 124/124 [00:03&lt;00:00, 39.96 MiB/s][A

Extraction completed...:   0%|          | 0/1 [00:03&lt;?, ? file/s][A[A

Dl Completed...: 100%|██████████| 1/1 [00:08&lt;00:00,  3.93s/ url]7s/ file][A[A
Dl Size...: 100%|██████████| 124/124 [00:08&lt;00:00, 39.96 MiB/s][A

Extraction completed...: 100%|██████████| 1/1 [00:08&lt;00:00,  8.09s/ file][A[A
Dl Size...: 100%|██████████| 124/124 [00:08&lt;00:00, 15.33 MiB/s]
Dl Completed...: 100%|██████████| 1/1 [00:08&lt;00:00,  8.09s/ url]







Shuffling...:   0%|          | 0/1 [00:00&lt;?, ? shard/s]

WARNING:tensorflow:From /opt/conda/envs/tf/lib/python3.7/site-packages/tensorflow_datasets/core/file_format_adapter.py:209: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.
Instructions for updating:
Use eager execution and: 
`tf.data.TFRecordDataset(path)`


WARNING:tensorflow:From /opt/conda/envs/tf/lib/python3.7/site-packages/tensorflow_datasets/core/file_format_adapter.py:209: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.
Instructions for updating:
Use eager execution and: 
`tf.data.TFRecordDataset(path)`

Reading...: 0 examples [00:00, ? examples/s][A
                                            [A
Writing...:   0%|          | 0/51785 [00:00&lt;?, ? examples/s][A
Shuffling...:   0%|          | 0/1 [00:00&lt;?, ? shard/s]        
Reading...: 0 examples [00:00, ? examples/s][A
                                            [A
Writing...:   0%|          | 0/1193 [00:00&lt;?, ? examples/s][A
Shuffling...:   0%|          | 0/1 [00:00&lt;?, ? shard/s]    [A
Reading...: 0 examples [00:00, ? examples/s][A
                                            [A
Writing...:   0%|          | 0/1803 [00:00&lt;?, ? examples/s][A
                                                           [A

[1mDataset ted_hrlr_translate downloaded and prepared to /home/jupyter/tensorflow_datasets/ted_hrlr_translate/pt_to_en/0.0.1. Subsequent calls will reuse this data.[0m


WARNING:absl:Warning: Setting shuffle_files=True because split=TRAIN and shuffle_files=None. This behavior will be deprecated on 2019-08-06, at which point shuffle_files=False will be the default for all splits.
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">tokenizer_en</span> <span class="o">=</span> <span class="n">tfds</span><span class="p">.</span><span class="n">features</span><span class="p">.</span><span class="n">text</span><span class="p">.</span><span class="n">SubwordTextEncoder</span><span class="p">.</span><span class="n">build_from_corpus</span><span class="p">(</span>
    <span class="p">(</span><span class="n">en</span><span class="p">.</span><span class="n">numpy</span><span class="p">()</span> <span class="k">for</span> <span class="n">pt</span><span class="p">,</span> <span class="n">en</span> <span class="ow">in</span> <span class="n">train_examples</span><span class="p">),</span> <span class="n">target_vocab_size</span><span class="o">=</span><span class="mi">2</span><span class="o">**</span><span class="mi">13</span><span class="p">)</span>

<span class="n">tokenizer_pt</span> <span class="o">=</span> <span class="n">tfds</span><span class="p">.</span><span class="n">features</span><span class="p">.</span><span class="n">text</span><span class="p">.</span><span class="n">SubwordTextEncoder</span><span class="p">.</span><span class="n">build_from_corpus</span><span class="p">(</span>
    <span class="p">(</span><span class="n">pt</span><span class="p">.</span><span class="n">numpy</span><span class="p">()</span> <span class="k">for</span> <span class="n">pt</span><span class="p">,</span> <span class="n">en</span> <span class="ow">in</span> <span class="n">train_examples</span><span class="p">),</span> <span class="n">target_vocab_size</span><span class="o">=</span><span class="mi">2</span><span class="o">**</span><span class="mi">13</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>2023-05-09 11:56:13.233103: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sample_string</span> <span class="o">=</span> <span class="s">'Transformer is awesome.'</span>

<span class="n">tokenized_string</span> <span class="o">=</span> <span class="n">tokenizer_en</span><span class="p">.</span><span class="n">encode</span><span class="p">(</span><span class="n">sample_string</span><span class="p">)</span>
<span class="k">print</span> <span class="p">(</span><span class="s">'Tokenized string is {}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">tokenized_string</span><span class="p">))</span>

<span class="n">original_string</span> <span class="o">=</span> <span class="n">tokenizer_en</span><span class="p">.</span><span class="n">decode</span><span class="p">(</span><span class="n">tokenized_string</span><span class="p">)</span>
<span class="k">print</span> <span class="p">(</span><span class="s">'The original string: {}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">original_string</span><span class="p">))</span>

<span class="k">assert</span> <span class="n">original_string</span> <span class="o">==</span> <span class="n">sample_string</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Tokenized string is [7915, 1248, 7946, 7194, 13, 2799, 7877]
The original string: Transformer is awesome.
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">ts</span> <span class="ow">in</span> <span class="n">tokenized_string</span><span class="p">:</span>
    <span class="k">print</span> <span class="p">(</span><span class="s">'{} ----&gt; {}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">ts</span><span class="p">,</span> <span class="n">tokenizer_en</span><span class="p">.</span><span class="n">decode</span><span class="p">([</span><span class="n">ts</span><span class="p">])))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>7915 ----&gt; T
1248 ----&gt; ran
7946 ----&gt; s
7194 ----&gt; former 
13 ----&gt; is 
2799 ----&gt; awesome
7877 ----&gt; .
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">BUFFER_SIZE</span> <span class="o">=</span> <span class="mi">20000</span>
<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">64</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="n">lang1</span><span class="p">,</span> <span class="n">lang2</span><span class="p">):</span>
    <span class="n">lang1</span> <span class="o">=</span> <span class="p">[</span><span class="n">tokenizer_pt</span><span class="p">.</span><span class="n">vocab_size</span><span class="p">]</span> <span class="o">+</span> <span class="n">tokenizer_pt</span><span class="p">.</span><span class="n">encode</span><span class="p">(</span>
      <span class="n">lang1</span><span class="p">.</span><span class="n">numpy</span><span class="p">())</span> <span class="o">+</span> <span class="p">[</span><span class="n">tokenizer_pt</span><span class="p">.</span><span class="n">vocab_size</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>

    <span class="n">lang2</span> <span class="o">=</span> <span class="p">[</span><span class="n">tokenizer_en</span><span class="p">.</span><span class="n">vocab_size</span><span class="p">]</span> <span class="o">+</span> <span class="n">tokenizer_en</span><span class="p">.</span><span class="n">encode</span><span class="p">(</span>
      <span class="n">lang2</span><span class="p">.</span><span class="n">numpy</span><span class="p">())</span> <span class="o">+</span> <span class="p">[</span><span class="n">tokenizer_en</span><span class="p">.</span><span class="n">vocab_size</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">lang1</span><span class="p">,</span> <span class="n">lang2</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">MAX_LENGTH</span> <span class="o">=</span> <span class="mi">40</span>
<span class="k">def</span> <span class="nf">filter_max_length</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="n">MAX_LENGTH</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tf</span><span class="p">.</span><span class="n">logical_and</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">max_length</span><span class="p">,</span>
                        <span class="n">tf</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">max_length</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">tf_encode</span><span class="p">(</span><span class="n">pt</span><span class="p">,</span> <span class="n">en</span><span class="p">):</span>
    <span class="n">result_pt</span><span class="p">,</span> <span class="n">result_en</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">py_function</span><span class="p">(</span><span class="n">encode</span><span class="p">,</span> <span class="p">[</span><span class="n">pt</span><span class="p">,</span> <span class="n">en</span><span class="p">],</span> <span class="p">[</span><span class="n">tf</span><span class="p">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">tf</span><span class="p">.</span><span class="n">int64</span><span class="p">])</span>
    <span class="n">result_pt</span><span class="p">.</span><span class="n">set_shape</span><span class="p">([</span><span class="bp">None</span><span class="p">])</span>
    <span class="n">result_en</span><span class="p">.</span><span class="n">set_shape</span><span class="p">([</span><span class="bp">None</span><span class="p">])</span>
    
    <span class="k">return</span> <span class="n">result_pt</span><span class="p">,</span> <span class="n">result_en</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">train_examples</span><span class="p">.</span><span class="nb">map</span><span class="p">(</span><span class="n">tf_encode</span><span class="p">)</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="p">.</span><span class="nb">filter</span><span class="p">(</span><span class="n">filter_max_length</span><span class="p">)</span>
<span class="c1"># 将数据集缓存到内存中以加快读取速度。
</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="p">.</span><span class="n">cache</span><span class="p">()</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="p">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">BUFFER_SIZE</span><span class="p">).</span><span class="n">padded_batch</span><span class="p">(</span><span class="n">BATCH_SIZE</span><span class="p">)</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="p">.</span><span class="n">prefetch</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">experimental</span><span class="p">.</span><span class="n">AUTOTUNE</span><span class="p">)</span>


<span class="n">val_dataset</span> <span class="o">=</span> <span class="n">val_examples</span><span class="p">.</span><span class="nb">map</span><span class="p">(</span><span class="n">tf_encode</span><span class="p">)</span>
<span class="n">val_dataset</span> <span class="o">=</span> <span class="n">val_dataset</span><span class="p">.</span><span class="nb">filter</span><span class="p">(</span><span class="n">filter_max_length</span><span class="p">).</span><span class="n">padded_batch</span><span class="p">(</span><span class="n">BATCH_SIZE</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pt_batch</span><span class="p">,</span> <span class="n">en_batch</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">val_dataset</span><span class="p">))</span>
<span class="n">pt_batch</span><span class="p">,</span> <span class="n">en_batch</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(&lt;tf.Tensor: shape=(64, 40), dtype=int64, numpy=
 array([[8214, 1259,    5, ...,    0,    0,    0],
        [8214,  299,   13, ...,    0,    0,    0],
        [8214,   59,    8, ...,    0,    0,    0],
        ...,
        [8214,   95,    3, ...,    0,    0,    0],
        [8214, 5157,    1, ...,    0,    0,    0],
        [8214, 4479, 7990, ...,    0,    0,    0]])&gt;,
 &lt;tf.Tensor: shape=(64, 40), dtype=int64, numpy=
 array([[8087,   18,   12, ...,    0,    0,    0],
        [8087,  634,   30, ...,    0,    0,    0],
        [8087,   16,   13, ...,    0,    0,    0],
        ...,
        [8087,   12,   20, ...,    0,    0,    0],
        [8087,   17, 4981, ...,    0,    0,    0],
        [8087,   12, 5453, ...,    0,    0,    0]])&gt;)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">num_layers</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">d_model</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">dff</span> <span class="o">=</span> <span class="mi">512</span>
<span class="n">num_heads</span> <span class="o">=</span> <span class="mi">8</span>

<span class="n">input_vocab_size</span> <span class="o">=</span> <span class="n">tokenizer_pt</span><span class="p">.</span><span class="n">vocab_size</span> <span class="o">+</span> <span class="mi">2</span>
<span class="n">target_vocab_size</span> <span class="o">=</span> <span class="n">tokenizer_en</span><span class="p">.</span><span class="n">vocab_size</span> <span class="o">+</span> <span class="mi">2</span>
<span class="n">dropout_rate</span> <span class="o">=</span> <span class="mf">0.1</span>
</code></pre></div></div>

<p>优化器（Optimizer）
根据论文中的公式，将 Adam 优化器与自定义的学习速率调度程序（scheduler）配合使用。</p>

\[\Large{lrate = d_{model}^{-0.5} * min(step{\_}num^{-0.5}, step{\_}num * warmup{\_}steps^{-1.5})}\]

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">CustomSchedule</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">optimizers</span><span class="p">.</span><span class="n">schedules</span><span class="p">.</span><span class="n">LearningRateSchedule</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">warmup_steps</span><span class="o">=</span><span class="mi">4000</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">CustomSchedule</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">d_model</span> <span class="o">=</span> <span class="n">d_model</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">d_model</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">cast</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">d_model</span><span class="p">,</span> <span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">warmup_steps</span> <span class="o">=</span> <span class="n">warmup_steps</span>

    <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">step</span><span class="p">):</span>
        <span class="n">arg1</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">math</span><span class="p">.</span><span class="n">rsqrt</span><span class="p">(</span><span class="n">step</span><span class="p">)</span>
        <span class="n">arg2</span> <span class="o">=</span> <span class="n">step</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">warmup_steps</span> <span class="o">**</span> <span class="o">-</span><span class="mf">1.5</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">tf</span><span class="p">.</span><span class="n">math</span><span class="p">.</span><span class="n">rsqrt</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">d_model</span><span class="p">)</span> <span class="o">*</span> <span class="n">tf</span><span class="p">.</span><span class="n">math</span><span class="p">.</span><span class="n">minimum</span><span class="p">(</span><span class="n">arg1</span><span class="p">,</span> <span class="n">arg2</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">CustomSchedule</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">optimizers</span><span class="p">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="p">,</span> <span class="n">beta_1</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">beta_2</span><span class="o">=</span><span class="mf">0.98</span><span class="p">,</span> 
                                     <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-9</span><span class="p">)</span>
<span class="n">temp_learning_rate_schedule</span> <span class="o">=</span> <span class="n">CustomSchedule</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">temp_learning_rate_schedule</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="nb">range</span><span class="p">(</span><span class="mi">40000</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">)))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"Learning Rate"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"Train Step"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Text(0.5, 0, 'Train Step')
</code></pre></div></div>

<p><img src="/assets/2023-12-03-Transformer-learning-C5W4A1SubclassV1_files/2023-12-03-Transformer-learning-C5W4A1SubclassV1_89_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">loss_object</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">losses</span><span class="p">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">(</span>
    <span class="n">from_logits</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s">'none'</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">loss_function</span><span class="p">(</span><span class="n">real</span><span class="p">,</span> <span class="n">pred</span><span class="p">):</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">math</span><span class="p">.</span><span class="n">logical_not</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">math</span><span class="p">.</span><span class="n">equal</span><span class="p">(</span><span class="n">real</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
    <span class="n">loss_</span> <span class="o">=</span> <span class="n">loss_object</span><span class="p">(</span><span class="n">real</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">cast</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">loss_</span><span class="p">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">loss_</span> <span class="o">*=</span> <span class="n">mask</span>
    <span class="k">return</span> <span class="n">tf</span><span class="p">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">loss_</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_loss</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">metrics</span><span class="p">.</span><span class="n">Mean</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s">'train_loss'</span><span class="p">)</span>
<span class="n">train_accuracy</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">metrics</span><span class="p">.</span><span class="n">SparseCategoricalAccuracy</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="s">'train_accuracy'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">transformer</span> <span class="o">=</span> <span class="n">Transformer</span><span class="p">(</span><span class="n">num_layers</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">dff</span><span class="p">,</span>
                          <span class="n">input_vocab_size</span><span class="p">,</span> <span class="n">target_vocab_size</span><span class="p">,</span> 
                          <span class="n">max_positional_encoding_input</span><span class="o">=</span><span class="n">input_vocab_size</span><span class="p">,</span> 
                          <span class="n">max_positional_encoding_target</span><span class="o">=</span><span class="n">target_vocab_size</span><span class="p">,</span>
                          <span class="n">dropout_rate</span><span class="o">=</span><span class="n">dropout_rate</span><span class="p">)</span>
    
<span class="k">def</span> <span class="nf">create_masks</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">tar</span><span class="p">):</span>
    <span class="c1"># 编码器填充遮挡
</span>    <span class="n">enc_padding_mask</span> <span class="o">=</span> <span class="n">create_padding_mask</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span>
    <span class="c1"># 在解码器的第二个注意力模块使用。
</span>    <span class="c1"># 该填充遮挡用于遮挡编码器的输出。
</span>    <span class="n">dec_padding_mask</span> <span class="o">=</span> <span class="n">create_padding_mask</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span>

    <span class="c1"># 在解码器的第一个注意力模块使用。
</span>    <span class="c1"># 用于填充（pad）和遮挡（mask）解码器获取到的输入的后续标记（future tokens）。
</span>    <span class="n">look_ahead_mask</span> <span class="o">=</span> <span class="n">create_look_ahead_mask</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">shape</span><span class="p">(</span><span class="n">tar</span><span class="p">)[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">dec_target_padding_mask</span> <span class="o">=</span> <span class="n">create_padding_mask</span><span class="p">(</span><span class="n">tar</span><span class="p">)</span>
    <span class="n">combined_mask</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">dec_target_padding_mask</span><span class="p">,</span> <span class="n">look_ahead_mask</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">enc_padding_mask</span><span class="p">,</span> <span class="n">combined_mask</span><span class="p">,</span> <span class="n">dec_padding_mask</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">checkpoint_path</span> <span class="o">=</span> <span class="s">"./checkpoints/train"</span>

<span class="n">ckpt</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">train</span><span class="p">.</span><span class="n">Checkpoint</span><span class="p">(</span><span class="n">transformer</span><span class="o">=</span><span class="n">transformer</span><span class="p">,</span>
                           <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">)</span>

<span class="n">ckpt_manager</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">train</span><span class="p">.</span><span class="n">CheckpointManager</span><span class="p">(</span><span class="n">ckpt</span><span class="p">,</span> <span class="n">checkpoint_path</span><span class="p">,</span> <span class="n">max_to_keep</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="c1"># 如果检查点存在，则恢复最新的检查点。
</span><span class="k">if</span> <span class="n">ckpt_manager</span><span class="p">.</span><span class="n">latest_checkpoint</span><span class="p">:</span>
    <span class="n">ckpt</span><span class="p">.</span><span class="n">restore</span><span class="p">(</span><span class="n">ckpt_manager</span><span class="p">.</span><span class="n">latest_checkpoint</span><span class="p">)</span>
    <span class="k">print</span> <span class="p">(</span><span class="s">'Latest checkpoint restored!!'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">20</span>
<span class="c1"># 该 @tf.function 将追踪-编译 train_step 到 TF 图中，以便更快地
# 执行。该函数专用于参数张量的精确形状。为了避免由于可变序列长度或可变
# 批次大小（最后一批次较小）导致的再追踪，使用 input_signature 指定
# 更多的通用形状。
</span>
<span class="n">train_step_signature</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">tf</span><span class="p">.</span><span class="n">TensorSpec</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">int64</span><span class="p">),</span>
    <span class="n">tf</span><span class="p">.</span><span class="n">TensorSpec</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">int64</span><span class="p">),</span>
<span class="p">]</span>

<span class="o">@</span><span class="n">tf</span><span class="p">.</span><span class="n">function</span><span class="p">(</span><span class="n">input_signature</span><span class="o">=</span><span class="n">train_step_signature</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">train_step</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">tar</span><span class="p">):</span>
    <span class="n">tar_inp</span> <span class="o">=</span> <span class="n">tar</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">tar_real</span> <span class="o">=</span> <span class="n">tar</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span>

    <span class="n">enc_padding_mask</span><span class="p">,</span> <span class="n">combined_mask</span><span class="p">,</span> <span class="n">dec_padding_mask</span> <span class="o">=</span> <span class="n">create_masks</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">tar_inp</span><span class="p">)</span>
    
    <span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
        <span class="n">predictions</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">transformer</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">tar_inp</span><span class="p">,</span> 
                                     <span class="bp">True</span><span class="p">,</span> 
                                     <span class="n">enc_padding_mask</span><span class="p">,</span> 
                                     <span class="n">combined_mask</span><span class="p">,</span> 
                                     <span class="n">dec_padding_mask</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">tar_real</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>
        
        <span class="n">gradients</span> <span class="o">=</span> <span class="n">tape</span><span class="p">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">transformer</span><span class="p">.</span><span class="n">trainable_variables</span><span class="p">)</span>    
        <span class="n">optimizer</span><span class="p">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">gradients</span><span class="p">,</span> <span class="n">transformer</span><span class="p">.</span><span class="n">trainable_variables</span><span class="p">))</span>
        
        <span class="n">train_loss</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
        <span class="n">train_accuracy</span><span class="p">(</span><span class="n">tar_real</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>
    <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">train_loss</span><span class="p">.</span><span class="n">reset_states</span><span class="p">()</span>
    <span class="n">train_accuracy</span><span class="p">.</span><span class="n">reset_states</span><span class="p">()</span>

    <span class="c1"># inp -&gt; portuguese, tar -&gt; english
</span>    <span class="k">for</span> <span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">tar</span><span class="p">))</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">):</span>
        <span class="n">train_step</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">tar</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">batch</span> <span class="o">%</span> <span class="mi">50</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">print</span> <span class="p">(</span><span class="s">'Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span>
                <span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">train_loss</span><span class="p">.</span><span class="n">result</span><span class="p">(),</span> <span class="n">train_accuracy</span><span class="p">.</span><span class="n">result</span><span class="p">()))</span>
    
    <span class="k">if</span> <span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">5</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">ckpt_save_path</span> <span class="o">=</span> <span class="n">ckpt_manager</span><span class="p">.</span><span class="n">save</span><span class="p">()</span>
        <span class="k">print</span> <span class="p">(</span><span class="s">'Saving checkpoint for epoch {} at {}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span>
                                                         <span class="n">ckpt_save_path</span><span class="p">))</span>
    <span class="k">print</span> <span class="p">(</span><span class="s">'Epoch {} Loss {:.4f} Accuracy {:.4f}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> 
                                            <span class="n">train_loss</span><span class="p">.</span><span class="n">result</span><span class="p">(),</span> 
                                            <span class="n">train_accuracy</span><span class="p">.</span><span class="n">result</span><span class="p">()))</span>
    <span class="k">print</span> <span class="p">(</span><span class="s">'Time taken for 1 epoch: {} secs</span><span class="se">\n</span><span class="s">'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">time</span><span class="p">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>2023-05-09 12:09:35.813744: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:175] Filling up shuffle buffer (this may take a while): 13805 of 20000
2023-05-09 12:09:40.167687: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:228] Shuffle buffer filled.
/opt/conda/envs/tf/lib/python3.7/site-packages/keras/backend.py:4907: UserWarning: "`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?"
  '"`sparse_categorical_crossentropy` received `from_logits=True`, but '


Epoch 1 Batch 0 Loss 4.4735 Accuracy 0.0000
Epoch 1 Batch 50 Loss 4.2140 Accuracy 0.0030
Epoch 1 Batch 100 Loss 4.1867 Accuracy 0.0151
Epoch 1 Batch 150 Loss 4.1394 Accuracy 0.0195
Epoch 1 Batch 200 Loss 4.0686 Accuracy 0.0261
Epoch 1 Batch 250 Loss 3.9926 Accuracy 0.0342
Epoch 1 Batch 300 Loss 3.9032 Accuracy 0.0396
Epoch 1 Batch 350 Loss 3.8193 Accuracy 0.0438
Epoch 1 Batch 400 Loss 3.7331 Accuracy 0.0472
Epoch 1 Batch 450 Loss 3.6467 Accuracy 0.0520
Epoch 1 Batch 500 Loss 3.5620 Accuracy 0.0580
Epoch 1 Batch 550 Loss 3.4791 Accuracy 0.0647
Epoch 1 Batch 600 Loss 3.3928 Accuracy 0.0722
Epoch 1 Batch 650 Loss 3.3050 Accuracy 0.0804
Epoch 1 Batch 700 Loss 3.2147 Accuracy 0.0884
Epoch 1 Loss 3.2126 Accuracy 0.0887
Time taken for 1 epoch: 931.3518960475922 secs

Epoch 2 Batch 0 Loss 2.1738 Accuracy 0.2027
Epoch 2 Batch 50 Loss 1.8804 Accuracy 0.2144
Epoch 2 Batch 100 Loss 1.8061 Accuracy 0.2266
Epoch 2 Batch 150 Loss 1.7319 Accuracy 0.2366
Epoch 2 Batch 200 Loss 1.6622 Accuracy 0.2467
Epoch 2 Batch 250 Loss 1.6010 Accuracy 0.2561
Epoch 2 Batch 300 Loss 1.5416 Accuracy 0.2644
Epoch 2 Batch 350 Loss 1.4910 Accuracy 0.2720
Epoch 2 Batch 400 Loss 1.4425 Accuracy 0.2788
Epoch 2 Batch 450 Loss 1.3931 Accuracy 0.2846
Epoch 2 Batch 500 Loss 1.3492 Accuracy 0.2897
Epoch 2 Batch 550 Loss 1.3049 Accuracy 0.2945
Epoch 2 Batch 600 Loss 1.2646 Accuracy 0.2993
Epoch 2 Batch 650 Loss 1.2268 Accuracy 0.3045
Epoch 2 Batch 700 Loss 1.1889 Accuracy 0.3088
Epoch 2 Loss 1.1872 Accuracy 0.3089
Time taken for 1 epoch: 878.3964555263519 secs

Epoch 3 Batch 0 Loss 0.7012 Accuracy 0.3709
Epoch 3 Batch 50 Loss 0.6513 Accuracy 0.3779
Epoch 3 Batch 100 Loss 0.6306 Accuracy 0.3825
Epoch 3 Batch 150 Loss 0.6076 Accuracy 0.3854
Epoch 3 Batch 200 Loss 0.5862 Accuracy 0.3889
Epoch 3 Batch 250 Loss 0.5626 Accuracy 0.3923
Epoch 3 Batch 300 Loss 0.5408 Accuracy 0.3962
Epoch 3 Batch 350 Loss 0.5193 Accuracy 0.3995
Epoch 3 Batch 400 Loss 0.4992 Accuracy 0.4032
Epoch 3 Batch 450 Loss 0.4803 Accuracy 0.4065
Epoch 3 Batch 500 Loss 0.4607 Accuracy 0.4088
Epoch 3 Batch 550 Loss 0.4430 Accuracy 0.4120
Epoch 3 Batch 600 Loss 0.4256 Accuracy 0.4150
Epoch 3 Batch 650 Loss 0.4084 Accuracy 0.4172
Epoch 3 Batch 700 Loss 0.3918 Accuracy 0.4201
Epoch 3 Loss 0.3911 Accuracy 0.4201
Time taken for 1 epoch: 878.9100172519684 secs

Epoch 4 Batch 0 Loss 0.1494 Accuracy 0.4347
Epoch 4 Batch 50 Loss 0.1458 Accuracy 0.4610
Epoch 4 Batch 100 Loss 0.1356 Accuracy 0.4609
Epoch 4 Batch 150 Loss 0.1269 Accuracy 0.4615
Epoch 4 Batch 200 Loss 0.1185 Accuracy 0.4626
Epoch 4 Batch 250 Loss 0.1106 Accuracy 0.4639
Epoch 4 Batch 300 Loss 0.1035 Accuracy 0.4654
Epoch 4 Batch 350 Loss 0.0966 Accuracy 0.4653
Epoch 4 Batch 400 Loss 0.0901 Accuracy 0.4656
Epoch 4 Batch 450 Loss 0.0843 Accuracy 0.4658
Epoch 4 Batch 500 Loss 0.0791 Accuracy 0.4667
Epoch 4 Batch 550 Loss 0.0743 Accuracy 0.4667
Epoch 4 Batch 600 Loss 0.0698 Accuracy 0.4671
Epoch 4 Batch 650 Loss 0.0659 Accuracy 0.4673
Epoch 4 Batch 700 Loss 0.0623 Accuracy 0.4676
Epoch 4 Loss 0.0622 Accuracy 0.4675
Time taken for 1 epoch: 876.3038239479065 secs

Epoch 5 Batch 0 Loss 0.0117 Accuracy 0.4605
Epoch 5 Batch 50 Loss 0.0130 Accuracy 0.4672
Epoch 5 Batch 100 Loss 0.0126 Accuracy 0.4679
Epoch 5 Batch 150 Loss 0.0121 Accuracy 0.4712
Epoch 5 Batch 200 Loss 0.0114 Accuracy 0.4714
Epoch 5 Batch 250 Loss 0.0108 Accuracy 0.4705
Epoch 5 Batch 300 Loss 0.0102 Accuracy 0.4697
Epoch 5 Batch 350 Loss 0.0097 Accuracy 0.4688
Epoch 5 Batch 400 Loss 0.0095 Accuracy 0.4699
Epoch 5 Batch 450 Loss 0.0093 Accuracy 0.4699
Epoch 5 Batch 500 Loss 0.0092 Accuracy 0.4711
Epoch 5 Batch 550 Loss 0.0089 Accuracy 0.4713
Epoch 5 Batch 600 Loss 0.0087 Accuracy 0.4709
Epoch 5 Batch 650 Loss 0.0085 Accuracy 0.4710
Epoch 5 Batch 700 Loss 0.0082 Accuracy 0.4712
Saving checkpoint for epoch 5 at ./checkpoints/train/ckpt-1
Epoch 5 Loss 0.0082 Accuracy 0.4712
Time taken for 1 epoch: 878.6954836845398 secs

Epoch 6 Batch 0 Loss 0.0059 Accuracy 0.4674
Epoch 6 Batch 50 Loss 0.0077 Accuracy 0.4734
Epoch 6 Batch 100 Loss 0.0066 Accuracy 0.4704
Epoch 6 Batch 150 Loss 0.0062 Accuracy 0.4702
Epoch 6 Batch 200 Loss 0.0064 Accuracy 0.4696
Epoch 6 Batch 250 Loss 0.0062 Accuracy 0.4698
Epoch 6 Batch 300 Loss 0.0061 Accuracy 0.4709
Epoch 6 Batch 350 Loss 0.0060 Accuracy 0.4704
Epoch 6 Batch 400 Loss 0.0059 Accuracy 0.4702
Epoch 6 Batch 450 Loss 0.0059 Accuracy 0.4703
Epoch 6 Batch 500 Loss 0.0059 Accuracy 0.4706
Epoch 6 Batch 550 Loss 0.0058 Accuracy 0.4706
Epoch 6 Batch 600 Loss 0.0057 Accuracy 0.4709
Epoch 6 Batch 650 Loss 0.0055 Accuracy 0.4711
Epoch 6 Batch 700 Loss 0.0055 Accuracy 0.4710
Epoch 6 Loss 0.0056 Accuracy 0.4709
Time taken for 1 epoch: 877.8011014461517 secs

Epoch 7 Batch 0 Loss 0.0037 Accuracy 0.4639
Epoch 7 Batch 50 Loss 0.0053 Accuracy 0.4670
Epoch 7 Batch 100 Loss 0.0048 Accuracy 0.4698
Epoch 7 Batch 150 Loss 0.0049 Accuracy 0.4722
Epoch 7 Batch 200 Loss 0.0048 Accuracy 0.4723
Epoch 7 Batch 250 Loss 0.0048 Accuracy 0.4707
Epoch 7 Batch 300 Loss 0.0046 Accuracy 0.4708
Epoch 7 Batch 350 Loss 0.0046 Accuracy 0.4704
Epoch 7 Batch 400 Loss 0.0047 Accuracy 0.4694
Epoch 7 Batch 450 Loss 0.0046 Accuracy 0.4699
Epoch 7 Batch 500 Loss 0.0045 Accuracy 0.4704
Epoch 7 Batch 550 Loss 0.0045 Accuracy 0.4705
Epoch 7 Batch 600 Loss 0.0044 Accuracy 0.4704
Epoch 7 Batch 650 Loss 0.0044 Accuracy 0.4703
Epoch 7 Batch 700 Loss 0.0044 Accuracy 0.4707
Epoch 7 Loss 0.0044 Accuracy 0.4707
Time taken for 1 epoch: 877.6704905033112 secs

Epoch 8 Batch 0 Loss 0.0043 Accuracy 0.4354
Epoch 8 Batch 50 Loss 0.0041 Accuracy 0.4712
Epoch 8 Batch 100 Loss 0.0040 Accuracy 0.4708
Epoch 8 Batch 150 Loss 0.0037 Accuracy 0.4711
Epoch 8 Batch 200 Loss 0.0035 Accuracy 0.4703
Epoch 8 Batch 250 Loss 0.0034 Accuracy 0.4696
Epoch 8 Batch 300 Loss 0.0033 Accuracy 0.4704
Epoch 8 Batch 350 Loss 0.0032 Accuracy 0.4705
Epoch 8 Batch 400 Loss 0.0033 Accuracy 0.4708
Epoch 8 Batch 450 Loss 0.0033 Accuracy 0.4707
Epoch 8 Batch 500 Loss 0.0033 Accuracy 0.4708
Epoch 8 Batch 550 Loss 0.0033 Accuracy 0.4714
Epoch 8 Batch 600 Loss 0.0033 Accuracy 0.4717
Epoch 8 Batch 650 Loss 0.0033 Accuracy 0.4720
Epoch 8 Batch 700 Loss 0.0033 Accuracy 0.4717
Epoch 8 Loss 0.0033 Accuracy 0.4717
Time taken for 1 epoch: 871.3958556652069 secs

Epoch 9 Batch 0 Loss 0.0122 Accuracy 0.4700
Epoch 9 Batch 50 Loss 0.0029 Accuracy 0.4676
Epoch 9 Batch 100 Loss 0.0030 Accuracy 0.4734
Epoch 9 Batch 150 Loss 0.0030 Accuracy 0.4718
Epoch 9 Batch 200 Loss 0.0029 Accuracy 0.4721
Epoch 9 Batch 250 Loss 0.0028 Accuracy 0.4713
Epoch 9 Batch 300 Loss 0.0028 Accuracy 0.4717
Epoch 9 Batch 350 Loss 0.0028 Accuracy 0.4704
Epoch 9 Batch 400 Loss 0.0028 Accuracy 0.4703
Epoch 9 Batch 450 Loss 0.0028 Accuracy 0.4701
Epoch 9 Batch 500 Loss 0.0028 Accuracy 0.4710
Epoch 9 Batch 550 Loss 0.0028 Accuracy 0.4709
Epoch 9 Batch 600 Loss 0.0028 Accuracy 0.4704
Epoch 9 Batch 650 Loss 0.0028 Accuracy 0.4704
Epoch 9 Batch 700 Loss 0.0028 Accuracy 0.4706
Epoch 9 Loss 0.0028 Accuracy 0.4707
Time taken for 1 epoch: 877.2159721851349 secs

Epoch 10 Batch 0 Loss 0.0082 Accuracy 0.4655
Epoch 10 Batch 50 Loss 0.0024 Accuracy 0.4676
Epoch 10 Batch 100 Loss 0.0026 Accuracy 0.4686
Epoch 10 Batch 150 Loss 0.0025 Accuracy 0.4703
Epoch 10 Batch 200 Loss 0.0026 Accuracy 0.4698
Epoch 10 Batch 250 Loss 0.0027 Accuracy 0.4690
Epoch 10 Batch 300 Loss 0.0027 Accuracy 0.4687
Epoch 10 Batch 350 Loss 0.0027 Accuracy 0.4704
Epoch 10 Batch 400 Loss 0.0028 Accuracy 0.4704
Epoch 10 Batch 450 Loss 0.0027 Accuracy 0.4700
Epoch 10 Batch 500 Loss 0.0027 Accuracy 0.4707
Epoch 10 Batch 550 Loss 0.0027 Accuracy 0.4705
Epoch 10 Batch 600 Loss 0.0026 Accuracy 0.4704
Epoch 10 Batch 650 Loss 0.0026 Accuracy 0.4707
Epoch 10 Batch 700 Loss 0.0026 Accuracy 0.4708
Saving checkpoint for epoch 10 at ./checkpoints/train/ckpt-2
Epoch 10 Loss 0.0026 Accuracy 0.4709
Time taken for 1 epoch: 879.2923848628998 secs

Epoch 11 Batch 0 Loss 0.0007 Accuracy 0.4331
Epoch 11 Batch 50 Loss 0.0025 Accuracy 0.4653
Epoch 11 Batch 100 Loss 0.0024 Accuracy 0.4699
Epoch 11 Batch 150 Loss 0.0024 Accuracy 0.4715
Epoch 11 Batch 200 Loss 0.0022 Accuracy 0.4713
Epoch 11 Batch 250 Loss 0.0023 Accuracy 0.4725
Epoch 11 Batch 300 Loss 0.0023 Accuracy 0.4724
Epoch 11 Batch 350 Loss 0.0023 Accuracy 0.4721
Epoch 11 Batch 400 Loss 0.0022 Accuracy 0.4718
Epoch 11 Batch 450 Loss 0.0022 Accuracy 0.4718
Epoch 11 Batch 500 Loss 0.0022 Accuracy 0.4719
Epoch 11 Batch 550 Loss 0.0021 Accuracy 0.4719
Epoch 11 Batch 600 Loss 0.0021 Accuracy 0.4715
Epoch 11 Batch 650 Loss 0.0021 Accuracy 0.4710
Epoch 11 Batch 700 Loss 0.0022 Accuracy 0.4711
Epoch 11 Loss 0.0022 Accuracy 0.4711
Time taken for 1 epoch: 878.5343689918518 secs

Epoch 12 Batch 0 Loss 0.0007 Accuracy 0.4329
Epoch 12 Batch 50 Loss 0.0025 Accuracy 0.4751
Epoch 12 Batch 100 Loss 0.0027 Accuracy 0.4730
Epoch 12 Batch 150 Loss 0.0025 Accuracy 0.4719
Epoch 12 Batch 200 Loss 0.0023 Accuracy 0.4706
Epoch 12 Batch 250 Loss 0.0022 Accuracy 0.4717
Epoch 12 Batch 300 Loss 0.0023 Accuracy 0.4711
Epoch 12 Batch 350 Loss 0.0023 Accuracy 0.4705
Epoch 12 Batch 400 Loss 0.0022 Accuracy 0.4713
Epoch 12 Batch 450 Loss 0.0022 Accuracy 0.4710
Epoch 12 Batch 500 Loss 0.0022 Accuracy 0.4708
Epoch 12 Batch 550 Loss 0.0022 Accuracy 0.4709
Epoch 12 Batch 600 Loss 0.0022 Accuracy 0.4708
Epoch 12 Batch 650 Loss 0.0021 Accuracy 0.4704
Epoch 12 Batch 700 Loss 0.0022 Accuracy 0.4703
Epoch 12 Loss 0.0022 Accuracy 0.4703
Time taken for 1 epoch: 876.938019990921 secs

Epoch 13 Batch 0 Loss 0.0006 Accuracy 0.4633
Epoch 13 Batch 50 Loss 0.0013 Accuracy 0.4619
Epoch 13 Batch 200 Loss 0.0016 Accuracy 0.4688
Epoch 13 Batch 250 Loss 0.0017 Accuracy 0.4707
Epoch 13 Batch 300 Loss 0.0018 Accuracy 0.4710
Epoch 13 Batch 350 Loss 0.0017 Accuracy 0.4714
Epoch 13 Batch 400 Loss 0.0018 Accuracy 0.4710
Epoch 13 Batch 450 Loss 0.0017 Accuracy 0.4712
Epoch 13 Batch 500 Loss 0.0017 Accuracy 0.4714
Epoch 13 Batch 550 Loss 0.0017 Accuracy 0.4716
Epoch 13 Batch 600 Loss 0.0018 Accuracy 0.4713
Epoch 13 Batch 650 Loss 0.0017 Accuracy 0.4712
Epoch 13 Batch 700 Loss 0.0017 Accuracy 0.4712
Epoch 13 Loss 0.0017 Accuracy 0.4712
Time taken for 1 epoch: 859.017169713974 secs

Epoch 14 Batch 0 Loss 0.0024 Accuracy 0.4848
Epoch 14 Batch 50 Loss 0.0016 Accuracy 0.4745
Epoch 14 Batch 100 Loss 0.0014 Accuracy 0.4715
Epoch 14 Batch 150 Loss 0.0016 Accuracy 0.4719
Epoch 14 Batch 200 Loss 0.0017 Accuracy 0.4732
Epoch 14 Batch 250 Loss 0.0017 Accuracy 0.4718
Epoch 14 Batch 300 Loss 0.0018 Accuracy 0.4714
Epoch 14 Batch 350 Loss 0.0017 Accuracy 0.4710
Epoch 14 Batch 400 Loss 0.0018 Accuracy 0.4711
Epoch 14 Batch 450 Loss 0.0017 Accuracy 0.4701
Epoch 14 Batch 500 Loss 0.0018 Accuracy 0.4709
Epoch 14 Batch 550 Loss 0.0018 Accuracy 0.4711
Epoch 14 Batch 600 Loss 0.0018 Accuracy 0.4713
Epoch 14 Batch 650 Loss 0.0018 Accuracy 0.4717
Epoch 14 Batch 700 Loss 0.0018 Accuracy 0.4716
Epoch 14 Loss 0.0018 Accuracy 0.4716
Time taken for 1 epoch: 857.9521288871765 secs

Epoch 15 Batch 0 Loss 0.0056 Accuracy 0.4800
Epoch 15 Batch 50 Loss 0.0022 Accuracy 0.4709
Epoch 15 Batch 100 Loss 0.0019 Accuracy 0.4722
Epoch 15 Batch 150 Loss 0.0018 Accuracy 0.4707
Epoch 15 Batch 200 Loss 0.0018 Accuracy 0.4706
Epoch 15 Batch 250 Loss 0.0018 Accuracy 0.4715
Epoch 15 Batch 300 Loss 0.0017 Accuracy 0.4703
Epoch 15 Batch 350 Loss 0.0017 Accuracy 0.4699
Epoch 15 Batch 400 Loss 0.0017 Accuracy 0.4700
Epoch 15 Batch 450 Loss 0.0017 Accuracy 0.4707
Epoch 15 Batch 500 Loss 0.0017 Accuracy 0.4711
Epoch 15 Batch 550 Loss 0.0017 Accuracy 0.4699
Epoch 15 Batch 600 Loss 0.0016 Accuracy 0.4702
Epoch 15 Batch 650 Loss 0.0016 Accuracy 0.4706
Epoch 15 Batch 700 Loss 0.0016 Accuracy 0.4708
Saving checkpoint for epoch 15 at ./checkpoints/train/ckpt-3
Epoch 15 Loss 0.0016 Accuracy 0.4707
Time taken for 1 epoch: 854.1302998065948 secs

Epoch 16 Batch 0 Loss 0.0003 Accuracy 0.4543
Epoch 16 Batch 50 Loss 0.0015 Accuracy 0.4704
Epoch 16 Batch 100 Loss 0.0013 Accuracy 0.4686
Epoch 16 Batch 150 Loss 0.0013 Accuracy 0.4687
Epoch 16 Batch 200 Loss 0.0014 Accuracy 0.4682
Epoch 16 Batch 250 Loss 0.0014 Accuracy 0.4698
Epoch 16 Batch 300 Loss 0.0014 Accuracy 0.4697
Epoch 16 Batch 350 Loss 0.0015 Accuracy 0.4707
Epoch 16 Batch 400 Loss 0.0015 Accuracy 0.4715
Epoch 16 Batch 450 Loss 0.0016 Accuracy 0.4712
Epoch 16 Batch 500 Loss 0.0016 Accuracy 0.4716
Epoch 16 Batch 550 Loss 0.0016 Accuracy 0.4715
Epoch 16 Batch 600 Loss 0.0016 Accuracy 0.4721
Epoch 16 Batch 650 Loss 0.0016 Accuracy 0.4717
Epoch 16 Batch 700 Loss 0.0015 Accuracy 0.4714
Epoch 16 Loss 0.0015 Accuracy 0.4714
Time taken for 1 epoch: 851.0064783096313 secs

Epoch 17 Batch 0 Loss 0.0003 Accuracy 0.4688
Epoch 17 Batch 50 Loss 0.0011 Accuracy 0.4727
Epoch 17 Batch 100 Loss 0.0014 Accuracy 0.4711
Epoch 17 Batch 150 Loss 0.0017 Accuracy 0.4718
Epoch 17 Batch 200 Loss 0.0017 Accuracy 0.4718
Epoch 17 Batch 250 Loss 0.0016 Accuracy 0.4724
Epoch 17 Batch 300 Loss 0.0016 Accuracy 0.4720
Epoch 17 Batch 350 Loss 0.0016 Accuracy 0.4707
Epoch 17 Batch 400 Loss 0.0015 Accuracy 0.4709
Epoch 17 Batch 450 Loss 0.0015 Accuracy 0.4717
Epoch 17 Batch 500 Loss 0.0014 Accuracy 0.4711
Epoch 17 Batch 550 Loss 0.0014 Accuracy 0.4714
Epoch 17 Batch 600 Loss 0.0014 Accuracy 0.4717
Epoch 17 Batch 650 Loss 0.0014 Accuracy 0.4723
Epoch 17 Batch 700 Loss 0.0014 Accuracy 0.4714
Epoch 17 Loss 0.0014 Accuracy 0.4715
Time taken for 1 epoch: 853.1788289546967 secs

Epoch 18 Batch 0 Loss 0.0006 Accuracy 0.4642
Epoch 18 Batch 50 Loss 0.0013 Accuracy 0.4678
Epoch 18 Batch 100 Loss 0.0012 Accuracy 0.4722
Epoch 18 Batch 150 Loss 0.0011 Accuracy 0.4726
Epoch 18 Batch 200 Loss 0.0010 Accuracy 0.4732
Epoch 18 Batch 250 Loss 0.0012 Accuracy 0.4719
Epoch 18 Batch 300 Loss 0.0012 Accuracy 0.4713
Epoch 18 Batch 350 Loss 0.0012 Accuracy 0.4721
Epoch 18 Batch 400 Loss 0.0012 Accuracy 0.4721
Epoch 18 Batch 450 Loss 0.0012 Accuracy 0.4715
Epoch 18 Batch 500 Loss 0.0012 Accuracy 0.4710
Epoch 18 Batch 550 Loss 0.0012 Accuracy 0.4704
Epoch 18 Batch 600 Loss 0.0013 Accuracy 0.4706
Epoch 18 Batch 650 Loss 0.0013 Accuracy 0.4710
Epoch 18 Batch 700 Loss 0.0013 Accuracy 0.4709
Epoch 18 Loss 0.0013 Accuracy 0.4710
Time taken for 1 epoch: 857.0118782520294 secs

Epoch 19 Batch 0 Loss 0.0002 Accuracy 0.4570
Epoch 19 Batch 50 Loss 0.0011 Accuracy 0.4778
Epoch 19 Batch 100 Loss 0.0016 Accuracy 0.4747
Epoch 19 Batch 150 Loss 0.0016 Accuracy 0.4735
Epoch 19 Batch 200 Loss 0.0016 Accuracy 0.4714
Epoch 19 Batch 250 Loss 0.0015 Accuracy 0.4710
Epoch 19 Batch 300 Loss 0.0015 Accuracy 0.4713
Epoch 19 Batch 350 Loss 0.0015 Accuracy 0.4711
Epoch 19 Batch 400 Loss 0.0015 Accuracy 0.4705
Epoch 19 Batch 450 Loss 0.0015 Accuracy 0.4702
Epoch 19 Batch 500 Loss 0.0014 Accuracy 0.4699
Epoch 19 Batch 550 Loss 0.0014 Accuracy 0.4699
Epoch 19 Batch 600 Loss 0.0014 Accuracy 0.4703
Epoch 19 Batch 650 Loss 0.0014 Accuracy 0.4708
Epoch 19 Batch 700 Loss 0.0014 Accuracy 0.4712
Epoch 19 Loss 0.0014 Accuracy 0.4712
Time taken for 1 epoch: 856.3480639457703 secs

Epoch 20 Batch 0 Loss 0.0008 Accuracy 0.4688
Epoch 20 Batch 50 Loss 0.0017 Accuracy 0.4751
Epoch 20 Batch 100 Loss 0.0011 Accuracy 0.4722
Epoch 20 Batch 150 Loss 0.0011 Accuracy 0.4716
Epoch 20 Batch 200 Loss 0.0012 Accuracy 0.4714
Epoch 20 Batch 250 Loss 0.0011 Accuracy 0.4724
Epoch 20 Batch 300 Loss 0.0011 Accuracy 0.4720
Epoch 20 Batch 350 Loss 0.0012 Accuracy 0.4723
Epoch 20 Batch 400 Loss 0.0012 Accuracy 0.4724
Epoch 20 Batch 450 Loss 0.0012 Accuracy 0.4718
Epoch 20 Batch 500 Loss 0.0012 Accuracy 0.4716
Epoch 20 Batch 550 Loss 0.0012 Accuracy 0.4711
Epoch 20 Batch 600 Loss 0.0012 Accuracy 0.4712
Epoch 20 Batch 650 Loss 0.0013 Accuracy 0.4712
Epoch 20 Batch 700 Loss 0.0013 Accuracy 0.4709
Saving checkpoint for epoch 20 at ./checkpoints/train/ckpt-4
Epoch 20 Loss 0.0013 Accuracy 0.4709
Time taken for 1 epoch: 858.4996719360352 secs
</code></pre></div></div>

<h2 id="conclusion">Conclusion</h2>

<p>You’ve come to the end of the graded portion of the assignment. By now, you’ve:</p>

<ul>
  <li>Create positional encodings to capture sequential relationships in data</li>
  <li>Calculate scaled dot-product self-attention with word embeddings</li>
  <li>Implement masked multi-head attention</li>
  <li>Build and train a Transformer model</li>
</ul>

<p><b>What you should remember</b>:</p>

<ul>
  <li>The combination of self-attention and convolutional network layers allows of parallization of training and <em>faster training</em>.</li>
  <li>Self-attention is calculated using the generated query Q, key K, and value V matrices.</li>
  <li>Adding positional encoding to word embeddings is an effective way of include sequence information in self-attention calculations.</li>
  <li>Multi-head attention can help detect multiple features in your sentence.</li>
  <li>Masking stops the model from ‘looking ahead’ during training, or weighting zeroes too much when processing cropped sentences.</li>
</ul>

<p>Now that you have completed the Transformer assignment, make sure you check out the ungraded labs to apply the Transformer model to practical use cases such as Name Entity Recogntion (NER) and Question Answering (QA).</p>

<h1 id="congratulations-on-finishing-the-deep-learning-specialization-">Congratulations on finishing the Deep Learning Specialization!!!!!! 🎉</h1>

<p>This was the last graded assignment of the specialization. It is now time to celebrate all your hard work and dedication!</p>

<p><a name="7"></a></p>
<h2 id="7---references">7 - References</h2>

<p>The Transformer algorithm was due to Vaswani et al. (2017).</p>

<ul>
  <li>Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin (2017). <a href="https://arxiv.org/abs/1706.03762">Attention Is All You Need</a></li>
</ul>

<p><strong>Training</strong>
This section describes the training regime for our models.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Batch</span><span class="p">:</span>
    <span class="s">"Object for holding a batch of data with mask during training."</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">trg</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">src</span> <span class="o">=</span> <span class="n">src</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">src_mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">src</span> <span class="o">!=</span> <span class="n">pad</span><span class="p">).</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">trg</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">trg</span> <span class="o">=</span> <span class="n">trg</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">trg_y</span> <span class="o">=</span> <span class="n">trg</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">trg_mask</span> <span class="o">=</span> \
                <span class="bp">self</span><span class="p">.</span><span class="n">make_std_mask</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">trg</span><span class="p">,</span> <span class="n">pad</span><span class="p">)</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">ntokens</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">trg_y</span> <span class="o">!=</span> <span class="n">pad</span><span class="p">).</span><span class="n">data</span><span class="p">.</span><span class="nb">sum</span><span class="p">()</span>
    
    <span class="o">@</span><span class="nb">staticmethod</span>
    <span class="k">def</span> <span class="nf">make_std_mask</span><span class="p">(</span><span class="n">tgt</span><span class="p">,</span> <span class="n">pad</span><span class="p">):</span>
        <span class="s">"Create a mask to hide padding and future words."</span>
        <span class="n">tgt_mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">tgt</span> <span class="o">!=</span> <span class="n">pad</span><span class="p">).</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">tgt_mask</span> <span class="o">=</span> <span class="n">tgt_mask</span> <span class="o">&amp;</span> <span class="n">Variable</span><span class="p">(</span>
            <span class="n">subsequent_mask</span><span class="p">(</span><span class="n">tgt</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)).</span><span class="n">type_as</span><span class="p">(</span><span class="n">tgt_mask</span><span class="p">.</span><span class="n">data</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">tgt_mask</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">run_epoch</span><span class="p">(</span><span class="n">data_iter</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">loss_compute</span><span class="p">):</span>
    <span class="s">"Standard Training and Logging Function"</span>
    <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">total_tokens</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">total_loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">data_iter</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">forward</span><span class="p">(</span><span class="n">batch</span><span class="p">.</span><span class="n">src</span><span class="p">,</span> <span class="n">batch</span><span class="p">.</span><span class="n">trg</span><span class="p">,</span> 
                            <span class="n">batch</span><span class="p">.</span><span class="n">src_mask</span><span class="p">,</span> <span class="n">batch</span><span class="p">.</span><span class="n">trg_mask</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_compute</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">batch</span><span class="p">.</span><span class="n">trg_y</span><span class="p">,</span> <span class="n">batch</span><span class="p">.</span><span class="n">ntokens</span><span class="p">)</span>
        <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span>
        <span class="n">total_tokens</span> <span class="o">+=</span> <span class="n">batch</span><span class="p">.</span><span class="n">ntokens</span>
        <span class="n">tokens</span> <span class="o">+=</span> <span class="n">batch</span><span class="p">.</span><span class="n">ntokens</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">50</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">elapsed</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span>
            <span class="k">print</span><span class="p">(</span><span class="s">"Epoch Step: %d Loss: %f Tokens per Sec: %f"</span> <span class="o">%</span>
                    <span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">loss</span> <span class="o">/</span> <span class="n">batch</span><span class="p">.</span><span class="n">ntokens</span><span class="p">,</span> <span class="n">tokens</span> <span class="o">/</span> <span class="n">elapsed</span><span class="p">))</span>
            <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="n">time</span><span class="p">()</span>
            <span class="n">tokens</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">return</span> <span class="n">total_loss</span> <span class="o">/</span> <span class="n">total_tokens</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">global</span> <span class="n">max_src_in_batch</span><span class="p">,</span> <span class="n">max_tgt_in_batch</span>
<span class="k">def</span> <span class="nf">batch_size_fn</span><span class="p">(</span><span class="n">new</span><span class="p">,</span> <span class="n">count</span><span class="p">,</span> <span class="n">sofar</span><span class="p">):</span>
    <span class="s">"Keep augmenting batch and calculate total number of tokens + padding."</span>
    <span class="k">global</span> <span class="n">max_src_in_batch</span><span class="p">,</span> <span class="n">max_tgt_in_batch</span>
    <span class="k">if</span> <span class="n">count</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">max_src_in_batch</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">max_tgt_in_batch</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">max_src_in_batch</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">max_src_in_batch</span><span class="p">,</span>  <span class="nb">len</span><span class="p">(</span><span class="n">new</span><span class="p">.</span><span class="n">src</span><span class="p">))</span>
    <span class="n">max_tgt_in_batch</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">max_tgt_in_batch</span><span class="p">,</span>  <span class="nb">len</span><span class="p">(</span><span class="n">new</span><span class="p">.</span><span class="n">trg</span><span class="p">)</span> <span class="o">+</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">src_elements</span> <span class="o">=</span> <span class="n">count</span> <span class="o">*</span> <span class="n">max_src_in_batch</span>
    <span class="n">tgt_elements</span> <span class="o">=</span> <span class="n">count</span> <span class="o">*</span> <span class="n">max_tgt_in_batch</span>
    <span class="k">return</span> <span class="nb">max</span><span class="p">(</span><span class="n">src_elements</span><span class="p">,</span> <span class="n">tgt_elements</span><span class="p">)</span>
</code></pre></div></div>]]></content><author><name>Zhu Tianda</name></author><category term="coding" /><category term="AI" /><category term="Transformer" /><summary type="html"><![CDATA[I update this document also refere to https://www.tensorflow.org/tutorials/text/transformer?hl=zh-cn https://nlp.seas.harvard.edu/2018/04/03/attention.html#positional-encoding]]></summary></entry><entry><title type="html">XGBoost from scratch</title><link href="http://0.0.0.0:8855/coding/2023/11/02/xgboost-from-scratch.html" rel="alternate" type="text/html" title="XGBoost from scratch" /><published>2023-11-02T00:00:00+08:00</published><updated>2023-11-02T00:00:00+08:00</updated><id>http://0.0.0.0:8855/coding/2023/11/02/xgboost-from-scratch</id><content type="html" xml:base="http://0.0.0.0:8855/coding/2023/11/02/xgboost-from-scratch.html"><![CDATA[<h1 id="xgboost-from-scratch">XGBoost from scratch</h1>

<p><img src="/assets/2023-11-02-xgboost-from-scratch_files/adb4c4af-7b2f-4a8e-8b0a-32846e450ebb.png" alt="image.png" /></p>

<h2 id="the--xgboost-model-class">The  XGBoost Model Class</h2>

<p>We begin with the user-facing API for our model, a class called <code class="language-plaintext highlighter-rouge">XGBoostModel</code> which will implement gradient boosting and prediction.  To be more consistent with the XGBoost library, we’ll pass hyperparameters to our model in a parameter dictionary, so our init method is going to pull relevant parameters out of the dictionary and set them as object attributes. Note the use of python’s <code class="language-plaintext highlighter-rouge">defaultdict</code> so we don’t have to worry about handling key errors if we try to access a parameter that the user didn’t set in the dictionary.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span> 
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">defaultdict</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">XGBoostModel</span><span class="p">():</span>
    <span class="s">'''XGBoost from Scratch
    '''</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">random_seed</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">params</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="bp">None</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">subsample</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">params</span><span class="p">[</span><span class="s">'subsample'</span><span class="p">]</span> \
            <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">params</span><span class="p">[</span><span class="s">'subsample'</span><span class="p">]</span> <span class="k">else</span> <span class="mf">1.0</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">params</span><span class="p">[</span><span class="s">'learning_rate'</span><span class="p">]</span> \
            <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">params</span><span class="p">[</span><span class="s">'learning_rate'</span><span class="p">]</span> <span class="k">else</span> <span class="mf">0.3</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">base_prediction</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">params</span><span class="p">[</span><span class="s">'base_score'</span><span class="p">]</span> \
            <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">params</span><span class="p">[</span><span class="s">'base_score'</span><span class="p">]</span> <span class="k">else</span> <span class="mf">0.5</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">max_depth</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">params</span><span class="p">[</span><span class="s">'max_depth'</span><span class="p">]</span> \
            <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">params</span><span class="p">[</span><span class="s">'max_depth'</span><span class="p">]</span> <span class="k">else</span> <span class="mi">5</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">random_seed</span><span class="p">)</span>
</code></pre></div></div>

<p>The fit method, based on our classic GBM,  takes a feature dataframe, a target vector, the objective function, and the number of boosting rounds as arguments. The user-supplied objective function should be an object with loss, gradient, and hessian methods, each of which takes a target vector and a prediction vector as input; the loss method should return a scalar loss score, the gradient method should return a vector of gradients, and the  hessian method should return a vector of hessians.</p>

<ul>
  <li>step1:  In contrast to boosting in the classic GBM, instead of computing residuals between the current predictions and the target, we compute gradients and hessians of the loss function with respect to the current predictions<br />
      记一阶导为gradients: $ g_i=l^{\prime}\left(y_i, \widehat{y}_i^{(t-1)}\right) $
      二阶导为hessians: $h_i=l^{\prime \prime}\left(y_i, \widehat{y}_i^{(t-1)}\right)$.</li>
  <li>
    <p>step2: and instead of predicting residuals with a decision tree, we fit a special XGBoost tree booster (which we’ll implement in a moment) using the gradients and hessians.</p>
  </li>
  <li>step3: The rest of the fit method is the same as the classic GBM, and the predict method is identical too.</li>
</ul>

<p>I’ve also added row subsampling by drawing a random subset of instance indices and passing them to the tree booster during each boosting round.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">objective</span><span class="p">,</span> <span class="n">num_boost_round</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
    <span class="n">current_predictions</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">base_prediction</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">y</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">boosters</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_boost_round</span><span class="p">):</span>
        <span class="c1">## compute gradients and hessians
</span>        <span class="n">gradients</span> <span class="o">=</span> <span class="n">objective</span><span class="p">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">current_predictions</span><span class="p">)</span>
        <span class="n">hessians</span> <span class="o">=</span> <span class="n">objective</span><span class="p">.</span><span class="n">hessian</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">current_predictions</span><span class="p">)</span>
        <span class="c1">## subsampling by drawing a random subset of instance indices and passing them to the tree booster during each boosting round
</span>        <span class="n">sample_idxs</span> <span class="o">=</span> <span class="bp">None</span> <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">subsample</span> <span class="o">==</span> <span class="mf">1.0</span> \
            <span class="k">else</span> <span class="bp">self</span><span class="p">.</span><span class="n">rng</span><span class="p">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> 
                                 <span class="n">size</span><span class="o">=</span><span class="n">math</span><span class="p">.</span><span class="n">floor</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">subsample</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)),</span> 
                                 <span class="n">replace</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        <span class="c1">#set up the boost tree
</span>        <span class="n">booster</span> <span class="o">=</span> <span class="n">TreeBooster</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">gradients</span><span class="p">,</span> <span class="n">hessians</span><span class="p">,</span> 
                              <span class="bp">self</span><span class="p">.</span><span class="n">params</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">max_depth</span><span class="p">,</span> <span class="n">sample_idxs</span><span class="p">)</span>
        <span class="n">current_predictions</span> <span class="o">+=</span> <span class="bp">self</span><span class="p">.</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">booster</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">boosters</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">booster</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span> 
            <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'[</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s">] train loss = </span><span class="si">{</span><span class="n">objective</span><span class="p">.</span><span class="n">loss</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">current_predictions</span><span class="p">)</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
            
<span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">base_prediction</span> <span class="o">+</span> <span class="bp">self</span><span class="p">.</span><span class="n">learning_rate</span> 
            <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">([</span><span class="n">booster</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="k">for</span> <span class="n">booster</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">boosters</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>

<span class="n">XGBoostModel</span><span class="p">.</span><span class="n">fit</span> <span class="o">=</span> <span class="n">fit</span>
<span class="n">XGBoostModel</span><span class="p">.</span><span class="n">predict</span> <span class="o">=</span> <span class="n">predict</span>            
</code></pre></div></div>

<p>All we have to do now is implement the tree booster.</p>

<h2 id="the-xgboost-tree-booster">The XGBoost Tree Booster</h2>

<p>The XGBoost tree booster is a modified version of the decision tree that we built in the decision tree from scratch post. Like the decision tree, we recursively build a binary tree structure by finding the best split rule for each node in the tree.</p>

<ul>
  <li>The main difference is the criterion for evaluating splits and the way that we define a leaf’s predicted value. Instead of being functions of the target values of the instances in each node, the criterion and predicted values are functions of the instance gradients and hessians. Thus we need only make a couple of modifications to our previous decision tree implementation to create the XGBoost tree booster.</li>
</ul>

<h3 id="initialization-and-inserting-child-nodes">Initialization and Inserting Child Nodes</h3>
<p>Most of the init method is just parsing the parameter dictionary to assign parameters as object attributes.</p>

<ul>
  <li>The one notable difference from our decision tree is in the way we define the node’s predicted value. We define <code class="language-plaintext highlighter-rouge">self.value</code> according to equation 5 of the XGBoost paper, a simple function of the gradient and hessian values of the instances in the current node. Of course the init also goes on to build the tree via the maybe insert child nodes method. This method is nearly identical to the one we implemented for our decision tree. So far so good.</li>
</ul>

<p>Note: XGBoost目标函数的各个叶子结点的目标式子是相互独立的。即每个叶子结点的式子都达到最值点，整个目标函数也达到最值点。则每个叶子结点的权重 $w_j^*$ 及此时达到最优的 $O b j$ 目标值 :
\(w_j^*=-\frac{G_j}{H_j+\lambda} \quad O b j=-\frac{1}{2} \sum_{j=1}^T \frac{G_j{ }^2}{H_j+\lambda}+\gamma T\)</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">TreeBooster</span><span class="p">():</span>
    <span class="c1">#init get the input include gradient and hessian value of all data
</span>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">max_depth</span><span class="p">,</span> <span class="n">idxs</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">params</span> <span class="o">=</span> <span class="n">params</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">max_depth</span> <span class="o">=</span> <span class="n">max_depth</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="p">.</span><span class="n">max_depth</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">,</span> <span class="s">'max_depth must be nonnegative'</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">min_child_weight</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s">'min_child_weight'</span><span class="p">]</span> \
            <span class="k">if</span> <span class="n">params</span><span class="p">[</span><span class="s">'min_child_weight'</span><span class="p">]</span> <span class="k">else</span> <span class="mf">1.0</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">reg_lambda</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s">'reg_lambda'</span><span class="p">]</span> <span class="k">if</span> <span class="n">params</span><span class="p">[</span><span class="s">'reg_lambda'</span><span class="p">]</span> <span class="k">else</span> <span class="mf">1.0</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">gamma</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s">'gamma'</span><span class="p">]</span> <span class="k">if</span> <span class="n">params</span><span class="p">[</span><span class="s">'gamma'</span><span class="p">]</span> <span class="k">else</span> <span class="mf">0.0</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">colsample_bynode</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s">'colsample_bynode'</span><span class="p">]</span> \
            <span class="k">if</span> <span class="n">params</span><span class="p">[</span><span class="s">'colsample_bynode'</span><span class="p">]</span> <span class="k">else</span> <span class="mf">1.0</span>
        <span class="c1">#if dataframe then covnert to data array
</span>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">pd</span><span class="p">.</span><span class="n">Series</span><span class="p">):</span> <span class="n">g</span> <span class="o">=</span> <span class="n">g</span><span class="p">.</span><span class="n">values</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">pd</span><span class="p">.</span><span class="n">Series</span><span class="p">):</span> <span class="n">h</span> <span class="o">=</span> <span class="n">h</span><span class="p">.</span><span class="n">values</span>
        <span class="k">if</span> <span class="n">idxs</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span> <span class="n">idxs</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">g</span><span class="p">))</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">g</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">h</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">idxs</span> <span class="o">=</span> <span class="n">X</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">idxs</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">n</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">c</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">idxs</span><span class="p">),</span> <span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        
        <span class="c1">#set the top node w value /predict value
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">value</span> <span class="o">=</span> <span class="o">-</span><span class="n">g</span><span class="p">[</span><span class="n">idxs</span><span class="p">].</span><span class="nb">sum</span><span class="p">()</span> <span class="o">/</span> <span class="p">(</span><span class="n">h</span><span class="p">[</span><span class="n">idxs</span><span class="p">].</span><span class="nb">sum</span><span class="p">()</span> <span class="o">+</span> <span class="bp">self</span><span class="p">.</span><span class="n">reg_lambda</span><span class="p">)</span> <span class="c1"># Eq (5)
</span>        
        <span class="c1">#init stat , if later have no change(no split so far) , it means it is leaf node
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">best_score_so_far</span> <span class="o">=</span> <span class="mf">0.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">max_depth</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">_maybe_insert_child_nodes</span><span class="p">()</span>

    <span class="c1">#try to build one node for the tree
</span>    <span class="k">def</span> <span class="nf">_maybe_insert_child_nodes</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">c</span><span class="p">):</span> <span class="bp">self</span><span class="p">.</span><span class="n">_find_better_split</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">is_leaf</span><span class="p">:</span> <span class="k">return</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">X</span><span class="p">.</span><span class="n">values</span><span class="p">[</span><span class="bp">self</span><span class="p">.</span><span class="n">idxs</span><span class="p">,</span><span class="bp">self</span><span class="p">.</span><span class="n">split_feature_idx</span><span class="p">]</span>
        <span class="n">left_idx</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">x</span> <span class="o">&lt;=</span> <span class="bp">self</span><span class="p">.</span><span class="n">threshold</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">right_idx</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">x</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="p">.</span><span class="n">threshold</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">left</span> <span class="o">=</span> <span class="n">TreeBooster</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">g</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">h</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">params</span><span class="p">,</span> 
                                <span class="bp">self</span><span class="p">.</span><span class="n">max_depth</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">idxs</span><span class="p">[</span><span class="n">left_idx</span><span class="p">])</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">right</span> <span class="o">=</span> <span class="n">TreeBooster</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">g</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">h</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">params</span><span class="p">,</span> 
                                 <span class="bp">self</span><span class="p">.</span><span class="n">max_depth</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">idxs</span><span class="p">[</span><span class="n">right_idx</span><span class="p">])</span>

    <span class="o">@</span><span class="nb">property</span>
    <span class="k">def</span> <span class="nf">is_leaf</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span> <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">best_score_so_far</span> <span class="o">==</span> <span class="mf">0.</span>

    <span class="k">def</span> <span class="nf">_find_better_split</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">feature_idx</span><span class="p">):</span>
        <span class="k">pass</span>
</code></pre></div></div>

<h3 id="split-finding">Split Finding</h3>

<p>Split finding follows the exact same pattern that we used in the decision tree, except we keep track of gradient and hessian stats instead of target value stats, and of course we use the XGBoost gain criterion (equation 7 from the paper) for evaluating splits.</p>

\[O b j=-\frac{1}{2} \sum_{j=1}^T \frac{G_j^2}{H_j+\lambda}+\gamma T\]

\[{ Gain }=\frac{1}{2}\left[\frac{G_L^2}{H_L+\lambda}+\frac{G_R^2}{H_R+\lambda}-\frac{\left(G_L+G_R\right)^2}{H_L+H_R+\lambda}\right]-\gamma\]

<p><img src="/assets/2023-11-02-xgboost-from-scratch_files/eb939d3d-7647-48c5-83cb-587133e35ed0.png" alt="image.png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">_find_better_split</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">feature_idx</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">X</span><span class="p">.</span><span class="n">values</span><span class="p">[</span><span class="bp">self</span><span class="p">.</span><span class="n">idxs</span><span class="p">,</span> <span class="n">feature_idx</span><span class="p">]</span>
    <span class="n">g</span><span class="p">,</span> <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">g</span><span class="p">[</span><span class="bp">self</span><span class="p">.</span><span class="n">idxs</span><span class="p">],</span> <span class="bp">self</span><span class="p">.</span><span class="n">h</span><span class="p">[</span><span class="bp">self</span><span class="p">.</span><span class="n">idxs</span><span class="p">]</span>
    <span class="c1">#sort the data with x feature
</span>    <span class="n">sort_idx</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">sort_g</span><span class="p">,</span> <span class="n">sort_h</span><span class="p">,</span> <span class="n">sort_x</span> <span class="o">=</span> <span class="n">g</span><span class="p">[</span><span class="n">sort_idx</span><span class="p">],</span> <span class="n">h</span><span class="p">[</span><span class="n">sort_idx</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="n">sort_idx</span><span class="p">]</span>
    <span class="c1">#init the GL, GR, HL, HR
</span>    <span class="n">sum_g</span><span class="p">,</span> <span class="n">sum_h</span> <span class="o">=</span> <span class="n">g</span><span class="p">.</span><span class="nb">sum</span><span class="p">(),</span> <span class="n">h</span><span class="p">.</span><span class="nb">sum</span><span class="p">()</span>
    <span class="n">sum_g_right</span><span class="p">,</span> <span class="n">sum_h_right</span> <span class="o">=</span> <span class="n">sum_g</span><span class="p">,</span> <span class="n">sum_h</span>
    <span class="n">sum_g_left</span><span class="p">,</span> <span class="n">sum_h_left</span> <span class="o">=</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="c1">#cacluate the  GL, GR, HL, HR under the split point is i
</span>        <span class="n">g_i</span><span class="p">,</span> <span class="n">h_i</span><span class="p">,</span> <span class="n">x_i</span><span class="p">,</span> <span class="n">x_i_next</span> <span class="o">=</span> <span class="n">sort_g</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">sort_h</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">sort_x</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">sort_x</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
        <span class="n">sum_g_left</span> <span class="o">+=</span> <span class="n">g_i</span><span class="p">;</span> <span class="n">sum_g_right</span> <span class="o">-=</span> <span class="n">g_i</span>
        <span class="n">sum_h_left</span> <span class="o">+=</span> <span class="n">h_i</span><span class="p">;</span> <span class="n">sum_h_right</span> <span class="o">-=</span> <span class="n">h_i</span>
        
        <span class="c1">#set up the break condition from iteration
</span>        <span class="c1">#what the considtion that x_i == x_i_next??
</span>        <span class="k">if</span> <span class="n">sum_h_left</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="p">.</span><span class="n">min_child_weight</span> <span class="ow">or</span> <span class="n">x_i</span> <span class="o">==</span> <span class="n">x_i_next</span><span class="p">:</span><span class="k">continue</span>
        <span class="k">if</span> <span class="n">sum_h_right</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="p">.</span><span class="n">min_child_weight</span><span class="p">:</span> <span class="k">break</span>
        
        <span class="c1"># calcuate the gain 
</span>        <span class="n">gain</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">((</span><span class="n">sum_g_left</span><span class="o">**</span><span class="mi">2</span> <span class="o">/</span> <span class="p">(</span><span class="n">sum_h_left</span> <span class="o">+</span> <span class="bp">self</span><span class="p">.</span><span class="n">reg_lambda</span><span class="p">))</span>
                        <span class="o">+</span> <span class="p">(</span><span class="n">sum_g_right</span><span class="o">**</span><span class="mi">2</span> <span class="o">/</span> <span class="p">(</span><span class="n">sum_h_right</span> <span class="o">+</span> <span class="bp">self</span><span class="p">.</span><span class="n">reg_lambda</span><span class="p">))</span>
                        <span class="o">-</span> <span class="p">(</span><span class="n">sum_g</span><span class="o">**</span><span class="mi">2</span> <span class="o">/</span> <span class="p">(</span><span class="n">sum_h</span> <span class="o">+</span> <span class="bp">self</span><span class="p">.</span><span class="n">reg_lambda</span><span class="p">))</span>
                        <span class="p">)</span> <span class="o">-</span> <span class="bp">self</span><span class="p">.</span><span class="n">gamma</span><span class="o">/</span><span class="mi">2</span> <span class="c1"># Eq(7) in the xgboost paper
</span>        
        <span class="c1">#record this split if the gain is better
</span>        <span class="k">if</span> <span class="n">gain</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="p">.</span><span class="n">best_score_so_far</span><span class="p">:</span> 
            <span class="bp">self</span><span class="p">.</span><span class="n">split_feature_idx</span> <span class="o">=</span> <span class="n">feature_idx</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">best_score_so_far</span> <span class="o">=</span> <span class="n">gain</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">threshold</span> <span class="o">=</span> <span class="p">(</span><span class="n">x_i</span> <span class="o">+</span> <span class="n">x_i_next</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>
            
<span class="n">TreeBooster</span><span class="p">.</span><span class="n">_find_better_split</span> <span class="o">=</span> <span class="n">_find_better_split</span>
</code></pre></div></div>

<h3 id="prediction">Prediction</h3>

<p>Prediction works exactly the same as in our decision tree, and the methods are nearly identical.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="bp">self</span><span class="p">.</span><span class="n">_predict_row</span><span class="p">(</span><span class="n">row</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">X</span><span class="p">.</span><span class="n">iterrows</span><span class="p">()])</span>

<span class="k">def</span> <span class="nf">_predict_row</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">row</span><span class="p">):</span>
    <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">is_leaf</span><span class="p">:</span> 
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">value</span>
    <span class="n">child</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">left</span> <span class="k">if</span> <span class="n">row</span><span class="p">[</span><span class="bp">self</span><span class="p">.</span><span class="n">split_feature_idx</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="bp">self</span><span class="p">.</span><span class="n">threshold</span> \
        <span class="k">else</span> <span class="bp">self</span><span class="p">.</span><span class="n">right</span>
    <span class="k">return</span> <span class="n">child</span><span class="p">.</span><span class="n">_predict_row</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>

<span class="n">TreeBooster</span><span class="p">.</span><span class="n">predict</span> <span class="o">=</span> <span class="n">predict</span> 
<span class="n">TreeBooster</span><span class="p">.</span><span class="n">_predict_row</span> <span class="o">=</span> <span class="n">_predict_row</span> 
</code></pre></div></div>

<h2 id="the-complete-xgboost-from-scratch-implementation">The Complete XGBoost From Scratch Implementation</h2>

<p>Here’s the entire implementation which produces a usable <code class="language-plaintext highlighter-rouge">XGBoostModel</code> class with fit and predict methods.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">XGBoostModel</span><span class="p">():</span>
    <span class="s">'''XGBoost from Scratch
    '''</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">random_seed</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">params</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="bp">None</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">subsample</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">params</span><span class="p">[</span><span class="s">'subsample'</span><span class="p">]</span> \
            <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">params</span><span class="p">[</span><span class="s">'subsample'</span><span class="p">]</span> <span class="k">else</span> <span class="mf">1.0</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">params</span><span class="p">[</span><span class="s">'learning_rate'</span><span class="p">]</span> \
            <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">params</span><span class="p">[</span><span class="s">'learning_rate'</span><span class="p">]</span> <span class="k">else</span> <span class="mf">0.3</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">base_prediction</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">params</span><span class="p">[</span><span class="s">'base_score'</span><span class="p">]</span> \
            <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">params</span><span class="p">[</span><span class="s">'base_score'</span><span class="p">]</span> <span class="k">else</span> <span class="mf">0.5</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">max_depth</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">params</span><span class="p">[</span><span class="s">'max_depth'</span><span class="p">]</span> \
            <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">params</span><span class="p">[</span><span class="s">'max_depth'</span><span class="p">]</span> <span class="k">else</span> <span class="mi">5</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">random_seed</span><span class="p">)</span>
                
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">objective</span><span class="p">,</span> <span class="n">num_boost_round</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
        <span class="n">current_predictions</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">base_prediction</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">y</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">boosters</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_boost_round</span><span class="p">):</span>
            <span class="n">gradients</span> <span class="o">=</span> <span class="n">objective</span><span class="p">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">current_predictions</span><span class="p">)</span>
            <span class="n">hessians</span> <span class="o">=</span> <span class="n">objective</span><span class="p">.</span><span class="n">hessian</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">current_predictions</span><span class="p">)</span>
            <span class="n">sample_idxs</span> <span class="o">=</span> <span class="bp">None</span> <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">subsample</span> <span class="o">==</span> <span class="mf">1.0</span> \
                <span class="k">else</span> <span class="bp">self</span><span class="p">.</span><span class="n">rng</span><span class="p">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> 
                                     <span class="n">size</span><span class="o">=</span><span class="n">math</span><span class="p">.</span><span class="n">floor</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">subsample</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)),</span> 
                                     <span class="n">replace</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
            <span class="n">booster</span> <span class="o">=</span> <span class="n">TreeBooster</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">gradients</span><span class="p">,</span> <span class="n">hessians</span><span class="p">,</span> 
                                  <span class="bp">self</span><span class="p">.</span><span class="n">params</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">max_depth</span><span class="p">,</span> <span class="n">sample_idxs</span><span class="p">)</span>
            <span class="n">current_predictions</span> <span class="o">+=</span> <span class="bp">self</span><span class="p">.</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">booster</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">boosters</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">booster</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span> 
                <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'[</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s">] train loss = </span><span class="si">{</span><span class="n">objective</span><span class="p">.</span><span class="n">loss</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">current_predictions</span><span class="p">)</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
            
    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">base_prediction</span> <span class="o">+</span> <span class="bp">self</span><span class="p">.</span><span class="n">learning_rate</span> 
                <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">([</span><span class="n">booster</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="k">for</span> <span class="n">booster</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">boosters</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">TreeBooster</span><span class="p">():</span>
 
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">max_depth</span><span class="p">,</span> <span class="n">idxs</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">params</span> <span class="o">=</span> <span class="n">params</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">max_depth</span> <span class="o">=</span> <span class="n">max_depth</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="p">.</span><span class="n">max_depth</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">,</span> <span class="s">'max_depth must be nonnegative'</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">min_child_weight</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s">'min_child_weight'</span><span class="p">]</span> \
            <span class="k">if</span> <span class="n">params</span><span class="p">[</span><span class="s">'min_child_weight'</span><span class="p">]</span> <span class="k">else</span> <span class="mf">1.0</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">reg_lambda</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s">'reg_lambda'</span><span class="p">]</span> <span class="k">if</span> <span class="n">params</span><span class="p">[</span><span class="s">'reg_lambda'</span><span class="p">]</span> <span class="k">else</span> <span class="mf">1.0</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">gamma</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s">'gamma'</span><span class="p">]</span> <span class="k">if</span> <span class="n">params</span><span class="p">[</span><span class="s">'gamma'</span><span class="p">]</span> <span class="k">else</span> <span class="mf">0.0</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">colsample_bynode</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s">'colsample_bynode'</span><span class="p">]</span> \
            <span class="k">if</span> <span class="n">params</span><span class="p">[</span><span class="s">'colsample_bynode'</span><span class="p">]</span> <span class="k">else</span> <span class="mf">1.0</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">pd</span><span class="p">.</span><span class="n">Series</span><span class="p">):</span> <span class="n">g</span> <span class="o">=</span> <span class="n">g</span><span class="p">.</span><span class="n">values</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">pd</span><span class="p">.</span><span class="n">Series</span><span class="p">):</span> <span class="n">h</span> <span class="o">=</span> <span class="n">h</span><span class="p">.</span><span class="n">values</span>
        <span class="k">if</span> <span class="n">idxs</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span> <span class="n">idxs</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">g</span><span class="p">))</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">g</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">h</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">idxs</span> <span class="o">=</span> <span class="n">X</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">idxs</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">n</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">c</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">idxs</span><span class="p">),</span> <span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">value</span> <span class="o">=</span> <span class="o">-</span><span class="n">g</span><span class="p">[</span><span class="n">idxs</span><span class="p">].</span><span class="nb">sum</span><span class="p">()</span> <span class="o">/</span> <span class="p">(</span><span class="n">h</span><span class="p">[</span><span class="n">idxs</span><span class="p">].</span><span class="nb">sum</span><span class="p">()</span> <span class="o">+</span> <span class="bp">self</span><span class="p">.</span><span class="n">reg_lambda</span><span class="p">)</span> <span class="c1"># Eq (5)
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">best_score_so_far</span> <span class="o">=</span> <span class="mf">0.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">max_depth</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">_maybe_insert_child_nodes</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_maybe_insert_child_nodes</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">c</span><span class="p">):</span> <span class="bp">self</span><span class="p">.</span><span class="n">_find_better_split</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">is_leaf</span><span class="p">:</span> <span class="k">return</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">X</span><span class="p">.</span><span class="n">values</span><span class="p">[</span><span class="bp">self</span><span class="p">.</span><span class="n">idxs</span><span class="p">,</span><span class="bp">self</span><span class="p">.</span><span class="n">split_feature_idx</span><span class="p">]</span>
        <span class="n">left_idx</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">x</span> <span class="o">&lt;=</span> <span class="bp">self</span><span class="p">.</span><span class="n">threshold</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">right_idx</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">x</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="p">.</span><span class="n">threshold</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">left</span> <span class="o">=</span> <span class="n">TreeBooster</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">g</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">h</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">params</span><span class="p">,</span> 
                                <span class="bp">self</span><span class="p">.</span><span class="n">max_depth</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">idxs</span><span class="p">[</span><span class="n">left_idx</span><span class="p">])</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">right</span> <span class="o">=</span> <span class="n">TreeBooster</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">g</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">h</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">params</span><span class="p">,</span> 
                                 <span class="bp">self</span><span class="p">.</span><span class="n">max_depth</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">idxs</span><span class="p">[</span><span class="n">right_idx</span><span class="p">])</span>

    <span class="o">@</span><span class="nb">property</span>
    <span class="k">def</span> <span class="nf">is_leaf</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span> <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">best_score_so_far</span> <span class="o">==</span> <span class="mf">0.</span>
    
    <span class="k">def</span> <span class="nf">_find_better_split</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">feature_idx</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">X</span><span class="p">.</span><span class="n">values</span><span class="p">[</span><span class="bp">self</span><span class="p">.</span><span class="n">idxs</span><span class="p">,</span> <span class="n">feature_idx</span><span class="p">]</span>
        <span class="n">g</span><span class="p">,</span> <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">g</span><span class="p">[</span><span class="bp">self</span><span class="p">.</span><span class="n">idxs</span><span class="p">],</span> <span class="bp">self</span><span class="p">.</span><span class="n">h</span><span class="p">[</span><span class="bp">self</span><span class="p">.</span><span class="n">idxs</span><span class="p">]</span>
        <span class="n">sort_idx</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">sort_g</span><span class="p">,</span> <span class="n">sort_h</span><span class="p">,</span> <span class="n">sort_x</span> <span class="o">=</span> <span class="n">g</span><span class="p">[</span><span class="n">sort_idx</span><span class="p">],</span> <span class="n">h</span><span class="p">[</span><span class="n">sort_idx</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="n">sort_idx</span><span class="p">]</span>
        <span class="n">sum_g</span><span class="p">,</span> <span class="n">sum_h</span> <span class="o">=</span> <span class="n">g</span><span class="p">.</span><span class="nb">sum</span><span class="p">(),</span> <span class="n">h</span><span class="p">.</span><span class="nb">sum</span><span class="p">()</span>
        <span class="n">sum_g_right</span><span class="p">,</span> <span class="n">sum_h_right</span> <span class="o">=</span> <span class="n">sum_g</span><span class="p">,</span> <span class="n">sum_h</span>
        <span class="n">sum_g_left</span><span class="p">,</span> <span class="n">sum_h_left</span> <span class="o">=</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">g_i</span><span class="p">,</span> <span class="n">h_i</span><span class="p">,</span> <span class="n">x_i</span><span class="p">,</span> <span class="n">x_i_next</span> <span class="o">=</span> <span class="n">sort_g</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">sort_h</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">sort_x</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">sort_x</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
            <span class="n">sum_g_left</span> <span class="o">+=</span> <span class="n">g_i</span><span class="p">;</span> <span class="n">sum_g_right</span> <span class="o">-=</span> <span class="n">g_i</span>
            <span class="n">sum_h_left</span> <span class="o">+=</span> <span class="n">h_i</span><span class="p">;</span> <span class="n">sum_h_right</span> <span class="o">-=</span> <span class="n">h_i</span>
            <span class="k">if</span> <span class="n">sum_h_left</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="p">.</span><span class="n">min_child_weight</span> <span class="ow">or</span> <span class="n">x_i</span> <span class="o">==</span> <span class="n">x_i_next</span><span class="p">:</span><span class="k">continue</span>
            <span class="k">if</span> <span class="n">sum_h_right</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="p">.</span><span class="n">min_child_weight</span><span class="p">:</span> <span class="k">break</span>

            <span class="n">gain</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">((</span><span class="n">sum_g_left</span><span class="o">**</span><span class="mi">2</span> <span class="o">/</span> <span class="p">(</span><span class="n">sum_h_left</span> <span class="o">+</span> <span class="bp">self</span><span class="p">.</span><span class="n">reg_lambda</span><span class="p">))</span>
                            <span class="o">+</span> <span class="p">(</span><span class="n">sum_g_right</span><span class="o">**</span><span class="mi">2</span> <span class="o">/</span> <span class="p">(</span><span class="n">sum_h_right</span> <span class="o">+</span> <span class="bp">self</span><span class="p">.</span><span class="n">reg_lambda</span><span class="p">))</span>
                            <span class="o">-</span> <span class="p">(</span><span class="n">sum_g</span><span class="o">**</span><span class="mi">2</span> <span class="o">/</span> <span class="p">(</span><span class="n">sum_h</span> <span class="o">+</span> <span class="bp">self</span><span class="p">.</span><span class="n">reg_lambda</span><span class="p">))</span>
                            <span class="p">)</span> <span class="o">-</span> <span class="bp">self</span><span class="p">.</span><span class="n">gamma</span><span class="o">/</span><span class="mi">2</span> <span class="c1"># Eq(7) in the xgboost paper
</span>            <span class="k">if</span> <span class="n">gain</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="p">.</span><span class="n">best_score_so_far</span><span class="p">:</span> 
                <span class="bp">self</span><span class="p">.</span><span class="n">split_feature_idx</span> <span class="o">=</span> <span class="n">feature_idx</span>
                <span class="bp">self</span><span class="p">.</span><span class="n">best_score_so_far</span> <span class="o">=</span> <span class="n">gain</span>
                <span class="bp">self</span><span class="p">.</span><span class="n">threshold</span> <span class="o">=</span> <span class="p">(</span><span class="n">x_i</span> <span class="o">+</span> <span class="n">x_i_next</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>
                
    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="bp">self</span><span class="p">.</span><span class="n">_predict_row</span><span class="p">(</span><span class="n">row</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">X</span><span class="p">.</span><span class="n">iterrows</span><span class="p">()])</span>

    <span class="k">def</span> <span class="nf">_predict_row</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">row</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">is_leaf</span><span class="p">:</span> 
            <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">value</span>
        <span class="n">child</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">left</span> <span class="k">if</span> <span class="n">row</span><span class="p">[</span><span class="bp">self</span><span class="p">.</span><span class="n">split_feature_idx</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="bp">self</span><span class="p">.</span><span class="n">threshold</span> \
            <span class="k">else</span> <span class="bp">self</span><span class="p">.</span><span class="n">right</span>
        <span class="k">return</span> <span class="n">child</span><span class="p">.</span><span class="n">_predict_row</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="testing">Testing</h2>

<p>Let’s take this baby for a spin and benchmark its performance against the actual XGBoost library. We use the scikit learn <a href="https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html">California housing dataset</a> for benchmarking.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">fetch_california_housing</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
    
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">fetch_california_housing</span><span class="p">(</span><span class="n">as_frame</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">return_X_y</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> 
                                                    <span class="n">random_state</span><span class="o">=</span><span class="mi">43</span><span class="p">)</span>
</code></pre></div></div>

<p>Let’s start with a nice friendly squared error objective function for training. We should probably have a future post all about how to define custom objective functions in XGBoost, but for now, here’s how I define squared error.<br />
   gradients: $g_i=l^{\prime}\left(y_i, \widehat{y}_i^{(t-1)}\right)$ ，hessians: $h_i=l^{\prime \prime}\left(y_i, \widehat{y}_i^{(t-1)}\right)$.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">SquaredErrorObjective</span><span class="p">():</span>
    <span class="k">def</span> <span class="nf">loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">pred</span><span class="p">):</span> <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">((</span><span class="n">y</span> <span class="o">-</span> <span class="n">pred</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">gradient</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">pred</span><span class="p">):</span> <span class="k">return</span> <span class="n">pred</span> <span class="o">-</span> <span class="n">y</span>
    <span class="k">def</span> <span class="nf">hessian</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">pred</span><span class="p">):</span> <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
</code></pre></div></div>

<p>Here I use a more or less arbitrary set of hyperparameters for training.  Feel free to play around with tuning and trying other parameter combinations yourself.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">xgboost</span> <span class="k">as</span> <span class="n">xgb</span>

<span class="n">params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">'learning_rate'</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span>
    <span class="s">'max_depth'</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span>
    <span class="s">'subsample'</span><span class="p">:</span> <span class="mf">0.8</span><span class="p">,</span>
    <span class="s">'reg_lambda'</span><span class="p">:</span> <span class="mf">1.5</span><span class="p">,</span>
    <span class="s">'gamma'</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span>
    <span class="s">'min_child_weight'</span><span class="p">:</span> <span class="mi">25</span><span class="p">,</span>
    <span class="s">'base_score'</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span>
    <span class="s">'tree_method'</span><span class="p">:</span> <span class="s">'exact'</span><span class="p">,</span>
<span class="p">}</span>
<span class="n">num_boost_round</span> <span class="o">=</span> <span class="mi">50</span>

<span class="c1"># train the from-scratch XGBoost model
</span><span class="n">model_scratch</span> <span class="o">=</span> <span class="n">XGBoostModel</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">random_seed</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">model_scratch</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">SquaredErrorObjective</span><span class="p">(),</span> <span class="n">num_boost_round</span><span class="p">)</span>

<span class="c1"># train the library XGBoost model
</span><span class="n">dtrain</span> <span class="o">=</span> <span class="n">xgb</span><span class="p">.</span><span class="n">DMatrix</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">dtest</span> <span class="o">=</span> <span class="n">xgb</span><span class="p">.</span><span class="n">DMatrix</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">y_test</span><span class="p">)</span>
<span class="n">model_xgb</span> <span class="o">=</span> <span class="n">xgb</span><span class="p">.</span><span class="n">train</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">dtrain</span><span class="p">,</span> <span class="n">num_boost_round</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X_train</span><span class="p">.</span><span class="n">shape</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">y_train</span><span class="p">.</span><span class="n">shape</span>
</code></pre></div></div>

<p>Let’s check the models’ performance on the held out test data to benchmark our implementation.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pred_scratch_train</span> <span class="o">=</span> <span class="n">model_scratch</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">pred_scratch</span> <span class="o">=</span> <span class="n">model_scratch</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">pred_xgb</span> <span class="o">=</span> <span class="n">model_xgb</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">dtest</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'scratch score: </span><span class="si">{</span><span class="n">SquaredErrorObjective</span><span class="p">().</span><span class="n">loss</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred_scratch</span><span class="p">)</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'xgboost score: </span><span class="si">{</span><span class="n">SquaredErrorObjective</span><span class="p">().</span><span class="n">loss</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred_xgb</span><span class="p">)</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">RSE</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">g</span><span class="p">):</span> 
    <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">square</span><span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">g</span><span class="p">))</span> <span class="o">/</span> <span class="nb">sum</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">square</span><span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="o">*</span><span class="nb">sum</span><span class="p">(</span><span class="n">y</span><span class="p">)))</span>

<span class="k">print</span><span class="p">(</span><span class="s">'Training error: {:.4f}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">RSE</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">pred_scratch_train</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Validation error: {:.4f}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">RSE</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred_scratch</span><span class="p">)))</span>
</code></pre></div></div>

<p>Well, look at that! Our scratch-built SGBoost is looking pretty consistent with the library. Go us!</p>

<h2 id="wrapping-up">Wrapping Up</h2>
<p>I’d say this is a pretty good milestone for us here at Random Realizations. We’ve been hammering away at the various concepts around gradient boosting, leaving a trail of equations and scratch-built algos in our wake. Today we put all of that together to create a legit scratch build of XGBoost, something that would have been out of reach for me before we embarked on this journey together over a year ago. To anyone with the patience to read through this stuff, cheers to you! I hope you’re learning and enjoying this as much as I am.</p>

<h2 id="reader-exercises">Reader Exercises</h2>
<p>If you want to take this a step further and deepen your understanding and coding abilities, let me recommend some exercises for you.</p>

<ol>
  <li>Implement column subsampling. XGBoost itself provides column subsampling by tree, by level, and by node. Try implementing by tree first, then try adding by level or by node as well. These should be pretty straightforward to do.</li>
  <li>Implement sparsity aware split finding for missing feature values (Algorithm 2 in the <a href="https://arxiv.org/abs/1603.02754">XGBoost paper</a>). This will be a little more involved, since you’ll need to refactor and modify several parts of the tree booster class.</li>
</ol>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
</code></pre></div></div>]]></content><author><name>Zhu Tianda</name></author><category term="coding" /><category term="AI" /><summary type="html"><![CDATA[XGBoost from scratch]]></summary></entry></feed>