<!DOCTYPE html>
<html lang="en-us">

<head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
  
  <!-- include collecttags -->
  
  





  

  <title>
    
      Understanding the performance of LightGBM and XGBoost &middot; Zhu Philip's AI Journey
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link href="https://fonts.googleapis.com/css?family=East+Sea+Dokdo&display=swap" rel="stylesheet">
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.7.0/css/all.min.css" rel="stylesheet">

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/apple-touch-icon-144-precomposed.png">
                                 <link rel="shortcut icon" href="/public/favicon.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">

  <!-- merge something else -->
  
  <!-- merge something else 
  <link rel="stylesheet" href="/assets/css/post.css" />
  <link rel="stylesheet" href="/assets/css/syntax.css" /> -->
  
  
  <link rel="stylesheet" href="/assets/css/common.css" />
  <script src="/assets/js/categories.js"></script>  
  
  <script defer src="/assets/js/lbox.js"></script>
   

  <!-- MathJax -->
  <script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
  });
  MathJax.Hub.Queue(function() {
    // Fix <code> tags after MathJax finishes running. This is a
    // hack to overcome a shortcoming of Markdown. Discussion at
    // https://github.com/mojombo/jekyll/issues/199
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });

  MathJax.Hub.Config({
  // Autonumbering by mathjax
  TeX: { equationNumbers: { autoNumber: "AMS" } }
  });
</script> 

</head>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-89141653-4"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-89141653-4');
</script>



  <body>

    <link rel="stylesheet" href="/assets/style-3.css">
<div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1>
        <div align="center">
          <img src="/assets/profile-pixel.png" class="profilepic pt-3 pb-2">
        </div>
        <!-- <a href="/"> -->
          Zhu Philip's AI Journey
        </a>
      </h1>
      <p class="lead"></p>
    </div>

    <nav class="sidebar-nav">
      <a class="sidebar-nav-item" href="/">Home</a>

      <!-- Manual set order -->
      <a class="sidebar-nav-item" href="/categories">Categories</a>
      <a class="sidebar-nav-item" href="/working">Working</a>
      <a class="sidebar-nav-item" href="/publication">Publication</a>
      <!-- <a class="sidebar-nav-item" href="/projects">Projects</a> -->
      <a class="sidebar-nav-item" href="/about">About</a>

      <!-- Uncomment for auto order -->
      <!-- 

      
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
            <a class="sidebar-nav-item" href="/about/">About</a>
          
        
      
        
          
        
      
        
      
        
          
        
      
        
      
        
          
            <a class="sidebar-nav-item" href="/categories/">Categories</a>
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
            <a class="sidebar-nav-item" href="/publication/">publications</a>
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
            <a class="sidebar-nav-item" href="/working/">Working</a>
          
        
      
        
          
        
      
        
      
        
          
        
      
        
          
        
       -->

      
      <!-- <a class="sidebar-nav-item" href="https://github.com/zphilip/zphilip.github.io">GitHub project</a> -->
      <!-- <span class="sidebar-nav-item">Currently v</span> -->
      
<div id="social-media">
    
    
        
        
            <a href="mailto:zphilip48@gmail.com" title="Email"><i class="fa fa-envelope"></i></a>
        
    
        
        
            <a href="https://www.linkedin.com/in/tianda-zhu-37a5b031" title="Linkedin"><i class="fab fa-linkedin"></i></a>
        
    
        
        
            <a href="https://github.com/zphilip" title="GitHub"><i class="fab fa-github"></i></a>
        
    
        
        
            <a href="https://www.youtube.com/user/zphilip" title="YouTube"><i class="fab fa-youtube"></i></a>
        
    
</div>


    </nav>

    <p>&copy; 2024. All rights reserved.</p>
  </div>
</div>


    <div class="content container">
      <div class="post">
  <h1 class="post-title">Understanding the performance of LightGBM and XGBoost</h1>
  <span class="post-date">01 Nov 2023</span>
  <h2 id="problem-statement-predict-the-pay-range-a-given-employee-would-belong-to-based-on-the-analysis-of-different-attributes-of-other-employees--their-respective-pay-range">Problem Statement: Predict the pay-range a given employee would belong to, based on the analysis of different attributes of other employees &amp; their respective pay-range.</h2>

<h4 id="the-dataset-is-sourced-from-httpopenbooksfgovorg-which-is-part-of-the-government-of-san-francisco-citys-initiative-in-providing-open--easily-accessible-data-related-to-performance--spending-across-different-departments-of-san-francisco-city-government-salary-range-is-the-range-of-pay-established-by-employers-to-pay-to-employees-performing-a-particular-job-or-function-salary-range-generally-has-a-minimum-pay-rate-a-maximum-pay-rate-and-a-series-of-mid-range-opportunities-for-pay-increases"><em>The dataset is sourced from http://openbook.sfgov.org, which is part of the Government of San Francisco city’s initiative in providing open &amp; easily accessible data related to performance &amp; spending across different departments of San Francisco City government. Salary range is the range of pay established by employers to pay to employees performing a particular job or function. Salary range generally has a minimum pay rate, a maximum pay rate, and a series of mid-range opportunities for pay increases.</em></h4>

<h4 id="the-salary-range-is-determined-by-market-pay-rates-organization-department-union-type-and-domain-of-jobs-established-through-market-pay-studies-for-people-doing-similar-work-in-similar-industries-in-the-same-region-of-the-country-pay-rates-and-salary-ranges-are-also-set-up-by-individual-employers-and-recognize-the-level-of-education-knowledge-skill-and-experience-needed-to-perform-each-job-its-a-database-of-the-salary-and-benefits-paid-to-city-employees-since-fiscal-year-2013"><em>The salary range is determined by market pay rates, organization, department, union, type and domain of jobs, established through market pay studies, for people doing similar work in similar industries in the same region of the country. Pay rates and salary ranges are also set up by individual employers and recognize the level of education, knowledge, skill, and experience needed to perform each job. Its a database of the salary and benefits paid to City employees since fiscal year 2013.</em></h4>

<h4 id="this-data-is-summarized-and-presented-on-the-employee-compensation-report-hosted-at-httpopenbooksfgovorg"><em>This data is summarized and presented on the Employee Compensation report hosted at http://openbook.sfgov.org</em></h4>

<h4 id="the-targetlabel-comprises-of-the-3-pay-range"><em>The target/label comprises of the 3 pay-range:</em></h4>
<h4 id="1-low-range-salary"><em>1. Low range salary</em></h4>
<h4 id="2-mid-range-salary"><em>2. Mid range salary</em></h4>
<h4 id="3-high-range-salary"><em>3. High range salary</em></h4>

<p>example is get from https://github.com/debajyotid/Understanding-the-performance-of-LightGBM-and-XGBoost</p>

<h3 id="the-objective-of-this-notebook-is-to-understand-the-impact-of-using-imblearn-libraries-on-an-imbalanced-dataset"><em>The objective of this notebook is to understand the impact of using Imblearn libraries on an imbalanced dataset</em></h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">timeit</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="p">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s">'ignore'</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span><span class="p">,</span> <span class="n">RepeatedStratifiedKFold</span><span class="p">,</span> <span class="n">cross_val_score</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelEncoder</span><span class="p">,</span> <span class="n">LabelBinarizer</span><span class="p">,</span> <span class="n">StandardScaler</span>

<span class="kn">from</span> <span class="nn">xgboost</span> <span class="kn">import</span> <span class="n">XGBClassifier</span>
<span class="kn">from</span> <span class="nn">lightgbm</span> <span class="kn">import</span> <span class="n">LGBMClassifier</span>

<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">decomposition</span>
</code></pre></div></div>

<h4 id="the-dataset-is-given-in-2-sets-train--test-wherein-the-test-set-doesnt-have-the-labels-marked-thus-the-train-set-has-to-be-split-for-actual-training--validation"><em>The dataset is given in 2 sets: train &amp; test, wherein the test set doesn’t have the labels marked. Thus the train set has to be split for actual training &amp; validation</em></h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'./data/train.csv'</span><span class="p">)</span>
<span class="n">test</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'./data/test.csv'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train</span><span class="p">.</span><span class="n">info</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 149087 entries, 0 to 149086
Data columns (total 21 columns):
 #   Column                   Non-Null Count   Dtype  
---  ------                   --------------   -----  
 0   ID                       149087 non-null  int64  
 1   Year Type                149087 non-null  object 
 2   Year                     149087 non-null  int64  
 3   Organization Group Code  149087 non-null  int64  
 4   Organization Group       149087 non-null  object 
 5   Department Code          149087 non-null  object 
 6   Department               149087 non-null  object 
 7   Union Code               149087 non-null  int64  
 8   Union                    149087 non-null  object 
 9   Job Family Code          149087 non-null  object 
 10  Job Family               149087 non-null  object 
 11  Job Code                 149087 non-null  object 
 12  Job                      149087 non-null  object 
 13  Employee Identifier      149087 non-null  int64  
 14  Overtime                 149087 non-null  float64
 15  Other Salaries           149087 non-null  float64
 16  Retirement               149087 non-null  float64
 17  Health/Dental            149087 non-null  float64
 18  Other Benefits           149087 non-null  float64
 19  Total Benefits           149087 non-null  float64
 20  Class                    149087 non-null  int64  
dtypes: float64(6), int64(6), object(9)
memory usage: 23.9+ MB
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train</span><span class="p">[</span><span class="s">'Class'</span><span class="p">].</span><span class="n">value_counts</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>3    50811
2    49604
1    48672
Name: Class, dtype: int64
</code></pre></div></div>

<h4 id="there-are-altogether-19-features--1-label-distributed-across-approx-150-thousand-datapoints-of-these-19-features-some-are-stringobject-type-while-the-others-are-numerical-integer-or-floating-point-most-ml-algorithms-work-well-with-numerical-data-and-non-numerical-categorical-data-usually-needs-to-be-encoded-into-some-numerical-form-or-the-other"><em>There are altogether 19 features &amp; 1 label distributed across approx. 150 thousand datapoints. Of these 19 features, some are string/object type while the others are numerical (integer or floating point). Most ML algorithms work well with numerical data, and non-numerical categorical data usually needs to be ENCODED into some numerical form or the other.</em></h4>
<h4 id="some-of-these-features-may-be-redundant-while-others-may-be-not-so-important-we-will-inspect-them-individually"><em>Some of these features may be redundant, while others may be not so important. We will inspect them individually</em></h4>
<h4 id="lastly-the-target-variable-comprises-of-3-classes-and-the-classes-seem-to-be-slightly-imbalanced-we-can-try-introducing-synthetic-methods-like-y_val--randomundersampler-to-handle-this-imbalance-so-that-the-model-is-capable-of-classifying-all-the-3-classes-equally-well"><em>Lastly the target variable comprises of 3 classes and the classes seem to be slightly imbalanced. We can try introducing synthetic methods like y_val &amp; RandomUnderSampler to handle this imbalance, so that the model is capable of classifying all the 3 classes equally well</em></h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ID</th>
      <th>Year Type</th>
      <th>Year</th>
      <th>Organization Group Code</th>
      <th>Organization Group</th>
      <th>Department Code</th>
      <th>Department</th>
      <th>Union Code</th>
      <th>Union</th>
      <th>Job Family Code</th>
      <th>...</th>
      <th>Job Code</th>
      <th>Job</th>
      <th>Employee Identifier</th>
      <th>Overtime</th>
      <th>Other Salaries</th>
      <th>Retirement</th>
      <th>Health/Dental</th>
      <th>Other Benefits</th>
      <th>Total Benefits</th>
      <th>Class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>9248</td>
      <td>Fiscal</td>
      <td>2017</td>
      <td>3</td>
      <td>Human Welfare &amp; Neighborhood Development</td>
      <td>DSS</td>
      <td>HSA Human Services Agency</td>
      <td>535</td>
      <td>SEIU - Human Services, Local 1021</td>
      <td>2900</td>
      <td>...</td>
      <td>2905</td>
      <td>Senior Eligibility Worker</td>
      <td>41351</td>
      <td>0.00</td>
      <td>240.00</td>
      <td>11896.36</td>
      <td>13765.55</td>
      <td>5248.43</td>
      <td>30910.34</td>
      <td>2</td>
    </tr>
    <tr>
      <th>1</th>
      <td>44541</td>
      <td>Fiscal</td>
      <td>2014</td>
      <td>6</td>
      <td>General Administration &amp; Finance</td>
      <td>ASR</td>
      <td>ASR Assessor / Recorder</td>
      <td>21</td>
      <td>Prof &amp; Tech Engineers - Miscellaneous, Local 21</td>
      <td>4200</td>
      <td>...</td>
      <td>4222</td>
      <td>Sr Personal Property Auditor</td>
      <td>41792</td>
      <td>0.00</td>
      <td>400.00</td>
      <td>15429.94</td>
      <td>9337.37</td>
      <td>5599.01</td>
      <td>30366.32</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>47031</td>
      <td>Fiscal</td>
      <td>2014</td>
      <td>3</td>
      <td>Human Welfare &amp; Neighborhood Development</td>
      <td>DSS</td>
      <td>HSA Human Services Agency</td>
      <td>535</td>
      <td>SEIU - Human Services, Local 1021</td>
      <td>2900</td>
      <td>...</td>
      <td>2910</td>
      <td>Social Worker</td>
      <td>9357</td>
      <td>0.00</td>
      <td>1080.00</td>
      <td>9682.00</td>
      <td>8848.03</td>
      <td>3463.92</td>
      <td>21993.95</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>139416</td>
      <td>Fiscal</td>
      <td>2014</td>
      <td>1</td>
      <td>Public Protection</td>
      <td>FIR</td>
      <td>FIR Fire Department</td>
      <td>798</td>
      <td>Firefighters - Miscellaneous, Local 798</td>
      <td>H000</td>
      <td>...</td>
      <td>H002</td>
      <td>Firefighter</td>
      <td>28022</td>
      <td>25730.46</td>
      <td>18414.18</td>
      <td>24222.26</td>
      <td>13911.13</td>
      <td>2416.58</td>
      <td>40549.97</td>
      <td>3</td>
    </tr>
    <tr>
      <th>4</th>
      <td>123780</td>
      <td>Fiscal</td>
      <td>2013</td>
      <td>2</td>
      <td>Public Works, Transportation &amp; Commerce</td>
      <td>MTA</td>
      <td>MTA Municipal Transprtn Agncy</td>
      <td>790</td>
      <td>SEIU - Miscellaneous, Local 1021</td>
      <td>1600</td>
      <td>...</td>
      <td>1224</td>
      <td>Pr Payroll &amp; Personnel Clerk</td>
      <td>51052</td>
      <td>1138.28</td>
      <td>2148.11</td>
      <td>15437.62</td>
      <td>12828.15</td>
      <td>7246.54</td>
      <td>35512.31</td>
      <td>3</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 21 columns</p>
</div>

<p>LabelEncoder是用来对分类型特征值进行编码，即对不连续的数值或文本进行编码。其中包含以下常用方法：</p>

<p>fit(y) ：fit可看做一本空字典，y可看作要塞到字典中的词。
fit_transform(y)：相当于先进行fit再进行transform，即把y塞到字典中去以后再进行transform得到索引值。
inverse_transform(y)：根据索引值y获得原始数据。
transform(y) ：将y转变成索引值。</p>

<p>LabelBinarizer
将对应的数据转换为二进制型，有点类似于onehot编码，这里有几点不同，LabelBinarizer可以处理数值型和类别型数据，输入必须为1D数组，可以自己设置正类和父类的表示方式</p>

<p>OneHotEncoder</p>

<p>有一些特征并不是以连续值的形式给出。例如：人的性别 [“male”, “female”]，来自的国家 [“from Europe”, “from US”, “from Asia”]，使用的浏览器[“uses Firefox”, “uses Chrome”, “uses Safari”, “uses Internet Explorer”]。这种特征可以采用整数的形式进行编码，如： [“male”, “from US”, “uses Internet Explorer”] 可表示成 [0, 1, 3] ，[“female”, “from Asia”, “uses Chrome”] 可表示成[1, 2, 1]。 但是，这些整数形式的表示不能直接作为某些机器学习算法输入，因为有些机器学习算法是需要连续型的输入数据，同一列数据之间数值的大小可代表差异程度。如： [0, 1, 3]与[0,1,0]的特征差异比[0, 1, 3]与[0,1,2]之间的差异要大，但事实上它们的差异是一样的，都是浏览器使用不一样。</p>

<p>一个解决办法就是采用OneHotEncoder，这种表示方式将每一个分类特征变量的m个可能的取值转变成m个二值特征，对于每一条数据这m个值中仅有一个特征值为1，其他的都为0。</p>

<blockquote>
  <p>enc = preprocessing.OneHotEncoder()<br />
enc.fit([[0, 0, 3], [1, 1, 0], [0, 2, 1], [1, 0, 2]])  # 注意：第1、2、3列分别有2、3、4个可能的取值<br />
OneHotEncoder(categorical_features=’all’, dtype=&lt;… ‘numpy.float64’&gt;,<br />
      handle_unknown=’error’, n_values=’auto’, sparse=True)<br />
enc.transform([[0, 1, 3]]).toarray() #要对[0,1,3]进行编码<br />
array([[ 1.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  1.]]) # [1,0]对应数值0，[0,1,0]对应数值1，[0,0,0,1]对应数值3</p>
</blockquote>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">OneHotEncoder</span>

<span class="n">enc</span> <span class="o">=</span> <span class="n">OneHotEncoder</span><span class="p">()</span>  
<span class="n">enc</span><span class="p">.</span><span class="n">fit</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]])</span>
<span class="n">enc</span><span class="p">.</span><span class="n">transform</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">]]).</span><span class="n">toarray</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([[1., 0., 0., 1., 0., 0., 0., 0., 1.]])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">enc</span> <span class="o">=</span> <span class="n">OneHotEncoder</span><span class="p">()</span>
<span class="n">lb</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
<span class="n">tmp</span> <span class="o">=</span> <span class="n">lb</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">([</span><span class="mi">123</span><span class="p">,</span><span class="mi">456</span><span class="p">,</span><span class="mi">789</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="n">tmp</span><span class="p">)</span><span class="c1">#输出LabelEncoder的结果
</span><span class="n">enc</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">tmp</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span><span class="c1">#将LabelEncoder的结果作为OneHotEncoder特征输入
</span><span class="n">x_train</span> <span class="o">=</span> <span class="n">enc</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">lb</span><span class="p">.</span><span class="n">transform</span><span class="p">([</span><span class="mi">123</span><span class="p">,</span><span class="mi">789</span><span class="p">]).</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="c1">#输出特征[123,789]的OneHotEncoder的编码结果
</span><span class="k">print</span><span class="p">(</span><span class="n">x_train</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[0 1 2]
  (0, 0)	1.0
  (1, 2)	1.0
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">label_encoder</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
<span class="n">lbl_binarizer1</span> <span class="o">=</span> <span class="n">LabelBinarizer</span><span class="p">()</span>
<span class="n">lbl_binarizer2</span> <span class="o">=</span> <span class="n">LabelBinarizer</span><span class="p">()</span>
<span class="n">lbl_binarizer3</span> <span class="o">=</span> <span class="n">LabelBinarizer</span><span class="p">()</span>
<span class="n">train</span><span class="p">[</span><span class="s">'Year'</span><span class="p">]</span><span class="o">=</span> <span class="n">label_encoder</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="s">'Year'</span><span class="p">])</span>
<span class="n">train</span><span class="p">[</span><span class="s">'Department Code'</span><span class="p">]</span><span class="o">=</span> <span class="n">lbl_binarizer1</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="s">'Department Code'</span><span class="p">])</span>
<span class="n">train</span><span class="p">[</span><span class="s">'Job Family Code'</span><span class="p">]</span><span class="o">=</span> <span class="n">lbl_binarizer2</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="s">'Job Family Code'</span><span class="p">])</span>
<span class="n">train</span><span class="p">[</span><span class="s">'Job Code'</span><span class="p">]</span><span class="o">=</span> <span class="n">lbl_binarizer3</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="s">'Job Code'</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">test</span><span class="p">[</span><span class="s">'Year'</span><span class="p">]</span><span class="o">=</span> <span class="n">label_encoder</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="s">'Year'</span><span class="p">])</span>
<span class="n">test</span><span class="p">[</span><span class="s">'Department Code'</span><span class="p">]</span><span class="o">=</span> <span class="n">lbl_binarizer1</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="s">'Department Code'</span><span class="p">])</span>
<span class="n">test</span><span class="p">[</span><span class="s">'Job Family Code'</span><span class="p">]</span><span class="o">=</span> <span class="n">lbl_binarizer2</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="s">'Job Family Code'</span><span class="p">])</span>
<span class="n">test</span><span class="p">[</span><span class="s">'Job Code'</span><span class="p">]</span><span class="o">=</span> <span class="n">lbl_binarizer3</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="s">'Job Code'</span><span class="p">])</span>
</code></pre></div></div>

<h4 id="we-first-fit-the-encoder-objects-on-the-training-data--then-transform-the-same-the-same-object-is-then-also-used-to-transform-the-test-data-as-in-this-case-we-are-using-the-train-data-for-both-training--validation-it-would-have-been-necessary-to-perform-any-transformative-functions-like-scaling-on-the-training-data-after-splitting-the-same-for-training--testing-fortunately-such-activity-has-not-been-needed-due-to-our-choice-of-ml-algorithm-tree-based-classifiers---random-forest--xgbclassifier-followed-by-stacking-the-2"><em>We first fit the encoder objects on the training data &amp; then transform the same. The same object is then also used to transform the test data. As in this case we are using the train data for both training &amp; validation, it would have been necessary to perform any transformative functions like scaling on the training data after splitting the same for training &amp; testing. Fortunately such activity has not been needed due to our choice of ML algorithm, Tree based Classifiers - Random Forest &amp; XGBClassifier, followed by stacking the 2</em></h4>

<h4 id="labelbinarizer-helps-in-generating-one-hot-encoded-data-from-multi-class-objectstring-data-labelencoder-helps-in-generating-ordered-numeric-feature-by-encoding-ordinal-numericobject-data"><em>LabelBinarizer helps in generating one-hot encoded data from multi-class object/string data. LabelEncoder helps in generating ordered numeric feature by encoding ordinal numeric/object data</em></h4>

<p>DataFrame.corr(method=’pearson’, min_periods=1)</p>

<p>参数说明：
method：可选值为{‘pearson’, ‘kendall’, ‘spearman’}
pearson：Pearson相关系数来衡量两个数据集合是否在一条线上面，即针对线性数据的相关系数计算，针对非线性                                           数据便会有误差。
kendall：用于反映分类变量相关性的指标，即针对无序序列的相关系数，非正太分布的数据
spearman：非线性的，非正太分析的数据的相关系数
min_periods：样本最少的数据量
返回值：各类型之间的相关系数DataFrame表格。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span><span class="p">,</span><span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>   
<span class="n">sns</span><span class="p">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">train</span><span class="p">.</span><span class="n">corr</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s">'kendall'</span><span class="p">),</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span> <span class="s">'.2f'</span><span class="p">,</span><span class="n">cmap</span><span class="o">=</span><span class="s">"magma"</span><span class="p">)</span> 
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;AxesSubplot:&gt;
</code></pre></div></div>

<p><img src="/assets/2023-11-01-Understanding-the-performance-of-LightGBM-and-XGBoost_files/2023-11-01-Understanding-the-performance-of-LightGBM-and-XGBoost_17_1.png" alt="png" /></p>

<h4 id="from-the-above-description-we-can-see-that-the-columns-organization-groupdepartmentunionjob-familyjobemployee-identifieryear-type-are-either-redundant-or-are-containing-not-important-information-the-same-information-as-organization-groupdepartmentunionjob-family-and-job-is-contained-in-organization-group-codedepartment-codeunion-codejob-family-codeand-job-code-respectively-this-data-being-available-in-numeric-format-is-more-suitable-for-analysis"><em>From the above description we can see that the columns ‘Organization Group’,’Department’,’Union’,’Job Family’,’Job’,’Employee Identifier’,’Year Type’ are either redundant or are containing not important information. The same information as ‘Organization Group’,’Department’,’Union’,’Job Family’, and ‘Job’ is contained in ‘Organization Group Code’,’Department Code’,’Union Code’,’Job Family Code’,and ‘Job Code’ respectively. This data being available in numeric format is more suitable for analysis.</em></h4>

<h4 id="additionally-information-like-year-typeid-and-employee-identifier-are-either-not-unique-for-different-employees-or-there-is-no-visible-strong-correlation-between-the-same--the-target-variable-class-thus-we-can-drop-them-also"><em>Additionally, information like ‘Year Type’,’ID’ and ‘Employee Identifier’ are either not unique for different employees or there is no visible strong correlation between the same &amp; the target variable ‘Class’. Thus we can drop them also.</em></h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train</span><span class="p">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s">'ID'</span><span class="p">,</span><span class="s">'Organization Group'</span><span class="p">,</span><span class="s">'Department'</span><span class="p">,</span><span class="s">'Union'</span><span class="p">,</span>
                    <span class="s">'Job Family'</span><span class="p">,</span><span class="s">'Job'</span><span class="p">,</span><span class="s">'Employee Identifier'</span><span class="p">,</span><span class="s">'Year Type'</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">test</span><span class="p">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s">'ID'</span><span class="p">,</span><span class="s">'Organization Group'</span><span class="p">,</span><span class="s">'Department'</span><span class="p">,</span><span class="s">'Union'</span><span class="p">,</span>
                   <span class="s">'Job Family'</span><span class="p">,</span><span class="s">'Job'</span><span class="p">,</span><span class="s">'Employee Identifier'</span><span class="p">,</span> <span class="s">'Year Type'</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train</span><span class="p">.</span><span class="n">info</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 149087 entries, 0 to 149086
Data columns (total 13 columns):
 #   Column                   Non-Null Count   Dtype  
---  ------                   --------------   -----  
 0   Year                     149087 non-null  int64  
 1   Organization Group Code  149087 non-null  int64  
 2   Department Code          149087 non-null  int64  
 3   Union Code               149087 non-null  int64  
 4   Job Family Code          149087 non-null  int64  
 5   Job Code                 149087 non-null  int64  
 6   Overtime                 149087 non-null  float64
 7   Other Salaries           149087 non-null  float64
 8   Retirement               149087 non-null  float64
 9   Health/Dental            149087 non-null  float64
 10  Other Benefits           149087 non-null  float64
 11  Total Benefits           149087 non-null  float64
 12  Class                    149087 non-null  int64  
dtypes: float64(6), int64(7)
memory usage: 14.8 MB
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Year</th>
      <th>Organization Group Code</th>
      <th>Department Code</th>
      <th>Union Code</th>
      <th>Job Family Code</th>
      <th>Job Code</th>
      <th>Overtime</th>
      <th>Other Salaries</th>
      <th>Retirement</th>
      <th>Health/Dental</th>
      <th>Other Benefits</th>
      <th>Total Benefits</th>
      <th>Class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>4</td>
      <td>3</td>
      <td>0</td>
      <td>535</td>
      <td>0</td>
      <td>0</td>
      <td>0.00</td>
      <td>240.00</td>
      <td>11896.36</td>
      <td>13765.55</td>
      <td>5248.43</td>
      <td>30910.34</td>
      <td>2</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>6</td>
      <td>0</td>
      <td>21</td>
      <td>0</td>
      <td>0</td>
      <td>0.00</td>
      <td>400.00</td>
      <td>15429.94</td>
      <td>9337.37</td>
      <td>5599.01</td>
      <td>30366.32</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>3</td>
      <td>0</td>
      <td>535</td>
      <td>0</td>
      <td>0</td>
      <td>0.00</td>
      <td>1080.00</td>
      <td>9682.00</td>
      <td>8848.03</td>
      <td>3463.92</td>
      <td>21993.95</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>798</td>
      <td>0</td>
      <td>0</td>
      <td>25730.46</td>
      <td>18414.18</td>
      <td>24222.26</td>
      <td>13911.13</td>
      <td>2416.58</td>
      <td>40549.97</td>
      <td>3</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>790</td>
      <td>0</td>
      <td>0</td>
      <td>1138.28</td>
      <td>2148.11</td>
      <td>15437.62</td>
      <td>12828.15</td>
      <td>7246.54</td>
      <td>35512.31</td>
      <td>3</td>
    </tr>
  </tbody>
</table>
</div>

<p>kdeplot(核密度估计图)</p>

<p>核密度估计(kernel density estimation)是在概率论中用来估计未知的密度函数，属于非参数检验方法之一。通过核密度估计图可以比较直观的看出数据样本本身的分布特征。具体用法如下：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'Overtime'</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">kdeplot</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="n">train</span><span class="p">[</span><span class="s">'Class'</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span><span class="p">][</span><span class="s">'Overtime'</span><span class="p">],</span><span class="n">label</span><span class="o">=</span><span class="s">'Low Range'</span><span class="p">,</span><span class="n">shade</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">kdeplot</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="n">train</span><span class="p">[</span><span class="s">'Class'</span><span class="p">]</span><span class="o">==</span><span class="mi">2</span><span class="p">][</span><span class="s">'Overtime'</span><span class="p">],</span><span class="n">label</span><span class="o">=</span><span class="s">'Mid Range'</span><span class="p">,</span><span class="n">shade</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">kdeplot</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="n">train</span><span class="p">[</span><span class="s">'Class'</span><span class="p">]</span><span class="o">==</span><span class="mi">3</span><span class="p">][</span><span class="s">'Overtime'</span><span class="p">],</span><span class="n">label</span><span class="o">=</span><span class="s">'High Range'</span><span class="p">,</span><span class="n">shade</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>No handles with labels found to put in legend.





&lt;AxesSubplot:xlabel='Overtime', ylabel='Density'&gt;
</code></pre></div></div>

<p><img src="/assets/2023-11-01-Understanding-the-performance-of-LightGBM-and-XGBoost_files/2023-11-01-Understanding-the-performance-of-LightGBM-and-XGBoost_23_2.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'Other Salaries'</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">kdeplot</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="n">train</span><span class="p">[</span><span class="s">'Class'</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span><span class="p">][</span><span class="s">'Other Salaries'</span><span class="p">],</span><span class="n">label</span><span class="o">=</span><span class="s">'Low Range'</span><span class="p">,</span> <span class="n">shade</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">kdeplot</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="n">train</span><span class="p">[</span><span class="s">'Class'</span><span class="p">]</span><span class="o">==</span><span class="mi">2</span><span class="p">][</span><span class="s">'Other Salaries'</span><span class="p">],</span><span class="n">label</span><span class="o">=</span><span class="s">'Mid Range'</span><span class="p">,</span> <span class="n">shade</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">kdeplot</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="n">train</span><span class="p">[</span><span class="s">'Class'</span><span class="p">]</span><span class="o">==</span><span class="mi">3</span><span class="p">][</span><span class="s">'Other Salaries'</span><span class="p">],</span><span class="n">label</span><span class="o">=</span><span class="s">'High Range'</span><span class="p">,</span> <span class="n">shade</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>No handles with labels found to put in legend.





&lt;AxesSubplot:xlabel='Other Salaries', ylabel='Density'&gt;
</code></pre></div></div>

<p><img src="/assets/2023-11-01-Understanding-the-performance-of-LightGBM-and-XGBoost_files/2023-11-01-Understanding-the-performance-of-LightGBM-and-XGBoost_24_2.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'Retirement'</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">kdeplot</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="n">train</span><span class="p">[</span><span class="s">'Class'</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span><span class="p">][</span><span class="s">'Retirement'</span><span class="p">],</span><span class="n">label</span><span class="o">=</span><span class="s">'Low Range'</span><span class="p">,</span> <span class="n">shade</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">kdeplot</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="n">train</span><span class="p">[</span><span class="s">'Class'</span><span class="p">]</span><span class="o">==</span><span class="mi">2</span><span class="p">][</span><span class="s">'Retirement'</span><span class="p">],</span><span class="n">label</span><span class="o">=</span><span class="s">'Mid Range'</span><span class="p">,</span> <span class="n">shade</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">kdeplot</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="n">train</span><span class="p">[</span><span class="s">'Class'</span><span class="p">]</span><span class="o">==</span><span class="mi">3</span><span class="p">][</span><span class="s">'Retirement'</span><span class="p">],</span><span class="n">label</span><span class="o">=</span><span class="s">'High Range'</span><span class="p">,</span> <span class="n">shade</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>No handles with labels found to put in legend.





&lt;AxesSubplot:xlabel='Retirement', ylabel='Density'&gt;
</code></pre></div></div>

<p><img src="/assets/2023-11-01-Understanding-the-performance-of-LightGBM-and-XGBoost_files/2023-11-01-Understanding-the-performance-of-LightGBM-and-XGBoost_25_2.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'Health/Dental'</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">kdeplot</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="n">train</span><span class="p">[</span><span class="s">'Class'</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span><span class="p">][</span><span class="s">'Health/Dental'</span><span class="p">],</span><span class="n">label</span><span class="o">=</span><span class="s">'Low Range'</span><span class="p">,</span> <span class="n">shade</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">kdeplot</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="n">train</span><span class="p">[</span><span class="s">'Class'</span><span class="p">]</span><span class="o">==</span><span class="mi">2</span><span class="p">][</span><span class="s">'Health/Dental'</span><span class="p">],</span><span class="n">label</span><span class="o">=</span><span class="s">'Mid Range'</span><span class="p">,</span> <span class="n">shade</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">kdeplot</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="n">train</span><span class="p">[</span><span class="s">'Class'</span><span class="p">]</span><span class="o">==</span><span class="mi">3</span><span class="p">][</span><span class="s">'Health/Dental'</span><span class="p">],</span><span class="n">label</span><span class="o">=</span><span class="s">'High Range'</span><span class="p">,</span> <span class="n">shade</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>No handles with labels found to put in legend.





&lt;AxesSubplot:xlabel='Health/Dental', ylabel='Density'&gt;
</code></pre></div></div>

<p><img src="/assets/2023-11-01-Understanding-the-performance-of-LightGBM-and-XGBoost_files/2023-11-01-Understanding-the-performance-of-LightGBM-and-XGBoost_26_2.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'Other Benefits'</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">kdeplot</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="n">train</span><span class="p">[</span><span class="s">'Class'</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span><span class="p">][</span><span class="s">'Other Benefits'</span><span class="p">],</span><span class="n">label</span><span class="o">=</span><span class="s">'Low Range'</span><span class="p">,</span> <span class="n">shade</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">kdeplot</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="n">train</span><span class="p">[</span><span class="s">'Class'</span><span class="p">]</span><span class="o">==</span><span class="mi">2</span><span class="p">][</span><span class="s">'Other Benefits'</span><span class="p">],</span><span class="n">label</span><span class="o">=</span><span class="s">'Mid Range'</span><span class="p">,</span> <span class="n">shade</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">kdeplot</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="n">train</span><span class="p">[</span><span class="s">'Class'</span><span class="p">]</span><span class="o">==</span><span class="mi">3</span><span class="p">][</span><span class="s">'Other Benefits'</span><span class="p">],</span><span class="n">label</span><span class="o">=</span><span class="s">'High Range'</span><span class="p">,</span> <span class="n">shade</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>No handles with labels found to put in legend.





&lt;AxesSubplot:xlabel='Other Benefits', ylabel='Density'&gt;
</code></pre></div></div>

<p><img src="/assets/2023-11-01-Understanding-the-performance-of-LightGBM-and-XGBoost_files/2023-11-01-Understanding-the-performance-of-LightGBM-and-XGBoost_27_2.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'Total Benefits'</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">kdeplot</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="n">train</span><span class="p">[</span><span class="s">'Class'</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span><span class="p">][</span><span class="s">'Total Benefits'</span><span class="p">],</span><span class="n">label</span><span class="o">=</span><span class="s">'Low Range'</span><span class="p">,</span> <span class="n">shade</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">kdeplot</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="n">train</span><span class="p">[</span><span class="s">'Class'</span><span class="p">]</span><span class="o">==</span><span class="mi">2</span><span class="p">][</span><span class="s">'Total Benefits'</span><span class="p">],</span><span class="n">label</span><span class="o">=</span><span class="s">'Mid Range'</span><span class="p">,</span> <span class="n">shade</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">kdeplot</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="n">train</span><span class="p">[</span><span class="s">'Class'</span><span class="p">]</span><span class="o">==</span><span class="mi">3</span><span class="p">][</span><span class="s">'Total Benefits'</span><span class="p">],</span><span class="n">label</span><span class="o">=</span><span class="s">'High Range'</span><span class="p">,</span> <span class="n">shade</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>No handles with labels found to put in legend.





&lt;AxesSubplot:xlabel='Total Benefits', ylabel='Density'&gt;
</code></pre></div></div>

<p><img src="/assets/2023-11-01-Understanding-the-performance-of-LightGBM-and-XGBoost_files/2023-11-01-Understanding-the-performance-of-LightGBM-and-XGBoost_28_2.png" alt="png" /></p>

<h4 id="it-seems-from-the-above-eda-that-low-range-employees-receive-mostly-no-retirement-other-salaries-and-other-benefits-thus-oevrall-amount-of-benefits-received-by-low-range-earners-is-very-less"><em>It seems from the above EDA that Low Range employees receive mostly no Retirement, Other Salaries and Other Benefits. Thus oevrall amount of benefits received by Low Range earners is very less</em></h4>

<h4 id="in-case-of-mid-range-earners-they-seem-to-be-the-largest-earners-of-overtime-their-other-salaries-mostly-seem-to-be-zero-same-as-low-range--high-range-earners-retirement-benefits-is-less-than-high-range-earners-but-there-is-significant-over-lap-between-the-higher-range-of-retirement-benefits-of-mid-range-earners--lower-range-of-retirement-benefits-of-high-range-earners-healthdental-benefits-are-identical-with-that-of-high-range-earners-while-other-benefits-component-is-significantly-higher-for-mid-range-earners-as-compared-to-the-other-2-class"><em>In case of Mid Range earners, they seem to be the largest earners of Overtime. Their Other Salaries mostly seem to be zero, same as Low Range &amp; High Range earners. Retirement benefits is less than High Range earners, but there is significant over-lap between the higher range of Retirement benefits of Mid Range earners &amp; lower-range of Retirement benefits of High Range earners. Health/Dental benefits are identical with that of High Range earners while Other Benefits component is significantly higher for Mid Range earners, as compared to the other 2 class</em></h4>

<h4 id="high-range-earners-mostly-dont-earn-any-overtime-or-other-salaries-as-already-seen-they-earn-slightly-better-other-benefits--retirals-than-mid-range-earners-with-whom-they-share-similar-healthdental-benefits"><em>High-Range earners mostly don’t earn any Overtime or Other Salaries. As already seen, they earn slightly better Other Benefits &amp; Retirals than Mid-Range earners, with whom they share similar Health/Dental benefits</em></h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#Dropping the target column 'Class' from the train data &amp; storing it into a new variable
</span><span class="n">y</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="s">'Class'</span><span class="p">]</span>
<span class="n">train</span><span class="p">.</span><span class="n">drop</span><span class="p">(</span><span class="s">'Class'</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<h4 id="splitting-the-train-data-into-2-sets-for-training--validation-by-a-7030-split-test_size03-further-this-split-will-be-done-after-ensuring-that-the-features-are-distributed-in-the-same-proportions-in-the-2-datasets-ie-if-if-the-3-classes-were-initially-distributed-in-the-main-dataset-in-a-304030-ratio-the-same-will-be-maintained-in-the-x_train--x_val-also-this-is-achieved-by-the-stratify-command-although-it-may-not-provide-useful-in-the-current-context-as-we-will-be-employing-up-sampling--down-sampling-techniques"><em>Splitting the train data into 2 sets for training &amp; validation by a 70:30 split (test_size=0.3). Further this split will be done after ensuring that the features are distributed in the same proportions in the 2 datasets, i.e. if if the 3 classes were initially distributed in the main dataset in a 30:40:30 ratio, the same will be maintained in the x_train &amp; x_val also. This is achieved by the ‘stratify’ command, although it may not provide useful in the current context as we will be employing Up-sampling &amp; Down-sampling techniques.</em></h4>
<h4 id="the-random_state-ensures-reproducability-over-multiple-execution-cycles"><em>The random_state ensures reproducability over multiple execution cycles</em></h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x_train</span><span class="p">,</span><span class="n">x_val</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span><span class="n">y_val</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">train</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span><span class="n">stratify</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">y_train</span><span class="p">.</span><span class="n">value_counts</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>3    35567
2    34723
1    34070
Name: Class, dtype: int64
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">y_train</span> <span class="o">=</span> <span class="n">y_train</span> <span class="o">-</span> <span class="mi">1</span>
<span class="n">y_val</span> <span class="o">=</span> <span class="n">y_val</span> <span class="o">-</span> <span class="mi">1</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">XGBClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> 
                      <span class="n">booster</span><span class="o">=</span><span class="s">'gbtree'</span><span class="p">,</span> 
                      <span class="n">objective</span><span class="o">=</span><span class="s">'multi:softmax'</span><span class="p">,</span> 
                      <span class="n">num_class</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> 
                      <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> 
                      <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span>            <span class="c1">#default 
</span>                      <span class="n">n_estimators</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> 
                      <span class="n">max_depth</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span>                  <span class="c1">#default
</span>                      <span class="n">subsample</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>
                      <span class="n">tree_method</span><span class="o">=</span><span class="s">'hist'</span><span class="p">,</span>
                      <span class="n">grow_policy</span><span class="o">=</span><span class="s">'lossguide'</span><span class="p">,</span>
                      <span class="n">max_leaves</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                      <span class="n">max_bin</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>                  <span class="c1">#default
</span>                      <span class="n">eval_metric</span><span class="o">=</span><span class="s">'mlogloss'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x_train</span><span class="p">.</span><span class="n">shape</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(104360, 12)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">start_time</span> <span class="o">=</span> <span class="n">timeit</span><span class="p">.</span><span class="n">default_timer</span><span class="p">()</span>
<span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
<span class="k">print</span> <span class="p">(</span><span class="s">'</span><span class="se">\n</span><span class="s">'</span><span class="p">,</span><span class="s">'Training Accuracy is: '</span><span class="p">,</span><span class="n">model</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">))</span>
<span class="n">stop_time</span> <span class="o">=</span> <span class="n">timeit</span><span class="p">.</span><span class="n">default_timer</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="s">'</span><span class="se">\n</span><span class="s">'</span><span class="p">,</span><span class="s">'Total Training Time: {time} seconds.'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">time</span><span class="o">=</span><span class="nb">round</span><span class="p">(</span><span class="n">stop_time</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>

<span class="n">start_time</span> <span class="o">=</span> <span class="n">timeit</span><span class="p">.</span><span class="n">default_timer</span><span class="p">()</span>
<span class="n">y_pred_test</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_val</span><span class="p">)</span>
<span class="n">stop_time</span> <span class="o">=</span> <span class="n">timeit</span><span class="p">.</span><span class="n">default_timer</span><span class="p">()</span>
<span class="k">print</span> <span class="p">(</span><span class="s">'</span><span class="se">\n</span><span class="s">'</span><span class="p">,</span><span class="s">'Testing Accuracy is: '</span><span class="p">,</span><span class="n">metrics</span><span class="p">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_val</span><span class="p">,</span><span class="n">y_pred_test</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'</span><span class="se">\n</span><span class="s">'</span><span class="p">,</span><span class="s">'Total Testing Time: {time} seconds.'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">time</span><span class="o">=</span><span class="nb">round</span><span class="p">(</span><span class="n">stop_time</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> Training Accuracy is:  0.9930816404752779

 Total Training Time: 4.27 seconds.

 Testing Accuracy is:  0.9871442305542514

 Total Testing Time: 0.18 seconds.
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#Viewing the classification report
</span><span class="k">print</span> <span class="p">(</span><span class="n">metrics</span><span class="p">.</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_val</span><span class="p">,</span><span class="n">y_pred_test</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>              precision    recall  f1-score   support

           0       0.99      0.99      0.99     14602
           1       0.98      0.98      0.98     14881
           2       0.99      0.99      0.99     15244

    accuracy                           0.99     44727
   macro avg       0.99      0.99      0.99     44727
weighted avg       0.99      0.99      0.99     44727
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">LGBMClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> 
                      <span class="n">boosting_type</span><span class="o">=</span><span class="s">'rf'</span><span class="p">,</span>
                      <span class="n">num_leaves</span><span class="o">=</span><span class="mi">31</span><span class="p">,</span>                <span class="c1">#default
</span>                      <span class="n">max_depth</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>                 <span class="c1">#default
</span>                      <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span>
                      <span class="n">n_estimators</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span>             
                      <span class="n">objective</span><span class="o">=</span><span class="s">'multiclass'</span><span class="p">,</span> 
                      <span class="n">class_weight</span><span class="o">=</span><span class="s">'balanced'</span><span class="p">,</span>      <span class="c1">#to handle class imbalance
</span>                      <span class="n">subsample</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>                <span class="c1">#bagging ratio
</span>                      <span class="n">subsample_freq</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>             <span class="c1">#perform bagging at every 5th iteration
</span>                      <span class="n">max_bin</span><span class="o">=</span><span class="mi">255</span><span class="p">,</span>                  <span class="c1">#default
</span>                      <span class="n">metric</span><span class="o">=</span><span class="s">'multi_logloss'</span>
                      <span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">start_time</span> <span class="o">=</span> <span class="n">timeit</span><span class="p">.</span><span class="n">default_timer</span><span class="p">()</span>
<span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
<span class="k">print</span> <span class="p">(</span><span class="s">'</span><span class="se">\n</span><span class="s">'</span><span class="p">,</span><span class="s">'Training Accuracy is: '</span><span class="p">,</span><span class="n">model</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">))</span>
<span class="n">stop_time</span> <span class="o">=</span> <span class="n">timeit</span><span class="p">.</span><span class="n">default_timer</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="s">'</span><span class="se">\n</span><span class="s">'</span><span class="p">,</span><span class="s">'Total Training Time: {time} seconds.'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">time</span><span class="o">=</span><span class="nb">round</span><span class="p">(</span><span class="n">stop_time</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>

<span class="n">start_time</span> <span class="o">=</span> <span class="n">timeit</span><span class="p">.</span><span class="n">default_timer</span><span class="p">()</span>
<span class="n">y_pred_test</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_val</span><span class="p">)</span>
<span class="n">stop_time</span> <span class="o">=</span> <span class="n">timeit</span><span class="p">.</span><span class="n">default_timer</span><span class="p">()</span>
<span class="k">print</span> <span class="p">(</span><span class="s">'</span><span class="se">\n</span><span class="s">'</span><span class="p">,</span><span class="s">'Testing Accuracy is: '</span><span class="p">,</span><span class="n">metrics</span><span class="p">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_val</span><span class="p">,</span><span class="n">y_pred_test</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'</span><span class="se">\n</span><span class="s">'</span><span class="p">,</span><span class="s">'Total Testing Time: {time} seconds.'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">time</span><span class="o">=</span><span class="nb">round</span><span class="p">(</span><span class="n">stop_time</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> Training Accuracy is:  0.9659448064392487

 Total Training Time: 4.61 seconds.

 Testing Accuracy is:  0.9639144141122812

 Total Testing Time: 0.3 seconds.
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#Viewing the classification report
</span><span class="k">print</span> <span class="p">(</span><span class="n">metrics</span><span class="p">.</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_val</span><span class="p">,</span><span class="n">y_pred_test</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>              precision    recall  f1-score   support

           0       0.98      0.98      0.98     14602
           1       0.95      0.95      0.95     14881
           2       0.97      0.97      0.97     15244

    accuracy                           0.96     44727
   macro avg       0.96      0.96      0.96     44727
weighted avg       0.96      0.96      0.96     44727
</code></pre></div></div>

<h3 id="using-pca-to-verify-if-model-accuracy-can-be-increased-later-we-will-try-imbalanced-learning-on-pca-data-also">Using PCA to verify if model accuracy can be increased. Later, we will try imbalanced learning on PCA data also</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'./data/train.csv'</span><span class="p">)</span>
<span class="n">test</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'./data/test.csv'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">label_encoder</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
<span class="n">lbl_binarizer1</span> <span class="o">=</span> <span class="n">LabelBinarizer</span><span class="p">()</span>
<span class="n">lbl_binarizer2</span> <span class="o">=</span> <span class="n">LabelBinarizer</span><span class="p">()</span>
<span class="n">lbl_binarizer3</span> <span class="o">=</span> <span class="n">LabelBinarizer</span><span class="p">()</span>
<span class="n">train</span><span class="p">[</span><span class="s">'Year'</span><span class="p">]</span><span class="o">=</span> <span class="n">label_encoder</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="s">'Year'</span><span class="p">])</span>
<span class="n">train</span><span class="p">[</span><span class="s">'Department Code'</span><span class="p">]</span><span class="o">=</span> <span class="n">lbl_binarizer1</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="s">'Department Code'</span><span class="p">])</span>
<span class="n">train</span><span class="p">[</span><span class="s">'Job Family Code'</span><span class="p">]</span><span class="o">=</span> <span class="n">lbl_binarizer2</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="s">'Job Family Code'</span><span class="p">])</span>
<span class="n">train</span><span class="p">[</span><span class="s">'Job Code'</span><span class="p">]</span><span class="o">=</span> <span class="n">lbl_binarizer3</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="s">'Job Code'</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">test</span><span class="p">[</span><span class="s">'Year'</span><span class="p">]</span><span class="o">=</span> <span class="n">label_encoder</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="s">'Year'</span><span class="p">])</span>
<span class="n">test</span><span class="p">[</span><span class="s">'Department Code'</span><span class="p">]</span><span class="o">=</span> <span class="n">lbl_binarizer1</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="s">'Department Code'</span><span class="p">])</span>
<span class="n">test</span><span class="p">[</span><span class="s">'Job Family Code'</span><span class="p">]</span><span class="o">=</span> <span class="n">lbl_binarizer2</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="s">'Job Family Code'</span><span class="p">])</span>
<span class="n">test</span><span class="p">[</span><span class="s">'Job Code'</span><span class="p">]</span><span class="o">=</span> <span class="n">lbl_binarizer3</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="s">'Job Code'</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span><span class="p">,</span><span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>   
<span class="n">sns</span><span class="p">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">train</span><span class="p">.</span><span class="n">corr</span><span class="p">(),</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span> <span class="s">'.2f'</span><span class="p">,</span><span class="n">cmap</span><span class="o">=</span><span class="s">"magma"</span><span class="p">)</span> 
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;AxesSubplot:&gt;
</code></pre></div></div>

<p><img src="/assets/2023-11-01-Understanding-the-performance-of-LightGBM-and-XGBoost_files/2023-11-01-Understanding-the-performance-of-LightGBM-and-XGBoost_48_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train</span><span class="p">[[</span><span class="s">'Retirement'</span><span class="p">,</span><span class="s">'Health/Dental'</span><span class="p">,</span><span class="s">'Other Benefits'</span><span class="p">,</span><span class="s">'Total Benefits'</span><span class="p">]].</span><span class="n">corr</span><span class="p">()</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Retirement</th>
      <th>Health/Dental</th>
      <th>Other Benefits</th>
      <th>Total Benefits</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Retirement</th>
      <td>1.000000</td>
      <td>0.787526</td>
      <td>0.671137</td>
      <td>0.962205</td>
    </tr>
    <tr>
      <th>Health/Dental</th>
      <td>0.787526</td>
      <td>1.000000</td>
      <td>0.606259</td>
      <td>0.888821</td>
    </tr>
    <tr>
      <th>Other Benefits</th>
      <td>0.671137</td>
      <td>0.606259</td>
      <td>1.000000</td>
      <td>0.796860</td>
    </tr>
    <tr>
      <th>Total Benefits</th>
      <td>0.962205</td>
      <td>0.888821</td>
      <td>0.796860</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div>

<h4 id="looking-to-run-pca-on-the-above-columns-which-have-high-collinearity"><em>Looking to run PCA on the above columns which have high collinearity</em></h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
<span class="n">sns</span><span class="p">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">train</span><span class="p">[[</span><span class="s">'Retirement'</span><span class="p">,</span><span class="s">'Health/Dental'</span><span class="p">,</span><span class="s">'Other Benefits'</span><span class="p">,</span><span class="s">'Total Benefits'</span><span class="p">]])</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;AxesSubplot:&gt;
</code></pre></div></div>

<p><img src="/assets/2023-11-01-Understanding-the-performance-of-LightGBM-and-XGBoost_files/2023-11-01-Understanding-the-performance-of-LightGBM-and-XGBoost_51_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">scaler</span><span class="o">=</span><span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">pca</span><span class="o">=</span><span class="n">decomposition</span><span class="p">.</span><span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s">'Retirement'</span><span class="p">,</span><span class="s">'Health/Dental'</span><span class="p">,</span><span class="s">'Other Benefits'</span><span class="p">,</span><span class="s">'Total Benefits'</span><span class="p">]</span>
<span class="n">data_scaled</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">scaler</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">train</span><span class="p">[[</span><span class="s">'Retirement'</span><span class="p">,</span><span class="s">'Health/Dental'</span><span class="p">,</span><span class="s">'Other Benefits'</span><span class="p">,</span><span class="s">'Total Benefits'</span><span class="p">]]),</span><span class="n">columns</span><span class="o">=</span><span class="n">columns</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
<span class="n">sns</span><span class="p">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data_scaled</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;AxesSubplot:&gt;
</code></pre></div></div>

<p><img src="/assets/2023-11-01-Understanding-the-performance-of-LightGBM-and-XGBoost_files/2023-11-01-Understanding-the-performance-of-LightGBM-and-XGBoost_54_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># PCA
# Step 1 - Create covariance matrix
</span><span class="n">cov_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">cov</span><span class="p">(</span><span class="n">data_scaled</span><span class="p">.</span><span class="n">T</span><span class="p">)</span>
<span class="c1"># Step 2- Get eigen values and eigen vector
</span><span class="n">eig_vals</span><span class="p">,</span> <span class="n">eig_vecs</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="n">eig</span><span class="p">(</span><span class="n">cov_matrix</span><span class="p">)</span>
<span class="c1">#Step 3- Understanding cumulative variance
</span><span class="n">tot</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">eig_vals</span><span class="p">)</span>
<span class="n">var_exp</span> <span class="o">=</span> <span class="p">[(</span> <span class="n">i</span> <span class="o">/</span><span class="n">tot</span> <span class="p">)</span> <span class="o">*</span> <span class="mi">100</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">eig_vals</span><span class="p">,</span> <span class="n">reverse</span><span class="o">=</span><span class="bp">True</span><span class="p">)]</span>
<span class="n">cum_var_exp</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">var_exp</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Cumulative Variance Explained"</span><span class="p">,</span> <span class="n">cum_var_exp</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Cumulative Variance Explained [ 84.25437992  94.72404974 100.         100.        ]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pcadata_reduced</span> <span class="o">=</span> <span class="n">pca</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">data_scaled</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">proj_data_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">pcadata_reduced</span><span class="p">)</span>  <span class="c1"># converting array to dataframe for pairplot
</span><span class="n">pca_df</span> <span class="o">=</span> <span class="n">proj_data_df</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">train</span><span class="p">)</span>             <span class="c1"># adding back the PCA to the main dataset
</span></code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pca_df</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>ID</th>
      <th>Year Type</th>
      <th>Year</th>
      <th>Organization Group Code</th>
      <th>Organization Group</th>
      <th>Department Code</th>
      <th>Department</th>
      <th>...</th>
      <th>Job Code</th>
      <th>Job</th>
      <th>Employee Identifier</th>
      <th>Overtime</th>
      <th>Other Salaries</th>
      <th>Retirement</th>
      <th>Health/Dental</th>
      <th>Other Benefits</th>
      <th>Total Benefits</th>
      <th>Class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.624622</td>
      <td>-0.327289</td>
      <td>-0.689272</td>
      <td>9248</td>
      <td>Fiscal</td>
      <td>4</td>
      <td>3</td>
      <td>Human Welfare &amp; Neighborhood Development</td>
      <td>0</td>
      <td>HSA Human Services Agency</td>
      <td>...</td>
      <td>0</td>
      <td>Senior Eligibility Worker</td>
      <td>41351</td>
      <td>0.00</td>
      <td>240.00</td>
      <td>11896.36</td>
      <td>13765.55</td>
      <td>5248.43</td>
      <td>30910.34</td>
      <td>2</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.403335</td>
      <td>0.081200</td>
      <td>0.149623</td>
      <td>44541</td>
      <td>Fiscal</td>
      <td>1</td>
      <td>6</td>
      <td>General Administration &amp; Finance</td>
      <td>0</td>
      <td>ASR Assessor / Recorder</td>
      <td>...</td>
      <td>0</td>
      <td>Sr Personal Property Auditor</td>
      <td>41792</td>
      <td>0.00</td>
      <td>400.00</td>
      <td>15429.94</td>
      <td>9337.37</td>
      <td>5599.01</td>
      <td>30366.32</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-0.463135</td>
      <td>-0.163763</td>
      <td>-0.155547</td>
      <td>47031</td>
      <td>Fiscal</td>
      <td>1</td>
      <td>3</td>
      <td>Human Welfare &amp; Neighborhood Development</td>
      <td>0</td>
      <td>HSA Human Services Agency</td>
      <td>...</td>
      <td>0</td>
      <td>Social Worker</td>
      <td>9357</td>
      <td>0.00</td>
      <td>1080.00</td>
      <td>9682.00</td>
      <td>8848.03</td>
      <td>3463.92</td>
      <td>21993.95</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1.275232</td>
      <td>-1.284027</td>
      <td>0.376024</td>
      <td>139416</td>
      <td>Fiscal</td>
      <td>1</td>
      <td>1</td>
      <td>Public Protection</td>
      <td>0</td>
      <td>FIR Fire Department</td>
      <td>...</td>
      <td>0</td>
      <td>Firefighter</td>
      <td>28022</td>
      <td>25730.46</td>
      <td>18414.18</td>
      <td>24222.26</td>
      <td>13911.13</td>
      <td>2416.58</td>
      <td>40549.97</td>
      <td>3</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1.098471</td>
      <td>0.089262</td>
      <td>-0.367685</td>
      <td>123780</td>
      <td>Fiscal</td>
      <td>0</td>
      <td>2</td>
      <td>Public Works, Transportation &amp; Commerce</td>
      <td>0</td>
      <td>MTA Municipal Transprtn Agncy</td>
      <td>...</td>
      <td>0</td>
      <td>Pr Payroll &amp; Personnel Clerk</td>
      <td>51052</td>
      <td>1138.28</td>
      <td>2148.11</td>
      <td>15437.62</td>
      <td>12828.15</td>
      <td>7246.54</td>
      <td>35512.31</td>
      <td>3</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 24 columns</p>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data_scaled_test</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">scaler</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">test</span><span class="p">[[</span><span class="s">'Retirement'</span><span class="p">,</span><span class="s">'Health/Dental'</span><span class="p">,</span><span class="s">'Other Benefits'</span><span class="p">,</span><span class="s">'Total Benefits'</span><span class="p">]]),</span><span class="n">columns</span><span class="o">=</span><span class="n">columns</span><span class="p">)</span>
<span class="n">pcadata_reduced_test</span> <span class="o">=</span> <span class="n">pca</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data_scaled_test</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">proj_data_df_test</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">pcadata_reduced_test</span><span class="p">)</span>  <span class="c1"># converting array to dataframe for pairplot
</span><span class="n">pca_df_test</span> <span class="o">=</span> <span class="n">proj_data_df_test</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">test</span><span class="p">)</span> 
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pca_df</span><span class="p">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s">'ID'</span><span class="p">,</span><span class="s">'Organization Group'</span><span class="p">,</span><span class="s">'Department'</span><span class="p">,</span><span class="s">'Union'</span><span class="p">,</span>
                    <span class="s">'Job Family'</span><span class="p">,</span><span class="s">'Job'</span><span class="p">,</span><span class="s">'Employee Identifier'</span><span class="p">,</span><span class="s">'Year Type'</span><span class="p">,</span>
                     <span class="s">'Retirement'</span><span class="p">,</span><span class="s">'Health/Dental'</span><span class="p">,</span><span class="s">'Other Benefits'</span><span class="p">,</span><span class="s">'Total Benefits'</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">pca_df_test</span><span class="p">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s">'ID'</span><span class="p">,</span><span class="s">'Organization Group'</span><span class="p">,</span><span class="s">'Department'</span><span class="p">,</span><span class="s">'Union'</span><span class="p">,</span>
                    <span class="s">'Job Family'</span><span class="p">,</span><span class="s">'Job'</span><span class="p">,</span><span class="s">'Employee Identifier'</span><span class="p">,</span><span class="s">'Year Type'</span><span class="p">,</span>
                     <span class="s">'Retirement'</span><span class="p">,</span><span class="s">'Health/Dental'</span><span class="p">,</span><span class="s">'Other Benefits'</span><span class="p">,</span><span class="s">'Total Benefits'</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pca_df</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>Year</th>
      <th>Organization Group Code</th>
      <th>Department Code</th>
      <th>Union Code</th>
      <th>Job Family Code</th>
      <th>Job Code</th>
      <th>Overtime</th>
      <th>Other Salaries</th>
      <th>Class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.624622</td>
      <td>-0.327289</td>
      <td>-0.689272</td>
      <td>4</td>
      <td>3</td>
      <td>0</td>
      <td>535</td>
      <td>0</td>
      <td>0</td>
      <td>0.00</td>
      <td>240.00</td>
      <td>2</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.403335</td>
      <td>0.081200</td>
      <td>0.149623</td>
      <td>1</td>
      <td>6</td>
      <td>0</td>
      <td>21</td>
      <td>0</td>
      <td>0</td>
      <td>0.00</td>
      <td>400.00</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-0.463135</td>
      <td>-0.163763</td>
      <td>-0.155547</td>
      <td>1</td>
      <td>3</td>
      <td>0</td>
      <td>535</td>
      <td>0</td>
      <td>0</td>
      <td>0.00</td>
      <td>1080.00</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1.275232</td>
      <td>-1.284027</td>
      <td>0.376024</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>798</td>
      <td>0</td>
      <td>0</td>
      <td>25730.46</td>
      <td>18414.18</td>
      <td>3</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1.098471</td>
      <td>0.089262</td>
      <td>-0.367685</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>790</td>
      <td>0</td>
      <td>0</td>
      <td>1138.28</td>
      <td>2148.11</td>
      <td>3</td>
    </tr>
  </tbody>
</table>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">y</span> <span class="o">=</span> <span class="n">pca_df</span><span class="p">[</span><span class="s">'Class'</span><span class="p">]</span>
<span class="n">pca_df</span><span class="p">.</span><span class="n">drop</span><span class="p">(</span><span class="s">'Class'</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x_train</span><span class="p">,</span><span class="n">x_val</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span><span class="n">y_val</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">pca_df</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span><span class="n">stratify</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model2</span> <span class="o">=</span> <span class="n">LGBMClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> 
                      <span class="n">boosting_type</span><span class="o">=</span><span class="s">'rf'</span><span class="p">,</span>
                      <span class="n">num_leaves</span><span class="o">=</span><span class="mi">31</span><span class="p">,</span>                <span class="c1">#default
</span>                      <span class="n">max_depth</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>                 <span class="c1">#default
</span>                      <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span>
                      <span class="n">n_estimators</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span>             
                      <span class="n">objective</span><span class="o">=</span><span class="s">'multiclass'</span><span class="p">,</span> 
                      <span class="n">class_weight</span><span class="o">=</span><span class="s">'balanced'</span><span class="p">,</span>      <span class="c1">#to handle class imbalance
</span>                      <span class="n">subsample</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>                <span class="c1">#bagging ratio
</span>                      <span class="n">subsample_freq</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>             <span class="c1">#perform bagging at every 5th iteration
</span>                      <span class="n">max_bin</span><span class="o">=</span><span class="mi">255</span><span class="p">,</span>                  <span class="c1">#default
</span>                      <span class="n">metric</span><span class="o">=</span><span class="s">'multi_logloss'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">start_time</span> <span class="o">=</span> <span class="n">timeit</span><span class="p">.</span><span class="n">default_timer</span><span class="p">()</span>
<span class="n">model2</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
<span class="k">print</span> <span class="p">(</span><span class="s">'</span><span class="se">\n</span><span class="s">'</span><span class="p">,</span><span class="s">'Training Accuracy is: '</span><span class="p">,</span><span class="n">model2</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">))</span>
<span class="n">stop_time</span> <span class="o">=</span> <span class="n">timeit</span><span class="p">.</span><span class="n">default_timer</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="s">'</span><span class="se">\n</span><span class="s">'</span><span class="p">,</span><span class="s">'Total Training Time: {time} seconds.'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">time</span><span class="o">=</span><span class="nb">round</span><span class="p">(</span><span class="n">stop_time</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>

<span class="n">start_time</span> <span class="o">=</span> <span class="n">timeit</span><span class="p">.</span><span class="n">default_timer</span><span class="p">()</span>
<span class="n">y_pred_test</span> <span class="o">=</span> <span class="n">model2</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_val</span><span class="p">)</span>
<span class="n">stop_time</span> <span class="o">=</span> <span class="n">timeit</span><span class="p">.</span><span class="n">default_timer</span><span class="p">()</span>
<span class="k">print</span> <span class="p">(</span><span class="s">'</span><span class="se">\n</span><span class="s">'</span><span class="p">,</span><span class="s">'Testing Accuracy is: '</span><span class="p">,</span><span class="n">metrics</span><span class="p">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_val</span><span class="p">,</span><span class="n">y_pred_test</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'</span><span class="se">\n</span><span class="s">'</span><span class="p">,</span><span class="s">'Total Testing Time: {time} seconds.'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">time</span><span class="o">=</span><span class="nb">round</span><span class="p">(</span><span class="n">stop_time</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> Training Accuracy is:  0.9529225756995017

 Total Training Time: 4.25 seconds.

 Testing Accuracy is:  0.9506785610481365

 Total Testing Time: 0.33 seconds.
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#Viewing the classification report
</span><span class="k">print</span> <span class="p">(</span><span class="n">metrics</span><span class="p">.</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_val</span><span class="p">,</span><span class="n">y_pred_test</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>              precision    recall  f1-score   support

           1       0.96      0.97      0.97     14602
           2       0.93      0.92      0.93     14881
           3       0.96      0.96      0.96     15244

    accuracy                           0.95     44727
   macro avg       0.95      0.95      0.95     44727
weighted avg       0.95      0.95      0.95     44727
</code></pre></div></div>

<h3 id="lightgbm-provides-a-much-faster-throughput-than-xgboost-this-is-even-more-accentuated-when-some-of-the-collinear-features-are-replaced-with-equivalent-principal-components-with-both-training-time--model-accuracy-improving-considerably"><em>LightGBM provides a much faster throughput than XGBoost. This is even more accentuated when some of the collinear features are replaced with equivalent Principal Components, with both training time &amp; model accuracy improving considerably</em></h3>

<p>From my run , there are no major difference in time betwen XgBoost and LightGBM, accuracy Xgboost is better….I guess there are some improvement in the xgboost in the sklearn.</p>

</div>

<span class="post-tags">
    
      <i class="fa fa-tag fa-xs" aria-hidden="true"></i>
      
      <a class="no-underline" href="/tag/AI"><nobr>AI</nobr></code>&nbsp;</a>    
    
      <i class="fa fa-tag fa-xs" aria-hidden="true"></i>
      
      <a class="no-underline" href="/tag/LightGBM"><nobr>LightGBM</nobr></code>&nbsp;</a>    
    
      <i class="fa fa-tag fa-xs" aria-hidden="true"></i>
      
      <a class="no-underline" href="/tag/XGBoost"><nobr>XGBoost</nobr></code>&nbsp;</a>    
    
</span>

<div class="recent">
  <h2>Recent Posts</h2>
  <ul class="recent-posts">
    
      <li>
        <h4>
          <a href="/coding/2023/12/11/diffusion-model-demo2.html">
            A Diffusion Model from Scratch in Pytorch
          </a>
          <small>[11 Dec 2023]</small>
        </h4>
      </li>
    
      <li>
        <h4>
          <a href="/coding/2023/12/11/diffusion-model-demo1.html">
            Diffusion Models Tutorial
          </a>
          <small>[11 Dec 2023]</small>
        </h4>
      </li>
    
      <li>
        <h4>
          <a href="/coding/2023/12/02/Inspect-BERT-Vocabulary.html">
            Inspect BERT Vocabulary
          </a>
          <small>[02 Dec 2023]</small>
        </h4>
      </li>
    
  </ul>
</div>
    </div>

  </body>
</html>
